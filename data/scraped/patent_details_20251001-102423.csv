publication_number,title,abstract,cpc_codes
US12299796B2,Generation of story videos corresponding to user input using generative models,"The present disclosure provides systems and methods for video generation corresponding to a user input. Given a user input, a story video with content relevant to the user input can be generated. One aspect includes a computing system comprising a processor and memory. The processor can be configured to execute a program using portions of the memory to receive the user input, generate a story text based on the user input, generate a plurality of story images based on the story text, and output a story including the story text and a story video having content corresponding to the story text, wherein the story video includes the plurality of story images. Additionally or alternatively, the story video can include audio data and a plurality of generated animated videos, each animated video corresponding to a story image in the plurality of story images.","['G06T13/80', 'G06T13/00', 'G06F16/5846', 'G06F16/635', 'G06F3/167', 'G06F40/216', 'G06F40/30', 'G06F40/44', 'G06T13/20', 'G06T7/50', 'G10L13/02', 'G11B27/031', 'G11B27/28', 'G06T2200/24', 'G06T2207/10016', 'G06T2213/04']"
US12412340B2,Synthesizing three-dimensional shapes using latent diffusion models in content generation systems and applications,"Approaches presented herein provide for the unconditional generation of novel three dimensional (3D) object shape representations, such as point clouds or meshes. In at least one embodiment, a first denoising diffusion model (DDM) can be trained to synthesize a 1D shape latent from Gaussian noise, and a second DDM can be trained to generate a set of latent points conditioned on this 1D shape latent. The shape latent and set of latent points can be provided to a decoder to generate a 3D point cloud representative of a random object from among the object classes on which the models were trained. A surface reconstruction process may be used to generate a surface mesh from this generated point cloud. Such an approach can scale to complex and/or multimodal distributions, and can be highly flexible as it can be adapted to various tasks such as multimodal voxel- or text-guided synthesis.","['G06T19/20', 'G06T17/20', 'G06V10/44', 'G06V10/82', 'G06V20/64', 'G06T2210/56', 'G06T2219/2021']"
US20230377099A1,Synthesizing content using diffusion models in content generation systems and applications,"Approaches presented herein provide for the generation of synthesized data from input noise using a denoising diffusion network. A higher order differential equation solver can be used for the denoising process, with one or more higher-order terms being distilled into one or more separate efficient neural networks. A separate, efficient neural network can be called together with a primary denoising model at inference time without significant loss in sampling efficiency. The separate neural network can provide information about the curvature (or other higher-order term) of the differential equation, representing a denoising trajectory, that can be used by the primary diffusion network to denoise the image using fewer denoising iterations.","['G06T5/002', 'G06T5/70', 'G06N3/042', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/096', 'G06T11/00', 'G06T5/60', 'G06T7/64', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
CN117911230B,Image invisible watermark embedding detection processing method and device based on diffusion model,"The invention provides an image invisible watermark embedding detection processing method and device based on a diffusion model. The image invisible watermark embedding detection processing method based on the diffusion model comprises the following steps: acquiring an original image, a watermark image and a random encryption sequence; performing forward diffusion processing on the original image and the watermark image according to the random encryption sequence to obtain image mixed characteristic data; performing reverse denoising processing on the image mixed characteristic data according to the random encryption sequence to obtain image characteristics; when the original image is an image to be embedded with a watermark, obtaining the watermark embedded image according to the image characteristics; and when the original image is an embedded watermark image, decoding the image characteristic according to a watermark decoder to obtain a watermark characteristic, and obtaining a watermark detection result according to the watermark characteristic and the watermark image. The invention has the advantages of clear watermark extraction, embedding and detection capability and difficult erasure and modification.","['G06T1/0021', 'G06F21/602', 'G06T2201/005', 'G06T2201/0065']"
US20250063136A1,Generative ai-based video aspect ratio enhancement,"A method includes obtaining, using at least one processing device of an electronic device, a video including multiple scenes at a first aspect ratio. The method also includes performing, using the at least one processing device, backward optical flow estimation and forward optical flow estimation for each of the multiple scenes to select an image frame having a largest missing area. The method further includes performing, using the at least one processing device, outpainting on the image frame having the largest missing area to generate a first outpainted image frame at a second aspect ratio different from the first aspect ratio. In addition, the method includes performing, using the at least one processing device, backward optical flow estimation and forward optical flow estimation using the first outpainted image frame to generate additional outpainted image frames in the multiple scenes at the second aspect ratio.","['H04N21/440272', 'G06T5/77', 'G06T5/60', 'G06T7/20', 'H04N21/4666', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'H04N7/0122']"
WO2024158987A1,Equivariant diffusion model for generative protein design,"A method may include applying a protein design computation model to generate an output sequence and an output three-dimensional structure of an output protein molecule by jointly denoising an input sequence and an input three-dimensional structure of an input protein molecule. The joint denoising may include modifying the input sequence by inserting, deleting, or changing the type of one or more constituent amino acid residues while performing corresponding updates to the positions of the atoms in each amino acid residue. The protein design computation model may operate on a fixed size representation of the input protein molecule. Prior and/or subsequent to the joint denoising, the protein design computation model may modify the input three-dimensional structure to conform to bond constraints. Moreover, an informative prior data distribution may be incorporated by training the protein design computation model on training samples with noise sampled from the informative prior data distribution.","['G16B15/20', 'G16B40/20']"
US20250284926A1,"Generative Model Training Method and Apparatus, and Data Conversion Method and Apparatus","This application provides a generative model training method, and a data conversion method and apparatus. The method includes: using data in a noise set as an input of the generative model, and outputting at least one generated sample, where the generative model is used to perform data conversion on the input data; using the at least one generated sample as an input of a first diffusion model, and outputting at least one first diffusion score, that is, scoring output effect of the generative model based on the first diffusion model; and updating the generative model based on the at least one first diffusion score and at least one second diffusion score output by a second diffusion model, to obtain an updated generative model, where the second diffusion model is obtained through training based on a real sample set.","['G06N3/08', 'G06N3/042', 'G06N3/0475', 'G06N3/096', 'G06T5/00']"
US20230377690A1,Protein sequence and structure generation with denoising diffusion probabilistic models,"Training a protein diffusion model includes receiving a representation of a protein as training data, the representation comprising at least three dimensions. It further includes training a protein diffusion model at least in part by performing rotational diffusion based at least in part on the representation of the protein.Generating proteins includes receiving protein conditioning information. It further includes, based at least in part on the protein conditioning information, performing conditional sampling of a protein diffusion model. The protein diffusion model is trained at least in part by performing rotational diffusion. Based at least in part on the conditional sampling of the protein diffusion model, the protein diffusion model generates one or more of a protein structure or a protein sequence.","['G16B15/20', 'G16B40/00', 'G16B15/00']"
WO2024118915A1,Thermodynamic artificial intelligence for generative diffusion models and bayesian deep learning,"A physics-based system performs generative modeling on a given dataset by turning the diffusion process in diffusion models into a physical process. Electrical circuits provide an exemplary implementation, where each unit cell (an electrical circuit in a network of electrical circuits) is composed of resistors, a stochastic noise source (such as a thermal or shot noise source), programmable voltage sources, and a capacitor whose charge encodes the state variable. These unit cells can be capacitively coupled with a connectivity that matches the problem geometry. A score network, which provides predictions for score values, can be implemented on a digital, analog, or hybrid digital-arialog device. A detailed construction for an analog score network is provided in the form of a physical system that evolves over time, simultaneously with the diffusion process. The analog score network allows score values to be provided continuously to the reverse diffusion process without latency, and also allows for efficient evaluation of the loss function when coupled to the forward diffusion process.","['G06N3/0475', 'G06N3/042', 'G06N3/0455', 'G06N3/047', 'G06N3/044', 'G06N3/048', 'G06N3/065']"
CN117411674A,Industrial Internet abnormal flow detection method and detection system based on generation and diffusion,"The invention discloses an industrial Internet abnormal flow detection method and a detection system based on generation and diffusion, which adopt a sliding data packet window and a sliding data packet time window to extract space features and time features from a public flow data set, and select an optimal feature set from all the space features and time features by utilizing an information gain IG and an information gain ratio IGR; constructing a pseudo-anomaly generator based on a table denoising diffusion probability model TabDDPM and establishing an anomaly flow detection model consisting of the pseudo-anomaly generator and a discriminator; selecting a proper baseline function for the trained network abnormal flow detection model to determine whether the accumulated flow on a window is identified as abnormal; and deploying a network abnormal traffic detection model on the mobile equipment and detecting in real time. According to the invention, the most relevant small part of features are selected for training and classifying, so that low-delay and high-precision detection is realized, and the defect of insufficient unknown abnormal simulation is overcome by adopting a more advanced generation model.","['H04L63/1425', 'H04L47/27']"
CN117519206B,"Autonomous driving model, method, device and vehicle based on generative diffusion model","The disclosure provides an automatic driving model, an automatic driving method, an automatic driving device and a vehicle based on a generated diffusion model, and relates to the technical field of computers, in particular to the technical field of automatic driving and artificial intelligence. The encoding layer in the autonomous model is configured to encode current perception information of the autonomous vehicle to obtain a discrete spatial representation of the current scene, the prediction layer is configured to discrete diffuse according to at least one discrete spatial representation of the scene including the discrete spatial representation of the current scene to determine a predicted spatial representation at a future time, and the decoding layer is configured to decode the predicted spatial representation to obtain autonomous decision information at the future time. Thus, the autopilot model may utilize the output based on the generative diffusion model to determine autopilot decisions for the autopilot model. The accuracy of future prediction is improved, so that the effects of automatic driving decision and prediction are further improved.","['G05D1/242', 'G05D1/243', 'G05D1/246', 'G05D1/247', 'G05D1/248', 'G05D1/43', 'G05D1/633', 'G05D1/644', 'G05D2109/10']"
EP4432289A1,"Generative sequence screening with conditional gans, diffusion models, and denoising diffusion conditional gans",Systems and methods for generating a polymer sequence for a biological molecule having one or more target biological properties are provided. A plurality of target metric values for one or more target biological properties of a biological molecule and a seed for a nucleic acid or amino acid sequence for the biological molecule are inputted into a conditional generator model of a conditional generative adversarial network to obtain as output from the conditional generator model a nucleic acid or amino acid sequence for the biological molecule that is predicted by the conditional generator model to confer on the biological molecule the one or more target biological properties approximating the plurality of target metric values.,"['G16B20/00', 'G06F30/27', 'G16B30/00', 'G16B40/20']"
WO2024215570A1,Generative machine learning models for omics data and phenotype data,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for identifying target genes that are predicted to be associated with a disease. In one aspect, a system comprises receiving data identifying: (i) a set of one or more disease phenotypes associated with the disease and (ii) a set of one or more healthy phenotypes that are not associated with the disease, determining a plurality of paths in a phenotype space, that each start from a respective disease phenotype and terminate at a respective healthy phenotype, processing data defining each path in the phenotype space using a phenotype-to-omics machine learning model to generate data defining a corresponding path in an omics space, and processing the data defining the paths in the omics space to identify a set of one or more target genes that are each predicted to be associated with the disease.","['G16B40/20', 'G16B20/00']"
CN116934965A,Cerebral blood vessel three-dimensional image generation method and system based on controllable generation and diffusion model,"The invention belongs to the technical field of network data processing and digital information transmission, and particularly relates to a brain blood vessel three-dimensional image generation method and system based on a controllable generation diffusion model.","['G06T17/00', 'G06N3/0455', 'G06N3/08', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06V20/70']"
CN115935817A,Rapid model generation method based on diffusion model,"A rapid model generation method based on a diffusion model comprises the following steps: s1, determining a target model; s2, training a diffusion model, generating and executing input query of the target model through the diffusion model, inputting data generated by the diffusion model into the target model, and performing iterative query on the target model; s3, estimating the gradient of the continuously updated diffusion model by using the zero-order gradient, and optimizing the parameters of the diffusion model to enable the generated data to fit a target decision boundary; and S4, constructing an input and output prediction pair by generating data, fitting a decision boundary of the target model, predicting the type of the sample according to the position of the sample in the feature space through the decision boundary, acquiring data distribution of a data set, constructing a virtual data set, and training a rapid generation model. The method and the device do not need to access the target model data set, the structure of the target model and the like, and simultaneously ensure the speed and the accuracy of model generation.",['Y02T10/40']
WO2024159082A2,Monocular depth and optical flow estimation using diffusion models,"Improved methods are provided for generating, via a noise-diffusion iterative process, depth maps or optical flow maps from input images. Also provided are improved methods for training the machine learning model(s) employed in the iterative process and for augmenting die set of training data used to train such models. By translating the depth or optical flow map prediction process into the noise diffusion context, improved performance with respect to compute cost, training data, requirements, model size, and output quality are obtained. Additionally, the noise diffusion context allows models trained as described herein to generate maps de novo from target color images and/or to begin from initial 'guess' maps (e.g., noisy maps, maps containing holes) when generating improved output maps, natively incorporating the imperfect prior information represented by such initial maps.","['G06T7/50', 'G06N20/20', 'G06N3/09', 'G06N5/01', 'G06N5/022', 'G06T2207/10024', 'G06T2207/20028', 'G06T2207/20081', 'G06T2207/20084']"
US20250061548A1,Hybrid sampling for diffusion models,"Systems and methods for generating images using hybrid sampling include obtaining a noisy image and generating a first denoised image during a first reverse diffusion phase using a diffusion neural network. The first denoised image is generated based on a first sampler that uses a first sampling density during at least a portion of the first reverse diffusion phase. Subsequently, a second denoised image is generated based on the first denoised image during a second reverse diffusion phase using the diffusion neural network. The second denoised image is generated based on a second sampler that uses a second sampling density different from the first sampling density during at least a portion of the second reverse diffusion phase.","['G06T5/70', 'G06T5/50', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
US20250253009A1,Machine learning enabled prediction of molecular structures and properties,"A method may include receiving a molecular structure file specifying an initial three-dimensional structure of a molecule. A representation of the molecule may be determined based on the molecular structure file. For example, the representation of the molecule may include a plurality of coarse-grained nodes, each corresponding to a structural body of two or more atoms (e.g., heavy atoms) forming an amino acid residue in the molecule. Alternatively, the representation of the molecule may include, for each residue in the molecule, a plurality of frames specifying a geometric state of the backbone of the residue and one or more torsion angles in the sidechain of the residue. A design computation model may be applied to determine a three-dimensional structure of the molecule by at least modifying the representation of the molecule. The three-dimensional structure may be associated with a desirable property and/or be configured for a downstream task.","['G16B15/20', 'G06N20/00', 'G16B40/20', 'G16B45/00']"
US12346995B2,Machine learning diffusion model with image encoder trained for synthetic image generation,"The present disclosure provides systems and methods for generating a synthesized image of a user with a trained machine learning diffusion model. In one example, a computing system includes one or more processors configured to execute instructions stored in memory to execute a trained machine learning diffusion model including an image encoder, a text encoder, and a diffusion model. The image encoder is configured to receive an image of a user and generate a set of embeddings that semantically describe visual features of the user based at least on the image of the user. The text encoder is configured to receive the set of embeddings and generate an input feature vector based at least on the set of embeddings. The diffusion model is configured to receive the input feature vector and generate a synthesized image of the user based at least on the input feature vector.","['G06N20/00', 'G06F3/14', 'G06F40/126', 'G06Q50/01', 'G06T11/00', 'G06T11/60', 'G06T3/60', 'G06T9/001', 'G06V10/70', 'G06V40/161', 'G06V40/171']"
CN116132227A,RIS-assisted massive MIMO channel estimation based on generative diffusion model,"The invention discloses a RIS auxiliary large-scale MIMO channel estimation method based on a generated diffusion model. Aiming at the RIS auxiliary large-scale MIMO system, the invention provides a cascade channel estimation method based on a generated diffusion model. First a conditional generating diffusion model is built which runs a forward process and a backward process in the spectral space of the RIS phase shift degradation matrix and is guided by the conditional information only in the backward process. The concatenated channel estimation is implemented by a sampling process that conditionally generates a diffusion model. During the sampling process, the received signal as condition information gradually directs the recovery of the concatenated channel in the spectral space of the RIS phase shift degradation matrix. The invention can greatly improve the estimation precision of the cascade channel of the RIS auxiliary large-scale MIMO communication system.","['H04L25/0204', 'H04B7/0413', 'H04L25/0242', 'H04L25/0254', 'Y02D30/70']"
CN119130783B,Virtual handoff method based on diffusion model,"The invention discloses a virtual hair-changing method based on a diffusion model, which relates to the technical field of virtual hair-changing, and adopts a two-stage generation method, wherein a coarser hair-style picture is generated in the first stage, the generated hair-style picture is refined through a redrawing mechanism in the second stage, so that the generated hair-style picture has higher detail fidelity, and the hairstyle is better presented on complex textures and details by adopting a hairstyle redrawing diffusion model in the second stage, so that the problem that the hair-style picture generated in the traditional method is easy to blur or lose details is avoided, the problem that the traditional GAN-based method is difficult to process the hair style of the complex textures is easy to generate artifacts or ignore details is solved, the scheme based on the diffusion model is combined with a cross attention mechanism, the details of the hair-style are better captured, and the transmission of the details of the hair-style is ensured by injecting the hair-style reference information in the generation process, so that the more complex hair-style can be processed, and the higher stability is maintained.","['G06T3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06T7/10', 'G06T2207/20081', 'G06T2207/20084']"
EP4599309A1,Systems and methods for simulating at least one solution of a stochastic differential equation and methods for using thereof for generative machine learning,"An opto-electronic system and method for simulating at least one solution of a stochastic differential equation (SDE) driven by a Levy process wherein the stochasticity of the Levy process is represented by photon statistics of at least one optical mode. The system comprises at least one input port for receiving the at least one optical mode, a computation and recurrence component, and an output port for readout.","['G06N3/0675', 'G06N3/045', 'G06N3/0475', 'G06N3/084', 'G06E3/008', 'G06N3/0455']"
US20250068901A1,Systems and methods for controllable data generation from text,"Embodiments described herein provide a diffusion-based framework that is trained on a dataset with limited text labels, to generate a distribution of data samples in the dataset given a specific text description label. Specifically, firstly, unlabeled data is used to train the diffusion model to generate a data distribution of data samples given a specific text description label. Then text-labeled data samples are used to finetune the diffusion model to generate data distribution given a specific text description label, thus enhancing controllability of training.","['G06N3/08', 'G06N3/045']"
CN118229600A,Virtual staining method and device for ulcerative colitis-related tumors under enteroscope,"The invention relates to the technical field of medical image processing, in particular to a virtual staining method for ulcerative colitis related tumors under enteroscopy, which comprises the following steps: obtaining a enteroscope white light image and a corresponding indigo carmine dyeing image; carrying out random noise adding treatment on the indigo carmine dyeing image, and then splicing the denoised image and the corresponding enteroscopy white light image to serve as input data to be input into a U-Net model with a time step; based on a back propagation process of generating a diffusion model, splicing a random noise image and a enteroscopy white light image to be virtually dyed, and inputting the spliced random noise image and the enteroscopy white light image to be virtually dyed into a trained U-Net model for pre-estimation; and splitting the final estimated result by an operation opposite to the splicing method to obtain an indigo carmine dyeing estimated result. The virtual staining method for the ulcerative colitis-related tumor under the enteroscope provided by the invention can obtain a better display effect, and reduce the professional and experience requirements of endoscopists when screening and diagnosing UCAN.","['G06T5/94', 'G06N3/0464', 'G06N3/084', 'G06T3/4038', 'G06T5/70', 'G06T2200/32', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30028', 'G06T2207/30096']"
WO2025042463A1,Generating realistic machine learning-based product images for online catalogs,"An online concierge system trains a fine-tuned generative image model for distinct categories of items based on a generative image model that takes a textual query as input and outputs and an associated image. Training of the fine-tuned generative image model is additionally based on a small set of representative images associated with the various categories, as well as textual tokens associated with the categories. Once trained, the fineÂ¬ tuned generative image model can be used to generate realistic representative images for items in a database of the online concierge system that are lacking associated images. The fine-tuned model permits the generation of different variants of an item, such as different quantities or amounts, different packaging or packing density, and the like.","['G06F16/583', 'G06F16/55', 'G06F16/58', 'G06Q30/0643', 'G06T11/203', 'G06T11/60']"
US20250022256A1,Data augmentation using conditioned generative models for synthetic content generation,"Synthetic data generation systems and methods are disclosed for augmenting synthetic scenes using neural networks that are conditioned on depth information. The synthetic data generation system may use a guided latent diffusion model to generate (or augment) synthetic images, which can subsequently be used to train other models to perform tasks such as object detection. Input of the model may be an image rendered by a graphic engine with coarsely rendered objects. When the image is rendered, segmentation masks may also be generated for objects in the image. The synthetic data generation system may generate a monocular depth image. During the image generation phase, the corresponding segmentation mask, depth map, and any guiding textual input serve as constraints for the denoising process. During the denoising step, the synthetic data generation system may also crop and adjust the resolution of individual objects during diffusion to enhance the results. The newly regenerated object is then blended back into the original image to produce a synthetic image.","['G06V10/25', 'G06T5/50', 'G06T7/194', 'G06V10/774', 'G06V10/82', 'G06T2207/20221', 'G06V2201/12']"
CN118760745A,A generative approach to complex logical reasoning in knowledge graphs,"The invention discloses a knowledge graph-oriented complex logic reasoning generating method. The invention comprises a query conversion module and a diffusion reasoning module, wherein the logic query conversion module converts a first-order logic query into an input sequence, the diffusion reasoning module displays a forward and backward bidirectional generation process, and a converter with a structure enhancing self-attention mechanism is designed. The query conversion module converts the signed first-order logic query into a natural language input sequence, and the diffusion reasoning module captures the composite distribution of the complex logic query through the multi-step generation process of the forward process and the backward process; meanwhile, a self-attention mechanism with enhanced structure is designed in a converter of the diffusion model so as to effectively fuse important structural features in the knowledge graph. The invention further ensures the controllability and the interpretability of the model through multi-granularity control of the diffusion intermediate process; compared with other baseline methods, better knowledge-graph reasoning results are achieved.","['G06F16/3329', 'G06F16/367', 'G06N3/04', 'G06N3/08', 'G06N5/022', 'G06N5/04']"
US20240420394A1,Design compositing using image harmonization,"Systems and methods are provided for image editing, and more particularly, for harmonizing background images with text. Embodiments of the present disclosure obtain an image including text and a region overlapping the text. In some aspects, the text includes a first color. Embodiments then select a second color that contrasts with the first color, and generate a modified image including the text and a modified region using a machine learning model that takes the image and the second color as input. The modified image is generated conditionally, so as to include the second color in a region corresponding to the text.","['G06T11/001', 'G06T11/60', 'G06T5/50', 'G06T5/60', 'G06T5/94', 'G06T7/11', 'G06T7/143', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
CN117669492A,A method and device for small sample calligraphy font generation based on diffusion model,"The invention discloses a method and a device for generating a small sample handwriting font based on a diffusion model, comprising the following steps: constructing a pairing data set comprising standard fonts and a plurality of calligraphic fonts; training the diffusion model by using one calligraphic font character picture and a standard font character picture in a training set to obtain a generalizable font generating diffusion model; performing fine tuning training on the generalizable font generation diffusion model by using the target calligraphic font character picture of the small sample to obtain a target calligraphic font generation diffusion model; generating a diffusion model by using the target handwriting font, and performing diffusion generation of all required character pictures of the target handwriting font by using the standard font character pictures; and vectorizing all the generated character and picture sets of the target handwriting fonts to obtain the expanded target handwriting fonts, and constructing a font TrueType file. The invention utilizes a small amount of sample target calligraphy font character pictures to finely adjust the model, thereby realizing high authenticity and high aesthetic degree of the generated calligraphy font strokes and fly-white.","['G06F40/109', 'Y02D10/00']"
WO2024187031A2,Systems and methods for dynamic-backbone protein-ligand structure prediction with multiscale generative diffusion models,"In some aspects, the present disclosure provides a method for generating a geometrical structure of a binding complex formed between a protein and a ligand. In some embodiments, the method comprises sampling an initial geometrical structure of the binding complex from a geometry prior. In some embodiments, the method comprises denoising, using a machine-learned stochastic differential equation (SDE), the initial geometrical structure to generate the geometrical structure of the binding complex.","['G16B40/20', 'G16B15/30']"
US20250252539A1,Material Classification with Conditional Diffusion Models,"Provided are systems and methods that perform material classification of imagery using generative denoising diffusion models. Traditional material classification systems, which are predominantly based on discriminative models, face issues with generalization and diversity, particularly when encountering new or complex material compositions. Furthermore, these systems often function like black boxes, making it difficult to understand their decision-making processes or identify spurious correlations. The provided systems and methods address these challenges by leveraging the capabilities of diffusion models, which can provide better generalization and more transparent decision-making processes.","['G06T5/60', 'G06T11/00', 'G06T5/70', 'G06T7/0002', 'G06V10/764', 'G06V10/774', 'G06T2207/20081', 'G06T2207/20084']"
US20250078245A1,Method and system for data generation,"A system for generating a dataset of damaged signs includes at least one computer configured to receive a first set of image data indicating damaged signs from a first set of classes and undamaged signs from a second set of classes, receive class information indicating a class type for each sign, and receive damage information indicating a damage type for each of the damaged signs. The at least one computer is also configured to process the first set of image data, the class information, and the damage information with a learning algorithm to produce output features, and generate output image data indicating an output sign from the second set of classes using a generative diffusion model that processes the output features, where the output image data indicates a damage type matching the damage type of at least one of the plurality of damaged signs.","['G06T7/0008', 'G06V10/764', 'G06T11/00', 'G06V10/44', 'G06V10/82', 'G06V20/582', 'G06V2201/07']"
WO2025131352A1,Predicting three-dimensional (3d) structures of molecule complexes using embedding neural networks and generative models,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for predicting a 3D structure of a molecule complex In one aspect, there is provided a method comprising: obtaining a network input that characterizes a molecule complex; processing the network input characterizing the molecule complex using an embedding neural network to generate molecule embedding data; and generating, using a generative model and while the generative model is conditioned on the molecule embedding data, a predicted three-dimensional (3D) structure of the molecule complex that defines a respective predicted 3D spatial location of each atom in the molecule complex.","['G16B15/10', 'G16B15/20', 'G16B15/30', 'G16B40/20', 'G16C20/70']"
CN120611597A,"Tropical cyclone ensemble forecast method, system, equipment and medium based on deep generative diffusion model","The invention belongs to the technical field of weather prediction, and discloses a method, a system, equipment and a medium for forecasting a tropical cyclone set based on a depth generation diffusion model, which aim to generate a diversified forecasting set by using the diffusion model by taking the output of a Fuxi weather large model as a condition, so that the accuracy, the reliability and the uncertainty quantification capability of forecasting are improved. The method comprises the steps of obtaining global ERA5 analysis data at the current moment and the previous moment as initial field data of deterministic forecast and inputting the initial field data into a Fuxi weather large model to enable the initial field data to generate a deterministic forecast result at the time of t+1, using the deterministic forecast result as conditional input of a conditional probability diffusion model, combining random noise data and auxiliary condition information in the same dimension as the deterministic forecast result, generating N set forecast members through the conditional probability diffusion model, and calculating probability distribution of tropical cyclone paths and intensities based on statistical analysis of the N set forecast members to generate a set forecast product.",[]
CN119562070B,"Image processing method, device, image encoding and decoding system, device and storage medium","The application discloses an image processing method, an image processing device, an image encoding and decoding system, an image encoding and decoding device and a storage medium. The image processing method comprises the steps of decoding a text code stream from an encoding end through a first decoder to obtain semantic information of an original image, decoding a feature code stream from the encoding end through a second decoder to obtain feature decoding information of the original image, processing the feature decoding information through a texture information acquisition module to obtain texture information of the original image, processing the semantic information and the texture information based on a hidden layer representation diffusion model to obtain fusion information, and processing the fusion information through an image generation module to obtain a decoded image. According to the image processing method provided by the embodiment of the application, the fusion information is obtained by processing the semantic information and the texture information based on the hidden layer representation diffusion model, the decoded image is obtained by processing the fusion information through the image generation module, a clearer image can be obtained, the condition of image blurring is greatly reduced, and the processing effect is good.","['H04N19/44', 'G06N3/0455', 'G06N3/08', 'G06T5/50', 'G06T5/60', 'G06T2207/20221']"
CN117880205B,"Load balancing optimization method, related server and system","The invention discloses a load balancing optimization method, a related server and a system. The optimization method for load balancing provided by the invention comprises the following steps: in an SDN network, iteratively performing the following steps in a loop until convergence: acquiring data of bandwidth utilization rate of each link in the network acquired by a data plane of the SDN, and generating network state information reflecting the load condition of each link at the current moment; training a generated diffusion model by taking the network state information as input in a control plane of the SDN, and outputting the priority weights of all links in the network through the GDM; and regenerating a flow table item according to the priority weight of each link and transmitting the flow table item to each switch in the network so that each switch forwards data according to the forwarding priority defined by the updated flow table item. The invention utilizes the generated diffusion model to realize the optimization of the load balance of each link in the network in a dynamic and real-time mode.","['H04L47/125', 'H04L45/122', 'H04L45/125', 'H04L45/302', 'H04L45/76', 'H04L49/1507']"
US12205197B1,Label image synthesis using generative AI,"Generative image synthesis conditioned on label prompts includes receiving a label prompt comprising a mapping of labels to portions of an image to be synthesized. At least some of the labels in the label prompt correspond to an object to be included in the image to be synthesized. It further includes, based on the label prompt, generating, using a generative model, a synthesized image corresponding to the label prompt.","['G06T11/001', 'G06F40/40', 'G06T11/00', 'G06T11/60', 'G06T7/10', 'G06V20/70', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
CN117809671A,General speech enhancement back-end refinement method based on diffusion model,"The invention relates to the technical field of voice signal processing, in particular to a general voice enhancement back-end refinement method based on a diffusion model. The first stage utilizes a pre-trained deep neural network model to carry out spectrum estimation on noisy speech so as to realize preliminary noise and reverberation suppression; the second stage utilizes a refiner based on a diffusion model to further repair and refine the speech enhanced in the first stage so as to recover lost or distorted speech components in the enhancement process of the deep neural network model in the first stage and reduce artifacts. The method of the invention skillfully combines the advantages of the discriminant network and the generating network, has novel conception and good application prospect, and is beneficial to playing an important role in improving the voice quality, enhancing the voice intelligibility, improving the voice recognition performance and the like.","['G10L21/0208', 'G10L21/0232', 'G10L25/18', 'G10L25/24', 'G10L2021/02082']"
WO2025160309A1,Systems and methods for dynamic-backbone protein-ligand structure prediction with multiscale generative diffusion models,"Systems and methods described herein include embodiments for generating a geometrical structure of a binding complex formed between a plurality of macromolecules, comprising: processing an input representation comprising a plurality of representations of the plurality of macromolecules to generate a geometry prior; sampling an initial geometrical structure of the binding complex based on the geometry prior; and processing, using a neural network, the initial geometrical structure to generate the geometrical structure of the binding complex formed by the plurality of macromolecules.","['G06N3/045', 'G06N3/08', 'G16B15/30', 'G16B20/30', 'G16B40/20', 'G16B45/00']"
US20250267240A1,Detecting the presence of a virtual meeting participant,"A method for detecting the presence of a virtual meeting participant includes obtaining a first frame of a video stream generated by a camera of a client device of a participant of a virtual meeting. The method includes generating a depth map of the first frame. The method includes, for each of one or more second frames of the video stream, generating a point cloud of an image of the participant located in a respective second frame, and determining whether the participant is in front of the camera based on an overlap between a selected zone of the depth map and the point cloud of the image of the participant located in the respective second frame. Responsive to the determining the participant is not in front of the camera, the method includes muting the participant's audio and deactivating the participant's video stream.","['H04N7/157', 'G06T7/50', 'H04N7/147']"
CN118828144A,"Long video generation method, system and device for multi-text video temporal positioning retrieval","The application provides a long video generation method, a system and equipment for multi-text video time sequence positioning retrieval, wherein the method comprises the following steps: according to the text retrieval sequence, retrieving target video fragments conforming to each text description from a video library to obtain a plurality of target video fragments corresponding to the text retrieval sequence, wherein the text retrieval sequence comprises a plurality of sections of text descriptions; adjusting the text retrieval sequence into a new text description sequence with the same main body and the same theme, and editing the plurality of target video clips according to the new text description sequence to obtain a plurality of processed video clips with the same main body and the same theme; and according to the noise characteristics of the two adjacent processing video segments, smoothly transiting and connecting the processing video segments according to the video sequence order, so as to obtain a long-time-sequence video, wherein the video sequence order is determined according to the new text description sequence. Thus, less memory is used, and long-time-sequence video which is more in accordance with the physical rule is generated.","['G06F16/7343', 'G06F16/783', 'G06F16/7837', 'G06T5/70', 'H04N21/23424', 'H04N21/44016', 'H04N21/47205', 'H04N21/8456', 'H04N21/8549', 'Y02D10/00']"
WO2025054881A1,Optimization-based image editing,"Described is an image processing apparatus (800), the apparatus comprising one or more processors (804) configured to: receive (701) image editing instructions (207, 208) indicating a desired modification to an input image (201); and input (702) the input image to an encoding-decoding process to form an edited image (213), wherein the encoding-decoding process comprises inputting (i) an intermediate image (205) derived from the input image and (ii) the image editing instructions (207, 208) to a pre-trained generative diffusion model to form the edited image (213) in dependence on respective outputs of a first loss function and a second loss function, the first loss function configured to preserve detail in one or more parts of the input image and the second loss function configured to guide the input image to be modified according to the image editing instructions. This can give pre-trained generative models highly controllable editing capability and allow to faithfully preserve image regions that are not to be edited (such as in background regions), and to achieve controllability using multiple instructions such as text, scribble and pose.",['G06T11/60']
US20250173825A1,Method and electronic device for performing image processing,"A method includes performing, using a first artificial intelligence (AI) network, image processing based on input information to obtain a first image and image guidance information, the image guidance information comprising at least one of spatial correlation guidance information and semantic correlation guidance information; and performing, using a second AI network, resolution processing on the first image based on the image guidance information to obtain a second image.","['G06T3/4053', 'G06T3/4046', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
WO2024187466A1,Equilibrium distribution prediction for molecular systems,"A computing system for predicting an equilibrium distribution for a molecular system includes a processor that executes instructions using portions of associated memory to implement an equilibrium distribution prediction model. In an inference phase, the processor is configured to receive input data representing a molecular system, create a graph representation of the molecular system, including position information for each atom in the molecular system, and input the graph representation of the molecular system to a graph neural network. The processor is further configured to receive a plurality of predicted conformations of the molecular system as output from the graph neural network, input each predicted conformation of the plurality of predicted conformations to a diffusion model, predict an equilibrium distribution of conformations for the molecular system, and output the equilibrium distribution.","['G16C20/30', 'G06N3/042', 'G06N7/01', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G16C20/70']"
EP4607453A2,Measurement charge removal and per-layer stack geometry inference using diffusion models,"A method of updating images taken by charged-particle beam (CPB) tool of a feature of a wafer. The method includes generating a distortion map by a machine learning model trained on: a first CPB image of the feature, wherein the first image has a first resolution; a second CPB image of the feature, wherein the second image has a second resolution different from the first resolution and the second CPB image includes distortions; and a mask based on the first CPB image. The distortion map indicates how the second CPB image is distorted relative to the feature. A third image of the feature is generated by applying the distortion map to the second CPB image, wherein the third image has a third resolution higher than the first resolution and is used for performing metrology or defect detection.","['G06T5/73', 'G06T5/50', 'G06T5/60', 'G06T5/80', 'G06T7/0004', 'G06T7/60', 'G06T2207/10016', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
WO2025110368A1,"Method and electronic device, performing image processing","A method includes performing, using a first artificial intelligence (AI) network, image processing based on input information to obtain a first image and image guidance information, the image guidance information comprising at least one of spatial correlation guidance information and semantic correlation guidance information; and performing, using a second AI network, resolution processing on the first image based on the image guidance information to obtain a second image.","['G06T3/4046', 'G06T3/4076']"
WO2025093548A1,Predicting joint three-dimensional (3d) structures of proteins and ligands by cofolding,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a predicted joint 3D structure of a protein and one or more ligands. In one aspect, a method comprises: obtaining a network input that characterizes the protein and the one or more ligands; processing the network input using an embedding neural network to generate a protein - ligand embedding of the protein and the one or more ligands; and generating, using a generative model and while the generative model is conditioned on the protein - ligand embedding, the predicted joint three-dimensional (3D) structure of the protein and the one or more ligands.","['G16B15/30', 'G16B15/20', 'G16B40/20']"
US20250124544A1,Upsampling low-resolution content within a high-resolution image using a generative model,Systems and methods for upsampling low-resolution content within a high-resolution image include obtaining a composite image and a mask. The composite image includes a high-resolution region and a low-resolution region. An upsampling network identifies the low-resolution region of the composite image based on the mask and generates an upsampled composite image based on the composite image and the mask. The upsampled composite image comprises higher frequency details in the low-resolution region than the composite image.,"['G06T3/4053', 'G06T11/00', 'G06T3/4046', 'G06T5/50', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20221']"
CN117911580A,Design synthesis using image coordination,"Embodiments of the present disclosure relate to design synthesis using image coordination. Systems and methods for image editing, and in particular for reconciling background images with text, are provided. Embodiments of the present disclosure obtain an image including text and an area overlapping the text. In some aspects, the text includes a first color. Then, the embodiment selects a second color that contrasts with the first color, and generates a modified image including text and a modified region using a machine learning model having the image and the second color as inputs. The modified image is conditionally generated to include a second color in the region corresponding to the text.","['G06T11/60', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06T11/001', 'G06V10/26']"
US20250226064A1,Methods and Systems for Machine-Learning Based Molecule Generation and Scoring,A method for machine learning aided modeling of two interacting structures may include: (a) receiving an input structure comprising an interaction region; (b) generating a plurality of candidate structures using a first differentiable machine learning model; (c) docking one or more candidate structures of the plurality of candidate structures at the interaction region of the input structure using a second differentiable machine learning model to predict a docking geometry; (d) ranking the one or more candidate structures of the plurality of candidate structures docked in (c) using a third differentiable machine learning model to predict a score; and (e) backpropagating the score to (i) the first differentiable machine learning model to update the plurality of candidate structures or (ii) the second differentiable machine learning model to update the docking geometry.,"['G16C20/50', 'G16C20/40', 'G16C20/70']"
WO2025189851A1,Data processing method and apparatus thereof,"A data processing method, applied to the field of artificial intelligence, and comprising: acquiring a first input and a second input; on the basis of the first input and the second input and by means of an encoder, respectively obtaining a first feature representation and a second feature representation outputted by a target network layer of the encoder; fusing the first feature representation and a third feature representation to obtain a fused feature; on the basis of the fused feature and the second feature representation and by means of a generation model, respectively obtaining first data and second data, and updating the fused feature on the basis of a difference between the first data and the second data to obtain an updated fused feature; and updating the encoder to minimize at least one difference comprising a first difference. The present application does not need to re-construct a training sample for model training. In addition, parameters of the generation model do not need to be updated, and only the encoder is updated, so that the training cost of the model is reduced.",[]
CN120374859A,Complete three-dimensional reconstruction method for damaged blade of aeroengine based on image generation type diffusion model,"The invention relates to the technical field of three-dimensional reconstruction of aero-engine blades, and particularly discloses a complete three-dimensional reconstruction method of damaged aero-engine blades based on an image generation type diffusion model, which comprises the steps of data acquisition and data set construction, wherein an RGB camera is adopted to acquire damaged video frame images of the aero-engine blades; the invention provides a brand-new three-dimensional model reconstruction framework of an aeroengine damaged blade based on an example segmentation, an image generation type diffusion model and an explicit modeling algorithm, solves the problems of low modeling efficiency, poor modeling detail and low accuracy of the damaged blade, provides a new thought for three-dimensional modeling in the blade repairing and remanufacturing process, designs an image generation type diffusion model for repairing the damaged blade image of the aeroengine, adopts a StableDiffusion-1.5 model as a framework to improve the image repairing efficiency, introduces the reference feature extraction capability of a dual U-Net structure enhancement model, and adopts a self-supervision training strategy to fully utilize data to improve the performance of the model.",[]
CN120475196A,Video frame inserting method of generating video diffusion model based on event guidance,"The invention relates to a video frame inserting method of a generating type video diffusion model based on event guidance, which comprises the following steps of constructing an event guidance generating type video diffusion network, wherein the event guidance generating type video diffusion network comprises a condition generator MMCG, a pre-trained VAE encoder/decoder, a space-time attention condition U-shaped network Unet and a guiding type embedded feature aggregation module GEA, the condition generator MMCG comprises a region of interest ROI selector, a voxel feature extractor VFE, a multi-mode feature fusion module MMF and a three-dimensional residual error learning module 3DVR, and a two-stage training strategy is adopted to input video data and event stream data into the guiding generating type video diffusion model to obtain an interpolation frame. Compared with the prior art, the invention has the advantages of overcoming the poor performance of the prior video frame inserting technology when processing large-amplitude motion, complex illumination change and low texture areas, and the like.",[]
US20250045892A1,Variational inferencing by a diffusion model,"Diffusion models are machine learning algorithms that are uniquely trained to generate high-quality data from an input lower-quality data. For example, they can be trained in the image domain, for example, to perform specific image restoration tasks, such as inpainting (e.g. completing an incomplete image), deblurring (e.g. removing blurring from an image), and super-resolution (e.g. increasing a resolution of an image), or they can be trained to perform image rendering tasks, including 2D-to-3D image generation tasks. However, current approaches to training diffusion models only allow the models to be optimized for a specific task such that they will not achieve high-quality results when used for other tasks. The present disclosure provides a diffusion model that uses variational inferencing to approximate a distribution of data, which allows the diffusion model to universally solve different tasks without having to be re-trained specifically for each task.","['G06T5/60', 'G06T7/0002', 'G06N3/047', 'G06T3/40', 'G06T5/70', 'G06T5/73', 'G06T5/77', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
WO2025181772A1,Determination of re-aged facial-image based on generative diffusion model,"Provided is an electronic device for determination of a re-aged facial image based on a generative diffusion model. The electronic device receives a source image including a facial region of a user. Further, the electronic device receives a textual prompt indicative of a set of facial attributes of a target image of the facial region of the user. The electronic device applies a generative diffusion model on the received source image, based on the received textual prompt. The electronic device predicts a set of re-aging delta images based on the application of the generative diffusion model. The electronic device determines the target image of the facial region of the user, based on the predicted set of re-aging delta images and the received source image. The determined target image corresponds to the set of facial attributes of the target image.",['G06T11/00']
CN118827286A,Channel estimation method for smart reflector-assisted wireless communication system based on generative diffusion model,"The invention belongs to the technical field of computer application, and provides a channel estimation method in an intelligent reflector-assisted wireless communication system by using a multilink pilot frequency attention condition diffusion model. First, in the channel estimation stage, two intelligent reflection surface reflection modes are adopted, and the number of the reflection modes is not changed along with the number of the reflection units. Second, pilot signals received at the access point are introduced into the diffusion model to guide the generation process and to achieve channel estimation. Finally, a multi-task learning framework is adopted to jointly solve the channel estimation tasks of the three links. The invention can effectively capture the data distribution of each channel, thereby reducing the performance loss under the high noise condition, improving the accuracy of channel estimation and reducing the dependence on the design of a complex pilot transmission scheme.","['H04L25/0224', 'H04L25/024', 'H04L25/0254', 'Y02D30/70']"
US20240394636A1,Generative diffusion machine learning for reservoir simulation model history matching,A method for generating history matched grid data. The method includes obtaining observed production data and obtaining latent grid data. The method further includes processing the observed production data to form observed latent production data and generating denoised latent grid data by removing noise from the latent grid data using a diffusion model guided by the observed latent production data and a time encoding. The method further includes generating history matched grid data by decoding the denoised latent grid data and optimizing production of a well using the history matched grid data.,"['E21B41/00', 'G06Q10/06375', 'E21B2200/20']"
WO2025049096A1,Designing de novo antibody structures by repurposing esmfold as a probabilistic denoising diffusion model,"An antigen-aware antibody folding computing system includes a processor and a memory having stored thereon a trained machine-learned model and instructions that, when executed, cause the system to receive input biomolecule digital representations and process the input using the model to generate predicted output biomolecule digital representations. A method includes receiving input biomolecule digital representations and processing the input using a trained machine-learned model to generate predicted output biomolecule digital representations. A non-transitory computer-readable storage medium includes a trained machine-learned model and instructions that, when executed, cause a computer to: receive input biomolecule digital representations and process the input using the machine-learned model to generate predicted output biomolecule digital representations.","['G16B15/20', 'G16B40/20', 'G16B15/30']"
WO2024158466A2,Generative protein design via noise diffusion,"Generative, noise-diffusive models and related embodiments are provided to generate novel protein structures. These embodiments include training a machine learning model to predict, from noisy three-dimensional structural information, output three-dimensional structural information that represents a valid protein. Such models can be employed iteratively, in a noise diffusion context, to generate structural information for novel proteins based on randomly -generated inputs and/or based on noisy inputs that have been conditioned to represent desired aspects of the output predicted protein, like complex symmetric oligomeric structures, target motifs, and/or structures of targets to which the protein should bind. These models can optionally receive two-dimensional structural information, allowing the noise diffusion generative process to proceed in a self-conditioned manner. Also provided are methods of training such models, e.g., by fine-tuning existing models trained to perform sequence-to-structure prediction.","['G16B15/20', 'G16B40/20']"
US20250182358A1,Amodal segmentation by synthesizing whole objects,Systems and methods are provided for generating amodal images from occlusions objects in input images. Examples herein include receiving a prompt selecting an object in an input image; applying the input image to a trained conditional generative model that generates an amodal image of the selected object based on the prompt and the input image; and outputting the amodal image.,"['G06T11/60', 'G06T5/50', 'G06T5/70', 'G06T7/11', 'G06T7/12', 'G06V10/26', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06V2201/07']"
TW202529121A,Designing de novo antibody structures by repurposing esmfold as a probabilistic denoising diffusion model,"An antigen-aware antibody folding computing system includes a processor and a memory having stored thereon a trained machine-learned model and instructions that, when executed, cause the system to receive input biomolecule digital representations and process the input using the model to generate predicted output biomolecule digital representations. A method includes receiving input biomolecule digital representations and processing the input using a trained machine-learned model to generate predicted output biomolecule digital representations. A non-transitory computer-readable storage medium includes a trained machine-learned model and instructions that, when executed, cause a computer to: receive input biomolecule digital representations and process the input using the machine-learned model to generate predicted output biomolecule digital representations.",[]
CN119626313A,A method for generating bound proteins based on an electron density latent space diffusion model,"The present disclosure proposes a method of binding protein generation based on electron density hidden space diffusion model. The methods of the present disclosure utilize a conditional diffusion model in hidden space to generate an electron density representation of the binding protein for structural related information of a given target. In the solution proposed by the present disclosure, the related concept of the reciprocal space is introduced to perform encoding and decoding of the hidden space, and meanwhile, a manner of using the guided mask is proposed to control the model to generate higher-quality electron density in a targeted manner. The unlabeled training performed by using the public data set (PDB) can obtain a hidden space diffusion model capable of accurately generating protein electron density with binding characteristics in a specific area, thereby laying a foundation for the realization of subsequent biological functions and the design and development of related medicines.","['G16B15/30', 'G16B40/30']"
US20250086896A1,Synthetic image generation for supplementing neural field representations and related applications,"In various examples, systems and methods are disclosed relating to neural networks for three-dimensional (3D) scene representations and modifying the 3D scene representations. In some implementations, a diffusion model can be configured to modify selected portions of 3D scenes represented using neural radiance fields, without painting back in content of the selected portions that was originally present. A first view of the neural radiance fields can be inpainted to remove a target feature from the first view, and used as guidance for updating the neural radiance field so that the target feature can be realistically removed from various second views of the neural radiance fields while context is retained outside of the selected portions.","['G06T19/00', 'G06V10/44', 'G06T19/20', 'G06T7/194', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06T2219/2021']"
CN120673385A,Camouflage object detection refinement method based on uncertainty mask Bernoulli diffusion model,"The invention discloses a method for detecting and refining a camouflage object based on an uncertainty mask Bernoulli diffusion model, which comprises the steps of firstly generating an initial segmentation mask by using a pre-training model, analyzing an image and the initial mask through a mixed uncertainty quantization network (HUQNet) to generate a space uncertainty mask for identifying a residual region, taking the initial mask as a Bernoulli distribution mean value, modulating noise injection through the uncertainty mask, carrying out iterative denoising through the Bernoulli diffusion model, carrying out targeted correction on the residual region, and finally fusing a refining result and the initial mask determination region and outputting a final segmentation mask. The invention solves the problems of large-scale fuzzy edge, detail loss and false positive/negative correction existing in the detection of the camouflage object in the prior art. The provided disguised object detection refiner has wide application potential in various fields by improving the capability of accurately segmenting objects highly fused with the environment.",[]
US12322068B1,Generating voxel representations using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate digital content. In at least one embodiment, one or more neural networks are used to generate a three-dimensional voxel representation of a scene based, at least in part, upon a plurality of two-dimensional images of the scene.","['G06T5/60', 'G06T2207/20084', 'G06T2210/61']"
CN116167219A,Method and system for reconstruction of dental crown restoration based on diffusion model,"The invention provides a method and a system for reconstructing a dental crown restoration based on a diffusion model, wherein a mesh model of a prepared tooth and an occlusion tooth is projected according to a fixed projection rule to generate a depth map, so as to obtain the prepared tooth depth map and the occlusion tooth depth map; the random noise image, the prepared tooth depth image and the occlusion tooth depth image are input into a trained diffusion model, the noise image is continuously denoised through the diffusion model to obtain a target tooth depth image, then the target tooth depth image is back projected according to a projection rule for generating the depth image to obtain a three-dimensional point cloud of target teeth, and finally a target tooth grid, namely a reconstructed dental crown restoration, is obtained through point cloud reconstruction; the dental crown restoration reconstruction method based on the diffusion model forms finer modeling of the dental crown, and greatly improves the quality of the dental crown restoration. Meanwhile, the invention omits the cost of training labor and greatly improves the efficiency.","['A61C5/77', 'G06F30/20', 'G06N3/08', 'G06T17/00', 'G06T5/70', 'G06V10/774', 'G06F2119/10', 'G06T2207/10028', 'G06T2207/30036', 'Y02T90/00']"
US20250117971A1,Video diffusion using superposition network architecture search,"A method, apparatus, non-transitory computer readable medium, apparatus, and system for video generation include first obtaining a training set including a training video. Then, embodiments initialize a video generation model, sample a subnet architecture from an architecture search space, and a identify a subset of the weights of the video generation model based on the sampled subnet architecture. Subsequently, embodiments train, based on the training video, a subnet of the video generation model to generate synthetic video data. The subnet includes a subset of the weights of the video generation model.","['H04N21/816', 'G06T11/00', 'G06T3/4046', 'G06T3/4053', 'G06V10/774', 'G06V10/776', 'G06V10/82']"
CN116071256A,A method for unified image inpainting and enhancement that generates diffusion priors,"The invention relates to a method for generating uniform image restoration and enhancement of diffusion priori, belonging to the field of digital image processing. According to the method, a diffusion model controlled generation mode with a damaged picture as a guide image is adopted, and in the controlled generation process, variance does not participate in offset calculation of sampling mean value of each step, so that the method not only can solve the problem of picture restoration of linear degradation and nonlinear degradation, but also can carry out blind image restoration. Further, according to the task type, a plurality of guide images can be adopted to repair and generate a single image so as to improve the image repair and the enhancement quality; and by a block-based strategy and a hierarchical guided generation method, a degradation model is estimated under the condition of low resolution, and the degradation model is used for restoring an image after the resolution of the degradation model is restored by interpolation, so that the damaged image with any size can be restored and enhanced.","['G06T5/77', 'G06T5/70', 'G06T5/92']"
US12333688B2,Denoising diffusion generative adversarial networks,"Apparatuses, systems, and techniques are presented to train and utilize one or more neural networks. A denoising diffusion generative adversarial network (denoising diffusion GAN) reduces a number of denoising steps during a reverse process. The denoising diffusion GAN does not assume a Gaussian distribution for large steps of the denoising process and applies a multi-model model to permit denoising with fewer steps. Systems and methods further minimize a divergence between a diffused real data distribution and a diffused generator distribution over several timesteps. Accordingly, various embodiments may enable faster sample generation, in which the samples are generated from noise using the denoising diffusion GAN.","['G06T5/70', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
US12277758B2,Generating videos using sequences of generative neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium. In one aspect, a method includes receiving a text prompt describing a scene; processing the text prompt using a text encoder neural network to generate a contextual embedding of the text prompt; and processing the contextual embedding using a sequence of generative neural networks to generate a final video depicting the scene.","['G06V10/82', 'G06N3/045', 'G06T3/4053']"
US20240161327A1,Diffusion models having continuous scaling through patch-wise image generation,"Aspects of the methods, apparatus, non-transitory computer readable medium, and systems include obtaining a noise map and a global image code encoded from an original image and representing semantic content of the original image; generating a plurality of image patches based on the noise map and the global image code using a diffusion model; and combining the plurality of image patches to produce an output image including the semantic content.","['G06T7/70', 'G06T11/60', 'G06T3/40', 'G06T5/003', 'G06T5/73', 'G06T7/10', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20212']"
US20240185588A1,Fine-tuning and controlling diffusion models,Systems and methods for fine-tuning diffusion models are described. Embodiments of the present disclosure obtain an input text indicating an element to be included in an image; generate a synthetic image depicting the element based on the input text using a diffusion model trained by comparing synthetic images depicting the element to training images depicting elements similar to the element and updating selected parameters corresponding to an attention layer of the diffusion model based on the comparison.,"['G06V10/774', 'G06N3/0455', 'G06N3/0464', 'G06N3/088', 'G06T11/00', 'G06V10/751', 'G06V10/778', 'G06V10/82']"
US20240169479A1,Video generation with latent diffusion models,"The present disclosure provides systems and methods for video generation using latent diffusion machine learning models. Given a text input, video data relevant to the text input can be generated using a latent diffusion model. The process includes generating a predetermined number of key frames using text-to-image generation tasks performed within a latent space via a variational auto-encoder, enabling faster training and sampling times compared to pixel space-based diffusion models. The process further includes utilizing two-dimensional convolutions and associated adaptors to learn features for a given frame. Temporal information for the frames can be learned via a directed temporal attention module used to capture the relation among frames and to generate a temporally meaningful sequence of frames. Additional frames can be generated via a frame interpolation process for inserting one or more transition frames between two generated frames. The process can also include a super-resolution process for upsampling the frames.","['G06V20/46', 'G06T3/4007', 'G06T3/4053', 'G06V20/62', 'G06V30/19147']"
US12192547B2,High-resolution video generation using image diffusion models,"In various examples, systems and methods are disclosed relating to aligning images into frames of a first video using at least one first temporal attention layer of a neural network model. The first video has a first spatial resolution. A second video having a second spatial resolution is generated by up-sampling the first video using at least one second temporal attention layer of an up-sampler neural network model, wherein the second spatial resolution is higher than the first spatial resolution.","['G06N3/045', 'G06T3/4053', 'G06T9/00', 'G06V10/24', 'G06V10/25', 'G06V10/82', 'G06V20/46', 'H04N21/234363', 'H04N7/0117']"
US12299962B2,Diffusion-based generative modeling for synthetic data generation systems and applications,"Systems and methods described relate to the synthesis of content using generative models. In at least one embodiment, a score-based generative model can use a stochastic differential equation with critically-damped Langevin diffusion to learn to synthesize content. During a forward diffusion process, noise can be introduced into a set of auxiliary (e.g., âvelocityâ) values for an input image to learn a score function. This score function can be used with the stochastic differential equation during a reverse diffusion denoising process to remove noise from the image to generate a reconstructed version of the input image. A score matching objective for the critically-damped Langevin diffusion process can require only the conditional distribution learned from the velocity data. A stochastic differential equation based integrator can then allow for efficient sampling from these critically-damped Langevin diffusion models.","['G06T5/70', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/096', 'G06T5/60', 'G06T7/277', 'G06V10/772', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06V10/774']"
US20240355022A1,Personalized text-to-image generation,"One or more aspects of a method, apparatus, and non-transitory computer readable medium include obtaining an input description and an input image depicting a subject, encoding the input description using a text encoder of an image generation model to obtain a text embedding, and encoding the input image using a subject encoder of the image generation model to obtain a subject embedding. A guidance embedding is generated by combining the subject embedding and the text embedding, and then an output image is generated based on the guidance embedding using a diffusion model of the image generation model. The output image depicts aspects of the subject and the input description.","['G06T11/60', 'G06T9/00', 'G06T11/00', 'G06T7/194', 'G06T2207/20081']"
US11922550B1,Systems and methods for hierarchical text-conditional image generation,"Disclosed herein are methods, systems, and computer-readable media for generating an image corresponding to a text input. In an embodiment, operations may include accessing a text description and inputting the text description into a text encoder. The operations may include receiving, from the text encoder, a text embedding, and inputting at least one of the text description or the text embedding into a first sub-model configured to generate, based on at least one of the text description or the text embedding, a corresponding image embedding. The operations may include inputting at least one of the text description or the corresponding image embedding, generated by the first sub-model, into a second sub-model configured to generate, based on at least one of the text description or the corresponding image embedding, an output image. The operations may include making the output image, generated by the first second sub-model, accessible to a device.","['G06T11/60', 'G06F40/284', 'G06F40/30', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T11/001', 'G06T9/002']"
US20240289407A1,Search with stateful chat,"Implementations are described herein for augmenting a traditional search session with stateful chatâvia what will be referred to as a âgenerative companionââto facilitate more interactive searching. In various implementations, a query may be received, e.g., from a client device operated by a user. Contextual information associated with the user or the client device may be retrieved. Generative model (GM) output may be generated based on processing, using a generative model, data indicative of the query and the contextual information. Synthetic queries may be generated using the GM output, and search result documents (SRDs) may be selected. State data indicative of: the query, contextual information, one or more of the synthetic queries, and the set of search result documents, may be processed to identify a classification of the query. Based on the classification downstream GM(s) may be selected and used to generate one or more additional GM outputs.","['G06F16/335', 'G06F16/9577', 'G06F16/3338', 'G06F16/9532', 'G06F16/9535', 'G06F16/9537', 'G06F40/40']"
US11900068B1,Generative summaries for search results,"At least selectively utilizing a large language model (LLM) in generating a natural language (NL) based summary to be rendered in response to a query. In some implementations, in generating the NL based summary additional content is processed using the LLM. The additional content is in addition to query content of the query itself and, in generating the NL based summary, can be processed using the LLM and along with the query contentâor even independent of the query content. Processing the additional content can, for example, mitigate occurrences of the NL based summary including inaccuracies and/or can mitigate occurrences of the NL based summary being over-specified and/or under-specified.","['G06F40/56', 'G06F40/40', 'G06F16/3328', 'G06F16/3344', 'G06F16/345', 'G06N20/00', 'G06N3/0455', 'G06N3/0475']"
US11995803B1,Training and deployment of image generation models,"In some embodiments, a method receives a text prompt and executes a text encoder on the text prompt to generate an embedding representation. A set of base images is generated based on the embedding representation and parameters of a base image generation model. A high resolution model is executed to upsample one or more base images in the set of base images based on parameters of the high resolution model to generate a set of final images. The method ranks the set of base images or the set of final images using reward values that are generated by a reward model. The reward model is trained using human input that provided feedback on a quality of generated images using the base image generation model and the high resolution model. One or more final images are output based on the ranking in response to the text prompt.","['G06T5/70', 'G06T11/00', 'G06T2207/20081', 'G06T2207/20084']"
US20230334834A1,Model training based on synthetic data,"Embodiments of the present disclosure relate to model training based on synthetic data. According to example embodiments of the present disclosure, synthetic images are generated by providing respective text prompts into a text-to-image generation model. Respective training labels associated with the synthetic images are also generated based on the used text prompts. A target model, which is configured to perform an image classification task, is trained based at least in part on the synthetic images and the associated training labels. Through this solution, a large scale of synthetic images can be automatically obtained and applicable for training a model for image classification, to improve the model performance with data-scare setting or in the case of model pre-training where the training data amount matters.","['G06V10/774', 'G06T11/60', 'G06V10/764', 'G06V10/82']"
US12165289B2,Image enhancement via iterative refinement based on machine learning models,"A method includes receiving, by a computing device, training data comprising a plurality of pairs of images, wherein each pair comprises an image and at least one corresponding target version of the image. The method also includes training a neural network based on the training data to predict an enhanced version of an input image, wherein the training of the neural network comprises applying a forward Gaussian diffusion process that adds Gaussian noise to the at least one corresponding target version of each of the plurality of pairs of images to enable iterative denoising of the input image, wherein the iterative denoising is based on a reverse Markov chain associated with the forward Gaussian diffusion process. The method additionally includes outputting the trained neural network.","['G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T3/4007', 'G06T5/50', 'G06T5/60', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
US20240087179A1,Video generation with latent diffusion probabilistic models,"Methods and systems for training a model include training an encoder in an unsupervised fashion based on a backward latent flow between a reference frame and a driving frame taken from a same video. A diffusion model is trained that generates a video sequence responsive to an input image and a text condition, using the trained encoder to determine a latent flow sequence and occlusion map sequence of a labeled training video.","['G06T11/00', 'G06T3/0093', 'G06T3/18', 'G06V20/46']"
US11983806B1,Systems and methods for image generation with machine learning models,"Disclosed herein are methods, systems, and computer-readable media for regenerating a region of an image with a machine learning model based on a text input. Disclosed embodiments involve accessing a digital input image. Disclosed embodiments involve generating a masked image by removing a masked region from the input image. Disclosed embodiments involve accessing a text input corresponding to an image enhancement prompt. Disclosed embodiments include providing at least one of the input image, the masked region, or the text input to a machine learning model configured to generate an enhanced image. Disclosed embodiments involve generating, with the machine learning model, the enhanced image based on at least one of the input image, the masked region, or the text input.","['G06T5/60', 'G06T11/00', 'G06T11/60', 'G06T5/00', 'G06T5/77', 'G06V10/77', 'G06V10/945', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20221']"
US20240266074A1,"Cognitive Communications, Collaboration, Consultation and Instruction with Multimodal Media and Augmented Generative Intelligence","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with networked cognitive collaboration, augmented clinical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal clinical communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms, including augmented generative AI algorithms, models and systems. The invention enables cognitively-enriched, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized clinical intelligence.","['A61B34/30', 'G06F40/169', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16H10/60', 'G16H15/00', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H80/00', 'H04L12/1822', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/152', 'A61B2090/365', 'A61B2090/373', 'A61B2090/376', 'A61B2090/378', 'A61B34/25', 'A61B34/73', 'A61B90/361', 'H04L51/10', 'H04M3/561', 'H04M3/567', 'H04M7/0027']"
US11922541B1,Enhancement of machine-generated product image,"Methods, systems, and computer programs are presented for enhancing a machine-generated product image. One method includes an operation for receiving a request on a user interface (UI) to generate an image, where the request comprises a description of the image to be generated and identification of a product for inclusion in the image. The method further includes operations for generating, by a generative artificial intelligence (GAI) model, a first image based on the request, analyzing the first image to identify a presentation of the product in the first image, and selecting a product image from a database of product images based on the identification of the product. The method further includes replacing the presentation of the product in the first image with the selected product image to obtain a second image, and causing presentation in the UI of the second image.","['G06T11/00', 'G06F3/0482', 'G06F3/04812', 'G06F3/0484', 'G06F3/04845', 'G06F40/103', 'G06F40/186', 'G06F40/216', 'G06F40/30', 'G06F40/44', 'G06F40/56', 'G06N3/0475', 'G06N5/022', 'G06T5/005', 'G06T5/50', 'G06T5/77', 'G06T7/11', 'G06T7/194', 'G06V20/62', 'G06T2200/24', 'G06T2207/20084']"
US20240153093A1,Diffusion-based open-vocabulary segmentation,"An open-vocabulary diffusion-based panoptic segmentation system is not limited to perform segmentation using only object categories seen during training, and instead can also successfully perform segmentation of object categories not seen during training and only seen during testing and inferencing. In contrast with conventional techniques, a text-conditioned diffusion (generative) model is used to perform the segmentation. The text-conditioned diffusion model is pre-trained to generate images from text captions, including computing internal representations that provide spatially well-differentiated object features. The internal representations computed within the diffusion model comprise object masks and a semantic visual representation of the object. The semantic visual representation may be extracted from the diffusion model and used in conjunction with a text representation of a category label to classify the object. Objects are classified by associating the text representations of category labels with the object masks and their semantic visual representations to produce panoptic segmentation data.","['G06V20/70', 'G06T7/10', 'G06T7/11', 'G06V10/26', 'G06V10/40', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/10']"
US20240348663A1,Ai-enhanced simulation and modeling experimentation and control,"An artificial intelligence-driven simulation and decision platform for reducing epistemic uncertainty in complex systems. The system integrates advanced techniques from artificial intelligence, simulation, and uncertainty quantification to generate and run scenarios, monitor progress, and adjust parameters in real-time to achieve user-defined goals. The simulation and decision platform comprises an AI system that employs natural language processing, reinforcement learning, and multi-objective optimization; a continuous and scalable simulation environment; scenario generation and guidance that provides human-readable scenario guides and contextual explanations; and an uncertainty quantification and reduction that employs entropy-based methods and Bayesian inference. The system allows users to define goals and objectives for their simulations, and the AI component generates and optimizes scenarios to achieve these goals while reducing epistemic uncertainty. The simulation and decision platform is designed to be flexible and adaptable to various domains and applications, providing a comprehensive and user-friendly solution for managing complex systems under uncertainty.","['H04L63/104', 'G06F16/2477', 'G06F16/951', 'H04L63/1425', 'H04L63/1441', 'H04L63/20', 'H04L67/10', 'H04L67/535', 'H04L67/55', 'H04L67/566', 'H04L67/02', 'H04L67/125']"
US12333692B2,Modifying digital images via multi-layered scene completion facilitated by artificial intelligence,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via multi-layered scene completion techniques facilitated by artificial intelligence. For instance, in some embodiments, the disclosed systems receive a digital image portraying a first object and a second object against a background, where the first object occludes a portion of the second object. Additionally, the disclosed systems pre-process the digital image to generate a first content fill for the portion of the second object occluded by the first object and a second content fill for a portion of the background occluded by the second object. After pre-processing, the disclosed systems detect one or more user interactions to move or delete the first object from the digital image. The disclosed systems further modify the digital image by moving or deleting the first object and exposing the first content fill for the portion of the second object.","['G06F3/04845', 'G06T5/60', 'G06T5/70', 'G06T5/77', 'G06T7/11', 'G06T7/194', 'G06T7/70', 'G06T2200/24', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20104', 'G06T2207/30196']"
US10610302B2,Liver disease assessment in medical imaging,"For liver modeling from medical scan data, multiple modalities of imaging are used. By using multiple modalities of imaging in combination with generative modeling, a more comprehensive and informed assessment may be performed. The generative modeling may allow feedback of effects of proposed therapy on function of the liver. This feedback is used to update the liver function information based on the imaging. Based on the computerized modeling with information from various imaging modes, an output based on more comprehensive information and patient personalized modeling and feedback may be provided to assist the physician.","['A61B34/10', 'A61B18/00', 'A61B18/02', 'A61B18/12', 'A61B5/0035', 'A61B5/055', 'A61B5/4244', 'A61B8/485', 'A61N7/00', 'G06F18/251', 'G06F19/321', 'G06K9/6289', 'G06T11/003', 'G06T7/0012', 'G06V10/803', 'G16H30/40', 'G16H40/63', 'G16H50/30', 'G16H50/50', 'A61B2018/00529', 'A61B2018/00535', 'A61B2018/00577', 'A61B2034/104', 'A61B2034/105', 'A61B5/0263', 'A61B6/03', 'A61B8/5223', 'A61N5/1002', 'A61N5/103', 'G06F18/214', 'G06F18/24', 'G06K2209/051', 'G06K9/6256', 'G06K9/6267', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/30024', 'G06T2207/30056', 'G06T2207/30096', 'G06T2210/41', 'G06T7/11', 'G06V2201/031']"
US12387096B2,Image-to-image mapping by iterative de-noising,"A method includes receiving training data comprising a plurality of pairs of images. Each pair comprises a noisy image and a denoised version of the noisy image. The method also includes training a multi-task diffusion model to perform a plurality of image-to-image translation tasks, wherein the training comprises iteratively generating a forward diffusion process by predicting, at each iteration in a sequence of iterations and based on a current noisy estimate of the denoised version of the noisy image, noise data for a next noisy estimate of the denoised version of the noisy image, updating, at each iteration, the current noisy estimate to the next noisy estimate by combining the current noisy estimate with the predicted noise data, and determining a reverse diffusion process by inverting the forward diffusion process to predict the denoised version of the noisy image. The method additionally includes providing the trained diffusion model.","['G06V10/30', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06V10/80', 'G06V10/82']"
US20240161017A1,Connectome Ensemble Transfer Learning,"The present disclosure describes a method of Connectome Ensemble Transfer Learning (CETL), which makes connectome-based predictive models useful for precision mental healthcare. CETL comprises a novel transfer learning process that incrementally trains Connectome Ensemble Predictive Models (CEPMs) by leveraging information from source domains to improve predictive performance in target domains. The disclosed methods broadly comprise selecting target and source domains, obtaining network connectivity data from individual persons, sampling source ensemble representations of connectome âviewsâ from the obtained network connectivity data of said persons in the source domain, reducing the dimensionality of the sampled connectome âviewsâ, and transferring the distilled representations to the target domain to train more robust, generalizable, and clinically deployable CEPMs that predict diverse target mental health phenotypes. Implemented through massively parallel distributed computing, a system of synchronized computer hardware implementing this method is also disclosed.","['G06N20/20', 'G06N3/096', 'G06N3/042', 'G06N3/045', 'G06N3/09', 'G06N5/01', 'G06N5/02', 'G06N7/01', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06N3/0895']"
US20240386015A1,Composite symbolic and non-symbolic artificial intelligence system for advanced reasoning and semantic search,"A semantic search system integrates with an AI platform to provide advanced search capabilities by leveraging automatically generated ontologies and knowledge graphs. The system employs natural language processing, machine learning, and large language models to create, update, and align ontologies from diverse data sources. It supports context-aware query interpretation, personalized results, and complex reasoning by incorporating user context, feedback, and domain knowledge. The system optimizes search performance and efficiency through indexing techniques, distributed computing, and continuous learning. With a modular architecture and scalable infrastructure, the semantic search system enables users to retrieve relevant, meaningful, and context-specific information from vast amounts of structured and unstructured data. The integration of the semantic search system with the AI platform's components, such as knowledge graphs and model blending, enhances the platform's overall reasoning, decision-making, and problem-solving capabilities, empowering users with intelligent and intuitive search experiences across various domains and applications.","['G06F40/30', 'G06F16/245', 'G06F16/248', 'G06F16/9024', 'G06N5/022', 'G06N5/04']"
US11631235B2,System and method for occlusion correction,"In variants, the method for occlusion correction can include: determining a measurement depicting an occluded object of interest (OOI), optionally infilling the occluded portion of the object of interest within the measurement, and determining an attribute of the object of interest based on the infilled measurement.","['G06Q30/0278', 'G06T5/50', 'G06T5/77', 'G06T7/11', 'G06T7/174', 'G06T7/60', 'G06V10/273', 'G06V20/176', 'G06T2200/04', 'G06T2207/10032', 'G06T2207/20084', 'G06T2207/20088', 'G06T2207/30184']"
US8312056B1,Method and system for identifying a key influencer in social media utilizing topic modeling and social diffusion analysis,A system and method for identifying a key influencer in a social media environment for enterprise marketing utilizing topic modeling and social diffusion analysis. A user interest profile can be generated by analyzing historical data stored in a database utilizing. A social graph can be generated and an influence measuring process based on the social graph data can be performed utilizing a static diffusion model and a dynamic diffusion model to calculate a set of key influencers. The dynamic diffusion model considers time stamp information to assess an impact of each user communication on the growth of a conversation within a time period. The key influencer can be identified in a specific topic area and a number of total users that can be reached via the influencer within a specific time window can be predicted.,"['G06Q50/01', 'G06F16/95']"
CN116541911B,Packaging design system based on artificial intelligence,"The invention relates to a packaging design system based on artificial intelligence, and belongs to the technical field of packaging design. The technical scheme of the invention mainly comprises the following steps: the demand analysis module is used for carrying out multi-round query interaction with a user based on the packaging language model and obtaining design demands according to user input analysis; the scheme generating module comprises a packaging model acquiring unit, a design image generating unit and a design template acquiring unit; the packaging model obtaining unit calls a corresponding packaging model from a box-type library according to the packaging type; the design image generating unit generates a package design pattern according to the type of the packaged product and the design style based on an image generating model; the design template obtaining unit calls a corresponding design template from a template library according to the design style; the scheme generating module generates a design scheme according to the packaging model, the packaging design pattern and the design template; and the editing module is used for editing the design elements in the design scheme.","['G06F30/10', 'G06F30/27', 'G06F40/166', 'G06F40/284', 'G06N3/0464', 'G06N3/08', 'G06T15/00', 'Y02P90/30']"
EP4566019A2,Social network with network-based rewards,"A user interface system is provided, comprising a content display output for presentation of content to a user; a communication network interface port; and at least one automated processor configured to: receive at least one hyperlink in a social network record of a social network; request content associated with the hyperlink; receive an advertisement associated with at least one of the user, the social network record, the hyperlink, and the content; verify presentation of the advertisement to the user; present the content to the user; and account for presentation of the advertisement to the user, by crediting at least one account distinct from an account associated with the user, an account associated with a content owner, and an account associated with a social network.","['G06Q30/0277', 'G06Q20/36', 'G06Q20/384', 'G06Q20/389', 'G06Q30/0214', 'G06Q30/0271', 'G06Q30/0273', 'G06Q30/0631', 'G06Q50/01', 'G06Q20/10']"
WO2025039697A1,"Image enhancement method and apparatus, electronic device, computer-readable storage medium and computer program product","Provided in the present application are an image enhancement method and apparatus, an electronic device, a computer-readable storage medium and a computer program product, which can be applied to various scenarios such as cloud technology, artificial intelligence, smart transportation, and driver assistance. The method comprises: acquiring a latent variable of a facial image to be enhanced, and adding noise to the latent variable, so as to obtain a noisy latent variable of said facial image, said facial image being an image of the face of a target subject; extracting facial features of the face in said facial image; on the basis of the facial features, denoising the noisy latent variable, so as to obtain a denoised latent variable of said facial image; and performing image reconstruction on the denoised latent variable, so as to obtain an enhanced facial image of said facial image.","['G06V40/171', 'G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06T5/00', 'G06V10/82', 'G06V40/16', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11087226B2,Identifying multiple causal anomalies in power plant systems by modeling local propagations,"A system identifies multiple causal anomalies in a power plant having multiple system components. The system includes a processor. The processor constructs an invariant network model having (i) nodes, each representing a respective system component and (ii) invariant links, each representing a stable component interaction. The processor constructs a broken network model having (i) the invariant network model nodes and (ii) broken links, each representing an unstable component interaction. The processor ranks causal anomalies in node clusters in the invariant network model to obtain anomaly score results. The processor generates, using a joint optimization clustering process applied to the models, (i) a model clustering structure and (ii) broken cluster scores. The processor performs weighted fusion ranking on the anomaly score results and broken cluster scores, based on the clustering structure and implicated degrees of severity of any abnormal system components, to identify the multiple causal anomalies in the power plant.","['G05B23/0254', 'G05B23/0281', 'G06F16/9024', 'G06F17/16', 'G06F18/2321', 'G06F18/2323', 'G06K9/6221', 'G06K9/6224', 'G06N20/00', 'G06N5/022', 'G06N5/045', 'G06N5/048', 'G06N7/005', 'G06N7/01', 'Y04S10/52']"
CN111915546B,"Infrared and visible light image fusion method, system, computer equipment and application","The invention belongs to the technical field of image fusion, and discloses an infrared and visible light image fusion method, a system, computer equipment and application, wherein the method, the system and the computer equipment are used for carrying out super-resolution reconstruction based on a convolutional neural network on an original infrared image to obtain a reconstructed infrared image with high resolution; respectively carrying out anisotropic diffusion on the visible light and the high-resolution infrared image to obtain a corresponding base layer and a corresponding detail layer; the KL transformation is utilized to obtain the maximum feature vector to fuse the detail layers, and the saliency self-adaptive extraction is utilized to fuse the base layers; and linearly reconstructing the fused detail layer and the basic layer to obtain a final fused image. A large number of experiments show that compared with 4 fusion algorithms, the algorithm provided by the invention has better fusion effect from subjective judgment and objective evaluation indexes, and has more abundant detail information and contour textures in order to ensure that the fusion image has higher definition.","['G06T5/50', 'G06T3/4053', 'G06T2207/10048', 'G06T2207/20021', 'G06T2207/20048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US10311978B2,Method and system for patient specific planning of cardiac therapies on preoperative clinical data and medical images,"A method and system for patient-specific planning of cardiac therapy, such as cardiac resynchronization therapy (CRT), based on preoperative clinical data and medical images, such as ECG data, magnetic resonance imaging (MRI) data, and ultrasound data, is disclosed. A patient-specific anatomical model of the left and right ventricles is generated from medical image data of a patient. A patient-specific computational heart model, which comprises cardiac electrophysiology, biomechanics and hemodynamics, is generated based on the patient-specific anatomical model of the left and right ventricles and clinical data. Simulations of cardiac therapies, such as CRT at one or more anatomical locations are performed using the patient-specific computational heart model. Changes in clinical cardiac parameters are then computed from the patient-specific model, constituting predictors of therapy outcome useful for therapy planning and optimization.","['G06F30/20', 'A61B5/0044', 'A61N1/3627', 'A61N1/36514', 'A61N1/36585', 'G06F19/00', 'G06T17/00', 'G09B23/30', 'G16H50/50', 'A61B2576/023', 'A61B5/055', 'A61B8/0883', 'G06T2210/41']"
US20230267611A1,Optimization of a deep learning model for performing a medical imaging analysis task,Systems and methods are provided for optimizing a deep learning model. A multi-site dataset associated with different clinical sites and a deployment dataset associated with a deployment clinical site are received. A deep learning model is trained based on the multi-site dataset. The trained deep learning model is optimized based on the deployment dataset. The optimized trained deep learning model is output.,"['G06T7/0014', 'G06F18/214', 'G06F18/2411', 'G06N20/00', 'G06T7/0012', 'G06T7/11', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US11938446B2,Systems and methods for quantifying and/or verifying ocean-based interventions for sequestering carbon dioxide,"A method for calculating carbon credits includes obtaining sensor data associated with at least a portion of a deployment for cultivating a target product in a body of water, executing at least one model based at least in part on the sensor data to generate an output predicting at least one characteristic associated with the target product, the deployment, or a portion of the body of water, and inputting the output into a quantification model. The quantification model is executed to generate an output associated with a predicted capacity of the target product to sequester carbon dioxide. An accuracy of the predicted capacity resulting from the output of the quantification model is greater than an accuracy of a predicted or inferred capacity resulting from the output of each model individually. Carbon dioxide offset credits are determined based on the predicted capacity resulting from the output of the quantification model.","['G06Q10/00', 'B01D53/62', 'A01G33/00', 'G06Q10/087']"
US12260530B2,Generating a modified digital image utilizing a human inpainting model,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06F3/0482', 'G06F3/04842', 'G06F3/04845', 'G06F3/04847', 'G06F3/0486', 'G06F3/04883', 'G06N3/02', 'G06T11/60', 'G06T5/60', 'G06T5/77', 'G06V10/25', 'G06V10/44', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US12288731B2,Multi-fractal heatsink system and method,"A heat sink comprising a heat exchange device having a large-scale morphology over a scale range and a small-scale texture over a scale range, wherein at least one of the large-scale morphology and the small scale texture has a fractal-like self-similarity over a scale range. The large-scale morphology and small-scale texture may be defined and implemented independently, or be provided with a transitional range. The large-scale morphology may be algorithmically optimized according to a set of geometrically constraints. The small-scale texture may be optimized according to aerodynamic parameters and constraints. The heat sink may be dynamically varying, and/or operated in conjunction with a dynamically varying heat transfer medium supply.","['H01L21/4871', 'F28F13/12', 'F28F3/048', 'G05B15/02', 'H01L23/367', 'H01L23/467', 'H01L23/473', 'H05K7/20136', 'H05K7/20154', 'H05K7/20172', 'H05K7/20209', 'H05K7/20272', 'H05K7/20281', 'H05K7/20418', 'F28F2210/02', 'F28F2215/10', 'H01L23/3736']"
US20240281472A1,Interactive interface with generative artificial intelligence,"An interactive search method is disclosed, utilizing a browser-based interface and generative artificial intelligence to enhance user search experiences. The method involves receiving an initial search query from a user, generating a proposed search result via hardware processors, and displaying the result to the user. To refine search accuracy, the method recommends clarifying questions, soliciting additional search parameters. Upon receiving an updated search query, the system interactively refines the initial query and displays an updated search result. This process allows for dynamic query adjustment and improved search result relevance in real-time.","['G06F16/24575', 'G06F16/248', 'G06F16/345', 'G06F16/90328', 'G06F16/93', 'G06F16/9538', 'G06F16/9558']"
US20240160902A1,Similarity-based generative ai output filtering,"Methods and systems for generating output content using a generative artificial intelligence (AI) model based on an input. A similarity-assessment layer at the output of the generative AI model determines a similarity measure for the output content vis-Ã -vis pre-existing items in a repository. The similarity measure is compared to a threshold value and, responsive to the comparison indicating excessive similarity, one or both of the input and the generative AI model are adjusted, and the generative AI model is re-run to generate new output content.","['G06N3/0455', 'G06N20/00', 'G06N3/044', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/0985', 'G06N3/006', 'G06N3/0464', 'G06N3/0499', 'G06N3/092']"
US11664125B2,System and method for deep learning based cardiac electrophysiology model personalization,"A method and system for deep learning based cardiac electrophysiological model personalization is disclosed. Electrophysiological measurements of a patient, such as an ECG trace, are received. A computational cardiac electrophysiology model is personalized by calculating patient-specific values for a parameter of the computational cardiac electrophysiology model based at least on the electrophysiological measurements of the patient using a trained deep neural network (DNN). The parameter of the computational cardiac electrophysiology model corresponds to a spatially varying electrical cardiac tissue property.","['G16H50/20', 'A61B5/7264', 'G06F30/23', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06N7/08', 'G16H50/50', 'G16Z99/00', 'G06N20/00', 'G06N3/048', 'G06N5/01', 'G06N7/01']"
US10535133B2,Automated anatomical labeling by multi-contrast diffeomorphic probability fusion,"A computer-implemented method, system and non-transitory computer readable storage medium for classifying a region of interest of a subject, including receiving imaging data comprising at least one image element, the imaging data comprising the region of interest of the subject; providing a plurality of atlases, each of the plurality of atlases having a candidate region that corresponds to the region of interest of the imaging data, each of the plurality of atlases having at least one image element with associated location and property information; co-registering the plurality of atlases to the imaging data, using at least one processor; assigning a probability to generate a labeling parameter for the region of interest, the probability being associated with each atlas; and classifying the region of interest of the subject based on the assigning.","['A61B5/055', 'A61B6/032', 'A61B6/037', 'A61B6/5211', 'A61B8/5215', 'G06F18/24', 'G06K9/4671', 'G06K9/52', 'G06K9/6267', 'G06T7/0012', 'G06T7/11', 'G06T7/143', 'G06T7/174', 'G06T7/33', 'G06K2009/4666', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/20021', 'G06T2207/20076', 'G06T2207/20128', 'G06T2207/30016']"
CN110503630B,"Cerebral hemorrhage classifying, positioning and predicting method based on three-dimensional deep learning model","The invention discloses a cerebral hemorrhage classifying, positioning and predicting method based on a three-dimensional deep learning model, which is used for carrying out three-dimensional modeling on a two-dimensional CT image by a surface reconstruction method to obtain a three-dimensional CT image; then, a three-dimensional convolutional neural network is used for extracting features of the three-dimensional CT image, and the extracted features are classified through an SVM classifier, so that whether the CT image contains bleeding points or not is classified and judged; slicing the three-dimensional CT image which is judged to contain the bleeding points by the classifier again, and accurately positioning the bleeding point positions of the two-dimensional CT image after slicing through a target detection network; compression encoding is carried out on physical characteristic information of a patient to serve as a three-dimensional conditional generation condition of an countermeasure network, the generation condition is integrated with random noise, and a three-dimensional CT image is output according to physical indexes of the patient by using a three-dimensional generator in the countermeasure network model, so that the diffusion of blood clots of the brain of the patient with time or the absorption condition of the brain of the patient by a human body is predicted.","['G06F18/2411', 'G06T11/003', 'G06T7/0012', 'G06T7/73', 'G16H50/20', 'G16H50/50', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'Y02A90/10']"
US11385292B2,Battery materials screening,"A method, apparatus, system for batter material screening is disclosed. First, microstructure generation parameters for a plurality of microstructures are received, where the microstructure generation parameters include microstructure characteristics. Microstructure statistics are generated using a first artificial intelligence (âAIâ) model, where the received microstructure generation parameters are inputs for the first AI model. Microstructure properties are predicted using a second AI model for the microstructures based on the generated microstructure statistics, the received microstructure generation parameters, and battery cell characteristics. It is determined whether at least one of the microstructures is within a predefined energy profile range based on the predicted microstructure properties.","['G01R31/367', 'H01M10/04', 'G01R31/378', 'G06N3/045', 'G06N3/0454', 'G06N7/005', 'G06N7/01', 'H01M4/02', 'G06N20/00', 'H01M10/0525']"
US10733726B2,"Pathology case review, analysis and prediction","Systems and methods for personalized cancer therapy using analysis of pathology slides to target regions in a single sample that interrogates the feature data of a relatively large number of cells. The disclosure describes pathology case review tools of the future which include analysis, visualization and prediction modeling to provide novel information to the pathologist for the diagnosis of disease. This disclosure further describes a user interface to assist the physicians that make that diagnosis, pathologists. Complex computer learning algorithms will combine and mine these data sets to recommend optimal treatment strategies. A computer interface is provided which allows a pathologist to access those data instantly to make a more informed and accurate diagnosis.","['G06T7/0012', 'G06F18/24', 'G06K9/0014', 'G06K9/00147', 'G06K9/4604', 'G06K9/6267', 'G06T7/11', 'G06V20/695', 'G06V20/698', 'G06K2209/051', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/30024', 'G06T2207/30096', 'G06V2201/031', 'G16H50/20']"
US11992702B2,Machine learning optimization of fluence maps for radiotherapy treatment,"Systems and methods are disclosed for generating fluence maps for a radiotherapy treatment plan that uses machine learning prediction. The systems and methods include identifying image data that indicates treatment constraints for target dose areas and organs at risk areas in an anatomy of the subject, generating anatomy projection images that represent a view of the subject from respective beam angles, using a trained neural network model to generate the computer-simulated fluence map representations based on the anatomy projection images, where the fluence maps indicate a fluence distribution of the radiotherapy treatment at each of the beam angles.","['A61N5/103', 'A61N5/1031', 'A61N5/1038', 'A61N5/1045', 'A61N5/1081', 'G06N3/08', 'G16H20/40', 'G16H30/40', 'G16H50/20']"
US9892367B2,Knowledge discovery from citation networks,"In a corpus of scientific articles such as a digital library, documents are connected by citations and one document plays two different roles in the corpus: document itself and a citation of other documents. A Bernoulli Process Topic (BPT) model is provided which models the corpus at two levels: document level and citation level. In the BPT model, each document has two different representations in the latent topic space associated with its roles. Moreover, the multi-level hierarchical structure of the citation network is captured by a generative process involving a Bernoulli process. The distribution parameters of the BPT model are estimated by a variational approximation approach.","['G06N99/005', 'G06N20/00', 'G06F16/24573', 'G06F16/24578', 'G06F16/93', 'G06F16/9558', 'G06F17/30011', 'G06F17/30525', 'G06F17/3053', 'G06F17/30882', 'G06N7/005', 'G06N7/01', 'G06Q10/10']"
US11896847B2,Adversarial prediction of radiotherapy treatment plans,"Systems and methods are disclosed for generating radiotherapy treatment machine parameters based on projection images of a target anatomy. The systems and methods include operations including receiving a set of pairs of image data for each gantry angle of a radiotherapy treatment machine, wherein each pair of the set of pairs comprises a given projection image that represents a view of an anatomy of a subject from a given gantry angle and a given graphical aperture image of multi-leaf collimator (MLC) leaf positions at the given gantry angle based on the given projection image; training a generative adversarial network (GAN) model based on the set of pairs of image data for each gantry angle; and using the trained GAN model to predict an aperture image of MLC leaf positions for a desired gantry angle based on a projection image that represents a view of an anatomical region of interest.","['A61N5/103', 'A61N5/1047', 'A61N5/1031', 'A61N5/1039', 'A61N5/1067', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G16H20/40', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084']"
CN113240613B,Image restoration method based on edge information reconstruction,"The invention discloses an image restoration method based on edge information reconstruction, which comprises the following steps: completing image data set selection and image preprocessing, and dividing data; adopting a generative confrontation network architecture, which comprises a generator and a discriminator; the generator receives the damaged image and generates a repair image; the discriminator judges the authenticity of the repair result; constraining model training by adopting combined loss, wherein the combined loss comprises reconstruction loss, perception loss, style loss, countermeasure loss and intermediate characteristic loss; iteratively updating and optimizing network parameters by adopting a back propagation algorithm until the model loss tends to converge; and inputting the image to be repaired into the repair model obtained by training, wherein the output of the model is the repair result. According to the method, the defect that the existing algorithm is insufficient in modeling of the relationship between the image texture and the structure is overcome through mutual constraint of edge information reconstruction and damaged texture synthesis, and the image repairing thought based on the depth generation model is expanded.","['G06T5/77', 'G06N3/045', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084']"
US20200294284A1,Posterior image sampling using statistical learning model,"Image reconstruction can include using a statistical or machine learning, MAP estimator, or other reconstruction technique to produce a reconstructed image from acquired imaging data. A Conditional Generative Adversarial Network (CGAN) technique can be used to train a Generator, using a Discriminator, to generate posterior distribution sampled images that can be displayed or further processed such as to help provide uncertainty information about a mean reconstruction image. Such uncertainty information can be useful to help understand or even visually modify the mean reconstruction image. Similar techniques can be used in a segmentation use-case, instead of a reconstruction use case. The uncertainty information can also be useful for other post-processing techniques.","['G06T11/006', 'G06T11/008', 'G06T7/10', 'G06T2207/20076', 'G06T2207/20081', 'G06T2211/424', 'G06T2211/441']"
US11564615B2,Method and systems for analyzing functional imaging data,Methods and systems for analyzing brain functional activity data are provided. Also provided are systems that find use in performing the present methods.,"['A61B5/377', 'A61B5/7275', 'A61B5/055', 'A61B5/246', 'A61B5/4064', 'A61B5/4076', 'A61N5/0622', 'G01R33/4806', 'G06T7/0012', 'G16H50/20', 'G16H50/50', 'G16Z99/00', 'A61B2576/026', 'A61B5/245', 'A61B5/369']"
US20230162023A1,System and Method for Automated Transfer Learning with Domain Disentanglement,"A system and method for automated construction of an artificial neural network architecture are provided. The system includes a set of interfaces and data links configured to receive and send signals, wherein the signals include datasets of training data, validation data and testing data, wherein the signals include a set of random number factors in multi-dimensional signals, wherein part of the random number factors are associated with task labels to identify, and nuisance variations. The system further includes a set of memory banks to store a set of reconfigurable deep neural network (DNN) blocks, hyperparameters, trainable variables, intermediate neuron signals, and temporary computation values including forward-pass signals and backward-pass gradients. The system further includes at least one processor, in connection with the interface and the memory banks, configured to submit the signals and the datasets into the reconfigurable DNN blocks, wherein the at least one processor is configured to explore hyperparameters of regularization modules, pre-processing and post-processing methods such that the reconfigurable DNN blocks achieve nuisance-robust Bayesian inference to be transferable to new datasets with domain shifts.","['G06N3/096', 'G06N3/08', 'G06N3/04', 'G06N3/0455', 'G06N3/047', 'G06N3/0985', 'G06N7/01', 'G06N3/006', 'G06N3/044', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'G06N3/094']"
US11074751B2,3D hair synthesis using volumetric variational autoencoders,"Devices and methods for single-view 3D hair modeling are disclosed. The method for single-view 3D hair modeling includes training, by a neural network processor, a volumetric autoencoder to encode a plurality of 3D hairstyles into latent features, and to generate an output based on the latent features. The method for single-view 3D hair modeling includes training, by the neural network processor, an embedding network to determine hair coefficients of a single hairstyle from an input image. The method for single-view 3D hair modeling includes receiving, by the neural network processor, the input image. The method for single-view 3D hair modeling includes synthesizing, by the neural network processor, hair strands to generate a single-view 3D model of the single hairstyle based on the volumetric autoencoder, the embedding network, and the input image.","['G06T17/20', 'G06T17/00', 'G06T15/00', 'G06T19/20', 'G06T7/10', 'G06T2207/20084', 'G06T2207/30196', 'G06T2219/2004']"
AU2019257675B2,Image enhancement using generative adversarial networks,"Techniques for generating an enhanced cone-beam computed tomography (CBCT) image using a trained model are provided. A CBCT image of a subject is received. a synthetic computed tomography (sCT) image corresponding to the CBCT image is generated, using a generative model. The generative model is trained in a generative adversarial network (GAN). The generative model is further trained to process the CBCT image as an input and provide the sCT image as an output. The sCT image is presented for medical analysis of the subject.","['G06T11/008', 'G06F17/18', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T7/0014', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US20240075079A1,Prebiotic formulations,"Provided herein are compositions comprising a biocompatible microsphere, a biofilm-generating probiotic bacterium, a prebiotic, and/or a prebiofilmic. Methods for preparing and formulating the compositions and methods for treating or preventing a disease using the compositions are also provided.","['A61K35/747', 'A01N63/20', 'A01N63/22', 'A01N63/23', 'A01N63/27', 'A23L33/135', 'A23L33/195', 'A61K35/741', 'A61K47/10', 'A61K47/22', 'A61K9/0031', 'A61K9/1647', 'A61K9/1652', 'A61K9/1658', 'A61K9/50', 'A23V2002/00', 'A23V2200/3202', 'A23V2200/3204']"
US20230177878A1,Systems and methods for learning videos and assessments in different languages,"Systems and methods of converting text into learning videos and assessments in different languages are described. A system receives content in a first language, then conducts a sentiment analysis in that first language. The system then translates the content into a second language, and generates (via a text-to-speech algorithm) second language speech based on the translated content. The system transliterates the second language speech into the first language, producing one or more visemes, and determines facial expressions of an animated avatar speaking the second language speech using the sentiment analysis results and the one or more visemes. The system then generates an animated presentation with the animated avatar having the facial expressions while speaking the second language speech.","['G06V10/82', 'G06V40/176', 'G06F40/30', 'G06F40/40', 'G06F40/58', 'G06T13/40', 'G06V10/7715', 'G06V40/165', 'G06V40/166', 'G10L13/027', 'G10L21/10']"
US10769761B2,Generating high resolution images from low resolution images for semiconductor applications,Methods and systems for generating a high resolution image for a specimen from a low resolution image of the specimen are provided. One system includes one or more computer subsystems configured for acquiring a low resolution image of a specimen. The system also includes one or more components executed by the one or more computer subsystems. The one or more components include a deep convolutional neural network that includes one or more first layers configured for generating a representation of the low resolution image. The deep convolutional neural network also includes one or more second layers configured for generating a high resolution image of the specimen from the representation of the low resolution image. The second layer(s) include a final layer configured to output the high resolution image and configured as a sub-pixel convolutional layer.,"['G06T5/90', 'G06T5/007', 'G06T3/4046', 'G06T3/4053', 'G06T2207/20084', 'G06T2207/20208']"
US11209220B2,Fractal heat transfer device,"A heatsink comprising a heat exchange device having a plurality of heat exchange elements each having a surface boundary with respect to a heat transfer fluid, having successive elements or regions varying according to a fractal relationship. According to one embodiment, a noise spectrum due to fluid flow is wideband. According to another embodiment, surface boundary layers are disrupted to increase heat transfer. Flow-induced vortices may be generated at non-corresponding locations of the plurality of fractally varying heat exchange elements.","['F28F1/40', 'F28F21/02', 'H01L23/36', 'H01L23/367', 'F28D2021/0029', 'F28F2215/10', 'F28F2255/20']"
US9277970B2,System and method for patient specific planning and guidance of ablative procedures for cardiac arrhythmias,A method and system for patient-specific planning and guidance of an ablation procedure for cardiac arrhythmia is disclosed. A patient-specific anatomical heart model is generated based on pre-operative cardiac image data. The patient-specific anatomical heart model is registered to a coordinate system of intra-operative images acquired during the ablation procedure. One or more ablation site guidance maps are generated based on the registered patient-specific anatomical heart model and intra-operative patient-specific measurements acquired during the ablation procedure. The ablation site guidance maps may include myocardium diffusion and action potential duration maps. The ablation site guidance maps are generated using a computational model of cardiac electrophysiology which is personalized by fitting parameters of the cardiac electrophysiology model using the intra-operative patient-specific measurements. The ablation site guidance maps are displayed by a display device during the ablation procedure.,"['A61B34/10', 'A61B19/50', 'A61N7/022', 'G06T19/20', 'G06T7/0083', 'G06T7/0089', 'G06T7/12', 'G06T7/149', 'A61B18/02', 'A61B18/1492', 'A61B2018/00357', 'A61B2018/00577', 'A61B2018/00839', 'A61B2019/504', 'A61B2019/505', 'A61B2019/507', 'A61B2019/5242', 'A61B2019/5289', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'A61B2090/364', 'A61B2090/3764', 'A61B5/042', 'A61B5/283', 'A61N1/362', 'A61N1/39', 'G06F19/3437', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20124', 'G06T2207/30048', 'G16H50/50']"
US11557123B2,Scene change method and system combining instance segmentation and cycle generative adversarial networks,"A scene change method and system combining instance segmentation and cycle generative adversarial networks are provided. The method includes: processing a video of a target scene and then inputting the video into an instance segmentation network to obtain segmented scene components, that is, obtain mask cut images of the target scene; and processing targets in the mask cut images of the target scene by using cycle generative adversarial networks according to the requirements of temporal attributes to generate data in a style-migrated state, and generating style-migrated targets with unfixed spatial attributes into a style-migrated static scene according to a specific spatial trajectory to achieve a scene change effect.","['G06T3/04', 'G06V20/49', 'G06V20/52', 'G06T7/10', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/70', 'G06V40/10', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
US11954578B2,Denoising magnetic resonance images using unsupervised deep convolutional neural networks,"Systems and methods for denoising a magnetic resonance (MR) image utilize an unsupervised deep convolutional neural network (U-DCNN). Magnetic resonance (MR) image data of an area of interest of a subject can be acquired, which can include noisy input images that comprise noise data and noise free image data. For each of the noisy input images, iterations can be run of a converging sequence in an unsupervised deep convolutional neural network. In each iteration, parameter settings are updated; the parameter settings are used in calculating a series of image feature sets with the U-DCNN. The image feature sets predict an output image. The converging sequence of the U-DCNN is terminated before the feature sets predict a respective output image that replicates all of the noise data from the noisy input image. Based on a selected feature set, a denoised MR image of the area of interest of the subject can be output.","['G06T5/70', 'G06N3/045', 'A61B5/055', 'G01R33/5608', 'G06N3/047', 'G06N3/088', 'G06T5/002', 'A61B5/7203', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/10092', 'G06T2207/30016']"
CN105181898B,Atmospheric pollution monitoring and management method as well as system based on high-density deployment of sensors,"The invention provides atmospheric pollution monitoring and a management method as well as a system based on high-density deployment of sensors. The method comprises the steps of acquiring status information in a deployment area, and deploying a plurality of sensors with high density in the deployment area; acquiring sensor data of the plurality of sensors, and performing joint correction on the sensor data; inferring atmospheric pollutant data of location points where the sensors are not deployed in space by utilizing a gauss inference model; performing forecast and analysis on atmospheric pollutant data of the location points with the deployed sensors and the location points where the sensors are not deployed by adopting a prediction model in time series; sending the atmospheric pollutant data to a monitoring center, and monitoring the atmospheric pollution state in the whole area in real time by monitoring personnel. According to the atmospheric pollution monitoring and management method as well as the system based on the high-density deployment of the sensors provided by the invention, purposes of real-time monitoring and evidence obtaining, quantized rating and fine management are achieved, perfect visual display is provided, and integrated management that pollution sources are monitored and discovered, evidences are obtained, and cooperation of enforcement is performed is realized.",[]
US10753997B2,Image standardization using generative adversarial networks,Systems and methods are provided for synthesizing protocol independent magnetic resonance images. A patient is scanned by a magnetic resonance imaging system to acquire magnetic resonance data. The magnetic resonance data is input to a machine learnt generator network trained to extract features from input magnetic resonance data and synthesize protocol independent images using the extracted features. The machine learnt generator network generates a protocol independent segmented magnetic resonance image from the input magnetic resonance data. The protocol independent magnetic resonance image is displayed.,"['G01R33/5608', 'G01R33/543', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/084']"
US9463072B2,System and method for patient specific planning and guidance of electrophysiology interventions,A method and system for patient-specific planning and guidance of electrophysiological interventions is disclosed. A patient-specific anatomical heart model is generated from cardiac image data of a patient. A patient-specific cardiac electrophysiology model is generated based on the patient-specific anatomical heart model and patient-specific electrophysiology measurements. Virtual electrophysiological interventions are performed using the patient-specific cardiac electrophysiology model. A simulated electrocardiogram (ECG) signal is calculated in response to each virtual electrophysiological intervention.,"['A61B19/50', 'A61B34/10', 'A61B5/04028', 'A61B5/327', 'A61B5/7278', 'A61B5/743', 'A61B6/486', 'A61B6/503', 'A61B6/5247', 'G06F19/321', 'G06F19/3437', 'G06T17/20', 'G06T7/0083', 'G06T7/12', 'G16H20/30', 'G16H30/20', 'G16H30/40', 'G16H50/50', 'G16Z99/00', 'A61B2034/101', 'A61B2034/105', 'A61B2576/023', 'A61B6/4441', 'A61N1/3627', 'G06T2200/08', 'G06T2207/30048']"
US12386189B2,Systems and methods for photometrically extracting 3-dimensional depth,"According to some embodiments of the present disclosure, the disclosure relates to an application system and server kit that create and serve digital twin-enabled applications. This disclosure also relates to a hub-and-spoke classification system. This disclosure also relates to a location-based services framework that leverages a generative content process to improve location prediction. This disclosure also relates to virtual reality and augmented reality applications, as well as digital agents that support various types of applications. This disclosure also relates to systems and methods for photometrically extracting information about objects and their features, including three-dimensional depth and related features.",['G02B27/0977']
US20230077187A1,Three-Dimensional Facial Reconstruction,A computer implemented method of generating a three-dimensional facial rendering from a two-dimensional image having a facial image includes: generating a three-dimensional shape model of the facial image and a low resolution two-dimensional texture map of the facial image from the two-dimensional image using a fitting neural network; applying a super-resolution model to the low resolution two-dimensional texture map to generate a high resolution two-dimensional texture map; generating a two-dimensional diffuse albedo map from the high resolution texture map using a de-lighting image-to-image translation neural network; and rendering a high resolution three-dimensional model of the facial image using the two-dimensional diffuse albedo map and the three dimensional shape model.,"['G06T15/205', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T11/001', 'G06T15/04', 'G06T17/00', 'G06T17/20', 'G06T3/4046', 'G06T3/4053', 'G06V20/64', 'G06V40/16', 'G06N3/02', 'G06T13/40', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084']"
US12228629B2,Deep learning methods for noise suppression in medical imaging,"Techniques for denoising a magnetic resonance (MR) image are provided, including: obtaining a noisy MR image; denoising the noisy MR image of the subject using a denoising neural network model, and outputting a denoised MR image. The denoising neural network model is trained by: generating first training data for training a first neural network model to denoise MR images by generating a first plurality of noisy MR images using clean MR data associated with a source domain and first MR noise data associated with the target domain; training the first neural network model using the first training data; generating training data for training the denoising neural network model by applying the first neural network model to a second plurality of noisy MR images and generating a plurality of denoised MR images; and training the denoising neural network model using the training data for training the denoising neural network model.","['G01R33/56', 'G01R33/5608', 'G01R33/565', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T5/60', 'G06T5/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
US9978175B2,"Real time concurrent design of shape, texture, and motion for 3D character animation","Systems and methods for automatically generating animation-ready 3D character models based upon model parameter, clothing selections, and texture-region color component selections are described. One embodiment of the invention includes an application server configured to receive the user defined model parameters and the at least one texture selection via a user interface. In addition, the application server includes a generative model and the application server is configured to generate a 3D mesh based upon the user defined model parameters using the generative model and to apply texture to the generated mesh based upon the at least one texture selection.","['G06T17/20', 'G06T13/40']"
US9373185B2,"Interactive design, synthesis and delivery of 3D motion data through the web","Systems and methods are described for animating 3D characters using synthetic motion data generated by generative models in response to a high level description of a desired sequence of motion provided by an animator. In a number of embodiments, an animation system is accessible via a server system that utilizes the ability of generative models to generate synthetic motion data across a continuum to enable multiple animators to effectively reuse the same set of previously recorded motion capture data to produce a wide variety of desired animation sequences. One embodiment of the invention includes a server system configured to communicate with a database containing motion data including repeated sequences of motion, where the differences between the repeated sequences of motion are described using at least one high level characteristic. In addition, the server system is configured to train a generative model using the motion data, the server system is configured to generate a user interface that is accessible via a communication network, to receive a high level description of a desired sequence of motion via the user interface, to use the generative model to generate synthetic motion data based on the high level description of the desired sequence of motion and to transmit a stream via the communication network including information that can be used to display a 3D character animated using the synthetic motion data.","['G06T13/40', 'G06T13/00', 'G06T2200/16']"
US20240256622A1,Generating a semantic search engine results page,"The present disclosure relates to generating semantic search engine results. Aspects of the present disclosure retrieve relevant information from a search engine based on user's search query. The query can be a classic search query (keyword or short phrase) or a conversational query (e.g., a chat messages between users and/or chatbots), a query based upon an email or other type of message, or a query generate based upon a content item (e.g., a webpage, image, video, document, etc.). Aspects of the disclosure leverage a large language model (LLM), such as, for example, a generative model, to summarizes the content according to the intent detected from the query. In some cases, aspects of the present disclosure may generate a direct answer to the query and provide relevant references to support the information.","['G06F40/30', 'G06F16/9538']"
US12165287B2,sCT image generation using CycleGAN with deformable layers,"Techniques for generating a synthetic computed tomography (sCT) image from a cone-beam computed tomography (CBCT) image are provided. The techniques include receiving a CBCT image of a subject; generating, using a generative model, a sCT image corresponding to the CBCT image, the generative model trained based on one or more deformable offset layers in a generative adversarial network (GAN) to process the CBCT image as an input and provide the sCT image as an output; and generating a display of the sCT image for medical analysis of the subject.","['G06T11/008', 'G06T5/70', 'G06T5/50', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2211/424']"
US9129053B2,Method and system for advanced measurements computation and therapy planning from medical data and images using a multi-physics fluid-solid heart model,"Method and system for computation of advanced heart measurements from medical images and data; and therapy planning using a patient-specific multi-physics fluid-solid heart model is disclosed. A patient-specific anatomical model of the left and right ventricles is generated from medical image patient data. A patient-specific computational heart model is generated based on the patient-specific anatomical model of the left and right ventricles and patient-specific clinical data. The computational model includes biomechanics, electrophysiology and hemodynamics. To generate the patient-specific computational heart model, initial patient-specific parameters of an electrophysiology model, initial patient-specific parameters of a biomechanics model, and initial patient-specific computational fluid dynamics (CFD) boundary conditions are marginally estimated. A coupled fluid-structure interaction (FSI) simulation is performed using the initial patient-specific parameters, and the initial patient-specific parameters are refined based on the coupled FSI simulation. The estimated model parameters then constitute new advanced measurements that can be used for decision making.","['G06F19/3437', 'A61B8/469', 'A61B8/483', 'G06T19/00', 'G16H50/50', 'G06T2210/41']"
CN110298415B,"A kind of training method of semi-supervised learning, system and computer readable storage medium","The present invention provides the training method, system and computer readable storage medium of a kind of semi-supervised learning, which comprises clusters to history mark sample, cluster centre is calculatedï¼It receives new mark sample and does not mark sampleï¼The prediction label that mark sample is calculated according to model acquires first-loss function in conjunction with prediction label and physical tagsï¼Comparative analysis does not mark the consistency of the history mark sample of sample and cluster centre, and the second loss function is calculatedï¼In conjunction with first-loss function and the second loss function, and using the parameter of preset semi-supervised learning algorithm optimization model.As long as the present invention marks a small amount of sample, the cost of annotation process is greatly reducedï¼Using a small amount of mark sample, do not mark sample largely to guide and carry out feature training, given full play to the effect for not marking sample, can further submodel training, improve the predictive ability of model.","['G06F18/2155', 'G06F18/23', 'G06F18/24']"
US11948314B2,Systems and methods for image processing,"The present disclosure is related to systems and methods for image processing. The method includes obtaining a first image of a first modality. The method includes generating a second image of a second modality by processing, based on a trained machine learning model, the first image. The second modality may be different from the first modality.","['G06T7/30', 'G06T5/77', 'G06T5/60', 'G06T7/55', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US12106216B2,Fakecatcher: detection of synthetic portrait videos using biological signals,"Detection of synthetic content in portrait videos, e.g., deep fakes, is achieved. Detectors blindly utilizing deep learning are not effective in catching fake content, as generative models produce realistic results. However, biological signals hidden in portrait videos which are neither spatially nor temporally preserved in fake content, can be used as implicit descriptors of authenticity. 99.39% accuracy in pairwise separation is achieved. A generalized classifier for fake content is formulated by analyzing signal transformations and corresponding feature sets. Signal maps are generated, and a CNN employed to improve the classifier for detecting synthetic content. Evaluation on several datasets produced superior detection rates against baselines, independent of the source generator, or properties of available fake content. Experiments and evaluations include signals from various facial regions, under image distortions, with varying segment durations, from different generators, against unseen datasets, and under several dimensionality reduction techniques.","['G06N3/08', 'G06F18/2411', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V40/161', 'G06V40/169', 'G06V40/40', 'G06V40/45', 'G06N20/10', 'G06V40/15']"
US11645356B2,Deep learning for partial differential equation (PDE) based models,"Embodiments for deep learning for partial differential equation (PDE)-based models by a processor. A trained forecasting model and consistency constraints may be generated using a PDE-based model, a discretization of the PDE-based model, historical inputs the of the PDE-based model, and a representation of consistency constraints to generate a predictive output.","['G06F17/13', 'G06F18/214', 'G06F18/2413', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06V10/764', 'G06F2218/12', 'G06N3/044']"
US10483005B2,System and method for characterization of electrical properties of the heart from medical images and body surface potentials,Methods and systems for estimating patient-specific cardiac electrical properties from medical image data and non-invasive electrocardiography measurements of a patient are disclosed. A patient-specific anatomical heart model is generated from medical image data of a patient. Patient-specific cardiac electrical properties are estimated by simulating cardiac electrophysiology over time in the patient-specific anatomical heart model using a computational cardiac electrophysiology model and adjusting cardiac electrical parameters based on the simulation results and the non-invasive electrocardiography measurements. A patient-specific cardiac electrophysiology model with the patient-specific cardiac electrical parameters can then be used to perform virtual cardiac electrophysiology interventions for planning and guidance of cardiac electrophysiology interventions.,"['G16H50/50', 'A61B5/0044', 'A61B5/0452', 'A61B5/349', 'A61B6/032', 'A61B6/5235', 'A61B6/5247', 'A61B8/0883', 'G06F17/5009', 'G06F19/00', 'G06F30/20', 'G09B23/288', 'G09B23/30', 'A61B2576/023', 'A61B5/004', 'A61B5/04', 'A61B5/24']"
US12067725B2,"Image region localization method, image region localization apparatus, and medical image processing device","Embodiments of this application disclose methods, systems, and devices for image region localization and medical image processing. In one aspect, a method comprises acquiring three-dimensional images of a target body part of a patient. The three-dimensional images comprise a plurality of magnetic resonant imaging (MRI) modalities. The method comprises registering a first image set of a first modality with a second image set of a second modality. After the registering, image features of the three-dimensional images are extracted. The image features are fused to obtain fused features. The method also comprises determining voxel types corresponding to voxels in the three-dimensional images according to the fused features. The method also comprises selecting, from the three-dimensional images, target voxels having a preset voxel type, obtaining position information of the target voxels, and localizing a target region within the target body part based on the position information of the target voxels.","['G06T7/11', 'A61B5/055', 'G01R33/4822', 'G01R33/5608', 'G06F18/253', 'G06F18/295', 'G06T7/0012', 'G06T7/0014', 'G06T7/174', 'G06T7/33', 'G06T7/73', 'G06V10/454', 'G06V10/806', 'G06V10/82', 'G06V10/85', 'G01R33/4838', 'G01R33/56341', 'G01R33/5635', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30068', 'G06T2207/30096', 'G06V2201/03']"
US20240054233A1,"Device, System, and Method for Protecting Machine Learning (ML) Units, Artificial Intelligence (AI) Units, Large Language Model (LLM) Units, and Deep Learning (DL) Units","Systems and methods for protecting machine learning engines, artificial intelligence engines, large language models, and deep learning engines. An Offline Protection Unit is configured to analyze one or more characteristics of a Protected Engine, and to perform offline fortification of the Protected Engine against attacks by changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks. An Online Protection Unit is configured to perform analysis of at least one of: (i) inputs that are directed to be inputs of the Protected Engine, (ii) outputs that are generated by the Protected Engine; and based on the analysis, to dynamically perform online fortification of the Protected Engine against attacks by dynamically changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks.","['G06F21/577', 'G06F21/54', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06N3/094', 'G06F2221/032', 'G06N20/20', 'G06N3/126', 'G06N5/01']"
CN105857388B,Electric power steering apparatus,"The present invention provides a kind of electric power steering apparatus that can obtain handling maneuver sense more appropriate.The ECU of electric power steering apparatus is at least based on handling maneuver torque ThCarry out the basic auxiliary element T of operationa1And target pinion gear angle Î¸ *p*.ECU is by making actual pinion gear angle and target pinion gear angle Î¸p* consistent feedback control carrys out the basic auxiliary element T of operationa1* amendment ingredient.ECU passes through to basic auxiliary element Ta1* carry out operation auxiliary instruction value plus amendment ingredient.ECU is according to relative to target pinion gear angle Î¸p* the elastic component T of the variation of absolute valuesp* variation ratio (gradient) corrects Delay control amount T respectivelyhyAnd viscosity component T *vi* value.Specifically, in elastic component Tsp* when variation ratio is bigger, more make Delay control amount ThyAnd viscosity component T *vi* respectively multiplied by the gain G of bigger valuehy, Gviã","['B62D5/0463', 'B62D6/002', 'B62D6/008']"
CN113674403B,"Three-dimensional point cloud up-sampling method, system, equipment and medium","The invention provides a three-dimensional point cloud up-sampling method, a system and a device, comprising the following steps: dividing the three-dimensional point cloud into fixed point number overlapped point cloud blocks capable of covering all points; extracting layering characteristics according to point cloud block midpoint coordinates; utilizing multi-scale thermonuclear graph convolution to realize point set feature expansion on the extracted hierarchical features; and reconstructing the up-sampled three-dimensional point cloud midpoint coordinates from the extended features. The method can enhance the detail information of different fine granularity of the three-dimensional point cloud with sparse and uneven space distribution, and has good stability on potential noise disturbance and local deformation. Compared with the prior art, the method can promote the uniformity of the spatial distribution of the up-sampling dense point cloud, ensure the accurate representation of the geometric structure of the target object and obtain the improvement of the performance.","['G06T17/00', 'G06T3/4046', 'G06F18/214', 'G06F18/22', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06T3/4053', 'G06T7/10', 'G06T2207/10028', 'G06T2207/20016', 'G06T2207/20021']"
US11669976B2,Automatically classifying animal behavior,"Systems and methods are disclosed to objectively identify sub-second behavioral modules in the three-dimensional (3D) video data that represents the motion of a subject. Defining behavioral modules based upon structure in the 3D video data itselfârather than using a priori definitions for what should constitute a measurable unit of actionâidentifies a previously-unexplored sub-second regularity that defines a timescale upon which behavior is organized, yields important information about the components and structure of behavior, offers insight into the nature of behavioral change in the subject, and enables objective discovery of subtle alterations in patterned action. The systems and methods of the invention can be applied to drug or gene therapy classification, drug or gene therapy screening, disease study including early detection of the onset of a disease, toxicology research, side-effect study, learning and memory process study, anxiety study, and analysis in consumer behavior.","['A61B5/1116', 'G06T7/215', 'A61B5/1128', 'A61B5/165', 'G06T7/0012', 'G06T7/251', 'G06T7/254', 'G06T7/66', 'G06T2207/10016', 'G06T2207/10021', 'G06T2207/10028', 'G06T2207/20032', 'G06T2207/20064', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/30241']"
US11026372B2,Plant growth system,"A system and related method for monitoring plant growth conditions is provided, comprising a plurality of detectors (7) and central detector data processing means (1103); each detector (7) being arranged to measure properties indicative of a temperature, a water content, and a nutrient content, of a plant growth substrate; each detector (7) being further arranged to transmit the measured property or properties over a communications link to the central detector data processing means (1103); the central detector data processing means (1103) being arranged to store predefined irrigation data, defining a relationship between plural values for temperature, water content, pH level and/or nutrient content of the plant growth substrate; and plural desired irrigation output values; process the measured properties from each detector (7) to determine calculated properties of the substrate; and provide an output indicative of a desired irrigation input for the growth substrate, based upon measured properties received from the detectors (7) and the predefined irrigation data. A portable detector communications device (1105) for communicating configuration data relating to the detectors (7) may be included in the system.","['A01G27/005', 'A01G9/24', 'A01B79/005', 'A01G25/16', 'A01G31/00', 'A01G31/02', 'A01G9/124', 'G05B15/02', 'A01G24/18', 'Y02P60/12', 'Y02P60/21']"
US20250265312A1,Efficient Training and Accuracy Improvement of Imaging Based Assay,"The present disclosure relates to devices, apparatuses and methods of improving the accuracy of image-based assay, that uses imaging system having uncertainties or deviations (imperfection) compared with an ideal imaging system. One aspect of the present invention is to add the monitoring marks on the sample holder, with at least one of their geometric and/optical properties of the monitoring marks under predetermined and known, and taking images of the sample with the monitoring marks, and training a machine learning model using the images with the monitoring mark.","['G06F18/2148', 'G06T7/0012', 'G06N20/00', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06T7/10', 'G06T7/11', 'G06T7/62', 'G06T7/70', 'G06V10/22', 'G06T2207/10061', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30024', 'G06T2207/30204']"
CN111295884B,Image processing apparatus and image processing method,"An image processing device (100) is provided with a memory (120) and a circuit (110); a circuit (110) performs processing for bringing the compression-released image close to the original image by using a neural network model that performs learning for bringing the compression-released image close to the original image; the neural network model comprises more than 1 convolution block and more than 1 residual block; 1 or more convolution blocks are processing blocks including convolution layers, respectively; the 1 or more residual blocks are respectively the following processing blocks: the method includes including a convolution group configured of at least 1 of 1 or more convolution blocks, inputting data input to the residual block to the convolution group included in the residual block, and adding the data input to the residual block to data output from the convolution group.","['H04N19/80', 'H04N19/865', 'G06T9/002', 'H04N19/85']"
US12288327B2,"Image-driven brain atlas construction method, apparatus, device and storage medium","The present application is applicable to the field of medical imaging technologies, and provides an image-driven brain atlas construction method and apparatus, a device and a storage medium. The method includes: acquiring multi-modal data of a brain to be predicted, where the multi-modal data is acquired according to image data collected when the brain is under at least three different modalities; inputting the multi-modal data into a preset fusion network for processing to output and acquire feature parameters of the brain; where the processing of the multi-modal data by the fusion network includes: extracting a non-Euclidean spacial feature and an Euclidean spacial feature of the multi-modal data, and performing hypergraph fusion on the non-Euclidean spacial feature and the Euclidean spacial feature to acquire the feature parameters, where the feature parameters are used to characterize a brain connection matrix and/or a disease category of the brain.","['G06T7/30', 'G06N3/08', 'G06T7/0012', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
US11494446B2,"Method and apparatus for collecting, detecting and visualizing fake news","Detecting fake news involves analyzing a distribution of publishers who publish many news articles, analyzing a distribution of various topics relating to the published news articles, analyzing a social media context relating to the published news articles, and detecting fake news articles among the news articles based on the analysis of the distribution of publishers, the analysis of the distribution of the various topics, and the analysis of the social media context. Detecting fake news alternatively involves receiving online news articles including both fake online news articles and real online news articles, creating a hierarchical macro-level propagation network of the fake online news and real online news articles, the hierarchical macro-level propagation network comprising news nodes, social media post nodes, and social media repost nodes, creating a hierarchical micro-level propagation network of the fake online news and real online news articles, the hierarchical micro-level propagation network comprising reply nodes, analyzing structural and temporal features of the hierarchical macro-level propagation network, analyzing structural, temporal, and linguistic features of the hierarchical micro-level propagation network, and identifying fake news among the online news articles based on the analysis of the structural and temporal features of the hierarchical macro-level propagation network and the analysis of the structural, temporal, and linguistic features of the hierarchical micro-level propagation network.","['G06F16/906', 'H04L51/02', 'G06F16/90332', 'G06F16/90335', 'G06F16/9035', 'G06F16/951', 'H04L51/52', 'H04L51/222']"
US20200294630A1,Systems and Methods for Determining Molecular Structures with Molecular-Orbital-Based Features,"Systems and methods for determining molecular structures based on molecular-orbital-based (MOB) features are described. MOB features can be utilized in combination with machine-learning methods to predict accurate properties, such as quantum mechanical energy, of molecular systems.","['G16C20/50', 'G06F18/213', 'G06F18/24', 'G06K9/6232', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'G16C10/00', 'G16C20/10', 'G16C20/70', 'G16C20/30', 'G16C20/90']"
US12354256B2,Brain feature prediction using geometric deep learning on graph representations of medical image data,"Described here are systems and method for predicting clinically relevant brain features using geometric deep learning techniques, such as may be implemented with graph convolutional neural networks or autoencoder networks that are applied to graph representations of brain surface morphology derived from medical images. As an example, graph convolutional neural networks can be applied to brain surface morphology data derived from magnetic resonance images (e.g., T1-weighted) using surface extraction techniques in order to predict brain feature data.","['G06T7/0012', 'A61B5/4088', 'A61B5/4842', 'A61B5/4848', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06N3/048', 'G06T2207/10088', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G16H15/00']"
US11263487B2,"Multi-task GAN, and image translator and image classifier trained thereby","A computer-implemented technique uses a generative adversarial network (GAN) to jointly train a generator neural network (âgeneratorâ) and a discriminator neural network (âdiscriminatorâ). Unlike traditional GAN designs, the discriminator performs the dual role of: (a) determining one or more attribute values associated with an object depicted in input image fed to the discriminator; and (b) determining whether the input image fed to the discriminator is real or synthesized by the generator. Also unlike traditional GAN designs, an image classifier can make use of a model produced by the GAN's discriminator. The generator receives generator input information that includes a conditional input image and one or more conditional values that express desired characteristics of the generator output image. The discriminator receives the conditional input image in conjunction with a discriminator input image, which corresponds to either the generator output image or a real image.","['G06K9/6257', 'G06V10/764', 'G06F18/2148', 'G06F18/217', 'G06F18/2431', 'G06F18/40', 'G06K9/6253', 'G06K9/6262', 'G06K9/628', 'G06N3/08', 'G06V10/82']"
WO2021215736A1,Artificial intelligent system for providing unmanned diagnosis service of infectious diseases,"Provided is an artificial intelligent system for providing an unmanned diagnosis service of infectious diseases, comprising: a user terminal for performing user authentication, receiving a diagnostic result, and sharing a location signal; and an unmanned diagnosis service providing server comprising a diagnostic kit releasing unit for releasing a diagnosis kit on which an identification code is printed in order to diagnose an infectious disease, a user authentication unit for scanning at least one type of identification and identifying a diagnostic subject, a diagnostic kit scanning unit for recognizing and scanning the identification code in order to collect the diagnosis kit containing a specimen collected from the diagnostic subject identified by the user authentication unit, a payment unit for making a payment with at least one type of payment means, and a thermographic camera for measuring the body temperature of a user.","['A61B5/0002', 'A61B10/0051', 'A61B5/0008', 'A61B5/01', 'A61B5/08', 'A61B5/103', 'A61B5/117', 'A61B5/7465', 'A61B5/749', 'G01J5/48', 'G06Q50/26', 'G16H10/20', 'G16H40/67', 'G16H50/80']"
US20230417852A1,Deep learning techniques for suppressing artefacts in magnetic resonance images,"Techniques for removing artefacts, such as RF interference and/or noise, from magnetic resonance data. The techniques include: obtaining input magnetic resonance (MR) data using at least one radio-frequency (RF) coil of a magnetic resonance imaging (MRI) system; and generating an MR image from input MR data at least in part by using a neural network model to suppress at least one artefact in the input MR data.","['G06V10/30', 'G01R33/5608', 'G01R33/565', 'G06F18/214', 'G06F18/2414', 'G06F18/28', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'G06T5/002', 'G06T5/60', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'G06V10/772', 'G06V10/774', 'G06V10/82', 'G06N3/047', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03', 'G06V2201/031']"
US20210248715A1,Method and system for end-to-end image processing,"A method of processing an input image comprises receiving the input image, storing the image in a memory, and accessing, by an image processor, a computer readable medium storing a trained deep learning network. A first part of the deep learning network has convolutional layers providing low-level features extracted from the input image, and convolutional layers providing a residual image. A second part of the deep learning network has convolutional layers for receiving the low-level features and extracting high-level features based on the low-level features. The method feeds the input image to the trained deep learning network, and applies a transformation to the residual image based on the extracted high-level features.","['G06T5/70', 'G06T3/4015', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T5/002', 'G06T5/60', 'G06N3/048', 'G06T2207/20084']"
US20230410450A1,Beautification techniques for 3d data in a messaging system,"The subject technology applies, to image data and depth data, a 3D effect including at least one beautification operation based on an augmented reality content generator, the 3D effect including a beautification operation, the beautification operation comprising modifying image data, the image data including a region corresponding to a representation of a face, the beautification operation comprising using a machine learning model for at least one of smoothing blemishes or preserving facial skin texture. The subject technology generates a depth map using at least the depth data. The subject technology generates a segmentation mask based at least on the image data. The subject technology performs background inpainting and blurring of the image data using at least the segmentation mask to generate background inpainted image data. The subject technology generates a 3D message based at least in part on the applied 3D effect including the at least one beautification operation.","['G06T19/20', 'G06T19/006', 'G06F3/04842', 'G06F3/04883', 'G06N20/00', 'G06T15/50', 'G06T7/194', 'G06T7/50', 'G06T7/507', 'G06V40/161', 'G06V40/166', 'G06V40/171', 'H04L67/131', 'G06N3/045', 'G06T2200/24', 'G06T2207/10028', 'G06T2207/30201', 'G06T2219/2012', 'G06T2219/2024']"
US10282588B2,Image-based tumor phenotyping with machine learning from synthetic data,"Machine training and application of machine-trained classifier are used for image-based tumor phenotyping in a medical system. To create a training database with known phenotype information, synthetic medical images are created. A computational tumor model creates various examples of tumors in tissue. Using the computational tumor model allows one to create examples not available from actual patients, increasing the number and variance of examples used for machine-learning to predict tumor phenotype. A model of an imaging system generates synthetic images from the examples. The machine-trained classifier is applied to images from actual patients to predict tumor phenotype for that patient based on the knowledge learned from the synthetic images.","['G06K9/00127', 'G06T7/0012', 'G16H30/40', 'G06F18/214', 'G06F18/24', 'G06F18/2413', 'G06F19/30', 'G06K9/00536', 'G06K9/00885', 'G06V10/443', 'G06V10/764', 'G06V20/69', 'G06V40/10', 'G16B40/00', 'G16B40/20', 'G16B45/00', 'G16H30/00', 'G16H50/20', 'G16H50/50', 'G16H70/60', 'G01N2800/7028', 'G06F2218/12', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US20210358193A1,Generating an image from a certain viewpoint of a 3d object using a compact 3d model of the 3d object,"A method for generating an image from a certain viewpoint of an object that is three dimensional, the method comprises: rendering an image of the object, based on a compact 3D model of the object and at least one two-dimensional (2D) texture map associated with the certain viewpoint.","['H04N7/147', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T13/40', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/20', 'G06T7/11', 'G06T7/251', 'G06T7/70', 'G06T7/73', 'H04N7/144', 'H04N7/152', 'H04N7/157', 'G06N3/044', 'G06T19/00', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30196', 'G06T2207/30201', 'G06T2219/2004']"
CN112634163B,Method for removing image motion blur based on improved cyclic generation countermeasure network,"The invention discloses an image motion blurring method based on improved cyclic generation and countering network, which comprises the following steps: step 1, constructing a non-paired fuzzy-clear data set; step 2, constructing a generator network consisting of an encoder, a feature converter and a decoder; step 3, constructing a discriminator network for dividing images by receptive fields; step 4, constructing a joint loss function; step 5, constructing two mirror image annular GAN networks to obtain a circularly generated countermeasure network model; step 6, inputting the motion blurred image to be processed into the trained model in the step 5 to obtain a deblurred image; and 7, performing two-dimensional Fourier transform on the preliminary deblurred image obtained in the step 6, and filtering high-frequency bright spot spectrum information to obtain an accurate clear image. The method does not need to estimate the fuzzy core, has few calculation parameters and high deblurring speed, avoids the problems of mode collapse and gradient disappearance, and solves the problem of false clear error identification of a frequency domain.","['G06T5/73', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06T5/10', 'G06T5/20', 'G06T7/246', 'G06T2207/10004', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20201', 'Y02T10/40']"
US10795645B2,Neural network for program synthesis,"Described are systems, methods, and computer-readable media for program generation in a domain-specific language based on input-output examples. In accordance with various embodiments, a neural-network-based program generation model conditioned on an encoded set of input-output examples is used to generate a program tree by iteratively expanding a partial program tree, beginning with a root node and ending when all leaf nodes are terminal.","['G06F8/30', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/105']"
US10902651B2,Systems and methods for magnetic resonance image reconstruction,The disclosure relates to systems and methods for magnetic resonance imaging (MRI). A method may include obtaining k-space data associated with MR signals acquired by an MR scanner. The k-space data may corresponding to a first sampling rate. The method may also include generating one or more estimated images based on the k-space data and a target neural network model. The one or more estimated images may correspond to a second sampling rate that exceeds the first sampling rate. The method may further include determining one or more target images based on the one or more estimated images and the k-space data using a compressed sensing model. The compressed sensing model may be constructed based on the one or more estimated images.,"['G06T11/006', 'G06T11/003', 'G01R33/4818', 'G01R33/5608', 'G01R33/561', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T11/005', 'G06T5/10', 'G06N3/047', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/416', 'G06T2211/424']"
US11491348B2,Real-time patient motion monitoring using a magnetic resonance linear accelerator (MRLINAC),"Systems and techniques may be used to estimate a real-time patient state during a radiotherapy treatment using a magnetic resonance linear accelerator (MR-Linac). For example, a method may include generating a dictionary of expanded potential patient measurements and corresponding potential patient states using a preliminary motion model. The method may include training, using a machine learning technique, a correspondence motion model relating an input patient measurement to an output patient state using the dictionary. The method may include estimating, using a processor, the patient state corresponding to a 2D MR image using the correspondence motion model. The method may include directing radiation therapy, using the MR-Linac, to a target according to the patient state.","['A61N5/1049', 'A61N5/1048', 'A61N5/1037', 'A61N5/1067', 'G06N3/08', 'G06N7/08', 'G06T7/0014', 'G06T7/20', 'G06T7/30', 'A61N2005/1055', 'G06T2207/10016', 'G06T2207/10072', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30096']"
US11083913B2,Machine learning approach to real-time patient motion monitoring,"Systems and techniques may be used to estimate a patient state during a radiotherapy treatment. For example, a method may include generating a dictionary of expanded potential patient measurements and corresponding potential patient states using a preliminary motion model. The method may include training, using a machine learning technique, a correspondence motion model relating an input patient measurement to an output patient state using the dictionary. The method may include estimating, using a processor, the patient state corresponding to an input image using the correspondence motion model.","['A61N5/1037', 'A61N5/107', 'A61N5/1039', 'G06N3/045', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'A61N2005/1034', 'A61N2005/1052', 'A61N2005/1054', 'A61N2005/1055', 'A61N2005/1058', 'A61N2005/1061', 'G06N20/10', 'G06N20/20', 'G06N3/08', 'G06N5/01', 'G06N7/01']"
CN112084314B,A Generative Conversational System Introducing Knowledge,"The invention provides a knowledge-introduced generative session system.A main body framework adopts a transform structure coding and decoding network, and external knowledge joint input is embedded on the coding and decoding network to jointly construct a reply. The system adopts the specific scheme that: the input information includes a historical dialog context and corresponding extrinsic knowledge, and the encoding portion includes a self-attention encoder encoding the historical dialog context and a knowledge encoder encoding the extrinsic knowledge. The self-attention encoder extracts knowledge information through a multi-head self-attention mechanism and integrates the knowledge information into the current context encoding process. The knowledge encoder respectively encodes heterogeneous data and converts the heterogeneous data into knowledge semantic vectors; the self-attention decoder first computes the current decoder state vector in conjunction with the context semantic vector, and then predicts the output knowledge in conjunction with the decoder state vector and the context semantic vector, thereby assisting the decoder in generating a reply. The invention utilizes external knowledge to increase the content richness of the generated response and the capability of active conversation.","['G06F16/3329', 'G06F16/3346', 'G06F40/30']"
US10248119B2,Interactive autonomous vehicle command controller,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving, at an autonomous vehicle system, a command to control an ambient feature associated with the autonomous vehicle system. One or more courses of action may be determined based on the command. In addition, one or more probabilistic models associated with the one or more courses of action may also be determined. Based on the one or more probabilistic models, confidence levels may also be determined to form a subset of the one or more courses of action. A course of action from the subset of the one or more courses of action may then be executed at the autonomous vehicle system responsive to the command.","['G05D1/0088', 'B60H1/00735', 'B60L15/20', 'B60Q3/00', 'B60L2260/32', 'B60Q1/28', 'B60Q1/30', 'G05D2201/0213', 'Y02T10/64', 'Y02T10/645', 'Y02T10/72', 'Y02T10/7275', 'Y02T90/16']"
US11232558B2,Systems and methods for image generation,"The present disclosure provides a system and method for image generation. The method may include obtaining a first image of a first modality including a complete representation of a subject, obtaining a second image of a second modality including a partial representation of the subject, obtaining a trained machine learning model, generating an synthesized second image including a complete representation of the subject using the trained machine learning model based on the first image and the second image.","['G06T7/0012', 'G06T11/008', 'G16H30/20', 'A61B6/037', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06T11/00', 'G06T7/10', 'G16H30/40', 'G16H50/70', 'A61B6/5229', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2211/40', 'Y02D10/00']"
US20240156069A1,Genetically modified rat models for severe combined immunodeficiency (scid),"This invention relates to the engineering of animal cells, preferably mammalian, more preferably rat, that are deficient due to the disruption of tumor suppressor gene(s) or gene product(s). In another aspect, the invention relates to genetically modified rats, as well as the descendants and ancestors of such animals, which are animal models of human cancer and methods of their use.","['A01K67/0276', 'C12N15/8509', 'C12N15/87', 'C12N15/907', 'C12N9/1205', 'C12N9/14', 'C12N9/22', 'A01K2217/05', 'A01K2217/054', 'A01K2217/056', 'A01K2217/15', 'A01K2217/20', 'A01K2217/206', 'A01K2227/105', 'A01K2267/0331', 'A01K2267/0387', 'C12N2015/8536']"
US9747421B2,Multi-factor brain analysis via medical imaging decision support systems and methods,"A medical imaging decision support system is provided that can conduct, and help medical professionals conduct multi-factor brain analysis. Data for disparate processing modes (for example, EEG, MRI, etc.) can be input to the system, processed in parallel in a cloud environment, and the results can be rendered in a thin client (for example, browser) for a user's rapid multi-modal evaluation of a brain.","['A61B5/316', 'G06F19/345', 'A61B5/04012', 'A61B5/048', 'A61B5/374', 'A61B5/4094', 'A61B5/7257', 'G06F19/321', 'G16H30/20', 'G16H40/67', 'G16H50/20', 'A61B5/055', 'A61B5/743', 'G01R33/4808', 'G01R33/546', 'G01R33/5608']"
AU2025208552A1,Scalable neutral atom based quantum computing,"#$%^&*AU2025208552A120250814.pdf##### ABSTRACT The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation. ABSTRACT The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation.20 25 20 85 52 28 J ul 2 02 5 A B S T R A C T 2 0 2 5 2 0 8 5 5 2 2 8 J u l 2 0 2 5 T h e p r e s e n t d i s c l o s u r e p r o v i d e s m e t h o d s a n d s y s t e m s f o r p e r f o r m i n g n o n - c l a s s i c a l c o m p u t a t i o n s . T h e m e t h o d s a n d s y s t e m s g e n e r a l l y u s e a p l u r a l i t y o f s p a t i a l l y d i s t i n c t o p t i c a l t r a p p i n g s i t e s t o t r a p a p l u r a l i t y o f a t o m s , o n e o r m o r e e l e c t r o m a g n e t i c d e l i v e r y u n i t s t o a p p l y e l e c t r o m a g n e t i c e n e r g y t o o n e o r m o r e a t o m s o f t h e p l u r a l i t y t o i n d u c e t h e a t o m s t o a d o p t o n e o r m o r e s u p e r p o s i t i o n s t a t e s o f a f i r s t a t o m i c s t a t e a n d a s e c o n d a t o m i c s t a t e , o n e o r m o r e e n t a n g l e m e n t u n i t s t o q u a n t u m m e c h a n i c a l l y e n t a n g l e a t l e a s t a s u b s e t o f t h e o n e o r m o r e a t o m s i n t h e o n e o r m o r e s u p e r p o s i t i o n s t a t e s w i t h a t l e a s t a n o t h e r a t o m o f t h e p l u r a l i t y , a n d o n e o r m o r e r e a d o u t o p t i c a l u n i t s t o p e r f o r m m e a s u r e m e n t s o f t h e s u p e r p o s i t i o n s t a t e s t o o b t a i n t h e n o n - c l a s s i c a l c o m p u t a t i o n .","['G06N10/40', 'G06N10/20', 'G06N10/60', 'G06N20/20', 'B82Y10/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US20220343475A1,Enhancement of medical images,"A method and apparatus for enhancing magnetic resonance images to produce contrast-enhanced images without the need to administer contrast agent to a patient. The image processing apparatus utilises a trained machine learning algorithm as an image processor, preferably a generative adversarial network, to produce images from contrast agent-free magnetic resonance images with the produced images having similar appearance and better image quality and better pathological sensitivity and being able to differentiate more pathological conditions than actually acquired contrast-enhanced images.","['G06T5/90', 'G06T5/009', 'G06T5/92', 'A61B5/055', 'G06F18/214', 'G06N20/00', 'G06T5/50', 'G06T5/60', 'G06T7/0012', 'A61B5/0044', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212', 'G06T2207/30048']"
US11030275B2,Modelling ordinary differential equations using a variational auto encoder,"A computer-implemented method comprising: from each of multiple trials, obtaining a respective series of observations y(t) of a subject over time t; using a variational auto encoder to model an ordinary differential equation, ODE, wherein the variational auto encoder comprises an encoder for encoding the observations into a latent vector z and a decoder for decoding the latent vector, the encoder comprising a first neural network and the decoder comprising one or more second neural networks, wherein the ODE as modelled by the decoder has a state x(t) representing one or more physical properties of the subject which result in the observations y, and the decoder models a rate of change of x with respect to time t as a function f of at least x and z: dx/dt=f(x, z); and operating the variational auto encoder to learn the function f based on the obtained observations y.","['G06N3/084', 'G06F17/13', 'G06F18/214', 'G06F18/2411', 'G06F18/2414', 'G06K9/6256', 'G06K9/6269', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06V10/82', 'G06V20/698', 'G06N3/044']"
CN113409456B,"Modeling method, system, device and medium for three-dimensional model before craniocerebral puncture operation","The invention relates to a modeling method, a system, a device and a medium of a three-dimensional model before a craniocerebral puncture operation. The method comprises the following steps: acquiring image scanning data of a patient needing craniocerebral puncture operation, and processing according to different procedures according to the type of the image scanning data. The input of the method can be three types of patient image scanning data: the first type: general diagnostic image scan data of a patient: CT and/or MR scan data; the second type: three-dimensional angiographic imaging data of a patient: CTA or MRA scan data; in the third category: diffusion MR scan imaging data of the patient: DWI versus baseline MR data. The method may create full three-dimensional scenes based on the input of different types of imagery scan data, which may be used for preoperative planning and intraoperative navigation.","['G06T17/00', 'G06T7/11', 'G06T7/30', 'G16H30/40', 'G06T2207/10012', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20221', 'G06T2207/30016', 'G06T2207/30101']"
US11765332B2,Virtual 3D communications with participant viewpoint adjustment,"A method for conducting a three dimensional (3D) video conference between multiple participants, the method may include receiving second participant metadata and first viewpoint metadata by a first unit that is associated with a first participant, wherein the second participant metadata is indicative of a pose of a second participant and an expression of the second participant, wherein the first viewpoint metadata is indicative of a virtual position from which the first participant requests to view an avatar of the second participant; generating, by the first unit, and based on the second participant metadata and the first viewpoint metadata, a second participant representation information; wherein the second participant representation information comprises a compact 3D model of the second participant and a second participant texture map; and determining, for the first participant and during the 3D video conference, a representation of virtual 3D video conference environment, wherein the determining is based on the second participant representation information.","['H04N13/111', 'G06T19/006', 'H04N7/157']"
US11805157B2,Sharing content during a virtual 3D video conference,"A method for sharing content during a virtual 3D video conference, the method may include inviting multiple participants to join a virtual 3D video conference; creating a shared folder dedicated for storing shared content items, wherein the shared content is accessible during at least during the virtual 3D video conference; enabling access, to the multiple participants, to the shared folder; wherein the access is governed by one or more access control rule; and conducting the virtual 3D video conference; wherein the conducting comprises sharing at least one of the content items.","['H04L65/4015', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04L12/1818', 'H04L12/1822', 'H04L63/101', 'H04L63/102', 'H04L63/108', 'H04L65/1089', 'H04L65/1093', 'H04L65/403', 'H04L65/80', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'H04N7/157', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/2004']"
US11856328B2,Virtual 3D video conference environment generation,"A method for virtual 3D video conference environment generation, the method may include (a) determining a first optical axis of a first virtual camera, the first optical axis represents a line of sight of the participant while a participant of the 3D video conference environment looks at a current displayed version of a virtual 3D video conference environment (V3DVCE); the current displayed version of the V3DVCE is displayed on a display; (b) determining a second optical axis of a second virtual camera that virtually captures the V3DVCE to provide the current displayed version of the V3DVCE; and (c) generating a next displayed version of the V3DVCE based on at least one of the first optical axis and the second optical axis.","['H04N7/157', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/024', 'G06T2219/2004', 'G06T2219/2012']"
US20200218982A1,Dithered quantization of parameters during training with a machine learning tool,"A machine learning tool uses dithered quantization of parameters during training of a machine learning model such as a neural network. The machine learning tool receives training data and initializes certain parameters of the machine learning model (e.g., weights for connections between nodes of a neural network, biases for nodes). The machine learning tool trains the parameters in one or more iterations based on the training data. In particular, in a given iteration, the machine learning tool applies the machine learning model to at least some of the training data and, based at least in part on the results, determines parameter updates to the parameters. The machine learning tool updates the parameters using the parameter updates and a dithered quantizer function, which can add random values before a rounding or truncation operation.","['G06N3/063', 'G06F7/49963', 'G06N20/00', 'G06N3/084', 'G06N3/048', 'G06N3/082']"
CN105045812B,The classification method and system of text subject,"The present invention relates to text subject sorting technique fields, disclose the classification method and system of a kind of text subject.In the present invention, the classification method of text subject comprising the steps of: acquisition corpusï¼Wherein, corpus includes the text of each type of themeï¼Corpus is segmented, and Text character extraction is carried out to the corpus after participle, obtains the feature vector of each type of theme textï¼The characteristic value in the feature vector of each type of theme text is adjusted according to dynamic logarithm excitation function, obtains the feature vector of new each type of theme textï¼According to the similarity of the feature vector of text to be sorted and new each type of theme text, treats classifying text and classify, determine the type of theme of text to be sorted.In this way, making more acurrate to text classification.",['G06F16/35']
US11410401B2,Beautification techniques for 3D data in a messaging system,"The subject technology receives a selection of a selectable graphical item from a plurality of selectable graphical items, the selectable graphical item comprising an augmented reality content generator for applying a 3D effect, the 3D effect including at least one beautification operation. The subject technology captures image data and depth data using a camera. The subject technology applies, to the image data and the depth data, the 3D effect including the at least one beautification operation based at least in part on the augmented reality content generator, the beautification operation being performed as part of applying the 3D effect. The subject technology generates a 3D message based at least in part on the applied 3D effect including the at least one beautification operation. The subject technology renders a view of the 3D message based at least in part on the applied 3D effect including the at least one beautification operation.","['G06T19/20', 'G06T19/006', 'G06F3/04842', 'G06F3/04883', 'G06N20/00', 'G06T15/50', 'G06T7/507', 'G06V40/161', 'G06V40/166', 'G06V40/171', 'G06N3/045', 'G06T2200/24', 'G06T2219/2012', 'G06T2219/2024']"
CN108665058B,A Generative Adversarial Network Method Based on Segmentation Loss,"A method for generating a countermeasure network based on segment loss comprises the following steps: 1. initializing parameters: setting the batch size m to be 100 and the super parameter k to be 1, initializing parameters by using an Xavier method, determining a maximum iteration number and a loss switching iteration number parameter T, and enabling the iteration number epoch to be 0; 2. training discriminator parameters: let i equal to 1, i be a cyclic variable; 3. training generator parameters; and (3) judging whether the epoch is greater than the maximum iteration number or not, if so, repeating the steps 2 and 3, and if so, ending the training. The method can realize that the generator adopts loss functions of different forms at different training stages, make up for the deficiency of the GAN theory under the single loss form to a certain extent, and make the network training more stable; by introducing the loss of the characteristic level between the real sample and the generated sample, the characteristics extracted by the discriminator are more robust.","['G06N3/045', 'G06V40/50']"
US11238843B2,Systems and methods for neural voice cloning with a few samples,"Voice cloning is a highly desired capability for personalized speech interfaces. Neural network-based speech synthesis has been shown to generate high quality speech for a large number of speakers. Neural voice cloning systems that take a few audio samples as input are presented herein. Two approaches, speaker adaptation and speaker encoding, are disclosed. Speaker adaptation embodiments are based on fine-tuning a multi-speaker generative model with a few cloning samples. Speaker encoding embodiments are based on training a separate model to directly infer a new speaker embedding from cloning audios, which is used in or with a multi-speaker generative model. Both approaches achieve good performance in terms of naturalness of the speech and its similarity to original speakerâeven with very few cloning audios.","['G10L13/047', 'G06N3/08', 'G10L13/027', 'G10L13/033', 'G10L13/0335', 'G10L13/08', 'G10L13/10', 'G10L25/60']"
US10974663B2,Trim part,"The disclosure provides a part of a vehicle, which includes a translucent cover layer having a front surface and a back surface; a heating layer comprising a translucent and opaque heating element extending in a plane of the heating layer, the heating layer located on the back surface side of the cover layer; and a lighting module associated with the heating layer and adapted for lighting the heating layer so that at least part of the heating layer is visible at the front surface side of the cover layer.","['B60R13/02', 'B60Q3/217', 'B60Q3/54', 'B60Q3/74', 'B60Q3/745', 'B60Q3/80', 'H05B3/20', 'H05B3/86', 'B60R2013/0287']"
CN113962358B,Information diffusion prediction method based on time sequence hypergraph attention neural network,"The invention discloses an information diffusion prediction method based on a time sequence hypergraph attention neural network, which predicts information diffusion by learning the preference of a user together from two aspects of a static friendship network and a dynamic interaction network of the user. The method not only captures the static dependency relationship of the user from the friendship network of the user by using the graph convolution neural network, but also innovatively designs a hypergraph attention network, thereby dynamically learning the interaction of the user at the cascade level and the connection between the cascade from the serialized information diffusion hypergraph. And according to the cascade characteristics to be predicted, the embedded searching module searches the vectors of the corresponding users from the obtained user representation vectors of the two aspects respectively so as to perform the next interactive learning. Finally, two self-attention modules are utilized to respectively perform internal deep interactive learning on the cascade representation obtained from the two aspects so as to predict the next affected user, thereby realizing gradual prediction of network information diffusion.","['G06N3/047', 'G06F18/251', 'G06N3/08', 'Y02D10/00']"
US20210106281A1,Implantable medical system,"A system to monitor a biological subject includes an implantable device to be inserted inside the subject, the device including an implanted transceiver, an accelerometer, one or more sensors, a battery to power the transceiver, accelerometer and one or more sensors, and a wireless charger to charge the battery; and a wireless charging system outside of the subject to charge the battery in the implantable device. Drug(s) may be carried in reservoir(s) and dispensed based on sensor output.","['A61B5/686', 'A61B5/6861', 'A61B5/0022', 'A61B5/0031', 'A61B5/02055', 'A61B5/0404', 'A61B5/076', 'A61B5/113', 'A61B5/486', 'A61B5/6805', 'A61B5/7267', 'A61B5/7282', 'A61B2503/40', 'A61B2560/0219', 'A61B2560/0223', 'A61B2562/0219', 'A61B5/002', 'A61B5/0077', 'A61B5/01', 'A61B5/021', 'A61B5/024', 'A61B5/02438', 'A61B5/053', 'A61B5/0538', 'A61B5/0816', 'A61B5/085', 'A61B5/14532', 'A61B5/14551', 'A61B5/14552', 'A61B5/1459', 'A61B5/283', 'A61B5/318', 'A61B5/332', 'A61B5/4839', 'A61B5/4872', 'A61B5/4875', 'A61N1/362', 'A61N1/36557', 'A61N1/37282', 'A61N1/3787']"
US12205042B2,Method and computing system for modelling a primate brain,"In one aspect the application relates to a computing system for providing data for modelling a human brain comprises a database including a plurality of datasets (or allow access to a plurality of datasets), each dataset including at least a dynamical model of the brain including at least one node and a neurodataset of a neuroimaging modality input. The at least one node include a representation of a local dynamic model and a parameter set of the local dynamic model.","['G06N3/10', 'G06N3/04', 'G06N3/049']"
US8731325B2,Automatic generation of a photo guide,"An apparatus, method and an image quality guide document are disclosed. The method includes, for at least one image in a set of images undergoing image enhancement, identifying image quality-related features for the image based on enhancements being applied to the image, identifying image content-related features based on content of the image, determining a content-based degradation of the image based on the identified image quality-related features and image content-related features, and generating a thumbnail of the image. The method further includes generating an image quality guide document for the set of images in which at least one of the thumbnails is associated with a respective text description that is based on the determined content-based degradation.","['G03B27/735', 'G06T5/60', 'G06T7/0002', 'G06V10/993', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US9710916B2,Kernel sparse models for automated tumor segmentation,"A robust method to automatically segment and identify tumor regions in medical images is extremely valuable for clinical diagnosis and disease modeling. In various embodiments, an efficient algorithm uses sparse models in feature spaces to identify pixels belonging to tumorous regions. By fusing both intensity and spatial location information of the pixels, this technique can automatically localize tumor regions without user intervention. Using a few expert-segmented training images, a sparse coding-based classifier is learned. For a new test image, the sparse code obtained from every pixel is tested with the classifier to determine if it belongs to a tumor region. Particular embodiments also provide a highly accurate, low-complexity procedure for cases when the user can provide an initial estimate of the tumor in a test image.","['G06T7/0081', 'G06T7/0012', 'A61B5/055', 'G06T7/11', 'A61B2576/026', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/30096', 'G16H30/40']"
US11935082B2,Discovering neighborhood clusters and uses therefor,"Computer-based systems and methods for discovering neighborhood clusters in a geographic region, where the clusters have a mix of venues and are determined based on venue check-in data. The mix of venues for the clusters may be based on the social similarity between pairs of venues; or emblematic of certain neighborhood typologies; or emblematic of temporal check-in pattern types; or combinations thereof. The neighborhood clusters that are so discovered through venue-check in data could be used for many commercial and civic purposes.",['G06Q30/0205']
US12100121B2,"System, method and computer-accessible medium for detecting structural disorder(s) using magnetic resonance imaging","An exemplary system, method, and computer-accessible medium for detection of structural disorder(s) of patient(s) can be provided which can include, for example, receiving magnetic resonance imaging (MRI) information of the portion(s), generating gadolinium (âGdâ) enhanced map(s) based on the MRI information using a machine learning procedure(s), and detecting the structural disorder(s) of the patient(s) based on a GD contrast of the Gd enhanced map(s). The Gd enhanced map(s) can be a full dosage Gd enhanced map. The machine learning procedure can be a convolutional neural network. The MRI information can include (i) a low-dosage Gd MRI scan(s), or (ii) a Gd-free MRI scan(s). The Gd contrast can be generated in the Gd enhanced map(s) using a T2-weighted MRI image of the portion(s). Structural disorder(s) can include Stroke, tumor, trauma, infection, Multiple sclerosis and/or other inflammatory disease.","['G06T5/00', 'G16H30/40', 'G06T5/50', 'G06T5/60', 'G06T5/92', 'G16H30/20', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2207/10088', 'G06T2207/10096', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
AU2021202422B2,Automatically classifying animal behavior,"Systems and methods are disclosed to objectively identify sub-second behavioral modules in the three-dimensional (3D) video data that represents the motion of a subject. Defining behavioral modules based upon structure in the 3D video data itself -rather than using a priori definitions for what should constitute a measurable unit of action - identifies a previously-unexplored sub-second regularity that defines a timescale upon which behavior is organized, yields important information about the components and structure of behavior, offers insight into the nature of behavioral change in the subject, and enables objective discovery of subtle alterations in patterned action. The systems and methods of the invention can be applied to drug or gene therapy classification, drug or gene therapy screening, disease study including early detection of the onset of a disease, toxicology research, side-effect study, learning and memory process study, anxiety study, and analysis in consumer behavior.","['A61B5/00', 'A61B5/1123', 'A61B5/1128', 'A61B5/7267', 'G06F18/2135', 'G06F18/295', 'G06T7/20', 'G06V10/147', 'G06V10/7715', 'G06V10/85', 'G06V40/20', 'G16H30/40', 'A61B2503/40', 'A61B2503/42', 'A61B2576/00', 'G16H50/70', 'Y02A90/10']"
CN107533577B,Use the IC design of generation and the instantiation of master die,Embodiment is related to carrying out integrated design circuit using the generation and instantiation of master die.The abstract version of master die indication circuit section.Master die includes the version of collapsing of the component of integrated circuit and the link information of node.By analyzing the function of circuit section and removing in the case where not modifying function or at least one redundant component of replacement circuit section or node generate the version of collapsing of link information.Master die is used for device instantiation or refers in the second integrated circuit.,"['G06F30/3323', 'G06F30/367', 'G06F30/39', 'G06F30/392', 'G06F30/394', 'G06F30/398', 'H03K19/00', 'G06F2111/04', 'G06F2111/12', 'G06F2115/08', 'G06F2115/12', 'G06F2119/20']"
US11694397B2,Method for setting a local coordinate system of a tooth 3D digital model,"In one aspect of the present application, a computer-implemented method for setting a local coordinate system of a tooth 3D digital model is provided, the method comprises: obtaining a first 3D digital model representing a first tooth, wherein the first 3D digital model is based on a world coordinate system; and setting a local coordinate system for the first 3D digital model using a first artificial neural network based on the first 3D digital model, where the first artificial neural network is a trained deep learning artificial neural network.","['G06T17/005', 'A61C7/002', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G16H50/50', 'A61C2007/004', 'G06N3/048', 'G16H30/20']"
US20180247227A1,Machine learning systems and methods for data augmentation,"Aspects relate to systems and methods for improving the operation of computer-implemented neural networks. Some aspects relate to training a neural network using a compressed representation of the inputs either through efficient discretization of the inputs, or choice of compression. This approach allows a multiscale approach where the input discretization is adaptively changed during the learning process, or the loss of the compression is changed during the training. Once a network has been trained, the approach allows for efficient predictions and classifications using compressed inputs. One approach can generate a larger more diverse training dataset based on both simulations from physical models, as well as incorporating domain expertise and other available information. One approach can automatically match the documents to the list, while still allowing a user to input information to update and correct the matching process.","['G06N99/005', 'G06N20/00', 'G06F16/2365', 'G06F17/30371', 'G06F17/5009', 'G06F18/22', 'G06F18/2411', 'G06F18/28', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N7/01', 'G06T9/002', 'G06V30/1914', 'G06V30/2504', 'H04N19/60', 'G06F30/20', 'G06N20/10', 'G06N5/01', 'H04N19/96']"
US12045244B1,System and method for automatic document management,"A system for managing documents, comprising: interfaces to a user interface, proving an application programming interface, a database of document images, a remote server, configured to communicate a text representation of the document from the optical character recognition engine to the report server, and to receive from the remote server a classification of the document; and logic configured to receive commands from the user interface, and to apply the classifications received from the remote server to the document images through the interface to the database. A corresponding method is also provided.","['G06F16/24578', 'G06F16/285', 'G06F16/35', 'G06F16/353', 'G06F16/93']"
US11748642B2,Model parameter determination using a predictive model,"A system may measure, using a measurement device, a response associated with a sample to an excitation. Then, the system may compute, using the measured response and the excitation as inputs to a predetermined predictive model, model parameters on a voxel-by-voxel basis in a forward model with multiple voxels that represent the sample. The forward model may simulate response physics occurring within the sample to a given excitation. For example, the forward model may be based on differential or phenomenological equations that approximates the response physics. Moreover, the system may determine an accuracy of the model parameters by comparing at least the measured response and a calculated predicted value of the response using the forward model, the model parameters and the excitation. When the accuracy exceeds a predefined value, the system may provide the model parameters as an output to: a user, another electronic device, a display, and/or a memory.","['G06N5/046', 'G06N3/082', 'G06F30/20', 'G06F30/27', 'G06F30/30', 'G06N20/20', 'G06N3/042', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06F2111/10', 'G06N20/10']"
US11064673B2,Endophytic microbial symbionts in plant prenatal care,"The present disclosure provides novel endophyte strains or cultures thereof that have a symbiotic relationship with plants. The present disclosure further provides methods of improving seed vitality, biotic and abiotic stress resistance, plant health and yield under both stressed and unstressed environmental conditions, comprising inoculating a seed with the novel endophyte strains and cultivating a plant therefrom.","['A01H17/00', 'A01H3/00', 'A01N25/00', 'A01N63/00', 'A01N63/28', 'A01N63/30', 'B09C1/105', 'C12N1/145', 'C12N1/20', 'C12N1/205', 'C12R1/465', 'C12R1/645', 'C12R1/80', 'B09C2101/00', 'C12R2001/465', 'C12R2001/645', 'C12R2001/80']"
CN209001101U,Electromagnetic transmission device,"The utility model provides a kind of electromagnetic transmission device, has the novel waveguide structure using wafer board structure.Electromagnetic transmission device includes transmission line module and waveguide module.The transmission line module includes: the multiple conductive components for the conductive component for separating gap and being laminated and include three or moreï¼And it is located at multiple artificial magnetic conductors between the adjacent any two conductive component in the multiple conductive component.At least one conductive component between two conductive components positioned at both ends in the multiple conductive component has plate shape, and has at least one gap.At least one described gap extends to the edge of at least one conductive component.The waveguide module includes having to separate gap and at least one waveguide in the opening face opposite with the open end at least one gap described in the edge.","['H01P3/123', 'H01P5/107', 'G01S1/00', 'G01S13/34', 'G01S13/931', 'G01S7/032', 'H01P3/08', 'H01P5/024', 'H01P5/12', 'H01P5/181', 'H01Q1/3266', 'H01Q13/065', 'H01Q5/55']"
US10471653B2,Method for producing silicone elastomer parts,Silicon elastomer articles are prepared by a 3-D printing process by depositing droplets of high viscosity curable silicone onto a substrate layer by layer from independently spatially controllable nozzles and irradiation with independently spatially controllable electromagnetic energy.,"['B29C64/112', 'B29C67/24', 'B29C64/153', 'B29C64/165', 'B29C64/209', 'B29C64/264', 'B29C64/268', 'B29C64/277', 'B29C64/393', 'B33Y10/00', 'B33Y40/20', 'B33Y50/02', 'B33Y70/00', 'C08L83/04', 'B29C2035/0822', 'B29C2035/0827', 'B29C2035/0838', 'B29K2083/005', 'B29K2105/16', 'B29K2105/251', 'C08G77/12', 'C08G77/20', 'C08L2205/025', 'C08L2205/03', 'C08L2205/035']"
CN208589518U,Transmission line apparatus,"The utility model provides a kind of transmission line apparatus, has the novel waveguide structure using wafer board structure.Transmission line apparatus includes: multiple conductive components, they separate gap and are laminated, and includes three or more conductive componentsï¼And multiple artificial magnetic conductors, they are located between the adjacent any two conductive component in the multiple conductive component.At least one conductive component between two conductive components positioned at both ends in the multiple conductive component has plate shape, and has at least one gap.At least part of the multiple artificial magnetic conductor is located at around at least one described gap, and the electromagnetic wave propagated along at least one described gap is inhibited to leak out.","['H01P1/211', 'H01P3/123', 'H01P3/088', 'H01P3/121', 'H01P5/024', 'H01P5/107', 'H01Q13/10', 'H01Q13/22', 'H01Q15/008', 'H01Q21/064', 'H01Q3/443', 'H01Q1/3233']"
CN109661684B,Ray tracing method for real interactive ultrasonic simulation,"Random ray tracing methods such as monte carlo ray tracing may be adapted to provide more efficient and realistic ultrasound imaging systems and methods. Many random ray paths perturbed according to the probability distribution can be generated until they converge to the correct solution. The new surface thickness and roughness model enables the reproduction of complex ultrasonic interactions such as multiple reflections and refractions. The contribution of each ray path may be further weighted to better simulate the beamformed ultrasound signal. On modern GPU computing architectures, it is easy to parallelize each transformer element to track many individual rays.","['G09B23/286', 'G06F17/10', 'G06T11/005', 'G06T15/06', 'G06T15/08', 'G09B9/00', 'G06T2210/41', 'G06T2215/16']"
US12282696B2,Method and system for semantic appearance transfer using splicing ViT features,"Using a pre-trained and fixed Vision Transformer (ViT) model as an external semantic prior, a generator is trained given only a single structure/appearance image pair as input. Given two input images, a source structure image and a target appearance image, a new image is generated by the generator in which the structure of the source image is preserved, while the visual appearance of the target image is transferred in a semantically aware manner, so that objects in the structure image are âpaintedâ with the visual appearance of semantically related objects in the appearance image. A self-supervised, pre-trained ViT model, such as a DINO-VIT model, is leveraged as an external semantic prior, allowing for training of the generator only on a single input image pair, without any additional information (e.g., segmentation/correspondences), and without adversarial training. The method may generate high quality results in high resolution (e.g., HD).","['G06V10/82', 'G06F3/14', 'G06F18/2415', 'G06T7/11', 'G06T7/143', 'G06V10/422', 'G06V10/54', 'G06V10/56', 'G06V10/761', 'G06V20/70', 'G06T2207/20084']"
US11589924B2,Non-invasive assessment and therapy guidance for coronary artery disease in diffuse and tandem lesions,"A method and system for non-invasive assessment and therapy planning for coronary artery disease from medical image data of a patient is disclosed. Geometric features representing at least a portion of a coronary artery tree of the patient are extracted from medical image data. Lesions are detected in coronary artery tree of the patient and a hemodynamic quantity of interest is computed at a plurality of points along the coronary artery tree including multiple points within the lesions based on the extracted geometric features using a machine learning model, resulting in an estimated pullback curve for the hemodynamic quantity of interest. Post-treatment values for the hemodynamic quantity of interest are predicted at the plurality of points along the coronary artery tree including the multiple points within the lesions for each of one or more candidate treatment options for the patient, resulting in a respective predicted post-treatment pullback curve for the hemodynamic quantity of interest for each of the one or more candidate treatment options. A visualization of a treatment prediction for at least one of the candidate treatment options is displayed.","['A61B34/10', 'A61B5/0036', 'A61B5/026', 'A61B5/4887', 'A61B5/7267', 'A61B5/7278', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T7/0012', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096', 'G06T2207/30101', 'G06T2207/30104', 'Y02A90/10']"
US12007455B2,Tensor field mapping with magnetostatic constraint,"A system may measure a response associated with a sample to an excitation. The system may compute, using the measured response and the excitation as inputs to an inverse model or a predetermined predictive model, model parameters on a voxel-by-voxel basis in a forward model with multiple voxels that represent the sample. The predetermined predictive model was trained using training data for different excitation strengths, different measurement conditions, or both. The forward model may simulate response physics occurring within the sample to a given excitation, and the model parameters may include magnetic susceptibilities of the multiple voxels. Moreover, the system may determine an accuracy of the model parameters by comparing at least the measured response and a calculated predicted value of the response using the forward model, the model parameters and the excitation. When the accuracy exceeds a predefined value, the system may provide the model parameters as an output.","['G01R33/5608', 'G01R33/30', 'G01R33/36', 'G01R33/443', 'G01R33/54']"
US10475165B2,Kernel-predicting convolutional neural networks for denoising,"Supervised machine learning using convolutional neural network (CNN) is applied to denoising images rendered by MC path tracing. The input image data may include pixel color and its variance, as well as a set of auxiliary buffers that encode scene information (e.g., surface normal, albedo, depth, and their corresponding variances). In some embodiments, a CNN directly predicts the final denoised pixel value as a highly non-linear combination of the input features. In some other embodiments, a kernel-prediction neural network uses a CNN to estimate the local weighting kernels, which are used to compute each denoised pixel from its neighbors. In some embodiments, the input image can be decomposed into diffuse and specular components. The diffuse and specular components are then independently preprocessed, filtered, and postprocessed, before recombining them to obtain a final denoised image.","['G06T5/002', 'G06T5/70', 'G06F17/10', 'G06F18/214', 'G06F18/24', 'G06K9/40', 'G06K9/6256', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T15/005', 'G06T15/06', 'G06T15/50', 'G06T5/60', 'G06V10/30', 'G06V10/764', 'G06V10/82', 'G06T2207/20084', 'G06T2207/20182']"
US12175641B2,Restoring degraded digital images through a deep learning framework,"The present disclosure relates to systems, methods, and non-transitory computer readable media for accurately, efficiently, and flexibly restoring degraded digital images utilizing a deep learning framework for repairing local defects, correcting global imperfections, and/or enhancing depicted faces. In particular, the disclosed systems can utilize a defect detection neural network to generate a segmentation map indicating locations of local defects within a digital image. In addition, the disclosed systems can utilize an inpainting algorithm to determine pixels for inpainting the local defects to reduce their appearance. In some embodiments, the disclosed systems utilize a global correction neural network to determine and repair global imperfections. Further, the disclosed systems can enhance one or more faces depicted within a digital image utilizing a face enhancement neural network as well.","['G06T5/77', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T3/18', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T7/11', 'G06N3/0464', 'G06N3/09', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20221', 'G06T2207/30201']"
US10226548B2,Autogenic living scaffolds and living tissue matrices: methods and uses thereof,The present invention is drawn to a 3-dimensional cell-produced scaffold construct comprising cells and the extracellular matrix that has been produced and arranged by these cells.,"['A61L27/3804', 'A61L27/3633', 'A61L27/3641', 'A61L27/3654', 'A61L27/367', 'A61L27/3675', 'A61L27/3683', 'A61L27/3687', 'A61L27/3834', 'A61L27/3839', 'A61L27/3886', 'A61L27/3895', 'A61L27/54', 'A61L27/56', 'C12N5/0619', 'C12N5/0658', 'C12N5/0671', 'A61L2300/64', 'A61L2430/00', 'A61L2430/06', 'A61L2430/28', 'A61L2430/30', 'A61L2430/32', 'C12N2513/00', 'C12N2533/90']"
US9892171B2,Personalized recommendation of a volatile item,"A system, method, and machine readable medium for creating a personalized recommendation of an item by creating a topic vector based on a plurality of search queries, at least one of a plurality of users associated with the search queries or a plurality of items associated with the search queries; interring a topical preference for a user based on a search query by the user; and recommending at least one item based on the topical preference and the topic vector.","['G06F16/2465', 'G06F16/9535', 'G06F17/30539', 'G06F16/26', 'G06F16/9538', 'G06F17/30572', 'G06F17/30867', 'G06N5/04', 'G06F16/951', 'G06F17/30864']"
US10343279B2,Navigational control of robotic systems and other computer-implemented processes using developmental network with turing machine learning,The Developmental Network incorporates a Turing Machine that injects teaching instructions directly into the skull-closed network. The Developmental Network can also autonomously learn directly from the natural world without the need for a human to encode its input and output. The neural network so configured can be used as a controller for robotic and other computer control applications where the neural network is organized into plural X-Y-Z areas receiving signals from sensors and providing signals to effectors.,"['B25J9/163', 'B25J9/161', 'G06N3/008', 'G06N3/08', 'Y10S901/01', 'Y10S901/47']"
US20230082164A1,Sensors for three-dimensional printing systems and methods,"The present disclosure provides methods and systems for printing a three-dimensional (3D) object. The methods may comprise providing, adjacent to a build surface, a film comprising a polymeric precursor. A sensor may be used to determine a profile of the film. The profile may be indicative of a quality of the film. If the profile meets a quality threshold, at least a portion of the film may be exposed to light to initiate formation of a polymeric material from the polymeric precursor, thereby printing at least a portion of the 3D object.","['B29C64/393', 'B33Y10/00', 'B29C64/124', 'B29C64/129', 'B29C64/264', 'B29C64/282', 'B29C64/343', 'B33Y30/00', 'B33Y40/00', 'B33Y50/02', 'B29K2505/00', 'B29K2509/02']"
US12243437B2,Crowd-based device configuration selection of a music teaching system,"Aspects of embodiments pertain to a method for determining an Input/Output (I/O) device configuration for a music teaching system. The method may comprise receiving a plurality of I/O device configurations of a music teaching system; receiving, for a given I/O device of the music teaching system, an initial I/O device configuration; and determining an updated I/O device configuration for the given I/O Device, based on the initial I/O device configuration of the given I/O Device and at least one of the plurality of received I/O device configurations. The determining is performed such that the updated I/O device configuration has improved device performance compared to the initial I/O device configuration.","['G10G1/04', 'G09B15/00', 'G10G3/04', 'G10H1/0008', 'G10H1/0083', 'G10L25/51', 'G10L25/90', 'G10H2210/091', 'G10H2220/015', 'G10H2240/105', 'H04R2499/15', 'H04S2400/15']"
US11670188B2,Method and apparatus for an adaptive and interactive teaching of playing a musical instrument,"A method for online music learning of playing a musical instrument, that may be a string instrument, a woodwind instrument, a brass instrument, a percussion instrument, or vocal (singing) is described. A client device, such as a smartphone or a tablet notifies a person, such as visually by a display or audibly by a sounder, of a sequence of musical symbols that may be part of a musical piece to be played on the musical instrument. The pace or tempo of the notified sequence is adapted according to a stored skill level value of the person and the pace or tempo associated with the musical piece. The client device, monitors, using a microphone(s) in the client device, the errors in the playing of the sequence, and using a predefined accordingly updates the stored skill level value, and accordingly changes the arrangement, pace and/or tempo of the next sequence of musical symbols.","['G09B15/003', 'G09B15/00', 'G10H1/0016', 'G10H1/0066', 'G10H1/0083', 'G10H2210/091', 'G10H2220/151', 'G10H2220/211', 'G10H2240/056', 'G10H2240/105', 'G10H2240/131', 'G10H2250/311']"
US11961189B2,Providing 3D data for messages in a messaging system,"The subject technology generates depth data using a machine learning model based at least in part on captured image data from at least one camera of a client device. The subject technology applies, to the captured image data and the generated depth data, a 3D effect based at least in part on an augmented reality content generator. The subject technology generates a depth map using at least the depth data. The subject technology generates a packed depth map based at least in part on the depth map, the generating the packed depth map. The subject technology converts a single channel floating point texture to a raw depth map. The subject technology generates multiple channels based at least in part on the raw depth map. The subject technology generates a segmentation mask based at least on the captured image data. The subject technology performs background inpainting and blurring of the captured image data using at least the segmentation mask to generate background inpainted image data.","['G06F1/1643', 'G06T19/00', 'G06F1/1626', 'G06F1/1686', 'G06F1/1694', 'G06F3/0346', 'G06F3/0482', 'G06F3/04842', 'G06F3/04845', 'G06F3/0488', 'G06T11/60', 'G06T19/006', 'G06T19/20', 'G06T7/50', 'H04L51/10', 'H04L51/42', 'G06T2200/24', 'G06T2207/20084', 'G06T2219/2012', 'G06T2219/2024']"
US12231609B2,Effects for 3D data in a messaging system,"The subject technology receives, at a client device, a selection of a selectable graphical item from a plurality of selectable graphical items, the selectable graphical item comprising an augmented reality content generator including a 3D effect. The subject technology applies, to image data and depth data, the 3D effect based at least in part on the augmented reality content generator, the applying the 3D effect. The subject technology generates a depth map using at least the depth data, generates a segmentation mask based at least on the image data, and performs background inpainting and blurring of the image data using at least the segmentation mask to generate background inpainted image data. The subject technology generates a 3D message based at least in part on the applied 3D effect.","['H04N13/128', 'G06T19/006', 'G06T7/571', 'G06T7/593', 'H04L67/131', 'H04N13/111', 'H04N13/239', 'G06T2200/24', 'G06T2207/30201', 'H04L67/02', 'H04L67/12', 'H04L67/52', 'H04N2013/0081']"
US11972693B2,"Method, device, system and apparatus for creating and/or selecting exercises for learning playing a music instrument",Embodiments pertain to a system configured to provide a music learning session to a user. The system comprises a memory for storing data and executable instructions; and a processor that is configured to execute the executable instructions to result in performing the following steps: presenting the user with a representation of a musical piece to be played by the user with a music instrument; receiving an audio signal relating to an instrument output provided by the music instrument played by the user; and determining a level of correspondence between the received audio signal and the representation of the musical piece presented to the user. The steps may further comprises identifying an audio signal portion for which a determined level of correspondence does not meet a correspondence criterion; and determining an error characteristic for the identified audio signal portion.,"['G09B15/023', 'G09B5/02', 'G10G1/00']"
US11017761B2,Parallel neural text-to-speech,"Presented herein are embodiments of a non-autoregressive sequence-to-sequence model that converts text to an audio representation. Embodiment are fully convolutional, and a tested embodiment obtained about 46.7 times speed-up over a prior model at synthesis while maintaining comparable speech quality using a WaveNet vocoder. Interestingly, a tested embodiment also has fewer attention errors than the autoregressive model on challenging test sentences. In one or more embodiments, the first fully parallel neural text-to-speech system was built by applying the inverse autoregressive flow (IAF) as the parallel neural vocoder. System embodiments can synthesize speech from text through a single feed-forward pass. Also disclosed herein are embodiments of a novel approach to train the IAF from scratch as a generative model for raw waveform, which avoids the need for distillation from a separately trained WaveNet.","['G10L13/047', 'G06F17/18', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G10L19/00', 'G10L25/30', 'G06N3/048', 'G06N3/082']"
CN208637609U,Slot antenna array and radar installations,"The utility model provides slot antenna array and radar installations.Compared with the case where using microstrip line, the aerial array of low loss is realized.Slot antenna array in one embodiment includes the 1st conductive component, the 2nd conductive surface of the 1st conductive surface and back side with face side, has the 1st gap and the 2nd gapï¼2nd conductive component, the 3rd conductive surface with the face side opposed with the 2nd conductive surfaceï¼1st waveguide elements have the waveguide surface that the electric conductivity extended is opposed to the 2nd conductive surface or the 3rd conductive surfaceï¼1st wave guide wall of electric conductivity is oriented at least part in the space surrounded between the 2nd gap and the 1st through hole or a part is clipped in the middleï¼With the 1st artificial magnetic conductor, it is configured in around two sides and the 1st wave guide wall of the 1st waveguide elements.The 1st through hole that 2nd conductive component is overlapped when having from the normal direction of the 1st conductive surface with the 2nd gap.","['H01Q21/005', 'H01Q13/10', 'G01S13/931', 'G01S7/03', 'H01P3/123', 'H01P5/12', 'H01Q13/16', 'H01Q21/0006', 'H01Q21/064', 'G01S7/028', 'H01Q1/3233', 'H01Q13/0233']"
US11170543B2,MRI image reconstruction from undersampled data using adversarially trained generative neural network,A method of magnetic resonance imaging acquires undersampled MRI data and generates by an adversarially trained generative neural network MRI data having higher quality without using any fully-sampled data as a ground truth. The generative neural network is adversarially trained using a discriminative neural network that distinguishes between undersampled MRI training data and candidate undersampled MRI training data produced by applying an MRI measurement function containing an undersampling mask to generated MRI training data produced by the generative neural network from the undersampled MRI training data.,"['G01R33/5608', 'G06T11/006', 'G01R33/561', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T5/10', 'G06N3/048', 'G06N3/084', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/41']"
CN209056614U,Electromagnetic horn array and radar installations,"The utility model provides electromagnetic horn array and radar installations.Shorten the interval of the phase center of antenna element.Electromagnetic horn array includes at least two electromagnetic horn element arranged on the 1st direction.At least two electromagnetic horn element is respectively provided with: base portion, is had in the gap that the 2nd side intersected with the 1st direction upwardly extendsï¼And the loudspeaker with the gap area, the loudspeaker have the 2nd inner wall of a pair of a pair the 1st inner wall and the electric conductivity intersected with the 2nd direction for the electric conductivity intersected with the 1st direction.The pair of 2nd inner wall has opposed pairs protrusion.The pair of protrusion forms 2 radiation sources in the inside of the pair of 1st inner wall in radiated electromagnetic wave.","['H01Q21/064', 'H01Q21/061', 'G01S1/04', 'H01Q1/36', 'H01Q13/0233', 'H01Q13/0283', 'H01Q21/0087', 'H01Q13/025']"
CN209298349U,Aerial array,"Aerial array is provided, realizes that the configuration space of antenna element is smaller and wide band aerial array.Aerial array includes the conductive component on conductive surface, and multiple gaps are open in the conductive surfaceï¼The edge of multiple ridges pair of electric conductivity, their described central portions on the conductive surface from the multiple gap protrudes respectively.When the direction of the central portion extension along each gap is observed, the at least part in the 2nd gap between at least part and the 2nd ridge pair in the 1st gap between the 1st ridge pair is overlapped, and the component of other electric conductivity is not present between them, or at least part of the 1st ridge pair and at least part of the 2nd ridge pair are overlapped, and the component of other electric conductivity is not present between them.","['H01Q21/064', 'H01Q21/00', 'H01Q1/50', 'H01Q13/0275', 'H01Q21/0025', 'H01Q21/005', 'H01P3/123']"
US12329491B2,Method and system for augmented imaging in open treatment using multispectral information,"Disclosed herein is a method of generating augmented images of tissue of a patient undergoing open treatment, in particular open surgery, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: estimating a spectral composition of light illuminating a region of interest of the tissue, obtaining one or more multispectral images of the region of interest, applying a machine learning based regressor or classifier to the one or more multispectral images, or an image derived from said multispectral image, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image, wherein said regressor or classifier has been trained to predict the one or more tissue parameters from a multispectral image under a given spectral composition of illumination, wherein the regressor or classifier employed is made to match the estimated spectral composition of light illuminating said region of interest of the tissue.","['A61B5/0037', 'A61B5/0002', 'A61B5/0071', 'A61B5/0075', 'A61B5/02042', 'A61B5/0205', 'A61B5/14546', 'A61B5/1455', 'A61B5/14551', 'A61B5/1495', 'A61B5/443', 'A61B5/4547', 'A61B5/4842', 'A61B5/4875', 'A61B5/4881', 'A61B5/4887', 'A61B5/489', 'A61B5/4893', 'A61B5/7267', 'A61B5/7275', 'A61B5/749', 'A61B90/361', 'G06F18/2413', 'G06T7/0012', 'G06V10/141', 'G06V10/60', 'G06V10/764', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B2090/365', 'A61B2505/05', 'A61B2560/0223', 'A61B2560/0247', 'A61B2576/00', 'G06T2207/10068', 'G06T2207/20008', 'G06T2207/20081', 'G06T2207/20084', 'G06V10/467', 'G06V2201/031']"
US20200285997A1,Near real-time detection and classification of machine anomalies using machine learning and artificial intelligence,"A method of determining anomalous operation of a system includes: capturing a stream of data representing sensed (or determined) operating parameters of the system over a range of operating states, with a stability indicator representing whether the system was operating in a stable state when the operating parameters were sensed; determining statistical properties of the stream of data, including an amplitude-dependent parameter and a variance thereof over time parameter for an operating regime representing stable operation; determining a statistical norm for the statistical properties that distinguish between normal operation and anomalous operation of the system; responsive to detecting that normal and anomalous operation of the system can no longer be reliably distinguished, determining new statistical properties to distinguish between normal and anomalous system operation; and outputting a signal based on whether a concurrent stream of data representing sensed operating parameters of the system represent anomalous operation of the system.","['G06N20/00', 'G05B23/024', 'G06N3/08', 'G06N7/00', 'G06N7/01']"
US20220138286A1,"Graphics security with synergistic encryption, content-based and resource management technology","Systems, apparatuses and methods may provide for encryption based technology. Data may be encrypted locally with a graphics processor with encryption engines. The graphics processor components may be verified with a root-of-trust and based on collection of claims. The graphics processor may further be able to modify encrypted data from a non-pageable format to a pageable format. The graphics processor may further process data associated with a virtual machine based on a key that is known by the virtual machine and the graphics processor.","['G06F21/602', 'G06F21/105', 'G06F21/53', 'G06F21/84', 'G06F8/65', 'G06F9/45558', 'G06F9/5027', 'G06N3/04', 'G06N3/08', 'G06T1/20', 'G06T1/60', 'H04L63/0428', 'H04L63/061', 'H04L9/085', 'H04L9/0866', 'H04L9/0891', 'H04L9/3242', 'H04L9/3247', 'H04L9/3263', 'G06F2009/45587', 'G06N3/063', 'H04L2209/603', 'H04L2463/081', 'H04L2463/101']"
US20220122001A1,Imitation training using synthetic data,"Approaches presented herein provide for the generation of synthetic data to fortify a dataset for use in training a network via imitation learning. In at least one embodiment, a system is evaluated to identify failure cases, such as may correspond to false positives and false negative detections. Additional synthetic data imitating these failure cases can then be generated and utilized to provide a more abundant dataset. A network or model can then be trained, or retrained, with the original training data and the additional synthetic data. In one or more embodiments, these steps may be repeated until the evaluation metric converges, with additional synthetic training data being generated corresponding to the failure cases at each training pass.","['G06N20/20', 'G06N3/084', 'A63F13/50', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0454']"
US11786694B2,"Device, method, and app for facilitating sleep","A device, system, and method for facilitating a sleep cycle in a subject, comprising selecting a waveform from a plurality of waveforms derived from brainwaves of at least one sleeping donor, wherein said waveform corresponds to at least one specific stage of sleep; and stimulating the subject with at least one stimulus, wherein said at least one stimulus is at least one of an auditory stimulus and a visual stimulus modulated with the selected waveform to entrain the brain of the subject with the selected waveform to facilitate sleep in the subject.","['A61M21/02', 'A61B5/165', 'A61B5/374', 'A61B5/4812', 'A61B5/7267', 'A61B5/7278', 'A61B5/7282', 'A61M21/00', 'A61N1/0456', 'A61N1/36025', 'A61N1/36078', 'A61N2/006', 'A61N2/02', 'A61N5/0618', 'A61N5/0622', 'G16H20/30', 'G16H40/63', 'G16H50/20', 'G16H50/70', 'A61B2505/09', 'A61B5/02055', 'A61B5/245', 'A61M2021/0016', 'A61M2021/0022', 'A61M2021/0027', 'A61M2021/0044', 'A61M2021/0055', 'A61M2021/0072', 'A61M2021/0077', 'A61M2205/3303', 'A61M2205/3317', 'A61M2205/332', 'A61M2205/3375', 'A61M2205/3553', 'A61M2205/3592', 'A61M2205/505', 'A61M2205/507', 'A61M2205/52', 'A61M2205/8206', 'A61M2209/088', 'A61M2230/04', 'A61M2230/06', 'A61M2230/10', 'A61M2230/18', 'A61M2230/205', 'A61M2230/42', 'A61M2230/50', 'A61M2230/60', 'A61M2230/63', 'A61M2230/65', 'A61N2005/0626', 'A61N2005/0648', 'A61N2005/0651', 'G06F2203/011']"
US11364361B2,System and method for inducing sleep by transplanting mental states,A method of replicating a mental state of a first subject in a second subject comprising: capturing a mental state of the first subject represented by brain activity patterns; and replicating the mental state of the first subject in the second subject by inducing the brain activity patterns in the second subject.,"['A61B5/055', 'A61B5/245', 'A61B5/369', 'A61B5/378', 'A61B5/38', 'A61B5/389', 'A61B5/486', 'A61B5/7253', 'A61M21/02', 'A61N1/36025', 'A61B5/291', 'A61B5/316', 'A61B5/4812', 'A61M2021/0016', 'A61M2021/0022', 'A61M2021/0027', 'A61M2021/0044', 'A61M2021/0055', 'A61M2021/0072', 'A61M2205/50', 'A61M2230/08', 'A61M2230/10', 'A61N1/0456', 'A61N1/36031', 'A61N2/006']"
CN103293498B,The system and method for susceptibility quantitative imaging is provided,"The invention provides susceptibility quantitative imaging method and system, by Bayesian statistic strategy, from magnetic resonance image (MRI) complex data, generate the image organizing magnetism characteristic.Likelihood item directly constructs from complex signal.The structure of priori makes structure and known morphological information content match.Susceptibility is quantitatively schemed (quantity of magnetism figure) can be determined by such as maximum a posteriori probability.Therefore according to exemplary embodiment, the system provided in literary composition, method and computer accessible can determine the corresponding informance of at least one structure.Use this exemplary embodiment, can receive with the relevant signal of structure, signal can be included in the complex signal of complex field.In addition, based on the real information with complex signal, can the quantity of magnetism figure of generating structure, wherein real information is correlated with the real noise characteristic of structure at least partly.","['G01R33/56545', 'A61B5/0042', 'A61B5/055', 'G01R33/24', 'G01R33/56536']"
US11885952B2,"Optics, device, and system for assaying and imaging","A method of assaying an analyte in a sample is disclosed. The method includes having a sample holder with a sample contact area for contacting a sample with an analyte, having a plurality of calibration structures on the sample contact area of the sample holder, imaging a part of the sample contact area that has the calibration structures, and using an algorithm that includes an image, calibration structures in the image, and artificial intelligence and/or machine learning to identify the analyte and/or determine the analyte concentration.","['G02B21/34', 'A61B5/00', 'A61B5/1455', 'A61B5/1495', 'G01N21/6456', 'G01N21/78', 'G01N33/54386', 'G02B27/32', 'G01N21/76', 'G01N2201/0221', 'G01N2496/05', 'G01N33/5094']"
CN109671433B,Keyword detection method and related device,"The invention discloses a keyword detection method, which comprises the following steps: obtaining an enhanced voice signal of a voice signal to be detected, wherein the enhanced voice signal corresponds to a target speech rate; performing variable speed processing on the enhanced voice signal to obtain a first variable speed voice signal, wherein the first variable speed voice signal corresponds to a first speech speed; acquiring a first voice characteristic signal according to the first variable speed voice signal; obtaining a keyword detection result corresponding to the first voice characteristic signal through a keyword detection model, wherein the keyword detection result is used for indicating whether a target keyword exists in the voice signal to be detected; and if the target keyword exists according to the keyword detection result, executing the operation corresponding to the target keyword. The invention also discloses a keyword detection device. The invention can carry out variable speed processing on the enhanced signal, and can improve the detection rate of keywords in fast voice or slow voice.","['G10L15/08', 'G10L15/22', 'G10L15/02', 'G10L15/28', 'G10L21/0208', 'G10L21/0216', 'G10L21/043', 'G10L25/12', 'G10L25/24', 'H04R3/005', 'G10L15/142', 'G10L15/16', 'G10L2015/088', 'G10L2015/223', 'G10L2021/02082', 'G10L2021/02163', 'G10L2021/02166', 'H04R2430/20', 'H04R2430/25', 'H04R3/02', 'Y02D10/00']"
US10762398B2,Modality-agnostic method for medical image representation,"Techniques for the operation and use of a model that learns the general representation of multimodal images is disclosed. In various examples, methods from representation learning are used to find a common basis for representation of medical images. These include aspects of encoding, fusion, and downstream tasks, with use of the general representation and model. In an example, a method for generating a modality-agnostic model includes receiving imaging data, encoding the imaging data by mapping data to a latent representation, fusing the encoded data to conserve latent variables corresponding to the latent representation, and training a model using the latent representation. In an example, a method for processing imaging data using a trained modality-agnostic model includes receiving imaging data, encoding the data to the defined encoding, processing the encoded data with a trained model, and performing imaging processing operations based on output of the trained model.","['G06K9/6289', 'G16H20/30', 'A61N5/1039', 'G06F18/24143', 'G06F18/251', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T11/008', 'G06T9/001', 'G06T9/002', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G06K2209/05', 'G06N20/10', 'G06N3/04', 'G06N3/044', 'G06T11/003', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/441', 'G06T7/11', 'G06T7/174', 'G06V2201/03', 'H04N19/176']"
US20220414429A1,Physics-informed attention-based neural network,"A physics-informed attention-based neural network (PIANN) system, wherein the PIANN system is a computer system configured to implement a PIANN, the computer system comprising at least one processor and memory storing computer instructions, wherein, when the at least one processor executes the computer instructions, the PIANN system is trained to learn a solution or model for a partial differential equation (PDE) respecting one or more physical constraints, and wherein the PIANN includes a physics-informed neural network (PINN) implementing a deep neural network and a transition zone detector. According to at least some implementations, the PIANN implements a recurrent neural network (RNN).","['G06N3/0442', 'G06N3/0445', 'G06N3/044', 'E21B41/00', 'G06N3/042', 'G06N3/0455', 'G06N3/08', 'G06N3/09', 'E21B2200/22']"
US10803631B2,Systems and methods for magnetic resonance imaging,A method for magnetic resonance imaging may include acquiring first k-space data that is generated by entering acquired magnetic resonance (MR) data into a plurality of first k-space locations. The method may further include synthesizing second k-space data for a plurality of second k-space locations that are not filled with the acquired MR data. The method may further include reconstructing an image from the first k-space data and the second k-space data by applying a reconstruction algorithm. The reconstruction algorithm is based at least in part on a neural network technique.,"['G06T11/003', 'G06T11/005', 'G01R33/5608', 'G01R33/4818', 'G01R33/5611', 'G06N3/045', 'G06N3/08', 'G06T11/006', 'G06T5/10', 'G01R33/482', 'G01R33/4824', 'G01R33/56509', 'G01R33/56545', 'G06N3/084', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/41', 'G06T2211/421', 'G06T2211/424', 'Y02A90/30']"
US11182896B2,Automated segmentation of organ chambers using deep learning methods from medical imaging,"A method of detecting whether or not a body chamber has an abnormal structure or function including: (a) providing a stack of images as input to a system comprising one or more hardware processors configured to obtain a stack of medical images comprising at least a representation of the body chamber inside the patient; to obtain a region of interest using a convolutional network trained to locate the body chamber, wherein the region of interest corresponds to the body chamber from each of the medical images; and to infer a shape of the body chamber using a stacked auto-encoder (AE) network trained to delineate the body chamber, wherein the AE network segments the body chamber; (b) operating the system to detect the body chamber in the images using deep convolutional networks trained to locate the body chamber, to infer a shape of the body chamber using a stacked auto-encoder trained to delineate the body chamber, and to incorporate the inferred shape into a deformable model for segmentation; and (c) detecting whether or not the body chamber has an abnormal structure, wherein an abnormal structure is indicated by a body chamber clinical indicia that is different from a corresponding known standard clinical indicia for the body chamber.","['G06V10/82', 'G06T3/0006', 'G06T3/02', 'G06T7/0012', 'G06T7/11', 'G06T7/149', 'G06T7/162', 'G06T7/38', 'G06V10/454', 'G06V10/764', 'G06V20/64', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20124', 'G06T2207/30048', 'G06V2201/031']"
US20210073959A1,Method and system for imaging and image processing,"A method of designing an element for the manipulation of waves, comprises: accessing a computer readable medium storing a machine learning procedure, having a plurality of learnable weight parameters. A first plurality of the weight parameters corresponds to the element, and a second plurality of the weight parameters correspond to an image processing. The method comprises accessing a computer readable medium storing training imaging data, and training the machine learning procedure on the training imaging data, so as to obtain values for at least the first plurality of the weight parameters.","['G06N3/084', 'G06F18/2413', 'G06N3/045', 'G06T19/006', 'G06T5/003', 'G06T5/30', 'G06T5/73', 'G06T7/50', 'G06V10/454', 'G06V10/764', 'G06N3/048', 'G06T2207/10052', 'G06T2207/20081', 'G06T2207/20084']"
US10264407B2,Intelligent multi-bean medium access control in ku-band for mission-oriented mobile mesh networks,"A MAC design for Ku-band mobile wireless mesh network with multi-beam smart antennas is disclosed. This MAC includes an overlay control that separates the collision domain. It also has lower layer CSMA-like scheme. The disclosed design includes an enhanced PCF and an enhanced DCF for two purposes: (1) exploiting multi-beam concurrent communication capability (2) supporting QoS and mission-based communications. An efficient time synchronization scheme is also disclosed to ensure all beams can concurrently send data to the star node. Finally, ARMA or HMM based prediction schemes are disclosed to predict future traffic profile in each beam. This helps the star node to better prepare the queue content and schedule information.","['H04W72/20', 'H04W4/046', 'G06F9/00', 'H04B7/022', 'H04B7/0617', 'H04B7/18504', 'H04L47/50', 'H04W28/0268', 'H04W4/40', 'H04B7/2643', 'H04K2203/36', 'H04K3/224', 'H04K3/25', 'H04W74/0808', 'H04W84/005', 'H04W84/06']"
WO2024152019A1,Systems and methods for building material based determinations,"Methods, systems, and computer program products for construction data linkage are provided. An example method includes receiving a first data element including one or more first data values and receiving a second data element including one or more second data values. The method further includes determining an association between the first data element and the second data element and generating a data linkage between the first data element and the second data element based on the association. The first data element and the second data element are associated with a building element and may be associated with one or more of a spatial representation associated or a structural progress flow associated with the structure, a first sensor device, a crush test result, a mix identifier, and/or a status identifier associated with a construction site resource.",['G06F21/6218']
US10980096B2,Learning a lighting preference based on a reaction type,"During operation, a computer provides, based at least in part on an initial lighting preference of an individual, instructions specifying initial lighting states of one or more lights in a lighting configuration in an environment, where an initial lighting state of a given light includes an intensity and a color of the given light. Then, the computer receives sensor data specifying a non-verbal physical response of the individual to initial lighting states. Moreover, the computer determines, based at least in part on the non-verbal physical response, a type of reaction of the individual to the initial lighting state. Next, the computer selectively modifies, based at least in part on a lighting behavior history of the individual and the determined type of reaction, the initial lighting preference of the individual to obtain an updated lighting preference.","['G06V10/764', 'H05B47/175', 'G06F18/2155', 'G06F30/12', 'G06F30/13', 'G06K9/00335', 'G06K9/6259', 'G06N3/08', 'G06V10/7753', 'G06V10/82', 'G06V40/107', 'G06V40/20', 'H04L12/282', 'H04Q9/00', 'H05B47/11', 'H05B47/115', 'H05B47/12', 'H05B47/125', 'H05B47/155', 'H05B47/16', 'H05B47/198', 'G06F3/167', 'G06F40/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G10L15/00', 'G10L25/51', 'H05B47/197', 'Y02B20/40']"
US12228566B2,System and method for protein corona sensor array for early detection of diseases,"The present disclosure provides a system comprising a communication interface and computer for assigning a label to the biomolecule fingerprint, wherein the label corresponds to a biological state. The present disclosure also provides a sensor arrays for detecting biomolecules and methods of use. In some embodiments, the sensor arrays are capable of determining a disease state in a subject.","['G01N33/5432', 'C01G49/02', 'G01N33/54326', 'G01N33/54346', 'G01N33/553', 'G01N33/57488', 'G01N33/586', 'G01N33/587', 'G01N33/6803', 'G01N33/6842', 'G01N33/6845', 'G01N33/6848', 'G06F18/24', 'G06N20/20', 'G06N3/04', 'G06N3/08', 'G06N5/01', 'G06N7/01', 'G16B20/00', 'G16B40/20', 'G16B40/30', 'B82Y30/00', 'B82Y35/00', 'C01P2004/64', 'G01N2570/00', 'G01N2800/2821', 'G06F2218/12', 'G06F2218/20']"
US9681250B2,"Statistical modelling, interpolation, measurement and anthropometry based prediction of head-related transfer functions",A system for generating and outputting three-dimensional audio data using head-related transfer functions (HRTFs) includes a processor configured to perform operations comprising: using a collection of previously measured HRTFs for audio signals corresponding to multiple directions for at least one subject; performing non-parametric Gaussian process hyper-parameter training on the collection of previously measured HRTFs to generate one or more predicted HRTFs that are different from the previously measured HRTFs; and generating and outputting three-dimensional audio data based on at least the one or more predicted HRTFs.,"['H04S7/303', 'H04S5/00', 'H04S7/304', 'H04S2400/15', 'H04S2420/01']"
US12182951B2,Augmented reality content generators including 3D data in a messaging system,"The subject technology generates a segmentation mask based on first image data. The subject technology applies the segmentation mask on first depth data to reduce a set of artifacts in a depth map based on the first depth data. The subject technology generates a packed depth map based at least in part on the depth map. The subject technology converts a single channel floating point texture to a raw depth map. The subject technology generates multiple channels. The subject technology applies, to the first image data and the first depth data, a first augmented reality content generator corresponding to a selected first selectable graphical item, the first image data and the first depth data being captured with a camera. The subject technology generates a message including the applied first augmented reality content generator to the first image data and the first depth data.","['G06T19/006', 'G06F3/011', 'G06F3/04815', 'G06F3/0482', 'G06F3/04845', 'G06F3/0488', 'G06T15/10', 'G06T5/77', 'G06T7/50', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028']"
US20200104726A1,"Machine learning data representations, architectures, and systems that intrinsically encode and represent benefit, harm, and emotion to optimize learning","A computer-implemented method, architecture and machine readable medium. The method includes receiving raw data and training data at an input of a neural network-based computing system (NNBCS) on a plurality of semantic concepts; and implementing a learning algorithm including: processing the raw data to generate processed output data; causing the processed output data to be stored in a data structure that corresponds to a continuous, differentiable vector space within a memory representing a Distributed Knowledge Graph (DKG) that reflects dimensions for the plurality of semantic concepts; comparing the processed output data with an output expected based on the training data to determine an error; and causing a weighted propagation of the error within the DKG as a function of one or more weights dependent on respective ones of one or more of the dimensions of the DKG corresponding to the error to generate an updated data structure of the DKG.","['G06N5/02', 'G06F16/9024', 'G06F18/2148', 'G06F18/22', 'G06F18/25', 'G06N20/00', 'G06N3/04', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N5/04', 'G06V10/7747', 'G06N20/10', 'G06N7/01']"
US11501415B2,Method and system for high-resolution image inpainting,"Methods and systems for high-resolution image inpainting are disclosed. An original high-resolution image to be inpainted is obtained, as well as an inpainting mask indicating an inside-mask area to be inpainted. The original high-resolution image is down-sampled to obtain a low-resolution image to be inpainted. Using a trained inpainting generator, a low-resolution inpainted image and a set of attention scores are generated from the low-resolution image. The attention scores represent the similarity between inside-mask regions and outside-mask regions. A high-frequency residual image is computed from the original high-resolution image. An aggregated high-frequency residual image is generated using the attention scores, including high-frequency residual information for the inside-mask area. A high-resolution inpainted image is outputted by combining the aggregated high-frequency residual image and a low-frequency inpainted image generated from the low-resolution inpainted image.","['G06T5/005', 'G06T5/77', 'G06F18/22', 'G06K9/6215', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06T3/4046', 'G06T3/4053', 'G06T5/60', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US9700578B2,Use of nitrite salts for the treatment of cardiovascular conditions,"It has been surprisingly discovered that administration of nitrite to subjects causes a reduction in blood pressure and an increase in blood flow to tissues. The effect is particularly beneficial, for example, to tissues in regions of low oxygen tension. This discovery provides useful treatments to regulate a subject's blood pressure and blood flow, for example, by the administration of nitrite salts. Provided herein are methods of administering a pharmaceutically-acceptable nitrite salt to a subject, for treating, preventing or ameliorating a condition selected from: (a) ischemia-reperfusion injury (e.g., hepatic or cardiac or brain ischemia-reperfusion injury); (b) pulmonary hypertension (e.g., neonatal pulmonary hypertension); or (c) cerebral artery vasospasm.","['A61K33/00', 'A61K45/06', 'A61P11/00', 'A61P13/02', 'A61P13/12', 'A61P17/02', 'A61P21/00', 'A61P25/00', 'A61P31/00', 'A61P31/12', 'A61P31/16', 'A61P33/00', 'A61P33/06', 'A61P37/00', 'A61P41/00', 'A61P43/00', 'A61P7/00', 'A61P7/02', 'A61P7/04', 'A61P7/06', 'A61P9/00', 'A61P9/04', 'A61P9/08', 'A61P9/10', 'A61P9/12', 'A61P9/14', 'A61K2300/00', 'Y02A50/30']"
CN208093761U,Slot antenna device and radar installations,"Slot antenna device and radar installations are provided.Slot antenna device based on from previous different principle.Slot antenna device hasï¼The 1st conductive component with the 1st conductive surface and the 2nd conductive surfaceï¼The 2nd conductive component with 3rd conductive surface opposed with the 2nd conductive surfaceï¼Waveguide elements on the 2nd conductive surfaceï¼Artificial magnetic conductor positioned at the both sides of the waveguide elements.1st conductive component has gap.The waveguide elements have the waveguide surface of the electric conductivity opposed with the 3rd conductive surface.3rd conductive surface, the waveguide surface and the artificial magnetic conductor prescribed waveguide in the gap of the 3rd conductive surface and the waveguide surface.The waveguide elements have the 1st ridge and the 2nd ridge.One end of 1st ridge is opposed with described one end of 2nd ridge.When from the direction vertical with the waveguide surface, the gap is located between described one end and described one end of the 2nd ridge of the 1st ridge.","['H01Q13/106', 'H01Q21/005', 'G01S13/38', 'G01S13/931', 'G01S7/03', 'H01Q1/38', 'H01Q13/206', 'H01Q13/22', 'H01Q23/00', 'G01S13/345', 'G01S13/347', 'G01S13/867', 'G01S13/87', 'G01S13/878', 'G01S19/51', 'G01S2013/9316', 'G01S2013/93271', 'G01S2013/93275', 'G01S2013/93276', 'H01Q13/10', 'H01Q21/064']"
US10970887B2,Tomographic image reconstruction via machine learning,"Tomographic/tomosynthetic image reconstruction systems and methods in the framework of machine learning, such as deep learning, are provided. A machine learning algorithm can be used to obtain an improved tomographic image from raw data, processed data, or a preliminarily reconstructed intermediate image for biomedical imaging or any other imaging purpose. In certain cases, a single, conventional, non-deep-learning algorithm can be used on raw imaging data to obtain an initial image, and then a deep learning algorithm can be used on the initial image to obtain a final reconstructed image. All machine learning methods and systems for tomographic image reconstruction are covered, except for use of a single shallow network (three layers or less) for image reconstruction.","['A61B5/00', 'G06T11/008', 'A61B5/055', 'A61B6/032', 'A61B6/037', 'A61B6/5205', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06T11/006', 'G06T2210/41', 'G06T2211/421', 'G06T2211/424']"
US10052026B1,Smart mirror,A mirror system includes a visual display disposed to convey information and images during an active period; and the visual display disposed to provide a reflected image during an inactive period; a multi-spectral 3D camera including a high definition video camera and an infrared camera; and a processor coupled to the visual display and the multi-spectral 3D camera.,"['A61B5/0075', 'A61B5/0022', 'A61B5/0077', 'A61B5/015', 'A61B5/02055', 'A61B5/165', 'A61B5/441', 'A61B5/4815', 'A61B5/7267', 'A61B5/742', 'C12Q1/6883', 'C12Q1/6886', 'G01N30/724', 'G01N33/6848', 'G06F16/90328', 'G06F17/3087', 'G06F17/30973', 'G06F17/30979', 'G06F19/3418', 'G06F19/3431', 'G06K9/00369', 'G06T11/60', 'G06T15/20', 'G06T19/006', 'G06T19/20', 'G06T7/0012', 'G06V20/20', 'G06V40/103', 'G06V40/161', 'G16H20/70', 'G16H30/40', 'G16H40/63', 'G16H50/30', 'H04N13/025', 'H04N13/25', 'H04N5/33', 'A61B5/021', 'A61B5/02444', 'A61B5/145', 'A61B5/14532', 'G01N2570/00', 'G01N33/48', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/30088', 'G06T2207/30201', 'G06T2210/16', 'G06T2219/2021', 'H01J49/26', 'H04N13/204', 'H04N13/275', 'Y02A90/10']"
CN110957009B,Single-cell transcriptome deletion value filling method based on deep hybrid network,"The invention provides a single-cell transcriptome deletion value filling method based on a deep hybrid network, which comprises the following steps: sequencing single cells and preprocessing to obtain an expression matrix and carrying out standardization treatment; constructing a mixed model based on deep learning, and inputting the standardized expression matrix into the mixed model for cyclic calculation to obtain a plurality of prediction expression matrices; and calculating the weight of each cycle, carrying out weighted average on a plurality of prediction expression matrixes according to the corresponding weights, and obtaining a result which is the filling output of the mixed model to finish filling the missing value. The filling method provided by the invention adapts to the expression distribution of single cells by means of the fitting capability of the deep neural network to complex functions, and ensures the universality of the filling method to various single cell transcriptome data; meanwhile, the expansibility of deep learning on the data set with the ultra-large cell number is reserved, the filling of the single-cell transcriptome deletion value is completed, and the reliability of single-cell data interpretation is remarkably improved.","['G16B40/00', 'Y02A90/10']"
US10393842B1,Highly-scalable image reconstruction using deep convolutional neural networks with bandpass filtering,"A method for magnetic resonance imaging (MRI) scans a field of view and acquires sub-sampled multi-channel k-space data U. An imaging model A is estimated. Sub-sampled multi-channel k-space data U is divided into sub-sampled k-space patches, each of which is processed using a deep convolutional neural network (ConvNet) to produce corresponding fully-sampled k-space patches, which are assembled to form fully-sampled k-space data V, which is transformed to image space using the imaging model adjoint Aadj to produce an image domain MRI image. The processing of each k-space patch ui preferably includes applying the k-space patch ui as input to the ConvNet to infer an image space bandpass-filtered image yi, where the ConvNet comprises repeated de-noising blocks and data-consistency blocks; and estimating the fully-sampled k-space patch vi from the image space bandpass-filtered image yi using the imaging model A and a mask matrix.","['G01R33/5608', 'G01R33/5611', 'G01R33/56509', 'G01R33/56545', 'G01R33/4824', 'G06T2207/10088']"
US12112238B2,Scalable neutral atom based quantum computing,"The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation.","['G06N10/40', 'G06N20/00', 'G06N20/20', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US12141995B2,Systems and methods for simulating dynamic objects based on real world data,Systems and methods for generating simulation data based on real-world dynamic objects are provided. A method includes obtaining two- and three-dimensional data descriptive of a dynamic object in the real world. The two- and three-dimensional information can be provided as an input to a machine-learned model to receive object model parameters descriptive of a pose and shape modification with respect to a three-dimensional template object model. The parameters can represent a three-dimensional dynamic object model indicative of an object pose and an object shape for the dynamic object. The method can be repeated on sequential two- and three-dimensional information to generate a sequence of object model parameters over time. Portions of a sequence of parameters can be stored as simulation data descriptive of a simulated trajectory of a unique dynamic object. The parameters can be evaluated by an objective function to refine the parameters and train the machine-learned model.,"['G06T7/70', 'G06N20/00', 'G06T17/20', 'G06T7/246', 'G06T7/73', 'G06V10/774', 'G06V10/82', 'G06V20/58', 'G06V20/653', 'G06V40/23', 'G06N3/02', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30241', 'G06T2207/30252']"
US11235512B2,Device for additively manufacturing a component,"A device may be provided for additively manufacturing a component, comprising at least one component holder, which is designed to hold the component to be manufactured, and comprising at least one application device, which is designed to heat a thermoplastic material and to deposit it in a predeterminable amount, wherein the device also includes at least one radiation source, which is designed to produce electromagnetic radiation, by means of which at least one partial area of the component can be heated, and the device also includes at least one supply apparatus, which is designed to introduce a fiber reinforcement into the component, which fiber reinforcement includes or consists of an endless fiber. A method for additively manufacturing a component may also be provided.","['B29C64/118', 'B29C64/106', 'B29C64/153', 'B29C64/295', 'B33Y10/00', 'B33Y30/00', 'B33Y70/00', 'B33Y70/10', 'B33Y80/00', 'B29C2035/0822', 'B29C2035/0838', 'B29C35/0805']"
US20230045690A1,System and method for molecular property prediction using edge conditioned identity mapping convolution neural network,"This disclosure relates generally to system and method for molecular property prediction. Typically, message-pooling mechanism employed in molecular property prediction using conventional message passing neural networks (MPNN) causes over smoothing of the node embeddings of the molecular graph. The disclosed system utilizes edge conditioned identity mapping convolution neural network for the message passing phase. In message passing phase, the system computes an incoming aggregated message vector for each node of the plurality of nodes of the molecular graph based on encoded message received from neighboring nodes such that encoded message vector is generated by fusing a node information and an connecting edge information of the set of neighboring nodes of the node. The incoming aggregated message vector is utilized for computing updated hidden state vector of each node. A discriminative graph-level vector representation is computed by pooling the updated hidden state vectors from all the nodes of the molecular graph.","['G06N3/04', 'G16C20/30', 'G06F18/2155', 'G06F9/5044', 'G06F9/546', 'G06K9/6259', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G16C20/70']"
US11731524B2,Mobile direct current fast charger customer-vehicle-station matching system,"A system for matching a plurality of electrically powered vehicles to a plurality of available mobile chargers includes a computerized server device programmed to monitor optimization inputs related to the plurality of available mobile chargers, monitor optimization inputs related to the plurality of electrically powered vehicles operated by a plurality of customers, determine a lowest-cost-based ranked listing of matched charger and vehicle pairings for each of the plurality of customers based upon the optimization inputs related to the plurality of available chargers and the optimization inputs related to the plurality of the electrically powered vehicles, present the ranked listing of matched charger and vehicle pairings to each of the customers, monitor selection by each of the plurality of customers of a desired charger for the customer from the ranked listing, and direct each of the plurality of customers to the desired charger for the customer.","['B60L53/305', 'B60L53/11', 'B60L53/16', 'B60L53/54', 'B60L53/57', 'B60L53/63', 'B60L53/68', 'G01R31/382', 'H01M10/44', 'H01M16/006', 'H01M2220/20', 'Y02E60/00', 'Y02E60/10', 'Y02E60/50', 'Y02T10/70', 'Y02T10/7072', 'Y02T90/12', 'Y02T90/14', 'Y02T90/16', 'Y02T90/167', 'Y04S10/126', 'Y04S30/12']"
CN111489287B,"Image conversion method, device, computer equipment and storage medium","The application relates to an image conversion method, an image conversion device, a computer device and a storage medium. Comprising the following steps: acquiring a first image containing face information of an object to be converted; inputting the first image into a trained image conversion model; the image conversion model is used for extracting facial features of an object to be converted in the first image and generating a second image of the object to be converted based on the facial features; the second image and the first image have different image styles; obtaining a target image corresponding to the first image based on the second image output by the image conversion model; wherein the image conversion model includes generating an countermeasure network, the generating the countermeasure network including a generator and a discriminator; the generator is used for extracting facial features of the object to be converted and generating a second image based on the facial features; the discriminator is configured to progressively transition from generating the coarse second image to generating the quality second image during training of the image conversion model. By adopting the method, the accuracy of image conversion can be improved.",['G06T3/04']
US11892746B1,Super system on chip,"A Super System on Chip (SSoC) is disclosed. The Super System on Chip (SSoC)'s input/outputs are coupled with a Mach-Zehnder interferometer (MZI), wherein the Mach-Zehnder interferometer (MZI) can generally include a phase transition material or a phase change material. The Mach-Zehnder interferometer (MZI) is coupled with a first optical waveguide in two-dimensions (2-D) or three-dimensions (3-D). The first optical waveguide is coupled with (i) a semiconductor optical amplifier (SOA) or (ii) a second optical waveguide that can include a nonlinear optical material in two-dimensions (2-D) or three-dimensions (3-D). Furthermore, the semiconductor optical amplifier (SOA) may be replaced by an optical resonator.","['G02F3/00', 'G01S17/34', 'G01S17/58', 'G01S17/89', 'G01S17/931', 'G01S7/4917', 'G02F1/212', 'G02F1/225', 'G06F15/7817']"
US20190189259A1,Systems and methods for generating an optimized patient treatment experience,"Implementations described and claimed herein provide systems and methods for generating an optimized treatment experience for a patient. In one implementation, patient experience data is captured using at least one patient experience device. The patient experience data corresponds to a patient experience factor for the patient. A current level of the patient experience factor is determined using a patient experience processing system. The current level of the patient experience factor is determined based on the patient experience data. A customized therapy for the patient is generated based on the current level of the patient experience factor. The customized therapy is an alternative treatment to a drug therapy administration. An administration of a patient treatment experience is generated based on the customized therapy. The patient treatment experience is generated using the at least one patient experience device and includes one or more of patient sense stimulation and patient cognitive stimulation.","['G16H20/10', 'G16H10/20', 'G16H10/60', 'G16H20/70', 'G16H70/40', 'G16H50/20']"
US11237169B2,Ratio based biomarkers and methods of use thereof,"Compositions, methods and kits are described for identifying biomolecules (e.g., proteins and nucleic acids) expressed in a biological sample that are associated with the presence, development, or progression of a disease (such as cancer), or more generally determination of the etiology or risk factors associated with a disease. Sample types analyzed by the disclosed methods include but are not limited to archival tissue blocks that have been preserved in a fixative, tissue biopsy samples, tissue microarrays, and so forth. The methods disclosed herein correlate expression profiles of biomolecules with various disease types, and allow for the determination of relative survival rates; in some embodiments, the methods permit determination of survival rates for a subject with cancer. In other embodiments, the disclosure relates to methods for evaluating therapeutic regimes for the treatment, such as treatment of cancer.","['G01N33/57484', 'G01N33/582', 'G16B25/10', 'G16B99/00', 'G16H50/20', 'G16Z99/00', 'G01N2800/60']"
US20220012890A1,Model-Based Deep Learning for Globally Optimal Surface Segmentation,An automated method for segmentation includes steps of receiving at a computing device an input image representing at least one surface and performing by the computing device image segmentation on the input image based on a graph surface segmentation model with deep learning. The deep learning may be used to parameterize the graph surface segmentation model.,"['G06T7/11', 'G06T7/12', 'G06T7/0012', 'G06T7/162', 'G06T2207/10072', 'G06T2207/10101', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30101']"
US9031317B2,Method and apparatus for improved training of object detecting system,"An adequate solution for computer vision applications is arrived at more efficiently and, with more automation, enables users with limited or no special image processing and pattern recognition knowledge to create reliable vision systems for their applications. Computer rendering of CAD models is used to automate the dataset acquisition process and labeling process. In order to speed up the training data preparation while maintaining the data quality, a number of processed samples are generated from one or a few seed images.","['G06T15/20', 'G06K9/6219', 'G06F18/214', 'G06F18/231', 'G06F18/285', 'G06F18/41', 'G06K9/6227', 'G06K9/6254', 'G06K9/6256', 'G06T15/50', 'G06V10/7625', 'G06V10/774', 'G06V10/7788']"
US9869007B2,"Hydrogen storage alloy, hydrogen storage alloy electrode, secondary battery, and method for producing hydrogen storage alloy",Provided is a hydrogen storage alloy which is characterized in that two or more crystal phases having different crystal structures are layered in a c-axis direction of the crystal structures. The hydrogen storage alloy is further characterized in that a difference between a maximum value and a minimum value of a lattice constant a in the crystal structures of the laminated two or more crystal phases is 0.03 â« or less.,"['C22C19/03', 'C22C1/023', 'C22C1/0441', 'C22C19/007', 'C22F1/002', 'C22F1/10', 'H01M4/134', 'H01M4/1395', 'H01M4/366', 'H01M4/383', 'H01M10/345', 'H01M2004/027', 'Y02E60/10', 'Y10T428/12493']"
US10504020B2,System and method for applying a deep learning neural network to data obtained from one or more sensors,"An application provisioning system and method. A server provides an application provisioning service. A user of a client provides a schema defining an application. The application interacts with peripherals coupled to the client and receives input from sensors coupled to the peripherals. The sensor data is provided to the server for processing, including by neural networks. The application includes a workflow defining a finite state machine that traverses states at least partially based on the response to sensor data. The server may provide dynamic reallocation of compute resources to resolve demand for classifier training job requests; use of jurisdictional certificates to define data usage and sharing; and data fusion. Applications include manufacturing verification, medical diagnosis and treatment, genomics and viral detection.","['G06F8/30', 'G06F18/214', 'G06F18/285', 'G06F8/35', 'G06F8/36', 'G06F9/5027', 'G06K9/00', 'G06K9/00536', 'G06K9/6227', 'G06K9/6256', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'H04L41/5041', 'H04L67/12', 'H04L67/34', 'H04L67/42', 'G06F2209/5017', 'G06F2209/503', 'G06F2209/509', 'G06F2209/541', 'G06F2209/549', 'G06F2218/12']"
CN113808248B,Three-dimensional fluid reverse modeling method based on physical perception,"The embodiment of the disclosure discloses a three-dimensional fluid reverse modeling method based on physical perception. One embodiment of the method comprises: coding the surface height field sequence of the fluid through a surface velocity field convolution neural network to obtain a surface velocity field at the time t; inputting the surface velocity field into a pre-trained three-dimensional convolution neural network to obtain a three-dimensional flow field, wherein the three-dimensional flow field comprises a velocity field and a pressure field; inputting the surface velocity field into a pre-trained regression network to obtain fluid parameters; and inputting the three-dimensional flow field and the fluid parameters into a fluid simulator based on physics to obtain a time sequence of the three-dimensional flow field. This embodiment satisfies the need for true fluid reproduction and physical-based fluid body editing.","['G06F30/27', 'G06T17/00', 'G06F30/28', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/094', 'G06F2111/10', 'G06T2210/24', 'Y02T90/00']"
US11705590B1,Systems and methods for predicting remaining useful life in batteries and assets,"In one aspect, computer-implemented method may include receiving, from a cloud-based computing system, one or more machine learning model parameters that are configured to enable predicting a remaining useful life of each cell of a battery pack of a vehicle. The method may include loading, into memory of a processing device at the vehicle, the one or more machine learning model parameters, receiving data comprising one or more measurements and one or more user battery usage profiles, and based on the data, executing a trained machine learning model with the one or more parameters to input the data and to output the remaining useful life of each cell of the battery pack.","['H01M10/482', 'B60L58/12', 'B60L3/12', 'B60L58/16', 'G01R31/367', 'G01R31/3842', 'G01R31/392', 'G01R31/396', 'G07C5/04', 'H01M10/486', 'B60L2240/545', 'B60L2240/547', 'B60L2240/549', 'B60L2240/70', 'B60L2260/44', 'B60L2260/46', 'H01M2220/20', 'Y02E60/10']"
US12334043B2,Time-varying and nonlinear audio processing using deep neural networks,"A computer-implemented method of processing audio data, the method comprising receiving input audio data (x) comprising a time-series of amplitude values; transforming the input audio data (x) into an input frequency band decomposition (X1) of the input audio data (x); transforming the input frequency band decomposition (X1) into a first latent representation (Z); processing the first latent representation (Z) by a first deep neural network to obtain a second latent representation (Z{circumflex over (â)}, Z1{circumflex over (â)}); transforming the second latent representation (Z{circumflex over (â)}, Z1{circumflex over (â)}) to obtain a discrete approximation (X3{circumflex over (â)}); element-wise multiplying the discrete approximation (X3{circumflex over (â)}) and a residual feature map (R, X5{circumflex over (â)}) to obtain a modified feature map, wherein the residual feature map (R, X5{circumflex over (â)}) is derived from the input frequency band decomposition (X1); processing a pre-shaped frequency band decomposition by a waveshaping unit to obtain a waveshaped frequency band decomposition (X1{circumflex over (â)}, X1.2{circumflex over (â)}), wherein the pre-shaped frequency band decomposition is derived from the input frequency band decomposition (X1), wherein the waveshaping unit comprises a second deep neural network; summing the waveshaped frequency band decomposition (X1{circumflex over (â)}, X1.2{circumflex over (â)}) and a modified frequency band decomposition (X2{circumflex over (â)}, X1.1{circumflex over (â)}) to obtain a summation output (X0{circumflex over (â)}), wherein the modified frequency band decomposition (X2{circumflex over (â)}, X1.1{circumflex over (â)}) is derived from the modified feature map; and transforming the summation output (X0{circumflex over (â)}) to obtain target audio data (y{circumflex over (â)}).","['G06N3/084', 'G06N3/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G10H1/0091', 'G10H1/12', 'G10H1/16', 'G10H3/187', 'G10L19/02', 'G10L21/038', 'G10L25/30', 'G06N3/048', 'G10H2210/215', 'G10H2210/281', 'G10H2210/311', 'G10H2250/025', 'G10H2250/311']"
US12034801B1,Cloud-based fleet and asset management for edge computing of machine learning and artificial intelligence workloads,"A process can include receiving monitoring information associated with a machine learning (ML) or artificial intelligence (AI) workload implemented by an edge compute unit of a plurality of edge compute units. Status information corresponding to a plurality of connected edge assets can be received, the plurality of edge compute units and connected edge assets included in a fleet of edge devices. A remote fleet management graphical user interface (GUI) can display a portion of the monitoring or status information for a subset of the fleet of edge devices, based on a user selection input, and can receive a user configuration input indicative of an updated configuration for at least one workload corresponding to a pre-trained ML or AI model deployed on the at least one edge compute unit. A cloud computing environment can transmit control information corresponding to the updated configuration to the at least one edge compute unit.","['H04B7/18513', 'G06F8/65', 'G06F9/5072', 'H04L41/0816', 'H04L41/16', 'H04L41/22', 'H04L43/0817', 'H04L67/1008', 'H04L67/101', 'G06F2209/508', 'H04L41/40']"
US11389171B2,Integrated system for the infixion and retrieval of implants,"Described are coordinated apparatus and methods for drug targeting, clearing the lumen, placing implants within the wall of, and stenting, as necessary, any tubular anatomical structure with single luminal entry. Miniature balls, or miniballs, are introduced into the wall aeroballistically from within the lumen, or small arcuate bands called stays inserted through the outer tunic by means of a hand tool. When miniballs must be placed too closely together to be controlled by hand, a positional control system assists in discharge. Implantation within or proximal to diseased tissue targeting, and thus concentrating the medication in that tissue, miniballs and stays can be used to deliver and controllably release multiple drugs, a radionuclide, or an open or closed loop smart-pill, for example. A glossary of terms follows the specification. Balance of abstract appended to the section entitled Summary of the Invention.","['A61B17/12118', 'A61B17/3468', 'A61B17/00491', 'A61B17/0057', 'A61B17/12181', 'A61B18/18', 'A61F2/82', 'A61B2017/00411', 'A61B2017/0065', 'A61B2017/00876', 'A61B2017/1205']"
US20200085382A1,"Automated lesion detection, segmentation, and longitudinal identification","Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are commonly used to assess patients with known or suspected pathologies of the lungs and liver. In particular, identification and quantification of possibly malignant regions identified in these high-resolution images is essential for accurate and timely diagnosis. However, careful quantitative assessment of lung and liver lesions is tedious and time consuming. This disclosure describes an automated end-to-end pipeline for accurate lesion detection and segmentation.","['A61B5/055', 'A61B5/7264', 'A61B5/7267', 'A61B6/032', 'A61B6/5217', 'A61B6/563', 'G06F18/24143', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T7/0016', 'G06T7/30', 'G06V10/764', 'G06V10/82', 'G16H50/30', 'G06N3/082', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30056', 'G06T2207/30064', 'G06T2207/30096', 'G06V2201/031']"
US20230395235A1,System and Method for Delivering Personalized Cognitive Intervention,"A computational personalized cognitive therapeutic system for treating patients with Mild Cognitive Impairment, Alzheimer's Disease, dementia and related conditions is described. The system includes a patient clinical database, a data aggregation layer and data pre-processor module, a digital cognitive therapy delivery module, a cognitive analytics engine, and a personalised cognitive platform configured to personalize a personalised cognitive digital therapy model. The personalised cognitive digital therapy model defines specific digital treatments to be delivered to the patient using the digital cognitive therapy delivery module each with a different mechanism of action. A range of digital cognitive biomarkers are collected along with behavioural and physiological biomarkers from wearable and medical devices which are processed by the cognitive analytics engine and uses AI/ML methods which are configured to estimate metrics and generate alerts. The metrics are used to assess treatment progress and then personalize the personalised cognitive digital therapy model for the patient including adjustment of digital therapies and medication. Alerts may be generated if adverse side effects are observed. This process is iteratively repeated to provide improved treatment over time.","['G16H20/70', 'A61B5/0077', 'A61B5/01', 'A61B5/02055', 'A61B5/02405', 'A61B5/02416', 'A61B5/0261', 'A61B5/0533', 'A61B5/11', 'A61B5/162', 'A61B5/165', 'A61B5/4088', 'A61B5/4803', 'A61B5/7264', 'A61B5/7275', 'G16H50/20', 'A61B2503/08', 'A61B2562/0219', 'G06N20/10', 'G06N3/08', 'G06N7/01', 'G16H50/70']"
CN114126491B,Assessment of coronary artery calcification in angiographic images,Systems and methods are provided for training an artificial intelligence model for detecting calcified portions of a blood vessel in an input medical image. One or more first medical images of the vessel in a first modality and one or more second medical images of the vessel in a second modality are received. Calcified portions of the blood vessel are detected in the one or more first medical images. The artificial intelligence model is trained for detecting calcified parts of the blood vessel in the input medical image in the second modality based on the one or more second medical images and calcified parts of the blood vessel detected in the one or more first medical images.,"['A61B6/504', 'A61B6/032', 'A61B6/481', 'A61B6/487', 'A61B6/5223', 'A61B6/5235', 'G06T7/0012', 'G16H50/20', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/10121', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30101']"
US20210265018A1,Knowledge Distillation and Gradient Pruning-Based Compression of Artificial Intelligence-Based Base Caller,"The technology disclosed compresses a larger, teacher base caller into a smaller, student base caller. The student base caller has fewer processing modules and parameters than the teacher base caller. The teacher base caller is trained using hard labels (e.g., one-hot encodings). The trained teacher base caller is used to generate soft labels as output probabilities during the inference phase. The soft labels are used to train the student base caller.","['G06F18/214', 'G06N3/082', 'G06K9/6256', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06V10/454', 'G06V10/82', 'G16B30/00', 'G16B40/10', 'G16B40/20']"
US12412209B2,Image processing arrangements,"Aspects of the detailed technologies concern training and use of neural networks for fine-grained classification of large numbers of items, e.g., as may be encountered in a supermarket. Mitigating false positive errors is an exemplary area of emphasis. Novel network topologies are also detailedâsome employing recognition technologies in addition to neural networks. A great number of other features and arrangements are also detailed.","['G06Q30/0641', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06N3/045', 'G06V10/17', 'G06V10/462', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G06F16/906', 'G06N3/04', 'G06N3/08', 'G06V2201/09']"
US11651531B2,Systems and methods for magnetic resonance imaging,The present disclosure relates to systems and methods for magnetic resonance imaging. The method may include obtaining primary imaging data associated with a region of interest (ROI) of a subject and obtaining secondary data associated with the ROI. The method may also include determining secondary imaging data based on the secondary data by using a trained model. The method may further include reconstructing a magnetic resonance image based on the primary imaging data and the secondary imaging data.,"['G06T11/003', 'A61B5/055', 'G01R33/5673', 'G01R33/4818', 'G01R33/483', 'G01R33/5608', 'G01R33/561', 'G01R33/5618', 'G01R33/56308', 'G01R33/5676', 'G01R33/56509', 'G06T2210/41']"
EP4170427A1,Slit lamp microscope,"A slit lamp microscope 1 according to an exemplary embodiment includes a scanning unit (lighting system 2, imaging system 3, and movement mechanism 6), an image group evaluation unit 81 (data processing unit 8), and a control unit 7. The scanning unit scans, with slit light, an anterior eye part of an eye E being inspected, and collects an image group. The image group evaluation unit 81 evaluates the quality of the image group collected by the scanning unit. The control unit 7 selectively executes two or more prescribed controls in accordance with the quality evaluation result acquired by a first evaluation unit. For example, the control unit 7 performs a control for applying a new scan to the anterior eye part when the quality is evaluated to be unsatisfactory, and performs a control for transmitting the image group to an external device when the quality is evaluated to be satisfactory.","['A61B3/135', 'A61B3/0016', 'A61B3/0025', 'A61B3/10', 'A61B3/117', 'G02B21/082', 'G02B21/367']"
CN111737434B,Generate automated assistant responses and/or actions directly from conversation history and resources,"The present disclosure relates to generating automated assistant responses and/or actions directly from dialog histories and resources. Training and/or utilizing a single neural network model generates a corresponding automated assistant natural language response and/or a corresponding automated assistant action at each of a plurality of assistant turns of a dialog session between a user and the automated assistant. For example, at a given turn of a dialog session, a corresponding natural language response and a corresponding action may be generated jointly and directly based on output generated using a single neural network model. The corresponding response and/or corresponding action may be generated based on processing the dialog history and the plurality of discrete resources using the neural network model. For example, a neural network model may be used to generate responses and/or actions on a token-by-token basis.","['G06N5/041', 'G10L15/1822', 'G06N3/006', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N5/04', 'G10L15/063', 'G10L15/16', 'G10L15/22', 'G10L15/26', 'G10L2015/0638', 'G10L2015/223', 'G10L2015/225']"
CN106250385B,System and method for automated information abstraction processing of documents,"Embodiments of the present invention generally relate to systems and methods for automated information abstraction processing of documents. In particular, a computer-implemented method, processing pipeline, and system create a hierarchical semantic graph of documents and extracted information. The method includes apportioning the document to the main sections by accessing the document using a data analyzer and a machine learning module, identifying a hierarchical structure of the document, and dividing the document into the main sections, classifying the main sections and mapping the main sections to key elements in one of the multiple levels, searching one of the main sections and identifying a sub-section from one of the main sections to accomplish a maximum confidence score indicating that the sub-section is associated with a key element, extracting information from the identified sub-section by using a sequence modeler and linguistic characteristics provided by the data analyzer, generating a hierarchical semantic graph of the document by using the extracted information, and displaying a drop-down selection of the key element in a user interface.","['G06F40/151', 'G06F16/345', 'G06F16/35', 'G06F16/36', 'G06F40/258', 'G06V30/413', 'G06V30/414', 'G06F18/2113', 'G06F18/285', 'G06V30/142', 'G06V30/2504', 'G06V30/416']"
US12161468B2,Hydrogen system,"A water powered system includes a sealed and insulated chamber with an aluminum alloy source; a control unit to selectively expose a predetermined amount of an aluminum alloy to a liquid to generate hydrogen gas; a fuel cell stack to receive hydrogen gas from the hydrogen gas tank and oxygen from the atmosphere, the fuel cell stack generating electricity; and an energy storage device to receive electricity.","['A61B5/201', 'A61B5/0077', 'A61B5/01', 'A61B5/0205', 'A61B5/02055', 'A61B5/1032', 'A61B5/1118', 'A61B5/14532', 'A61B5/14546', 'A61B5/207', 'A61B5/6808', 'A61F13/8405', 'A61F5/4404', 'A61F5/453', 'A61F5/4556', 'H01M8/065', 'A61B5/021', 'A61B5/024', 'A61B5/0816', 'A61F2013/8479', 'A61F2013/8494', 'Y02E60/50']"
US20230407404A1,Methods and compositions for analyzing immune infiltration in cancer stroma to predict clinical outcome,"Provided herein are methods for analyzing immune cell infiltration in a cancer stromal region of a biological sample obtained from a subject using machine learning modules. For example, the methods may include (a) identifying a cancerous region or an analyte associated with the cancerous region in the biological sample; (b) identifying a stromal region or an analyte associated with the stromal region in the biological sample; (c) identifying one or more immune cells or an analyte associated with an immune cell in one or more locations in the biological sample; and (d) using (i) the identified cancerous and stromal regions or associated analytes thereof in the biological sample and (ii) the identified one or more immune cells or associated analytes thereof to analyze immune cell infiltration in the cancer stromal region of the biological sample obtained from the subject.","['C12Q1/6886', 'G16H50/20', 'C12Q2600/118', 'C12Q2600/158', 'Y02A90/10']"
US10964075B2,Gating with anatomically varying durations,"A method for reconstructing a radioactive emission image of an overall volume having first and second volumetric regions, each volumetric region having respectively independent dynamic characteristics. The method comprises the following steps: a) obtaining radioactive emissions from the overall volume, including the volumetric regions, b) reconstructing an initial radioactive emission image of the volumetric region according to the radioactive emissions, c) segmenting the initial radioactive emission image to delineate the first and second volumetric regions, and d) separately reconstructing the first and the second volumetric regions according to the respectively independent dynamic characteristics.","['G01T1/161', 'G06T11/006', 'A61B5/055', 'A61B5/7289', 'A61B6/032', 'A61B6/037', 'A61B6/503', 'A61B6/5288', 'A61B8/13', 'A61B8/5284', 'G01T1/1644', 'G01T1/243', 'G01T1/247', 'G01T1/249', 'G06T7/0012', 'G06T7/62', 'G06T2207/10088', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/10136', 'G06T2207/30048']"
US11568423B2,"Multi-dimensional product information analysis, management, and application systems and methods","Disclosed here are methods of analyzing product-related datasets using a computer system including a product data collection; receiving a product-related data submission; identifying system-identified terms in the submission; generating a query dataset comprising search elements, such as lexical vector(s), semantic vector(s), or both; querying the product data collection and identifying datasets that sufficiently match aspect(s) of the query dataset; comparing the content of the submission and matching datasets to provide an output such as a determination of an error or omission in the submission, identifying a relationship between the submission product and a product associated with an identified dataset; or assessing one or more product status characteristics; and optionally performing additional applications, such as generating a regulatory authority submission based on the determination that the submission product is subject a regulatory requirements based on the comparison of the submission with the identified datasets.","['G06Q50/26', 'G06Q30/018', 'G06F16/36', 'G06F40/279', 'G06F40/284', 'G06F40/30', 'G06Q10/0635', 'G06Q10/06395', 'G06Q10/0875', 'G06Q50/18']"
US9993166B1,Monitoring device using radar and measuring motion with a non-contact device,"A user monitoring device system has a user monitoring device that includes one or more microphones, a transmitter and sensors to determine air quality, sound level quality, light quality, ambient temperature and humidity near the user. The transmitter serves as a communication system. A radar apparatus or system is configured to detect a user's movement information. The radar apparatus or system and the monitoring system configured assist to determine at least one of: user sleep information and sleep behavior information, or user respiration information. A cloud based system is in communication with the monitoring device and the radar apparatus or system.","['A61B5/0205', 'G16H40/67', 'A61B5/0022', 'A61B5/4806', 'A61B7/026', 'A61B2560/0242', 'A61B2560/0252', 'A61B2560/0257', 'A61B2562/0257', 'A61B5/024', 'A61B5/0507', 'A61B5/08', 'A61B5/1032', 'A61B5/1102', 'A61B5/1118', 'A61B5/113', 'A61B7/04']"
CN106063090B,Transmission device and robotic arm assemblies,"[purpose] is in order to accurately detect rotation angle and also for more safely driving.[solution] the present invention provides a kind of transmission device (300), the transmission device (300) includes: reduction gearing (320), the reduction gearing (320) reduces the rotation speed for being bonded to the input shaft of rotary shaft of motor (360) by certain reduction ratio, and reduced rotation speed is sent to output shaft (350)ï¼First absolute angle encoder (330), the first absolute angle encoder (330) detect the rotation angle of input shaftï¼With the second absolute angle encoder (340), which detects the rotation angle of output shaft.","['H02K7/116', 'B25J13/088', 'B25J9/06', 'B25J9/126', 'B25J9/1641', 'G01D5/04', 'G01D5/145', 'G01D5/2451', 'H02K11/215', 'H02P6/16', 'G05B2219/39191']"
US10058290B1,Monitoring device with voice interaction,"A user monitoring device system has a user monitoring device that includes one or more microphones, a transmitter and sensors to determine air quality, sound level/quality, light quality and ambient temperature near the user. The transmitter serves as a communication system. A motion detection apparatus detects a user's movement information. The motion detection apparatus and the monitoring system assist to determine at least one of: user sleep information and sleep behavior information, or user respiration information. A cloud based system is in communication with the monitoring device and the motion detection apparatus. The cloud based system includes a user database. A speech recognition system is coupled to the cloud based system.","['A61B5/749', 'A61B5/0022', 'G16H40/67', 'A61B2560/0252', 'A61B2562/0204', 'A61B5/01', 'A61B5/0205', 'A61B5/021', 'A61B5/024', 'A61B5/0816', 'A61B5/113', 'A61B5/14532', 'A61B5/318', 'A61B5/4815', 'A61B5/486', 'A61B5/746']"
US10004451B1,User monitoring system,"A user monitoring device system includes a user monitoring device with one or more microphones, a transmitter and sensors to determine light, sound temperature and humidity near the user, the transmitter serving as a communication system. A motion detection apparatus detects a user's movement information. The motion detection apparatus and the monitoring system assist to determine at least one of: user sleep information and sleep behavior information, or user respiration information. A cloud based system is in communication with the monitoring device and the motion detection apparatus. The cloud based system includes a user database.","['A61B5/4806', 'A61B5/0022', 'A61B5/113', 'A61B5/749', 'A61M21/02', 'G16H40/67', 'A61B2560/0252', 'A61B2560/0257', 'A61B2562/0204', 'A61B2562/0257', 'A61M2021/0005', 'A61M2021/0027', 'A61M2205/505', 'A61M2230/06', 'A61M2230/50', 'A61M2230/62', 'A61M2230/63']"
US10227391B2,System and method for controlling G-protein coupled receptor pathways,A light-sensitive G-protein coupled receptor includes a light sensitive extracellular cone opsin or melanopsin domain and a hetorologous intracellular domain capable of modulating an intracellular signaling pathway.,"['C07K14/705', 'C07K14/70571', 'C12N5/0618', 'C07K2319/00', 'C12N2510/00']"
US11540754B2,Using near and far detectors to measure oxygen saturation,"A device includes source and detector sensors. In a specific implementation, the device has two near detectors, two far detectors, and two sources. The two near detectors are arranged closer to the two sources than the two far detectors. A light-diffusing layer covers the two near detectors. The device may be part of a medical device that is used to monitor or measure oxygen saturation levels in a tissue. In a specific implementation, light is transmitted into the tissue and received by the detectors. An attenuation coefficient is first calculated for a shallow layer of tissue. The attenuation coefficient is then used to calculate an attenuation coefficient for a deep layer of tissue.","['A61B5/14552', 'A61B5/14553', 'A61B2562/0238', 'A61B2562/0242', 'A61B2562/043']"
CN112045556B,Method and apparatus for forming advanced polishing pads using additive manufacturing processes,"The present disclosure relates to methods and apparatus for forming advanced polishing pads using additive manufacturing processes. In accordance with one or more embodiments of the present disclosure, it has been discovered that polishing pads having improved characteristics can be produced by additive manufacturing processes, such as three-dimensional (3D) printing processes. Accordingly, embodiments of the present disclosure may provide advanced polishing pads having discrete features and geometries formed from at least two different materials including functional polymers, functional oligomers, reactive diluents, addition polymer precursor compounds, catalysts, and curing agents. For example, the advanced polishing pad can be formed from multiple polymeric layers by automated sequential deposition of at least one polymer precursor composition followed by at least one curing step, wherein each layer can represent at least one polymer composition and/or regions of different composition. Embodiments of the present disclosure further provide a polishing pad having a polymeric layer that can be an interpenetrating polymer network.","['B24D18/0045', 'B24D11/001', 'B24B37/22', 'B24B37/24', 'B24B37/26', 'B24D11/04', 'B24D18/00', 'B24D18/009', 'B24D3/28', 'B33Y10/00', 'B33Y80/00', 'B29C64/112']"
US20190259033A1,System and method for using a data genome to identify suspicious financial transactions,"A system and method for using a data genome to identify suspicious financial transactions. In one embodiment, the method comprises receiving a data set of financial activity data of multiple participants; configuring a deep neural network and thresholds, wherein the thresholds enable detection of what is within abnormal range of financial activity, patterns, and behavior over a period of time; converting the data set to a genome containing a node for each participant among the multiple participants; computing threat vectors for each node within a graphical representation of the genome that represents behavioral patterns of participants in financial activities, including determining when a key risk indicator (KRI) value computed for a particular threshold within the data set falls outside of a dynamically determined range bounded by thresholds, wherein the threat vectors automatically identify one or more of suspicious participants and suspicious activities in a provided financial activity pattern; and determining a particular edge in the network whose behavior falls outside the dynamically determined range associated with normal activity as a suspicious.","['G06Q20/4016', 'H04L63/1425', 'G06N20/00', 'G06N3/08', 'G06N5/02']"
US20190311367A1,System and method for using a data genome to identify suspicious financial transactions,"A system and method for using a data genome to identify suspicious financial transactions. In one embodiment, the method comprises receiving a data set of financial activity data of multiple participants; configuring a deep neural network and thresholds, wherein the thresholds enable detection of what is within abnormal range of financial activity, patterns, and behavior over a period of time; converting the data set to a genome containing a node for each participant among the multiple participants; computing threat vectors for each node within a graphical representation of the genome that represents behavioral patterns of participants in financial activities, including determining when a key risk indicator (KRI) value computed for a particular threshold within the data set falls outside of a dynamically determined range bounded by thresholds, wherein the threat vectors automatically identify one or more of suspicious participants and suspicious activities in a provided financial activity pattern; and determining a particular edge in the network whose behavior falls outside the dynamically determined range associated with normal activity as a suspicious.","['H04L63/1425', 'G06N20/00', 'G06N3/042', 'G06N5/02', 'G06Q20/4016', 'G06Q30/0201', 'G06N3/08']"
US20220351431A1,A low dose sinogram denoising and pet image reconstruction method based on teacher-student generator,"The present invention discloses a low dose Sinogram denoising and PET image reconstruction method based on teacher-student generator, the adopted network model is divided into a Sinogram denoising module and a PET image reconstruction module, the entire network needs to be processed in a training stage and a test stage. In the training stage: the present invention uses the denoising module to denoise the low dose Sinogram, and then makes the reconstruction module use the denoised Sinogram to reconstruct, in which the teacher generator is introduced in the training stage to constrain the whole, the denoising module is decoupled from the reconstruction module, and a better reconstructed image is obtained through training. In the testing stage, the present invention only needs to input low-dose Sinogram to the denoising module to obtain the denoised Sinogram, and then input the denoised Sinogram to the student generator to get the final reconstruction image.","['G06T5/70', 'G06T11/005', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06N3/096', 'G06T5/002', 'G06T5/60', 'G06T2207/10104', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/441']"
US10074006B2,Methods and systems for disease classification,"This invention describes methods and systems for use of computer vision systems for classification of biological cells as an aid in disease diagnostics. More particularly the present invention describes a process comprising employing a robust and discriminative color space which will help provide segmentation of the cells; employing a segmentation algorithm, such as a feature-based level set, that will be able to segment the cells using a different k-phase-segmentation process, which detect for example, if a while blood cell occurs for segmenting the internal components of the cell robustly; employing a combination of different type of features including shape, texture, and invariant information, and employing a classification step to associate abnormal cell characteristics with disease states.","['G06V20/695', 'G06K9/00147', 'G06K9/0014', 'G06K9/4604', 'G06K9/4652', 'G06T7/0012', 'G06T7/187', 'G06T7/90', 'G06V20/698', 'H04N23/63', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/30024', 'H04N5/23293']"
US11743719B2,System and method for authenticating an occupant of a vehicle,A system in a vehicle includes one or more sensors configured to obtain occupant information from an occupant utilizing at least facial information of the occupant. The system also includes a controller in communication with the one or more sensors. The controller is configured to determine an application policy associated with one or more applications of the vehicle and execute the one or more applications in response to facial information exceeding a first authentication layer or second authentication layer associated with the application policy.,"['B60W40/08', 'H04W12/06', 'B60W50/08', 'G06F21/32', 'G06F21/629', 'G06V20/59', 'G06V40/20', 'G10L15/25', 'H04L63/0861', 'H04L63/102', 'H04L63/20', 'H04W12/35', 'H04W12/60', 'H04W4/38', 'H04W4/40', 'B60W2040/089', 'B60W2050/0043', 'B60W2540/21', 'B60W2540/223', 'B60W2540/225', 'H04L2463/082']"
US9373160B2,"System, method and computer-accessible medium for restoring an image taken through a window","Systems, methods and computer-accessible mediums for modifying an image(s) can be provided. For example, first image information for the image(s) can be received. Second image information can be generated by separating the first image information into at least two overlapping images. The image(s) can be modified using a prediction procedure based on the second image information.","['G06T5/77', 'G06T5/005', 'G06T5/60', 'G06T2207/20084', 'G06T2207/30248']"
US20250215487A1,Nanopore sequencing,"Systems and methods for sequencing polynucleotides using nanopores are disclosed. In some embodiments, a polynucleotide including a single-stranded region and a double-stranded region, in which the single-stranded region is disposed through a nanopore. The polynucleotide can be moved relative to the nanopore by electric forces while one or more structural locks keep the polynucleotide close to the nanopore. A characteristic signal based on nanopore ionic current blockade and associated with the regions of the polynucleotide at or near the nanopore recognition zone is measured and used to infer the nucleobase sequence of the polynucleotide. In some examples, the double-stranded region is extended by a polymerase, and the polymerase is removed from the polynucleotide. In some examples, signals measured under different applied voltages provide nonredundant information regarding the polynucleotide sequence.","['C12Q1/6869', 'C12Q1/701', 'G01N27/3276', 'G01N27/44791', 'G01N33/48721', 'G16B30/20', 'G16B40/10', 'C12Q2521/101', 'C12Q2537/155', 'C12Q2563/116', 'C12Q2565/631']"
CN105451767B,Multivalence and monovalent polyspecific compound and application thereof,"The composition containing multivalence and monovalent polyspecific compound is described, the compound has the bracket such as antibody for supporting this kind of binding function.The purposes and method of the composition containing multivalence and monovalent polyspecific compound are also described, the compound has the bracket such as antibody for supporting this kind of binding function.","['C07K14/435', 'A61K45/06', 'A61P29/00', 'A61P35/00', 'C07K16/18', 'C07K16/24', 'C07K16/28', 'C07K16/2848', 'C07K16/2863', 'C07K16/32', 'C07K16/40', 'C07K7/08', 'C12N9/0002', 'A61K2039/505', 'A61K38/00', 'C07K2317/31', 'C07K2317/35', 'C07K2317/76', 'C07K2319/00', 'Y02A50/30']"
US10068024B2,Method and apparatus for correlating and viewing disparate data,"Methods and apparatuses of the present invention generally relate to generating actionable data based on multimodal data from unsynchronized data sources. In an exemplary embodiment, the method comprises receiving multimodal data from one or more unsynchronized data sources, extracting concepts from the multimodal data, the concepts comprising at least one of objects, actions, scenes and emotions, indexing the concepts for searchability; and generating actionable data based on the concepts.","['G06F17/30867', 'G06F16/9535', 'G06F16/9537', 'G06F17/2785', 'G06F17/3087', 'G06F40/30', 'G06F17/2827', 'G06F40/45', 'G06Q50/26']"
US20190227553A1,Interactive autonomous vehicle command controller,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving, at an autonomous vehicle system, a command to control an ambient feature associated with the autonomous vehicle system. One or more courses of action may be determined based on the command. In addition, one or more probabilistic models associated with the one or more courses of action may also be determined. Based on the one or more probabilistic models, confidence levels may also be determined to form a subset of the one or more courses of action. A course of action from the subset of the one or more courses of action may then be executed at the autonomous vehicle system responsive to the command.","['G05D1/0088', 'B60L58/12', 'B60H1/00735', 'B60L15/20', 'B60Q3/00', 'B60W60/00253', 'B60L2260/32', 'B60Q1/28', 'B60Q1/30', 'B60Q2900/50', 'B60W2540/041', 'G08G1/202', 'Y02T10/64', 'Y02T10/70', 'Y02T10/72', 'Y02T90/16']"
JP2021167311A,Sol containing nano-zirconia particles for use in additive manufacturing processes for production of three-dimensional articles,"To improve existing additive manufacturing processes.SOLUTION: The invention relates to the use of printing sol as construction material in an additive manufacturing process for producing a three-dimensional article. The printing sol comprises: solvent(s); nano-sized crystalline zirconia particles in an amount from 2 to 25 vol.% based on the volume of the sol, where the average primary particle size of the nano-sized crystalline zirconia particles is in a range up to 50 nm; a first monomer being a polymerizable surface modification agent represented by formula A-B, with A being capable of attaching to the surface of the nano-sized crystalline zirconia particles, and B being a radiation curable group; optionally a second monomer, the second monomer comprising at least one radiation curable moiety but no acidic or silane group(s); and photo initiator(s). The invention also relates to a ceramic article obtainable by such a process.SELECTED DRAWING: Figure 1","['C04B35/486', 'A61C13/0013', 'A61C13/0019', 'A61C13/083', 'A61C13/09', 'A61C5/70', 'A61C5/73', 'A61C5/77', 'A61K6/17', 'A61K6/802', 'A61K6/807', 'A61K6/818', 'A61K6/82', 'A61K6/822', 'B28B1/001', 'B33Y10/00', 'B33Y70/10', 'B33Y80/00', 'C04B35/624', 'C04B35/64', 'C04B2235/3206', 'C04B2235/3208', 'C04B2235/3225', 'C04B2235/3227', 'C04B2235/3229', 'C04B2235/5454', 'C04B2235/6026', 'C04B2235/762', 'C04B2235/765', 'C04B2235/9653']"
US10446037B2,Software application to request and control an autonomous vehicle service,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving, from a user device, a ride request to transport a user to a destination from an origin location through an autonomous vehicle system service. Based on the origin location associated with the request, an autonomous vehicle system may be selected from a fleet of autonomous vehicles to execute the ride request. The fleet may be managed by the autonomous vehicle system service. The ride request may then be provided to the autonomous vehicle system, and information about the autonomous vehicle system may also be provided to the user device.","['G08G1/202', 'G01C21/34', 'G05D1/0088', 'G06K9/00791', 'G06K9/00805', 'G06Q10/02', 'G06Q10/063', 'G06Q50/30', 'G06Q50/40', 'G06V20/56', 'G06V20/58']"
US10334050B2,Software application and logic to modify configuration of an autonomous vehicle,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include identifying a location of a user device associated with a user, transmitting a command to an autonomous vehicle system associated with an autonomous vehicle service to transit to the location, and providing information associated with the user device to the autonomous vehicle system, where the information includes configuration data to adapt one or more sub-systems of the autonomous vehicle. Sub-systems of the autonomous vehicle may include interior lighting, ambient sound, road handling, seating configuration, communication synchronization, and temperature control systems.","['H04L67/125', 'G06F3/0482', 'G06F3/04842', 'G06F3/04847', 'G06Q10/00', 'G06Q10/02', 'G06Q10/087', 'G06Q30/0601', 'G06Q50/01', 'G06Q50/40', 'G08G1/202', 'G08G1/207', 'H04L29/00', 'H04L69/00', 'H04W4/02', 'H04W4/40', 'B60Q1/28', 'B60Q1/30', 'G07C5/008']"
US11283877B2,Software application and logic to modify configuration of an autonomous vehicle,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include identifying a location of a user device associated with a user, transmitting a command to an autonomous vehicle system associated with an autonomous vehicle service to transit to the location, and providing information associated with the user device to the autonomous vehicle system, where the information includes configuration data to adapt one or more sub-systems of the autonomous vehicle. Sub-systems of the autonomous vehicle may include interior lighting, ambient sound, road handling, seating configuration, communication synchronization, and temperature control systems.","['G06Q10/00', 'B60Q1/503', 'B60Q1/507', 'B60Q1/508', 'B60Q1/549', 'G05D1/0038', 'G05D1/0214', 'G05D1/024', 'G05D1/0246', 'G06F3/0482', 'G06F3/04842', 'G06F3/04847', 'G08G1/20', 'H04L29/00', 'H04L67/125', 'H04L67/306', 'H04L67/34', 'H04L67/52', 'H04L69/00', 'B60Q1/28', 'B60Q1/30', 'G07C5/008']"
CN105745955B,Protection privacy in network-based immersion augmented reality,""" AR privacy API "" is provided for allowing to apply the API for being showed with web browser using each content and being abstracted to protect privacy of user in extensive network-based immersion augmented reality (AR) scene.The concept of traditional "" webpage "" is expanded to immersion "" network room "" by AR privacy API, wherein showing the combination of any desired of existing or new 2D and 3D content in the room or other spaces of user.Advantageously, AR privacy API and it is associated show it is abstract be available by wide variety of application and web page contents, for enhancing the room or other spaces of user by network-based immersion AR content.Furthermore, AR privacy API is realized using any existing or new web page coding platform, including but not limited to, HTML, XML, CSS, JavaScript etc., so that existing Web content and coding techniques can be smoothly integrated into extensive network room AR scene.","['G06F21/60', 'G06F21/6245', 'G06F21/629', 'G06T19/006', 'H04L67/02', 'H04L67/10', 'H04L67/12', 'H04L67/131', 'H04W12/02', 'H04L67/535', 'H04W12/65']"
US10073887B2,System and method for performing k-nearest neighbor search based on minimax distance measure and efficient outlier detection,"A system and method enable a set of dataset objects that are K-nearest neighbors (K-NN), based on their Minimax distances to a test object, to be identified without computing the all-pair Minimax distances directly. A pairwise distance between the test object and each dataset object is computed. Iteratively, one of the dataset objects is selected to add to a K-NN set until the K-NN set includes a predefined number of nearest neighbors. The selected dataset object at each iteration is the one for which there is no other unselected dataset object which has a smaller pairwise distance to any of a current subset of objects than the selected dataset object. The current subset of objects includes the test object and the dataset objects currently in the K-NN set. After the K-NN set is identified it may be output or used to generate other information, such as a test object label.","['G06F17/30477', 'G06F16/2455', 'G06F16/22', 'G06F17/30312']"
US9066883B2,Administration of cells and cellular extracts for rejuvenation,"The invention describes methods and agents for improving cosmetic appearance, for promoting, improving or restoring health of cells and tissues, preferably skin, and more preferably, for restoring aged or damaged skin to a healthy appearance. In some embodiments, the invention relates to compositions of cells, eggs, cell extracts, egg extracts, and extract components such as purified nucleic acids, polypeptides, lipids, carbohydrates or other natural products.","['A61K35/60', 'A61K31/7088', 'A61K35/36', 'A61K38/02', 'A61K45/06', 'A61K8/606', 'A61K8/64', 'A61K8/65', 'A61K8/97', 'A61K8/975', 'A61K8/9789', 'A61K8/981', 'A61K8/982', 'A61K8/987', 'A61K8/99', 'A61P17/00', 'A61P17/02', 'A61P17/16', 'A61P19/00', 'A61P21/00', 'A61P29/00', 'A61P31/00', 'A61P39/06', 'A61P43/00', 'A61Q19/00', 'A61Q19/004', 'A61Q19/08', 'A61Q19/06']"
US20220331841A1,Methods and arrangements to aid recycling,"A waste stream is analyzed and sorted to segregate different items for recycling. Certain features of the technology improve the accuracy with which waste stream items are diverted to collection repositories. Other features concern adaptation of neural networks in accordance with context information sensed from the waste. Still other features serve to automate and simplify maintenance of machine vision systems used in waste sorting. Yet other aspects of the technology concern marking 2D machine readable code data on items having complex surfaces (e.g., food containers with integral ribbing for structural strength or juice pooling), to mitigate issues that such surfaces can introduce in code reading. Still other aspects of the technology concern prioritizing certain blocks of conveyor belt imagery for analysis. Yet other aspects of the technology concern joint use of near infrared spectroscopy, artificial intelligence, digital watermarking, and/or other techniques, for waste sorting. A variety of further features and arrangements are also detailed.","['G06K19/06037', 'B07C5/342', 'B65G47/26', 'G06F18/214', 'G06K19/06046', 'G06K7/1417', 'G06K7/1482', 'G06K9/6256', 'G06N3/045', 'G06N3/08', 'G06V10/143', 'G06V10/225', 'G06V10/245', 'G06V10/764', 'G06V10/768', 'G06V10/82', 'G06V20/52', 'G06V20/64', 'B07C2501/0054', 'B65G2203/0208', 'B65G2203/041', 'G06V2201/06', 'G06V2201/10']"
US12118738B2,Generation of three-dimensional scans for intraoperative imaging,A system for executing a three-dimensional (3D) intraoperative scan of a patient is disclosed. A 3D scanner controller projects the object points included onto a first image plane and the object points onto a second image plane. The 3D scanner controller determines first epipolar lines associated with the first image plane and second epipolar lines associated with the second image plane based on an epipolar plane that triangulates the object points included in the first 2D intraoperative image to the object points included in the second 2D intraoperative image. Each epipolar lines provides a depth of each object as projected onto the first image plane and the second image plane. The 3D scanner controller converts the first 2D intraoperative image and the second 2D intraoperative image to the 3D intraoperative scan of the patient based on the depth of each object point provided by each corresponding epipolar line.,"['G06T7/593', 'A61B34/20', 'A61B90/37', 'G06T7/30', 'G06T7/33', 'G06T7/521', 'G06T7/73', 'H04N13/106', 'H04N13/239', 'A61B2034/2051', 'A61B2034/2055', 'A61B2034/2065', 'A61B2090/373', 'G06T2207/10012', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30012', 'G06T2207/30196', 'H04N13/302', 'H04N13/332', 'H04N2013/0081']"
CN111540025B,Predicting images for image processing,An image for image processing is predicted. Systems and methods for image prediction for image processing are provided. The trained image predictor may be used to generate a virtual image based on a previous actual image. The virtual image may be preprocessed to generate an intermediate image. The intermediate image may then be used to process the next actual image to generate a final image.,"['G06T5/70', 'G06T11/003', 'G06F18/21', 'G06F18/2431', 'G06T15/08', 'G06T5/20', 'G06T5/50', 'G06T5/60', 'G06T2207/10081', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10136', 'G06T2207/20024', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/20221', 'G06T2207/20224']"
US20240029426A1,Image Recognition System,"Systems and methods for predicting items within content and using improved, fine-grained image classification techniques to produce images used to identify consumer products in the real-world by allowing for the recognition of a product using an image captured under a variety of conditions and environments, such as angles, lighting, camera settings, and the like.","['G06V20/10', 'G06F18/2413', 'G06T7/74', 'G06V10/28', 'G06V10/44', 'G06V10/764', 'G06F18/24323', 'G06T2200/24', 'G06V10/141', 'G06V10/143', 'G06V2201/09']"
US20190213705A1,"Artwork generated to convey digital messages, and methods/apparatuses for generating such artwork","A neural network is applied to imagery including a machine readable code, to transform its appearance while maintaining its machine readability. One particular method includes training a neural network with a style image having various features. The trained network is then applied to an input pattern that encodes a plural-symbol payload. The network adapts features from the style image to express details of the input pattern, to thereby produce an output image in which features from the style image contribute to encoding of the plural-symbol payload. This output image can then be used as a graphical component in product packaging, such as a background, border, or pattern fill. In some embodiments, the input pattern is a watermark pattern, while in others it is a host image that has been previously watermarked. A great variety of other features and arrangements are also detailed.","['G06T1/0092', 'G06F16/1858', 'G06K19/06103', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T1/0028', 'G06T11/20', 'G06T2201/0061']"
US11374171B2,Memristor and neuromorphic device comprising the same,Provided are memristors and neuromorphic devices including the memristors. A memristor includes a lower electrode and an upper electrode that are apart from each other and first and second two-dimensional material layers that are arranged between the lower electrode and the upper electrode and stacked without a chemical bond therebetween.,"['H01L45/1233', 'H10N70/826', 'G11C13/0069', 'G06N3/065', 'G11C13/0009', 'H01L27/2463', 'H01L45/08', 'H10B63/80', 'H10N70/24', 'H10N70/8822', 'H10N70/8825', 'H10N70/8828', 'H10N70/883', 'H10N70/8833', 'G06N3/049', 'G11C2213/32', 'G11C2213/35', 'H01L45/1266', 'H10N70/8416']"
US20190122651A1,Systems and methods for neural text-to-speech using convolutional sequence learning,"Described herein are embodiments of a fully-convolutional attention-based neural text-to-speech (TTS) system, which various embodiments may generally be referred to as Deep Voice 3. Embodiments of Deep Voice 3 match state-of-the-art neural speech synthesis systems in naturalness while training ten times faster. Deep Voice 3 embodiments were scaled to data set sizes unprecedented for TTS, training on more than eight hundred hours of audio from over two thousand speakers. In addition, common error modes of attention-based speech synthesis networks were identified and mitigated, and several different waveform synthesis methods were compared. Also presented are embodiments that describe how to scale inference to ten million queries per day on one single-GPU server.","['G10L13/027', 'G10L13/047', 'G10L13/08', 'G10L25/30']"
US20190247650A1,Systems and methods for augmenting human muscle controls,"Systems and methods are disclosed for physical assistance by: during a training phase, capturing muscle signals associated with a predetermined task and training a learning machine to associate the muscle signals with the task; during use, identifying a desired task to the learning machine to retrieve the muscle signals associated with the task; and applying functional electrical stimulation (FES) to actuate the muscle signals for the desired task.","['A61N1/3603', 'A61N1/025', 'A61N1/36003', 'A61N1/36007', 'A61N1/3625', 'A61N1/3704', 'G16H20/30', 'G16H40/63', 'G16H50/20', 'A61B2562/0219', 'A61B5/0022', 'A61B5/021', 'A61B5/318', 'A61B5/369', 'A61B5/389', 'A61B5/7267', 'A61N1/0484', 'Y02A90/10']"
CN107428073B,For preparing the silicon composition of elastomer formation component by ballistic processes,"The present invention relates to crosslinkable silicone rubber compounds, wherein its property of the invention, which allows to increase material method (3D printing) by trajectory, prepares elastic body moulding body.","['C08G77/38', 'B29C64/10', 'B33Y10/00', 'B33Y70/10', 'C08G77/20', 'C08J3/24', 'C08J3/28', 'C08K3/36', 'C08K5/1515', 'C08K5/54', 'C08L83/04', 'C08L83/14', 'B29C64/112', 'B29K2083/00', 'C08G77/12', 'C08G77/14', 'C08J2383/07']"
CN112638529B,Methods and systems for cell counting,"The present disclosure provides methods and systems for Ghosting Cytometry (GC) that can be used to generate images of objects without the use of spatially resolved detectors. It can be used to perform imaging cytometry without imaging ultrafast fluorescence, e.g., based on a single pixel detector. Spatial information obtained from the movement of the cell relative to the patterned optical structure may be compressively converted into signals that arrive sequentially at the single pixel detector. The use of a time domain waveform in combination with a random or pseudo-random pattern of intensity distribution may allow for computational reconstruction of cell morphology. The machine learning method can be directly applied to compressed waveforms without image reconstruction to achieve efficient image-free morphology-based cytometry. The image-free GC allows accurate and high throughput cell sorting and selective sorting based on cell morphology without specific biomarkers, which is challenging with conventional flow cytometry.","['G01N15/1459', 'G01N15/1434', 'G01N15/1433', 'B01L2200/0652', 'B01L2400/0439', 'B01L3/502761', 'G01N15/149', 'G01N2015/1006', 'G01N2015/145', 'G01N2015/1497']"
US9314488B2,Cellular extracts,"The invention describes methods and agents for improving cosmetic appearance, for promoting, improving or restoring health of cells and tissues, preferably skin, and more preferably, for restoring aged or damaged skin to a healthy appearance. The agents include compositions of cells, eggs, cell extracts, egg extracts, and extract components such as purified nucleic acids, polypeptides, lipids, carbohydrates or other natural products.","['A61K35/60', 'A61K35/65', 'A61K8/987', 'A61K9/06', 'A61P17/00', 'A61P17/02', 'A61P17/12', 'A61Q19/00', 'A61Q19/08', 'A61K2800/805']"
US20200405148A1,Medical analysis system,"Systems and methods are disclosed to inspect an eye includes capturing an eye image using a mobile device camera; extracting features of the eye; applying a deep learning neural network to detect potential eye damage; and reporting the potential eye damage for treatment, such as those from laser pointers, among others.","['A61B3/14', 'A61B3/0025', 'A61B3/0008', 'A61B3/0016', 'A61B3/107', 'A61B3/16', 'G16H30/40', 'G16H50/20', 'G06T2207/20084', 'G06T2207/30041']"
US20240406989A1,Advanced mobile devices and network supporting same,"A method performed by a wireless device may comprise transmitting control information of a variable length control information format. The control information may comprise a plurality of beam index fields and a plurality of time resource indication fields. The method may further comprise transmitting a single indicator corresponding to a number of beam index fields and a number of time resource indication fields contained in the control information. Wireless repeater circuitry may be operated according to the control information. Certain information may be repeated by the wireless repeater circuitry, but the control information is not repeated by the wireless repeater circuitry.","['H04W72/23', 'H04W72/542', 'H04W72/0453', 'H04W80/02', 'H04W84/12', 'H04W88/08']"
US12226207B1,Multidepth tissue oximeter,"An oximeter measures oxygen saturation for two or more different tissue depths and shows these results on a screen. A probe of the oximeter has multiple different distances between source and detector sensors. One probe implementation has fixed sensor positions. Other implementations include sensors on a moveable platform or openings to accept sensors, which allow a user to vary a distance between sensors.","['A61B5/1459', 'A61B5/0022', 'A61B5/063', 'A61B5/1455', 'A61B5/14551', 'A61B5/14552', 'A61B5/742', 'A61B2562/043', 'A61B5/061']"
US10775376B2,Methods for assaying cellular binding interactions,"There are provided methods, and devices for assaying for a binding interaction between a protein, such as a monoclonal antibody, produced by a cell, and a biomolecule. The method may include retaining the cell within a chamber having an aperture; exposing the protein produced by the cell to a capture substrate, wherein the capture substrate is in fluid communication with the protein produced by the cell and wherein the capture substrate is operable to bind the protein produced by the cell; flowing a fluid volume comprising the biomolecule through the chamber via said aperture, wherein the fluid volume is in fluid communication with the capture substrate; and determining a binding interaction between the protein produced by the cell and the biomolecule.","['G01N33/56966', 'B01L3/502738', 'B01L3/502761', 'G01N33/577', 'G01N33/582', 'G01N33/6854', 'B01L2200/0668', 'B01L2300/0681', 'B01L2300/0861', 'B01L2300/0864', 'B01L2300/0867', 'B01L2400/0481']"
US20200224243A1,Proximity Ligation in Situ Hybridization (PLISH),"Compositions and reagents for molecular profiling using proximity ligation-/>7 situ hybridization (PLISH) are disclosed. In particular, PLISH merges the specificity of proximity ligation, the sensitivity of tiling multiple probes for a target nucleic acid, and the high signal intensity of rolling circle amplification. The probe design capitalizes on the formation of Holliday-like junctions for optimal signal amplification. PLISH provides single molecule resolution and allows for quantitation of a virtually unlimited number of nucleic acids within individual cells. PLISH is also compatible with immunohistochemistry and archival formal-fixed, paraffin-embedded tissue samples.","['C12Q1/682', 'C12N15/11', 'C12Q1/6888', 'G16B40/00']"
US9996772B2,Detection of objects in images using region-based convolutional neural networks,"A transformed image is received. The transformed image includes an other-than-visible light image that has been captured using a transformation device. A region of the transformed image is isolated, the region being less than an entirety of the transformed image. By applying to the region a convolutional Neural Network (CNN) which executes using a processor and a memory, and by processing only the region of the transformed image, an object of interest is detected in the region. Upon detecting, an indication is produced to indicate the presence of the object of interest in the region.","['G06T7/70', 'G06K9/66', 'G06F18/214', 'G06F18/22', 'G06F18/23213', 'G06F18/24', 'G06K9/52', 'G06K9/6215', 'G06K9/6256', 'G06K9/6267', 'G06T7/0042', 'G06T7/11', 'G06T7/33', 'G06T7/73', 'G06V10/255', 'G06V10/454', 'G06V10/763', 'G06K2009/4666', 'G06T2207/10048', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084']"
US11517901B2,High-efficiency particle encapsulation in droplets with particle spacing and downstream droplet sorting,"A passive, hydrodynamic technique implemented using a microfluidic device to perform co-encapsulation of samples in droplets and sorting of said droplets is described herein. The hydrodynamic technique utilizes laminar flows and high shear liquid-liquid interfaces at a microfluidic junction to encapsulate samples in the droplets. A sorting mechanism is implemented to separate sample droplets from empty droplets. This technique can achieve a one-one-one encapsulation efficiency of about 80% and can significantly improve the droplet sequencing and related applications in single cell genomics and proteomics.","['C12N11/00', 'B01L3/502715', 'B01L3/502746', 'B01L3/502761', 'B01L3/502784', 'G01N15/10', 'G01N15/1492', 'G01N35/08', 'B01L2200/0636', 'B01L2200/0652', 'B01L2200/0668', 'B01L2200/0673', 'B01L2300/06', 'B01L2300/0645', 'B01L2300/0864', 'B01L2300/0867', 'B01L2400/0487', 'B01L2400/082', 'G01N2015/1006', 'G01N2015/1481', 'G01N21/6408', 'G01N21/6458']"
US20220176622A1,Stereolithography three-dimensional printing systems and methods,The present disclosure provides systems and methods for printing three-dimensional (3D) objects. A system for printing a 3D object may comprise a platform comprising an area configured to hold a mixture including a photoactive resin. The platform may comprise a first coupling unit. The system may comprise an optical source configured to provide light to the mixture for curing the photoactive resin in at least a portion of the mixture to print at least a portion of the 3D object. The system may comprise a build head configured to support the at least he portion of the 3D object during printing. The build head may comprise a second coupling unit that is configured to couple to the first coupling unit to provide an alignment of the area of the platform relative to a surface of the build head while printing the at least the portion of the 3D object.,"['B29C64/223', 'B22F10/12', 'B22F10/85', 'B22F12/33', 'B22F12/38', 'B22F12/50', 'B22F12/90', 'B29C64/124', 'B29C64/20', 'B29C64/255', 'B29C64/386', 'B33Y10/00', 'B33Y30/00', 'B33Y50/00', 'B22F12/42']"
CN105705072B,Multi-lumen catheter retractor system for minimally invasive surgical gastrointestinal treatment,"A system for performing minimally invasive procedures in a body lumen of a patient includes a flexible catheter having a first lumen configured and dimensioned to receive an endoscope therethrough and a second lumen configured and dimensioned to receive a first flexible tube therethrough. The first flexible tube is movable through the second lumen and has a distal portion including a first bend and a second bend, the first bend extending in a first direction relative to the longitudinal axis and the second bend extending in a second, different direction relative to the longitudinal axis. A retractor system is positioned at a distal portion of the catheter and is movable from a non-expanded insertion position to an expanded position forming an expanded cage structure to form a larger working space. The distal portion of the first flexible tube is movable within the expansion cage.","['A61B17/0218', 'A61B17/00234', 'A61B2017/00269', 'A61B2017/003', 'A61B2017/00331', 'A61B2017/00557', 'A61B2017/00818', 'A61B2017/0225', 'A61B2017/345']"
CN117938960A,A request allocation method based on diffusion model in cloud-edge collaborative system,"The invention discloses a request distribution method based on a diffusion model in a cloud edge cooperative system, which comprises a request assignment algorithm and a service arrangement algorithm embedded in cloud clusters and edge clusters; the diffusion model is used as an action strategy network, and an assignment action is generated for carrying out request assignment according to the state information of the system on edge agent nodes in the edge cluster, so that an optimization request assignment algorithm is obtained; the diffusion model is used as a strategy gradient network, high-value edge nodes are selected, and the expansion actions on the edge nodes are calculated to carry out service arrangement, so that an optimized service arrangement algorithm is obtained; the invention enhances the request assignment algorithm and the service orchestration algorithm to handle complex situations through a diffusion model.","['H04L67/60', 'H04L41/145', 'H04L41/16']"
US20240401109A1,"Methods, compositions, and kits for multiple barcoding and/or high-density spatial barcoding","The present disclosure features methods, compositions, and kits for multiple barcoding, high-density barcoding, and/or selective release of barcoded capture probes to capture analytes, or proxies thereof, from a biological sample.","['C12Q1/6806', 'C12Q1/6823', 'C12Q1/6841']"
US10346982B2,Method and system of computer-aided detection using multiple images from different views of a region of interest to improve detection accuracy,"A system and method of computer-aided detection (CAD or CADe) of medical images that utilizes persistence between images of a sequence to identify regions of interest detected with low interference from artifacts to reduce false positives and improve probability of detection of true lesions, thereby providing improved performance over static CADe methods for automatic ROI lesion detection.","['G06T7/0016', 'G06T7/223', 'G06T2207/10121', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/30068', 'G06T2207/30096']"
US12136034B2,Dynamic gradient aggregation for training neural networks,"The disclosure herein describes training a global model based on a plurality of data sets. The global model is applied to each data set of the plurality of data sets and a plurality of gradients is generated based on that application. At least one gradient quality metric is determined for each gradient of the plurality of gradients. Based on the determined gradient quality metrics of the plurality of gradients, a plurality of weight factors is calculated. The plurality of gradients is transformed into a plurality of weighted gradients based on the calculated plurality of weight factors and a global gradient is generated based on the plurality of weighted gradients. The global model is updated based on the global gradient, wherein the updated global model, when applied to a data set, performs a task based on the data set and provides model output based on performing the task.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/047']"
US7587099B2,Region-based image denoising,"An âImage Denoiserâ provides a probabilistic process for denoising color images by segmenting an input image into regions, estimating statistics within each region, and then estimating a clean (or denoised) image using a probabilistic model of image formation. In one embodiment, estimated blur between each region is used to reduce artificial sharpening of region boundaries resulting from denoising the input image. In further embodiments, the estimated blur is used for additional purposes, including sharpening edges between one or more regions, and selectively blurring or sharpening one or more specific regions of the image (i.e., âselective focusâ) while maintaining the original blurring between the various regions.","['G06T5/73', 'H04N5/21', 'G06T5/70', 'H04N5/208', 'G06T2207/20076']"
US8659596B2,Real time generation of animation-ready 3D character models,"Systems and methods for automatically generating animation-ready 3D character models based upon model parameter and clothing selections are described. One embodiment of the invention includes an application server configured to receive the user defined model parameters and the clothing selection via a user interface. In addition, the application server includes a generative model and the application server is configured to generate a 3D anatomical mesh based upon the user defined model parameters using the generative model, the application server includes at least one clothing mesh template including a clothing mesh, a template skeleton, and skinning weights and the application server is configured to apply the clothing mesh from the clothing mesh template corresponding to the user clothing selection to the generated 3D anatomical mesh to create a clothed mesh, the application server is configured to adjust the template skeleton of the clothing mesh template corresponding to the user clothing selection based upon the shape of the clothed mesh, the application server is configured to generate skinning weights based upon the skinning weights of the clothing mesh template corresponding to the user clothing selection, and the application server stores an animation-ready 3D character model including the clothed mesh, the adjusted skeleton, and the generated skinning weights.","['G06T13/40', 'G06T17/20']"
US9799098B2,Method and apparatus for image processing,"Identifying objects in images is a difficult problem, particularly in cases an original image is noisy or has areas narrow in color or grayscale gradient. A technique employing a convolutional network has been identified to identify objects in such images in an automated and rapid manner. One example embodiment trains a convolutional network including multiple layers of filters. The filters are trained by learning and are arranged in successive layers and produce images having at least a same resolution as an original image. The filters are trained as a function of the original image or a desired image labeling; the image labels of objects identified in the original image are reported and may be used for segmentation. The technique can be applied to images of neural circuitry or electron microscopy, for example. The same technique can also be applied to correction of photographs or videos.","['G06T5/001', 'G06V10/267', 'G06K9/342', 'G06K9/4628', 'G06T5/60', 'G06T7/11', 'G06V10/454', 'G06T2207/20084']"
US8311623B2,Systems and methods for estimating surface electromyography,A rehabilitation device is presented that is inexpensive to produce and is easy to use. The device uses a predictable method to estimate the activity of muscle and therefore provide many ways to train and rehabilitate a person having a prosthetic limb or other neuromuscular disorder.,"['A61B5/486', 'A61F2/72', 'A61B5/389']"
US7624077B2,Methods and systems for multi-participant interactive evolutionary computing,"Disclosed are methods, systems, and processor program products that include executing an optimization scheme to obtain a first solution set, presenting the first solution set to at least two users, receiving rankings of the first solution set from the at least two users, aggregating the rankings, and, generating a second solution set based on the aggregated rankings. The optimization scheme can include a genetic algorithm. In embodiments, at least a part of the first solution set can be presented to the users based on the parts of the solution set associated with the user (e.g., user's knowledge).",['G06N3/126']
US7933454B2,Class-based image enhancement system,"A method for image enhancement includes providing for a semantic class to be assigned to a digital image based on image content, the assigned semantic class being selected from a plurality of semantic classes. The method further includes providing for an aesthetic enhancement to be applied to the image based on image quality of the image and the assigned semantic class, the enhancement including at least one enhancement dimension selected from a plurality of enhancement dimensions.","['G06V30/413', 'G06T5/60', 'G06T2207/20008', 'G06T2207/20081']"
US9552442B2,Visual meme tracking for social media analysis,"A system and method for analyzing visual memes includes identifying visual memes associated with at least one topic in a data source. The visual memes propagated over time are tracked to extract information associated with identified visual memes. The information associated with the visual memes is analyzed to determine at least one of generation, propagation, and use of the identified memes.","['G06F16/7837', 'G06F16/903', 'G06F17/30964', 'G06F16/40', 'G06F16/48', 'G06F16/70', 'G06F16/9024', 'G06F16/9535', 'G06F17/30017', 'G06F17/30781']"
EP2347774B1,Scaffolds for cell transplantation,"A device that includes a scaffold composition and a bioactive composition with the bioactive composition being incorporated into or coated onto the scaffold composition such that the scaffold composition and/or a bioactive composition controls egress of a resident cell or progeny thereof. The devices mediate active recruitment, modification, and release of host cells from the material.","['A61K38/1866', 'A61K38/193', 'A61K38/39', 'A61K39/0011', 'A61K39/001156', 'A61K39/00117', 'A61K39/001171', 'A61K39/00118', 'A61K39/001182', 'A61K39/001184', 'A61K39/001186', 'A61K39/001191', 'A61K39/001192', 'A61K39/001195', 'A61K39/21', 'A61K39/39', 'A61K9/0024', 'A61K9/1647', 'A61L27/18', 'A61L27/20', 'A61L27/3633', 'A61L27/38', 'A61L27/3826', 'A61L27/54', 'A61L27/56', 'A61L27/58', 'A61P35/00', 'A61P43/00', 'C12N15/117', 'C12N7/00', 'A61K2039/54', 'A61K2039/55516', 'A61K2039/55522', 'A61K2039/55561', 'A61K2039/55583', 'A61K2039/6093', 'A61L2300/232', 'A61L2300/252', 'A61L2300/412', 'A61L2300/414', 'A61L2300/426', 'A61L2300/438', 'A61L2300/604', 'A61L2300/606', 'A61L2400/18', 'A61L2430/30', 'A61L2430/34', 'B33Y80/00', 'C12N2310/17', 'C12N2320/32', 'C12N2740/16034', 'Y02A50/30']"
US7970895B2,"System, method, and service for inducing a pattern of communication among various parties","A communication pattern inducing system focuses on the propagation of topics amongst a plurality of nodes based on the text of the node rather than hyperlinks of the node. A node could represent a weblog or any other source of information such as person, a conversation, images, etc. The system utilizes a model for information diffusion, wherein the parameters of the model capture how a new topic spreads from node to node. The system further comprises a process to learn the parameters of the model based on real data and to apply the process to real (or synthetic) node data. Consequently, the system is able to identify particular individuals that are highly effective at contributing to the spread of topics.","['G06Q50/01', 'G06F16/9535', 'Y10S707/99935', 'Y10S707/99945']"
US7841995B2,Pressure pulse/shock wave therapy methods and an apparatus for conducting the therapeutic methods,"The method of stimulating a substance is disclosed. The method has the steps of activating an acoustic shock wave generator or source to emit acoustic shock waves; and subjecting the substance to the acoustic shock waves stimulating said substance wherein the substance is positioned within a path of the emitted shock waves and away from a geometric focal volume or point of the emitted shock waves. In one embodiment the emitted shock waves are divergent or near planar. In another embodiment the emitted shock waves are convergent having a geometric focal volume of point at a distance of at least X from the source, the method further comprising positioning the substance at a distance less than the distance X from the source. The substance is a tissue having cells. The tissue can be an organ of a mammal. The mammal may be a human or an animal. The organ may be a heart, a brain, skin, a liver or a kidney or any other organ. The tissue may be muscle, cartilage, tendon, bone, teeth or gums. The tissue may be a part of the vascular system, a part of the nervous system, a part of the urinary or reproductive system, a part of the lymph node or pituitary systems, a part of the ocular system or a part of a skeletal system.","['A61B17/22004', 'A61B17/225', 'A61H23/0245']"
US8015127B2,"System, method, and computer-accessible medium for providing a multi-objective evolutionary optimization of agent-based models","Agent-based models (ABMs)/multi-agent systems (MASs) are one of the most widely used modeling-simulation-analysis approaches for understanding the dynamical behavior of complex systems. These models can be often characterized by several parameters with nonlinear interactions which together determine the global system dynamics, usually measured by different conflicting criteria. One problem that can emerge is that of tuning the controllable system parameters at the local level, in order to reach some desirable global behavior. According to one exemplary embodiment t of the present invention, the tuning of an ABM for emergency response planning can be cast as a multi-objective optimization problem (MOOP). Further, the use of multi-objective evolutionary algorithms (MOEAs) and procedures for exploration and optimization of the resultant search space can be utilized. It is possible to employ conventional MOEAs, e.g., the Nondominated Sorting Genetic Algorithm II (NSGA-II) and the Pareto Archived Evolution Strategy (PAES), and their performance can be tested for different pairs of objectives for plan evaluation. In the experimental results, the approximate Pareto front of the non-dominated solutions is effectively obtained. Further, a conflict between the proposed objectives can be seen. Additional robustness analysis may be performed to assist policy-makers in selecting a plan according to higher-level information or criteria which is likely not present in the original problem description.",['G06N3/126']
US8139067B2,"Shape completion, animation and marker-less motion capture of people, animals or characters","Motion capture animation, shape completion and markerless motion capture methods are provided. A pose deformation space model encoding variability in pose is learnt from a three-dimensional (3D) dataset. Body shape deformation space model encoding variability in pose and shape is learnt from another 3D dataset. The learnt pose model is combined with the learnt body shape model. For motion capture animation, given parameter set, the combined model generates a 3D shape surface of a body in a pose and shape. For shape completion, given partial surface of a body defined as 3D points, the combined model generates a 3D surface model in the combined spaces that fits the 3D points. For markerless motion capture, given 3D information of a body, the combined model traces the movement of the body using the combined spaces that fits the 3D information or reconstructing the body's shape or deformations that fits the 3D information.","['G06T17/00', 'G06T13/40', 'Y10S345/952']"
US8157205B2,Multibody aircrane,"This invention performs relative positioning, predictive control, and ballast control to achieve very heavy-lifting tasks on land or sea. Such tasks allow station keeping and precise transfer of very heavy payloads between ships underway. This scalable multibody system features three subcomponents: Airship, Skycrane and Loadframe. This semi-autonomous system combines aerodynamic (kinetic) and aerostatic (buoyancy force) lift with efficient power and propulsion. During low-speed flight, the Airship and Skycrane are decoupled but linked via a reelable Tether Control Line. Beneath the Skycrane, centered on its hull, a patented NIST (National Institute of Standards and Technology) RoboCrane, featuring a computer controlled six degrees of freedom (DoF) cabling system, is attached, to precisely suspend and control a Loadframe, with or without payload. During subsonic forward flight, these Airship and Skycrane are coupled as a single airframe: fuselage and delta wing.","['B64B1/70', 'B64B1/02', 'B64B1/06']"
US8252975B2,Genetically modified plants which synthesize a low amylose starch with increased swelling power,"The present invention relates to genetically modified monocotyledonous plant cells and plants whose starch has an apparent amylose content of less than 5% by weight and an increased activity of a protein with the activity of a starch synthase II and an increased activity of a protein with the activity of a glucan, water dikinase. Such plants synthesize starch with an increased hot-water swelling power. Methods and processes for the generation/preparation of these plant cells, plants, starches and flours are likewise subject matter of the present invention.","['C12N15/8245', 'A23L29/212', 'C12N9/1051', 'C12N9/1294']"
US8162859B2,Shock wave treatment device and method of use,"The system for treating an internal organ has a generator source for producing a shock wave connected to a portable shock wave applicator device, wherein the shock wave applicator device has a side-firing shock wave head having a variable angle adjustment relative to a release and lock connected handle or holder means for holding said device. The inclination of the shock wave head can be set to a fixed inclination to reach the organ at various locations or surfaces or can be pivotally inclined continuous to vary the treatment surfaces area.","['A61H23/008', 'A61B17/22004', 'A61B46/17', 'A61B90/30', 'A61B2017/00703', 'A61H23/00']"
US7889950B2,Kernel regression for image processing and reconstruction,"A method of image processing using kernel regression is provided. An image gradient is estimated from original data that is analyzed for local structures by computing a scaling parameter, a rotation parameter and an elongation parameter using singular value decomposition on local gradients of the estimated gradients locally to provide steering matrices. A steering kernel regression having steering matrices is applied to the original data to provide a reconstructed image and new image gradients. The new gradients are analyzed using singular value decomposition to provide new steering matrices. The steering kernel regression with the new steering matrices is applied to the noisy data to provide a new reconstructed image and further new gradients. The last two steps are repeated up to ten iterations to denoise the original noisy data and improve the local image structure.","['G06T3/4084', 'G06T5/20', 'G06T5/70', 'G06T5/73', 'G06V10/30', 'G06V10/34', 'G06T2207/20012', 'G06T2207/20028', 'G06T2207/20192', 'G06T2207/20204']"
CA2761187C,Systems and methods for the autonomous production of videos from multi-sensored data,"An autonomous computer based method and system is described for personalized production of videos such as team sport videos such as basketball videos from multi- sensored data under limited display resolution. Embodiments of the present invention relate to the selection of a view to display from among the multiple video streams captured by the camera network. Technical solutions are provided to provide perceptual comfort as well as an efficient integration of contextual information, which is implemented, for example, by smoothing generated viewpoint/camera sequences to alleviate flickering visual artefacts and discontinuous story-telling artefacts. A design and implementation of the viewpoint selection process is disclosed that has been verified by experiments, which shows that the method and system of the present invention efficiently distribute the processing load across cameras, and effectively selects viewpoints that cover the team action at hand while avoiding major perceptual artefacts.","['H04N5/262', 'G11B27/034', 'G11B27/105', 'H04N5/268']"
CA2642041C,Spatio-temporal pattern recognition using a spiking neural network and processing thereof on a portable and/or distributed computer,"A system and method for characterizing a pattern, in which a spiking neural network having at least one layer of neurons is provided. The spiking neural network has a plurality of connected neurons for transmitting signals between the connected neurons. A model for inducing spiking in the neurons is specified. Each neuron is connected to a global regulating unit for transmitting signals between the neuron and the global regulating unit. Each neuron is connected to at least one other neuron for transmitting signals from this neuron to the at least one other neuron, this neuron and the at least one other neuron being on the same layer. Spiking of each neuron is synchronized according to a number of active neurons connected to the neuron. At least one pattern is submitted to the spiking neural network for generating sequences of spikes in the spiking neural network, the sequences of spikes (i) being modulated over time by the synchronization of the spiking and (ii) being regulated by the global regulating unit. The at least one pattern is characterized according to the sequences of spikes generated in the spiking neural network.","['G06N3/049', 'G06V10/451', 'G06V10/758']"
US8280126B2,Cartilage curvature,A method for the analysis of three dimensional scan data representing an articular cartilage is provided to extract a quantitative parameter indicative of joint pathology. A measure of local curvature of the cartilage is determined within a region of interest. The value of the quantitative parameter of this joint derived from this measure is compared with the value of a similar quantitative parameter previously established in respect of healthy joints and/or joints characterized by a pathology.,"['A61B5/055', 'A61B5/4514', 'A61B5/4528', 'G06T7/0012', 'G06T7/64', 'A61B5/7267', 'G06T2207/30008']"
CA2704315C,Antibodies to gdf8 and uses thereof,"The disclosure provides novel molecules related to growth and differentiation factor 8 (GDF8), in particular epitopes spe-cific to GDF8 and other specific antagonists of GDF8 in particular anti GDF8 antibodies or antigen binding protein or fragment thereof that may inhibit GDF8 activity and signal in vitro and/or in vivo. The dis-closure also provides for an immunoassay used to detect and quantitate GDF8. The disclosure also provides methods for diagnosing, prevent-ing, ameliorating, and treating GDF8 associated disorders, e.g., de-generative orders of muscle, bone, and insulin metabolism. Finally, the disclosure provides pharmaceuticals for the treatment of such dis-orders by using the antibodies, polypeptides, polynucleotides, and vec-tors of the invention.","['C07K16/22', 'A61K39/395', 'A61P11/00', 'A61P15/00', 'A61P19/00', 'A61P19/08', 'A61P19/10', 'A61P21/00', 'A61P21/02', 'A61P25/00', 'A61P3/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P5/00', 'A61P5/18', 'A61K2039/505', 'C07K2317/56', 'C07K2317/565', 'C07K2317/76', 'C07K2317/92', 'C07K2317/94']"
JP4943410B2,Fibroblast growth factor-like polypeptide,"The present invention provides nucleic acid molecules encoding Fibroblast Growth Factor-like (FGF-like) polypeptides. The invention also provides vectors, host cells, and methods for producing FGF-like polypeptides. Also provided for are methods for the diagnosis and treatment of diseases associated with FGF-like polypeptides","['C07K14/50', 'A61P1/00', 'A61P1/04', 'A61P1/16', 'A61P1/18', 'A61P11/00', 'A61P11/16', 'A61P13/00', 'A61P13/12', 'A61P15/00', 'A61P15/08', 'A61P17/00', 'A61P17/02', 'A61P17/14', 'A61P19/02', 'A61P19/10', 'A61P21/00', 'A61P21/02', 'A61P25/00', 'A61P25/08', 'A61P25/16', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P35/00', 'A61P37/00', 'A61P37/02', 'A61P37/04', 'A61P43/00', 'A61P5/06', 'A61P5/26', 'A61P7/00', 'A61P9/00', 'A61P9/02', 'A61P9/10', 'A61K38/00', 'C07K2319/30', 'C12N2310/111', 'G01N2333/50']"
CN101981294B,Gas turbine control method and controller,"Provided is gas turbine control method and controller whereby a design performance and an operating state based on ideal fuel flow rate and air flow rate assumed at the time of designing can be maintained by preventing an operation deviated from an operating state that is based on ideal fuel flow rate and air flow rate assumed by initial design values, in a gas turbine control method designed to search optimal operating conditions automatically using control inputs such as a pilot ratio. The gas turbine controller comprises a second database that stores load sensitivity, i.e. the correlation between the load amount of a gas turbine and control inputs such as a fuel flow rate, air flow rate, pilot fuel ratio, and top hat fuel ratio in the gas turbine, wherein the amount of load variation for at least one of control inputs, a fuel flow rate or an air flow rate supplied to a combustor is predicted according to operational conditions obtained by searching using the load sensitivity, regulation is made according to the prediction results, and the regulation results are stored in the second database.","['F02C9/28', 'F02C9/34', 'F02C9/50', 'F05D2270/44']"
CN102395710B,Electrolytic cell and method of use thereof,"In one embodiment of the present invention an electrolytic cell is provided comprising a containment vessel; a first electrode; a second electrode; a source of electrical current in electrical communication with the first electrode and the second electrode; an electrolyte in fluid communication with the first electrode and the second electrode; a gas, wherein the gas is formed during electrolysis at or near the first electrode; and a separator; wherein the separator includes an inclined surface to direct flow of the electrolyte and the gas due to a difference between density of the electrolyte and the combined density of the electrolyte and the gas such that the gas substantially flows in a direction distal to the second electrode.","['C25B9/19', 'C01B32/225', 'C04B35/536', 'C25B1/00', 'C25B1/02', 'C25B1/04', 'C25B11/02', 'C25B11/03', 'C25B13/02', 'C25B15/00', 'C25B15/02', 'C25B15/08', 'C25B9/00', 'C25B9/05', 'C25B9/17', 'F02B43/08', 'F24S20/20', 'F28D7/103', 'C02F2001/46171', 'Y02B10/20', 'Y02E10/40', 'Y02E60/36', 'Y02T10/30', 'Y02W10/33', 'Y02W10/37', 'Y10T156/1059', 'Y10T29/49947', 'Y10T428/24322', 'Y10T428/26']"
US8357189B2,Physiology enhancing device,"A physiology enhancing device for improving physiological functions of a human body, etc., which comprises a heat generating element making use of chemical energy and a sheet interposed between the heat generating element and a body surface of a wearer, and which is designed to supply steam generated from the heat generating element while the device is applied to the body surface. The device exhibits steam generating capability for 2 hours or longer and, while applied to the body surface, raises the body surface temperature to a temperature from 38Â° C. to lower than 42Â° C. within one hour from the application. The sheet interposed between the heat generating element and the body surface preferably has a function of regulating air feed to the heat generating element and a function of transferring the heat of the physiology enhancing device to the body surface and preferably has a total thickness of 0.05 to 1.5 mm.","['A61F7/034', 'C09K5/18', 'A61F2007/0062', 'A61F2013/00187', 'A61F2013/00919', 'A61H2201/0207', 'A61H2201/0242', 'A61H2201/025', 'A61H2201/0278', 'A61H2201/0292', 'A61H2201/10']"
US9470801B2,Gating with anatomically varying durations,"A method for reconstructing a radioactive emission image of an overall volume having first and second volumetric regions, each volumetric region having respectively independent dynamic characteristics. The method comprises the following steps: a) obtaining radioactive emissions from the overall volume, including the volumetric regions, b) reconstructing an initial radioactive emission image of the volumetric region according to the radioactive emissions, c) segmenting the initial radioactive emission image to delineate the first and second volumetric regions, and d) separately reconstructing the first and the second volumetric regions according to the respectively independent dynamic characteristics.","['G01T1/1644', 'A61B5/055', 'A61B5/415', 'A61B5/416', 'A61B5/418', 'A61B6/037', 'G01T1/1663', 'G06T11/005', 'G06T11/006', 'G06T11/008', 'A61B5/7285', 'A61B6/503', 'A61B6/541', 'A61B8/0883', 'A61B8/543', 'G06T2207/10104', 'G06T2207/30048', 'G06T2211/436']"
US8352228B2,Method for predicting petroleum expulsion,A method for predicting petroleum production is provided. An exemplary embodiment of The computer-implemented comprises computing a first approximation of an amount of generated petroleum that is retained with a complex organic product using a Threshold and a Maximum Retention value. The exemplary method also comprises revising the first approximation by approximating a process of chemical fractionation using at least one partition factor to create a revised approximation and predicting petroleum production based on the revised approximation.,"['E21B43/00', 'E21B43/24', 'E21B49/00']"
US20240355018A1,Utilizing a diffusion neural network for mask aware image and typography editing,"The present disclosure relates to systems, methods, and non-transitory computer readable media for utilizing a diffusion neural network for mask aware image and typography editing. For example, in one or more embodiments the disclosed systems utilize a text-image encoder to generate a base image embedding from a base digital image. Moreover, the disclosed systems generate a mask-segmented image by combining a shape mask with the base digital image. In one or more implementations, the disclosed systems utilize noising steps of a diffusion noising model to generate a mask-segmented image noise map from the mask-segmented image. Furthermore, the disclosed systems utilize a diffusion neural network to create a stylized image corresponding to the shape mask from the base image embedding and the mask-segmented image noise map.","['G06T11/60', 'G06T11/001', 'G06T13/00', 'G06T5/50', 'G06T5/70', 'G06T7/11', 'G06T7/50', 'G06T2200/24', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20212']"
CN109011046B,Device for delivering a fluid to a target,"A jetting device (100) for jetting droplets onto a surface, comprising a jetting mechanism (108) attached to a fluid reservoir (102) by a fluid load plate (104), the fluid load plate (104) configured to pierce the reservoir and direct fluid by capillary action to a rear surface of the jetting mechanism (108). The ejection mechanism (108) may have a centrosymmetric configuration with a lead-free piezoelectric actuator, and may be covered by an automatically closing lid.","['B05B17/0646', 'A61M11/00', 'A61F9/0008', 'A61M11/005', 'A61M15/00', 'A61M15/025', 'B05B17/0661', 'B05B17/0676', 'A61F9/00', 'A61M2210/0612']"
CN102395709B,Apparatus and method for gas capture during electrolysis,"An electrolytic cell comprising a pair of electrodes connected to a source of electrical current an electrolyte in fluid communication with the electrodes; a first gas, formed at the first electrode; a second gas formed at the second electrode; a separator, and first and second gas collection vessels. The separator includes a first inclined surface to direct flow of the electrolyte and the first gas in a direction distal the second electrode and towards the first gas collection vessel due to a difference between density of the electrolyte and combined density of the electrolyte and the first gas. The separator includes an second inclined surface to direct flow of the electrolyte and the second gas in a direction distal the first electrode and towards the second gas collection vessel due to a difference between density of the electrolyte and combined density of the electrolyte and the second gas.","['C25B9/19', 'C25B11/02', 'C25B1/04', 'C25B11/03', 'C25B13/02', 'C25B15/083', 'F02B43/08', 'H01M8/02', 'H01M8/16', 'C02F2001/46171', 'Y02E60/36', 'Y02E60/50', 'Y02T10/30', 'Y02W10/33', 'Y02W10/37', 'Y10T156/1059', 'Y10T29/49947', 'Y10T428/24322', 'Y10T428/26']"
CA2656202C,Treatment of neurodegenerative diseases through inhibition of hsp90,"Treatment of neurodegenerative diseases is achieved using small molecule purine scaffold compounds that inhibit Hsp90 and that possess the ability to cross the blood-brain barrier or are otherwise delivered to the brain.
(see above formula)","['C07D473/40', 'A61K31/52', 'A61P21/00', 'A61P21/02', 'A61P25/00', 'A61P25/14', 'A61P25/16', 'A61P25/28', 'A61P25/36', 'A61P39/02', 'A61P43/00']"
CN117296061A,Diffusion model with improved accuracy and reduced computing resource consumption,"A computer-implemented method for using a diffusion model with improved accuracy, comprising: obtaining input data, the input data comprising one or more channels; providing the input data to a machine learning diffusion model, the machine learning diffusion model comprising: a noise adding model comprising a plurality of noise adding stages, the noise adding model configured to introduce noise to receive input data and to generate intermediate data in response to receipt of the input data; and a denoising model configured to reconstruct output data from the intermediate data; and receiving, by the computing system, output data from the machine-learned diffusion model. The diffusion model may include a learned noise schedule. Additionally and/or alternatively, the input of the denoising model may comprise a set of fourier features. Additionally and/or alternatively, the diffusion model may be trained based at least in part on the continuous time loss of the evidence lower bound.","['G06N3/048', 'G06N3/088', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/084', 'G10L21/0208']"
US20240135611A1,Neural compositing by embedding generative technologies into non-destructive document editing workflows,"One or more aspects of the method, apparatus, and non-transitory computer readable medium include obtaining an original image, a scene graph describing elements of the original image, and a description of a modification to the original image. The one or more aspects further include updating the scene graph based on the description of the modification. The one or more aspects further include generating a modified image using an image generation neural network based on the updated scene graph, wherein the modified image incorporates content based on the original image and the description of the modification.","['G06T11/60', 'G06T3/40', 'G06T5/50', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20221']"
US20250103868A1,Image generation using neural networks,"Apparatuses, systems, and techniques to generate an image using a neural network based model using a variable error threshold. In at least one embodiment, one or more neural networks are used to generate a final output image by iteratively removing noise from an initial image based, at least in part, on one or more variable error threshold values.","['G06N3/0475', 'G06N3/045', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN103890561B,The optical detection of particle and analysis,"The present invention provides a kind of method that analysis comprises the sample of time micron particle, and the method comprises: determine the first information about size of particles and number of particles in this sample by nanoparticle trace analysis; In this sample, the 2nd information of the average particle size about particle is determined by dynamic light scattering; Determine to represent three information of detected particle for the theoretical impact of the result obtained by dynamic light scattering from this first information; And use the 3rd information to adjust the 2nd information to produce the 4th information representing the institute's adjustment information about average particle size.","['G01N15/14', 'G01N15/0211', 'G01N15/1459', 'G01N21/49', 'G01N2015/0038', 'G01N2015/0222', 'G01N2015/0238', 'G01N2015/025', 'G01N2015/0277']"
JP5460642B2,Multi-component vaccine,"Multicomponent vaccines are provided which aid in the prevention and treatment of staphylococcal infections and which include certain selected combinations of bacterial binding proteins or fragments thereof, or antibodies to those proteins or fragments. By careful selection of the proteins, fragments, or antibodies, a vaccine is provided that imparts protection against a broad spectrum of Staphylococcus bacterial strains and against proteins that are expressed at different stages of the logarithmic growth curve. In one embodiment of the invention, a composition is provided that includes at least a collogen binding protein or peptide (or an appropriate site directed mutated sequence thereof) such as CNA, or a protein or fragment with sufficiently high homology thereto, in combination with a fibrogen binding protein, preferably Clumping factor A (""ClfA"") or Clumping factor B (""ClfB""), or a useful fragment thereof or a protein or fragment with sufficiently high homology thereto. The vaccines and products of the present invention are advantageous in that they respond to the urgent need of the medical community for a sustitute for small molecule antibiotics, which are rapidly losing effectiveness and provide effective combinations of the large number of known bacterial surface adhesins which can impart effective protection against a broad spectrum of bacterial infections.","['A61K39/395', 'C07K16/1275', 'A61K39/085', 'A61P31/04', 'A61P37/04', 'A61P39/02', 'C07K14/31', 'C07K16/1271', 'A61K2039/505', 'A61K39/00']"
US12413829B2,Systems and methods for controllable video generation,"Embodiments described herein provide a video generation framework built on a decoupled multimodal cross-attention module to simultaneously condition the generation on both an input image and a text input. The video generation may thus be conditioned on the visual appearance of a target object reflected in the input image. In this way, zero-shot video generation may be achieved with little fine-tuning efforts.","['H04N21/816', 'G06F40/00', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T11/00', 'G06T13/20', 'G06T13/80', 'G06T15/20', 'G06T17/00', 'G06T5/70', 'G06T9/00', 'G06T2207/20182']"
CN115794999B,Patent document query method based on diffusion model and computer equipment,"The application discloses a patent document query method based on a diffusion model and computer equipment, and aims to solve the problem that the completeness and accuracy of the existing patent retrieval are not ideal. The method comprises the steps of obtaining a plurality of keywords through word segmentation for a short text input by a user, and respectively sending the keywords into three diffusion models for diffusion generation, wherein clusters of the keywords in word segmentation results are jointly used as control signals of the diffusion models to limit the diffusion generation direction; the training corpora of the three diffusion models are respectively derived from the abstract, the claim and the specification and are used for correspondingly generating sentences similar to the sentence expression forms of the abstract, the claim and the specification; after retrieval, performing weighted integration on the three groups of patent documents, and selecting and outputting a plurality of patent documents with the highest similarity after weighting as the intention retrieval result of the user; therefore, the retrieval result is comprehensive and more accords with the real retrieval intention of the user, and the completeness and the accuracy of patent retrieval are improved.",['Y02D10/00']
US11995512B2,Scalable neutral atom based quantum computing,"The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation.","['G06N10/00', 'G06N10/40', 'G06N10/60', 'G06N20/20', 'G06N3/002', 'G06N3/047', 'G06N3/08', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US12118976B1,Computer-implemented method and computer system for configuring a pretrained text to music AI model and related methods,"The method involves configuring a pretrained text to music AI model that includes a neural network implementing a diffusion model. The process includes receiving audio sample data corresponding to a specific audio concept, generating a concept identifier token based on the audio sample data, adapting a loss function of the diffusion model based on the concept identifier token, selecting pivotal parameters in weight matrices in a self-attention layer of the neural network of the AI model based on the audio sample data, and further training the pivotal parameters of the AI model, to optimize the AI model for the specific audio concept.",['G10L13/027']
WO2025039694A1,"Image enhancement method and apparatus, electronic device, computer-readable storage medium, and computer program product","The present application provides an image enhancement method and apparatus, an electronic device, a computer-readable storage medium, and a computer program product, which can be applied to various scenarios such as cloud technology, artificial intelligence, intelligent traffic and assisted driving. The method comprises: acquiring a latent variable of an object image to be enhanced, and adding noise to the latent variable to obtain a noisy latent variable of the object image, the object image being an image of a target object; extracting object structure features of the target object in the object image; on the basis of the object structure features, denoising the noisy latent variable to obtain a denoised latent variable of the object image; and on the basis of the denoised latent variable, performing image reconstruction to obtain a first object enhanced image of the object image.","['G06T3/4053', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06V10/454', 'G06T2207/20084']"
WO2024242633A1,Text image generation method and diffusion generative model training method,"Provided in the embodiments of the present disclosure are a text image generation method and a diffusion generative model training method. The text image generation method comprises: acquiring an initial image; inputting the initial image into a conditional encoder, so as to obtain an image feature of the initial image; inputting the initial image and the image feature into a diffusion generative model, so as to obtain noise data corresponding to the initial image, wherein the diffusion generative model is obtained by means of performing training on the basis of a sample text image, a sample image feature of the sample text image and a noise sample image, the noise sample image is obtained by means of adding sample noise to the sample text image, and the sample image feature comprises at least one of a sample visual feature and a sample semantic feature; and according to the initial image and the noise data, generating a target text image corresponding to the initial image.","['G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T11/60', 'G06V10/774', 'G06V10/82', 'G06V30/14']"
CN104012063B,Controller for flexible and extensible flow processing in software-defined networks,"A network device acts as a controller within a software-defined network. The network device receives a processing definition, which includes a representation of configurable definitions of protocols, configurable flow table definitions, and configurable logic for selecting between flow tables defined by the configurable flow table definitions. The network device translates the processing definition to create a parser configuration package, which is distributed to a plurality of forwarding elements. This distribution causes each forwarding element to create a flow table based on each of the configurable flow table definitions. The flow tables include one or more configurable key columns and a set of one or more action columns to store forwarding decisions. The network device transmits data to populate the configurable key columns and action columns of the flow tables created within each of the plurality of forwarding elements.","['H04L47/2441', 'H04L67/63', 'H04L69/22']"
US20240185498A1,Graphic rendering using diffusion models,"A system or method for generating computer graphics. One or more three-dimensional (3D) scenes are obtained and rasterized into a first set of two-dimensional (2D) images having a first resolution. Features are extracted from the first set of 2D images, and text prompts are generated based on the features. A diffusion model is applied to the features, and the text prompts to generate a second set of 2D images having a second resolution greater than the first resolution. The diffusion model is trained over a dataset comprising images and corresponding text descriptions to generate an image consistent with a text prompt. The second set of 2D images having the second resolution are caused to be rendered at a client device.","['G06T15/00', 'G06V10/7715', 'G06T11/40', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2210/32']"
US20240169500A1,Image and object inpainting with diffusion models,"Systems and methods for image processing are described. Embodiments of the present disclosure receive an image comprising a first region that includes content and a second region to be inpainted. Noise is then added to the image to obtain a noisy image, and a plurality of intermediate output images are generated based on the noisy image using a diffusion model trained using a perceptual loss. The intermediate output images predict a final output image based on a corresponding intermediate noise level of the diffusion model. The diffusion model then generates the final output image based on the intermediate output image. The final output image includes inpainted content in the second region that is consistent with the content in the first region.","['G06T5/77', 'G06T5/005', 'G06N3/0464', 'G06N3/08', 'G06T11/60', 'G06T5/003', 'G06T5/60', 'G06T5/73', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104']"
US20240161462A1,Embedding an input image to a diffusion model,"Systems and methods for image editing are described. Embodiments of the present disclosure include obtaining an image and a prompt for editing the image. A diffusion model is tuned based on the image to generate different versions of the image. The prompt is then encoded to obtain a guidance vector, and the diffusion model generates a modified image based on the image and the encoded text prompt.","['G06T11/60', 'G06V10/774', 'G06F40/30', 'G06N3/0464', 'G06N3/08', 'G06T11/00', 'G06T5/002', 'G06T5/60', 'G06T5/70', 'G06V10/776', 'G06V10/82', 'G06V10/945', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084']"
CN118470219B,Multi-view three-dimensional reconstruction method and system based on calibration-free image,"The invention discloses a multi-view three-dimensional reconstruction method and system based on a calibration-free image, and belongs to the field of computer vision. Firstly, segmenting a foreground image from a background through a SAM model, and taking the foreground image as training image data; taking the point cloud expression as input of a point cloud diffusion model PointE, generating a point cloud expression in a coarse stage, and encoding by a ResNet image encoder to obtain image characteristic data; encoding by a point cloud encoder to obtain point cloud characteristic data; based on an attention mechanism, fusing the characteristics of a single image with the characteristics of the point cloud of the coarse stage, making up for the defects of the characteristics of the point cloud of the coarse stage, and fusing a plurality of image characteristics based on a cross attention mechanism; and combining the fused multi-image characteristics to restore the details of the point cloud, and carrying out model parameter learning with a loss function of the real point cloud based on the chamfer distance so as to reconstruct the point cloud of the object. Through practical verification, the three-dimensional building method provided by the invention has the characteristics of high efficiency and high precision.","['G06T17/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06T9/001', 'G06T9/002', 'G06V10/454', 'G06V10/806', 'G06V10/82', 'Y02T10/40']"
CN117576257A,"Method, terminal and storage medium for editing face image through text","The invention discloses a method, a terminal and a storage medium for editing a face image through text, wherein the method comprises the following steps: acquiring an input image data set, and generating a first description text data set according to the input image data set; acquiring an editing instruction, and processing the first descriptive text data set according to the editing instruction to obtain a second descriptive text data set corresponding to the first descriptive text data set; denoising the input image dataset according to the second descriptive text dataset to generate an output image dataset matched with the second descriptive text dataset; the invention provides a new method for editing a face image through a natural language text, which solves the problem of limited editable attribute in the existing face image editing technology based on a generated countermeasure network, improves the convenience and user experience of face image editing, and generates a face image editing effect meeting the personalized requirements of users.","['G06T11/60', 'G06F40/166', 'G06N3/0475', 'G06N3/094', 'G06T2207/20081', 'G06T2207/20084', 'Y02D10/00']"
US20250061610A1,Image generation with legible scene text,"Systems and methods for generating images with legible scene text are described. Embodiments are configured to obtain a prompt describing a scene, where the prompt includes scene text indicating text that is intended to be shown in a generated image; encode, using a prompt encoder, the prompt to generate a prompt embedding; encode, using a character-level encoder, the scene text to generate a character-level embedding; and generate, using an image generation network, an image that includes the scene text based on the prompt embedding and the character-level embedding.","['G06F40/126', 'G06F40/103', 'G06T11/00', 'G06T3/4053', 'G06V10/82', 'G06V30/10']"
WO2025035924A1,"Method and apparatus for training text-graph model, device, and storage medium","A method and apparatus for training a text-graph model, a device, and a storage medium, relating to the artificial intelligence. The method comprises: on the basis of a training set of graph-text sample pairs, performing iterative training on a model to be trained, to obtain a text-graph model; in a training process: selecting a graph-text sample pair from the training set of graph-text sample pairs, the graph-text sample pair comprising a sample image and a description text, and the sample image comprising at least two objects; obtaining mask images corresponding to the at least two objects and associated object class names, the mask images being used for distinguishing position regions of the objects in the sample image; inputting the sample image and the description text to a model to be trained, to obtain an image prediction noise of the sample image, and inputting at least two mask images and the associated object class names to the model to be trained to obtain object prediction noises respectively associated with the at least two mask images; and constructing a loss function on the basis of the image prediction noise and the object prediction noises, and by using the loss function, adjusting a parameter for the model to be trained.","['G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06T11/00', 'G06T5/00', 'G06V10/774', 'G06V10/80', 'G06V10/82', 'G06V20/70']"
US12321831B1,Automated detection of content generated by artificial intelligence,"In some embodiments, at a first time, a computing system receives a classification request specifying query content. The system executes a first pre-trained AI-generated content classifier in the set of AI-generated content classifiers on the query content to compute a set of confidence scores proportional to predicted probabilities that the query content includes content data produced by a generative AI model. The set of confidence scores is generated based on parameters learned by the first pre-trained AI-generated content classifier during a training stage. The classification results are output based on the set of confidence scores at approximately the first time.","['G06N20/00', 'G06N3/045', 'G06N5/04']"
CN117409192B,A data-enhanced infrared small target detection method and device,"The invention discloses a data enhancement-based infrared small target detection method and device, which are used for overcoming the problem that the acquisition and labeling of the existing infrared small targets are challenging, so that the quantity cannot meet the requirements of a CNN-based deep learning detection model, and an effective infrared small target image amplification method with diversity is not available. Firstly, a clean background image is obtained by adopting a background filling method, and a diffusion model is used for generating a more complex and diversified background image; then, a target self-adaptive fusion method based on a generated countermeasure network is designed, a target mask and a generated background image are fused better, and a more realistic infrared small target enhanced image can be generated. The invention solves the complex problem of infrared small target image enhancement, and decomposes the complex problem into two relatively simple problems by a two-stage method. By the amplification of the infrared small target image, the existing data set is amplified, so that the detection model can obtain a better detection effect.","['G06V10/25', 'G06V10/30', 'G06V10/774', 'G06V10/80', 'G06V10/82', 'G06V2201/07', 'Y02T10/40']"
CN118295029B,Seismic data denoising method integrating self-attention and Mamba architecture,"The invention discloses a seismic data denoising method integrating self-attention and Mamba framework, which belongs to the technical field of geophysics and is used for denoising seismic data, and comprises the steps of collecting noisy seismic data, denoising the noisy seismic data to obtain a plurality of denoised seismic data blocks; and inputting noise time steps corresponding to the denoised seismic data blocks and the seismic data blocks to a lightweight self-attention Mamba module, normalizing the adaptive layer, then introducing the adaptive layer into the linear change layer, carrying out noise prediction and covariance prediction, and training and verifying the lightweight self-attention Mamba module. The invention overcomes the defects of the existing seismic data denoising technology, improves the denoising effect, enhances the stability of network training, reduces the calculation cost, realizes stable training and achieves high-efficiency denoising performance.","['G01V1/36', 'G01V1/30', 'G01V2210/32']"
US10317498B2,Methods and apparatus for modeling diffusion-weighted MR data acquired at multiple non-zero B-values,"Methods and apparatus for characterizing biological micro structure in a voxel based, at least in part, on a set of diffusion-weighted magnetic resonance (MR) data. A multi-compartment parametric model is used to predict a diffusion signal for the voxel using information from the set of diffusion-weighted MR data. Predicting the diffusion signal comprises determining, based on the set of diffusion-weighted MR data, a first set of parameters describing isotropic diffusion in a first compartment of the multi-compartment model and a second set of parameters describing anisotropic diffusion due to the presence of at least one white matter fascicle in a second compartment of the multi-compartment model. At least one first dataset of the set of diffusion-weighted MR data is associated with a first non-zero b-value and at least one second dataset of the set of diffusion-weighted MR data is associated with a second non-zero b-value different than the first non-zero b-value.","['G01R33/56341', 'A61B5/055', 'G01R33/5608', 'A61B2576/026', 'G16H30/40']"
CN117011207A,Virtual fitting method based on diffusion model,"The invention discloses a virtual fitting method based on a diffusion model, which comprises the steps of firstly, acquiring a two-dimensional human body image and target clothes; then extracting two-dimensional human body image information; twisting the target clothing to generate twisted clothing; generating mask images of the arms and the dressing change area; gradually adding noise to the two-dimensional human body image to obtain a noise image of the T step; sending the noise image of the step T to a reverse sampling denoising module, and generating a fitting synthetic prediction noise image under the condition of distorting the clothing and the human skeleton posture image; fusing the fitting synthesis prediction noise map with the noise map of the forward noise adding module in the corresponding step through the mask image to obtain a fused noise map; gradually removing noise to obtain the final fitting synthetic image. The invention adopts the diffusion model to overcome the inherent defects of the generated countermeasure network, effectively solves the problem of serious shielding of the limb part, improves the stability of the training effect and generates good fitting effect.","['G06T5/50', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/094', 'G06Q30/0643', 'G06V10/26', 'G06V10/82', 'G06V10/85', 'G06V20/70', 'G06V40/103', 'G06T2207/20221', 'G06T2207/30196', 'Y02P90/30']"
US20180114096A1,Machine learning to process monte carlo rendered images,A method of rendering an image includes Monte Carlo rendering a scene to produce a noisy image. The noisy image is processed to render an output image. The processing applies a machine learning model that utilizes colors and/or features from the rendering system for denoising the noisy image and/or to for adaptively placing samples during rendering.,"['G06N3/084', 'G06K9/6256', 'G06F18/214', 'G06N7/01', 'G06T15/06', 'G06T15/50', 'G06T5/002', 'G06T5/60', 'G06T5/70', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US8263558B2,Methods of preparation of recombinant forms of human beta-amyloid protein and uses of these proteins,"The subject invention relates to the cloning, expression and isolation of recombinant forms of beta-amyloid protein containing a N-terminal methionine (or one or more amino acids) as well as to methods of using this recombinant protein in the production of therapeutic antibodies, in the identification of therapeutic small molecules, and in the performance of diagnostic assays.","['C07K14/4711', 'A61P25/00', 'A61P25/28', 'C07K16/18', 'A61K38/00']"
CN119943242A,A multimodal large language model data management system for medical applications,"The invention discloses a multi-mode large language model data management system which comprises a data transmission module, a data sharing contract customization module, an optimal contract generation module, a multi-mode large language model pre-training module, a mixed multi-mode retrieval enhancement generation module and a multi-mode large language model reasoning optimization module. The system constructed by the invention can efficiently encourage the data provider to share high-quality and fresh data, fundamentally solve the problem of information asymmetry, adapt to continuously-changed data sharing environments, ensure the realization of efficient data sharing and utilization under various complex conditions, improve the stability and reliability of the system, realize the safety and the high efficiency of medical data management and application by means of a cross-link technology and a mixed multi-mode RAG framework, mutually cooperate all parts, ensure the safety and the efficiency of data processing and sharing processes, and simultaneously enhance the output performance of MLLM.",[]
US20230153949A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate one or more images. In at least one embodiment, one or more neural networks are used to generate one or more images based, at least in part, on one or noise values.","['G06T5/70', 'G06T1/20', 'G06T5/002', 'G06N20/00', 'G06N3/084', 'G06N5/04', 'G06T1/60', 'G06T5/60', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
WO2025050542A1,Diffusion model and generative adversarial network-based image segmentation method and apparatus,"Disclosed in the present invention are a diffusion model and generative adversarial network-based image segmentation method and apparatus, which are applied to the technical field of image processing. The method comprises: preprocessing a raw image; training a diffusion model for a preprocessed image and outputting a predicted label image; training a discriminator model for the predicted label image and outputting a predicted classification label image; jointly training the diffusion model and a discriminator by using a generative adversarial network and outputting a parameter of the diffusion model and a parameter of the discriminator model; and segmenting the preprocessed image on the basis of the parameter of the diffusion model and the parameter of the discriminator model, so that the misleading by an individual piece of information in a denoising process is avoided and the robustness of the model is improved. In the training process, by splicing the raw image and label data, extraction of blood vessels is more accurate. The generative adversarial network trains the discriminator and the diffusion model, so that the network training is converged in an accelerated mode and the accuracy of segmentation is improved.","['G06T7/11', 'G06T7/0012', 'G06T2207/20081', 'G06T2207/30101', 'Y02T10/40']"
US20240104698A1,Neural network-based perturbation removal,"Apparatuses, systems, and techniques are presented to remove unintended variations introduced into data. In at least one embodiment, a first image of an object can be generated based, at least in part, upon adding noise to, and removing the noise from, a second image of the object.","['G06N3/045', 'G06T5/70', 'G06T5/002', 'G06N3/044', 'G06N3/0445', 'G06N3/047', 'G06N3/0472', 'G06T5/50', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
CN118365984A,CGADM text description image generation method combining generative adversarial network and diffusion model,"The invention discloses a method for generating images by combining CGADM (Combine GAN And Diffusion Model) text descriptions for generating an antagonism network and a diffusion model, which comprises the steps of constructing a three-layer stacked network model, inputting an original text into a trained CGADM model, and obtaining a final high-resolution image containing emotion characteristics; the CGADM model also replaces a charCNN +RNN text encoder of a sublayer network of the model before improvement with a text encoder of a CLIP, further increases the processing capacity of the text model on complex texts containing various feature information, further understands the semantic information of the texts, and uses the non-physical features such as emotion and other multielement features contained in the texts to guide the image generation; and a VAE codec model, a U-Net model and a stable diffusion model are introduced as a third layer model of the network, and a generated image definitely generated by a sub-layer model object is input to replace a noise image of the original stable diffusion model, so that possible catastrophic neglect of the stable diffusion model is effectively avoided.","['G06V10/774', 'G06N3/0464', 'G06N3/094']"
CN117911355A,A method for improving CBCT image quality based on generative adversarial diffusion model,"The invention provides a method for improving CBCT image quality based on generation of an anti-diffusion model, wherein x 0 is a source domain image, y 0 is a target image, and the aim of the invention is to realize conversion from x 0 to y 0 by using the diffusion model. The diffusion model adds T steps of Gaussian noise to y 0 in the forward direction to obtain y t, and predicts y t by using a neural network in the reverse direction to obtain y tâ1. The invention does not need the mapping relation between the source domain image and the target domain image, because a function is designed for extracting the same point and different points between the source domain image and the target domain image and restraining the same in the training process.","['G06T7/001', 'G06N3/04', 'G06N3/08', 'G16H20/10', 'G16H20/40', 'G06T2207/10081']"
US20230419075A1,Automated Variational Inference using Stochastic Models with Irregular Beliefs,"A system and method for automated construction of a stochastic deep neural network (DNN) architecture is provided. The framework of invention automatically searches for most relevant stochastic modes underlaying datasets for variational Bayesian inference. The invention provides a way to use heterogenous, irregular, and mismatched beliefs in stochastic sampling for intermediate representation in DNNs with a capability of an automatically tuning mechanism of posterior, prior, and likelihood models to enable accurate generative models and uncertainty models for machine learning tasks. The system further allows adjustable discrepancy measure to regularize intermediate representation by variants of divergence metrics including Renyi's alpha, beta, and gamma divergences. The invention enables diverse mixture combinations of stochastic models for misspecified and unspecified probabilistic relations in an automatic fashion. Accordingly, the representation capability of variational autoencoders, variational information bottlenecks, denoising diffusion probabilistic models and other stochastic DNNs are improved.","['G06N3/047', 'G06N3/04', 'G06N3/0455', 'G06N3/082', 'G06N3/084', 'G06N3/0895']"
CN117961976B,Assembly robot online detection method and device based on generated diffusion migration,"Embodiments of the present application provide an assembly robot online detection method, apparatus, device, and computer-readable storage medium based on generating diffusion migration. The method comprises the steps of obtaining signal data of an assembly robot; inputting the signal data into a trained fault identification model to obtain the fault type of the current assembly operation, wherein the fault identification model can be trained by the following modes: acquiring a sample data set; the sample data set comprises sample data with labeling information; splitting the sample data into two subfields; based on a supervised training mode and an unsupervised training mode, learning sample data in two sub-domains by using a neural network model to obtain a target loss function; and training the fault recognition model based on the target loss function. In this way, the on-line real-time fault diagnosis of the assembly robot can be realized, and the production efficiency is greatly improved.","['B25J19/0095', 'B25J9/161', 'B25J9/1653']"
US20250218530A1,Diffusion model for generative protein design,"A system is disclosed for de novo protein generation. The system receives a set of design condition(s) that specify target characteristics of a synthetic protein. The system defines a modular energy function as a composition of a diffusion energy component and one or more conditioner energy components. The system applies a diffusion model to determine a denoised protein backbone. In applying the diffusion model, in each sampling step: the system transforms one prior sampled state of the synthetic protein from unconstrained space into constrained space based on the one or more design conditions, denoises the prior sampled state in the constrained space, and samples a subsequent sampled stated by applying a gradient of the modular energy function to the denoised prior sampled state in the constrained space. The final sampled state is a denoised protein backbone for the synthetic protein that satisfies the set of design condition(s).","['G16B15/00', 'G16B15/20', 'G16B40/00']"
US20210350934A1,Synthetic tumor models for use in therapeutic response prediction,"Systems and methods for creating therapeutic response predictions based on a synthetic tumor model generated based on micro-scale data associated with one or more parameters representative of one or more biological characteristics of tumors, where synthetic CT images constructed via back projection of the synthetic tumor model and distribution/response of one or more therapeutic therapies predicted for the synthetic tumor model are used to train an unsupervised learning model for determining a personalized treatment plan for a patient's tumor.","['G16H50/50', 'G06F18/214', 'G06F18/22', 'G06F30/23', 'G06F30/27', 'G06K9/6215', 'G06K9/6256', 'G06N3/045', 'G06N3/088', 'G06T11/006', 'G06V10/82', 'G16H20/10', 'G16H20/30', 'G16H20/40', 'G16H30/00', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G16H70/60', 'G06F2111/10', 'G06K2209/05', 'G06N20/10', 'G06N7/01', 'G06V2201/03']"
US20240212360A1,Generating object data using a diffusion model,"Techniques for generating a scene for simulation using a conditional generative model are described herein. For example, the techniques may include a generative model receiving data from a diffusion model that is usable to generate different scenes for simulation between an autonomous vehicle and one or more objects. The diffusion model can receive and/or provide condition data representing image data and/or text data associated with the object in an environment. Scenes can be generated based on condition data indicating an intersection type, a number of objects in the environment, or a scene characteristic, to name a few. The techniques described herein enable a model to generate scenes that represent potential interactions between objects.","['G06V20/58', 'G06T5/002', 'G06T5/70', 'G06T2207/20182', 'G06T2207/30242', 'G06T2207/30252']"
US20240211797A1,Training a variable autoencoder using a diffusion model,"Techniques for training a variable autoencoder to output data associated with one or more objects in an environment are described herein. For example, the techniques can include training an encoder and a decoder of the variable autoencoder to improve predictions over time. The variable autoencoder can be trained to output object occupancy information (e.g., a bounding box, heatmap, feature vector) and/or object attribute information (e.g., an object state, an object type, etc.). A vehicle computing device can use an output from a trained autoencoder during vehicle planning, which may include simulation.","['G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088']"
US20240394932A1,Text-to-image diffusion model rearchitecture,"Described is a system for improving machine learning models. In some cases, the system improves such models by identifying a performance characteristic for machine learning model blocks in an iterative denoising process of a machine learning model, connecting a prior machine learning model block with a subsequent machine learning model block of the machine learning model blocks within the machine learning model based on the identified performance characteristic, identifying a prompt of a user, the prompt indicative of an intent of the user for generative images, and analyzing data corresponding to the prompt using the machine learning model to generate one or more images, the machine learning model trained to generate images based on data corresponding to prompts.","['G06N3/0455', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T11/00', 'G06T5/60', 'G06T5/70', 'G06V10/82', 'G10L15/1815', 'G10L15/22', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G10L15/16']"
US20250225700A1,Fine-tuning diffusion-based generative neural networks using singular value decompositions for text-to-image generation,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for fine-tuning diffusion-based generative neural networks in compact parameter spaces for text-to-image generation. In one aspect, a method performed by one or more computers for fine-tuning a diffusion-based generative neural network to obtain a fine-tuned version of the diffusion-based generative neural network is described. The method includes: for each of a number of neural network layers of the diffusion-based generative neural network: obtaining an initial weight matrix including a number of pre-trained weights parametrizing the neural network layer: performing a singular value decomposition on the initial weight matrix; and re-parametrizing the neural network layer with new weights that depend on spectral sifts; and training the spectral shifts of each of the number of neural network layers of the diffusion-based generative neural network to obtain the fine-tuned version of the diffusion-based generative neural network.","['G06T11/60', 'G06T5/20', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
US12339658B2,Generating a scenario using a variable autoencoder conditioned with a diffusion model,"Techniques for performing a simulation using a variable autoencoder conditioned with a diffusion model are described herein. For example, the techniques may include a decoder of a variable autoencoder receiving latent variable data representing an action, intent, or attribute of an object from the diffusion model and outputting occupancy information for an object. The occupancy information can be input into a prediction component associated with a vehicle computing device of a vehicle. The prediction component can output a predicted state for one or more objects proximate the vehicle and perform a simulation between the vehicle and the one or more objects.","['G05D1/0088', 'B60W30/0956', 'G06F30/15', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06V10/25', 'G06V10/82', 'G06V20/59']"
US20240111894A1,Generative machine learning models for privacy preserving synthetic data generation using diffusion,"In various examples, systems and methods are disclosed relating to differentially private generative machine learning models. Systems and methods are disclosed for configuring generative models using privacy criteria, such as differential privacy criteria. The systems and methods can generate outputs representing content using machine learning models, such as diffusion models, that are determined in ways that satisfy differential privacy criteria. The machine learning models can be determined by diffusing the same training data to multiple noise levels.","['G06F21/6245', 'G06N3/0455', 'G06N3/084']"
CN116629323A,"Diffusion model optimization method, image generation method, electronic device and medium","The invention discloses an optimization method of a diffusion model, which comprises the steps of firstly randomly sampling steps from a Markov chain path of a diffusion process in a mini batch to obtain a step t in a current batch, then randomly adding noise to each pixel point in an image of the step t to obtain a noise image of the step t, predicting an original image through the model to obtain model predicted noise, calculating the mean square loss between the model predicted noise and real noise, finally sampling from a label set conforming to preset distribution to obtain an additional random label, and re-predicting the noise of the noise image based on the random label, and calculating the distribution adjustment loss. The method adjusts the conditional transition probability in the sampling process, implicitly forces the generated image to approach the target prior distribution in each sampling step, and fills up the study gap of generating model direction which is more robust for training based on long tail distribution data.","['G06N3/0475', 'G06N3/094', 'G06T11/00', 'Y02T10/40']"
US20250035741A1,Generative model for generating synthetic radar data,"In accordance with an embodiment, a method includes: obtaining a trained generative model; and using the trained generative model to generate synthetic radar data, wherein the synthetic radar data is synthetic raw radar data of sampled chirps.","['G01S7/417', 'G01S7/352', 'G01S13/88', 'G01S13/584', 'G01S7/4052', 'G01S7/415', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G01S7/4056']"
US10585937B2,"Method for visual search, corresponding system, apparatus and computer program product","Local descriptors are extracted from digital image information and digital depth information related to digital images. The local descriptors convey appearance description information and shape description information related to the digital images. Global representations of the one or more digital images are generated based on the extracted local descriptors, and are hashed. Visual search queries are generated based on the hashed global representations. The visual search queries include fused appearance description information and shape description information conveyed in the local descriptors. The fusing may occur before the global representations are generated, before the hashing or after the hashing.","['G06V20/20', 'G06F16/5854', 'G06F16/5838', 'G06F16/5846', 'G06F16/5866', 'G06V10/44', 'G06F16/583', 'G06F16/5862']"
US20240378763A1,Diffusion model virtual try-on experience,Methods and systems are disclosed for generating an extended reality (XR) try-on experience based on an image produced by a diffusion model. The system receives a first image depicting a real-world object and receives a second image depicting a target fashion item. The system generates a warped image in which pixels of the target fashion item depicted in the second image replace pixels of a portion of the real-world object in the first image and generates one or more segmentation maps corresponding to incomplete portions of the warped image. The system analyzes the warped image and the one or more segmentation maps using a generative machine learning model to generate an artificial image that populates the incomplete portions of the warped image to depict the real-world object wearing the target fashion item.,"['G06T11/00', 'G06V10/26', 'G06N3/08', 'G06Q30/0643', 'G06T11/60', 'G06T19/006', 'G06T19/20', 'G06T7/11', 'G06V20/20', 'G06T2207/20081', 'G06T2207/30196', 'G06T2210/16', 'G06T2210/44', 'G06V40/103']"
US12111744B1,Cloud-based fleet and asset management for edge computing of machine learning and artificial intelligence workloads,"An apparatus can be configured to receive monitoring information associated with a machine learning (ML) or artificial intelligence (AI) workload implemented by an edge compute unit of a plurality of edge compute units. Status information corresponding to a plurality of connected edge assets can be received, the plurality of edge compute units and connected edge assets included in a fleet of edge devices. A remote fleet management graphical user interface (GUI) can display a portion of the monitoring or status information for a subset of the fleet of edge devices, based on a user selection input, and can receive a user configuration input indicative of an updated configuration for at least one workload corresponding to a pre-trained ML or AI model deployed on the at least one edge compute unit. A cloud computing environment can transmit control information corresponding to the updated configuration to the at least one edge compute unit.","['H04L41/082', 'G06F11/3006', 'G06F11/3013', 'G06F11/3055', 'G06F11/328', 'G06F8/65', 'G06N20/00', 'G06N20/20', 'H04B7/18513', 'H04L41/0895', 'H04L41/16', 'H04L41/22', 'H04L41/40']"
US20240037822A1,Prompt-to-prompt image editing with cross-attention control,"Some implementations are directed to editing a source image, where the source image is one generated based on processing a source natural language (NL) prompt using a Large-scale language-image (LLI) model. Those implementations edit the source image based on user interface input that indicates an edit to the source NL prompt, and optionally independent of any user interface input that specifies a mask in the source image and/or independent of any other user interface input. Some implementations of the present disclosure are additionally or alternatively directed to applying prompt-to-prompt editing techniques to editing a source image that is one generated based on a real image, and that approximates the real image.","['G06T11/60', 'G06F3/04845', 'G06F40/40', 'G06N3/0455', 'G06N3/0464', 'G06N3/096']"
US20250169698A1,3d cameras or sensors inputting to multi-modal generative artificial intelligence models trained on images or videos,"3D cameras may serve as an input to a multi-modal generative artificial intelligence (GAI) model operating on a processor coupled to a non-transitory computer readable medium. Examples of 3D cameras include direct or indirect time-of-flight sensors or structured light systems and may also be coupled to 2D cameras. The GAI comprises a vision transformer configured to analyze an item in an input video or image. The vision transformer comprises self-attention and positional encoding layers. The GAI may be trained using reinforcement learning or fine-tuning involving training images or videos, and it may perform data fusion by combining the 3D information with data from other sensors. The GAI may perform anomalous occurrence detection by training on images or videos corresponding to normal occurrences. The GAI detects differences in an image or video that fall outside of a threshold value. The GAI may also provide safeguards for privacy issues.","['A61B5/0013', 'A61B5/0022', 'A61B5/0075', 'A61B5/0077', 'A61B5/0086', 'A61B5/0088', 'A61B5/0091', 'A61B5/0261', 'A61B5/14532', 'A61B5/14542', 'A61B5/14546', 'A61B5/1455', 'A61B5/4547', 'A61B5/6801', 'A61B5/682', 'A61B5/7203', 'A61B5/7257', 'A61B5/7405', 'A61B5/742', 'A61C19/04', 'G01J3/02', 'G01J3/021', 'G01J3/0218', 'G01J3/108', 'G01J3/12', 'G01J3/14', 'G01J3/28', 'G01J3/2823', 'G01J3/42', 'G01J3/453', 'G01M3/38', 'G01N21/3151', 'G01N21/35', 'G01N21/3504', 'G01N21/3563', 'G01N21/359', 'G01N21/39', 'G01N21/88', 'G01N33/02', 'G01N33/025', 'G01N33/15', 'G01N33/442', 'G01N33/49', 'G16H20/00', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16Z99/00', 'G01J2003/1208', 'G01N2201/0627', 'G01N2201/129', 'G01N2201/1296', 'H01S3/302']"
RU2569182C2,Treating diseases associated with vascular endothelial growth factor (vegf) by suppression of natural antisense vegf transcript,FIELD: medicine.,"['C12Q1/6883', 'A61K31/7088', 'A61K31/712', 'A61P1/00', 'A61P1/02', 'A61P11/06', 'A61P13/12', 'A61P15/00', 'A61P17/00', 'A61P17/02', 'A61P17/06', 'A61P19/02', 'A61P19/08', 'A61P21/02', 'A61P25/00', 'A61P25/16', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/04', 'A61P31/00', 'A61P35/00', 'A61P37/06', 'A61P37/08', 'A61P43/00', 'A61P9/00', 'A61P9/04', 'A61P9/10', 'A61P9/12', 'C12N15/1136', 'C12Q1/6816', 'C12Q1/6886', 'C12N2310/11', 'C12N2310/113', 'C12N2310/14', 'C12N2310/315', 'C12Q2600/136', 'C12Q2600/156']"
US20240320444A1,User interface for ai-guided content generation,"A computer-implemented method is disclosed. The method includes: obtaining at least one output of a generative model based on input of a first text prompt; presenting the at least one output via a user interface; receiving, via the user interface, user selection of a desired portion of the at least one output; modifying the first text prompt based on the user selection to obtain a second text prompt; and providing the second text prompt as input to the generative model for obtaining a second output.","['G06F40/166', 'G06F3/0482', 'G06F3/04842', 'G06F3/04845', 'G06F40/284', 'G06F40/40', 'G06N3/045', 'G06N3/08', 'G06T11/60', 'G06F3/0486']"
WO2024127318A1,Denoising diffusion models for digital oral care,"Systems and techniques are disclosed for automatically generating a data structure for oral care treatment using trained machine learning models. The method involves receiving one or more attributes that describe the intended output from the trained machine learning model. One or more noisy representations of the intended output are generated by one or more computer processors. These noisy representations are then denoised using a trained machine learning model, also executed by the computer processors. The denoised representations of the intended output are generated, providing more accurate and reliable data. Based on the generated denoised representations, one or more aspects of digital oral care treatments are automatically defined by the computer processors. These systems and techniques enable the creation of a comprehensive data structure for oral care treatment, enhancing treatment planning and decision-making processes in the field of oral healthcare.","['G06T17/00', 'G06T2210/41']"
CN116306588A,"An interaction-based image generation method, device, electronic equipment and storage medium","According to the embodiment of the application, by acquiring image description information submitted based on an interaction component, the interaction component can comprise a content description input component and a plurality of style description input components, the content description input component can be configured to receive the image content description information, the style description input component can be configured to receive the image style description information and corresponding information weights, then structured description text data is generated according to the image content description information, the image style description information and the information weights, the description text data is input into an image generation model, image characteristic information matched with the description text data is determined by the image generation model, and a target image is generated according to the image characteristic information. By the aid of the scheme, controllability of an artificial intelligent image generation result can be improved, and user experience is improved.","['G06F40/216', 'G06F3/0484', 'G06F40/126', 'G06F40/284', 'G06N3/0475', 'G06N3/0499', 'G06N3/094', 'G06V10/774', 'Y02D10/00']"
US12364430B2,Wearable device for continuous monitoring of user health for accurate clinical outcomes and wellness programs,"A wearable device consists of a smart band and a display unit. The smart band comprises a microbial biosensor, a particulate matter sensor, an enviro sensor, a physiological sensor, a biofluid sensor, a biokinetics sensor, a lifestyle sensor, and a single board computer. The microbial biosensor detects, measures, and monitors microorganisms, and a sterilizer kills pathogens. The particulate matter sensor detects, measures, and monitors a set of suspended particles in the surrounding air. The enviro sensor monitors environmental conditions surrounding the user. The biofluid sensor detects, measures, and monitors biological fluid parameters of the user. The physiological sensor detects, measures, and monitors physiological parameters of the user. The biokinetics sensor detects, measures, and monitors physical activities of the user. The lifestyle sensor detects, measures, and monitors healthy lifestyle activities of the user. The wearable device allows for continuous monitoring of user health for accurate clinical outcomes and wellness programs.","['A61B5/0002', 'A61B5/0022', 'A61B5/0036', 'A61B5/004', 'A61B5/0077', 'A61B5/082', 'A61B5/1112', 'A61B5/1171', 'A61B5/681', 'A61B5/7275', 'A61B5/742', 'A61B5/746', 'A61B5/7475', 'A61B5/748', 'A61L2/0011', 'G16H20/60', 'A61B2560/0214', 'A61B2560/0242', 'A61B2562/0219', 'A61B2562/0247', 'A61B2562/0271', 'A61B2562/029', 'A61B2562/06', 'A61B2576/00', 'A61B5/411', 'A61B5/6844', 'A61L2/04', 'A61L2/08', 'A61L2/10', 'A61L2/12', 'A61L2/24', 'A61L2/26', 'A61L2202/14']"
US20240101157A1,Latent variable determination by a diffusion model,"Techniques for predicting an object trajectory or scene information are described herein. For example, the techniques may include inputting latent variable data into a machine learned model. The machine learned model may output an object trajectory (e.g., position data, velocity data, acceleration data, etc.) for one or more objects in the environment based on the latent variable data. The object trajectory can be sent to a vehicle computing device for consideration during vehicle planning, which may include simulation.","['B60W50/0097', 'B60W60/0027', 'B60W40/04', 'G06N3/04', 'G06N3/045', 'B60W2050/0028', 'B60W2554/404', 'B60W2554/4046']"
CN116091288A,Diffusion model-based image steganography method,"The invention provides an image steganography method based on a diffusion model, which comprises the following steps: training the diffusion probability model by using a real image sample set to obtain an image generation model; embedding the image in the real image sample set into the image generation model to obtain a dense image; and extracting the dense image by using the image generation model to obtain a message image, and completing image steganography. The invention firstly utilizes two types of data sets to respectively train diffusion models to obtain two diffusion models, and then carries out different serial combinations on the two diffusion models to realize the embedding and extraction of the information.","['G06T1/00', 'G06N3/04', 'G06N3/08']"
WO2024184745A1,Unsupervised voice restoration with unconditional diffusion model,"The invention relates to the field of computer technologies, in particular to methods for processing and analyzing audio recordings, and may be employed for improving the quality and intelligibility of speech recordings. A method for voice restoration in speech recordings comprises the steps of receiving audio data of a speech recording containing a voice audio signal; applying a diffusion probabilistic model trained by denoising score matching objective for unconditional speech generation, wherein the diffusion probabilistic model is applied to the audio data of the speech recording in the form of a waveform comprising random Gaussian noise, iteratively sampling the waveform with a conditional score function, which is a sum of unconditional score function estimated by the diffusion probabilistic model and log-likelihood, so as to produce a sample with a reduced amount of noise for the next iteration, until a speech waveform without noise is obtained; and outputting the processed voice audio signal comprising the speech waveform without noise. A system and computer readable medium which implement the method are also provided. The technical result consists in improving the quality and intelligibility of speech recordings.","['G10L21/0208', 'G10L13/02', 'G10L21/0272', 'G10L21/038']"
WO2024249218A1,Loss determination for latent diffusion models,"Described is a system for improving machine learning models by accessing a first latent diffusion machine learning model, accessing a second latent diffusion machine learning model that was derived from the first latent diffusion machine learning model, the second latent diffusion machine learning model trained to perform a second number of denoising steps, generating noise data, processing the noise data via the first latent diffusion machine learning model to generate one or more first latent features, processing the noise data via the second latent diffusion machine learning model to generate one or more second latent features, and inputting the one or more first latent features and the one or more second latent features into a loss function. The system then modifies a parameter of the second latent diffusion machine learning model based on the output of the loss function.","['G06N3/0455', 'G06N3/096']"
US20240303764A1,Device and method for watermarking a diffusion model,"System, methods, and non-transitory computer-readable medium are provided for watermarking a diffusion model. For example, a method for watermarking a diffusion model may include generating one or more training data elements. In some aspects, the one or more trainings data elements may include target images. Moreover, the target images may include pre-defined watermark information. Further, the method may include training the diffusion model to predict the target images using training data including the one or more training data elements.","['G06T11/00', 'G06N20/00', 'G06T1/0028', 'G06T1/005', 'G06T2201/0053', 'G06T2201/0065', 'G06T2201/0202']"
US12361616B2,Image generation using a diffusion model,"Systems and methods for image generation are provided. An aspect of the systems and methods for image generation includes obtaining an original image depicting an element and a target prompt describing a modification to the element. The system may then compute a first output and a second output using a diffusion model. The first output is based on a description of the element and the second output is based on the target prompt. The system then computes a difference between the first output and the second output, and generates a modified image including the modification to the element of the original image based on the difference.","['G06T11/60', 'G06T5/70', 'G06T2200/24']"
CN117540797A,A knowledge graph completion method and system based on generative diffusion,"The invention discloses a knowledge graph completion method and system based on generation and diffusion, which belongs to the technical field of knowledge graphs and specifically comprises the following steps: the method comprises the steps of adopting a knowledge graph embedding model TransE, learning an embedding vector of a knowledge graph entity and a relation, constructing a counter fact sample generating model based on generation diffusion, constructing a semantic encoder and a conditional denoising diffusion implicit model, converting an original embedding vector into a potential semantic vector by the semantic encoder, inputting the potential semantic vector into the conditional denoising diffusion implicit model as a condition, obtaining the counter fact sample of the original embedding vector by the conditional denoising diffusion implicit model through forward and reverse diffusion processes, constructing a knowledge graph complement model based on a convolutional neural network, inputting the original embedding vector and the counter fact sample into the trained knowledge graph complement model, sequencing the prediction scores of all samples in descending order, selecting the samples with the front score sequence to complement the knowledge graph, and improving the accuracy and robustness of the knowledge graph complement.","['G06N5/02', 'G06N3/0455', 'G06N3/0464', 'G06N3/084']"
CN117909800A,Fault diagnosis method for rotating machinery based on interpretable implicit diffusion model,"The invention provides a rotary mechanical equipment fault diagnosis method based on an interpretable implicit diffusion model, which comprises the following steps: s1, collecting and preprocessing fault vibration signals, S2, constructing an interpretable implicit diffusion model, S3, generating fault vibration signals of rotary mechanical equipment, S4, constructing a diagnosis model, identifying fault types of the fault vibration signals and performing fault diagnosis. The invention collects fault vibration signals of the rotary mechanical equipment, utilizes the periodic attenuation fault impact signals of the rotary mechanical equipment, combines a vector quantization variation self-coding network to construct an interpretable implicit diffusion model, and generates new data to expand an original data set to improve the diagnostic performance of the model. According to the method, the synthetic fault vibration signal is provided for the diagnosis of the rotary mechanical equipment by the generation method based on the denoising diffusion probability model, and the diagnosis performance of the universal fault diagnosis model under the sample scarcity scene is improved.","['G06F18/241', 'G01M13/00', 'G01M13/028', 'G01M13/045', 'G06F18/15', 'G06F18/214', 'G06N3/0464']"
CN116644439B,A model security assessment method based on denoising diffusion model,"The invention belongs to the technical field of information safety, and discloses a model safety assessment method based on a denoising diffusion model, which comprises the following steps: sending the classified sample of the target model into an initial generator to generate initial data; expanding initial data by using a denoising diffusion model to generate additional data; the initial data and the additional data are fused through a residual error structure, and a multi-source query sample is obtained; training a substitution model and a generator model through multisource query samples and target model prediction results; and calculating the functional similarity of the substitution model and the target model, and evaluating the safety of the target model. Aiming at an artificial intelligent model with an unknown architecture, the method generates a high-quality multi-source query sample through the denoising diffusion model and the residual structure on the basis of not accessing the training data set of the target model, so that the target model is efficiently fitted by the substitution model, and the safety evaluation efficiency of the target model is improved.","['G06F21/57', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06V10/30', 'G06V10/761', 'G06V10/764', 'G06V10/82', 'Y02T10/40']"
US11599972B1,"Method and system for lossy image or video encoding, transmission and decoding","There is provided a method for lossy image or video encoding and transmission, including the steps of receiving an input image at a first computer system, encoding the input image using a first trained neural network to produce a latent representation, performing a quantization process on the latent representation to produce a quantized latent, and transmitting the quantized latent to a second computer system.","['G06T5/002', 'G06T5/70', 'H04N19/90', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06T3/40', 'G06T2207/20081', 'G06T2207/20084']"
US12100159B2,System and method for object analysis,"In variants, the method can include: determining a timeseries of measurements of a geographic region; determining a set of object representations from the timeseries of measurements; and determining a timeseries of object versions based on relationships between the object representations.","['G06T7/11', 'G06F16/587', 'G01C11/06', 'G06F16/432', 'G06F16/489', 'G06F16/5854', 'G06F18/22', 'G06T7/0004', 'G06T7/60', 'G06T7/70', 'G06V10/82', 'G06V20/17', 'G06V20/176', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30184', 'G06T2207/30242']"
US20240185035A1,Systems and methods for text-to-image generation using language models,"Embodiments described herein provide a mechanism for replacing existing text encoders in text-to-image generation models with more powerful pre-trained language models. Specifically, a translation network is trained to map features from the pre-trained language model output into the space of the target text encoder. The training preserves the rich structure of the pre-trained language model while allowing it to operate within the text-to-image generation model. The resulting modularized text-to-image model receives prompt and generates an image representing the features contained in the prompt.","['G06N3/0455', 'G06N3/045', 'G06N3/084', 'G06T5/002', 'G06T5/70', 'G06T2207/20084']"
CN117911581A,Neural synthesis embedding generative techniques in non-destructive document editing workflows,"Embodiments of the present disclosure relate to neural synthesis that embeds generative techniques in a non-destructive document editing workflow. One or more aspects of the method, apparatus, and non-transitory computer-readable medium include obtaining an original image, a scene graph describing elements of the original image, and a description of modifications to the original image. One or more aspects also include updating the scene graph based on the description of the modification. One or more aspects further include generating a modified image using an image generation neural network based on the updated scene graph, wherein the modified image incorporates content based on the original image and a description of the modification.","['G06T11/60', 'G06F40/166', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06V10/82', 'G06V20/70']"
CN118280492A,"Super-atomic structure design method, product, medium and equipment based on cross attention diffusion model","The invention discloses a super-atomic structure design method, a product, a medium and equipment based on a cross attention diffusion model, and relates to the field of nano-structure design. The method comprises the steps of obtaining an original data set through a time domain finite difference method; training a scattering spectrum forward prediction model through a residual neural network; a reverse design model taking a spectrum as input and a structural image as output is built through a cross attention diffusion model, so that a generated result has higher quality, degree of freedom and precision; the optimal super-atomic structure is screened through the forward model and the cross attention diffusion model, so that the accuracy of the generated structure can be improved. The invention uses a cross attention mechanism and a multiplication embedding mode, so that the quality and the accuracy of the cross attention diffusion model in structural design are improved; by utilizing the characteristic of high degree of freedom of the cross attention diffusion model, the high-precision reverse design of the super-atomic structure is realized through the synergistic effect of the forward prediction model and the reverse design model.","['G16C60/00', 'G06F30/23', 'G06F30/27', 'G06N3/0464', 'G06N3/08']"
CN116721200A,A three-dimensional object generation method based on diffusion model and semantic guidance,"The invention discloses a three-dimensional object generation method based on a diffusion model and semantic guidance, which is characterized by comprising the following steps of: generating a semantic vector according to the text data by using a text encoder of the CLIP model; generating a shape vector according to the semantic vector and the first random noise by using a conditional flow model, and splicing the shape vector and the time step vector as guiding conditions; taking the second random noise as an initial inverse diffusion vector, and generating a low-dimensional point cloud vector by inverse diffusion based on a guide condition and the initial inverse diffusion vector by using a diffusion model; and decoding the low-dimensional point cloud vector by using a point cloud decoder to obtain Gao Weidian cloud, and generating a three-dimensional object according to Gao Weidian cloud. The method can generate a three-dimensional object with higher quality, but has the defects of slow training, slow reasoning, only single-class object generation and the like.","['G06T17/00', 'G06N3/08', 'G06T15/005', 'G06V10/7715', 'G06V10/806', 'G06V10/82', 'Y02T10/40']"
KR102588332B1,Method for generating storyboard based on script text,"Disclosed is a method for generating a storyboard based on script text, which is performed by a computing device according to one embodiment of the present disclosure. The method comprises: a step of acquiring the script text; a step of performing clustering for text parts included in the script text based on place information; a step of determining prompt information for each cluster generated by the clustering based on the place information; and a step of generating a storyboard for each cluster based on the determined prompt information. The present invention can simplify content production processes.","['G06F40/103', 'G06F40/295', 'G06F18/214', 'G06F18/23', 'G06F40/205', 'G06F40/30', 'G06F40/40', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06T11/00', 'G06V30/1448', 'G06V30/19093', 'G06V30/191', 'G06F40/166']"
CN117726542B,Controllable noise removing method and system based on diffusion model,"The application provides a controllable noise removal method and a controllable noise removal system based on a diffusion model, wherein the method comprises the following steps: constructing a simulated noise modeling network based on a potential diffusion model, wherein the simulated noise modeling network comprises a noise generation network and a camera adaptation network; pre-training the simulated noise modeling network by training data comprising camera parameters and paired real noisy images and clean images; performing fine adjustment on the pre-trained camera adaptation network based on the diffusion model; generating a large amount of simulation paired data through the camera adaptive network after fine adjustment and the noise generating network after pre-training, training the deep learning denoising network through the simulation paired data, and denoising the image to be processed through the trained deep learning denoising network. The method can controllably generate the paired training data set which approximates to the real noise distribution aiming at the specific parameters of various cameras, and achieves the efficient image noise removal effect.",['Y02T90/00']
US20250166236A1,Segmentation free guidance in diffusion models,"Certain aspects of the present disclosure provide techniques for generating an output image based on a text prompt. A method may include receiving the text prompt; providing a user interface comprising one or more input elements associated with one or more words of the text prompt; receiving input corresponding to at least one of the one or more input elements, the input indicating a semantic importance for each of at least one of the one or more words associated with the at least one of the one or more input elements; and generating the output image based on the text prompt and the input.","['G06T11/00', 'G06F40/284', 'G06T5/70', 'G06T2200/24']"
CN103037821B,For integrating the method and apparatus of cataract operation and glaucoma or astigmatism surgery,"A kind of method for integrating ocular operation can comprise: determine the cataract target area in crystalline lens; Apply cataract laser pulse with a part for the determined cataract target area of photodisruption; Determine the glaucoma target area in an outer peripheral areas or astigmatism target area; And apply surgical laser pulse to create one or more otch by photodisruption in described glaucoma or astigmatism target area; Each step of wherein said method performs in an operative procedure integrated.Laser pulse can apply before produce otch on cornea.The operative procedure integrated can be related to following three kinds of functions and uses identical pulsed laser source: for photodisruption target area, for manufacturing otch and for manufacturing otch on cornea on eye capsule.","['A61F9/008', 'A61F9/00825', 'A61F2009/00851', 'A61F2009/00853', 'A61F2009/00865', 'A61F2009/0087', 'A61F2009/00872', 'A61F2009/00887', 'A61F2009/00889', 'A61F2009/00891', 'A61F9/00827']"
WO2024220710A1,Product image generation based on diffusion model,Methods and systems are disclosed for generating an extended reality (XR) try-on experience based on an image produced by a diffusion model. The system receives an image depicting a real -world object and generates a prompt comprising a textual description of a fashion item. The system analyzes the image and the textual description of the fashion item using a generative machine learning model to generate an artificial image that depicts an artificial object that resembles the real -world object wearing an artificial fashion item matching the textual description of the fashion item. The system identifies an object comprising a real -world product image that matches visual attributes of the artificial fashion item and replaces the artificial fashion item in the artificial image with the object to generate an output image.,"['G06V20/60', 'G06F40/20', 'G06F40/40', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06T11/00', 'G06T11/001', 'G06T11/60', 'G06T7/10', 'G06T7/60', 'G06V10/757', 'G06V10/776', 'G06V10/82', 'G06V20/20', 'G06V40/10', 'G06V40/161', 'G06T2200/24', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20092', 'G06T2207/20132', 'G06T2207/30201', 'G06T2210/16', 'G06T2210/22']"
US20240169630A1,Synthesizing shadows in digital images utilizing diffusion models,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing to synthesize shadows for object(s). For instance, in one or more embodiments, the disclosed systems receive a digital image depicting a scene. The disclosed systems access an object mask of the object depicting in the digital image. The disclosed systems further combine the object mask, the digital image, and a noise representation to generate a combined representation. Moreover, the disclosed systems generate a shadow for the object from the combined representation and further generates the modified digital image by combining the shadow with the digital image.","['G06T11/60', 'G06F3/0481', 'G06F3/04842', 'G06F3/04845', 'G06F3/0486', 'G06T11/001', 'G06T5/002', 'G06T5/005', 'G06T5/70', 'G06T5/77', 'G06T5/94', 'G06T2200/24', 'G06T2207/20092', 'G06T2207/20212']"
WO2024100129A1,Audio-driven body motion synthesis using a diffusion probabilistic model,"There is disclosed a method (100) for providing a model suitable for audio-driven body motion synthesis, the method comprising: obtaining (110) combined audio training data and body-motion training data; forming (120) conditioning data, wherein the conditioning data includes the audio training data; providing (122) a model of body pose sequences using a trainable diffusion probabilistic model; and training (124) the model on the basis of the body-motion training data and the conditioning data. To perform audio-driven body motion synthesis using this trained model, a further method disclosed herein comprises: obtaining an audio signal; and generating a sequence of body poses from the model conditioned upon at least the audio signal. This synthesis may optionally use classifier-free guidance for all or parts of the conditioning.","['G06T13/205', 'G06T13/40']"
WO2023060746A1,Small image multi-object detection method based on super-resolution,"A small image multi-object detection method based on super-resolution. The method comprises: acquiring a first-resolution image of an original scene (S110); converting the first-resolution image into a second-resolution image by using a reversible neural network model, then transmitting the second-resolution image, and then restoring the second-resolution image to the first-resolution image, wherein the resolution of the second-resolution image is lower than that of the first-resolution image (S120); inputting the first-resolution image obtained after restoration into a trained super-resolution diffusion model, executing super-resolution reconstruction by means of a random iterative denoising process, and outputting an ultra-high-resolution image (S130); and executing object detection on the ultra-high-resolution image, so as to obtain object identification information (S140). By means of the method, the obstacle detection precision in a low-resolution scenario is improved, and a blind guidance device can operate for a long time, thereby alleviating the burden of a user.","['G06T3/4053', 'G06N3/045', 'G06N3/084', 'G06T3/4046']"
US20240320867A1,Iterative Image Generation From Text,"Methods and systems are presented for automatically identifying additional descriptors of an image generated by a text-to-image generator from an initial prompt. The additional descriptors are either incorporated into the initial prompt or made into a new prompt in order to produce another image from the text-to-image generator. The initial prompt and additional descriptors can describe visual features represented in images including content, artistic styles, visual perspectives, and other visible attributes of images. The additional descriptors can be incorporated into the initial prompt by replacing or supplementing existing descriptors. Subsequent images generated by the text-to-image generator can be used to iteratively produce additional descriptors.","['G06T11/00', 'G06F40/30', 'G06F16/532', 'G06F18/24', 'G06F3/04895', 'G06F40/279', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06T11/60', 'G06V10/945', 'G06F40/56', 'G06T2207/20092']"
CN115660931A,Robust Watermarking Method Based on Transformer and Denoising Diffusion Model,"The invention discloses a robust watermarking method based on a Transformer and a denoising diffusion model, which comprises the following steps: inputting the carrier image and the original watermark into a watermark encoder consisting of a transform to generate an encoded image embedded with the watermark; dividing the coded image into three paths and inputting the three paths of coded images into a noise-free layer, a known noise layer and an unknown noise layer based on a denoising diffusion model to generate a noise image; inputting the noise image into a watermark decoder consisting of a transform to obtain an extracted watermark; calculating a loss function, and updating parameters of a watermark encoder and a watermark decoder by adopting a random gradient descent method; and repeating the steps until the set training times are met, and after the watermark encoder and the watermark decoder are trained, keeping the watermark encoder and the watermark decoder respectively used for embedding and extracting the watermark.",[]
US20240241573A1,Full body motion tracking for use in virtual environment,"A method for full body motion tracking includes receiving tracking signals from a plurality of sensors associated with an upper body of a person, and based on the tracking signals, determining motion features and joint features. The method further includes training a diffusion model that includes a multi-layer perceptron (MLP) network, and generating a multiple inputs to the trained diffusion model, the inputs including the motion features and the joint features. The method includes providing the inputs to the trained diffusion model to generate multiple outputs. The outputs include sequences of full body poses, the sequences of full body poses including upper body poses and lower body poses.","['G06F3/0346', 'G06F3/011']"
CN117496072B,Three-dimensional digital person generation and interaction method and system,"The invention belongs to the technical field of three-dimensional reconstruction, and discloses a three-dimensional digital human generation and interaction method and system. The method comprises the following steps: human body example segmentation is carried out from the monocular video to capture human body actions in the video; reconstructing a three-dimensional digital human figure containing details using the neuro-radiation field; accelerating reconstruction by adopting a hash table coding method; generating a motion sequence using a diffusion model; generating an arbitrary length sequence in an editing generation mode; restoring the action parameters available for driving; independently establishing a three-dimensional nerve radiation field model for a human face; synthesizing a two-dimensional image of any view angle by using the low-resolution feature map and the two-dimensional nerve rendering; and mapping facial features such as facial forms, expressions and the like to a group of parameters, and controlling different parameters to realize facial expression driving and editing. The invention can quickly reconstruct any digital human figure containing fine head portrait from monocular video, and provides various and intelligent interaction modes.","['G06T17/00', 'G06N3/04', 'G06T15/005']"
US20240355065A1,Dynamic model adaptation customized for individual users,"Described is a system for dynamically applying model adaptations customized for individual users by detecting an image of a first real-world object from a camera feed, detecting landmarks on the first real-world object, and processing the landmarks on the first real-world object using a generative machine learning model to generate a first custom image template for the first real-world object where portions of the first custom image template are populated with visual content placed based on the first custom image template. The system then applies a content augmentation based on the first custom image template to the camera feed.","['G06V40/171', 'G06T19/006', 'G06V10/82', 'G06V2201/07']"
CN117789744A,Voice noise reduction method and device based on model fusion and storage medium,"The application discloses a voice noise reduction method, a device and a storage medium based on model fusion, and relates to the technical field of voice processing, wherein the method comprises the following steps: inputting the voice characteristics to be denoised corresponding to the voice signals to be denoised into a target discrimination model to obtain discrimination denoising results and reference noise information, wherein the discrimination denoising results comprise first noise characteristics to be denoised, and the reference noise information is noise information in the estimated voice characteristics to be denoised; inputting the voice characteristics to be noise-reduced and the reference noise information into a target generation model to obtain second noise-reduced voice characteristics, wherein the second noise-reduced voice characteristics are voice characteristics obtained by noise reduction processing of the voice characteristics to be noise-reduced based on the reference noise information by the target generation model; and fusing the first noise reduction voice feature and the second noise reduction voice feature to obtain fused noise reduction voice features, and converting the fused noise reduction voice features into noise reduction voice signals corresponding to the fused noise reduction voice features.",[]
US12211598B1,Configuring a generative machine learning model using a syntactic interface,"Described herein are a system, method, and device for configuring a generative machine learning model using a syntactic interface. A system may include a user interface, a memory, and a processor configured to, using a syntactic interface displayed using the user interface, receive a syntactic interface input from a user; identify an electronic medical record (EMR) by generating an EMR database query as a function of the syntactic interface input, querying an EMR database using the EMR database query, and receiving, from the EMR database, an EMR database response; generate a prompt as a function of the syntactic interface input; generate a first generative model output as a function of the prompt and the EMR using a trained generative machine learning model; and using a conversational interface displayed using the user interface, display the first generative model output to the user.","['G16H10/60', 'G06F16/2455', 'G16H10/20']"
US9619914B2,"Web platform for interactive design, synthesis and delivery of 3D character motion data","Systems and methods are described for animating 3D characters using synthetic motion data generated by motion models in response to a high level description of a desired sequence of motion provided by an animator. In a number of embodiments, the synthetic motion data is streamed to a user device that includes a rendering engine and the user device renders an animation of a 3D character using the streamed synthetic motion data. In several embodiments, an animator can upload a custom model of a 3D character or a custom 3D character is generated by the server system in response to a high level description of a desired 3D character provided by the user and the synthetic motion data generated by the generative model is retargeted to animate the custom 3D character.","['G06T13/20', 'G06T13/40', 'G06T2200/16']"
US20240256965A1,Instruction Fine-Tuning Machine-Learned Models Using Intermediate Reasoning Steps,"An example method for training a machine-learned sequence processing model includes obtaining a plurality of training examples for training the machine-learned sequence processing model. For each respective training example of the plurality of training examples, the example method includes: obtaining a respective query associated with the respective training example; inputting the respective query to the machine-learned sequence processing model; obtaining, from the machine-learned sequence processing model a response to the respective query and a trace of intermediate states from the respective query to the response; evaluating the response using a ground truth response associated with the respective training example; evaluating the trace using a ground truth trace associated with the respective training example; and updating one or more parameters of the machine-learned sequence processing model based on the evaluation of the response and based on the evaluation of the trace.","['G06N20/00', 'G06F16/33']"
US12073313B2,Electro-optical devices and methods for identifying and inducing topological states formed among interconnecting neural modules,"A system for monitoring an environment may include an input device for monitoring and capturing pattern-based states of a model of the environment. The system may also include a thalamobot embodied in at least a first processor in communication with the input device. The thalamobot may include at least one filter for monitoring captured data from the input device and for identifying at least one state change within the captured data. The system may also include at least one critic and/or at least one recognition system. The at least one filter forwards said at least one state change to the critic and/or recognition system. Novel schemes are introduced to allow processors to interconnect themselves into brain-like structures that contemplate both the environment and the model thereof, unifying disparate data into discoveries. The significance of such discoveries is recognized either through neural activation patterns or the topologies of interconnecting neural modules.","['G06N3/063', 'G06N3/045', 'G06N3/08']"
US20240355064A1,Overlaying visual content using model adaptation,"Described is a system for overlaying visual content onto a real-world object by identifying a prompt of a user indicating a user's intent, accessing an image template, wherein the image template includes placement of features within the image template, and processing a combination of data associated with the image template and the prompt using a generative machine learning model to generate a first populated image template in which one or more portions of the image template are populated with visual content representing the user's intent. The system then proceeds to access an image depicting a real-world object and overlay the first populated image template that includes the visual content representative of the user's intent on at least a portion of the real-world object based on the placement of the features of the image template.","['G06T17/20', 'G06T15/04', 'G06T19/006', 'G06T19/20', 'G10L15/1815', 'G10L15/22', 'G06T2219/2004', 'G06T2219/2012', 'G10L15/1822', 'G10L2015/223']"
CN102438529B,Method and system for automatic detection of lesions in medical images,"The invention provides a system and a method for processing medical images. First, the input medical image is normalized with the pixel intensity of the control point tissue including subcutaneous fat. Cluster density maps and malignancy probability maps are generated by normalizing the images and further analyzing these maps to identify common internal features, or blobs which may represent lesions. These blobs are analyzed and classified to distinguish likely true lesions from other types of non-malignant tumors commonly seen in medical images.","['G16H30/20', 'A61B5/0033', 'A61B5/4312', 'A61B5/7203', 'A61B5/7264', 'A61B8/0825', 'A61B8/5223', 'A61B8/5269', 'G06T5/92', 'G06T7/0012', 'G16H50/70', 'G06T2207/10132', 'G06T2207/20192', 'G06T2207/30096']"
US20240296919A1,Learning a sequential diffusion model for the forward and inverse problem in simulation of physical systems,"A method for simulating physical systems using a sequential diffusion model (SDM) comprising a denoising model includes collecting training data for training the SDM. The method further includes training the denoising model using the training data such that the SDM models a forward and/or reverse problem for a simulation of a physical system over a period of time, and generating a solution for the physical system based on training the denoising model. The solution indicates a final condition of the physical system at a final instance in the period of time for the forward problem and an initial condition of the physical system at an initial instance in the period of time for the reverse problem.","['G16C20/70', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16B15/30', 'G16C20/50']"
EP3798659A1,Automated noninvasive determining the fertility of a bird's egg,"Shown herein is a method of automated noninvasive determining the fertility of a bird's egg (14), comprising the following steps:conveying a plurality of bird eggs (14) sequentially or in parallel into an NMR apparatus (18),subjecting the bird eggs (14) to an NMR measurement, such as to generate a 3-D NMR image of at least a part of each of said eggs (14), said 3-D NMR image having a spatial resolution in at least one dimension of 1.0 mm or less, preferably of 0.50 mm or less, wherein said part of the egg (14) includes the germinal disc of the respective egg (14), determining a prediction of the fertility according to at least one of the following two procedures:(i) deriving at least one feature from each of said 3-D NMR images, and employing said at least one feature in a feature-based classifier for determining a prediction of the fertility, and(ii) using a deep learning algorithm, and in particular a deep learning algorithm based on convolutional neural networks, generative adversarial networks, recurrent neural networks or long short-term memory networks.","['A01K43/04', 'B07C5/344', 'G01N24/085', 'G01N33/08', 'G01R33/307', 'G01R33/3415', 'G01R33/483', 'G01R33/4835', 'G01R33/5608', 'G01R33/561', 'G01R33/5611']"
CN117974693B,"Image segmentation method, device, computer equipment and storage medium","The present application relates to an image segmentation method, an apparatus, a computer device, a storage medium and a computer program product. The method comprises the following steps: acquiring a target image to be segmented and a Gaussian noise image; performing feature coding processing on the Gaussian noise image by taking the target image as conditional information, and applying potential space representation constraint to the result of the feature coding processing to obtain a plurality of probabilistic potential feature vectors of the target image; performing feature decoding processing on the probabilistic latent feature vectors by taking the target image as conditional information to obtain a plurality of prediction noise; and denoising the Gaussian noise image through back diffusion based on the prediction noise to obtain an image segmentation result corresponding to each prediction noise. The method can effectively reconstruct a plurality of probabilistic segmentation masks, realize the reconstruction processing of the diversified segmentation masks of the target image, reduce the occurrence of the missing detection condition and effectively improve the accuracy of the image segmentation processing.","['G06T7/11', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06T5/20', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084']"
WO2024239827A1,Diffusion model-based inference acceleration method and system for text-to-image generation task,"The present disclosure relates to a diffusion model-based inference acceleration method and system for a text-to-image generation task. The method comprises: running a full generation process to acquire intermediate variables; selecting n steps from the full process, and in the iterative computation of the n steps: using a linear combination of a previous latent variable and output intermediate variables as an estimated value of a latent variable obtained in the current step; obtaining a coefficient in the linear combination by minimizing a mean squared error between the estimated value and a corresponding latent intermediate variable; and on the basis of the obtained coefficient, generating an image as the inference result of a text-to-image generation task. According to the present invention, the full generation process is analyzed, the design problem of a scheduler is transformed into the determination of a plurality of parameters, and an accelerated generation process is further transformed into a span process of a linear subspace, so that by reconstructing a short-step approximation process, the number of iterations is reduced from hundreds or thousands of steps to dozens of steps or even a few steps, thereby ensuring the generation effect while greatly improving the efficiency.","['G06T11/00', 'G06N20/00', 'G06N5/046']"
US20240121398A1,Diffusion-based data compression,"Systems and techniques are described for processing image data using a residual model that can be configured with an adjustable number of sampling steps. For example, a process can include obtaining a latent representation of an image and processing, using a decoder of a machine learning model, the latent representation of the image to generate an initial reconstructed image. The process can further include processing, using the residual model, the initial reconstructed image and noise data to predict a plurality of predictions of a residual over a number of sampling steps. The residual represents a difference between the image and the initial reconstructed image. The process can include obtaining, from the plurality of predictions of the residual, a final residual representing the difference between the image and the initial reconstructed image. The process can further include combining the initial reconstructed image and the residual to generate a final reconstructed image.","['H04N19/137', 'G06T9/002', 'G06N3/044', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'H04N19/147', 'H04N19/162', 'H04N19/86', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09']"
CN117575907A,A single image super-resolution reconstruction method based on an improved diffusion model,"The invention discloses a single image super-resolution reconstruction method based on an improved diffusion model, which comprises the following steps: 1) Constructing a data set of a training model; 2) Performing LR degradation processing on the low-resolution image; 3) Creating a hybrid dataset; 4) Modeling a denoising model according to the diffusion model; 5) And performing super-resolution reconstruction on the LR image. The method can quickly reconstruct and restore the HR image and provides a new thought and method for the super-resolution task of the image.","['G06T3/4053', 'G06N3/0464', 'G06N3/08', 'G06T3/4046', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
CN118071881A,Multi-modal image editing,"The present disclosure relates to multimodal image editing. Systems and methods for multi-modal image editing are provided. In one aspect, a system and method for multi-modal image editing includes identifying an image, a hint identifying an element to be added to the image, and a mask indicating a first area of the image for depicting the element. The system then generates a partial noise image map comprising noise in the first region and image features from images in a second region that is outside the first region. The diffusion model generates a composite image map based on the partial noise image map and the cues. In some cases, the composite image map includes target elements in a first region corresponding to the mask.","['G06T11/00', 'G06T11/60', 'G06N3/0464', 'G06N3/08', 'G06T11/001', 'G06T5/00', 'G06T5/60', 'G06T7/10', 'G06T7/11', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084']"
US20240127510A1,Stylized glyphs using generative ai,A method includes receiving an input including a target style and a glyph. The method further includes masking the glyph. The method further includes generating a stylized glyph by a glyph generative model using the masked glyph. The method further includes rendering the stylized glyph as a unicode stylized glyph.,"['G06T11/60', 'G06F16/50', 'G06T11/203', 'G06T7/0002', 'G06T2207/30168']"
CN113822320A,"Generative model training method and device, sample generation method and computing equipment","Generative model training methods and apparatus, sample generation methods, and computing devices are disclosed. The training method comprises the following steps: obtaining parameters of a trained noise removal network in the generative model as reference parameters, wherein the first training sample set comprises a plurality of independent and identically distributed first training samples; acquiring a second training sample set, wherein the second training sample set and the first training sample set are the same training sample set or have the same distribution; randomly selecting a second training sample from a second training sample set, and determining a noise level corresponding to the second training sample; training the noise scheduling network in the generated model by using each randomly selected second training sample and the corresponding noise level; wherein parameters of the noise-removal network remain unchanged at the reference parameters during training of the noise-scheduling network, wherein the noise-removal network corresponds to a reverse process and the noise-scheduling network corresponds to a forward process.",['G06F18/214']
US20240129601A1,Content velocity and hyper-personalization using generative ai,A method includes receiving a description of content to be generated using a generative model. The received description of content is associated with a user profile. The method further includes determining a semantic term based on the description of content. The method further includes generating a user-specific template including the semantic term and a user preference associated with the user profile. The method further includes generating the content using the generative model based on the user-specific template. The method further includes outputting the content for display on a target user device.,"['G06F16/532', 'H04N21/854', 'G06F40/30', 'H04L67/306']"
CN101163800B,Devices and methods for monitoring genomic DNA of organisms,"The invention provides an apparatus that can be used in methods of preparing, amplifying, detecting, and/or optionally selecting for further analysis the genomic material from an organism for the rapid detection and/or classification of an organism in a sample (e.g., screening for, identifying, quantifying, and/or optionally further analyzing, e.g., sequencing, the genomic material of the organism). The invention further provides methods of using the apparatus, e.g., in combination with novel SGP primers for improved use in waveform-profiling methods of DNA amplification. It is an object of the invention to provide an apparatus for fully automated analysis of genomic material, and multiple methods of using the apparatus that are beneficial to society, e.g., the apparatus may be used in methods of screening for, identifying, quantifying, and/or selecting genomic material for further analysis (e.g., sequencing) in relation to monitoring a source for the presence of contaminating organisms.","['C12Q1/6888', 'B01L3/502715', 'B01L3/502784', 'B01L7/52', 'B01L7/525', 'C12Q1/6839', 'C12Q1/686', 'G01N35/08', 'B01L2200/0673', 'B01L2200/10', 'B01L2300/0636', 'B01L2300/0645', 'B01L2300/0816', 'B01L2300/087', 'B01L2300/0877', 'B01L2300/1827', 'B01L2400/0415', 'B01L2400/0487', 'B01L3/502738', 'B01L7/54', 'C12Q2525/161', 'C12Q2525/179', 'C12Q2535/139', 'C12Q2563/173', 'C12Q2565/629', 'G01N1/34', 'G01N2001/4088', 'G01N2035/00237']"
JP2025082797A,"Method, apparatus, device, and medium for generating video","To provide a method, an apparatus, a device, and a medium for generating a video, in an object in the video.SOLUTION: A method includes: determining a first reference image and a second reference image from a plurality of reference images in a reference video; receiving a reference text for describing the reference video; and obtaining a generative model based on the first reference image, the second reference image, and the reference text. The generative model is used to generate a target video based on the first image, the second image, and the text, and the second reference image is used as guide data to determine the direction of story development in the video. In this way, the generative model clearly captures changes in contents of each image in the video, and helps generation of a richer and more compelling video.SELECTED DRAWING: Figure 11","['H04N21/85', 'G06V10/82', 'G11B27/036', 'H04N21/854', 'G06N3/045', 'G06N3/0475', 'G06V20/46', 'G11B27/34', 'H04N21/475', 'H04N21/84', 'G06N3/09']"
CN116665000A,A Federated Learning Algorithm Based on Diffusion Model and Weight Adaptive Knowledge Distillation,"The invention relates to the technical field of multi-source heterogeneous data fusion of federal learning, and discloses a federal learning algorithm based on diffusion model and weight self-adaptive knowledge distillation, which comprises the following steps: the client trains the diffusion model locally and generates data conforming to the original image distribution at the server, and expands the local data of the client through the generated image so as to realize data enhancement; the weight is dynamically distributed to each participant during knowledge distillation, and the migration of knowledge is completed at a server side. According to the invention, the diffusion model is trained at each client and the data conforming to the global image distribution is directly generated at the server, so that the original data is not required to be transmitted to a central server, and the privacy of a user can be better protected; and the invention can alleviate the forgetting of knowledge caused by model aggregation by carrying out weight self-adaptive knowledge distillation by utilizing the generated data, thereby improving the generalization capability of the global model.","['G06V10/80', 'G06F21/6245', 'G06N3/096', 'G06N3/098', 'Y02D10/00']"
CN101308782B,"Method for manufacturing SOI substrate, and method for manufacturing semiconductor device","The purpose of the invention is providing a manufacturing method of an SOI substrate by the method of implanting hydrogen ions. The manufacturing method of an SOI substrate which possesses a base substrate having low heat resistance and a very thin semiconductor layer having high planarity is demonstrated. The method includes: implanting hydrogen ions into a semiconductor substrate to form an ion implantation layer; bonding the semiconductor substrate and a base substrate such as a glass substrate, placing a bonding layer therebetween; heating the substrates bonded to each other to separate the semiconductor substrate from the base substrate, leaving a thin semiconductor layer over the base substrate; irradiating the surface of the thin semiconductor layer with laser light to improve the planarity and recover the crystallinity of the thin semiconductor layer; and thinning the thin semiconductor layer. This method allows the formation of an SOI substrate which has a single-crystalline semiconductor layer with a thickness of 100 nm or less over a base substrate.","['H01L21/76254', 'H10D86/00', 'H10D86/201', 'H10D86/0214', 'H10D86/40', 'H10D86/60', 'H10K71/421', 'H01L2224/03552', 'H10D30/6744']"
CN101366266B,Method and device for embedding and detecting digital watermark in text document,"Amethod and device for embedding digital watermark into a text document and detecting it, which belongs to a technical art of document protection. The method and device are accomplished by repeatedly printing a layer of shading for recording a mass of watermark infromation at the bottom of the normal document idditionally, the shading composed of the grids arranged by a certainrule, the change of the grid's position recording the eachbit string in the information flow of the watermark. With the method and device, it is possible to increase the amount of the hidden information, wherein the watermark information embedded into the shading will be diffused along with the document, if necessary, it is possible to detect afterthe document is digitized by a scanner.","['H04N1/32203', 'H04N1/32219', 'H04N1/32352', 'H04N2201/3205', 'H04N2201/3208', 'H04N2201/3214', 'H04N2201/3221', 'H04N2201/3266', 'H04N2201/3281', 'H04N2201/3284']"
CN118297820A,"Training method for image generation model, image generation method, device, equipment and storage medium","The application provides a training method, an image generation device, equipment and a storage medium of an image generation model, wherein the training method acquires an initial image; adding noise with random degree into the initial image to form a first noise-added image; adding noise with fixed degree into the initial image to form a second noise-added image; based on the first noisy image and the second noisy image, training to obtain an image generation model. After the initial image is acquired, the convergence speed of the image generation model is improved by adding random degree noise and fixed degree noise into the initial image, and the image generation performance is further improved.","['G06T5/60', 'G06N3/0455', 'G06N3/0895', 'G06T5/70', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
CN117376575A,Compressed domain video anomaly detection method based on conditional diffusion model,"The invention discloses a compressed domain video anomaly detection method based on a conditional diffusion model, which comprises the following steps: sparse sampling is carried out on an input compressed video stream; 1I frame and the following 3P frames are referred to as a set of gips; taking the MSE of the reconstructed MV and the original MV as an abnormal reconstruction fraction; taking the last I frame in the input as a target I frame, performing diffusion operation on the frame, and then performing noise adding; taking the noisy target I frame as input, reconstructing the splicing of MV and the I frame corresponding to the time sequence of the MV on a channel as a condition, and inputting the reconstructed MV and the I frame into a noise predictor Unet for noise prediction; weighting the anomaly reconstruction score and the anomaly prediction score obtained in the steps to obtain a final anomaly score; and processing different video streams in the data set to obtain the anomaly score of the whole data set and obtain the final anomaly detection result of the compressed domain video. The invention reduces complexity while maintaining high detection performance.","['H04N19/20', 'H04N19/42', 'Y02T10/40']"
US20240320872A1,Image generation using a text and image conditioned machine learning model,"A method, apparatus, non-transitory computer readable medium, and system for image generation include obtaining a text embedding of a text prompt and an image embedding of an image prompt. Some embodiments map the text embedding into a joint embedding space to obtain a joint text embedding and map the image embedding into the joint embedding space to obtain a joint image embedding. Some embodiments generate a synthetic image based on the joint text embedding and the joint image embedding.","['G06T11/00', 'G06F40/284', 'G06F40/40', 'G06T2207/20081', 'G06T2207/20084']"
US20250111866A1,Video editing using image diffusion,"Embodiments are disclosed for editing video using image diffusion. The method may include receiving an input video depicting a target and a prompt including an edit to be made to the target. A keyframe associated with the input video is then identified. The keyframe is edited, using a generative neural network, based on the prompt to generate an edited keyframe. A subsequent frame of the input video is edited using the generative neural network, based on the prompt, features of the edited keyframe, and features of an intervening frame to generate an edited output video.","['G11B27/031', 'G06T11/00', 'G06T7/50', 'G06T2207/10016']"
US20240135630A1,Image synthesis using diffusion models created from single or multiple view images,"A method and system for performing novel image synthesis using generative networks are provided. The encoder-based model is trained to infer a 3D representation of an input image. A feature image is then generated using volume rendering techniques in accordance with the 3D representation. The feature image is then concatenated with a noisy image and processed by a denoiser network to predict an output image from a novel viewpoint that is consistent with the input image. The denoiser network can be a modified Noise Conditional Score Network (NCSN). In some embodiments, multiple input images or keyframes can be provided as input, and a different 3D representation is generated for each input image. The feature image is then generated, during volume rendering, by sampling each of the 3D representations and applying a mean-pooling operation to generate an aggregate feature image.","['G06T15/06', 'G06T5/002', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06V10/44', 'G06V10/771', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US20220129600A1,Systems and methods for growth-based design,"Systems and methods are disclosed for generating designs for mechanical parts in a computer aided design (CAD) context. One method includes generating a model of a mechanical part, the model including one or more cells, wherein each cell is comprised of a plurality of parameterized representations, each of the plurality of parameterized representations representing a material property; determining, for each cell, a cell-specific parameter value for each of the parameterized representations; comparing, for each cell, each of the cell-specific parameter values to a corresponding threshold parameter value associated with each of the representations of the material properties; and generating at least one additional cell or removing at least one of the one or more cells based on the comparison of each cell-specific parameter value to the corresponding threshold parameter value.","['G06F30/17', 'G06T17/10', 'G06F30/22', 'G06F30/23', 'G06T19/20', 'G06F2111/06', 'G06F2119/14', 'G06T2219/2021']"
CN102422630B,Picture pick-up device,"The invention provides a kind of picture pick-up device, it has ambiguity correction unit, and ambiguity correction unit has the Presentation Function making photographer easily confirm photographic images.Picture pick-up device comprises: taking lens, for the formation of subject image; Photoelectric conversion unit, it is configured on the prediction imaging surface of taking lens; Display unit, for showing the photographic images that photoelectric conversion unit obtains; Image display control unit, after obtaining photographic images at photoelectric conversion unit, utilizes display unit to show photographic images; Range information acquiring unit, for obtaining the range information in photographic images; And ambiguity correction unit, for the range information obtained based on range information acquiring unit, ambiguity correction is carried out to photographic images.The photographic images of image display control unit display to the multiple Range Focusings in photographic images.","['G03B13/36', 'H04N25/778', 'G03B15/00', 'G03B17/18', 'G06T1/00', 'H04N23/611', 'H04N23/635', 'H04N23/672', 'H04N23/675', 'H04N23/68', 'H04N25/134', 'H04N25/704', 'H04N25/77', 'G03B2205/0007']"
US20230368073A1,Techniques for content synthesis using denoising diffusion models,"Techniques are disclosed herein for generating a content item. The techniques include receiving a content item and metadata indicating a level of corruption associated with the content item; and for each iteration included in a plurality of iterations: performing one or more operations to add corruption to a first version of the content item to generate a second version of the content item, and performing one or more operations to reduce corruption in the second version of the content item to generate a third version of the content item, wherein a level of corruption associated with the third version of the content item is less than a level of corruption associated with the first version of the content item.","['G06T5/70', 'G06N3/044', 'G06N20/00', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/094', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
US12114984B2,System and apparatus for generating imaging information based on at least a signal,"A system for generating imaging information based on at least a signal includes at least a processor and a memory communicatively connected thereto, where the memory contains instructions configuring the at least a processor to receive a plurality of unconditioned electrocardiogram images, a plurality of conditioned electrocardiogram images and a corpus of ECG signals. Additionally, the processor learns at least a discrepancy between the plurality of unconditioned electrocardiogram images and the plurality of conditioned electrocardiogram images using a self-supervised machine learning model. Further, the processor generates a generative model as a function of the at least a discrepancy wherein generating the generative model comprises training the generative model using generative training data wherein the generative training data correlates at least an ECG signal from the corpus of ECG signals input to an output echocardiogram datum and output a diagnosis as a function of the output echocardiogram datum.","['G06N3/047', 'A61B5/327', 'A61B5/7267', 'A61B8/0883', 'A61B8/5215', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'A61B8/06', 'A61B8/12', 'A61B8/4416', 'A61B8/488']"
US20240331322A1,Facial expression and pose transfer utilizing an end-to-end machine learning model,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06V20/40', 'G06T13/40', 'G06T19/20', 'G06T7/10', 'G06V10/774', 'G06V10/82', 'G06V10/945', 'G06V40/174', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06T2219/2021']"
CN114581552B,A grayscale image colorization method based on generative adversarial network,"The invention discloses a gray image colorization method based on a generated countermeasure network, which comprises the steps of firstly selecting a quantitative color picture group in COCO image data set, manufacturing a training set after the color removal treatment, secondly constructing a generated countermeasure network architecture, enabling a generator model to finish pre-training in the training set, then alternately training a judging model and the pre-trained generating model, adjusting parameters to obtain a trained model, and inputting test data into the model to realize gray image colorization. According to the method and the device, through the pre-training method and the pre-training process of the generator, the training method and the data set are greatly improved in optimization, the training time is greatly shortened on the basis of guaranteeing the training quality and the generalization quality of the finally generated image, and the flexibility is achieved; and by utilizing the thought of U-Net, training and testing are carried out on the COCO data set, so that the defects that the traditional method needs manual intervention and is difficult to carry out fine coloring work of a large-size image pixel level can be greatly reduced.","['G06T11/001', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'Y02T10/40']"
US8351649B1,Video feed target tracking,"Technologies for object tracking can include accessing a video feed that captures an object in at least a portion of the video feed; operating a generative tracker to capture appearance variations of the object operating a discriminative tracker to discriminate the object from the object's background, where operating the discriminative tracker can include using a sliding window to process data from the video feed, and advancing the sliding window to focus the discriminative tracker on recent appearance variations of the object; training the generative tracker and the discriminative tracker based on the video feed, where the training can include updating the generative tracker based on an output of the discriminative tracker, and updating the discriminative tracker based on an output of the generative tracker; and tracking the object with information based on an output from the generative tracker and an output from the discriminative tracker.","['G06T7/251', 'G06F18/24323', 'G06V10/764', 'G06V20/52', 'G06T2207/10016', 'G06T2207/30201']"
CN117894072B,A method and system for hand detection and three-dimensional posture estimation based on diffusion model,"The invention provides a hand detection and three-dimensional posture estimation method and system based on a diffusion model, wherein the method comprises the following steps: inputting an image to be detected into a first diffusion model, wherein the first diffusion model adds a boundary box to a hand region in the image to be detected; clipping the image to be detected based on a boundary box, inputting the clipping image into a second diffusion model, and marking a first joint point of the hand on the clipping image by the second diffusion model; determining respective bone lengths of the hands and bone rotation angles of the respective bones based on the positions of the first articulation points; determining an axial angle corresponding to each first joint point based on the bone length and the bone rotation angle of the bone, and calculating a rotation matrix corresponding to each first joint point; based on the joint route of each first joint point, calculating a rotation matrix corresponding to the first joint point on the joint route, and converting the first joint point into a second joint point; and constructing a hand image based on the coordinate data of the second articulation point.","['G06V40/28', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06T17/00', 'G06V10/25', 'G06V10/273', 'G06V10/32', 'G06V10/454', 'G06V10/98', 'G06V40/113', 'Y02T10/40']"
US20250078349A1,Controllable diffusion model,"A method, apparatus, and non-transitory computer readable medium for image generation are described. Embodiments of the present disclosure obtain a content input and a style input via a user interface or from a database. The content input includes a target spatial layout and the style input includes a target style. A content encoder of an image processing apparatus encodes the content input to obtain a spatial layout mask representing the target spatial layout. A style encoder of the image processing apparatus encodes the style input to obtain a style embedding representing the target style. An image generation model of the image processing apparatus generates an image based on the spatial layout mask and the style embedding, where the image includes the target spatial layout and the target style.","['G06T11/60', 'G06T11/40']"
CN117995161A,Speech synthesis system based on discrete speech mark and discrete diffusion model,"The invention discloses a speech synthesis system based on discrete speech marks and a discrete diffusion model, which relates to the field of speech.A speaker characteristic with a dimension of 512 is obtained through a speaker characteristic encoder, and a phoneme and the speaker characteristic are jointly sent to a phoneme encoder to obtain a phoneme level characteristic; the phoneme level features and the speaker features pass through a duration predictor to obtain the duration corresponding to each phoneme, and the frame level features containing duration information are obtained by copying the number of frames corresponding to the phonemes; the frame level features are sent as conditions to a discrete diffusion model to generate a corresponding discrete voice tag sequence, which is further sent to a neural audio decoder to obtain a final voice waveform. The invention can reduce the dimension of input data and improve the model efficiency by using the neural audio coding scheme.","['G10L13/02', 'G10L13/047']"
CN118172237A,Multimodal medical image conversion method and system based on latent diffusion model,"The invention discloses a multimode medical image conversion method and a system based on a potential diffusion model, wherein the method comprises the following steps: acquiring a first mode image and a second mode image, and performing data processing and amplification to acquire a training data set; constructing a potential diffusion model comprising an automatic codec and a diffusion model, the automatic codec comprising an encoder and a decoder; training the potential diffusion model based on the training data set; the method comprises the steps of inputting a first mode image to be converted into a potential diffusion model, compressing the first mode image into a potential space by an encoder, generating first mode potential space data, inputting the first mode potential space data into the diffusion model, generating second mode potential space data, inputting the second mode potential space data into a decoder, and generating the second mode image by the decoder. The invention diffuses in potential space, greatly reduces the calculation complexity, improves the reverse reasoning speed and maintains the excellent image generation quality of the diffusion model while realizing the mode conversion.","['G06T3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'Y02T10/40']"
CN118211268A,Heterogeneous federal learning privacy protection method and system based on diffusion model,"The disclosure provides a heterogeneous federal learning privacy protection method and system based on a diffusion model, which relate to the technical field of federal learning privacy protection and comprise the steps of establishing a communication channel between a server side and a client side; acquiring data with uneven category distribution of a client side, uploading the data to a server side, taking the data with uneven category distribution as input of a denoising diffusion model, and generating an image conforming to data distribution at the server side; the server initiates global model parameters by utilizing the generated image data to train heterogeneous federal learning, distributes the global model parameters to the randomly selected clients, utilizes a knowledge distillation method to treat the global model as a teacher network, treats the local model of the previous round as a student network to train and upload parameters of the local model, and utilizes the uploaded local model parameters of each client to aggregate the global model to finish knowledge migration.","['G06F21/6245', 'G06N3/0464', 'G06N3/098', 'G06V10/30', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
CN117314733A,"Video filling method, device, equipment and storage medium based on diffusion model","The invention provides a video filling method, a device, equipment and a storage medium based on a diffusion model, and relates to the technical field of artificial intelligence, wherein the method comprises the following steps: obtaining a trained diffusion model; the U-shaped network model in the trained diffusion model comprises a first encoder, a first middle layer and a decoder; the attention modules in the first encoder and decoder are both space-time attention modules; the attention calculation dimension of the space-time attention module comprises a channel dimension, a width dimension and a height dimension, wherein the channel dimension is a dimension represented by the product of the number of channels and the number of frames; and inputting the video frame sequence to be filled into the trained diffusion model for video filling to obtain a target video frame sequence. The invention can promote the frame consistency of the target video frame sequence.","['G06T11/40', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US20240160888A1,"Realistic, controllable agent simulation using guided trajectories and diffusion models","In various examples, systems and methods are disclosed relating to neural networks for realistic and controllable agent simulation using guided trajectories. The neural networks can be configured using training data including trajectories and other state data associated with subjects or agents and remote or neighboring subjects or agents, as well as context data representative of an environment in which the subjects are present. The trajectories can be determining using the neural networks and using various forms of guidance for controllability, such as for waypoint navigation, obstacle avoidance, and group movement.","['G06N3/0442', 'G06N3/02', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N7/01', 'G06N3/006']"
US12383157B2,"Brain functional connectivity correlation value clustering device, brain functional connectivity correlation value clustering system, brain functional connectivity correlation value clustering method, brain functional connectivity correlation value classifier program, brain activity marker classification system and clustering classifier model for brain functional connectivity correlation values","A brain functional connectivity correlation value clustering device for clustering subjects having a prescribed attribute on the basis of brain measurement data obtained from a plurality of facilities, wherein a plurality of MRI devices capture resting state fMRI image data of a healthy cohort and a patient cohort; a computing system 300 performs generation of an identifier as ensemble learning of âsupervised learningâ between harmonized component values of correlation matrixes and disease labels of each of the subjects, selects, during the ensemble learning, features for clustering in accordance with importance from the features specified for generating an identifier for a disease label, and performs multiple co-clustering by âunsupervised learning.â","['A61B5/055', 'A61B5/0042', 'A61B5/165', 'A61B5/7267', 'G06F18/211', 'G06F18/2415', 'G06N20/20', 'G06F2123/02', 'G06N7/01']"
US8331669B2,Method and system for interactive segmentation using texture and intensity cues,"A method for processing image data for segmentation includes receiving image data. One or more seed points are identified within the image data. Intensity and texture features are computer based on the received image data and the seed points. The image data is represented as a graph wherein each pixel of the image data is represented as a node and edges connect nodes representative of proximate pixels of the image data and establishing edge weights for the edges of the graph using a classifier that takes as input, one or more of the computed image features. Graph-based segmentation such as segmentation using the random walker approach may then be performed based on the graph representing the image data.","['G06T7/162', 'G06T7/11', 'G06T7/143', 'G06T2207/20101']"
US11893713B1,Augmented diffusion inversion using latent trajectory optimization,"Augmented Denoising Diffusion Implicit Models (âDDIMsâ) using a latent trajectory optimization process can be used for image generation and manipulation using text input and one or more source images to create an output image. Noise bias and textual bias inherent in the model representing the image and text input is corrected by correcting trajectories previously determined by the model at each step of a diffusion inversion process by iterating multiple starts the trajectories to find determine augmented trajectories that minimizes loss at each step. The trajectories can be used to determine an augmented noise vector, enabling use of an augmented DDIM and resulting in more accurate, stable, and responsive text-based image manipulation.","['G06T5/70', 'G06T5/002', 'G06T5/60', 'G06T9/00', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
CN117541906A,Method for generating multi-category special vehicle SAR images based on denoising diffusion model,"The invention discloses a method for generating a multi-category special vehicle SAR image based on a denoising diffusion model, which specifically comprises the following steps: step 1, acquiring a sample of a special vehicle SAR image and preprocessing the sample; step 2, creating a category label for the special vehicle SAR image preprocessed in the step 1 according to the category, and converting the category label into a learnable category coding vector; step 3, obtaining a time step coding vector at the moment t; adding noise to the special vehicle SAR image with the class label preset in the step 2; step 4, sending the time step coding vector at the moment t, the special vehicle SAR image after noise addition and the class coding vector into a self-attention U-Net network for training to obtain a denoising diffusion model; and 5, generating a special vehicle SAR image according to the denoising diffusion model. The method solves the problems that in the prior art, mode collapse and overlarge network parameters are easy to occur due to poor stability in the training process when the GAN adopting the countermeasure mechanism generates the SAR image of the special vehicle.","['G06V10/82', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06V10/774']"
US12026887B2,Processing three-dimensional (3D) ultrasound images,"A first set of embodiments relates to an apparatus comprising one or more processors configured to: access three-dimensional (3D) ultrasound imaging of an eye; generate at least one segmented ocular structure by segmenting at least one ocular structure represented in the 3D ultrasound imaging using at least one deep learning ocular structure segmentation model configured to generate a predicted segmentation volume of the at least one ocular structure based on at least one portion of the 3D ultrasound imaging; compute at least one clinical metric associated with the at least one segmented ocular structure based on the at least one segmented ocular structure; and display at least one of: the at least one segmented ocular structure, the at least one clinical metric, the 3D ultrasound imaging, or at least one portion of the 3D ultrasound imaging.","['G06T7/11', 'G06T5/60', 'G06T5/70', 'G06T7/0012', 'G06T7/62', 'G06T2200/04', 'G06T2200/24', 'G06T2207/10136', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/20192', 'G06T2207/30041']"
US20240320789A1,High-resolution image generation,"A method, non-transitory computer readable medium, apparatus, and system for image generation include obtaining an input image having a first resolution, where the input image includes random noise, and generating a low-resolution image based on the input image, where the low-resolution image has the first resolution. The method, non-transitory computer readable medium, apparatus, and system further include generating a high-resolution image based on the low-resolution image, where the high-resolution image has a second resolution that is greater than the first resolution.","['G06T3/4046', 'G06T11/00', 'G06T3/4053']"
US20240338799A1,Utilizing regularized forward diffusion for improved inversion of digital images,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for utilizing machine learning models to generate modified digital images. In particular, in some embodiments, the disclosed systems generate image editing directions between textual identifiers of two visual features utilizing a language prediction machine learning model and a text encoder. In some embodiments, the disclosed systems generated an inversion of a digital image utilizing a regularized inversion model to guide forward diffusion of the digital image. In some embodiments, the disclosed systems utilize cross-attention guidance to preserve structural details of a source digital image when generating a modified digital image with a diffusion neural network.","['G06F40/126', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
US20240386529A1,Generating domain-specific videos using diffusion models,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output video conditioned on an input. The video generation method can be implemented by a system including one or more computers. The system receives a conditioning input, and initializes a current intermediate representation of the output video. At each of a plurality of iterations, the system updates the current intermediate representation using a first denoising diffusion model and a second denoising diffusion model conditioned on the conditioning input.","['G06T5/60', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06T13/00', 'G06T5/70', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
AU2024202381B2,Model based document image enhancement,"#$%^&*AU2024202381B220250703.pdf##### 2312629AU 35 ABSTRACT Systems and methods are disclosed for model based document image enhancement. Instead of requiring paired dirty and clean images for training a model to clean document images (which may cause privacy concerns), two models are trained on the unpaired images such that only the dirty images are accessed or only the clean images are accessed at one time. One model is a first implicit model to translate the dirty images from a source space to a latent space, and the other model is a second implicit model to translate the images from the latent space to clean images in a target space. The second implicit model is trained based on translating electronic document images in the target space to the latent space. In some implementations, the implicit models are diffusion models, such as denoising diffusion implicit models based on solving ordinary differential equations. 2312629AU ABSTRACT Systems and methods are disclosed for model based document image enhancement. Instead of requiring paired dirty and clean images for training a model to clean document images (which may cause privacy concerns), two models are trained on the unpaired images such that only the dirty images are accessed or only the clean images are accessed at one time. One model is a first implicit model to translate the dirty images from a source space to a latent space, and the other model is a second implicit model to translate the images from the latent space to clean images in a target space. The second implicit model is trained based on translating electronic document images in the target space to the latent space. In some implementations, the implicit models are diffusion models, such as denoising diffusion implicit models based on solving ordinary differential equations. 35 20 24 20 23 81 11 A pr 2 02 4 2 3 1 2 6 2 9 A U A B S T R A C T S y s t e m s a n d m e t h o d s a r e d i s c l o s e d f o r m o d e l b a s e d d o c u m e n t i m a g e e n h a n c e m e n t . I n s t e a d o f r e q u i r i n g p a i r e d d i r t y a n d c l e a n i m a g e s f o r t r a i n i n g a m o d e l t o c l e a n d o c u m e n t 2 0 2 4 2 0 2 3 8 1 1 1 A p r 2 0 2 4 i m a g e s ( w h i c h m a y c a u s e p r i v a c y c o n c e r n s ) , t w o m o d e l s a r e t r a i n e d o n t h e u n p a i r e d i m a g e s s u c h t h a t o n l y t h e d i r t y i m a g e s a r e a c c e s s e d o r o n l y t h e c l e a n i m a g e s a r e a c c e s s e d a t o n e t i m e . O n e m o d e l i s a f i r s t i m p l i c i t m o d e l t o t r a n s l a t e t h e d i r t y i m a g e s f r o m a s o u r c e s p a c e t o a l a t e n t s p a c e , a n d t h e o t h e r m o d e l i s a s e c o n d i m p l i c i t m o d e l t o t r a n s l a t e t h e i m a g e s f r o m t h e l a t e n t s p a c e t o c l e a n i m a g e s i n a t a r g e t s p a c e . T h e s e c o n d i m p l i c i t m o d e l i s t r a i n e d b a s e d o n t r a n s l a t i n g e l e c t r o n i c d o c u m e n t i m a g e s i n t h e t a r g e t s p a c e t o t h e l a t e n t s p a c e . I n s o m e i m p l e m e n t a t i o n s , t h e i m p l i c i t m o d e l s a r e d i f f u s i o n m o d e l s , s u c h a s d e n o i s i n g d i f f u s i o n i m p l i c i t m o d e l s b a s e d o n s o l v i n g o r d i n a r y d i f f e r e n t i a l e q u a t i o n s . 3 5 2312629AU Sheet 5/7 Figure 5 500 Obtain an electronic document image by an ML model. 502 Enhance the electronic document image by the ML model. 506 Translate the electronic document image in a source space to a latent space by a first implicit probabilistic model of the ML model. 508 The first implicit probabilistic model is trained based on translating electronic document images in the source space to the latent space. 510 The electronic document image is generated from scanning a physical document. 504 Translate the electronic document image in the latent space to a target space by a second implicit probabilistic model of the ML model. 512 The second implicit probabilistic model is trained independently from the first implicit probabilistic model. 516 The second implicit probabilistic model is trained based on translating electronic document images in the target space to the latent space. 514 Provide the electronic document image in the target domain for an OCR engine to perform OCR. 518 Perform OCR on the electronic document image in the target space by the OCR engine to generate an OCR document. 520 2312629AU Sheet 5/7 500 Obtain an electronic document image by an ML model. 502 The electronic document image is generated from scanning a physical document. 504 Enhance the electronic document image by the ML model. 506 Translate the electronic document image in a source space to a latent space by a first implicit probabilistic model of the ML model. 508 The first implicit probabilistic model is trained based on translating electronic document images in the source space to the latent space. 510 Translate the electronic document image in the latent space to a target space by a second implicit probabilistic model of the ML model. 512 The second implicit probabilistic model is trained based on translating electronic document images in the target space to the latent space. 514 The second implicit probabilistic model is trained independently from the first implicit probabilistic model. 516 Provide the electronic document image in the target domain for an OCR engine to perform OCR. 518 Perform OCR on the electronic document image in the target space by the OCR engine to generate an OCR document. 520 Figure 5 20 24 20 23 81 11 A pr 2 02 42 3 1 2 6 2 9 A U S h e e t 5 / 7 2 0 2 4 2 0 2 3 8 1 1 1 A p r 2 0 2 4 5 0 0 O b t a i n a n e l e c t r o n i c d o c u m e n t i m a g e b y a n M L m o d e l . 5 0 2 T h e e l e c t r o n i c d o c u m e n t i m a g e i s g e n e r a t e d f r o m s c a n n i n g a p h y s i c a l d o c u m e n t . 5 0 4 E n h a n c e t h e e l e c t r o n i c d o c u m e n t i m a g e b y t h e M L m o d e l . 5 0 6 T r a n s l a t e t h e e l e c t r o n i c d o c u m e n t i m a g e i n a s o u r c e s p a c e t o a l a t e n t s p a c e b y a f i r s t i m p l i c i t p r o b a b i l i s t i c m o d e l o f t h e M L m o d e l . 5 0 8 T h e f i r s t i m p l i c i t p r o b a b i l i s t i c m o d e l i s t r a i n e d b a s e d o n t r a n s l a t i n g e l e c t r o n i c d o c u m e n t i m a g e s i n t h e s o u r c e s p a c e t o t h e l a t e n t s p a c e . 5 1 0 T r a n s l a t e t h e e l e c t r o n i c d o c u m e n t i m a g e i n t h e l a t e n t s p a c e t o a t a r g e t s p a c e b y a s e c o n d i m p l i c i t p r o b a b i l i s t i c m o d e l o f t h e M L m o d e l . 5 1 2 T h e s e c o n d i m p l i c i t p r o b a b i l i s t i c m o d e l i s t r a i n e d b a s e d o n t r a n s l a t i n g e l e c t r o n i c d o c u m e n t i m a g e s i n t h e t a r g e t s p a c e t o t h e l a t e n t s p a c e . 5 1 4 T h e s e c o n d i m p l i c i t p r o b a b i l i s t i c m o d e l i s t r a i n e d i n d e p e n d e n t l y f r o m t h e f i r s t i m p l i c i t p r o b a b i l i s t i c m o d e l . 5 1 6 P r o v i d e t h e e l e c t r o n i c d o c u m e n t i m a g e i n t h e t a r g e t d o m a i n f o r a n O C R e n g i n e t o p e r f o r m O C R . 5 1 8 P e r f o r m O C R o n t h e e l e c t r o n i c d o c u m e n t i m a g e i n t h e t a r g e t s p a c e b y t h e O C R e n g i n e t o g e n e r a t e a n O C R d o c u m e n t . 5 2 0 F i g u r e 5","['G06T7/0002', 'G06T5/70', 'G06T9/00', 'G06V10/70', 'G06V10/82', 'G06V30/10', 'G06V30/164', 'G06V30/18086', 'G06T2207/20081', 'G06T2207/30168']"
US12013891B2,Model-based attribution for content generated by an artificial intelligence (AI),"In some aspects, a server trains an artificial intelligence (AI) to create a trained AI. The training includes: selecting a content creator from multiple content creators to create a selected content creator, selecting a plurality of content items associated with the content creator to create selected content items, training the AI using the selected content items, determining a creator influence of the selected content creator on the trained AI based on an aggregate influence of the selected content items on the AI during the training, and including the creator influence in a static attribution vector. After the training is completed, the trained AI receives an input and generates an output. The server creates an attribution determination based at least in part on the static attribution vector and initiates providing compensation to one or more of the multiple content creators based at least in part on the attribution determination.","['G06F16/45', 'G06F16/438', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06N3/096', 'G06Q30/0208']"
CN102714320B,Electrochemical systems and methods of operating same,"This disclosure relates to electrochemical systems, e.g., a combination of an electrical energy source and an electrical energy storage system having a regenerative fuel cell system, that exhibit operational stability in harsh environments, e.g., both charging and discharging reactions in a regenerative fuel cell in the presence of an acid or a mixture of acids, or a halogen ion or a mixture of halogen ions. The electrochemical systems are capable of conducting both hydrogen evolution reactions (HERs) and hydrogen oxidation reactions (HORs) in the same system. The electrochemical systems have low cost, fast response time, and acceptable life and performance. This disclosure also relates to methods of operating the electrochemical systems containing a regenerative fuel cell system.","['H01M4/9083', 'H01M8/02', 'H01M4/90', 'H01M4/921', 'H01M4/926', 'H01M4/96', 'H01M8/04', 'H01M8/1051', 'H01M8/24', 'H01M8/0202', 'H01M8/0258', 'H01M8/0271', 'H01M8/186', 'Y02E10/50', 'Y02E60/50', 'Y02P70/50']"
CN109685072A,A kind of compound degraded image high quality method for reconstructing based on generation confrontation network,"The invention discloses a kind of based on the compound degraded image high quality method for reconstructing for generating confrontation network, for containing haze simultaneously, system noise, the low-quality image of a variety of degradation problems such as low-light (level) and compression artefacts, the present invention is first from the angle rebuild for complex factors degraded image, it establishes a kind of based on the compound degraded image high quality method for reconstructing for generating confrontation network, it is achievable to be directed to by haze, low-light (level), compression, system noise, the factors such as optical dimming combine the reconstruction of degraded imageï¼Secondly, the present invention uses asymmetrical generation network, the parameter amount of model is greatly reduced, model is made to be easy to training and useï¼Furthermore using thought end to end, the framework of reconstructing system is simplified, eliminates pretreatment and post-processingï¼It is all made of convolutional layer finally, generating network, the compound degraded image of arbitrary dimension can be inputted and rebuild.","['G06V10/32', 'G06N3/045', 'G06N3/08', 'G06T5/50', 'G06T5/70', 'G06V10/44']"
US7578162B2,Apparatus for detecting a physical quantity acting as an external force and method for testing and manufacturing this apparatus,"A sensor comprises a semiconductor pellet (10) including a working portion (11) adapted to undergo action of a force, a fixed portion (13) fixed on the sensor body, and a flexible portion (13) having flexibility formed therebetween, a working body (20) for transmitting an exerted force to the working portion, and detector means (60-63) for transforming a mechanical deformation produced in the semiconductor pellet to an electric signal to thereby detect a force exerted on the working body as an electric signal. A signal processing circuit is applied to the sensor. This circuit uses analog multipliers (101-109) and analog adders/subtracters (111-113), and has a function to cancel interference produced in different directions. Within the sensor, two portions (E3, E4-E8) located at positions opposite to each other and producing a displacement therebetween by action of a force are determined. By exerting a coulomb force between both the portions, the test of the sensor is carried out.","['G01P1/023', 'G01L1/148', 'G01L1/18', 'G01L25/00', 'G01L5/162', 'G01P15/123', 'G01P15/125', 'G01P15/18', 'G01P21/00', 'G01P2015/084']"
CN111524205A,Image colorization processing method and device based on recurrent generative adversarial network,"The invention discloses an image coloring processing method and device based on a loop generation countermeasure network, wherein the method comprises the following steps: according to a pre-acquired image training sample, training a double-layer cycle generation confrontation network model through machine learning, so that the generation confrontation loss and consistency loss of the model meet a preset convergence condition, wherein the model comprises: the system comprises a first generator for mapping a gray level image into a color image, a second generator for mapping the color image into a gray level image, a first discriminator for distinguishing the color image output by the first generator from a real color image, and a second discriminator for distinguishing the gray level image output by the second generator from the real gray level image; and under the condition that the generation countermeasure loss and the consistency loss of the model meet the preset convergence condition, performing coloring processing on the gray-scale image to be colored by adopting a first generator. The method can avoid the mistaken coloring of the image under the complex background and improve the accuracy of the image coloring treatment.","['G06T11/40', 'G06N3/045', 'G06N3/084']"
CN117078510B,Single image super-resolution reconstruction method of potential features,"The invention discloses a super-resolution reconstruction method for a single image with potential characteristics, and belongs to the technical field of image processing. In order to ensure that the diffusion probability model performs high-quality sampling in a small number of sampling steps, the reconstruction of the high-resolution image is realized based on the set multi-mode distribution model, the model is realized based on a generator and a normalized flow, and the high-frequency detail of the high-resolution image is focused in a small number of iteration steps. And the low-resolution image is converted into hidden conditions as the condition input of the model through the self-adaptive multi-head attention mechanism and the variational self-encoder, and the negative influence caused by model collapse is reduced while the sampling is fast, so that the complicated and diversified high-quality high-resolution image is generated. The predictive randomness effect brought by the maximum variation lower bound in the diffusion probability model is limited through the self-adaptive multi-head attention mechanism and the variation self-encoder, so that model training is stable, and an image consistent with the style and content of the original high-resolution image can be generated.","['G06T3/4053', 'G06N3/0455', 'G06N3/0464', 'G06N3/094', 'G06T2207/20081', 'G06T2207/20084']"
US20240169541A1,Amodal instance segmentation using diffusion models,Systems and methods for instance segmentation are described. Embodiments include identifying an input image comprising an object that includes a visible region and an occluded region that is concealed in the input image. A mask network generates an instance mask for the input image that indicates the visible region of the object. A diffusion model then generates a segmentation mask for the input image based on the instance mask. The segmentation mask indicates a completed region of the object that includes the visible region and the occluded region.,"['G06T7/11', 'G06T7/10', 'G06T2207/20081', 'G06T2207/20084']"
US20190206057A1,Systems and methods for modeling neural architecture,Systems and methods are described herein for modeling neural architecture. Regions of interest of a brain of a subject can be identified based on image data characterizing the brain of the subject. the identified regions of interest can be mapped to a connectivity matrix. The connectivity matrix can be a weighted and undirected network. A multivariate transformation can be applied to the connectivity matrix to transform the connectivity matrix into a partial correlation matrix. The multivariate transformation can maintain a positive definite constraint for the connectivity matrix. The partial correlation matrix can be transformed into a neural model indicative of the connectivity matrix.,"['A61B5/7267', 'A61B5/0263', 'A61B5/369', 'A61B5/4064', 'G06F17/16', 'G06F17/18', 'G06F18/2321', 'G06K9/6226', 'G06T7/0014', 'G01R33/4806', 'G01R33/5608', 'G01R33/56341', 'G06T2207/30016', 'G16H50/70']"
US20240135572A1,Synthesizing a modified digital image utilizing a reposing model,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06V10/82', 'G06T7/70', 'G06N20/10', 'G06N20/20', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N5/01', 'G06N5/025', 'G06N7/01', 'G06T11/001', 'G06T11/60', 'G06T7/40', 'G06V10/44', 'G06V10/771', 'G06V10/806', 'G06V40/174', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/30196']"
US12245052B2,Reinforcement learning (RL) and graph neural network (GNN)-based resource management for wireless access networks,"A computing node to implement an RL management entity in an NG wireless network includes a NIC and processing circuitry coupled to the NIC. The processing circuitry is configured to generate a plurality of network measurements for a corresponding plurality of network functions. The functions are configured as a plurality of ML models forming a multi-level hierarchy. Control signaling from an ML model of the plurality is decoded, the ML model being at a predetermined level (e.g., a lowest level) in the hierarchy. The control signaling is responsive to a corresponding network measurement and at least second control signaling from a second ML model at a level that is higher than the predetermined level. A plurality of reward functions is generated for training the ML models, based on the control signaling from the MLO model at the predetermined level in the multi-level hierarchy.","['H04W24/02', 'H04L41/145', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/092', 'H04L41/044', 'H04L43/08', 'H04L47/822', 'H04L47/824', 'G06N3/09', 'H04L41/046', 'H04L41/0631', 'H04L41/0806', 'H04L41/0894', 'H04L41/0895', 'H04L41/0896', 'H04L41/0897', 'H04L41/122', 'H04L41/142', 'H04L41/147', 'H04L41/16', 'H04L41/22', 'H04L41/40', 'H04L43/045', 'H04L43/0811', 'H04L43/0829', 'H04L43/0852', 'H04L43/0888', 'H04L43/20']"
US20250045930A1,Unsupervised zero-shot segmentation mask generation and semantic labeling,"Implementations relate to generation of segmentation masks for images in a zero-shot, unsupervised manner. Implementations also relate to generation of labels for the segmentation layers of the segmentation mask. Implementations use self-attention maps from a pass of the image through a generative image model to determine the segmentation mask and may use cross-attention maps generated when a prompt describing the image is provided with the image to the generative image model. Implementations aggregate maps from different resolutions to determine the mask and labels. The disclosed techniques enable accurate segmentation for any image without apriori training, facilitating applications in image processing, computer vision, extended reality applications, and robotics.","['G06T3/40', 'G06T7/11', 'G06T7/12', 'G06V10/25', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN101290876B,Manufacturing method of SOI substrate,"The present invention provides an SOI substrate having an SOI layer, which can withstand practical use even when a substrate having a low heat-resistant temperature such as a glass substrate is used. The present invention also provides a semiconductor device using the SOI substrate. In order to bond a single crystal semiconductor substrate to a base substrate such as a glass substrate, a silicon oxide film formed by CVD using organic silane as a raw material is used as a bonding layer. Even when a substrate having a heat resistance temperature of 700 â or lower, such as a glass substrate, is used, an SOI substrate having a high bonding force at a bonding portion can be formed. Further, by irradiating a semiconductor layer separated from the single crystal semiconductor substrate with laser light, the surface thereof is planarized, and crystallinity thereof is recovered.","['H01L21/76254', 'H01L21/20', 'H01L21/2007', 'H01L21/268', 'H01L21/302', 'H10D86/01']"
US11853908B2,"Data-analysis-based, noisy labeled and unlabeled datapoint detection and rectification for machine-learning","Noisy labeled and unlabeled datapoint detection and rectification in a training dataset for machine-learning is facilitated by a processor(s) obtaining a training dataset for use in training a machine-learning model. The processor(s) applies ensemble machine-learning and a generative model to the training dataset to detect noisy labeled datapoints in the training dataset, and create a clean dataset with preliminary labels added for any unlabeled datapoints in the training dataset. Data-driven active learning and the clean dataset are used by the processor(s) to facilitate generating an active-learned dataset with true labels added for one or more selected datapoints of a datapoint pool including the detected noisy labeled datapoints and the unlabeled datapoints of the training dataset. The machine-learning model is trained by the processor(s) using, at least in part, the clean dataset and the active-learned dataset.","['G06N5/04', 'G06N20/20', 'G06N3/02', 'G06N7/01']"
CN116415152A,Diffusion model-based self-supervision contrast learning method for human motion recognition,"The invention belongs to the technical field of motion recognition based on WiFi Channel State Information (CSI), and discloses a self-supervision contrast learning method based on a diffusion model for human motion recognition. Experiments show that compared with the existing most advanced method, the method provided by the invention is obviously improved.","['G06F18/2155', 'G06F18/10', 'G06F18/2451', 'G06F18/295', 'G06N3/0895', 'G06F2123/02', 'G06F2218/04', 'G06F2218/12']"
US12333636B2,Utilizing cross-attention guidance to preserve content in diffusion-based image modifications,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for utilizing machine learning models to generate modified digital images. In particular, in some embodiments, the disclosed systems generate image editing directions between textual identifiers of two visual features utilizing a language prediction machine learning model and a text encoder. In some embodiments, the disclosed systems generated an inversion of a digital image utilizing a regularized inversion model to guide forward diffusion of the digital image. In some embodiments, the disclosed systems utilize cross-attention guidance to preserve structural details of a source digital image when generating a modified digital image with a diffusion neural network.","['G06T11/60', 'G06T5/60', 'G06T5/70', 'G06T9/00', 'G06V10/761', 'G06V10/82', 'G06V20/70', 'G06T2207/20182']"
WO2024255105A1,"Method and apparatus for training picture recognition model, and storage medium, electronic device and program product","Disclosed in the embodiments of the present application are a method and apparatus for training a picture recognition model, and a storage medium, an electronic device and a program product. The method comprises: acquiring N sample pictures in a first sample picture set, and picture description text and at least one picture label of each sample picture among the N sample pictures; and for each sample picture, executing the following processing: according to the picture description text and the at least one picture label of the sample picture, generating a group of picture prompt words corresponding to the sample picture, according to the sample picture and the group of picture prompt words, generating a sample picture subset corresponding to the sample picture, wherein N sample picture subsets form a second sample picture set, and by using the first sample picture set and the second sample picture set, training a picture recognition model to be trained.","['G06V10/774', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06V10/764', 'G06V10/82']"
WO2022001517A1,"Information sending method and apparatus based on rumor prediction model, and computer device","The present application relates to the technical field of artificial intelligence, can be applied to the field of smart cities, and discloses an information sending method and apparatus based on a rumor prediction model, a computer device, and a storage medium. The method comprises: detecting the click-through rate of an online article; if the increase of the click-through rate of the online article is greater than a preset increase threshold, performing vectorization to obtain a text vector matrix; inputting the text vector matrix into a rumor prediction model to obtain a predicted probability value; if the predicted probability value is greater than a probability threshold, obtaining a keyword; calling a specified knowledge map; generating a knowledge node salvage tool; performing salvage by means of the knowledge node salvage tool so as to correspondingly obtain a node set; and sending early warning information to a server, wherein the early warning information carrying the node set. Thus, recognition of initial network rumors and prevention of secondary rumors are implemented. The present application further relates to blockchain technology, and the rumor prediction model can be stored in a blockchain.","['G06F16/3344', 'G06F16/35', 'G06F16/367', 'G06F16/953', 'G06F40/295', 'G06F40/30']"
US20180055608A1,"Integrated support device for providing temporary primary stability to dental implants and prosthesis, and related methods","Integrated support devices for providing temporary primary stability to a dental prosthesis implant, each individually designed and manufactured for a specific pre-identify patient are also provided. An integrated support device can include a prosthesis interface member configured to connect to an abutment or reduced sized portion of a dental prosthesis/implant. The integrated support device also includes one or more bonding wings for connecting to the adjacent healthy teeth.","['A61C8/0018', 'A61C13/0003', 'A61C13/0004', 'A61C5/007', 'A61C5/30', 'A61C5/70', 'A61C8/0012', 'A61C8/0036', 'A61C8/005', 'A61C8/0077', 'A61C9/0046', 'G06F17/50', 'G06F30/00', 'A61C13/0013', 'A61C13/0019', 'A61C13/082', 'A61C19/063', 'A61C8/0006', 'A61C8/0075', 'B33Y80/00']"
CN101425449B,"Method for manufacturing semiconductor substrate, semiconductor device and electronic device","A semiconductor substrate including a single crystal semiconductor layer with a buffer layer interposed therebetween is manufactured. A semiconductor substrate is doped with hydrogen to form a damaged layer containing a large amount of hydrogen. After the single crystal semiconductor substrate and a supporting substrate are bonded, the semiconductor substrate is heated so that the single crystal semiconductor substrate is separated along a separation plane. The single crystal semiconductor layer is irradiated with a laser beam from the single crystal semiconductor layer side to melt a region in the depth direction from the surface of the laser-irradiated region of the single crystal semiconductor layer. Recrystallization progresses based on the plane orientation of the single crystal semiconductor layer which is solid without being melted; therefore, crystallinity of the single crystal semiconductor layer is recovered and the surface of the single crystal semiconductor layer is planarized.","['H01L21/20', 'H10D86/0214', 'H01L21/02532', 'H01L21/02686', 'H01L21/76254', 'H10D86/0229', 'H10D86/40', 'H10D86/60', 'H10D30/0323', 'H10D86/411']"
US20160062950A1,Systems and methods for anomaly detection and guided analysis using structural time-series models,"Systems and methods for anomaly detection and guided analysis using structural time-series model. A server may receive a request from a client to analyze a time-series data comprising a plurality of data points. A database of global calendars may be accessed. A structural time-series model may be built from the time-series data and the database of global calendars, the structural time-series model comprising a hidden structure and a plurality of probability distributions, each probability distribution corresponding to a data point. For each data point of the time-series data, a range of expected values is determined from a respective probability distribution, the range of expected values capturing a predefined percentage of the respective probability distribution. An anomaly is detected at a first data point of the time-series data responsive to comparing the first data point with a respective range of expected values. The anomaly is transmitted to the client for display with the time-series data.","['G06F17/18', 'G06F18/2433']"
US12411841B2,Systems and methods for automatically generating source code,"A computer-implemented method is disclosed. The method includes: receiving a request for retrieval of data satisfying one or more criteria, the request including at least one data request parameter; searching a database storing example queries based on the request to identify at least one matching query; providing, to a large language model (LLM), an input prompt to generate a query purporting to retrieve data satisfying the one or more criteria, the input prompt including the at least one data request parameter and the at least one matching query as an example; and receiving, from the LLM, a result including the generated query.","['G06F16/2433', 'G06F16/245', 'G06F8/30']"
CN117237479A,"Product style automatic generation method, device and equipment based on diffusion model","The application relates to the technical field of image processing, in particular to a product style automatic generation method, a system and a storage medium based on a diffusion model. The application relates to a product style automatic generation method based on a diffusion model, which comprises the following specific steps: inputting a related text of a product by a user, wherein the text is matched with a product style knowledge quantization model, and the product style knowledge quantization model automatically predicts the style of the text by analyzing style design elements of the text; converting the text into a text vector using a CLIP model-based text encoder; the text vector and the noise are input into an image generator of the diffusion model together to generate an image of the product style. The automatic product style generation method can automatically generate the product style picture through simple text input, helps a product design platform to improve the design speed and grasp the product style more accurately, thereby designing the product design satisfactory to users.",['Y02P90/30']
US20210012162A1,3d image synthesis system and methods,Aspects of the technology described herein provide a system for improved synthesis of a target domain image from a source domain image. A generator that performs the synthesis is formed based on texture propagation from the first domain to the second domain by making use of a bidirectional generative adversarial network. A framework is provided for training that includes texture propagation with a shape prior constraint.,"['G16H30/40', 'G06K9/6262', 'G06F18/214', 'G06F18/217', 'G06F18/40', 'G06K9/00201', 'G06K9/6253', 'G06K9/6256', 'G06N3/02', 'G06N3/042', 'G06V10/32', 'G06V10/72', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V10/945', 'G06V20/64', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'G06V2201/03']"
US11790535B2,Foreground and background segmentation related to a virtual three-dimensional (3D) video conference,"A method for foreground and background segmentation related to a virtual three-dimensional (3D) video conference, the method may include segmenting each image of multiple images of a video stream, to segments, each segment has one or more properties that are constant; determining temporal properties of the segments; and classifying each segment as a background segment or a foreground segment, based at least in part, on the temporal properties of the segments.","['G06T7/194', 'G06F18/24', 'G06N20/00', 'G06T7/11', 'G06V10/26', 'G06V40/171', 'G06V40/172', 'G06N3/006', 'G06N3/045', 'G06N3/08', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
CN112889005B,Method for generating a characteristic pattern and training a machine learning model,"A method of generating a feature pattern for a patterning process and training a machine learning model. The method for generating the characteristic pattern comprises the following steps: obtaining a trained generator model and an input pattern, the trained generator model configured to generate a feature pattern (e.g., a hotspot pattern); and generating a feature pattern based on the input pattern via simulation of a trained generator model (e.g., CNN), wherein the input pattern is at least one of a random vector, a type of pattern.","['G06F30/392', 'G03F7/705', 'G03F7/70441', 'G03F7/70525', 'G03F7/706839', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094']"
CN110390650A,OCT Image Denoising Method Based on Dense Connection and Generative Adversarial Network,"The invention discloses a kind of based on intensive connection and generates the OCT image denoising method of confrontation network, belong to image restoration technology field, the present invention is according to the feature of noise randomness, mode synthesized reference image is registrated using multiframe, so that network be allow to learn noise image to the mapping relations between reference pictureï¼The step of composite noise, can effectively expand the diversity of speckle noise, synthesize new sample dataï¼It is intensively merged using the Analysis On Multi-scale Features of network, with the recycling and transmitting of less parameter enhancing validity featureï¼Guarantee the overall recognition quality of image in such a way that confrontation generates networkï¼The production model that training is completed can directly handle the noise OCT image of any resolution ratio, have higher speed and performance, there is higher use value in clinic.","['G06T5/70', 'G06T11/008', 'G06T2207/10101', 'G06T2207/30041']"
US10335238B2,System and method for non-invasively estimating electrophysiological maps and measurements from cardio-thoracic 3D images and electrocardiography data,A method and system for patient-specific simulation of cardiac electrophysiology is disclosed. A patient-specific anatomical heart model is generated from medical image data of a patient. A patient-specific cardiac electrophysiology model is generated based on simulated torso potentials and body surface potential measurements of the patient. Cardiac electrophysiology of the patient is simulated over time for the patient-specific anatomical heart model using the patient-specific electrophysiology model. One or more electrophysiology maps are generated based on the cardiac electrophysiology simulated using the patient-specific cardiac electrophysiology model.,"['A61B34/10', 'A61B5/04021', 'A61B5/04028', 'A61B5/044', 'A61B5/319', 'A61B5/327', 'A61B5/339', 'A61B5/343', 'G06T19/00', 'G16H50/50', 'A61B2576/023', 'A61B5/742', 'G06T2210/41']"
US8358806B2,Fast crowd segmentation using shape indexing,"A method for performing crowd segmentation includes receiving video image data (S21). Background differencing is performed on the received video image data to identify a foreground silhouette shape (S22). Approximate number and position of human subjects within the received video image data are determined by matching the foreground silhouette shape against a set of predetermined foreground silhouette shapes, for each of which a number and position of human subjects is known (S28). The estimated number and position of the human subjects is refined to determine a final number and position of the human subjects (S27).","['G06V40/103', 'G06V20/53']"
US12255749B2,Meeting insights with large language models,"In accordance with examples of the present disclosure, a collaborative platform provides a digital collaboration assistant that continuously monitors and analyzes shared meeting contents (e.g., voice, text chat messages, shared links and documents, presentation materials, and the like) by participants during a collaborative meeting in near real-time, periodically updates a structure summary log of the meeting contents that are deemed important during the collaborative meeting, and interacts with the participants throughout the collaborative meeting in near real-time, for example, to answer questions or provide additional information.","['H04L12/1822', 'H04L12/1831']"
CN113888437A,"Image processing method, apparatus, electronic device, and computer-readable storage medium","The embodiment of the application discloses an image processing method, an image processing device, electronic equipment and a computer readable storage medium. The method comprises the following steps: acquiring a plurality of frames of images to be processed, wherein the plurality of frames of images to be processed comprise at least one bright frame image and at least one dark frame image; denoising at least one frame of the bright frame image, and fusing the denoised bright frame image and the at least one frame of dark frame image to obtain a low-light high-dynamic-range LLHDR image; identifying a foreground region in the LLHDR image to obtain a foreground identification result; and performing blurring processing on the LLHDR image based on the foreground identification result to obtain a target image. The image processing method, the image processing device, the electronic equipment and the computer readable storage medium can improve the blurring effect of the image.","['G06T5/70', 'G06T7/10', 'G06T2207/10004', 'G06T2207/20208', 'G06T2207/20221', 'G06T2207/30196', 'G06T2207/30201']"
US11348230B2,Systems and methods for generating and tracking shapes of a target,"Systems and methods for generating and tracking shapes of a target may be provided. The method may include obtaining at least one first resolution image corresponding to at least one of a sequence of time frames of a medical scan. The method may include determining, according to a predictive model, one or more shape parameters regarding a shape of a target from the at least one first resolution image. The method may include determining, based on the one or more shape parameters and a shape model, at least one shape of the target from the at least one first resolution image. The method may further include generating a second resolution visual representation of the target by rendering the determined shape of the target.","['G06T7/246', 'G06T7/251', 'G06F18/2135', 'G06N20/00', 'G06T7/0012', 'G06T7/11', 'G06T7/136', 'G06T7/143', 'G06T7/149', 'G06V10/40', 'G06V10/422', 'G06N3/045', 'G06N3/08', 'G06T2200/04', 'G06T2207/10016', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30048', 'G06V10/476', 'G06V2201/031']"
TWI823028B,Computer readable medium for machine learning based image generation for model based base alignments,"A method for training a machine learning model to generate a predicted measured image includes obtaining (a) an input target image associated with a reference design pattern, and (b) a reference measured image associated with a specified design pattern printed on a substrate, wherein the input target image and the reference measured image are non-aligned images; and training, by a hardware computer system and using the input target image, the machine learning model to generate a predicted measured image.","['G03F7/70516', 'G03F7/705', 'G03F7/70616', 'G03F7/70625', 'G03F7/706845', 'G06T7/32', 'G06T7/337', 'G06V10/774', 'G06V10/82', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084']"
US10817552B2,Input-output example encoding,"Generally discussed herein are devices, systems, and methods for encoding input-output examples. A method of generating a program using an encoding of input-output examples, may include processing an input example of the input-output examples, using a first long short term memory (LSTM) neural network, one character at a time to produce an input feature vector, processing an output example associated with the input example in the input-output examples, using the LSTM neural network, one character at a time to produce an output feature vector, determining (a) a cross-correlation between the input feature vector and the output feature vector or (b) previously computed feature vectors for a different input-output example that are sufficiently close to the input feature vector and the output feature vector, respectively, and using the determined cross-correlation or previously computed vector, generating a program consistent with the input example and the output example.","['G06F16/3344', 'G06N3/08', 'G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N5/003', 'G06N5/01', 'G06N5/046']"
CN114600165A,System and method for modeling surfaces using polarization cues,"A computer-implemented method for surface modeling comprising: receiving one or more polarization original frames of a surface of a physical object, the polarization original frames captured at different linear polarization angles by means of a polarization filter; extracting one or more first tensors in polarization representation space from the polarized original frame; and detecting a surface characteristic of the surface of the physical object based on the one or more first magnitudes in the one or more polarization-representing spaces.","['G06V10/145', 'G01B11/24', 'G06F18/2413', 'G06T7/0004', 'G06T7/55', 'G06V10/60', 'G06V10/764', 'G06V10/82', 'G06V20/80', 'G02B21/0016', 'G02B21/0092', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30156', 'G06V2201/06']"
US20190346442A1,Improved hla epitope prediction,"Adaptive immune responses rely on the ability of cytotoxic T cells to identify and eliminate cells displaying disease-specific antigens on human leukocyte antigen (HLA) class I molecules. Investigations into antigen processing and display have immense implications in human health, disease and therapy. To extend understanding of the rules governing antigen processing and presentation, immunopurified peptides from B cells, each expressing a single HLA class I allele, were profiled using accurate mass, high-resolution liquid chromatography-mass spectrometry (LC-MS/MS). A resource dataset containing thousands of peptides bound to 28 distinct class I HLA-A, -B, and -C alleles was generated by implementing a novel allele-specific database search strategy. Applicants discovered new binding motifs, established the role of gene expression in peptide presentation and improved prediction of HLA-peptide binding by using these data to train machine-learning models. These streamlined experimental and analytic workflows enable direct identification and analysis of endogenously processed and presented antigens.","['G01N33/56977', 'A61K39/0011', 'C12Q1/6881', 'C12Q1/6886', 'G16B25/10', 'G16B30/00', 'G16B40/10', 'A61K2039/5158', 'G01N2560/00']"
US12353979B2,Generating object representations using a variable autoencoder,"Techniques for generating a representation for an object in an environment of an autonomous vehicle are described herein. For example, the techniques may include a decoder of a variable autoencoder receiving latent variable data from a diffusion model and determining an object representation such as a bounding box or a heatmap for one or more objects proximate the autonomous vehicle. The bounding box can include orientation data indicating an orientation for each of the one or more bounding boxes. The object representation(s) can be sent to a vehicle computing device for consideration during vehicle planning, which may include simulation.","['G06N3/0455', 'G05B19/4069', 'G06N3/045', 'G06N3/047', 'G06N3/088']"
CN109640810B,Methods of modulating epileptogenicity in a patient's brain,"The present invention relates to the modulation of epileptogenesis in the brain of epileptogenic patients. The method according to the invention comprises the following steps: providing a virtual brain; providing a model of an epileptogenic region and a propagation region, and loading the model in a virtual brain to create a virtual epileptic brain; acquiring data of the brain of an epileptic patient; identifying in said data the location of at least one potential epileptogenic region; fitting a virtual epileptogenic brain to data acquired from an epileptic patient and parameterizing the at least one likely epileptogenic region into an epileptogenic region in the virtual epileptogenic brain; and simulating an effect of network adjustments in the virtual epileptic brain, the network adjustments simulating clinical intervention to the patient's brain.","['A61B5/4094', 'A61B34/10', 'A61B5/291', 'A61B5/369', 'G16H50/50', 'A61B2034/101', 'A61B2034/105', 'G16H10/60']"
US11975218B2,Radiotherapy plan parameters with privacy guarantees,"Techniques for producing segmentation with privacy are provided. The techniques include receiving a medical image; processing the medical image with a student machine learning model to estimate radiotherapy plan parameters, the student machine learning model being trained to establish a relationship between a plurality of public training medical images and corresponding radiotherapy plan parameters, the radiotherapy plan parameters of the plurality of public training medical images being generated by aggregating a plurality of radiotherapy plan parameter estimates produced by: processing the plurality of public training medical images with a plurality of teacher machine learning models to generate sets of radiotherapy plan parameter estimates; and reducing respective dimensions of the sets of radiotherapy plan parameter estimates or medical images, the radiotherapy plan parameters of the plurality of public training medical images being perturbed in accordance with privacy criteria; and generating a radiotherapy treatment plan based on the estimated radiotherapy plan parameters.","['G06F21/6254', 'A61N5/1039', 'A61N5/103', 'A61N5/1071', 'G06F21/6245', 'G06N3/045', 'G06N3/08', 'G16H20/40', 'G16H30/40', 'A61N2005/1041', 'G06N3/047']"
US20240221738A1,Systems and methods for using silent speech in a user interaction system,"The techniques described herein relate to computerized methods and systems for integrating with a knowledge system. In some embodiments, a user interaction system may include a speech input device wearable on a user and configured to receive an electronic signal indicative of a user's speech muscle activation patterns when the user is speaking. In some embodiments, the electronic signal may include EMG data received from an EMG sensor on the speech input device. The system may include at least one processor configured to use a speech model and the electronic signal as input to the speech model to generate a text prompt. The at least one processor may use a knowledge system to take an action or generate a response based on the text prompt. In some embodiments, the system may provide context to the knowledge system.","['G10L13/027', 'G06N20/00', 'G06F3/011', 'G06F3/012', 'G06F3/015', 'G06F3/017', 'G06N3/092', 'G10L13/033', 'G10L13/047', 'G10L15/06', 'G10L15/18', 'G10L15/22', 'G10L15/24', 'G10L15/25', 'G10L19/012', 'G10L19/04', 'G10L25/18', 'G10L25/78', 'G06F2203/011', 'G10L2015/223']"
US9921283B2,Methods for detecting abnormalities and degenerative processes in soft tissue using magnetic resonance imaging,"The present invention provides methods to detect degenerative processes and abnormalities in soft tissues at high spatial resolution, high signal-to-noise ratio and short scanning times, based on quantitative tissue properties. These methods might provide a useful tool to detect and assess abnormalities in soft tissues and to monitor disease progression.","['G01R33/4828', 'A61B5/055', 'G01R33/50', 'A61B2576/026', 'A61B5/0042', 'A61B5/1073', 'A61B5/4064', 'A61B5/4076', 'G16H30/40']"
US20240331235A1,User interface for generating and manipulating molecular images with natural language instructions,A machine learning model is used to generate molecular images by text-to-image diffusion techniques based on natural language text inputs. The machine learning model is trained on combinations of molecule images and corresponding text such that representatives of both are embedded in latent space. Users provide natural language text describing molecular characteristics and the machine learning model generates an image of a molecule with those characteristics. Existing molecular images or those generated by the system can be further edited and refined with additional natural language text instructions. The system also uses machine vision techniques to understand the molecule represented by a molecular image and translate that image into other representations of the molecule.,"['G16C20/70', 'G06T11/60', 'G06F40/40', 'G06N3/045', 'G06V10/776', 'G16C20/50', 'G16C20/80', 'G06F40/216', 'G06F40/279', 'G06F40/30', 'G06N20/00', 'G16C20/90']"
US12333786B2,Time series generator trained using satellite data,"Implementations are described herein for utilizing the spectral-, spatial-, and temporal-information of a satellite image time series to facilitate crop control or monitoring. In various implementations, a plurality of training examples may be assembled for a generative model. Each training example of the plurality of training examples may include a respective high-resolution image capturing a respective region and a corresponding low-resolution satellite image time series capturing the respective region. The plurality of training examples can be used to train the generative model, to acquire a trained generative model. A high-resolution image depicting one or more agricultural conditions for a given region, can be received and processed using the trained generative model, to generate a synthetic low-resolution satellite image time series, where the synthetic low-resolution satellite image time series represent the one or more agricultural conditions.","['G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V20/13', 'G06V20/188', 'G06V20/70', 'G06V2201/10']"
US12158906B2,Systems and methods for generating query responses,"A computer-implemented method is disclosed. The method includes: obtaining at least one query; clustering a set comprising the at least one query into first clusters; for each first cluster, identifying, by a large language model (LLM), queries in the cluster that are semantically dissimilar; clustering the queries identified as semantically dissimilar into one or more second clusters; receiving an incoming query; matching the incoming query to a particular cluster from the first or second clusters; obtaining one or more generated response messages based on providing, to the LLM, data associated with the particular cluster for the incoming query.","['G06F16/338', 'G06F16/35', 'G06F16/355', 'G06F30/27']"
US20240202405A1,Method and system for analyzing and establishing trust in systems that include artificical intelligence systems,"Method and system for analyzing a computing system for properties of a machine learning model in the computing system include loading input data for the machine learning model; generating a surrogate model that simulates the behavior and/or characteristics, or an approximation of the behavior and/or the characteristics of the machine learning model, by using segments or an entirety of the loaded input data; adjusting the input data and/or the surrogate model to enable an analysis; loading and executing the analysis of a correlation between inputs and outputs of the surrogate model to identify a result pertaining to the input data and/or the machine learning model; generating an output data describing the result; storing the output data pertaining to the result in the memory; determining if the result satisfies a predetermined condition, and if so, executing an action corresponding to the result on the computing system.",['G06F30/27']
CN110612192B,"Apparatus and method for manufacturing three-dimensional object, control apparatus and method, and storage medium","The invention relates to a method for controlling at least one solidification (20) of a generative manufacturing device (1) for manufacturing a three-dimensional object (2) by means of a generative layer-by-layer construction method in which at least one object is manufactured by repeatedly applying layers of a construction material (15), preferably a powder, onto a construction zone (8) and by selectively solidifying the applied layers at locations corresponding to a cross section of the object to be manufactured, and in which a gas is caused to flow over the construction zone in a plurality of flow directions that are distinctly different. The control method comprises the following steps for at least one layer to be cured: receiving and/or determining a distribution of gas flow directions over a build area, assigning a reference flow direction to an area of the build area according to the distribution of flow directions over the area, and operating a solidification device to solidify at least a portion of a cross-section of an object to be manufactured according to the reference flow direction over the area of the build area, in which area the corresponding portion of the cross-section is located.","['B29C64/371', 'B22F10/28', 'B22F10/322', 'B29C64/153', 'B29C64/393', 'B33Y10/00', 'B22F10/366', 'B22F10/80', 'B22F12/70', 'B22F12/90', 'B33Y50/02', 'Y02P10/25']"
EP4184448A1,Method and system for the automatic classification of rocks according to their minerals,"The present disclosure refers to methods and system for classifying rocks according to their minerals from the processing of color images and hyperspectral images. The methods and systems of this disclosure achieve an efficient and low-cost classification of rocks with minerals. In particular, the method uses classification methods that take color images and hyperspectral images and give as a result a probability that the rock or rocks present in said images are suitable or waste.","['G06V10/56', 'G06V10/764', 'B07C5/3425', 'G06V10/26', 'G06V10/52', 'G06V10/54', 'G06V10/58', 'G06V10/77', 'G06V10/806', 'G06V10/82']"
US11762049B2,"Medical data processing apparatus, medical data processing method, and magnetic resonance imaging apparatus","According to one embodiment, a medical data processing apparatus includes processing circuitry. The processing circuitry acquires first data pieces obtained by sparse sampling. The processing circuitry generates first compressed data pieces lower in number than the first data pieces by multiplying the first data pieces by each of sets of weight coefficients and adding each of the multiplied first data pieces. The processing circuitry performs first processing of outputting second compressed data pieces by applying a trained model to the first compressed data pieces, the trained model being trained by receiving first compressed data pieces based on sparse sampling and outputting at least one of second compressed data pieces based on full sampling.","['G01R33/5608', 'G01R33/561', 'G01R33/4818', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G01R33/4824', 'G01R33/50', 'G01R33/5611', 'G06N3/047']"
US20240320873A1,Text-based image generation using an image-trained text,"A method, apparatus, non-transitory computer readable medium, and system for image generation include obtaining a text prompt and encoding, using a text encoder jointly trained with an image generation model, the text prompt to obtain a text embedding. Some embodiments generate, using the image generation model, a synthetic image based on the text embedding.","['G06T11/00', 'G06T2211/441']"
RU2621968C2,Improved neutron system,FIELD: physics.,"['G06F30/20', 'G06F17/11', 'G21D3/001', 'G06F2111/10', 'G21D3/002', 'G21D3/005', 'Y02E30/00', 'Y02E30/30']"
CA3153503C,Maxwell parallel imaging,"A computer that determines coefficients in a representation of coil sensitivities and MR information associated with a sample is described. During operation, the computer may acquire MR signals associated with a sample from the measurement device. Then, the computer may access a predetermined set of coil magnetic field basis vectors, where weighted superpositions of the predetermined set of coil magnetic field basis vectors using the coefficients represent coil sensitivities of coils in the measurement device, and where the predetermined coil magnetic field basis vectors are solutions to Maxwell's equations. Next, the computer may solve a nonlinear optimization problem for the MR information associated with the sample and the coefficients using the MR signals and the predetermined set of coil magnetic field basis vectors.","['G01R33/56581', 'G01R33/5608', 'G01R33/50', 'G01R33/5611', 'G06N20/00', 'G06N3/08']"
US20170124781A1,Calibration for autonomous vehicle operation,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving data associated with a sensor measurement of a perceived object, determining a label associated with the perceived object based on an initial calibration, retrieving log file data associated with the label, determining a calibration parameter associated with the sensor measurement based on the retrieved log file data, and storing the calibration parameter in association with a sensor associated with the sensor measurement. Sensors may be calibrated on the fly while the autonomous vehicle is in operation using one or more other sensors and/or fused data from multiple types of sensors.","['G07C5/0808', 'B60Q1/26', 'B60Q1/28', 'B60Q1/30', 'B60Q1/507', 'B60Q1/508', 'G01C25/00', 'G01S15/86', 'G01S15/872', 'G01S15/931', 'G01S17/86', 'G01S17/875', 'G01S17/931', 'G01S7/40', 'G01S7/497', 'G01S7/4972', 'G01S7/52004', 'G05D1/0038', 'G05D1/024', 'G05D1/0257', 'G05D1/0268', 'G05D1/027', 'G05D1/0272', 'G05D1/0274', 'G05D1/0291', 'G06Q10/06', 'G06Q10/08', 'G07C5/0841', 'G07C5/0866', 'G08G1/005', 'G08G1/056', 'G08G1/096816', 'G08G1/096838', 'G08G1/096844', 'G08G1/20', 'G08G1/202', 'G08G1/207', 'G01S13/865']"
US20250078343A1,Control font generation consistency,Systems and methods for generating custom art fonts with consistent style include receiving user input that identifies a base font style for a custom font and includes descriptive text that defies one or more text effects to use for the custom font. Depth maps are selected for characters to be included in the custom font. The depth maps are preprocessed to add noise to the depth maps. A generative model generates custom font images conditioned with the text prompt and the depth maps. The custom font images are then used to render text on a display screen of a computing device.,"['G06F40/40', 'G06T11/001', 'G06F40/109', 'G06T11/203', 'G06T5/70', 'G06T7/50', 'G06T2200/24']"
US20240428067A1,Methods and systems for solving a stochastic differential equation using a hybrid computer system,"A method for solving a stochastic differential equation includes receiving by a classical computer a partial differential equation describing dynamics of a quantile function QF associated a stochastic differential equation defining a stochastic process as a function of time and variable(s) and the QF defining a modelled distribution of the stochastic process; executing by the classical computer a first training process for training neural network(s) to model an initial quantile function, the neural network(s) being trained by a special purpose processor based on measurements of the stochastic process; executing by the classical computer a second training process wherein the neural network(s) are further trained based on the QFP equation for time interval(s) to model the time evolution of the initial quantile function; and, executing by the classical computer a sampling process including generating samples of the stochastic process using the quantile function, the generated samples representing solutions of the SDE.","['G06N10/60', 'G06N3/08', 'G06F17/13', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09']"
CN208589437U,semiconductor device,"The utility model provides a kind of semiconductor device.Resistance variation rate after the molded packages technique of polysilicon resistance is big.In order to realize it is high-precision trim, it is expected that realizing a kind of resistance hardly by the influence of the stress generated due to molded packages technique in substrate.Resistive element is formed in multiple wiring layers, repeat patterns with the 1st conductive layer (51), the 2nd conductive layer (52) and interlayer conductive layer (53), 1st conductive layer (51) is formed in the 1st wiring layer, 2nd conductive layer (52) is formed in the 2nd wiring layer, and the 1st conductive layer (51) is connect by the interlayer conductive layer (53) with the 2nd conductive layer (52).","['H03K3/011', 'H01L23/49838', 'H01L23/481', 'H01L23/485', 'H01L23/49883', 'H01L23/5226', 'H01L23/5228', 'H03K3/356113', 'H10D1/47', 'H10D84/209', 'H10D89/10', 'H01L23/53266', 'H01L23/53271']"
CA2838324C,"Detecting method of life activity, controlling method of life activity, and transmission method of information concerning life activity","According to a measuring method or a control method of life activity, a life object is illuminated with an electromagnetic wave including a wavelength in a designated waveband, and a characteristic in a local area of the life object is detected, or a life activity thereof is controlled. This ""local area"" is an area constituted by one or more cells. The ""designated waveband"" is defined based on any one of the following phenomena: [1] transition energy between a ground state of a vibration mode newly occurring between atoms in a constituent molecule of a cell membrane and a plurality of excited states; [2] transition energy between vibration modes occurring between specific atoms in a molecule corresponding to the activity of the life object or the change thereof; and [3] a specific chemical shift value in Nuclear Magnetic Resonance.","['A61B5/0075', 'A61B5/0059', 'A61N5/00', 'A61B5/0013', 'A61B5/0068', 'A61B5/01', 'A61B5/05', 'A61B5/055', 'A61B5/14551', 'A61B5/40', 'A61B5/4041', 'A61B5/4519', 'A61B5/486', 'A61B5/7228', 'A61B5/7246', 'G01P13/00', 'A61B2562/0242', 'A61B2576/00']"
CN102105403B,Method for producing water having redox activity and apparatus for producing water having redox activity,"The present invention provides a method for producing water having redox activity and an apparatus for producing water having redox activity, which can cause redox reaction in a living body outside the living body by including active oxygen capable of maintaining operation for a long time in water regardless of transparency (ultraviolet transmittance) of the water, and which can provide a method for producing water having redox activity and an apparatus for producing water having redox activity. The method and apparatus for generating water having redox activity of the present invention mixes at least one of oxygen, ozone, chlorine, nitric oxide, and ammonia as a reaction precursor having an adjusted concentration in water or flowing water in advance, and applies ultrasonic vibration to generate active oxygen in water. In addition, active oxygen is generated in water by bringing water or flowing water into contact with a catalyst to which ultrasonic vibration or electromagnetic waves are applied.","['C02F1/50', 'C02F1/30', 'C02F1/36', 'C02F1/4618', 'C02F1/48', 'B01J21/04', 'B01J21/06', 'B01J21/063', 'B01J35/58', 'B01J37/0215', 'C02F1/725', 'C02F2209/04', 'Y02W10/37']"
US8868406B2,System and method for classifying communications that have low lexical content and/or high contextual content into groups using topics,"Disclosed herein are systems, methods, and non-transitory computer-readable storage media for identifying document topics. A system configured to practice the method receives a document from a corpus of documents, learns interpersonal relationships of users associated with the document, performs a lexical analysis of the document, and, based on the interpersonal relationships of the users and the lexical analysis, identifying a topic for the document. The approaches disclosed herein can integrate user-people relationships to identify topics for documents with low lexical or high contextual content. The system can learn this user-people relationship from context. The system uses this learned behavior to identify communication documents correctly. Another aspect is the separation of the two phases. The system overlays the learned model on the lexical topic analysis, allowing the system to capture user-defined topics and user behavior that is learned from other factors such as medium (calls, events, etc) or user preferences.","['G06F17/2745', 'G06F40/258']"
CN113223010B,Method and system for multi-tissue full-automatic segmentation of oral cavity image,"The invention provides a method and a system for full-automatically segmenting a plurality of tissues of an oral cavity CBCT image, which are characterized in that the data are marked by a deep learning method according to the acquired three-dimensional CBCT data of an original oral cavity, a new image is segmented by a deep learning method again, the image processing process is simple, excessive manual marking and intervention are not needed, the difficulty of the marking of the existing medical data is overcome, and meanwhile, the artificial difference in the image marking process is reduced. In the process of training the network, the countermeasures are generated for the training data, so that the training data quantity is increased, and the universality of the network can be effectively improved. The establishment of the method greatly promotes the segmentation of medical image technology and provides effective technical support for automatic diagnosis and prognosis of oral diseases.","['G06T7/11', 'G06F18/214', 'G06N3/04', 'G06N3/08', 'G06T7/0012', 'G06T7/155', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20152', 'G06T2207/30036']"
US20220291593A1,Method and apparatus for lithographic process performance determination,"A method for characterizing a patterning process, the method including obtaining a plurality of values of stitching errors made along one or more boundaries between at least two patterned adjacent fields or sub-fields on a substrate; and fitting, using a hardware computer system, a distortion model to the plurality of values to obtain a fingerprint representing deformation of a field or sub-field out of the at least two patterned adjacent fields or sub-fields.","['G03F7/70475', 'G03F1/42', 'G03F7/705', 'G03F7/70633', 'G03F9/7003']"
CN102789944B,There is the charged particle microscopy of occlusion detection,"The present invention relates to the charged particle microscopy with occlusion detection.A kind of method using charged particle microscope to check sample, comprises the following steps :-sample is arranged on sample holderï¼-use particle optics lens barrel the most a branch of corpuscular radiation to be directed on sample, thus produce the interaction that the radiation launched is sent from sampleï¼-use the first detector configuration C1Detect the Part I of the radiation launched and produce the first image I based on this1, said method comprising the steps of :-use at least the second detector configuration C2Detect the Part II of the radiation launched and produce the second image I based on this2, thus C2With C1Difference, thus compilation detector configuration set SD={ C1, C2And respective image set SI={ I1, I2}ï¼-use computer-processing equipment automatically to compare SIDifferent members and utilize relative to SDThe sight line mathematics on sample that is blocked of at least one member identify at least one occlusion area.","['H01J37/28', 'H01J37/222', 'H01J37/244', 'H01J2237/2442', 'H01J2237/2445', 'H01J2237/24475', 'H01J2237/2448', 'H01J2237/2611', 'H01J2237/2807', 'H01J2237/2817']"
WO2019237200A1,Precision agriculture system and related methods,"The present disclosure relates to a precision agriculture system and related methods. In one aspect, there is a growing system comprising: a plurality of sensors for sensing one or both of parameters of a plant or parameters of an environment in which the plant is being grown; an environmental control system for controlling one or more growing conditions of the plant; a controller coupled to the plurality of sensors and configured to: receive sensor data from the plurality of sensors; determine whether parameters based at least in part on the sensor data match one or more performance criteria; and cause the environmental control system to perform an adjustment to at least one growing condition of the plant in response to a determination that the parameters do not match the one or more performance criteria.","['G06N3/084', 'A01G9/006', 'A01G9/143', 'A01G9/18', 'A01G9/246', 'A01G9/249', 'G01N33/0098', 'G06N3/045', 'G06N3/047', 'G06Q10/0639', 'G06Q50/02', 'G01N15/01', 'G01N15/06', 'G01N2015/0046', 'G01N2021/8466', 'G01N21/31', 'G01N21/6486', 'G01N21/65', 'G06N3/126', 'Y02A40/10', 'Y02A40/25']"
US20190287654A1,Methods Using Nucleic Acid Signals for Revealing Biological Attributes,"Processes to reveal biological attributes from nucleic acids are provided. In some instances, nucleic acids are used to develop frequency sequence signal maps, construct V-plots, and/or to train computational models. In some instances, trained computational models are used to predict features that reveal biological attributes.","['G16B40/20', 'C12Q1/6886', 'G16B20/00', 'G16B40/30']"
US8477972B2,Method for operating a hearing device,"A method for operating a hearing device comprising an input transducer (1), an output transducer (3) and a signal processing unit (2) for processing an output signal of the input transducer (1) to obtain an input signal for the output transducer (3) by applying a transfer function to the output signal of the input transducer (1) is disclosed. The method comprises the steps of:","['H04R25/43', 'H04R25/70', 'H04R2225/41', 'H04R25/505']"
CN110753935A,Dose reduction using deep convolutional neural networks for medical imaging,"A method of reducing radiation dose for radiological imaging modalities and nuclear medicine by: generating a standard dose nuclear medicine image from a low dose nuclear medicine image using a convolutional network, wherein the network comprises N Convolutional Neural Network (CNN) stages, wherein each stage comprises M convolutional layers with K x K kernels, wherein the network further comprises an encoder-decoder structure with symmetric tandem connections between corresponding stages; downsampling using pooling and upsampling using bilinear interpolation between stages, wherein the network extracts multi-scale and high-level features from the low-dose image to simulate a high-dose image; and adding the series connection to the low-dose image to preserve local information and resolution of the high-dose image, the high-dose image including a Dose Reduction Factor (DRF) of the radiotracer in the patient equal to 1, the low-dose PET image including a DRF of the radiotracer in the patient of at least 4.","['A61B6/037', 'A61B6/4417', 'A61B6/501', 'A61B6/5205', 'G06N20/10', 'G06N3/0464', 'G06N3/08', 'G06T3/4007', 'G06T7/0012', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'A61B6/542', 'G06T2207/10081', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/20004', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/031']"
RU2611191C2,"Treatment of diseases, associated with sex hormones binding globulin (shbg), by inhibition of natural antisense transcript to shbg",FIELD: biochemistry.,"['A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P15/00', 'A61P15/08', 'A61P17/14', 'A61P19/10', 'A61P25/00', 'A61P25/14', 'A61P25/18', 'A61P25/20', 'A61P25/22', 'A61P25/24', 'A61P25/28', 'A61P25/30', 'A61P3/00', 'A61P3/10', 'A61P35/00', 'A61P43/00', 'A61P5/14', 'A61P9/00', 'C12N15/113', 'C12N2310/11', 'C12N2310/113', 'C12N2310/14', 'C12N2310/315', 'Y10T436/143333']"
US11506735B2,Systems and methods for magnetic resonance imaging,"A method for magnetic resonance imaging (MRI) may include obtaining a magnetic resonance (MR) image of a subject, wherein the MR image may be acquired based on a first MRI device and include at least one region of interest (ROI) of the subject. The method may also include selecting, based on the MR image and an ROI determination model, a portion of a main magnetic field generated by the first MRI device. The selected portion of the main magnetic field may correspond to the at least one ROI. The method may also include performing a magnetic field homogenization operation on the selected portion of the main magnetic field.","['G01R33/3875', 'G01R33/24', 'G06N3/045', 'A61B5/055', 'G01R33/243', 'G01R33/32', 'G01R33/5608', 'G06N3/08', 'G06T11/008', 'G06T3/4053', 'G06T2207/10088', 'G06T2207/20104']"
AU2013378058B2,Detecting subsurface structures,"Systems and methods for analyzing geophysical data to identify structures in a subsurface are provided herein. In an exemplary method, an iterative optimization is performed that includes computing similarities between potential shapes and shape cluster models, updating cluster memberships and the shape cluster models, and determining if a criterion is improved from a previous iteration.","['G01V1/301', 'G01V1/28', 'G01V1/345', 'G01V20/00', 'G01V1/40', 'G01V2210/64', 'G01V2210/641', 'G01V2210/642']"
WO2020056418A9,System and method of improving sleep,A method of transplanting a sleep state of a first subject (donor) to a second subject (recipient) comprising: capturing a sleep state of the first subject represented by brain activity patterns; and transplanting the sleep state of the first subject in the second subject by inducing the brain activity patterns in the second subject.,"['A61M21/02', 'A61B5/372', 'A61B5/4809', 'A61B5/4812', 'A61N1/36025', 'A61N1/36031', 'A61N2/006', 'A61N5/0618', 'G16H20/30', 'G16H50/20', 'G16H70/60', 'A61B5/0006', 'A61B5/369', 'A61M2021/0016', 'A61M2021/0022', 'A61M2021/0027', 'A61M2021/0044', 'A61M2021/005', 'A61M2021/0055', 'A61M2021/0072', 'A61M2021/0077', 'A61M2205/507', 'A61M2230/08', 'A61M2230/10', 'A61M2230/60', 'A61N1/0456', 'A61N1/0526']"
TW202102526A,Recombinant adeno-associated viruses and uses thereof,"The present invention relates to recombinant adeno-associated viruses (rAAVs) having capsid proteins engineered to include amino acid sequences that confer and/or enhance desired properties. In particular, the invention provides engineered capsid proteins comprising peptide insertions from heterologous proteins inserted within or near variable region IV (VR-IV) of the virus capsid, such that the insertion is surface exposed on the AAV particle. The invention also provides capsid proteins that direct rAAVs to target tissues, in particular, capsid proteins comprising peptides derived from erythropoietin or dynein that are inserted into surface-exposed variable regions and that target rAAVs to retinal tissue and/or neural tissue, including the central nervous system, and deliver therapeutics for treating neurological and/or eye disorders.","['C07K14/005', 'A61K38/162', 'A61K48/0008', 'A61K48/005', 'A61P25/28', 'A61P27/02', 'C12N15/86', 'C12N2750/14122', 'C12N2750/14143', 'C12N2750/14145', 'C12N2750/14152']"
US20240273261A1,Equivariant trajectory optimization with diffusion models,"Systems and techniques are described herein for modeling tasks using a geometric structure. An example method includes receiving, via a training preparation engine, a training dataset comprising state-action pairs, separating, via the training preparation engine, the state-action pairs from the training dataset into geometric data types, converting, via the training preparation engine, the geometric data types into internal representations, processing, via an equivariant denoising network, the internal representations to generate output data and transforming the output data to a data representation.","['G06F30/27', 'G06F30/10']"
WO2024172904A1,Equivariant trajectory optimization with diffusion models,"Systems and techniques are described herein for modeling tasks using a geometric structure. An example method includes receiving, via a training preparation engine, a training dataset comprising state-action pairs, separating, via the training preparation engine, the state-action pairs from the training dataset into geometric data types, converting, via the training preparation engine, the geometric data types into internal representations, processing, via an equivariant denoising network, the internal representations to generate output data and transforming the output data to a data representation.","['G06N3/045', 'G06N3/092']"
RU2615450C2,Treating diseases associated with nuclear respiratory factor 1 (nrf1) by inhibition of natural antisense transcript to nrf1,FIELD: biochemistry.,"['C12N15/113', 'A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P21/02', 'A61P25/00', 'A61P25/16', 'A61P25/28', 'A61P3/10', 'A61P35/00', 'A61P37/00', 'A61P43/00', 'A61P5/48', 'A61P9/10', 'C12Q1/6811', 'C12N2310/11', 'C12N2310/113', 'C12N2310/312', 'C12N2310/314', 'C12N2310/315', 'C12N2310/316', 'C12N2310/321', 'C12N2310/322']"
US20240169604A1,Text and color-guided layout control with a diffusion model,Systems and methods for image generation are described. Embodiments of the present disclosure obtain user input that indicates a target color and a semantic label for a region of an image to be generated. The system also generates of obtains a noise map including noise biased towards the target color in the region indicated by the user input. A diffusion model generates the image based on the noise map and the semantic label for the region. The image can include an object in the designated region that is described by the semantic label and that has the target color.,"['G06T11/001', 'G06F3/04842', 'G06F3/04845', 'G06T11/20']"
WO2020025696A1,Method and system for augmented imaging using multispectral information,"Disclosed herein is a method of generating augmented images of tissue of a patient, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: obtaining one or more multispectral images of said tissue, and applying a machine learning based regressor or classifier, or an out of distribution (OoD) detection algorithm for determining information about the closeness of the multispectral image or parts of said multispectral image to a given training data set, or a change detection algorithm to at least a part of said one or more multispectral images, or an image derived from said multispectral image, or to a time sequence of multispectral images, parts of multiple images or images derived therefrom, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image.","['G06T7/0012', 'G06F18/241', 'G06T7/254', 'G06T2207/20081']"
US20220117956A1,Lsd for the treatment of alzheimer's disease,The invention features methods and compositions for the treatment of Alzheimer's Disease using lysergic acid diethylamide and pharmaceutically acceptable salts thereof.,"['A61K31/48', 'A61K31/13', 'A61K45/06', 'A61K9/4858', 'A61K9/5078', 'A61P25/28']"
US12340480B2,Text-to-3D avatars,"Three-dimensional (3D) avatars may be produced by stylizing a dataset of images based on a user-input text prompt input to a stable diffusion model, and using the output stylized dataset of images to train an efficient geometry-aware 3D generative adversarial network (EG3D) model.","['G06T15/02', 'A63F13/52', 'G06N3/006', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06T13/40', 'G06T17/00', 'G06T19/20', 'A63F2300/66', 'G06T2219/2024']"
US11965881B2,Nanosensors and methods for detection of biological markers,"Methods and devices for microfluidic detection of a biological maker in a biospecimen collected from a subject are disclosed. The microfluidic devices include nanoparticle-based nanosensors comprising supramolecular recognition sequences, protease consensus sequences, post-translationally modifiable sequences, or sterically hindered benzylether bonds for specific interaction with a biological marker. Also disclosed are particular nanosensors for detecting cytokines, and other proteins based upon supramolecular recognition without chemical modification or enzymatic cleavage.","['G01N33/54346', 'B01L3/502715', 'G01N33/50', 'G01N33/574', 'B01L2300/0636', 'B01L2300/0816', 'G01N2333/70596']"
US20080292194A1,Method and System for Automatic Detection and Segmentation of Tumors and Associated Edema (Swelling) in Magnetic Resonance (Mri) Images,"A method and system for segmenting an object represented in one or more input images, each of the one or more input images comprising a plurality of pixels. The method comprising: aligning the one or more input images with one or more corresponding template images each comprising a plurality of pixels; extracting features of each of the one or more input images and one or more template images; and classifying each pixel, or a group of pixels, in the one or more input images based on the measured features of the one or more input images and the one or more corresponding template images in accordance with a classification model mapping image properties or features to a respective class so as to segment the object represented in the one or more input images according to the classification of each pixel or group of pixels.","['G06T7/0012', 'A61B5/4076', 'A61B5/7267', 'G06T7/11', 'G06T7/143', 'A61B5/055', 'A61B5/4878', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20192', 'G06T2207/30016', 'G06T2207/30096', 'G16H50/70']"
CN101743229B,Quinazolinamide derivatives,"The invention relates to novel quinazolinamide derivatives of formula (I) wherein R1 - R3 have the meanings cited in claim 1. Said derivatives are HSP90 inhibitors and can be used to produce a medicament for treating diseases, in which the inhibition, regulation and/or modulation of HSP90 plays a part.","['C07D239/84', 'A61P1/04', 'A61P1/16', 'A61P11/06', 'A61P13/12', 'A61P17/02', 'A61P17/06', 'A61P19/02', 'A61P21/00', 'A61P25/00', 'A61P25/14', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/10', 'A61P31/00', 'A61P31/04', 'A61P31/12', 'A61P31/16', 'A61P31/18', 'A61P31/20', 'A61P31/22', 'A61P35/00', 'A61P35/02', 'A61P35/04', 'A61P37/00', 'A61P37/02', 'A61P37/06', 'A61P43/00', 'A61P9/10', 'A61P9/14', 'C07D401/14', 'C07D403/06', 'C07D403/14', 'C07D405/14', 'C07D417/14']"
TWI810679B,Methods and systems to determine shapes for semiconductor or flat panel display fabrication,"Methods for calculating a pattern to be manufactured on a substrate include inputting a physical design pattern, determining a plurality of possible neighborhoods for the physical design pattern, generating a plurality of possible mask designs for the physical design pattern, calculating a plurality of possible patterns on the substrate, calculating a variation band from the plurality of possible patterns, and modifying the physical design pattern to reduce the variation band. Embodiments also include inputting a set of parameters for a neural network to calculate a pattern to be manufactured on a substrate, calculating a plurality of patterns to be manufactured on the substrate for the physical design in each possible neighborhood of the plurality of possible neighborhoods, training the neural network with the calculated plurality of patterns, and adjusting the set of parameters to reduce the manufacturing variation for the calculated plurality of patterns to be manufactured on a substrate.","['G03F1/78', 'G03F1/36', 'G03F7/70441', 'G03F1/70', 'G03F7/705', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'H01J37/3177', 'G06F30/398', 'G06N20/00', 'G06N5/01', 'H01J2237/31761']"
CN104579646B,"Method, device and circuit that the limited monotonic transformation of clobber book and encryption and decryption thereof are applied","The invention discloses the limited monotonic transformation of clobber book and encryption and decryption application thereof.Wherein, the method for the limited monotonic transformation of clobber book initial clobber book is carried out after monotonic transformation with text XOR, and the number of times that initial clobber book participates in monotonic transformation is limited.The method of the limited monotonic transformation of clobber book of the present invention is in fact a kind of with the encipher-decipher method of bandwidth throw-over degree, namely to spend a small amount of bandwidth to exchange encryption/decryption speed for.Compare and traditional standard encryption and decryption method, method of the present invention needs to consume a small amount of bandwidth, under the prerequisite of fail safe ensureing data, can improve the encrypting and decrypting speed of ten times and even hundred times.And the present invention realizes simply, therefore can be widely used in Large Volume Data storage and transmission in.","['H04L9/06', 'H04L9/08']"
CN108073760A,For obtaining the method and system that analysis model writes knowledge,"The present invention relates to for obtaining the method and system that analysis model writes knowledge.Specifically, some embodiments are directed to the system for writing prediction model.Embodiment includes implementing development environment come for generating the computer system of prediction model.Prediction model authoring tool is configured to:One or more users based on the Interface Controller for being provided to prediction model authoring tool input to perform modelling operability, determine the modeling background of modelling operability, the one or more user's inputs of record, prediction model is generated based on the one or more model parameters limited during modelling operability, prediction model is contacted to assets so that from asset acceptance to operation of one or more data sets in prediction model during be provided to prediction model, operation prediction model is caused to cause prediction model from asset acceptance data, and provide modeling background, one or more user's inputs and one or more model parameters.","['G06Q10/04', 'G06N5/02', 'G06F30/00', 'G06F16/90335', 'G06F8/24', 'G06N20/00']"
CN118229817A,Picture generation acceleration method for text-generated picture diffusion large model,"A picture generation acceleration method for a large diffusion model of a text-to-text graph is characterized in that a pre-trained text-to-text graph diffusion model is subjected to linear interpolation sampling by adopting a stepwise resampling strategy for a later step and a former step in a noise adding path in the noise adding process of the diffusion model, so that intermediate noise adding is obtained, and model training is performed through a consistency constraint relation between the intermediate noise adding and the former step noise adding; meanwhile, in the denoising and inverse sampling process of the diffusion model, solving is carried out step by step for a plurality of times in the interval between the later step and the earlier step; errors in training are reduced through a stepwise resampling strategy and a multi-step inverse sampling strategy, the inverse sampling times of the diffusion model are reduced, and the acceleration of the picture generation of the pre-trained diffusion model is completed. The invention is based on the training thought of the consistency model, and further accelerates the generation efficiency of pictures while inheriting the overall advantages of the diffusion model, and the trained model has excellent performance and less calculation cost.","['G06T11/00', 'G06N3/0455', 'G06N3/082', 'G06T3/4007', 'G06T5/70']"
CN117152600A,An underwater image processing method based on lightweight diffusion model,"The invention belongs to the field of image processing, and discloses an underwater image processing technology based on a lightweight diffusion model, which aims to solve the serious degradation problem of an underwater image and is beneficial to the development of subsequent tasks. Firstly, analyzing color distribution of images in a underwater dataset with reference as prior; secondly, defining a search space and a neural network of a neural architecture search algorithm; thirdly, guiding the training process of the latent diffusion model by using the distribution priori; and finally, combining a plurality of network modules obtained according to a neural architecture search algorithm into a plurality of latent diffusion models, evaluating model performances, and selecting models for different terminal devices according to the performances. The invention can enhance the quality of the underwater image and generate the underwater image with stronger diversity by utilizing the data distribution learning advantage of the diffusion model. In addition, the invention also automatically searches the proper diffusion model according to the resource limit of the terminal equipment, thereby achieving the purpose of lightweight design.","['G06V20/05', 'G06V10/56', 'G06V10/774', 'G06V10/82']"
CN117314935A,Diffusion model-based low-quality fundus image enhancement and segmentation method and system,"The present disclosure provides a method and a system for enhancing and segmenting a low-quality fundus image based on a diffusion model, comprising: obtaining a corresponding fundus blood vessel mask through matched filtering based on the low-quality fundus image; based on the low-quality fundus image and the corresponding illumination map, a pre-trained UNet network is utilized to obtain a degradation factor of the low-quality image, wherein jump connection is arranged between input and output of the UNet network, and a attention mechanism is arranged in a symmetrical expansion path of the UNet network; taking the low-quality fundus image and the fundus blood vessel mask corresponding to the low-quality fundus image as input of a pre-trained diffusion model to obtain the fundus image after image enhancement and the fundus blood vessel mask corresponding to the fundus image; the diffusion model adopts a UNet network, a prediction head for predicting a vascular mask is arranged behind a denoising device at the last layer of the UNet network, and the degradation factors are embedded into the diffusion model and are associated with fundus images after image enhancement.","['G06T7/11', 'G06N3/0464', 'G06N3/08', 'G06T7/0012', 'G06T2207/20081', 'G06T2207/30041', 'G06T2207/30101']"
US20180122143A1,Hybrid photonic vr/ar systems,"A VR/AR system, method, architecture includes an augmentor that concurrently receives and processes real world image constituent signals while producing synthetic world image constituent signals and then interleaves/augments these signals for further processing. In some implementations, the real world signals (pass through with possibility of processing by the augmentor) are converted to IR (using, for example, a false color map) and interleaved with the synthetic world signals (produced in IR) for continued processing including visualization (conversion to visible spectrum), amplitude/bandwidth processing, and output shaping for production of a set of display image precursors intended for a HVS.","['G06T19/006', 'G02B27/017', 'G02B27/0172', 'G02B5/30', 'H04N23/84', 'H04N9/31', 'H04N9/64', 'G02B2027/011', 'G02B2027/0118', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0187', 'G02B27/0101', 'G06T2200/21', 'G06T2200/28', 'G06T2207/10048']"
CN101794111B,"Image recording medium, hologram replicating device and hologram replicating method","An image recording medium in which a refractive index modulation is recorded in a material in a layer such that, when the hologram recording medium is illuminated from a predetermined angle and a viewpoint is moved horizontally with respect to a normal line, a hologram image having continuous parallax in at least the horizontal direction is reproduced and that, when the viewpoint is moved in a direction with respect to the normal line different from the horizontal direction, another image that is different from and thus is not continuous with the hologram image is reproduced.","['G03H1/268', 'G03H1/202', 'G03H1/265', 'G03H1/0011', 'G03H2001/0421', 'G03H2210/441', 'G03H2210/454', 'G03H2210/562']"
EP3709877A2,Methods for using machine learning and mechanistic models for biological feature mapping with multiparametric mri,"Described here are systems and methods for generating and implementing a hybrid machine learning and mechanistic model to produce biological feature maps, or other measurements of biological features, based on an input of multiparametric magnetic resonance or other images. The hybrid model can include a combination of a machine learning model and a mechanistic model that takes as an input multiparametric MRI, or other imaging, data to generate biological feature maps (e.g., tumor cell density maps), or other measures or predictions of biological features (e.g., tumor cell density). The hybrid models have capabilities of learning individual-specific relationships between imaging features and biological features.","['G06N20/10', 'G06F18/2155', 'G06N5/022', 'G06N7/01', 'G06T7/0012', 'G16H30/40', 'G16H50/20', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/30016', 'G06T2207/30096', 'G16H20/40']"
WO2019103912A2,Content based image retrieval for lesion analysis,"Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are commonly used to assess patients with known or suspected pathologies of the lungs and liver. In particular, identification and quantification of possibly malignant regions identified in these high-resolution images is essential for accurate and timely diagnosis. However, careful quantitative assessment of lung and liver lesions is tedious and time consuming. This disclosure describes an automated end-to-end pipeline for accurate lesion detection and segmentation.","['G16H50/20', 'G06N3/08', 'G06T7/0012', 'G06T7/11', 'G06T7/143', 'G06T7/194', 'G06V10/82', 'G16H10/60', 'G16H20/10', 'G16H20/40', 'G16H30/40', 'G16H50/70', 'G16H70/20', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20152', 'G06T2207/30056', 'G06T2207/30064', 'G06T2207/30096']"
CN114302953B,Bacillus strain and method for promoting plant growth by using same,"The present invention relates to a composition comprising a strain of bacillus sp NRRL B-67746 and a biologically pure culture of a mutant of this strain having all the identifying characteristics of this strain. The invention also provides a method of promoting plant growth, wherein the method comprises applying the strain or mutant to a plant, plant part and/or plant location.","['A01N63/22', 'A01P21/00', 'A01P3/00', 'A01P5/00']"
CN118072143A,"Missing mode generation method, system and storage medium based on diffusion model","The invention discloses a missing mode generation method, a system and a storage medium based on a diffusion model, wherein the method comprises the following steps: constructing a missing mode generation network model based on a UNet backbone network based on a conditional diffusion model, wherein the multiple modes respectively correspond to one missing mode generation network model, inputting noisy data for adding noise to a sample missing mode, the noise adding degree and other conditional modes consisting of non-missing modes during model training, and outputting a noise predicted value in the noisy data of the sample missing mode; the method also comprises the steps of constructing samples with higher deletion rate from the existing data as supplementary data of model training, and improving the capability of the model for processing the deletion condition of different types of data; and denoising the noisy data by using the prediction noise output by the model to obtain the missing mode information. The method can flexibly cope with the task of generating the missing mode under any mode missing, has stable model training and has a better missing mode recovery result.","['G06V10/82', 'G06N3/0464', 'G06N3/08', 'Y02D10/00']"
US11361440B2,Method and system for diagnosis of COVID-19 disease progression using artificial intelligence,"Embodiments of the disclosure provide methods and systems for disease condition prediction from images of a patient. The system may include a communication interface configured to receive a sequence of images acquired of the patient by an image acquisition device. The sequence of images are acquired at a sequence of prior time points during progression of a disease. The system may include a processor, configured to determine regions of interest based on the sequence of images. The processor applies a progressive condition prediction network to the regions of interest to predict a level of disease progression at a future time point during the progression of the disease. The progressive condition prediction network predicts the level of disease progression based on the regions of interest and disease conditions at the sequence of prior time points. The processor further provides a diagnostic output based on the predicted level of disease progression.","['G06T7/0012', 'A61B5/08', 'A61B5/7267', 'A61B6/032', 'A61B6/50', 'A61B6/5217', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G16H10/60', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G16H50/80', 'A61B5/004', 'A61B5/7275', 'A61B6/025', 'A61B6/469', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30061']"
CN114930399A,Image generation using surface-based neurosynthesis,"Aspects of the present disclosure relate to systems and methods for performing operations, including: receiving a two-dimensional continuous surface representation of a three-dimensional object, the continuous surface comprising a plurality of landmark localizations; determining a first set of soft membership functions based on the landmark locations and the relative locations of the points in the two-dimensional continuous surface representation; receiving a two-dimensional input image, the input image comprising an image of an object; extracting a plurality of features from an input image using a feature recognition model; generating an encoded feature representation of the extracted features using a first set of soft membership functions; generating a dense feature representation of the extracted features from the encoded representation using a second set of soft membership functions; and processing the second set of soft membership functions and the dense feature representation using a neural image decoder model to generate an output image.","['G06T11/001', 'G06F17/18', 'G06F18/22', 'G06F18/253', 'G06T15/04', 'G06T5/50', 'G06V10/74', 'G06V10/806', 'G06V20/647', 'G06V40/103', 'G06T2207/20084']"
US12020807B2,Algorithm orchestration of workflows to facilitate healthcare imaging diagnostics,"Techniques for orchestrating execution of algorithms on medical images according to pre-defined workflows and techniques for managing workflow and model execution are provided. In an embodiment, a system comprises a memory that stores computer executable components and a processor that executes the computer executable components stored in the memory. The computer executable components comprise an algorithm catalog that comprises algorithm information identifying algorithms available for processing medical images, the algorithm information comprising algorithm execution instructions for executing the algorithms as web-services; and an onboarding component that adds the algorithm information to the algorithm catalog in response to reception of the algorithm information via an onboarding user interface of an algorithm management application, wherein based on inclusion of the algorithm information in the algorithm catalog, the algorithms are made available for incorporating into workflows for executing the algorithms on the medical images.","['G16H30/20', 'G06F11/079', 'G06F11/3476', 'G06Q10/067', 'G06T7/0012', 'G16H30/40', 'G16H40/20', 'G16H50/20', 'H04L63/102', 'G06F11/0751', 'G06F11/0766', 'G06F11/3698']"
US10360472B2,"System, method and computer-accessible medium for determining brain microstructure parameters from diffusion magnetic resonance imaging signal's rotational invariants","An exemplary system, method and computer-accessible medium for determining a plurality of tissue parameters of a tissue(s), can include, for example, receiving information related to a plurality of rotational invariants contained within a diffusion magnetic resonance (dMR) image(s) of the tissue(s), and generating the tissue parameters using a set of rotational invariants related to the plurality of tissue parameters using such information. The tissue parameters can be generated by factorizing a response of an individual fiber segment of the tissue(s) based on the set of rotational invariants. The response of the individual fiber segments can be factorized from an orientational distribution function (âODFâ). The individual fiber segments can be factorized using a scalar tensor factorization(s) of the rotational invariants. The set of rotational invariants can be of a rotation group SO(3).","['G06K9/52', 'A61B5/055', 'G01R33/5608', 'G06V10/42', 'A61B2576/026', 'A61B5/0042', 'A61B5/7203', 'G01R33/56341', 'G16H30/40']"
US8458715B1,System for allocating resources to optimize transition from a current state to a desired state,"Described is a Distributed Resource Allocation System (DRAS) for sensor control and planning. The DRAS comprises an information framework module that is configured to specify performance goals, assess current performance state, and includes sensor models to achieve the performance goals. The DRAS is configured to further allocate the sensors to achieve the performance goals. Once allocated, the DRAS then reassesses the current performance state and continues reallocating the sensors until the current performance state is most similar to the performance goals.","['G06F9/50', 'G06Q10/06']"
US8285059B2,Method for automatic enhancement of images containing snow,A content-based image processing method and system are provided for images identified as having snow content. Images having dark snow content are identified and processed with a first enhancement chain tailored to enhancing images which would be generally perceived as having dark snow while images having blue snow content are identified and processed with a second enhancement chain tailored to enhancing images which would be generally perceived as having blue snow.,"['G06T5/40', 'G06T5/90', 'H04N21/44008', 'H04N21/4402', 'H04N21/84', 'H04N5/57', 'H04N9/643', 'G06T2207/10024', 'G06T2207/20012', 'H04N23/88']"
CN102089326B,Anti-IL-6/IL-6R antibodies and methods of use thereof,"This invention provides fully human monoclonal antibodies that recognize the IL-6/IL-6R complex. The invention further provides methods of using such monoclonal antibodies as a therapeutic, diagnostic, and prophylactic.","['C07K16/2866', 'A61P1/04', 'A61P11/06', 'A61P17/06', 'A61P19/02', 'A61P25/00', 'A61P25/28', 'A61P29/00', 'A61P35/00', 'A61P37/00', 'A61P37/06', 'C07K16/248', 'C07K2317/21', 'C07K2317/32', 'C07K2317/33', 'C07K2317/56', 'C07K2317/565', 'C07K2317/73', 'C07K2317/76', 'C07K2317/92']"
RU2611186C2,TREATMENT OF TUMOR PROTEIN 63 (p63) RELATED DISEASES BY INHIBITION OF NATURAL ANTISENSE TRANSCRIPT TO p63,FIELD: biochemistry.,"['C12N15/113', 'A61K31/7088', 'A61P1/02', 'A61P11/00', 'A61P15/00', 'A61P15/12', 'A61P17/00', 'A61P17/02', 'A61P17/04', 'A61P17/08', 'A61P17/14', 'A61P17/16', 'A61P19/04', 'A61P27/02', 'A61P35/00', 'A61P43/00', 'A61P5/00', 'C12N15/1135', 'C12Q1/6811', 'C12N2310/11', 'C12N2310/113', 'C12N2310/31', 'C12N2310/315', 'C12N2310/32', 'C12N2310/321', 'C12N2310/3231', 'C12N2310/33']"
US20230277065A1,"Active illumination and time-of-flight camera system to evaluate facial blood flow, eye movements and physiological parameters","A measurement system comprising one or more semiconductor diodes configured to penetrate tissue comprising skin. The detection system comprising a camera, which may also include a direct or indirect time-of-flight sensor. The detection system synchronized to the pulsing of the semiconductor diodes, and the camera further coupled to a processor. The detection system non-invasively measuring blood within the skin, measuring hemoglobin absorption between 700 to 1300 nm, and the processor deriving physiological parameters and comparing properties between different spatial locations and variation over time. The semiconductor diodes may comprise vertical cavity surface emitting lasers, and the detection system may comprise single photon avalanche photodiodes. The measurement system may be used to observe eye parameters and differential blood flow. The system may be used with photo-bio-modulation therapy, or it may be used in advanced driver monitoring systems for multiple functions including head pose, eye tracking, facial authentication, and smart restraint control systems.","['G01N33/15', 'A61B5/0013', 'A61B5/0022', 'A61B5/0075', 'A61B5/0077', 'A61B5/0086', 'A61B5/0088', 'A61B5/0091', 'A61B5/0261', 'A61B5/14532', 'A61B5/14546', 'A61B5/1455', 'A61B5/4547', 'A61B5/6801', 'A61B5/7203', 'A61B5/7257', 'A61B5/7405', 'A61B5/742', 'A61C19/04', 'G01J3/02', 'G01J3/0218', 'G01J3/108', 'G01J3/14', 'G01J3/28', 'G01J3/2823', 'G01J3/42', 'G01J3/453', 'G01M3/38', 'G01N21/3151', 'G01N21/35', 'G01N21/3504', 'G01N21/3563', 'G01N21/359', 'G01N21/39', 'G01N21/88', 'G01N33/02', 'G01N33/025', 'G01N33/442', 'G01N33/49', 'G16H20/00', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16Z99/00', 'A61B2562/0233', 'A61B2562/0238', 'A61B2562/146', 'A61B2576/02', 'A61B5/0024', 'A61C1/0046', 'G01J2003/104', 'G01J2003/1208', 'G01J2003/2826', 'G01J3/1838', 'G01N2021/3513', 'G01N2021/3595', 'G01N2021/399', 'G01N21/85', 'G01N21/9508', 'G01N2201/061', 'G01N2201/06113', 'G01N2201/062', 'G01N2201/0627', 'G01N2201/08', 'G01N2201/12', 'G01N2201/129', 'G01N2201/1296', 'H01S3/0092', 'H01S3/06758', 'H01S3/302', 'Y02A90/10']"
RU2612161C2,Treatment of pancreatic developmental gene related diseases by inhibition of natural antisense transcript to pancreatic developmental gene,FIELD: chemistry.,"['C12N15/113', 'A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P1/00', 'A61P1/04', 'A61P1/14', 'A61P1/16', 'A61P1/18', 'A61P11/02', 'A61P13/10', 'A61P13/12', 'A61P17/06', 'A61P19/02', 'A61P19/08', 'A61P19/10', 'A61P21/00', 'A61P21/02', 'A61P21/04', 'A61P25/00', 'A61P25/04', 'A61P25/16', 'A61P25/24', 'A61P25/28', 'A61P27/02', 'A61P27/12', 'A61P29/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P31/00', 'A61P31/20', 'A61P31/22', 'A61P35/00', 'A61P37/02', 'A61P37/06', 'A61P37/08', 'A61P9/00', 'A61P9/04', 'A61P9/06', 'A61P9/10', 'C12Q1/6813', 'C12N2310/11']"
US20210015417A1,Emotion data training method and system,"The present invention relates to a computer implemented method for training one or more parameters of a model. More particularly, the present invention relates to a computer implemented method for training one or more parameters of a model based on emotion signals. Aspects and/or embodiments seek to provide a computer implemented method which can calculate and/or predict emotion signals for training software implementations of mathematical models or machine learned models based on these emotion signals.","['G10L25/63', 'A61B5/165', 'A61B5/486', 'A61B5/6802', 'G06N20/00']"
CN103842362B,Compositions and methods for treating Alzheimer's disease,The present invention provides compositions for reducing amyloid plaque burden associated with Alzheimer's disease and methods of using the same.,"['A61K31/519', 'A61K31/4418', 'A61K31/437', 'A61K31/4439', 'A61K31/496', 'A61K31/5025', 'A61K31/506', 'A61K31/5377', 'A61K31/5513', 'A61P25/28', 'A61P43/00', 'C07D211/16', 'C07D213/82', 'C07D231/40', 'C07D401/04', 'C07D401/12', 'C07D401/14', 'C07D403/04', 'C07D403/12', 'C07D405/14', 'C07D413/04', 'C07D417/04', 'C07D471/04', 'C07D487/04', 'C07D513/04']"
US20070258329A1,Method and apparatus for the exploitation of piezoelectric and other effects in carbon-based life forms,"The invention promotes piezoelectric effects in carbon-based life forms using specific geometries, ratios, frequencies and combinations therein using associated vibrational states functioning in part, as bi-directional holographic transducers between the acoustic and electromagnetic domains.","['A63B53/10', 'A63B53/04', 'A63B60/00', 'A63B2209/00']"
RU2639550C2,"Treatment of diseases connected with site-1 membrane-impacted peptidase of transcription factors (mbtps1), by inhibiting natural antisense transcript to mbtps1","FIELD: medicine.SUBSTANCE: method of increasing site-1 gene expression membrane-impacted peptidase of transcription factors (MBTPS1), in cells or tissues of a mammal in vivo or in vitro, including: bringing these cells or tissues in contact with at least one antisense oligonucleotide comprising a length of 10 to 30 nucleotides, which specifically hybridizes with complementary plot of natural antisense polinucleotide, which has a sequence of SEQ ID NO: 2, and increases, due to this, the expression of the specified site-1 gene membrane-impacted peptidase of transcription factors (MBTPS1) in cells or tissues of a mammal in vivo or in vitro. Also presented an antisense oligonucleotide, at a length of approximately 10-30 nucleotides that contains at least one modification, where specified at least one modification is selected of: at least one of the modified fragment of sugar; at least one modified intenucleotid link; at least one modified nucleotide and their combinations; wherein the specified antisense oligonucleotide gibridizes with natural antisense polinucleotide of site-1 gene of membrane-impacted peptidase of transcription factors (MBTPS1) with a sequence of SEQ ID NO: 2, and increases, due to this, site-1 gene membrane-impacted peptidase of transcription factors (MBTPS1) in vivo or in vitro compared to control, and in doing so: the said oligonucleotide has sequence at least 80% identical to reverse complementary sequence to section of length of 10-30 nucleotides from the sequence SEQ ID NO: 2, or the specified oligonucleotide has sequence at least 80% identical to the section of 10-30 nucleotides in the sequence of SEQ ID NO: 1. Moreover, the composition is described, containing submitted an antisense oligonucleotide and method of preventing or treating disease associated with site-1 gene membrane-impacted peptidase of transcription factors (MBTPS1) and/or PIN specified gene MBTPS1 product, including use of submitted antisense oligonucleotide.EFFECT: FIELD: increased efficiency.24 cl, 1 dwg, 2 ex","['A61K31/7088', 'A61K31/713', 'A61K38/00', 'A61K48/00', 'A61P1/00', 'A61P1/16', 'A61P19/04', 'A61P29/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P43/00', 'A61P9/00', 'C12N15/09', 'C12N15/11', 'C12N15/113', 'C12N15/1137', 'C12N15/1138', 'C12N15/63', 'C12N15/64', 'C12Y304/21112', 'C12N2310/11', 'C12N2310/113', 'C12N2310/313', 'C12N2310/314', 'C12N2310/315', 'C12N2310/321', 'C12N2310/322', 'C12N2310/3231', 'Y10T436/143333']"
CN103246175B,Lens heating aware source mask optimization for advanced lithography,"A computer-implemented method for improving a lithographic process for imaging a portion of a design layout onto a substrate using a lithographic projection apparatus comprising an illumination source and projection optics, the method including computing a multi-variable cost function of a plurality of design variables that are characteristics of the lithographic process, at least some of the design variables being characteristics of the illumination source and the design layout, the computing of the multi-variable cost function accounting for lens heating effects; and reconfiguring the characteristics of the lithographic process by adjusting the design variables until a predefined termination condition is satisfied.","['G03F7/00', 'G06F30/398', 'G03F7/20', 'G03F7/70125', 'G03F7/70433', 'G03F7/705', 'G03F7/70891', 'G03F9/00']"
CN101632018B,Sensor device and method for sensing magnetic particles,"The present invention relates to a kind of sensor device (50) for being used for sensing magnetic particles (15), the sensor device (50) includesï¼Substrate (25)ï¼It is provided on the substrate (25) and/or wherein and/or neighbouring sensing unit (11,20), it is adapted to the existing detection signal that sensing represents the magnetic particle (15)ï¼And the magnetic field control unit (30 to 34) outside the substrate (25) is provided at, it is adapted to the magnetic field of generation and time correlation to be interacted with the magnetic particle (15).","['G01N33/54373', 'B82Y25/00', 'G01N27/745', 'G01N33/54326', 'G01R33/07', 'G01R33/093', 'G01R33/12', 'G01R33/1269', 'G01R33/1276']"
CN105764402B,Stereoscopic endoscope system,"Stereoscopic endoscope system hasï¼1st image pickup part and the 2nd image pickup part, they have the 1st photographing element and the 2nd photographing element respectively, 1st photographing element and the 2nd photographing element configure with dividing right and left in endoscope leading section, for obtaining common subject respectively along the 1st visual field direction and the 2nd visual field directionï¼Reference component, it is integrally provided to endoscope distal end portion, at least front is photographed in the 1st image pickup scope and the 2nd image pickup scope that can be shot respectively by the 1st photographing element and the 2nd photographing element, and the reference component turns into benchmark when the 1st image pickup part of adjustment and 2 image pickup partï¼And adjustment portion, in the case that its 1st image when the 1st photographing element and the 2nd photographing element are photographed into reference component respectively and the 2nd image are shown in display device as left images, image captured by the image pickup part of at least one party is adjusted or the image pickup part of a side is adjusted, to cause generation close to the image of symmetrical state.","['H04N13/239', 'A61B1/00057', 'A61B1/00193', 'A61B1/00194', 'A61B1/045', 'A61B1/05', 'G02B23/2415', 'G02B23/2423', 'G02B23/2461', 'G02B23/2484', 'G02B23/26', 'H04N13/296', 'H04N23/555']"
CN111542843A,Active development with collaboration generators,"Various systems and methods for improving the active development of machine learning systems are described herein. In machine learning, there is always a trade-off between allowing the machine learning system to learn from the training data as much as possible and to over-fit the training data. This trade-off is important because overfitting typically results in poorer performance of the new data. However, various systems and methods may be utilized to separate the process of detailed learning and knowledge acquisition from the process of imposing constraints and smoothing estimates, thereby allowing the machine learning system to actively learn from the training data while mitigating the impact of overfitting on the training data.","['G06N3/088', 'G06F18/24', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/0499', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/0985', 'G06N7/01', 'G06F12/0815', 'G06F17/18']"
CN113822321A,"Generative model training method and device, noise scale generation method and computing equipment","A generative model training method and apparatus, a noise scale generation method, and a computing device are disclosed. The training method comprises the following steps: acquiring a training sample set, wherein the training sample set comprises a plurality of training samples which are independently and uniformly distributed samples; randomly selecting a training sample from the training sample set each time, and determining the noise level corresponding to the training sample; training a noise-removal network and a noise-scheduling network with each training sample selected randomly and with a corresponding noise level, the noise-removal network corresponding to a reverse process from a noisy input to a desired output, and the noise-scheduling network corresponding to a forward process from training samples from the set of training samples to an output with noise.",['G06F18/214']
CN101123873B,"Method of disinfecting livestock, livestock disinfecting apparatus","To provide an ozone water production apparatus by which a high dissolution/high concentration ozone water can be produced simply in high efficiency. [MEANS FOR SOLVING PROBLEMS] Ozone water production apparatus (201) comprising line (273) for passage of water to be treated, gas/liquid mixing structure (205) disposed at the middle of the line and ozone supply structure (203) for feeding ozone to the gas/liquid mixing structure, wherein the gas/liquid mixing structure is provided with magnet (243) for applying magnetic force to the interior thereof. Magnetic force is applied to both of the water to be treated and the ozone, so that a high dissolution/high concentration ozone water can be produced simply in high efficiency.",[]
US8983828B2,System and method for extracting and reusing metadata to analyze message content,A system and method for extracting and reusing metadata to analyze messages is provided. A stream of messages is monitored. Those messages with a predetermined message component pointing to a referent are identified. Words that are related to the referent are extracted from each of the messages. A local similarity of the identified messages is determined by comparing the extracted words of each message. A global similarity of the identified messages is determined by combining the extracted words from all the identified messages and by comparing the combined extracted words with extracted words from all messages that include a different referent. A determination is made as to whether one or more of the extracted words from the identified messages are descriptive of the referent based on the local and global comparisons.,"['G06F16/353', 'G06F40/30']"
CN103782301B,Systems and methods for web-based biological activity assessment,"The present disclosure relates to systems and methods for network-based assessment of biological activity. Systems and methods for quantifying a response of a biological system to one or more perturbations based on activity data measured from a subset of entities in the biological system are disclosed herein. Inferring an activity of the unmeasured entity based on the activity data and a network model of the biological system describing a relationship between the measured and unmeasured entities. The inferred activity is used to derive a score that quantifies the response of the biological system to the perturbation, such as the response to the treatment condition. The score may represent the magnitude and topological distribution of the network's response to the disturbance.","['G16H50/30', 'G16B5/00']"
WO2021028728A1,Method and system for remotely selecting garments,"A method for remotely selecting garments comprises: determining anthropometric parameters of a user; automatically evaluating the fit of a garment to the shape and measurements of the user's body in real time; producing and presenting to the user recommendations for selecting a particular garment; and, optionally, visualising the garment on a digital avatar of said user in a virtual fitting room, including changing the pose of said avatar. The invention provides: increased effectiveness of the remote selection of garments by a user; improving the user's impression of remote purchasing; increasing the satisfaction of the user; and, ultimately, increasing the volume of online sales of garments and decreasing the proportion of garments returned after purchase due to dissatisfaction with the fit thereof to the shape and measurements of the user's figure.","['G06T17/00', 'G06Q30/0643', 'G06T17/20', 'G06T19/20', 'G06T7/50', 'G06T7/60', 'G06T2200/04', 'G06T2207/10028', 'G06T2207/20028', 'G06T2207/30196', 'G06T2210/56', 'G06T2219/2021']"
CN107018395B,"Image processing apparatus, image processing method and photographic device","The present invention provides a kind of image processing apparatus, image processing method and photographic device.First image data and the second image data are the image datas that each pixel value corresponds to one of multiple color components of colour filter for constituting imaging sensor.In addition, the second image data is the image data for the resolution ratio that its visual field is Chong Die with the visual field of the first image data and its high resolution is in the first image data.Image processing apparatus executes color interpolation processing by reference to the value of the pixel at first position corresponding with the position for the pixel to be interpolated in the first image data or the value of the pixel at the position near first position in the value for the pixel for constituting the second image data, to the first image data.","['H04N23/951', 'H04N23/10', 'H04N23/843', 'H04N25/134', 'H04N9/64', 'H04N2209/046', 'H04N2209/048']"
US20070265870A1,Methods and systems for utilizing a time factor and/or asymmetric user behavior patterns for data analysis,"Methods and systems for data mining and analysis that may be used for capturing user/entity behavior, providing influence filtering and/or providing recommendations. One particular use may be for providing, among other things, personalized recommendations. The methods and systems may include generating an influence network. The influence network may include a user's adoption behavior of items. The influence network may further include temporal aspects of information flow or diffusion of information through the network. The influence network may also include adoption time(s) of one or more item(s) between users/entities. Further, the influence network may include asymmetric user/entity adoption behavior. Methods and systems of influence filtering are provided that include generating asymmetric relationship(s) between users and providing a filtering module utilizing the asymmetric relationship(s) between user/entity.","['G06Q30/00', 'G06Q30/0201']"
US11893898B2,Method and apparatus for an adaptive and interactive teaching of playing a musical instrument,"Embodiments pertain to a method for use with a musical piece, or part thereof, comprising: presenting, by at least one client device to a plurality of users, a corresponding plurality of sequences of musical symbols to be cooperatively played by the plurality of users using a plurality of instruments; capturing instrument outputs produced by the plurality of instruments to generate audio data descriptive of the captured instrument outputs; analyzing the audio data for determining a level of correspondence between the captured instrument outputs and the plurality of musical symbols presented to the plurality of users; and presenting, based on the level of correspondence, an adapted or non-adapted sequence of music symbols to at least one of the plurality of players.","['G09B15/00', 'G10G1/00', 'G10H1/0008', 'G10H2210/091', 'G10H2220/005', 'G10H2220/015', 'G10H2240/105', 'G10H2250/311']"
US12406338B2,Pseudoinverse guidance for data restoration with diffusion models,"A diffusion model is augmented with pseudoinverse guidance to restore data, removing artifacts and generating high-quality reconstructed data from limited, low-quality and/or noisy input data. The low-quality input data is denoised by a diffusion model and the denoised input data is combined with a guidance term to produce output data of higher-quality compared with the low-quality input data. The guidance term is a vector-Jacobian product that encourages consistency between the denoised input data and measurements after a pseudoinverse transformation. The denoising process may be applied in an iterative fashion to generate valid solutions to the inverse problem. The augmented diffusion model is a problem-agnostic (e.g., plug-and-play) denoiser that can restore data for a variety of tasks. Example image restoration tasks include denoising, JPEG denoising, deblurring, outpainting, inpainting, colorization, high-dynamic range, and super-resolution.","['G06T5/70', 'G06T5/50', 'G06T5/60', 'G06T5/77', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212']"
US20220148699A1,Systems and methods for hosting wellness programs,"Systems and methods for matching a client and a coach are provided. A request for a wellness program including a set of attributes is received. A plurality of coaching profiles is obtained, each associated with a corresponding coach and includes a corresponding one or more wellness programs and a first corresponding data set associated with performance of the corresponding coach. Responsive to the request, a plurality of wellness programs is obtained, each associated with one or more corresponding coaches and includes one or more attributes improved by the respective wellness program and a second corresponding data set associated with performance of the respective wellness program. The coaching profiles, the wellness programs, and the set of attributes are processed, producing a respective result for each computational model that is collectively considered, producing a set of at least one coaching profile and wellness program that is communicated to a remote device.","['G16H40/20', 'G16H10/20', 'G16H10/60', 'G16H50/70', 'G16H20/30', 'G16H20/70']"
US20240253217A1,Loss-guided diffusion models,"Apparatuses, systems, and techniques to calculate a combined loss value based on applying one or more loss functions to the plurality of samples generated by a diffusion model to update the samples to determine a synthesized motions of one or more objects.","['B25J9/163', 'B25J9/1664', 'B25J9/1697']"
US20240152695A1,Automatically generating graphic design variants from input text,"Systems and methods for automatically generating graphic design documents are described. Embodiments include identifying an input text that includes a plurality of phrases; obtaining one or more images based on the input text; encoding an image of the one or more images in a vector space using a multimodal encoder to obtain a vector image representation; encoding a phrase from the plurality of phrases in the vector space using the multimodal encoder to obtain a vector text representation; selecting an image text combination including the image and the phrase by comparing the vector image representation and the vector text representation; selecting a design template from a plurality of candidate design templates based on the image text combination; and generating a document based on the design template, wherein the document includes the at least one image and the at least one phrase.","['G06F40/186', 'G06F16/5846', 'G06F40/56', 'G06F16/56', 'G06F40/216', 'G06F40/295', 'G06F40/30']"
RU2619185C2,"Treatment of diseases associated with uncoupling proteins 2 (ucp2), by inhibiting of natural antisense transcript to ucp2","FIELD: medicine, pharmacy.","['A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P13/12', 'A61P25/00', 'A61P25/28', 'A61P29/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P35/00', 'A61P37/00', 'A61P37/02', 'A61P43/00', 'A61P9/00', 'A61P9/10', 'C12N15/113', 'C12N15/1138', 'C12N2310/11', 'C12N2310/113', 'C12N2310/14', 'C12N2310/31', 'C12N2310/312', 'C12N2310/313', 'C12N2310/314', 'C12N2310/315', 'C12N2310/316', 'C12N2310/3181', 'C12N2310/32', 'C12N2310/321', 'C12N2310/322', 'C12N2310/3231']"
WO2019209888A1,Systems and methods for complex biomolecule sampling and biomarker discovery,Provided herein relates to methods and systems of a complex biomolecule sampling using machine learning algorithms. The methods and systems provided herein can aid in selection of previously unknown biomarkers and provide a report comprising a score or probability relating to a specified biological state. The methods and systems provided herein can aid in the rational design of particles to capture biomarkers.,"['G16B50/30', 'A61B5/7267', 'A61B5/7282', 'G01N33/5432', 'G16B25/10', 'G16B40/00', 'G16H50/20', 'G16H50/70', 'A61B2503/42', 'G01N2800/52', 'Y02A90/10']"
US7884602B2,Nuclear magnetic resonance evaluation using independent component analysis (ICA)-based blind source separation,"Disclosed is a non-lineal statistical independent component (ICA) analysis methodology for calculating T2 or T1 distributions of nuclear magnetic resonance logs. In one aspect, the invention employs a classical blind source separation (BSS) approach with the input data (T2 or T1 distributions) being considered not only horizontally (in relaxation time units), but also vertically (in depth). The statistical variations are used for separating the principal independent components and their corresponding weighting matrix. The result of such ICA based BSS is an efficient separation of T2 components correlative to the presence of particular conditions (e.g., clay bound water, heavy oil, capillary bound water, free water, mud filtrate (water and oil), and noise). Individual saturation of estimated fluids can be calculated from the weighting matrix generated in accordance with the invention. In accordance with a further feature of the invention, it is contemplated that independent component analysis techniques may be applied to the underlying time domain data prior to its transformation to a T2 distribution. This advantageously results in âde-noisingâ of the signal, leading to more precise and accurate results following analysis of the T2 distribution.","['G01V3/32', 'G01N24/081', 'G01R33/441', 'G01R33/5615', 'G01R33/50', 'Y02A90/30']"
WO2021078179A1,Image display method and device,"An image display method and device. The method is applied to an electronic device having a display screen and a camera. The method comprises: detecting a first operation, used for opening an application, of a user (310); in response to the first operation, displaying a first interface on a display screen (320); detecting a second operation, used for indicating to photograph an image, of the user on the first interface, or detecting a second operation, used for indicating to select an image, of the user on the first interface (330); in response to the second operation, displaying a multi-dimensional model of a target object on the first interface or the second interface, the multi-dimensional model being a multi-dimensional model constructed for a target image collected by the camera or for a target object in the selected target image, wherein a model construction required for constructing the multi-dimensional model is a model construction parameter matched with an object mask corresponding to the target object (340). The method can improve a display effect of the target object.","['G06T19/20', 'G06T15/005', 'G06T15/04', 'G06T17/20', 'G06T3/18', 'G06T7/50', 'G06V10/267', 'G06V20/40', 'G06V20/64', 'G06V40/10', 'G06T2200/24', 'G06T2207/30196', 'G06T2219/2016', 'G06T2219/2021']"
US8164506B2,Electromagnetic absorber using resistive material,"An electromagnetic absorber using resistive material includes a ground plane of a conductive material; a dielectric layer formed on the ground plane; and a pattern layer in which specific unit cell patterns made of a resistive material are periodically arranged on the dielectric layer. The electromagnetic absorber is applied to an electronic toll collection system, a transportation device, a building structure, an electronic device and an anechoic chamber.","['H01Q17/008', 'G07B15/063']"
RU2608496C2,Treatment of pyrroline-5-carboxylate reductase 1 (pycr1) related diseases by inhibition of natural antisense transcript to pycr1,FIELD: biochemistry.,"['C12Q1/6876', 'A61K31/7088', 'A61P1/02', 'A61P1/04', 'A61P1/16', 'A61P11/00', 'A61P13/02', 'A61P13/08', 'A61P13/10', 'A61P13/12', 'A61P15/00', 'A61P17/00', 'A61P17/06', 'A61P19/00', 'A61P19/02', 'A61P19/06', 'A61P19/08', 'A61P19/10', 'A61P21/00', 'A61P25/00', 'A61P25/04', 'A61P25/08', 'A61P25/14', 'A61P25/16', 'A61P25/18', 'A61P25/24', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/00', 'A61P35/00', 'A61P35/02', 'A61P43/00', 'A61P5/00', 'A61P9/00', 'A61P9/10', 'C12N15/113', 'C12N15/1137', 'C12Q1/68', 'C12Y105/01002', 'C12N2310/11', 'C12N2310/113', 'C12N2310/14', 'C12N2310/315', 'C12N2320/30', 'C12Q2600/136', 'C12Q2600/158', 'C12Q2600/178']"
US10611808B2,Isolated polypeptides and polynucleotides encoding same for generating plants with increased cuticlar water permeability,"An isolated polynucleotide is provided. The isolated polynucleotides comprising a nucleic acid sequence encoding a polypeptide having an amino acid sequence at least 88% homologous to SEQ ID NO: 22, the polypeptide being capable of increasing a cuticular water permeability of a plant expressing same. Also provided are methods of generating plants expressing such polypeptides which can be used for producing dehydrated plants or cuticular covered portions thereof.","['C07K14/415', 'A01H5/08', 'A01H6/825', 'A23L19/09', 'A23L27/63', 'C12N15/8273', 'A23V2002/00']"
CN102396093B,For controlling the apparatus and method of nucleation in electrolytic process,"In one embodiment of the invention, a kind of electrolysis tank is provided, comprises: container containing; First electrode; Second electrode; With the current source of the first electrode and the second electrode electric connection; The electrolyte be communicated with the second electrode fluid with the first electrode; Gas, wherein said gas is formed near described first electrode place or described first electrode in electrolytic process; And dividing plate; Wherein the first electrode structure is the position being controlled Gas nucleation by the position of the transfer of separate electronic substantially and nucleation.","['C25B11/02', 'H01M8/06', 'C25B11/03', 'C25B13/02', 'C25B9/19', 'F02B43/08', 'H01M8/16', 'C02F2001/46171', 'Y02E60/36', 'Y02E60/50', 'Y02T10/30', 'Y02W10/33', 'Y02W10/37', 'Y10T156/1059', 'Y10T29/49947', 'Y10T428/24322', 'Y10T428/26']"
US12183452B2,Algorithm orchestration of workflows to facilitate healthcare imaging diagnostics,"Techniques for orchestrating execution of algorithms on medical images according to pre-defined workflows and techniques for managing workflow and model execution are provided. In an embodiment, a system comprises a memory that stores computer executable components and a processor that executes the computer executable components stored in the memory. The computer executable components comprise an algorithm catalog that comprises algorithm information identifying algorithms available for processing medical images, the algorithm information comprising algorithm execution instructions for executing the algorithms as web-services; and an onboarding component that adds the algorithm information to the algorithm catalog in response to reception of the algorithm information via an onboarding user interface of an algorithm management application, wherein based on inclusion of the algorithm information in the algorithm catalog, the algorithms are made available for incorporating into workflows for executing the algorithms on the medical images.","['G06F11/079', 'G06F11/3476', 'G06F11/3664', 'G06F11/3698', 'G06F9/541', 'G06Q10/067', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H50/20', 'H04L63/102', 'G06F11/0751', 'G06F11/0766', 'G16H15/00']"
US20070081712A1,"System and method for whole body landmark detection, segmentation and change quantification in digital images","A method for segmenting digitized images includes providing a training set comprising a plurality of digitized whole-body images, providing labels on anatomical landmarks in each image of said training set, aligning each said training set image, generating positive and negative training examples for each landmark by cropping the aligned training volumes into one or more cropping windows of different spatial scales, and using said positive and negative examples to train a detector for each landmark at one or more spatial scales ranging from a coarse resolution to a fine resolution, wherein the spatial relationship between a cropping windows of a coarse resolution detector and a fine resolution detector is recorded.","['G06T7/174', 'G06T7/155', 'G06T7/33', 'G06T7/38', 'G06T2207/10072', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20164', 'G06T2207/30004', 'G06T2207/30204']"
CN113544707A,"Deep Causal Learning for Continuous Detection, Diagnosis and Optimization","A system and method for multivariate learning and optimization that repeatedly generates a self-organizing experimental unit (SOEU) based on one or more hypotheses of randomized multivariate comparison of process decisions to be provided to a user of the system. The SOEU is injected into the system to generate quantitative inferences about the process decisions. In response to injecting the SOEU, at least one confidence interval within the quantitative inference is identified, and the SOEU is iteratively modified based on the at least one confidence interval to identify at least one causal interaction of process decisions within the system. Causal interactions may be used for testing, diagnosis, and optimization of system performance.","['G05B13/042', 'G06Q10/087', 'B60W40/064', 'B60W40/08', 'B60W40/105', 'G05B13/02', 'G05B13/021', 'G05B13/024', 'G05B13/0265', 'G05B13/041', 'G05B19/042', 'G05B19/4065', 'G05B19/41835', 'G05B23/0229', 'G05B23/024', 'G05B23/0248', 'G06F18/2193', 'G06N20/00', 'G06N5/043', 'G06N5/046', 'G06N7/01', 'G06Q10/0631', 'G06Q10/06315', 'G06Q10/0639', 'G06Q10/06395', 'G06Q30/0202', 'G05B2219/36301', 'G06N3/08', 'G06N5/01', 'G06Q10/063', 'Y02P90/80', 'Y02P90/82']"
US20170243084A1,Dsp-sift: domain-size pooling for image descriptors for image matching and other applications,"A variation of scale-invariant feature transform (SIFT) based on pooling gradient orientations across different domain sizes, in addition to spatial locations. The resulting descriptor is called DSP-SIFT, and it outperforms other methods in wide-baseline matching benchmarks, including those based on convolutional neural networks, despite having the same dimension of SIFT and requiring no training. Problems of local representation of imaging data are also addressed as computation of minimal sufficient statistics that are invariant to nuisance variability induced by viewpoint and illumination. A sampling-based and a point-estimate based approximation of such representations are described.","['G06K9/6267', 'G06V10/42', 'G06F18/24', 'G06K9/4642', 'G06K9/52', 'G06V10/462', 'G06V10/50', 'G06V10/764', 'G06K2009/4666']"
WO2020047224A1,System and method for identifying transdiagnostic features shared across mental health disorders,"A system for evaluating mental health of patients includes a memory and a control system. The memory contains executable code storing instructions for performing a method. The control system is coupled to the memory and includes one or more processors. The control system is configured to execute the machine executable code to cause the control system to perform the method: A selection of answers associated with a patient is received. The selection of answers corresponds to each question in a series of questions from mental health questionnaires. Unprocessed MRI data are received. The unprocessed MRI data correspond to a set of MRI images of a biological structure associated with the patient. The unprocessed MRI data is processed to output a set of MRI features. Using a machine learning model, the selection of answers and the set of MRI features are processed to output a mental health indication of the patient.","['G16H50/30', 'A61B5/0042', 'A61B5/055', 'A61B5/16', 'A61B5/7267', 'G06F18/2148', 'G06F18/2178', 'G06F18/2193', 'G06N20/00', 'G16H10/20', 'G16H10/60', 'G16H20/70', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B2576/026', 'G06V2201/031']"
CN118428196A,Deep learning-based method for generating an oral restoration,"A computer-implemented geometric processing method generates a design of an oral restoration model. The method first obtains a hybrid restoration dataset of the oral restoration, the hybrid restoration dataset comprising natural tooth data and restoration tooth data designed by a technician. By preprocessing the depth map generated by the hybrid restoration data set, the data converted into the depth map is more suitable for deep learning so as to ensure that a smooth grid surface is generated. A neural network generation algorithm with loss of tooth features trained on the pre-processed data set and used to form a deep learning model of the restoration will ensure that the generated restoration meets the requirements of accuracy, surface roughness, anatomical morphology and mechanical properties simultaneously. And then using the oral information associated with the oral dentition model to process and generate the surface of the 3D oral restoration by a post-processing method so as to meet the requirements of the oral restoration. Finally, the remainder of the dental restoration is completed to fulfill the full function.","['A61C13/34', 'A61C13/08', 'A61C13/0004', 'G06F30/10', 'G06F30/27', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0499', 'G06N3/084', 'G06T17/20', 'G06T5/20', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T7/55', 'G06T2200/04', 'G06T2207/20024', 'G06T2207/20028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20112', 'G06T2207/20192', 'G06T2207/30036']"
RU2611187C2,"Treatment diseases, associated with interferon-regulatory factor 8 (irf8), by inhibition of natural antisense transcript to irf8",FIELD: chemistry.,"['C12N15/113', 'A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P1/02', 'A61P19/02', 'A61P19/08', 'A61P19/10', 'A61P25/00', 'A61P29/00', 'A61P3/00', 'A61P31/18', 'A61P35/00', 'A61P35/02', 'A61P37/00', 'A61P37/02', 'A61P43/00', 'C12Q1/6876', 'C12N2310/113', 'C12N2310/14', 'C12Q2600/136', 'C12Q2600/178']"
RU2612884C2,Treatment of diseases associated with colonystimulating factor 3 (csf3) by inhibition of natural antisense transcript to csf3,FIELD: biochemistry.,"['C12N15/63', 'C12Q1/6876', 'A61K31/713', 'A61K48/00', 'A61P17/00', 'A61P17/02', 'A61P19/00', 'A61P25/00', 'A61P29/00', 'A61P31/00', 'A61P35/00', 'A61P37/00', 'A61P37/02', 'A61P37/06', 'A61P43/00', 'A61P7/00', 'A61P7/06', 'A61P9/00', 'C12N15/113', 'C12N15/1136', 'G01N25/04', 'C12N2310/11', 'C12N2310/111', 'C12N2310/113', 'C12N2310/14', 'C12N2310/315', 'C12N2330/10', 'C12Q2600/136', 'C12Q2600/178']"
UA128035C2,AN ANTIBODY THAT SPECIFICALLY BINDS PD-1 AND METHOD OF ITS USE,"Antibodies that specifically bind PD-1 or antigen binding fragments thereof, polynucleotides encoding the antibodies or fragments, and methods of making and using the foregoing are useful in the treatment of an inflammatory or immune disorders.","['C07K16/40', 'A61K39/3955', 'A61P37/06', 'C07K16/065', 'C07K16/18', 'C07K16/2818', 'C12N15/00', 'A61K2039/505', 'A61K2039/57', 'C07K2317/24', 'C07K2317/33', 'C07K2317/73', 'C07K2317/732', 'C07K2317/75', 'C07K2317/76', 'C07K2317/92']"
CN101542271B,Process for generating bidirectional reflectance distribution functions of gonioapparent materials with limited measurement data,"The invention discloses a computer-implemented process for generating a bidirectional reflectance distribution function (BRDF) of a gonioapparent material containing effect flake pigments in a solid medium using limited measurement data, comprising the following steps: (A) acquiring and inputting into a computing device (1) photometric data and (2) the refractive index of the solid medium of the gonioapparent material; (B) converting any non-linear photometric data from step (A) above to linear photometric data; (C) using the illumination angle and the reflective scattering angle associated with the linear photometric data and the refractive index of the medium to calculate corresponding effect flake angles; (D) fitting the linear photometric data and the effect angle data with an equation; (E) calculating the corresponding effect flake angle needed to calculate the BRDF being generated in step (F); and (F) generating the BRDF from the corresponding effect flake angle from step (E) and the equation developed in step (D).","['G01N21/4738', 'G01N2021/4771']"
CN104485073B,Brightness adjustment method and system for LED display screens,"The invention relates to a brightness adjustment method and system for LED display screens. The method comprises the following steps: determining current corresponding to each point through the brightness of each point, determining benchmark reference current corresponding to each point through the current corresponding to each point, and therefore adjusting the brightness of the LED display screen according to the benchmark reference current corresponding to each point. The current output peak value of a constant-current drive circuit is adjustable, and the adjustment benchmark value is set by an external resistor and is not limited by the external resistor. The overall brightness adjustment overall brightness tends to the selected standard brightness conforming to the requirement of the display screen, and the overall brightness overall brightness cannot be reduced. The method does not need to independently reply on current pulse width adjustment, and the gray-scale sacrifice is reduced, that is, under the conditions of sacrificing less gray scales and preventing display brightness reduction, the adjustment for the brightness consistency of the LED display screen is realized.",[]
EP3703007A2,Tumor tissue characterization using multi-parametric magnetic resonance imaging,"Brain tumor or other tissue classification and/or segmentation is provided based on from multi-parametric MRI. MRI spectroscopy, such as in combination with structural and/or diffusion MRI measurements, are used to classify. A machine-learned model or classifier distinguishes between the types of tissue in response to input of the multi-parametric MRI. To deal with limited training data for tumors, a patch-based system may be used. To better assist physicians in interpreting results, a confidence map may be generated using the machine-learned classifier.","['G06T7/11', 'G06T7/0012', 'A61B5/055', 'G01R33/46', 'G01R33/50', 'G01R33/56341', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06T7/174', 'G01R33/34084', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096']"
CN107090414B,Pesticidal flavobacterium strains,"The present invention provides a flavobacterium insecticidal strain, which is flavobacterium H492 strain with NRRL accession number B-50584.","['C12N1/20', 'C12N1/205', 'A01N31/08', 'A01N35/02', 'A01N35/04', 'A01N37/10', 'A01N37/46', 'A01N63/10', 'A01N63/20', 'C12P7/26', 'C12R2001/20']"
US20160098687A1,Systems and methods for private schedule coordination and event planning,"Systems and methods for scheduling events for one or more users using a decision engine examining data in user models to select a date, time, and/or place to schedule a meeting between the users and store the meeting data in an event cloud using a dynamic software object.","['G06Q10/1095', 'G06Q10/1093']"
CN102014848B,Dental composition and composite resin,"Provided is a dental composition which has good operability as a paste and of which the cured form has excellent light-dispersing properties and transparency as well as excellent mechanical strength and polishing properties. The dental composition contains (A) polymerizable monomer and (B) amorphous powder of mean particle size from 1 to 20 [mu]m which includes fine silica-based particles and oxide containing zirconium atoms, silicon atoms and oxygen atoms coated on the surface of said fine silica-based particles. The difference between the refractive indices of the cured form of said polymerizable monomer (A) and said amorphous powder (B) is from 0.005 to 0.03.","['A61K6/887', 'Y10T428/2993']"
CN206341198U,On-off circuit and electronic system,"The various embodiments of the disclosure are related to on-off circuit and electronic system.On-off circuit includes the first transistor and transistor seconds being connected between two terminals, and including public control node, has electric capacity between public control node and intermediate point.Control circuit includes the first circuit and second circuit for being configured as being charged and discharged electric capacity according to the first control signal and the second control signal.Controlling circuit includes switch and the tertiary circuit with multiple diodes, voltage of the switch at electric capacity is operated when the threshold value of two diodes between intermediate point and public control node is associated in more than level, to enable current to flow to public control node from intermediate point.Voltage of the switch at electric capacity is operated when being less than the given threshold value for two diodes being connected in series between public control node and intermediate point, to enable current to flow to intermediate point from public control node.","['H03K17/223', 'H03K17/6874', 'A61B8/4494', 'H03K17/687', 'H03K17/74', 'H03K5/08']"
RU2610661C2,Treatment of fibroblast growth factor 21 (fgf21) related diseases by inhibition of natural antisense transcript to fgf21,FIELD: biotechnology.,"['C12N15/1136', 'C12N15/63', 'A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P1/16', 'A61P13/12', 'A61P3/00', 'A61P3/04', 'A61P3/06', 'A61P3/10', 'A61P35/00', 'A61P7/02', 'A61P9/00', 'A61P9/10', 'A61P9/12', 'C12N15/11', 'C12N15/113', 'C12Q1/6876', 'C12N2310/111', 'C12N2310/113', 'C12N2310/14', 'C12N2310/17', 'C12N2310/31', 'C12N2310/312', 'C12N2310/313', 'C12N2310/314', 'C12N2310/315', 'C12N2310/316', 'C12N2310/3181', 'C12N2310/32', 'C12N2310/321', 'C12N2310/322', 'C12N2310/3231']"
RU2611192C2,TREATMENT OF RNase H1 RELATED DISEASES BY INHIBITION OF NATURAL ANTISENSE TRANSCRIPT TO RNase H1,FIELD: biotechnology.,"['C12N15/1137', 'A61K31/7088', 'A61P1/16', 'A61P31/12', 'A61P31/18', 'A61P31/20', 'A61P33/02', 'A61P35/00', 'A61P43/00', 'C12N9/22', 'C12N2310/11', 'C12N2310/113', 'C12N2310/14', 'C12N2310/315', 'C12N2310/321', 'C12N2310/322', 'Y02A50/30']"
CN101543091B,"Voice input device, method of manufacturing the same, and information processing system","The invention provides a voice input device, a method of manufacturing the same, and an information processing system. The voice input device includes: a first microphone (710-1) having a first diaphragm; a second microphone (710-2) having a second diaphragm; and a differential signal generation unit (720) that generates a differential signal of the first voltage signal and the second voltage signal; the first and second diaphragms are arranged so that a noise intensity ratio is smaller than an input voice intensity ratio indicating a ratio of an intensity of an input voice component, and a differential signal generating unit (720) includes: a delay unit (730); and a differential signal output unit (740) that generates and outputs a differential signal of the signal to which the delay is given by the delay unit.",[]
RU2609631C2,"Treatment of diseases, associated with hepatocyte growth factor (hgf), by inhibition of natural antisense transcript to hgf",FIELD: biochemistry.,"['C12N15/113', 'A61K31/7088', 'A61K31/713', 'A61K48/00', 'A61P1/00', 'A61P1/04', 'A61P1/16', 'A61P11/00', 'A61P13/02', 'A61P13/12', 'A61P15/00', 'A61P17/00', 'A61P17/02', 'A61P17/04', 'A61P17/08', 'A61P17/14', 'A61P19/02', 'A61P19/04', 'A61P19/08', 'A61P21/00', 'A61P25/00', 'A61P25/02', 'A61P25/08', 'A61P25/14', 'A61P25/16', 'A61P25/28', 'A61P29/00', 'A61P3/00', 'A61P31/04', 'A61P31/18', 'A61P35/00', 'A61P37/00', 'A61P37/02', 'A61P37/06', 'A61P37/08', 'A61P43/00', 'A61P7/00', 'A61P7/02', 'A61P7/04', 'A61P9/00', 'A61P9/04', 'A61P9/08', 'A61P9/10', 'C12N15/1136', 'C12Q1/6876', 'C12N2310/113', 'C12N2310/14', 'C12N2310/31', 'C12N2310/311', 'C12N2310/3125', 'C12N2310/313', 'C12N2310/314', 'C12N2310/315', 'C12N2310/316', 'C12N2310/321', 'C12N2310/322', 'C12N2310/3231', 'C12Q2600/136']"
AU2020274863B2,Dose guided real-time adaptive radiotherapy,"Techniques for adjusting radiotherapy treatment for a patient in real-time are provided. The techniques include determining a patient anatomy at a first time within a given radiotherapy treatment fraction after a radiotherapy treatment dose has been delivered by a radiotherapy device; retrieving a reference patient anatomy for the given radiotherapy treatment fraction that indicates a prescribed dose parameter to be delivered within the given radiotherapy treatment fraction; comparing the patient anatomy at the first time with the reference patient anatomy during the given radiotherapy treatment fraction; and based on the comparison of the patient anatomy at the first time with the reference patient anatomy, adjusting a parameter of the radiotherapy device to change an amount of radiotherapy treatment dose delivered at a second time, following the first time, within the given radiotherapy treatment fraction in accordance with the prescribed dose parameter to be delivered within the given radiotherapy treatment fraction.","['A61N5/1071', 'A61N5/1038', 'A61N5/1042', 'A61N5/1045', 'A61N5/1049', 'A61N5/1067', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'A61N2005/1062', 'A61N2005/1087', 'A61N5/1031', 'A61N5/1039', 'G16H20/40']"
US20100198101A1,Non-invasive location and tracking of tumors and other tissues for radiation therapy,"Embodiments herein provide a non-invasive tracking system that accurately predicts the location of tumors, such as lung tumors, in real time, while allowing patients to breathe naturally. This is accomplished by using Electrical Impedance Tomography (EIT), in conjunction with spirometry, strain gauge and infrared sensors, and by using sophisticated patient-specific mathematical models that incorporate the dynamics of tumor motion. With the direction and speed of lung tumor movement successfully tracked, radiation may be effectively delivered to the lung tumor and not to the surrounding healthy tissue, thus increased radiation dosage may be directed to improving local tumor control without compromising functional parenchyma.","['A61N5/103', 'A61B5/0536', 'A61B5/0871', 'A61B5/091', 'A61N5/1049', 'A61N2005/1051', 'A61N2005/1059', 'A61N5/1037']"
CN101605871B,Reliable carbon-neutral power generation system,"Disclosed is a method for providing reliable, controllable power without releasing the greenhouse gas carbon dioxide to the environment2) The system of (1). All CO produced2Are captured and converted to hydrocarbons, which may be used as hydrocarbon feedstock or as additional fuel. Some of these systems may even reduce atmospheric carbon dioxide. The system may use a carbon-neutral energy source.","['C10G2/50', 'C01B3/34', 'C01B2203/0233', 'C01B2203/0244', 'C01B2203/025', 'C01B2203/84', 'H01M8/0656', 'Y02E60/36', 'Y02E60/50', 'Y02P30/00']"
US11885887B1,Imaging subsystem,"An imaging subsystem is disclosed, wherein the imaging subsystem is coherent and it generally includes an optical phased array (OPA), frequency modulation (FM) and/or amplitude modulation (AM). The imaging subsystem is operable with a Super System on Chip (SSoC) or a photonic neural learning processor (PNLP). The Super System on Chip (SSoC) includes memristors. The imaging subsystem is further operable with a camera (e.g., a metamaterial camera, wherein the metamaterial camera includes one or more metasurfaces). Furthermore, the imaging subsystem may be included with a vehicle system, wherein the vehicle system can recommend a service or an offer to a user/driver by anticipating any need of the user/driver.","['G06V20/597', 'G01S17/931', 'G01S17/34', 'G01S17/86', 'G01S17/89', 'G02F1/292', 'G06V20/56', 'G06V20/58']"
WO2024081778A1,A generalist framework for panoptic segmentation of images and videos,"Provided are systems and methods for performing panoptic segmentation of images and videos using a denoising diffusion model. The panoptic segmentation task is formulated as a conditional discrete data generation problem. This is achieved by learning a generative model for panoptic masks, for example treated as an array of discrete tokens, conditioned on an input image. The generative model can also be applied to video data by including predictions from past frames as an additional conditioning signal. This enables the model to learn to track and segment objects automatically across video frames.","['G06V10/82', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06T7/11', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
US20180103917A1,Head-mounted display eeg device,"Methods, systems, and devices are disclosed for monitoring electrical signals of the brain. In one aspect, a system for monitoring electrical brain activity associated with visual field of a user includes a sensor unit to acquire electroencephalogram (EEG) signals including a plurality of EEG sensors circumnavigating the head of a user, and a head-mounted frame for docking a personal electronic device over the user's eyes to present visual stimuli, in which the visual stimuli is configured to evoke EEG signals exhibited by the user, in which the assessment indicates if there is a presence of visual field defects in the user's visual field.","['A61B5/7445', 'A61B5/00', 'A61B5/0478', 'A61B5/04842', 'A61B5/0496', 'A61B5/24', 'A61B5/291', 'A61B5/369', 'A61B5/378', 'A61B5/398', 'A61B5/6803', 'G02B27/017', 'A61B5/7264']"
US20230108422A1,Methods and systems for use in processing images related to crops,"Systems and methods are provided for use in processing image data associated with crop-bearing fields. One example computer-implemented method includes accessing a first data set including images associated with a field, where the images have a spatial resolution of about one pixel per at least about one meter, and generating, based on a generative model, defined resolution images of the field from the first data set. In doing so, the defined resolution images each have a spatial resolution of about X centimeters per pixel, where X is less than about 5 centimeters. The method also includes deriving index values for the field, based on the defined resolution images of the field, and predicting a characteristic (e.g., a yield, etc.) for the field based on the index values and, in some implementations, at least one environmental metric for the field.","['G06T3/4053', 'A01B79/005', 'G06N3/0464', 'G06N3/0475', 'G06N3/049', 'G06N3/08', 'G06T3/4092', 'G06T7/0016', 'G06V10/62', 'G06V10/82', 'G06V20/13', 'G06V20/17', 'G06V20/188', 'G06V20/194', 'G06N3/0455', 'G06N3/048', 'G06N3/094', 'G06T2207/10024', 'G06T2207/10036', 'G06T2207/10048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30188']"
EP3933852A1,Improved mapping efficiency by suggesting map points location,"A method and apparatus of mapping efficiency by suggesting map points location includes receiving data at a machine, the data including a plurality of signals received during the performance of a triangulation to locate a focal tachycardia, generating, by the machine, a prediction model as to the location of the focal tachycardia, and modifying, by the machine, the prediction model based upon additional data received by the machine.","['A61B34/10', 'A61B5/02055', 'A61B5/363', 'A61B5/367', 'A61B5/7267', 'G06N3/045', 'G06V10/25', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'A61B2034/101', 'A61B5/343', 'A61B5/6852', 'A61B5/6869', 'A61B5/743']"
US20160256130A1,Monitoring structural features of cerebral blood flow velocity for diagnosis of neurological conditions,The systems and methods described herein include a non-invasive diagnostic tool for intracranial hypertension (IH) detection and other neurological conditions like mild and moderate TBI that utilizes the transcranial Doppler (TCD) measurement of cerebral blood flow velocity (CBFV) in one or more cerebral vessels. A headset includes a TCD scanner which automatically locates various cerebral arteries and exerts an appropriate pressure on the head to acquire good CBFV signals.,"['A61B8/06', 'A61B5/0285', 'A61B5/031', 'A61B5/4064', 'A61B8/04', 'A61B8/0816', 'A61B8/0891', 'A61B8/4209', 'A61B8/4227', 'A61B8/4427', 'A61B8/4461', 'A61B8/488', 'A61B8/5223', 'G16H50/30', 'A61B5/0042', 'A61B5/0059', 'A61B5/055', 'A61B5/7267', 'Y02A90/10']"
CN110097951B,Image generation from medical text reports,"Image generation from medical text reports is disclosed. A method for generating a first image from a medical text report, comprising: obtaining a medical text report, the medical text report including one or more natural language statements; analyzing the medical text report by using a computer-implemented analysis process to determine for each natural language statement: statement whether a predetermined criterion regarding the first medical finding is met; and in response to determining that the statement meets a predetermined criterion, adding an image representing the first medical finding to the image template to generate a first image. Also disclosed is an apparatus and a computer program.","['G16H30/40', 'G06F40/289', 'G06N20/00', 'G16H10/60', 'G16H15/00', 'G16H30/20']"
EP3620935A1,System and method for natural language processing,"The present invention generally relates to natural language processing system configured for receiving an input sequence of input tokens representing a first sequence of words in a natural language of a first text and generating an output sequence of output tokens representing a second sequence of words in a natural language of a second text. The natural language processing system has at least one sequence-to-sequence (seq2seq) model and a policy gradient generator. The seq2seq model comprises an encoder, an attention module and a decoder. The encoder comprises a forward recurrent neural network RNN and a backward RNN configured for encoding each input token in the input sequence into a respective encoded representation of each input token. The attention module is configured for applying weights to the encoded representations. The decoder comprises a forward RNN and a backward RNN configured for decoding the weighted encoded representations into the output tokens of the output sequence. The policy gradient generator is configured for training the weights for adaption to one corpus for each seq2seq model.",['G06F40/30']
WO2018146558A2,"Systems, methods and apparatuses for stereo vision and tracking","A system, method and apparatus for stereo vision and tracking with a plurality of coupled cameras and optional sensors.","['H04N13/383', 'H04N13/239', 'G02B27/0172', 'G06F3/011', 'G06F3/014', 'G06F3/016', 'H04N13/271', 'H04N13/296', 'H04N25/61', 'H04N25/671', 'H04N25/683', 'G02B2027/0138', 'G06F2203/011']"
US10657378B2,Classifying images and videos,"A method, system and computer program product for classifying an image or video. An image or video to be classified is received. Scene statistics (statistical model of pictures, images or videos representative of pictures, images or videos, respectively, that are captured of the physical world) of the image or video are captured. A model (a statistical model that describes a set of probability distributions) of the image or video is then created using the captured scene statistics. A comparison between the model of the image or video with two other models of images or videos is performed, such as a model of visible light images or videos and a model of infrared images or videos. The received image or video is then classified (e.g., classified as corresponding to a visible light image) based on the comparison.","['G06V20/35', 'G06K9/00718', 'G06F18/2415', 'G06K9/00684', 'G06K9/00744', 'G06K9/00771', 'G06K9/6212', 'G06K9/6277', 'G06V20/41', 'G06V20/46', 'G06V20/52']"
US11264206B2,Methods and systems for forming a pattern on a surface using multi-beam charged particle beam lithography,"Methods for fracturing or mask data preparation are disclosed in which a set of single-beam charged particle beam shots is input; a calculated image is calculated using a neural network, from the set of single-beam charged particle beam shots; and a set of multi-beam shots is generated based on the calculated image, to convert the set of single-beam charged particle beam shots to the set of multi-beam shots which will produce a surface image on the surface. Methods for training a neural network include inputting a set of single-beam charged particle beam shots; calculating a set of calculated images using the set of single-beam charged particle beam shots; and training the neural network with the set of calculated images.","['H01J37/3175', 'G06N3/008', 'G06N3/04', 'G06N3/08', 'G06N3/10', 'G06T2207/20081', 'G06T2207/20084', 'H01J2237/30416', 'H01J2237/31761', 'H01J37/3177']"
US20160027342A1,Modeling the autonomous nervous system and uses thereof,"Generating, populating and/or using a model of a portion of the ANS, possibly in conjunction with a model of organ response thereto. Optionally, the model is provided with a treatment plan which indicates one or more locations in the ANS to treat. In an exemplary embodiment of the invention, the model is analyzed to determine a cause and/or possible solution or improvement of a condition, for example a chronic condition.","['A61B5/4035', 'G09B23/30', 'A61B34/10', 'A61B6/037', 'A61B6/5211', 'G06T19/00', 'G09B5/02', 'G16H50/50', 'A61B18/14', 'A61B2034/105', 'A61B2090/376', 'A61B2090/3762', 'A61B6/032', 'G06T2210/41', 'Y02A90/10']"
US11580425B2,Managing defects in a model training pipeline using synthetic data sets associated with defect types,"The disclosure herein describes managing defects in a model training pipeline. A synthetic data set is generated that is associated with a defect type and a lifecycle stage of the model training pipeline, and baseline performance metrics associated with the defect type are generated. Based on a code change to the pipeline, a test model is trained using the pipeline and the synthetic data set, and test performance metrics are collected based on the test model and associated with the defect type. Based on comparing the baseline performance metrics and the test performance metrics, a defect of a particular defect type is identified in the pipeline. An indicator of the defect is provided that includes the defect type and the lifecycle stage with which the synthetic data set is associated, whereby a defect correction process is enabled to remedy the defect based on the associated defect type and the lifecycle stage.","['G06N5/04', 'G06N20/00']"
CN108375856A,"Display device, display module and electronic equipment","The invention provides a display device with high resolution or high display quality. The invention provides a display device including a display unit, a first terminal group, and a second terminal group. The display portion includes a plurality of pixels, a plurality of scanning lines, and a plurality of signal lines. The first terminal group and the second terminal group are separated from each other. The first terminal group includes a plurality of first terminals. The second terminal group includes a plurality of second terminals. Each of the plurality of scanning lines is electrically connected to a plurality of pixels arranged in the row direction. Each of the plurality of signal lines is electrically connected to a plurality of pixels arranged in the column direction. Each of the plurality of signal lines is electrically connected to the first terminal or the second terminal. The display portion includes a first region. The first region is a region in which a signal line electrically connected to the first terminal and a signal line electrically connected to the second terminal are mixed.","['H10H29/142', 'G02F1/136286', 'H10D86/60', 'G02F1/1368', 'G09G3/2092', 'G09G3/32', 'G09G3/3225', 'G09G3/36', 'G09G3/3611', 'G09G3/3659', 'G09G3/3666', 'G09G5/003', 'H10D86/40', 'H10D86/441', 'H10K59/131', 'G09G2300/0426', 'G09G2300/0443', 'G09G2300/0452', 'G09G2310/0221', 'G09G2310/0278', 'G09G2320/0238', 'G09G2370/08', 'H10D30/6734', 'H10D30/6746', 'H10D30/6755', 'H10D30/6757', 'H10D86/421', 'H10D86/423']"
US11745179B2,Microfluidic systems and methods for lipoplex-mediated cell transfection,"Systems and methods for transfection using a microfluidic device are disclosed. Microdroplets encapsulate cells, transfection molecules, and cationic lipid transfection reagent. Droplet chaotic advection in a rendering channel of the system results in a uniform lipid-DNA complex (lipoplex) formation, which can improve gene delivery efficacy. The shear stress exerted on cell membranes during the chaotic mixing increases membrane permeability, which when combined with the co-confinement of cell and lipoplex, improves transfection efficiency of the cell. The systems and methods can be used for a variety of applications such as gene therapy, in vitro fertilization, regenerative medicine, cancer treatment, and vaccines.","['A61K31/7088', 'B01L3/502715', 'A61P35/00', 'B01L3/502769', 'C12M21/00', 'C12M23/16', 'B01L2300/0877']"
US12094091B2,Intelligent denoising,A computer-implemented method of machine learning including learning a Convolutional Neural Network (CNN) architecture for estimating a degradation generated by a denoiser on a ray traced image. The method includes obtaining a dataset and learning the CNN architecture based on the obtained dataset. The learning including taking as input an image generated by the denoiser and a corresponding noisy image of the provided dataset and outputting an error map. This forms an improved solution with respect to estimating a degradation generated by a denoiser on a ray traced image.,"['G06T5/70', 'G06F18/214', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T3/40', 'G06T5/50', 'G06T5/60', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224']"
US20120277155A1,Therapy for kidney disease and/or heart failure,"Medical systems and methods for treating kidney disease alone, heart failure alone, chronic kidney disease with concomitant heart failure, or cardiorenal syndrome are described. The systems and methods are based on delivery of a natriuretic peptide such as Vessel Dilator to a subject. Methods for increasing and maintaining peptide levels at a certain concentration include direct peptide delivery via either an external or implantable programmable pump.","['A61K38/2242', 'A61K47/18', 'A61K9/0019', 'A61M5/14228', 'A61M5/14276', 'A61P13/12', 'A61P9/04']"
US20160278736A1,Monitoring structural features of cerebral blood flow velocity for diagnosis of neurological conditions,The systems and methods described herein include a non-invasive diagnostic tool for intracranial hypertension (IH) detection and other neurological conditions like mild and moderate TBI that utilizes the transcranial Doppler (TCD) measurement of cerebral blood flow velocity (CBFV) in one or more cerebral vessels. A headset includes a TCD scanner which automatically locates various cerebral arteries and exerts an appropriate pressure on the head to acquire good CBFV signals.,"['A61B8/06', 'A61B8/0808', 'A61B8/42', 'A61B8/4209', 'A61B8/4227', 'A61B8/44', 'A61B8/488', 'A61B8/5223', 'G16H50/30', 'A61B2018/00446', 'A61B2576/00', 'A61B2576/026', 'A61B8/4254', 'A61B8/4281', 'A61B8/4461', 'A61B8/48', 'A61B8/52', 'A61B8/56', 'Y02A90/10']"
US12408566B2,Variable resistance memory device,"A variable resistance memory device includes a variable resistance layer, a first conductive element, and a second conductive element. The variable resistance layer includes a first layer including a first material and a second layer on the first layer and the second layer including a second material. The second material has a different valence than a valence of the first material. The first conductive element and the second conductive element are on the variable resistance layer and separated from each other to form an electric current path in the variable resistance layer in a direction perpendicular to a direction in which the first layer and the second layer are stacked.","['H10N70/231', 'H10N70/821', 'H10B63/30', 'H10B63/34', 'H10B63/80', 'H10B63/82', 'H10B63/84', 'H10N70/24', 'H10N70/253', 'H10N70/823', 'H10N70/8265', 'H10N70/841', 'H10N70/883', 'H10N70/8833']"
CN117689532A,An image style transfer method based on diffusion model,"The invention discloses an image style migration method based on a diffusion model, which comprises the steps of firstly obtaining text embedding of a style image by using a CLIP image encoder and an attention mechanism, and carrying out style migration on the text embedding so as to obtain more accurate semantic representation of the style image. And then carrying out forward process of diffusion model on the content image, and adding text embedding of the style image in the reverse process. The invention provides a mixed denoising module in the reverse process, wherein two U-Net modules are arranged, and the tasks are respectively to maintain the structural characteristics of a content image and to generate the artistic style of a style image. The method aims at ensuring the accuracy of style image migration, and combines the semantic and visual characteristics of content and style images to generate a style migration image. The method can solve the problem that the generation of the countermeasure network possibly causes blurring or artifacts, and overcomes the difficult challenges of gradient disappearance, mode collapse and the like in the training process.","['G06N3/0475', 'G06N3/094', 'G06T2207/20081', 'G06T2207/20084']"
US20240144544A1,Generating objects of mixed concepts using text-to-image diffusion models,"Generating an object using a diffusion model includes obtaining a first input and a second input, and synthesizing an output object from the first input and the second input. The synthesizing of the output object includes generating a layout of the output object from the first input, injecting the second input as a content conditioner to the layout of the output object, and de-noising the layout of the output object injected with the content conditioner to generate a content of the output object.","['G06T11/00', 'G06T11/60', 'G06F40/284', 'G06F40/40', 'G06N3/04', 'G06N3/08', 'G06T5/002', 'G06T5/20', 'G06T5/70', 'G06F40/30', 'G06T2207/20084']"
KR20220051145A,Organic light emitting diode comprising an organic semiconductor layer,"The present invention relates to an organic light emitting diode including an anode electrode, a cathode electrode, at least one light emitting layer, and at least one organic semiconductor layer and a method for manufacturing the same. The at least one light emitting layer and the at least one organic semiconductor layer are arranged between the anode electrode and the cathode electrode. The organic semiconductor layer substantially comprises a metallic rare earth metal dopant and a first matrix compound. The first matrix compound comprises at least two phenanthrolinyl groups.","['H10K85/6572', 'H10K50/12', 'H10K71/30', 'H01L51/0072', 'C07D519/00', 'H01L51/0002', 'H01L51/5072', 'H01L51/5234', 'H10K50/157', 'H10K50/19', 'H10K50/828', 'H10K85/351', 'H10K2102/3035', 'H10K50/15', 'H10K50/16', 'H10K50/17', 'H10K50/18', 'H10K85/111', 'H10K85/1135', 'H10K85/615', 'H10K85/626', 'H10K85/633', 'H10K85/636', 'H10K85/654']"
CN102681216B,Light control element,"The invention provides multiple resonance type electrodes that can use resonant frequency different, simultaneously the expensive low light modulation control element of modulation efficiency. possessing the substrate (1) with electrooptic effect, the fiber waveguide (2) forming on this substrate, and in the light control element for control electrode (3) that the phase place of the light of propagating in this fiber waveguide is controlled arranging on this substrate, this control electrode (3) has along the resonant frequency (f1 of this fiber waveguide (2) configuration, f2) different multiple resonance type electrodes (31, 32), on each resonance type electrode, connect 1 input distribution (30) of input control signal and the branch signal line from this input distribution branch, and it is consistent by near the timing this resonance type electrode with the light of propagating in this fiber waveguide that this branch signal line makes to supply with the timing of this control signal to this resonance type electrode in each resonance type electrode.","['G02F1/2255', 'G02F1/0356', 'G02F1/225', 'G02F1/0316', 'G02F1/212']"
US20240261068A1,Optical coherence tomography for intra-oral scanning,Provided are systems and methods for generating a three-dimensional model from an intra-oral optical coherence tomography scan.,"['A61C9/0053', 'G01B11/2441', 'A61B1/24', 'A61B34/30', 'A61B5/0035', 'A61B5/004', 'A61B5/0066', 'A61B5/0088', 'A61B5/7425', 'A61B6/512', 'A61C1/0015', 'A61C1/082', 'G01B9/02091', 'G06T11/00', 'G06T7/0012', 'G06T7/70', 'H04N23/685', 'H04N23/90', 'A61B2034/302', 'G01B2210/50', 'G06T2207/10024', 'G06T2207/10101', 'G06T2207/30036', 'G06T2207/30244']"
CN101610793B,Long-acting pharmaceutical preparations,"The present invention relates to long-acting therapeutic formulations and methods of use thereof, wherein the formulations comprise a genetically modified micro-organ comprising a vector comprising a nucleic acid sequence operably linked to one or more regulatory sequences, wherein the nucleic acid sequence encodes a therapeutic polypeptide such as erythropoietin or interferon alpha.","['A61K38/1816', 'A61K48/00', 'A61K31/70', 'A61K35/12', 'A61K38/212', 'A61K47/6901', 'A61K48/0075', 'A61P1/16', 'A61P11/00', 'A61P11/02', 'A61P11/04', 'A61P11/06', 'A61P13/12', 'A61P17/00', 'A61P19/02', 'A61P19/10', 'A61P21/04', 'A61P25/14', 'A61P25/16', 'A61P25/18', 'A61P25/24', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/10', 'A61P31/00', 'A61P31/12', 'A61P35/00', 'A61P35/02', 'A61P37/06', 'A61P43/00', 'A61P7/06', 'A61P9/00', 'A61P9/10', 'A61P9/12', 'C07K14/505', 'C12N15/85', 'C12N15/86', 'C12N15/88', 'C12N7/00', 'C12N2710/10343']"
CN102918776B,Precoder codebooks for effective channels with structured frequency-selectivity,"A precoder for an effective channel linking a wireless receiver to a wireless transmitter includes a precoder report and a precoder update report, the effective channel including a propagation channel, transmit filters and receive filters. A structured frequency-selectivity of the effective channel is determined, the structured frequency-selectivity being induced by one or more long term and/or persistent parameters of the effective channel. The precoder update report is generated based on the structured frequency-selectivity. The precoder update report includes frequency-dependent phase compensation which accounts for the structured frequency-selectivity. The precoder report is generated for the effective channel based on channel state information determined for the effective channel. The precoder report and the precoder update report are transmitted to the wireless transmitter. The transmitter determines a transmission operation based on the precoder report and the precoder update report, and transmits data to the wireless receiver in accordance with the transmission operation.","['H04B7/0626', 'H04B7/0417', 'H04B7/0456', 'H04B7/0639', 'H04B7/065', 'H04L25/0202']"
RU2616283C2,Treatment of diseases associated with substrate of insulin receptor 2 (irs2) by inhibition of natural antisense transcript to irs2,FIELD: medicine; chemistry.,"['C12N15/113', 'A61K31/7088', 'A61K31/711', 'A61K31/713', 'A61K48/00', 'A61P1/16', 'A61P13/12', 'A61P15/00', 'A61P21/00', 'A61P21/02', 'A61P25/00', 'A61P25/16', 'A61P25/28', 'A61P3/00', 'A61P3/04', 'A61P3/08', 'A61P3/10', 'A61P35/00', 'A61P43/00', 'A61P9/10', 'C12N2310/11', 'C12N2310/113', 'C12N2310/17', 'C12N2310/312', 'C12N2310/313', 'C12N2310/314', 'C12N2310/315', 'C12N2310/316', 'C12N2310/3181', 'C12N2310/32', 'C12N2310/321', 'C12N2310/322', 'C12N2310/3231']"
US20140163664A1,Integrated system for the ballistic and nonballistic infixion and retrieval of implants with or without drug targeting,"Described are coordinated apparatus and methods for drug targeting, clearing the lumen, placing implants within the wall of, and stenting, as necessary, any tubular anatomical structure with single luminal entry. Miniature balls, or miniballs, are introduced into the wall aeroballistically from within the lumen, or small arcuate bands called stays inserted through the outer tunic by means of a hand tool. When miniballs must be placed too closely together to be controlled by hand, a positional control system assists in discharge. Implantation within or proximal to diseased tissue targeting, and thus concentrating the medication in that tissue, miniballs and stays can be used to deliver and controllably release multiple drugs, a radionuclide, or an open or closed loop smart-pill, for example. A glossary of terms follows the specification. Balance of abstract appended to paragraph [0004].","['A61F2/82', 'A61B17/00491', 'A61B17/0057', 'A61B17/12022', 'A61B17/12118', 'A61B17/12181', 'A61F2/95', 'A61M37/00', 'A61B17/3468', 'A61B18/02', 'A61B18/04', 'A61B18/1492', 'A61B18/18', 'A61B18/245', 'A61B2017/00411', 'A61B2017/00544', 'A61B2017/0065', 'A61B2017/00809', 'A61B2017/00876', 'A61B2017/1205', 'A61B2017/22001', 'A61B2018/00005', 'A61B2018/00023', 'A61B2018/00345', 'A61B2018/00517', 'A61B2018/00541', 'A61B2018/00577', 'A61B2018/00595', 'A61B2018/00982', 'A61B2018/1861', 'A61B2218/002', 'A61F2/013', 'A61F2002/9528', 'A61F2210/009', 'A61N2005/1011', 'A61N7/00']"
CN108069036A,For the electric system of more electric aircrafts,"The present invention is provided to one or more loads on aircraft (10) to provide the system (20) of electric power and method (400).It may include the first fuel cell (202) for the electric system (20) of aircraft (10), one or more loads that first fuel cell (202) is configured on the aircraft provide prime power.The electric system can further comprise the second fuel cell (214), and one or more of loads that second fuel cell (214) is configured on the aircraft provide peak power.","['B64D27/24', 'B64D41/00', 'B64D27/02', 'B64U50/19', 'H01M16/003', 'H01M8/00', 'H01M8/04201', 'H01M8/0494', 'H01M8/0612', 'H01M8/0618', 'H01M8/0656', 'B64D2041/005', 'B64D2221/00', 'H01M2008/1095', 'H01M2008/1293', 'H01M2008/147', 'H01M2250/20', 'H01M8/083', 'H01M8/086', 'H01M8/184', 'Y02E60/50', 'Y02T50/50', 'Y02T90/40']"
CN106471588B,"Dust magnetic core, powder for magnetic core, and method for producing the same","The dust core of specific resistance or excellent strength is provided.Dust core of the invention, it is characterized in that, with soft-magnetic particles, the 1st coating and the 2nd coating, 1st coating includes aluminium nitride, and the surface of coating soft-magnetic particles, 2nd coating is made of the softening point low-melting glass lower than the annealing temperature of soft-magnetic particles, and at least part of surface of coating 1st coating.The 1st coating comprising aluminium nitride, it is excellent with the wetability for the low-melting glass for constituting the 2nd coating, also, inhibit constitution element diffusion between soft-magnetic particles and the low-melting glass of the 2nd coating.Dust core of the invention, the synergistic effect of the 1st coating and the 2nd coating in this way are compared with the past to play consistently high specific resistance and high intensity.","['H01F1/147', 'B22F1/16', 'C03C8/02', 'C03C8/04', 'C03C8/08', 'C22C38/02', 'C22C38/06', 'H01F1/14791', 'H01F1/24', 'H01F3/08', 'H01F41/0246', 'C03C2209/00']"
US20100089524A1,Actuator and method for manufacturing planar electrode support for actuator,"An actuator as a drive source of robots and the like is usable for housekeeping assistance, job assistance, and nursing help. The drive source itself is small, light, flexible, and safe. A manufacturing method for a planar electrode support therefor is also described. The actuator has an electrolyte layer in contact with a conductive polymer layer disposed in between a first electrode having the conductive polymer layer attached thereto and opposite second electrode, for deforming the conductive polymer layer by application of electric fields to the electrodes. The first electrode has low rigidity in a longitudinal direction of the conductive polymer layer to facilitate expansion and contraction thereof.","['B25J9/1095', 'H02N11/006', 'Y10S310/80', 'Y10T156/1043']"
US20090189452A1,System and Method for Creating a Networked Infrastructure Distribution Platform of Small Fixed and Vehicle Based Wind Energy Gathering Devices Along Roadways,"A roadway system for energy generation and distribution is presented. In accordance with one embodiment of the invention, the roadway system comprises a plurality of wind energy generating devices, and a roadway system electricity grid. The wind energy generating devices are electrically connected to the roadway system electricity grid and are positioned on part of or near to a road in a system of roads and are optionally fixed in a position such that a multi-form, wind energy gathering network can be formed.","['H02J7/35', 'B60L53/51', 'B60L53/52', 'B60L8/006', 'F03D9/11', 'F03D9/25', 'F03D9/255', 'F03D9/32', 'H02J3/381', 'H02S10/12', 'B60K2016/003', 'B60L2200/26', 'F05B2220/61', 'F05B2240/212', 'F05B2240/9113', 'F05B2240/941', 'F05B2250/25', 'F05B2250/82', 'H02J2300/20', 'H02J2300/24', 'H02J2300/28', 'H02J2300/40', 'Y02B10/30', 'Y02E10/10', 'Y02E10/56', 'Y02E10/72', 'Y02E10/728', 'Y02E10/76', 'Y02E60/00', 'Y02E60/36', 'Y02E70/30', 'Y02T10/62', 'Y02T10/70', 'Y02T10/7072', 'Y02T10/90', 'Y02T90/12', 'Y04S10/126']"
US20070239082A1,Shock Wave Treatment Device,"The system for treating an internal organ has a generator source for producing a shock wave connected to a handheld or small shock wave applicator device 2, wherein the external housing 16 of the device 2 is hermetically sealed in a non-electrically conductive insulating skin membrane 5 being of a polymer material, preferably a silicone rubber or polyurethane rubber. Preferably the entire device 2 including the connectors 32, 33 and at least a 20 cm portion of attached cable 1 is sealed using a dip coating process or alternatively can use an insert molding process wherein the device 2 is placed in a mold 400 and the skin membrane 5 is injection molded around the entire housing 16 and the cable 1 has an outer skin 5 that abuttingly seals at a connection 32, 33 to the housing 16. The device 2 may further include an internal vacuum conduit connected to a vacuum system to detect leakages and in use may be used with a sterile sleeve cover with a similar vacuum system for leakage detection.","['A61H23/008', 'A61B17/22004', 'A61B46/17', 'A61B17/2251']"
US20120128683A1,Autism treatment,"A safe and effective treatment to curtail and cure autism spectrum disorders has been described in this invention using insulin, IGF-1, with multiple known adjuvant therapeutic agents, as well as other pharmaceutical, biochemical, nurticeuticals, and biological agents or compounds delivered through the olfactory mucosal region of the nose and external auditory meatus.","['A61K38/08', 'A61K38/28', 'A61P25/00']"
US20240312087A1,Custom content generation,Systems and methods for document processing are provided. One aspect of the systems and methods includes identifying a theme and an input image of a product. Another aspect of the systems and methods includes generating an output image depicting the product and the theme based on the input image using an image generation model that is trained to generate images consistent with a brand. Another aspect of the systems and methods includes generating text based on the product and the theme using a text generation model. Another aspect of the systems and methods includes generating custom content consistent with the brand and the theme based on the output image and the text.,"['G06F40/186', 'G06F40/40', 'G06Q30/0276', 'G06T11/60', 'G06T7/90', 'G06T2207/10024', 'G06T2207/20081']"
CN107145839B,Fingerprint image completion simulation method and system,"The invention discloses a fingerprint image completion simulation method and a system thereof, wherein the method comprises the following steps: collecting a plurality of fingerprint images, and judging and distinguishing incomplete fingerprint images and complete fingerprint images; extracting convolution network response from the incomplete fingerprint image, and performing super-pixel segmentation on the incomplete fingerprint image; extracting convolution network response summary characteristics of the superpixels according to the convolution network response and the result of the superpixel segmentation; carrying out similar structure chart matching on a super pixel adjacency graph by using a super pixel structure adjacent to the unknown region to obtain a middle layer structure region similar to the unknown region; matching image blocks with structural characteristics in the complete fingerprint image information to obtain an affine mapping relation between similar areas; and (3) optimizing and obtaining an optimal image block for complementing the unknown region by combining an affine mapping relation and a Markov random field energy minimization model, and fusing the images to generate a complementing fingerprint image. The invention aims to solve the technical problem that a complete fingerprint image cannot be obtained when the fingerprint of a user is incomplete.","['G06V40/1347', 'G06F18/295', 'G06N3/045', 'G06T5/50', 'G06T5/77', 'G06V10/95', 'G06T2207/20021', 'G06T2207/30196']"
WO2025005875A1,Image processing method and apparatus and computer device,"Disclosed in the present disclosure are an image processing method and apparatus and a computer device. The method comprises: acquiring a first image, wherein a first object in the first image wears clothing; performing clothing segmentation on the first image to obtain a clothing mask of the clothing; acquiring an object generation parameter, wherein the object generation parameter is used for representing a parameter required to generate the first object as a second object; in a generative diffusion model, by using the clothing mask to occlude the clothing in the first image, and by generating a second object on the basis of the object generation parameter, replacing with the second object the first object in the first image in which the clothing is occluded, thereby obtaining a second image in which the second object wears the clothing. The present invention solves the technical problem in related art of low fitness of clothing and an object in a display image when the display image is generated.","['G06T11/60', 'G06F3/0481', 'G06F3/04845', 'G06T7/10', 'G06T7/13', 'G06T2207/10004']"
US20240386634A1,Non-destructive generative image editing,"Systems and methods for non-destructive image editing are described. Embodiments are configured to obtain, via a document editor user interface, a selection input identifying a portion of a first image displayed in the document editor user interface. According to some aspects, the first image is part of a first layer of a multilayer document. Embodiments are further configured to: obtain an image generation text prompt; generate, using an image generation network, a second image based on the first image and the image generation text prompt; and present, via a multilayer window of the document editor user interface, a first element representing the first layer of the multilayer document and a second element representing a second layer of the multilayer document. The first element includes the first image and the second element includes the second image and a mask corresponding to the portion of the first image.","['G06F40/166', 'G06T11/60']"
US20250077765A1,System and methods to facilitate content generation using generative artificial intelligence models,"The present disclosure is directed to systems and methods to enhance the process of creating an artificial intelligence (AI) generated content or content items, such as images, text, video, sounds, etc., using a text or other suitable prompt, such as via voice input. The systems and methods disclosed provide streamlined content generation with, e.g., reduced processing power and computing time. In an embodiment the systems and methods receive a prompt for generating a first content item using a generative artificial intelligence (AI) model and retrieve, based on the prompt, a collection of matching content items. The systems and methods may then receive input selecting one of the content items from the collection and identify a prompt used to generate the selected content item. The systems and methods may then merge using a trained natural language processing model, the received prompt with the prompt of the selected content item to create a third prompt. In an embodiment the systems and methods may modify the third prompt based on additional input and, based on the modified third prompt, generate a second content item.","['G06F16/24578', 'G06F3/0482', 'G06F3/04845', 'G06F3/04847', 'G06F40/174', 'G06F40/30', 'G06F40/56', 'G06N3/0475']"
US20250150267A1,"Method of semantic transposition of text into an unrelated semantic domain for secure, deniable, stealth encryption","A method for linguistically encrypting a plaintext, comprising mapping the plaintext to a semantics and language model, thereby forming a semantically mapped plaintext; deriving a topology of the semantically mapped plaintext; and either conserving the topology during the semantic transposition, or performing a reversible transformation on the topology which is expected to be eventually reversed during decryption. Using an encryption key for linguistic encryption, a semantic transposition is applied onto the semantically mapped plaintext to produce a ciphertext which is a human-readable text in a semantic domain distinct from the plaintext. Conversely, the method can be used for decryption of the ciphertext into the plaintext using a decryption key. A zero-knowledge-proof can be used by sending a query in the semantic domain of the ciphertext, and a reply to the combined query and ciphertext can be generated using the semantic transposition engine (STE) by both parties for sharing and comparison.","['H04L9/0637', 'H04L9/088', 'G06F21/31', 'G06F21/602', 'G06F21/64', 'H04L9/12', 'H04L2209/34']"
US20240419949A1,Input-based attribution for content generated by an artificial intelligence (ai),"In some aspects, a server determines an input provided to a generative artificial intelligence, parses the input to determine: a type of content to generate, a content description, and creator identifiers. The server embeds the input into a shared language-image space to create an input embedding. The server determines a creator description comprising a creator-based embedding associated with individual creators. The server performs a comparison of the input embedding to the creator-based embedding associated with individual creators to determine a distance measurement of an embedding of individual creators in the input embedding. The server determines creator attributions based on the distance measurement and creates a creator attribution vector to provide compensation to the creators.","['G06F16/438', 'G06F16/45', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06Q30/0208']"
US20240420407A1,Autodecoding latent 3d diffusion models,"Systems and methods for generating static and articulated 3D assets are provided that include a 3D autodecoder at their core. The 3D autodecoder framework embeds properties learned from the target dataset in the latent space, which can then be decoded into a volumetric representation for rendering view-consistent appearance and geometry. The appropriate intermediate volumetric latent space is then identified and robust normalization and de-normalization operations are implemented to learn a 3D diffusion from 2D images or monocular videos of rigid or articulated objects. The methods are flexible enough to use either existing camera supervision or no camera information at allâinstead efficiently learning the camera information during training. The generated results are shown to outperform state-of-the-art alternatives on various benchmark datasets and metrics, including multi-view image datasets of synthetic objects, real in-the-wild videos of moving people, and a large-scale, real video dataset of static objects.","['G06V20/64', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06T13/40', 'G06T15/08', 'G06T15/20', 'G06T17/00', 'G06T19/20', 'G06T9/001', 'G06V10/82', 'G06T2210/21', 'G06T2219/2016', 'G06T2219/2021']"
US20240169488A1,Wavelet-driven image synthesis with diffusion models,"Systems and methods for synthesizing images with increased high-frequency detail are described. Embodiments are configured to identify an input image including a noise level and encode the input image to obtain image features. A diffusion model reduces a resolution of the image features at an intermediate stage of the model using a wavelet transform to obtain reduced image features at a reduced resolution, and generates an output image based on the reduced image features using the diffusion model. In some cases, the output image comprises a version of the input image that has a reduced noise level compared to the noise level of the input image.","['G06T5/70', 'G06T5/002', 'G06T3/4046', 'G06T2207/20064', 'G06T2207/20081', 'G06T2207/20084']"
US12153778B2,Prompted text-to-image generation,"Methods, non-transitory computer-readable storage media and computer or computer systems are described which include or relate to inputting or receiving information on one or more image characteristics from a graphical user interface, outputting one or more questions or options for additional details of the one or more image characteristics on a graphical user interface by way of a generative artificial intelligence language model performed on one or more processor, inputting or receiving the additional details from the graphical user interface, and outputting one or more images by way of a generative artificial intelligence text-to-image model performed on one or more processor based on the one or more image characteristics and the additional details.","['G06F3/0484', 'G06F9/451', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06T11/60', 'G06T2200/24']"
CN109923513A,System for detecting and characterizing input on a touch sensor,"One variation of a method for characterizing an input includes: scanning the array of sensing electrodes at a first resolution to generate a first force image; detecting a first force input in a first force image; responsive to a first geometric dimension of the first force input exceeding a first threshold, characterizing the first force input as a non-stylus input type; in response to the first force input, the first geometry remains below a first threshold: scanning the array of sensing electrodes at a second resolution; detecting a second force input in a second force image; and, in response to a ratio of a force magnitude of the second force input to a geometric dimension of the second force input exceeding a second threshold, characterizing the first force input as a stylus input type; and a location and type of output first force input.","['G06F3/0418', 'G06F3/03545', 'G06F3/0414', 'G06F3/04144', 'G06F3/04166', 'G06F3/04186', 'G06F3/045', 'G06F3/0488', 'G06F2203/04104', 'G06F2203/04105']"
US20080226684A1,Method and process for the production of multi-coated recognitive and releasing systems,"The present invention includes compositions, methods, systems and kits for the controlled delivery of an active agent within a polymeric network upon the binding of a molecule that decreases the structural integrity of the polymeric network at one or more micro- or nanovacuoles.","['A61K9/0004', 'A61K9/5138', 'A61K31/137', 'A61K38/28', 'A61K38/43', 'A61K8/0245', 'A61K8/042', 'A61K8/11', 'A61K8/73', 'A61K8/733', 'A61K9/1676', 'A61K9/209', 'A61K9/5123', 'A61K9/5161', 'A61K9/7084', 'A61Q13/00', 'A61Q15/00', 'A61Q19/00', 'A61K2800/10', 'A61K2800/413', 'A61K2800/546', 'A61K2800/56', 'A61K2800/592', 'A61K2800/77', 'A61K9/5073', 'A61K9/5084', 'A61Q1/02', 'A61Q1/06', 'A61Q1/08', 'A61Q1/10', 'A61Q19/10', 'A61Q5/02']"
US20250111655A1,Image generator for targeted visual characteristics,"The subject technology includes an image generator that generates images having specific visual concepts. The image generator uses a selective training process to fine-tune a text to a image generative system. The constrained text to image generative system may be trained to understand multiple custom tokens that embody visual characteristics of images included in fine-tuning datasets. Image generation prompts including one or more custom tokens may be used to condition the image creation process of the constrained text to image system to produce synthetic images having improved specificity, more creativity, and higher performance. Images created by the constrained text to image system may be ranked based on one or more criteria to further refine the created images for one or more specific use cases.","['G06F40/284', 'G06T11/00', 'G06T5/60', 'G06V10/774', 'G06T2207/20081']"
US11113890B2,Artificial intelligence enabled mixed reality system and method,"The present invention relates to an artificial intelligence based system and method for moderating interaction between interacting users. The attempt is to improve emotional intelligence of users so that a seasoned response and reaction is observed during interaction, even if situations of conflict arise. The disclosure, thus, provides for a mixed reality glass powered assistant that displays the moderated expressions of a customer to the service provider. For the same, the analytical engine upon determining the negative emotions of customer, transforms the image of customer and adds smile to his face, which is presented to the service provider via a mixed reality glass so that he responds back to the customer in a positive manner.","['H04N7/157', 'G06K9/00315', 'G06K9/00335', 'G06N3/045', 'G06N3/0454', 'G06T19/006', 'G06V10/764', 'G06V10/82', 'G06V40/174', 'G06V40/176', 'G06V40/20', 'G10L25/63', 'H04L67/131', 'H04L67/38', 'G06N20/10', 'G06N3/044']"
US20230082362A1,Processes and methods to predict blood pressure,"The present invention relates to systems and methods to measure, compute, and predict blood pressure. More specifically, the invention generally relates to systems, methods, and process for predicting blood pressure from respiratory, circulatory, acoustic, hemodynamic, movement and blood flow characteristics and metrics.","['A61B5/021', 'A61B5/0205', 'A61B5/7246', 'A61B5/725', 'A61B5/7253', 'A61B5/726', 'A61B5/7267', 'A61B5/7275', 'A61B5/7278', 'A61B5/7257', 'A61B5/743', 'A61B5/746']"
US12242530B2,Hyper-personalized prompt based content generation,"Methods, systems, and apparatus are provided for generating an image. A personalized text prompt is generated by processing an input embedding using a transformer model followed by a first fully connected neural network. The input embedding comprises a multi-dimensional embedding vector associated with a user profile and a plurality of user items. A scored label set is generated identifying a user's preferences by processing a set of attributes for the plurality of user items using a second fully connected neural network. The image is generated by processing the personalized text prompt and the scored label set using a diffusion model.","['G06F16/535', 'G06F16/538', 'G06F16/56', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
CN117496099A,"Three-dimensional image editing method, system, electronic device and storage medium","The invention relates to the technical field of three-dimensional modeling, and provides a three-dimensional image editing method, a system, electronic equipment and a storage medium, wherein the method comprises the following steps: acquiring an original image and a text instruction; inputting an original image and a text instruction into an image editing model to obtain an editing image output by the image editing model, wherein the editing image comprises a plurality of target objects displayed in the original image from different angles, and the form of each target object in each editing image is matched with the description of the text instruction; the image editing model is used for mapping an original image into hidden vectors, removing noise added on the hidden vectors by adopting a noise predictor under the guidance of a text instruction, removing the noise based on the condition obtained by removing the noise, and rendering an edited image through a three-dimensional generation countermeasure network. The invention is used for solving the defects that the existing three-dimensional image editing method applied in the prior art cannot simultaneously ensure that natural language guidance is supported and text guidance is accurate.","['G06T19/20', 'G06N3/0475', 'G06N3/094', 'G06T15/00']"
US20240157979A1,Trajectory prediction using diffusion models,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating trajectory predictions for one or more target agents, e.g., a vehicle, a cyclist, or a pedestrian, in an environment. In one aspect, one of the methods include: obtaining scene context data characterizing a scene at a current time point in an environment that includes multiple target agents; generating, from the scene context data, an encoded representation of the scene in the environment; and generating, by a diffusion model based on the encoded representation, a respective trajectory prediction output that predicts a respective future trajectory for each of the multiple target agents after the current time point.","['B60W60/00276', 'B60W50/0097', 'B60W50/06', 'B60W2552/20', 'B60W2554/4044', 'B60W2556/10']"
CN117689996A,"Model generation method and device, electronic equipment and storage medium","The application discloses a method and a device for generating a model, electronic equipment and a storage medium, and relates to the technical field of electronic equipment. The method comprises the following steps: the method comprises the steps of obtaining a first image and a first description text corresponding to the first image, pre-training a diffusion model based on the first image and the first description text, obtaining a pre-trained diffusion model, obtaining a second image and a second description text corresponding to the second image, performing feature decomposition on the second image, obtaining a plurality of image features corresponding to the second image, and performing fine adjustment on the pre-trained diffusion model based on the plurality of image features and the second description text to obtain a target diffusion model. According to the method and the device, the plurality of image features are obtained by combining different feature characterization technologies, and accurate extraction and fusion of image details can be achieved, so that the visual quality and detail expression of a model on a generated image are enhanced.","['G06V10/82', 'G06F40/30', 'G06N3/045', 'G06N3/0475', 'G06V10/44', 'G06V10/54', 'G06V10/806', 'G06V20/70']"
US20250061650A1,Interactive three-dimension aware text-to-image generation,An image processing system is configured to receive a three-dimensional (3D) model and a text prompt that describes a scene corresponding to the 3D model. The system may then generate a depth map of the 3D model and generate an output image based on the depth map and the text prompt. The output image may depicts a view of the scene that includes textures described by the text prompt. The output image may be generated using an image generation model.,"['G06T17/00', 'G06F3/04845', 'G06F3/04815', 'G06F3/0482', 'G06T19/003', 'G06T19/20', 'G06T7/50', 'G06T2207/10028', 'G06T2219/2021']"
CN118657685A,Remote sensing image generation method for comprehensive monitoring of forestry resources,"The invention discloses a remote sensing image generation method for forestry resource comprehensive monitoring, which belongs to the technical field of image data processing and comprises a construction dataset, a construction style consistency diffusion network M 1 and total loss; training to obtain a style consistency diffusion model M 2; constructing a generated countermeasure network M 3, wherein the reverse process of a diffusion model in M 2 is used as a generator, a pre-trained YOLOv s model is used as a discriminator, and a discriminator loss and a generator loss are constructed; and (3) obtaining an optimization generator during training M 3, and generating forestry resource remote sensing images by using the optimization generator. According to the invention, style loss is introduced into the diffusion model, so that the visual effect of the image is improved, and the consistency of the image in style is ensured; the target detection is used as a discriminator, so that not only is the authenticity of the whole image focused, but also each object in the remote sensing image can be accurately classified and positioned, and therefore, the required ground object can be accurately generated at a preset specific position.","['G06T5/70', 'G06N3/094', 'G06T5/50', 'G06V10/74', 'G06V10/764', 'G06V10/774', 'G06T2207/10032', 'G06T2207/20221']"
CN117911319A,An injection molded parts defect detection method based on improved YOLOv5,"The invention discloses an injection molding defect detection method based on an improvement YOLOv, which comprises the following steps: collecting and marking injection molding products and analyzing defect types as an initial data set; the defect of the injection molding is highlighted by image processing, the data set after the image processing is subjected to traditional data enhancement and deep learning data enhancement, the injection molding data set after the data enhancement is input into an improved YOLOv algorithm for training, and the improved YOLOv algorithm comprises an optimized loss function and an optimized network structure; the modified YOLOv algorithm was compared to other YOLO and to the original YOLOv algorithm for injection molding detection. Compared with the original YOLOv detection algorithm, the method has a better detection effect, and can better detect the defects of a small target and a conventional target in the injection molding.","['G06T7/0004', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/806', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'Y02P90/30']"
CN118469374A,Continuous casting billet quality prediction method and system based on diffusion model data enhancement,"The invention provides a continuous casting billet quality prediction method and a continuous casting billet quality prediction system based on diffusion model data enhancement, wherein the method comprises the following steps: firstly, integrating continuous casting billet production parameters into a table structured data set, obtaining each column data type in the data set, analyzing continuous and discrete data to obtain a continuous column number range and discrete column type information; then taking the continuous features and the discrete features as inputs of a Gaussian diffusion model and a polynomial diffusion model respectively, and training an integral diffusion model; performing data enhancement by applying the trained diffusion model to generate a synthetic data set, and training a quality prediction model based on machine learning by combining the generated data and the real data; and finally, applying the continuous casting production characteristic parameters to a trained square billet quality prediction model, and outputting a quality grade result. The method can be used for relieving the problems of data scarcity and sample imbalance in the continuous casting billet production process, and can improve the generalization capability of the prediction model, thereby improving the actual billet production quality prediction effect.","['G06Q10/06395', 'G06N20/00', 'G06Q50/04', 'Y02P90/30']"
CN117292704A,Voice-driven gesture action generation method and device based on diffusion model,"The invention discloses a method and a device for generating voice-driven gesture actions based on a diffusion model, wherein the method comprises the following steps: acquiring a human body gesture action data set with voice labels, preprocessing the human body gesture action data set to obtain training data of gesture action sequence fragments with voice information labels, and adding noise to gesture action sequences in the training data to obtain a noisy gesture action sequence sample for training a diffusion model; constructing and training a diffusion model for voice-driven gesture motion generation, wherein the diffusion model regards a gesture motion generation task as a denoising process for a noisy gesture motion sequence; and (3) using a trained diffusion model, and performing iterative denoising from random sampling Gaussian noise according to given voice input with any length to generate a gesture action sequence. According to the invention, the diffusion model is utilized to model the gesture action sequence distribution based on voice driving, so that the gesture action sequence with more authenticity and diversity can be generated.","['G06V10/774', 'G06N3/0464', 'G06N3/08', 'G10L21/055', 'G10L25/30']"
CN118114124A,"Text-guided controllable portrait generation method, system and device based on diffusion model","The invention discloses a method, a system and equipment for generating a text-guided controllable portrait based on a diffusion model, which are characterized in that firstly, a prompt text is subjected to conditional coding to be vector representation; then generating a semantic condition appointed editing region mask based on the coded prompt text and a source image x0 to be processed; and finally, inputting the source image, the coded symptom prompt text and the editing area mask into an image generation network based on a diffusion model together to generate an image meeting the requirements. The invention can effectively improve the controllability and the image quality of the generated image, reduce the local blurring of the image and enhance the fidelity of the image.","['G06F18/241', 'G06F18/15', 'G06F18/214', 'G06N3/0455']"
CN118015421A,Personalized Single Image Concept Encoder Using Pretrained Diffusion Model,The present disclosure relates to a personalized single image concept encoder using a pre-trained diffusion model. Systems and methods for image processing are provided. One aspect of the system and method includes identifying a style image that includes a target style. The pattern encoder network generates a pattern vector representing the target pattern based on the pattern image. The pattern encoder may be trained based on pattern losses that encourage the network to match the desired pattern. The diffusion model generates a composite image including the target pattern based on the pattern vector. The diffusion model is trained independently of the style encoder network.,"['G06T11/001', 'G06V10/82', 'G06N3/0464', 'G06N3/08', 'G06V10/751', 'G06V10/771', 'G06T2207/20081', 'G06T2207/20084']"
CN118691497A,"Image shadow removal method, device, equipment and medium based on diffusion model","The application relates to an image shadow removing method, device, equipment and medium based on a diffusion model, which are used for detecting a shadow region in an optical image to be subjected to shadow removing by using a shadow detection model to obtain a shadow mask image, meanwhile, decomposing the optical image by using an intrinsic image decomposition model to obtain an illumination image and a reflectivity image, taking the shadow mask image and the reflectivity image as physical priori information of the optical image, designing a shadow region condition generation constraint and an iteration structure texture consistency constraint based on the physical priori information, guiding the diffusion model by using the shadow region condition generation constraint and the iteration structure texture consistency constraint, and denoising a Gaussian noise image in a back diffusion process to obtain a reinforced image after shadow removing. The shadow removing performance of the low-quality image can be effectively improved by adopting the method.","['G06T5/70', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06T5/60', 'G06T7/49']"
CN118799337A,Medical image segmentation method and system based on diffusion model and domain adaptation,"The invention discloses a medical image segmentation method and a system based on a diffusion model and domain adaptation, wherein the method comprises the following steps: collecting target domain image data and source domain image data; generating a pseudo tag for an unlabeled image in the target domain image data through a preset model to obtain a target domain image-mask pair; performing deformation enhancement processing on the source domain image-mask pairs and the target domain image-mask pairs through a preset deformation enhancement module, and inputting the source domain image-mask pairs and the target domain image-mask pairs into a pre-constructed conditional diffusion model for iterative training so as to generate a plurality of new image-mask pairs; and (3) carrying out iterative training on the pre-constructed domain adaptation model after mixing the new image-mask pair and the source domain image-mask pair, and carrying out segmentation processing on the image to be segmented based on the domain adaptation model after training so as to obtain a segmentation result. The generalization capability of the model to the target domain can be enhanced, the model is better adapted to the change in the target domain, and the performance of the model in the target domain is improved.","['G06T7/10', 'G06T3/02', 'G06T3/60', 'G06T7/0012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'Y02T10/40']"
WO2025044138A1,"Method and system for generating three-dimensional target texture on the basis of text, and storage medium","A method and system for generating a three-dimensional target texture on the basis of text, and a storage medium. The method comprises: obtaining three-dimensional model data and corresponding descriptive text data; generating a depth map and a current normal line map at a corresponding angle of view, and inputting the descriptive text data and the depth map to a depth map diffusion model, to obtain a set of synthetic images; and performing multi-stage generative training, performing multi-stage iterative updating, and on the basis of a restored texture map and a texture map obtained after completing the multi-stage iterative updating, generating a three-dimensional target texture map. According to the present invention, a stage-by-stage advancing method is used, a region having a relatively large discontinuity in generated texture is updated by means of calculation using a normal line map, the generated texture map has a higher definition and is more delicate, and a texture map of a current stage is outputted on the basis of an updated weight score. Therefore, the consistency of the texture map of the current stage and a synthetic map can be enhanced, which is also equivalent to matching semantics of input text (i.e., the descriptive text data), so that the generated three-dimensional target texture map is more accurate.","['G06T15/04', 'G06T17/20', 'G06V10/774']"
WO2022205657A1,"Csm image segmentation method and apparatus, terminal device, and storage medium","Provided in the present application are a CSM image segmentation method and apparatus, a terminal device, and a storage medium, relating to the technical field of deep learning, and capable of increasing the precision of CSM image segmentation to a certain degree. The method comprises: acquiring a target image; and inputting the target image into a trained generator for processing to obtain a segmented image of the target image, the generator being an encoder-decoder structure, a pyramid pooling module being arranged between the encoder and the decoder, and a plurality of convolutional layers in the encoder and the pyramid pooling module being interconnected.","['G06T7/0012', 'G06F18/214', 'G06F18/25', 'G06T7/11', 'G16H30/00', 'G06T2207/10092', 'G06T2207/20081', 'G06T2207/30012', 'G06T2207/30016']"
CN117671084A,Semantic picture editing method based on diffusion model,"The invention discloses a semantic picture editing method based on a diffusion model, which belongs to the technical field of computer vision and artificial intelligence and comprises the following steps: constructing a text encoder and an image encoder, embedding a tag into a vector space through the text encoder, and calculating through the image encoder and the tag to generate a picture mask; constructing a denoising diffusion probability model, and encoding an input image based on the denoising diffusion probability model to obtain potential characteristics corresponding to the input image; decoding the denoising diffusion probability model based on the picture mask and the potential features corresponding to the input image to obtain an inferred mask; the background of the input image is replaced with pixel values in the encoding process and mapped back to the original pixels based on the inferred mask, resulting in a new picture. The application provides a semantic guidance picture editing method based on a diffusion model. The method can automatically find out which areas of the input image should be edited according to the text query.","['G06T11/60', 'G06T2207/20084', 'Y02D10/00']"
US12223577B2,Data-driven physics-based models with implicit actuations,"One embodiment of the present invention sets forth a technique for generating actuation values based on a target shape such that the actuation values cause a simulator to output a simulated soft body that matches the target shape. The technique includes inputting a latent code that represents a target shape and a point on a geometric mesh into a first machine learning model. The technique further includes generating, via execution of the first machine learning model, one or more simulator control values that specify a deformation of the geometric mesh, where each of the simulator control values is based on the latent code and corresponds to the input point, and generating, via execution of the simulator, a simulated soft body based on the one or more simulator control values and the geometric mesh. The technique further includes causing the simulated soft body to be outputted to a computing device.","['G06T13/40', 'G06T17/20', 'G06T19/20', 'G06T2210/36', 'G06T2219/2021']"
US20250035907A1,Apparatus and methods for real-time image generation,"Aspects of present disclosure relate to real-time image generation. An exemplary apparatus for real time image generation includes at least an optical system, a slide port configured to hold a slide, an actuator mechanism mechanically connected to a mobile element, a user interface comprising an input interface and an output interface, at least a processor configured to: using the at least an optical system, capture a first image of the slide at a first position, modify the first image, using the output interface, display the first image to a user, using the input interface, receive a parameter set from the user.","['G02B21/26', 'G02B21/32', 'G02B21/34', 'G02B21/361', 'G02B21/365', 'G02B21/368']"
CN118827875A,A large-capacity generative image steganography method based on diffusion model,"The invention discloses a large-capacity generation type image steganography method based on a diffusion model, which comprises the steps of firstly constructing a mapping algorithm for mapping secret information into carrier-secret noise, and generating an initial carrier-secret image by using the diffusion model DDIM; then, a mechanism for detecting and correcting errors is provided by using a mapping rule aiming at errors generated when the floating point image is converted into a real image; finally, DDIM accelerated sampling is applied and a final encrypted image is generated. Experiments and analysis are carried out on FFHQ, cat and Bedroom large-scale data sets by the method provided by the invention, and experimental results show that the method provided by the invention can ensure that secret data is extracted 100% correctly and has higher embedding capacity, and in addition, compared with the image generation efficiency of a steganography method based on a diffusion model (DDPM), the generation speed of the method is improved by 65.92%.",['H04N1/32267']
CN117522697A,"Face image generation method, face image generation system and model training method","The invention discloses a face image generation method, a face image generation system and a model training method, wherein the face image generation method comprises the following steps: acquiring a given natural language text for describing the face features, encoding by using a text encoder to obtain coarse-granularity text features and fine-granularity text features, and mapping the coarse-granularity text features and the fine-granularity text features into a latent space; inputting the extracted coarse-granularity text features into a multi-layer diffusion model, generating a low-resolution sketch by the multi-layer diffusion model through the learned probability distribution of the latent space noise, generating image features in the process, carrying out feature fusion alignment on the fine-granularity features and the image features, and embedding the fine-granularity features and the image features into a memory network to form a memory slot; taking the image features as an inquiry to a memory network, extracting the missing fine-grained features from the low-resolution sketch from the memory network, and recovering the high-resolution face image on the basis of generating the sketch. The invention is oriented to open texts, interactively generates face images, and does not limit the quantity and description style of input texts.","['G06T3/4076', 'G06F16/5846', 'G06F18/213', 'G06F18/253', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06V10/806', 'G06V10/82']"
US20220383986A1,Complex System for Contextual Spectrum Mask Generation Based on Quantitative Imaging,"Methods, apparatus, and storage medium for determining a condition of a biostructure by a neural network based on quantitative imaging data (QID) corresponding to an image of the biostructure. The method includes obtaining specific quantitative imaging data (QID) corresponding to an image of a biostructure; determining a context spectrum selection from context spectrum including a range of selectable values by: applying the specific QID to an input layer of a context-spectrum neural network, wherein the context-spectrum neural network is trained, according to a combination of focal loss and dice loss, based on previous QID and constructed context spectrum data associated with the previous QID; mapping the context spectrum selection to the image to generate a context spectrum mask for the image; and determining a condition of the biostructure based on the context spectrum mask.","['G16B45/00', 'G16H10/40', 'G06T7/0012', 'G16B40/10', 'G16H30/40', 'G16H50/70', 'G06T2207/10056', 'G06T2207/30024']"
CN117994167A,Diffusion model defogging method integrating parallel multi-convolution attention,"The invention belongs to the field of deep learning, and particularly relates to a HazeDiffusion diffusion model defogging method integrating parallel multi-convolution attention, which comprises the following steps: constructing a data set; constructing a diffusion network model HazeDiffusion; training on the built HazeDiffusion model by utilizing the belonging training set; acquiring a foggy image to be recovered, and carrying out defogging enhancement on the foggy image through a HazeDiffusion model after training; an evaluation index is established for evaluation of the HazeDiffusion model. The invention is based on a diffusion model, introduces a parallel multi-convolution attention residual block (PMCA), and the PMCA module comprises two parts of parallel attention and parallel multi-convolution, and performs multi-scale connection through residual errors; and the size of the input image is adjusted through double three times of downsampling, and then the defogging image is upsampled by using the Laplacian pyramid, so that the model can process high-resolution images, and the efficiency of the diffusion model is indirectly improved.","['G06V10/82', 'G06N3/0464', 'G06N3/08', 'Y02A90/10']"
CN117494791A,"Content generation model optimization method, content generation method and related device","One or more embodiments of the present disclosure provide a content generation model optimization method, a content generation method, and related devices. According to the optimization method, a plurality of basic generation models with different types of content generation capacities are obtained through training according to a plurality of first training sample sets of different types, then joint distillation is carried out on the plurality of basic generation models, the capacities of the basic generation models are migrated to a plurality of adaptation modules corresponding to the basic generation models one by one, the adaptation modules and an initial fusion model form a fusion generation model, and the content generation capacities of the plurality of basic generation models are fused to the fusion generation model. The optimization method also performs random exchange on the functional layers of the plurality of basic generative models before distillation. The content generating method generates target content requested by a user through a target model group, wherein a fusion generating model is configured in the target model group; and according to the fitting capacity of the fusion model to the basic generation model, one or more basic generation models can be selected to be configured in the target model group.","['G06N3/096', 'G06F18/214', 'G06N3/045', 'G06N3/0475']"
US20250022100A1,Multi-modal synthetic content generation using neural networks,"In various examples, systems and methods are disclosed relating to systems and methods for multi-modal creative content generation using neural networks. The systems and methods can use one or more neural networks to generate outputs representative of creative and/or artistic characteristics of features indicated by input prompts. The one or more neural networks can include at least one text extension model to increase an amount of information of the input prompts. The one or more neural networks can be configured to generate high resolution outputs. The one or more neural networks can be used to implement end-to-end conversational interfaces for receiving input prompts and presenting creative and/or artistic outputs.","['G06T5/50', 'G06T11/00', 'G06T5/70', 'G06F40/289', 'G06F40/35', 'G06T2207/20081', 'G06T2207/20084']"
US20240346234A1,Structured document generation from text prompts,"Systems and methods for document processing are provided. One aspect of the systems and methods includes obtaining a prompt including a document description describing a plurality of elements. A plurality of image assets are generated based on the prompt using a generative neural network. In some cases, the plurality of image assets correspond to the plurality of elements of the document description. A structured document is then generated that matches the document description. In some cases the structured document includes the plurality of image assets and metadata describing a relationship between the plurality of image assets.","['G06T11/00', 'G06F40/30', 'G06F40/166', 'G06F40/103', 'G06F40/12', 'G06N20/00', 'G06V30/41', 'G06F40/10', 'G06N3/02', 'G06T2210/61']"
WO2024164030A2,Photorealistic content generation from animated content by neural radiance field diffusion guided by vision-language models,"A method implemented by a computing device. The method includes obtaining one or more of animated video content, a text prompt, and view information; generating photorealistic two dimensional (2D) image frames based on the animated video content, the text prompt, and the view information using a vision-language model; and rendering photorealistic three dimensional (3D) image frames based on the photorealistic 2D image frames using a 3D representation model.","['G06T15/20', 'G06N3/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T11/00', 'G06T15/08', 'G06T17/00', 'G06F40/00']"
US20170235915A1,Personalized model with regular integration of data,"For personalized modeling with regular integration from a sensor, a wearable sensor and/or sensor outside of the medical facility or environment provides health-related data on a regular, periodic, or continuous basis (e.g., every few minutes or hours). Rather than using that data alone, the data is used to update a previously created personalized model of anatomy of the patient. After updating a parameter value for the personalized model, the updated model is used to output more complex health-related information than provided by the sensors.","['G16H10/60', 'G06F19/3437', 'A61B5/02055', 'A61B5/6802', 'G06F19/322', 'G06F19/3418', 'G16H40/67', 'G16H50/30', 'G16H50/50']"
CN116579945B,Night image restoration method based on diffusion model,"The invention provides a night image restoration method based on a diffusion model, which belongs to the technical field of computer vision and adopts forward noise adding and reverse noise removing diffusion treatment for a white-day normal light image: in order to restore the definition of the night image at the same time and also reduce high-frequency noise and restore the end-to-end night image, the invention adopts a night image restoration frame based on a diffusion model depth neural network, thereby maximally utilizing the denoising characteristic; meanwhile, high-frequency details are reserved consistently under extremely dark and noisy conditions, and the proposed framework can be applied to the traffic field and can also be extended to the image restoration field of other real night scenes, so that the universality of the method is improved.","['G06T5/00', 'G06N3/04', 'G06N3/08', 'G06T5/70', 'G06T5/77', 'G06T2207/10016', 'G06T2207/20081', 'Y02T10/40']"
WO2023144386A1,Generating data items using off-the-shelf guided generative diffusion processes,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating a data item using a diffusion neural network. In particular, the data item is generated by guiding a reverse diffusion process using a time-independent guidance neural network.","['G06N3/045', 'G06V10/72', 'G06N3/0475', 'G06T11/60', 'G06V10/26', 'G06V10/764', 'G06V10/82']"
US12354576B2,Artificial intelligence music generation model and method for configuring the same,"The present disclosure provides a method for configuring a learning model for music generation and the corresponding learning model. The method includes training a masked autoencoder with training data comprising a combination of a reconstruction loss over time and frequency domains and a patch-based adversarial objective operating at different resolutions. An omnidirectional latent diffusion model is trained based on music data represented in a latent space to obtain a pretrained diffusion model. The pretrained diffusion model is fine-tuned based on text-guided music generation, bidirectional music in-painting, and unidirectional music continuation. The method enables high-fidelity music generation conditioned on text or music representations while maintaining computational efficiency.","['G10H1/0025', 'G10H2210/111', 'G10H2250/311']"
US20250078366A1,Method of generating partial area of image by using generative model and electronic device for performing the method,"Provided are a method of generating a partial area of an image by using a generative model and an electronic device for performing the method. The method of generating a partial area of an image by using a generative model includes obtaining an image comprising information of the partial area, obtaining an intermediate generated image by inputting the image into a first generative model, the intermediate generated image comprising first image information corresponding to the partial area, and obtaining a final generated image comprising second image information by inputting the image and the intermediate generated image to a second generative model, the second image information being at least partially different from the first image information.","['G06T11/60', 'G06T5/60', 'G06T5/70', 'G06T9/00', 'G06T2207/20081', 'G06T2207/20084']"
US20100105975A1,Nuclear Assisted Hydrocarbon Production Method,"A method is disclosed for the temporary or permanent storage of nuclear waste materials comprising the placing of waste materials into one or more repositories or boreholes constructed into an unconventional oil formation. The thermal flux of the waste materials fracture the formation, alters the chemical and/or physical properties of hydrocarbon material within the subterranean formation to allow removal of the altered material. A mixture of hydrocarbons, hydrogen, and/or other formation fluids are produced from the formation. The radioactivity of high-level radioactive waste affords proliferation resistance to plutonium placed in the periphery of the repository or the deepest portion of a borehole.","['E21B43/2403', 'E21B41/0057', 'G21F9/34', 'G21F9/36']"
CN116434734A,"Voice editing method, electronic device and storage medium","The invention discloses a voice editing method, electronic equipment and a storage medium, wherein the voice editing method comprises the following steps: inputting the frequency spectrum of the original voice, the phoneme sequence of the original voice and the alignment relation between the phoneme sequence and the frequency spectrum to an encoder for encoding to obtain an original hidden space code; dividing the original hidden space code into a plurality of fragments, and keeping other fragments in the plurality of fragments unchanged by corresponding a certain fragment in the plurality of fragments to a phoneme sequence to be modified; acquiring an edited phoneme sequence, and generating a new certain segment based on the edited phoneme sequence by using a diffusion model, wherein the diffusion process of the diffusion model is guided by the other segments; and decoding the new hidden space codes formed by the new certain segment and the other segments by using a decoder to obtain an edited frequency spectrum. The method of the embodiment can realize zero-sample voice editing.","['G10L15/01', 'G10L13/08', 'G10L15/02', 'G10L15/04', 'G10L19/0018', 'G10L19/02', 'G10L25/60', 'G10L2015/025']"
CN117349427A,An artificial intelligence multi-modal content generation system for responding to public opinion events,"The invention discloses an artificial intelligence multi-mode content generating system facing public opinion event coping, which applies an artificial intelligence multi-mode content generating technology to the application scene of public opinion event coping, comprising: data processing, content generation and content quality credibility evaluation. The system abandons the traditional manual public opinion coping mode, automatically processes a large amount of content generating tasks through an intelligent algorithm and technology, can quickly and accurately generate public opinion content meeting the requirements of users, improves the efficiency and quality of content generation, provides more comprehensive and diversified public opinion event coping capability, saves the time and cost of manual processing, simultaneously has an intelligent algorithm and model, can generate data driving according to public opinion data and user feedback, and provides more accurate, comprehensive and diversified content, thereby effectively improving the effect and efficiency of public opinion event coping.","['G06F16/335', 'G06F16/3329', 'G06F16/3344', 'G06F16/35', 'G06F40/237', 'G06N3/04', 'G06V10/24', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US20240304177A1,Emotion and character parameters for diffusion model content generation systems and applications,"Approaches presented herein provide systems and methods for generating three-dimensional (3D) content with fine grained emotions and character traits. A set of classifiers may be used to identify emotions and character traits from an input provided by a user. Each of the classifiers in the set of classifiers may use a set of seed words that is expanded through methods including manual collection, synonym extension, and/or word alignment. An input may then be evaluated for indications of emotion and/or character traits, such as by identifying certain words or phrases present within the input. Output vectors associated with the identified emotion and/or character traits may then be provided to different generative models to adjust content, such as modifications to output audio or facial expressions for digital character representations.","['G06F40/247', 'G06F40/30', 'G06T13/205', 'G06T17/20', 'G10L13/10']"
US20200025737A1,Chemical sensor data recognition,"Methods, systems, and computer readable media for chemical sensor data recognition using an odor detection system with sensor modules.",['G01N33/0073']
US20240296535A1,Automatic image quality evaluation,"Examples disclosed herein describe techniques for automatic image quality evaluation. A first set of images generated by a first automated image generator and a second set of images generated by a second automated image generator are accessed. A first machine learning model generates a first quality indicator for each image in the first set of images and the second set of images. A second machine learning model generates a second quality indicator for each image in the first set of images and the second set of images. Based on the generated indicators, a first image from the first set of images and a second image from the second set of images are automatically selected and compared. A first ranking of the first automated image generator and the second automated image generator is generated based on the comparison, and ranking data is caused to be presented on a device.","['G06V10/993', 'G06F40/126', 'G06F40/40', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T11/00', 'G06T7/0002', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
CN107423707A,A kind of face Emotion identification method based under complex environment,"The invention discloses a kind of face Emotion identification method based under mobile embedded complex environment, face is divided into forehead, looks, cheek, nose, face, chin main region by this method, and it is further divided into 68 characteristic points, for features described above point, in order to realize the discrimination of face Emotion identification, the degree of accuracy and reliability under circumstances, the method of user's face portion and expressive features classification in the case of normality, uses methods of the Faster R CNN based on facial zone convolutional neural networks under illumination, reflection, shadowed conditionï¼The method that Bayesian network, Markov Chain, variation reasoning in the case where moving, shake, rocking and moving complex situations are combinedï¼The method being combined in the case where face shows incomplete, plurality of human faces environment, noisy background condition using depth convolutional neural networks and super resolution degree antagonism neutral net SRGANs, enhancing study, back-propagation algorithm, discard algorithm, it is effectively facilitated effect, the degree of accuracy and the reliability of expression recognition.","['G06V40/171', 'G06F18/2411', 'G06N3/045', 'G06N3/084', 'G06T3/40', 'G06T3/60', 'G06T7/60', 'G06V40/174', 'G06T2207/20081']"
WO2025031067A1,"Image processing method and apparatus, device, and computer readable storage medium","The present application discloses an image processing method and apparatus, a device, and a computer readable storage medium. Embodiments of the present invention can be applied to scenarios such as cloud technology, artificial intelligence, intelligent transportation, and assisted driving. The method comprises: acquiring a reference image, and acquiring a similar image similar to the reference image; determining difference information between the reference image and the similar image; determining a target mask map in the reference image for the difference information, wherein the target mask map is used for highlighting a difference object, determined on the basis of the difference information, in the reference image relative to the similar image,; on the basis of the difference object and the reference image, expanding a text to obtain a difference description text; and on the basis of the target mask map, the difference description text, and the reference image, performing local adjustment on the similar image to obtain a target image. The present application can improve the accuracy of image adjustment, so that the adjusted image effect conforms to actual requirements, facilitating the development of other subsequent services.","['G06V10/761', 'G06V10/30', 'G06V10/44', 'G06V10/762', 'G06V10/774']"
US20130012823A1,Methods and Systems for Non-Invasive Measurement of Blood Pressure,"Methods and systems for determining a blood pressure value for a patient in a non-invasive manner are disclosed. A photoplethysmograph (PPG) signal is obtained from a patient's measurement location. Clinical parameters of the patient are also received. Based on measurement parameters extracted from the PPG signal and the clinical parameters, a fixed length vector is generated. The fixed length vector is analyzed using a deep belief network, and an estimated blood pressure reading is output.","['A61B5/14551', 'A61B5/021', 'A61B5/7267', 'G06F18/217', 'G06F18/2411', 'G06F18/24323', 'G06F2218/08', 'G16H50/20']"
US12106548B1,Balanced generative image model training,"A method for training a generative image model, including defining multiple sensitive categories and protected attributes associated with multiple training images, determining for a particular sensitive category a distribution of a protected attribute within the training images, and based on the distribution, calculating for each training image a corresponding image debiasing weight value associated with the protected attribute. The method further includes generating annotated training data including the training images, and for each training image, (1) the corresponding image debiasing weight value associated with the protected attribute and (2) a corresponding descriptive text caption. The method further includes performing a training process using the annotated training data to train a generative image model resulting in a trained model. A contribution of each image in the training images to an optimization loss of the training process is weighted during the training process using the corresponding image debiasing weight value.","['G06V10/774', 'G06V20/70']"
CN119066403A,A fault diagnosis data enhancement method based on diffusion model and generative adversarial network,"The invention discloses a novel fault diagnosis data enhancement method, namely ADGAN, which is a self-adaptive diffusion model generation countermeasure network, and ADGAN generates Gaussian mixture distribution noise through a forward diffusion chain, so that gradient is smoother and more stable, and the problems of gradient disappearance and the like in a traditional GAN model are avoided. ADGAN on each diffusion time step, the real data and the generated data of diffusion are learned and distinguished by using discriminators with different noise data proportions and time step correlations, the generator learns from feedback of the discriminators through back propagation of a forward diffusion chain, the length of the forward diffusion chain can be adaptively adjusted, the diversity of the generator is improved, and the problems of pattern collapse and slow reverse generation process of a traditional diffusion model are effectively avoided. The patent uses the Kesi Chu Da bearing dataset and the NEFU dataset to collect the dataset collected by the test bed, verifies that ADGAN is excellent in data generation effect and stability, can effectively solve the problem of fault samples in unbalanced datasets, remarkably improves fault diagnosis performance, and provides a new solution for data enhancement and fault diagnosis.","['G06F18/2131', 'G06F18/214', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'Y02T90/00']"
US12406232B2,Building management system with generative AI-based automated flexible customer report generation and standardization,"A method includes receiving, by one or more processors, an unstructured service report corresponding to a service request handled by one or more technicians for servicing building equipment. The unstructured service report may include unstructured data not conforming to a predetermined format or conforming to a plurality of different predetermined formats. The method may include extracting, by the one or more processors, a set of standards from one or more technical documents associated with the building equipment. The method may include automatically generating, by the one or more processors using a generative AI model, a structured service report in the predetermined format for delivery to a customer associated with the building equipment. Generating the structured service report may include standardizing the structured service report to comply with the set of standards extracted from the one or more technical documents associated with the building equipment.","['G06F40/103', 'G06F40/186', 'G06F40/56', 'G06Q10/20', 'G06Q50/163']"
US20240345560A1,Building management system with generative ai-based coupling of unstructured service data to other input / output data sources and analytics,"A method includes receiving, by one or more processors, unstructured service data corresponding to one or more service requests handled by technicians for servicing building equipment of a building. The method may include detecting, by the one or more processors, an identifier of the building equipment, a space of the building, or a customer associated with the building using the unstructured service data. The method may include retrieving, by the one or more processors based on the identifier of the building equipment, the space, or the customer, additional data associated with the building equipment, the space, or the customer from one or more additional data sources separate from the unstructured service data. The method may include training, by the one or more processors, a generative AI model using training data including the unstructured service data and the additional data.","['G05B19/042', 'G06F11/0736', 'G06F11/079', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/094', 'G05B2219/2642']"
US20240346036A1,Building management system with generative ai-based interactive service tool,"A method including training, by one or more processors, a generative AI model using a plurality of first unstructured service reports corresponding to a plurality of first service requests handled by technicians for servicing building equipment. The plurality of first unstructured service reports include unstructured data not conforming to a predetermined format or conforming to a plurality of different predetermined formats. The method includes receiving, by the processors, a second service request for servicing building equipment. The method includes generating, by the processors using the generative AI model, a user interface prompting a user to provide information about a problem leading to the second service request as unstructured data not conforming to the predetermined format or conforming to the plurality of different predetermined formats. The method includes automatically initiating, by the processors, one or more actions to address the problem based on the information provided via the user interface.","['G06F16/3329', 'G06F11/079', 'G06F16/258']"
US20240346060A1,Building management system with generative ai-based unstructured service data ingestion,"A method includes receiving, by one or more processors, a plurality of first unstructured service reports corresponding to a plurality of first service requests handled by technicians for servicing building equipment. The plurality of first unstructured service reports may include unstructured data not conforming to a predetermined format or conforming to a plurality of different predetermined formats. The method may include training, by the one or more processors, a generative AI model using the plurality of first unstructured service reports. The method may include performing, by the one or more processors using the trained generative AI model, one or more actions with respect a second service request subsequent to training the generative AI model.","['G06Q30/012', 'G06F16/345', 'G06F16/383', 'G06Q50/163']"
US20240346459A1,Building management system with generative ai-based automated maintenance service scheduling and modification,"A method includes training, by one or more processors, a generative AI model using a plurality of first service requests handled by technicians for servicing building equipment and outcome data indicating outcomes of the plurality of first service requests. The generative AI model may be trained to identify one or more patterns or trends between characteristics of the plurality of first service requests and the outcomes of the plurality of first service requests. The method may include receiving a second service request for servicing building equipment. The method may include automatically determining, using the generative AI model, one or more responses to the second service request based on characteristics of the second service request and the one or more patterns or trends between the characteristics of the plurality of first service requests and the outcomes of the plurality of first service requests identified using the generative AI model.","['G06Q10/0631', 'G06Q10/063112', 'G06Q10/20']"
US12124961B2,System for continuous update of advection-diffusion models with adversarial networks,"A computing device configured for automatic selection of model parameters includes a processor and a memory coupled to the processor. The memory stores instructions to cause the processor to perform acts including providing an initial set of model parameters and initial condition information to a model based on historical data. A model generates data based on the model parameters and the initial condition information. After determining whether the model-generated data is similar to an observed data, updated model parameters are selected for input to the model based on the determined similarity.","['G06N3/08', 'G06N3/088', 'G06N3/042', 'G06N3/045', 'G06N3/047', 'G06N7/01']"
US12282305B2,Building management system with generative AI-based predictive maintenance,"A method including training, by one or more processors, a generative AI model using first operating data from building equipment and a plurality of first service reports indicating a plurality of first problems associated with the building equipment. The method may include predicting, by the one or more processors using the generative AI model, one or more future problems likely to occur with the building equipment based on second operating data from the building equipment. The method may include automatically initiating, by the one or more processors, one or more actions to prevent the one or more future problems from occurring or mitigate an effect of the one or more future problems.","['G05B15/02', 'G05B2219/2642']"
CN105008571B,"Ferritic stainless steel sheet exhibiting small increase in strength after thermal aging treatment, and method for producing same","This ferritic stainless steel sheet for which the increase in strength after a thermal aging treatment is small contains, in mass%, C in the amount of 0.020% or less, Cr in the amount of 10.0-25.0%, N in the amount of 0.020% or less, and Sn in the amount of 0.010-0.50%, and is characterized: by containing one or more types of Ti in the amount of 0.60% or less, Nb in the amount of 0.60% or less, V in the amount of 0.60% or less, and Zr in the amount of 0.60% or less, so as to satisfy formula (1); and in that the difference between the stress ([sigma]1 (N/mm2)) after a predistortion-imparting tensile deformation at 7.5% distortion and the upper-yield stress ([sigma]2 (N/mm2)) when stretched again after executing a thermal treatment at 200 DEG C for 30 minutes after the tensile deformation is 8 or less. (Ti/48+V/51+Zr/91+Nb/93)/(C/12+N/14) >= 1.0 ... (1)","['C21D8/005', 'C21D6/002', 'C21D8/0226', 'C21D8/0263', 'C22C38/00', 'C22C38/001', 'C22C38/002', 'C22C38/004', 'C22C38/005', 'C22C38/008', 'C22C38/02', 'C22C38/04', 'C22C38/06', 'C22C38/20', 'C22C38/22', 'C22C38/24', 'C22C38/26', 'C22C38/28', 'C22C38/32', 'C22C38/34', 'C22C38/42', 'C22C38/44', 'C22C38/46', 'C22C38/48', 'C22C38/50', 'C22C38/54', 'C22C38/58', 'C22C38/60']"
CN117173035A,Data processing method and device,"A data processing method is applied to the field of artificial intelligence, and comprises the following steps: acquiring a plurality of first images and random noise; the different first images are denoised images predicted by a denoising module in the diffusion model at different historical step sizes; and fusing the plurality of first images with the random noise to obtain a denoised image of the current step length. When the denoising method is used for predicting the denoised image, the denoised images predicted in different historical step sizes are fused, so that sampling errors can be reduced under the condition of same calculation consumption, and the sampling times are reduced.","['G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06T5/00', 'G06T5/50']"
CN117371543A,Enhanced soft measurement method based on time sequence diffusion probability model,"An enhanced soft measurement method based on a time sequence diffusion probability model belongs to the technical field of soft measurement modeling. Which comprises the following steps: (1) acquiring sample data of a dynamic process; (2) data set partitioning and preprocessing of time series data; (3) Establishing a time sequence diffusion probability model and generating an expansion sample; (4) establishing a three-phase flow process pressure variable prediction model; (5) model performance assessment. The invention provides an enhanced soft measurement method based on a time sequence diffusion probability model. According to the method, the LSTM unit and the one-dimensional convolution structure are fused in the noise prediction model, so that the time sequence characteristic and the space characteristic of dynamic data can be captured simultaneously, the dynamic data similar to an original sample can be generated, and the prediction precision of modeling of the small sample time sequence data is improved.","['G06N7/01', 'G06F18/213', 'G06F18/217', 'G06F18/29', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'Y02T90/00']"
CN117495714A,Face image restoration method and device based on diffusion generation priori and readable medium,"The invention discloses a face image restoration method, a device and a readable medium based on diffusion generation priori, relating to an image processing module, comprising the following steps: constructing a face image restoration model based on a pre-trained diffusion model, inputting a face image to be restored into a forward noise adding module to gradually increase noise, and obtaining a noise image; inputting the noise image into a reverse denoising module to gradually denoise, and generating a final restored face image; inputting the noise image of the t step and the time stamp of the t step into a noise predictor, and predicting to obtain the noise of the t step; in a forward noise adding module, combining the noise image of the t step and the noise input of the t step with a forward diffusion formula of fusion inversion to obtain a noise image of the t+1 step; in the reverse denoising module, zero threshold decomposition is carried out on the noise image in the t step, and the zero threshold decomposition and the noise in the t step are input into a reverse diffusion formula to obtain the noise image in the t-1 step, so that the problem that the restored image generated in the prior art is poor in authenticity and consistency is solved.","['G06T5/10', 'G06N3/0455', 'G06N3/0464', 'G06T5/50', 'G06T2207/20056', 'G06T2207/20084', 'G06T2207/20221']"
US20240161258A1,System and methods for tuning ai-generated images,"A computer-implemented is disclosed. The method includes: obtaining a first set of a plurality of images of products that are associated with a same product category; selecting a subset of the first set based on interaction data of customer interactions with a merchant's online storefront; and providing, to a deep learning generative model, the subset of the first set and a second set of training images depicting a first product for training a customized generative model associated with the first product.","['G06T7/0002', 'G06Q30/0201', 'G06T11/00', 'G06T7/70', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G06T2207/30196']"
GB2627345A,Super-resolution on text-to-image synthesis with GANS,"A method of generating a high-resolution image 975 from a low-resolution image 970 and a text description 945 thereof uses a text encoder 905 to convert the text description to a text embedding (i.e. converting the text into numerical vector form for subsequent processing). The text embedding is transformed to obtain a global vector 955 for the text description as a whole and a plurality of local vectors 950 corresponding to individual tokens (linguistic units, e.g. words or part thereof) in the description. A style vector 965 is generated by a mapping network 920 based upon the global vector, and optionally a noise vector 960, which enables an adaptive convolution filter to be generated based on the style vector. The resultant adaptive convolution filter is used to generate a high-resolution image corresponding to the low-resolution image, based upon the plurality of local vectors. The method achieves text-guided super-resolution text-to-image (TTI) synthesis of high-resolution images using a generative adversarial network (GAN) 925. Also described is an associated apparatus for generating high-resolution images from low-resolution images based on a style vector derived from a text description, and a method for training an image generation network.","['G06T3/4053', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/082', 'G06T11/00', 'G06T3/4046', 'G06T5/60', 'G06T2207/20084', 'G06T2211/441']"
US12334116B2,Image diffusion framework for text-guided video editing,"The invention provides a method for adapting a text-to-image (T2I) diffusion model for video editing by using spectral decomposition to achieve controlled spectral shifts in the model's weights. This adaptation involves maintaining constant singular vectors while selectively adjusting singular values in response to a text prompt. A spectral shift regularizer constrains adjustments, particularly limiting changes to larger singular values to ensure minimal deviation from the original model's structure. This approach allows efficient, prompt-driven video editing by modifying specific elements according to the prompt while preserving the original video context. By focusing on selective spectral adjustments, the method reduces adaptation time and computational demands, making it suitable for real-time and resource-sensitive applications, such as dynamic video editing for streaming services.","['G11B27/031', 'G06F40/40']"
US20240420389A1,Generating tile-able patterns from text,"Systems and methods for generating tile-able patterns from text include obtaining a text prompt and generating, by a generation prior model, a latent vector based on the text prompt, where the generation prior model is trained to output vectors within a distribution of tile-able patterns. An image generation model then generates an output image based on the latent vector. The output image comprises a tile-able pattern including an element from the text prompt.","['G06V10/764', 'G06T3/4038', 'G06T11/001', 'G06T11/20', 'G06T3/40', 'G06V10/774', 'G06V10/82', 'G06F40/40', 'G06T2200/24', 'G06T2200/32']"
US20240221178A1,Systems and methods for sports tracking using diffusion models,"A method for tracking one or more individuals during a sporting event, the method including: receiving, as an input, a geospatial data of a sporting event; receiving, as an input, labeled event data of the sporting event; performing multi-object tracking of one or more agents of the geospatial data to determine one or more vectors; inputting the labeled event data and one or more vectors into a diffusion model; and determining, using the diffusion model, one or more trajectory sequences for the one or more agents.","['G06N3/006', 'G06T7/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06T7/70', 'G06V20/44', 'G06T2207/30241']"
WO2024120206A1,"Unrestricted adversarial example generation method and apparatus, electronic device, and storage medium","Embodiments of the present application relate to the technical field of adversarial example generation, and provide an unrestricted adversarial example generation method and apparatus, an electronic device, and a storage medium. The method comprises: obtaining a denoised image at a current moment and a corresponding prediction image on the basis of a backward process of a diffusion model; generating disturbance between the prediction image and an adversarial example of the prediction image by an adversarial attack on the prediction image; and migrating the disturbance to the denoised image at the current moment, and denoising, by means of the backward process of the diffusion model, the denoised image migrated at the current moment until an unrestricted adversarial example is generated. The embodiments of the present application solves the problems in the related art that a generated unrestricted adversarial example has distorted shape and does not confirm to real distribution, and semantic information of a region for artificial discrimination is fuzzy and difficult to distinguish.","['G06T5/70', 'G06N3/04', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US20240346731A1,Live model prompting and real-time output of photoreal synthetic content,"Prompting a trained artificial intelligence (AI) model(s) to output photoreal synthetic content in real-time is described. In some examples, one or more AI models are trained using sequential video frames as training data to obtain one or more trained AI models configured to generate temporally-coherent output data. In an example process, user-provided prompt data representing a prompt provided by a user is received, output data representing synthetic content is generated using the trained AI model(s) based at least in part on the user-provided prompt data, and video content featuring the synthetic content is caused to be displayed on a display based at least in part on the output data. In some examples, the output data is provided to the trained AI model(s) as part of a feedback loop to generate further output data as part of a real-time, iterative prompting system.","['G06T13/40', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T13/205', 'G06T19/006', 'G10L15/26']"
CN117037179A,"Image generation method, device, equipment and storage medium thereof and model construction method, device and equipment thereof","The present disclosure provides an image generation method, apparatus, device, and storage medium for model construction; the training sample comprises an image sample, a prompt text, characters contained in the image sample and a character area where the characters are located; the method comprises the steps that a model respectively extracts text features of prompt texts, text features of texts contained in image samples and image features of images corresponding to text areas, fusion features obtained by fusing the text features and the image features, splice features obtained by splicing the text features and generate a predicted image, and the error between the predicted image and the image samples, the error between the images corresponding to the text areas in the predicted image and the images of the text areas in the image samples, and the error between the text features of the texts contained in the predicted image and the text features of the texts contained in the image samples are taken as optimization targets, so that the image generation model is trained. The model constructed by the method can stably generate the image with the characters.","['G06V30/1918', 'G06V30/148', 'G06V30/19147', 'Y02T10/40']"
WO2024133344A1,A method for providing a candidate biological sequence and related electronic device,"Disclosed is a method, performed by an electronic device, for providing a candidate biological sequence. The method comprises obtaining input data indicative of an input biological sequence. The method comprises determining the candidate biological sequence by applying a generative non-unidirectional model to the input data. The method comprises providing biological sequence data indicative of the candidate biological sequence.","['G16B40/30', 'G16B20/30', 'G16B30/00']"
WO2023239358A1,Systems and methods for image manipulation based on natural language manipulation instructions,"Provided are computer systems and methods for image manipulation based on natural language manipulation instructions. In particular, the present disclosure introduces an entirely new problem space of referring object manipulation (ROM). In ROM, a computer system aims to generate photo-realistic image edits regarding two textual descriptions: 1) a reference text referring to an object in the input image and 2) a target text describing how to manipulate the referred object. The successful ROM models described herein enable users to simply use natural language to manipulate images, removing the need for learning sophisticated image editing software.","['G06F3/04845', 'G06F3/04842', 'G06F3/167', 'G06N3/045', 'G06T11/60', 'G06F2203/0381', 'G06N3/084']"
US20240338746A1,Generative content based on user session signals,"An online system employs real-time and pre-generated images for recommendation. The system leverages generative machine-learning models, such as diffusion models, to generate images dynamically. The selection and creation of these images rely upon user data and session data, which are collected during a user's application session. These data are employed to generate a text prompt string, which directs the image generation process. For instances where real-time computation may be a resource constraint, the system utilizes pre-generated images linked to user-context clustersâdata set groupings related to user characteristics and session context. This method enables the system to present tailored recommendations to the user, making use of both dynamic generation and pre-existing image resources, thereby optimizing the balance between customization, computational resources, and latency.","['G06Q30/0631', 'G06Q30/0643']"
WO2024182144A1,Aspect ratio conversion for automated image generation,"Examples disclosed herein describe aspect ratio conversion techniques for automated image generation. An image generation request comprising a prompt is received from a user device. A processor-implemented automated image generator may generate a first image based on the prompt. The first image has a first aspect ratio. According to some examples, a region of interest is determined in the first image, based on a prompt alignment indicator for the region of interest. The first image is then processed to obtain a second image. The processing includes an automatic cropping operation directed at the region of interest. The second image has a second aspect ratio that is different from the first aspect ratio. The second image is caused to be presented on the user device.","['H04N7/0122', 'G06T3/40', 'G06T7/70', 'G06T9/00', 'G06V10/25', 'G06V10/32', 'G06V10/82', 'G06V10/945', 'G06T2207/20084', 'G06T2207/20132', 'G06V2201/07']"
WO2024127311A1,Machine learning models for dental restoration design generation,"Systems and methods are disclosed for generating a dental restoration tooth design. The method involves receiving a three-dimensional (3D) pre-restoration tooth representation and providing it as input to a trained encoder of a reconstruction autoencoder. The trained encoder outputs a lower- dimensional latent space representation of the 3D pre-restoration tooth. The latent space representation is then modified, and the modified representation is provided as input to a trained decoder of the reconstruction autoencoder. Using the modified latent space representation, the trained decoder reconstructs a 3D tooth representation that defines a post-restoration version of the 3D pre-restoration tooth. Finally, at least one oral care appliance is generated using the reconstructed 3D tooth representation. These systems and method enable efficient and accurate generation of dental restoration tooth designs, improving the overall oral care process.","['G06T17/00', 'A61C13/0004', 'A61C7/002', 'G06F18/213', 'G06T2210/41', 'G06V2201/03']"
US12197496B1,Searching for images using generated images,"In implementations of systems for searching for images using generated images, a computing device implements a search system to receive a natural language search query for digital images included in a digital image repository. The search system generates a set of digital images using a machine learning model based on the natural language search query. The machine learning model is trained on training data to generate digital images based on natural language inputs. The search system performs an image-based search for digital images included in the digital image repository using the set of digital images. An indication of the search result is generated for display in a user interface based on performing the image-based search.","['G06F16/55', 'G06F16/532', 'G06F16/538', 'G06F40/40']"
WO2024207872A9,"Image processing method, image processing apparatus, electronic device, and computer readable storage medium","The present application provides an image processing method and apparatus, an electronic device, and a computer readable storage medium. The method comprises: obtaining a prompt sentence to be processed; obtaining a textual feature of said prompt sentence, and mapping the textual feature to a generativity indicator and a description type of said prompt sentence; in response to the generativity indicator being greater than an indicator threshold, the description type representing that said prompt sentence comprise no verb, and said prompt sentence comprising a plurality of clauses, obtaining similar images respectively corresponding to the plurality of clauses; determining an image difference degree between said similar images; and in response to the image difference degree being greater than an image difference degree threshold, taking said similar images as matching images of the corresponding clauses.","['G06V30/1918', 'G06T11/60', 'G06F16/51', 'G06F16/535', 'G06F16/583', 'G06F16/5846', 'G06F40/284', 'G06F40/30', 'G06T5/70', 'G06V10/74', 'G06V10/761', 'G06V10/80', 'G06V10/82', 'G06V30/18', 'G06V30/19093', 'G06V30/19173', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084']"
CN109643286A,System and method for obfuscating circuit designs,"Systems and methods for obfuscating a circuit design are described. One of the methods includes receiving the circuit design from a user computing device. The circuit design includes a plurality of circuit components. The method also includes obfuscating each of the circuit components by transforming layout features associated with the circuit design into a generic layout feature representation. The generic layout feature representation does not include a scaled representation of the layout features. The method also includes generating a visual representation of the obfuscated design. Each of the obfuscated designs has an input port and an output port. The method also includes enabling placement and routing of the obfuscated design between the input port and the output port of the obfuscated design. The method includes generating a garbled integrated circuit design having a main input port, a main output port, the garbled design, and the routing between the garbled designs.","['G06F30/394', 'G06F30/398', 'G06F30/30', 'G06F30/33', 'G06F30/3308', 'G06F30/3323', 'G06F30/367', 'G06F30/39', 'G06F30/392', 'H01L23/573', 'G06F2119/18']"
CN116823994A,"Image generation and model training method, device, equipment and storage medium","The disclosure relates to an image generation method, an image training method, an image generation device, an image training device and a storage medium. The method and the device generate the target image through the plurality of image generation elements, so that the plurality of image elements of the target image comprise a plurality of target elements, the plurality of target elements are in one-to-one correspondence with the plurality of image generation elements, and the similarity between the target elements with the corresponding relationship and the image generation elements is larger than or equal to a preset value. Because the number of the image generating elements is large, and the combination modes among different image generating elements are flexible and various, a large number of different target images can be generated by combining different image generating elements, and the diversity of the target images is greatly improved.","['G06T11/206', 'G06N20/00', 'G06V10/761', 'G06V10/774', 'G06T2207/20081']"
CN118366011B,"Model training, underground cable pipeline defect identification methods, products and equipment","The application discloses a model training method, an underground cable pipeline defect identification method, a product and equipment, wherein a sample image and a first label corresponding to the sample image are acquired; extracting first potential features of the sample image and extracting second potential features of the first tag; inputting the first potential features and the second potential features into a pre-trained layering model for layering to obtain a target level; determining a target image adjustment mode in a plurality of image adjustment modes respectively corresponding to a plurality of preset levels based on the target level so as to adjust a sample image and obtain an adjustment image; generating corresponding text description based on the adjustment image, and combining the text description with the first label to obtain a synthetic text; generating a target image corresponding to the synthesized text; and training the target detection model by utilizing the target image and the sample image to obtain the underground cable duct defect identification model, and improving the detection precision of the underground cable duct defect identification model obtained by training.","['G06V10/82', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/25', 'G06V10/454', 'G06V10/761', 'G06V10/774', 'G06V2201/07']"
WO2024263885A1,Diffusion plug-in for conditioned text-to-image generation,"Methods and systems for performing image generation are disclosed herein. The method can include receiving, by a processor, a text prompt for generating an image using a diffusion model, the diffusion model including an encoder-decoder network and receiving, by the processor, a multiscale feature vector from a plug-in network, the multiscale feature vector modeling a condition image. The method can also include applying, by the processor, the multiscale feature vector to one or more levels of an encoder of the encoder-decoder network, performing, by the processor, image generation with the diffusion model based on the text prompt and the multiscale feature vector, and outputting, by the processor, a generated image from the diffusion model.","['G06N3/0464', 'G06N3/0455', 'G06N3/0475', 'G06N3/098', 'G06T11/00']"
CN117615200A,"Video generation method, device, computer readable storage medium and electronic equipment","The application relates to a video generation method, a device, a computer readable storage medium and an electronic apparatus, wherein the video generation method comprises the following steps: acquiring a target object image, a target description text and a target action video; encoding the target object image and the target description text into a target image feature vector and a target text feature vector respectively; performing multi-step noise adding treatment on the target image feature vector according to the target text feature vector to obtain a diffusion reverse track; optimizing the target unconditional embedding according to the diffusion reverse track to obtain optimized unconditional embedding; and generating a video of the target object for executing the target action by utilizing a video generation model with time sequence sensing and gesture injection functions according to the noise vector after the noise adding processing in the last step, the unconditional embedding after the optimization, the target description text and the skeleton point data of the video frame in the target action video, so that accurate original image reconstruction and customization of the action in the video can be realized, and the user experience is improved.","['H04N21/431', 'G06T11/60', 'G06V10/774', 'G06V10/86', 'H04N21/44008']"
US20240402661A1,Machine learning systems and methods for building automation and security systems,"Systems and methods are disclosed relating to machine learning systems and methods for building automation and security systems. A system can include one or more processors configured to detect a condition regarding an item of equipment; generate, using at least one machine learning model and based on at least one of the condition or an identifier of the item of equipment, an output corresponding to the condition and to the item of equipment, the at least one machine learning model configured using training data comprising unstructured data regarding items of equipment; and present, using at least one of a display device and an audio output device, the output. The one or more processors can generate a user interface for presenting the output according to at least one of an identifier of a user and historical interactions of the user with the user interface or the item of equipment.","['G05B13/027', 'G05B15/02']"
US20250157008A1,Image Generation with Minimal Denoising Diffusion Steps,"Provided is a one-step text-to-image generative model, which represents a fusion of GAN and diffusion model elements. In particular, despite the promising outcomes of prior diffusion GAN hybrid models, achieving one-step sampling and extending their utility to text-to-image generation remains a complex challenge. The present disclosure provides a number of innovative techniques to enhance diffusion GAN models, resulting in an ultra-fast text-to-image model capable of producing high-quality images in a single sampling step.","['G06T5/60', 'G06T11/00', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN116910572B,Training method and device for three-dimensional content generation model based on pre-training language model,"The invention discloses a training method and a training device for a three-dimensional content generation model based on a pre-training language model, which are applied to the technical field of three-dimensional content generation and comprise the following steps: acquiring three-dimensional content and three-dimensional content description of the three-dimensional content from a first training data set; the three-dimensional content description comprises text descriptions of a plurality of attributes corresponding to the three-dimensional content; randomly generating noise to obtain first noise, and adding the first noise to the three-dimensional content to obtain first noise point cloud; training a first diffusion model by utilizing the three-dimensional content description, the first noise point cloud and the diffusion time to obtain a three-dimensional content generation model; the first diffusion model includes a plurality of condition descriptor extraction structures, each condition descriptor extraction structure corresponding to a textual description of an attribute for extracting a descriptor of the textual description of the attribute. The performance of the three-dimensional content generation model can be improved, and the accuracy of three-dimensional content generation is further improved.","['G06F18/214', 'G06F40/205', 'G06T19/20', 'Y02D10/00']"
US20250095224A1,Generative virtual backgrounds for video conferencing,"A video conferencing system may receive, via a user interface of a video conferencing application, a user prompt for a virtual background in a video conference. A video conferencing system may generate a first prompt from the user prompt, the first prompt including an instruction to create a second prompt based on the user prompt. A video conferencing system may receive the second prompt from a text-to-text language model. A video conferencing system may provide the second prompt as an input to an image generation model. A video conferencing system may receive a generated image from the image generation model. A video conferencing system may apply the generated image as the virtual background.","['G06T11/00', 'G06F40/40', 'G06T2200/24']"
US20240345573A1,Building system with generative ai-based analysis and contextual insight generation,"A method for servicing building equipment using generative artificial intelligence models includes creating a set of analysis components that describe expected behaviors of the building equipment, combining multiple analysis components that satisfy a similarity criterion to form a concise set of analysis components, prompting a generative artificial intelligence model using the concise set of analysis components, and performing an automated action for servicing the building equipment based on the response of the generative artificial intelligence model.","['G05B23/0281', 'G05B15/02', 'G05B23/0283']"
US12354244B2,Systems and methods for reversible transformations using diffusion models,"Embodiments described herein provide systems and methods for image editing, a first copy and a second copy of an input image are generated; noise is iteratively added to the first copy and the second copy by: updating the first copy based on a first inverted output of a denoising diffusion model (DDM) based on the second copy and a first caption and updating the second copy based on a second inverted output of the DDM based on the first copy and the first caption. A resultant noised image is iteratively denoised by a reverse process using the DDM conditioned on a second caption, thereby producing a final image.","['G06T5/60', 'G06T5/70', 'G06T11/60', 'G06T5/30', 'G06T5/50', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20216']"
US20250005303A1,Generative summaries for search results,"At least selectively utilizing a large language model (LLM) in generating a natural language (NL) based summary to be rendered in response to a query. In some implementations, in generating the NL based summary additional content is processed using the LLM. The additional content is in addition to query content of the query itself and, in generating the NL based summary, can be processed using the LLM and along with the query contentâor even independent of the query content. Processing the additional content can, for example, mitigate occurrences of the NL based summary including inaccuracies and/or can mitigate occurrences of the NL based summary being over-specified and/or under-specified.","['G06F40/40', 'G06F16/3328']"
US11922289B1,Machine learning-based systems and methods for on-demand generation of anonymized and privacy-enabled synthetic datasets,"A system and method for generating synthetic datasets includes receiving, via an application programming interface (API) of a remote generative database service, a generative database query for obtaining synthetic data samples statistically representative of a sensitive dataset, searching a generative model data structure comprising a plurality of generative model nexuses based on a generative model election request derived from the generative database query, wherein the searching returns a generative model for fulfilling the generative database query, generating a synthetic dataset using the generative model returned from the searching based on a plurality of generative query parameters extracted from the generative database query, and returning the synthetic dataset as a result to the generative database query.","['G06N3/0455', 'G06F16/24578', 'G06F16/2471', 'G06N3/0475', 'G06N3/094', 'G06N3/0985', 'G06N3/045']"
KR102665707B1,Face image conversion method using diffusion model,"According to one embodiment of the present disclosure, disclosed is a method for training a neural network model for converting an image, performed by one or more processors of a computing device. The method may comprise: a step of receiving a target image and an original image; a step of removing a part or all of a noise regarding first image information comprising noise by utilizing a neural network model, and obtaining second image information; a step of comparing the second image information and the target image to calculate a feature loss function; a step of comparing the second image information and the original image to calculate a structure loss function; and a step of training the neural network model based on at least one among the feature loss function or the structure loss function.","['G06T3/10', 'G06N3/08', 'G06T3/00', 'G06T3/04', 'G06T3/40', 'G06T3/4046', 'G06T5/00', 'G06T5/20', 'G06T5/70', 'G06T7/10', 'G06V10/74', 'G06V10/761', 'G06V40/13', 'G06T2207/20081', 'G06T2207/20084']"
CN117376484B,Electronic license anti-counterfeiting oriented generation type steganography method,"The invention provides a generation type steganography method for electronic license anti-counterfeiting, which specifically comprises the following steps: when a message is sent, the secret message is encoded, a pre-trained encoder is input to obtain potential noise, and the potential noise is input to a pre-trained denoising diffusion implicit model to obtain a dense image; and/or when receiving the message, restoring the image containing the secret to the potential noise by utilizing the inverse sampling process of the pre-trained denoising diffusion implicit model, inputting the restored potential noise into a pre-trained decoder, and restoring the potential noise to the secret message according to the coding mode. Compared with the traditional steganography method and the generation type steganography method, the steganography method provided by the invention not only has higher safety and is difficult to detect and analyze, but also can obtain higher image quality, and improves the message capacity of the confidential pictures and the accuracy of extracting the confidential messages.","['H04N1/32347', 'G06N3/0455', 'G06N3/08', 'Y02T10/40']"
WO2024182438A1,Automatic image generation in an interaction system,"Examples disclosed herein describe techniques related to automated image generation in an interaction system. An image generation request is received from a first user device associated with a first user of an interaction system. The image generation request comprises a text prompt. In response to receiving the image generation request, an image is automatically generated by an automated text-to-image generator, based on the text prompt. The image is caused to be presented on the first user device. An indication of user input to select the image is received from the user device. In response to receiving the indication of the user input to select the image, the image is associated with the first user within the interaction system, and a second user of the interaction system is enabled to be presented with the image.","['H04L51/10', 'G06T11/60', 'G06F3/0482', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06T2200/24', 'H04L51/52']"
WO2025123922A1,Video generation method and parameter generation model training method,"Provided in the embodiments of the present disclosure are a video generation method and a parameter generation model training method. The video generation method comprises: acquiring speech to be processed; inputting an emotion feature of a target object and said speech into a parameter generation model, so as to obtain an expression parameter, wherein the expression parameter is used for describing facial motion information of the target object under the influence of the emotion feature, the parameter generation model is obtained by means of performing training on the basis of a sample emotion feature, sample speech and an expression parameter label that corresponds to the sample speech, and the sample emotion feature and the sample speech are obtained on the basis of a sample video; and inputting an object image of the target object and the expression parameter into a video generation model, so as to obtain a target video of the target object. By means of generating an expression parameter on the basis of an emotion feature and speech to be processed, and further generating a target video on the basis of the expression parameter, diversified emotion information is fused into the target video while ensuring the synchronization between speech and expression in the target video, thereby improving the accuracy and vividness of the target video.","['G10L21/10', 'G06T13/205', 'G06T13/40', 'G10L25/63', 'G06T2200/04']"
US20240296607A1,Utilizing machine learning models to generate image editing directions in a latent space,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for utilizing machine learning models to generate modified digital images. In particular, in some embodiments, the disclosed systems generate image editing directions between textual identifiers of two visual features utilizing a language prediction machine learning model and a text encoder. In some embodiments, the disclosed systems generated an inversion of a digital image utilizing a regularized inversion model to guide forward diffusion of the digital image. In some embodiments, the disclosed systems utilize cross-attention guidance to preserve structural details of a source digital image when generating a modified digital image with a diffusion neural network.","['G06V20/70', 'G06F40/56', 'G06T1/0021', 'G06T11/60', 'G06T5/70', 'G06V10/44', 'G06V10/82', 'G06T2207/20182']"
CN109919347A,"Road conditions generation method, relevant apparatus and equipment","The invention discloses a kind of road conditions generation methods, comprising: obtains current driving condition informationï¼Road status messages are generated according to the corresponding relationship from transinformation and road condition and road section capacity information between each road condition extracted in history road condition data for the current driving condition informationï¼Export the road status messages.The invention also discloses a kind of road conditions generating means and road conditions generating devices, the road conditions generation method or road conditions determination method for solving the prior art are influenced by abnormal flow speeds, error can be brought to the calculating or judgement of road conditions, cause the technical problem of road conditions inaccuracy.","['G08G1/0133', 'G08G1/0141', 'G06N7/01', 'G06Q10/04', 'G07C5/08', 'G08G1/0112', 'G08G1/012', 'G08G1/0129', 'G08G1/09675', 'G08G1/096775', 'G06Q50/40']"
WO2022062590A1,"Image recognition method and apparatus, device, storage medium and program","Disclosed are an image recognition method and apparatus, an electronic device, a computer storage medium and a computer program. The image recognition method comprises: acquiring a plurality of medical images to be subjected to recognition; respectively extracting a style characteristic representation of each of said medical images; and performing classification processing on the style characteristic representations of said plurality of medical images, so as to obtain a scanning image category of each of said medical images.","['G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06V10/267', 'G06V10/44', 'G06V10/56']"
CN116110099A,Head portrait generating method and head portrait replacing method,"The disclosure provides a head portrait generation method and a head portrait replacement method, and relates to the technical field of image processing, in particular to the technical fields of artificial intelligence, deep learning, cloud computing and the like. The specific implementation scheme is as follows: determining first text description information according to a face image of a target face; the first text description information is at least used for representing the face characteristics of the face image; determining a first image vector of a face image; generating a target species head portrait corresponding to a target face according to the first image vector and the first text description information by utilizing a pre-trained text graph model corresponding to the target species; the target species head portrait comprises facial features corresponding to the facial features. According to the technology disclosed by the disclosure, the cross-species head portrait special for the target face can be generated by migrating the face features of the target face to the target species.","['G06V40/168', 'G06N3/08', 'G06V10/82']"
CN117853604A,"Image generation method, service providing method, device, medium, and program product","The embodiment of the invention provides an image generation method, a service providing method, equipment, a medium and a program product, wherein the method comprises the following steps: a reference image corresponding to the image generation task is acquired, and a first feature extracted from the reference features and corresponding to the image generation task is input into the generation model. The first feature may comprise an image feature of the reference image and/or an identity feature of a target object contained in the reference image. Further, the target image may be generated using the output result of the generation model. It can be seen that the second feature described above is a control condition for controlling the image generation direction, which is introduced in the image generation process, so that the generation of an image can be finely controlled. And when different image generating tasks have different control conditions, different image generating tasks can be realized by means of one generating model, so that the universality of the generating model is improved.","['G06T11/00', 'G06N3/0455', 'G06N3/0464', 'G06V10/806', 'G06V40/168']"
CN116168269A,"Training method and system for palm print image generation model, and palm print image generation method and system","The specification provides a training method and system for a palm print image generation model, and a palm print image generation method and system, wherein the training method for the palm print image generation model comprises the following steps: based on a noise generation model, taking a first geometric palm print image sample as a guide condition, and carrying out noise adding treatment on a first real palm print image sample to obtain a corresponding noise sample; taking the first geometric palm print image sample as a guide condition, and performing inverse operation on the noise sample through an initial model to obtain a target palm print image and corresponding prediction noise; determining loss values of the tag and the predicted noise by taking the noise sample as the tag; and training the initial model based on the loss value to obtain the palm print image generation model, wherein the first real palm print image sample is any sample in a real palm print sample set, and the first geometric palm print image sample and the first real palm print image sample are paired and marked with the same user identity information.","['G06V10/774', 'G06V40/12', 'Y02T90/00']"
CN117409140A,Controllable layout 3D scene representation and generation method based on large language model,"The invention discloses a controllable Layout three-dimensional scene representation and generation method based on a large language model, which uses 3D Layout under text and image prompt conditions as the space state representation of a three-dimensional multi-object scene, performs three-dimensional space state extraction on a specified text or image through the large language model and a 3D perception model, generates 3D Layout space state representation by using the extracted category and space position state information, and further generates a vivid three-dimensional real scene on the basis of the generated 3D Layout by using a nerve radiation field and a diffusion model, thereby realizing high-fidelity, diversified and highly controllable three-dimensional scene generation. The method breaks through the thought of conventional manual 3D scene modeling, does not depend on a specific large language model and a diffusion generation model, can be applied to complex and diverse three-dimensional scene generation, including but not limited to multi-object combined scenes, indoor scenes, outdoor scenes and the like, and has the advantages of accurate generated scene geometric shape, high rendering quality, simplicity, high efficiency and strong controllability.","['G06T17/00', 'G06F40/30', 'G06N3/0499', 'G06N3/08', 'G06T15/02', 'G06V10/56', 'G06V10/764']"
CN119941509A,A generative image prior method for scene text super-resolution,"The invention discloses a scene text image super-resolution method for generating an image priori, which comprises two stages, wherein a first stage is used for constructing a multi-mode-based diffusion model, a GPT model is used for obtaining specific text information from a low-resolution text image to generate a high-resolution image priori, a second stage is used for constructing a ITPGDM model, the high-resolution text image is reconstructed through the high-resolution image priori and a text recognition priori, the ITPGDM model comprises a PSAB module and a CFAB module, the PSAB module is used for aligning different priori information, the CFAB module is used for refining character-level features, the ITPGDM model represents a scene text image super-resolution diffusion model based on image and text priori guidance, the PSAB module represents a priori semantic alignment module, and the CFAB module represents a character attention module. The method fully utilizes the strong advantages of the diffusion model and the GPT model, and uses the multi-prior semantic alignment module and the character attention module to enhance the super-resolution capability of the scene text image.",[]
US20240311652A1,Markup Language for Generative Model Prompting,Systems and methods for prompt generation for generative models can include utilizing a specialized markup language. A markup language transform can be utilized to augment user input data to generate a prompt that includes structure and/or wording that facilitates the generation of a generative output that reflects a user's intent. The systems and methods can leverage the specialized markup language and/or an integrated development environment interface to inform a user of the prompt parts and provide editing options.,"['G06N3/10', 'G06N3/045', 'G06N3/0475', 'G06N3/08']"
US12086716B1,"Method for constructing multimodality-based medical large model, and related device thereof","A method for constructing a multimodality-based medical large model, and a related device thereof are provided. The medical large model includes a multimodal transformer T, a prompt manager M, a dialogue engine L, a task controller H, and a multimodal foundation (MMF) that includes at least one medical foundation model (MFM). Five stages, namely modal analysis, model allocation, downstream task result feedback, modal transformation normalization, and response generation are designed.","['G16H50/70', 'G06N3/08', 'G16H50/20', 'Y02D10/00']"
WO2025054697A1,Composable adaptation models for defining parameters of generative model output,"A computer system maintains adaptation models (e.g., low-rank adaptation (LoRA) models), where each adaptation model includes a set of weights configured to modify parameters of a generative model (e.g., a large-language model) to cause the generative model to generate output (e.g., text) having a corresponding property. The computer system presents a set of manipulable user-interface controls that allow configuration of properties of model-generated output. Output of the generative model is modified using adaptation models that are selected based on a state of the user-interface controls as manipulated. A preview of generative model output may be provided that corresponds to the current state of the user-interface controls during presentation and manipulation thereof.","['G06F3/0484', 'H04L51/02', 'G06F3/0482', 'G06F3/04847', 'G06F40/30', 'G06F40/56', 'G06N20/00', 'G06N3/045', 'G06N3/047']"
CN118377933B,Optimization method of text video retrieval based on text-generated image technology,"The invention provides a text video retrieval optimization method based on text generated image technology, which generates an image model by using Stable diffration text, and generating images of the text information in the data set, and adding the generated image information as a video frame into the training set, so that the data scale is effectively expanded. The invention also considers that the key frame information is reversely generated into text information, and further enriches the text data set. Based on the expanded data set, the invention designs a new loss function, comprehensively considers the fine granularity and coarse granularity characteristics of the video, optimizes the training process of the text video retrieval model, and improves the retrieval effect. The invention can effectively solve the problems of data deficiency, insufficient model training and the like in the existing text video retrieval research by using the Stable diffration driven data enhancement and optimized loss function design, and provides a new technical support for multimedia content analysis and retrieval application.","['G06F16/7844', 'G06V10/761', 'G06V10/80', 'G06V20/40', 'G06V20/635', 'Y02T10/40']"
WO2024118198A1,Automated generation of data visualizations and infographics using large language models and diffusion models,"Systems and methods are provided for generating visualization data associated with raw data using a machine learning model. For example, the machine learning model may automatically generate a set of candidate analytics and/or a scenario for visualizing the raw data based on summary data. Given the summary data and answers to prompts for visualizing data, the generated candidate analytics may reflect a context of the raw data as intended by the user. A visualization code scaffold according to a visualization specification may be used to generate programmatic output that corresponds to the candidate analytics, which may thus be used to generate a visualization accordingly. In some examples, an infographic may further be generated based on the visualization and a prompt using a diffusion model.","['G06F16/26', 'G06N20/00', 'G06N3/0475', 'G06N3/08']"
US20240185490A1,Automated generation of data visualizations and infographics using large language models and diffusion models,"Systems and methods are provided for generating visualization data associated with raw data using a machine learning model. For example, the machine learning model may automatically generate a set of candidate analytics and/or a scenario for visualizing the raw data based on summary data. Given the summary data and answers to prompts for visualizing data, the generated candidate analytics may reflect a context of the raw data as intended by the user. A visualization code scaffold according to a visualization specification may be used to generate programmatic output that corresponds to the candidate analytics, which may thus be used to generate a visualization accordingly. In some examples, an infographic may further be generated based on the visualization and a prompt using a diffusion model.","['G06T11/206', 'G06F40/40', 'G06N20/00', 'G06N20/10']"
CN119169127A,A system for generating intangible cultural heritage enamel images based on large model fine-tuning technology,"The invention provides an enamel color non-genetic picture generation system based on a large model fine tuning technology, and relates to the technical field of picture generation. The enamel color non-genetic picture generation system based on the large model fine tuning technology comprises an image data collection module, a LORA large model fine tuning module and a Stable dispersion module, wherein the image data collection module is connected with data cleaning, the data cleaning module is connected with label labels, the label labels are connected with data enhancement, the data enhancement is connected with model learning, the model learning is connected with model evaluation, the LORA large model fine tuning module and the Stable dispersion module are connected with AIGC large model generation pictures, and the model learning comprises batch size, training wheel number and normalization parameters. A small model suitable for enamel color is trained by utilizing the lora large model fine tuning technology, so that high-quality enamel color pictures can be accurately generated.","['G06T11/001', 'G06T5/70', 'G06T5/90', 'G06V10/764', 'G06V10/774', 'G06T2207/10024', 'Y02T10/40']"
US20240161250A1,Techniques for denoising diffusion using an ensemble of expert denoisers,"Techniques are disclosed herein for generating a content item. The techniques include performing one or more first denoising operations based on an input and a first machine learning model to generate a first content item, and performing one or more second denoising operations based on the input, the first content item, and a second machine learning model to generate a second content item, where the first machine learning model is trained to denoise content items having an amount of corruption within a first corruption range, the second machine learning model is trained to denoise content items having an amount of corruption within a second corruption range, and the second corruption range is lower than the first corruption range.","['G06T5/002', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN116051683B,"A remote sensing image generation method, storage medium and device based on ad hoc style","The invention relates to the field of remote sensing image generation, and discloses a remote sensing image generation method, a storage medium and equipment based on style self-organization. Including creating initial mask data. And acquiring preset control parameters. And inputting the initial mask data and the control parameters into a remote sensing sample generator to generate a target remote sensing image. When the initial mask data is created, the method can adaptively design a plurality of configuration parameters, and further quickly create the initial mask data corresponding to various scenes. To generate a corresponding target remote sensing image. Thus, a large number of remote sensing image samples of different scenes can be correspondingly generated. To adapt to training of different deep learning network models. Meanwhile, the cost of the generated remote sensing image sample is lower because the generation of the remote sensing image sample does not need to consume manpower to annotate the cost. In addition, the remote sensing sample generator can be controlled by the target iteration times, so that the corresponding target remote sensing image can be generated more quickly.","['G06T11/60', 'G06N3/08', 'G06T3/04', 'G06T5/50', 'G06T2207/10032', 'G06T2207/20081', 'G06T2207/20084']"
CN117152285A,"A virtual human generation method, device, equipment and medium based on audio control","The invention discloses a virtual person generating method, a device, equipment and a medium based on audio control, wherein the method comprises the following steps: acquiring an input image, and performing image coding on the input image to acquire a hidden layer vector; noise is added to the hidden layer vector based on Gaussian distribution noise, and a noise added image is obtained; acquiring a visual image, and extracting features of the visual image to acquire visual features; the method comprises the steps of obtaining input audio, and carrying out feature extraction and mask processing on the input audio to obtain mask audio features; carrying out emotion recognition on the input image or the input audio to obtain emotion characteristics; and carrying out inverse denoising and image decoding on the noisy image based on the visual features, the mask audio features and the emotion features to obtain a target image of the virtual person. The invention can effectively solve the limitation that the existing virtual person generation method is only limited to facial modeling, efficiently realizes virtual person generation based on audio control, and can be widely applied to the technical field of image processing.","['G10L25/63', 'G06T11/00', 'G06T7/40', 'G06T9/00', 'G10L25/03', 'G10L25/57', 'Y02D10/00']"
CN117036386A,Cervical MRI image self-supervision segmentation method for generating data by using diffusion model,"The invention discloses a cervical MRI image self-supervision segmentation method for generating data by using a diffusion model. The method comprises the steps of cervical vertebra MRI slice screening, super-resolution reconstruction based on a diffusion model and other image preprocessing; in order to solve the problems of insufficient training data amount and lack of variability of the depth segmentation model, an improved diffusion model is used for generating a high-quality MRI image; finally, a self-supervision method is used for combining a real image and a generated image, the problem of insufficient label quantity is solved, an Att-UNet network of an Encoder-Decoder structure is constructed for extracting relevant characteristics of input data, multi-scale consistency output is used for measuring loss, and finally, more accurate vertebral body and intervertebral disc segmentation results are obtained. The invention combines MRI image generation based on diffusion model with self-supervision segmentation, effectively expands the sample number, improves model robustness and segmentation precision, and provides more accurate reference information for clinical cervical vertebra disease diagnosis.","['G06T7/11', 'G06N3/0464', 'G06N3/09', 'G06T3/4046', 'G06T3/4053', 'G06T7/0012', 'G06V10/761', 'G06V10/774', 'G06V10/82', 'G16H30/20', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30012']"
CN117035049A,"Agent learning method, device, equipment and storage medium","The present invention relates to the field of machine learning technologies, and in particular, to an agent learning method, apparatus, device, and storage medium. The method comprises the following steps: acquiring an initial multi-agent and acquiring a training data set corresponding to the initial multi-agent, wherein the initial multi-agent comprises at least one initial agent; for each initial agent: constructing a denoising strategy corresponding to the initial intelligent agent based on the performance of the initial intelligent agent and the diffusion model; based on the denoising strategy corresponding to each initial agent, synchronously training each initial agent by using a training data set, and obtaining a target multi-agent after training. The method is used for solving the defects of low algorithm performance caused by poor expression capability of an offline multi-agent reinforcement learning algorithm based on conservative estimation and dependence on a large number of training samples in the prior art.","['G06N3/092', 'G06N20/00']"
CN117058479B,Diffusion model design method and system for removing anti-noise,"The invention provides a diffusion model design method and a diffusion model design system for removing anti-noise, which comprise the steps of obtaining an original image, carrying out image augmentation through a preset diffusion model, carrying out construction of an anti-noise sample through a preset attack model and a defense model, training the preset diffusion model based on the original image, the augmented image and part of the anti-noise sample of the augmented image as training data, adding an anti-training mode in the training process of the preset diffusion model to generate a final diffusion model, and carrying out identification removal on Gaussian noise and the anti-noise based on the final diffusion model. The method solves the problem that the existing countermeasure model is poor in noise removal effect.","['G06V10/774', 'G06N3/094', 'G06V10/30', 'G06V10/764', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN117522694A,An image super-resolution reconstruction method and system based on diffusion model,"The invention discloses an image super-resolution reconstruction method based on a diffusion model, and relates to the technical field of computer vision. Comprising acquiring a pair-wise dataset comprising both a high resolution image and a corresponding low resolution image; iteratively training a latent model on the paired data sets, adding a kernel-based attention module to the noise prediction network to fix the latent model, and simultaneously training a diffusion model in a latent space; and inputting the low-image-quality image into the trained potential diffusion model to obtain a corresponding super-resolution generated image. The invention makes the data set based on the degradation characteristic of the high-quality image to the low-quality image, improves the noise prediction network of the diffusion model and carries out iterative training in the potential space, so that the training speed is faster and the effect is better.","['G06T3/4053', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06T3/4046']"
CN117173018A,Single image super-resolution method based on conditional diffusion model,"The invention discloses a single image super-resolution method based on a conditional diffusion model, which comprises the steps of obtaining an image sample, performing downsampling to generate a low-resolution image, performing upsampling on the low-resolution image to generate a noise image, and denoising to obtain a corresponding super-resolution image, so as to obtain a training sample; according to actual needs, a conditional diffusion model is built, a super-resolution image corresponding to a noise image in a training sample is used as Gaussian representation of time T, the noise image is used as an initial noise image, a corresponding image sample is used as expected output, the conditional diffusion model is trained, mutual information between input and output is maximized during training, when super-resolution image generation is needed, a low-resolution image is up-sampled to obtain the noise image and denoised to obtain a corresponding super-resolution image, the trained conditional diffusion model is input, and the super-resolution image is denoised according to the reverse sequence of a diffusion process, so that the corresponding super-resolution image is generated. The invention can improve the quality of the output image.",[]
CN117237371A,Gland segmentation method in colon histology images based on instance-aware diffusion model,"The invention discloses a colon histological image gland segmentation method based on an example perception diffusion model, and belongs to the technical field of colon histological image gland segmentation. Comprises the steps of obtaining a colon histological image to be segmented; inputting a colon histological image to be segmented into a preset example perception diffusion model for processing so as to obtain a gland segmentation result; the method specifically comprises the following steps: respectively inputting the colon histological image to be segmented into a trained image encoder and an FPN network to obtain original image features and multi-scale features; fusing the original image features and Gaussian noise to generate noise image features, inputting the noise image features and the original image features into a segmentation network, obtaining predicted glandular instance features and filtering; and obtaining a gland example segmentation result according to the multi-scale characteristics and the filtered gland example characteristics. The method can accurately detect the target, display better segmentation details and solve the problems of inaccurate target position identification and erroneous classification of background tissues.",['Y02P90/30']
CN117894085A,Diffusion model-based face identity privacy protection method and system for antagonism,"The invention provides a face identity privacy protection method and system based on a diffusion model. The method for solving the problems of the invention is as follows: step 1: preprocessing data; step 2: constructing an information extractor; step 3: constructing a face generation network based on a conditional diffusion model; step 4: constructing a face image to generate a loss function; step 5: after preprocessing the data set in the step 1, inputting the data set into the information extractor constructed in the step 2, and combining the face generation network in the step 3 and the face image generation loss function in the step 4 to complete training together, and testing. The invention takes the extracted non-identity information and the agent identity information extracted by the residual network as conditions, replaces the original identity with the agent identity through the diffusion model and the transducer and generates a brand new face image, so that the result image is similar to the original image as far as possible in vision, but the identity in the characteristic space becomes the identity of the agent face, thereby realizing privacy protection of the face.","['G06V40/53', 'G06F21/6245', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06N3/0985', 'G06V10/454', 'G06V10/806', 'G06V10/82', 'G06V40/168']"
CN117974450B,"Image super-resolution method, system and medium based on gradient optimization diffusion model","The invention discloses an image super-resolution method, system and medium based on a gradient optimization diffusion model, wherein the method comprises the following steps: projecting the pixel space to a low-dimensional hidden space, and establishing a denoising reconstruction process of a conditional diffusion model in the hidden space; calculating the consistency constraint of the denoising intermediate variable and the input low-resolution image; dynamically scaling the consistency constraint of the denoising intermediate variable and the input low-resolution image; enhancing the representation consistency of the denoising intermediate variable and the input low-resolution image by using a gradient optimization method; extracting outline masks of the input low-resolution images as positioning guide information, so as to fuse denoising variables before and after gradient optimization; and projecting the potential representation of the denoising variable obtained after the denoising step number is completed to a pixel space through a pre-trained decoder to obtain a high-resolution denoising image. The invention can effectively solve the problems of instability and inconsistency in the image super-resolution task.",['G06T3/4076']
CN118096980A,A three-dimensional virtual try-on method and system based on custom diffusion model,"The invention relates to the technical field of deep learning and computer vision, and discloses a three-dimensional virtual fitting method and system based on a custom diffusion model, wherein the method comprises the following steps: constructing a diffusion model, pre-training the diffusion model to obtain a pre-trained diffusion model, and introducing LoRA and Densepose ControlNet of multiple concepts into the pre-trained diffusion model to obtain a custom diffusion model; generating an RGB template by using a custom diffusion model, and acquiring a mask template and a normal template according to the RGB template; training a first MLP network and updating parameters until convergence to obtain an optimized geometric representation by parameterizing the geometric representation based on DMTet using the first MLP network; parameterizing the texture corresponding to the optimized geometric representation by using a second MLP network, training the second MLP network, updating parameters until convergence, and obtaining an optimized texture representation; and combining the optimized geometric representation and the optimized texture representation to obtain a human body with a fitting result, and finishing fitting. The invention can simplify the processing steps of the test-on and improve the quality of generating the test-on view.","['G06T15/04', 'G06N3/0499', 'G06N3/08', 'G06T17/00', 'Y02T10/40']"
CN117934952A,Data set enhancement method based on low-rank adaptation of diffusion model,"The invention discloses a data set enhancement method based on low-rank adaptation of a diffusion model. The method comprises the following steps: s1, acquiring an initial data set, preprocessing the initial data set to obtain a training data set, wherein the training data set comprises a plurality of groups of image-text pairs, and the images contained in the image-text pairs contain a plurality of types of objects, and the text content is a prompt word corresponding to the types of objects. S2, training LoRA the model based on the training data set and combining the model with the baseline model to generate a diffusion model. S3, acquiring a target data set, preprocessing the target data set, inputting the preprocessed target data set into a diffusion model to generate a target sample, and adding the target sample into the target data set to obtain an enhanced data set. The invention has the characteristics of low cost and strong practicability.","['G06V10/764', 'G06V10/774', 'G06V10/82']"
CN118885736A,Small Sample Mechanical Fault Diagnosis Method Based on Improved De-noising Diffusion Model,"The invention belongs to the field of mechanical intelligent diagnosis, and particularly discloses a small sample mechanical fault diagnosis method based on an improved noise diffusion model, which comprises the following steps: collecting original vibration signals of key transmission parts under different mechanical health states and preprocessing the original vibration signals; converting the one-dimensional time domain signal into a two-dimensional time-frequency diagram by utilizing short-time Fourier transform; constructing a denoising diffusion model and improving a model structure; inputting the converted time-frequency diagram into an improved denoising diffusion model for training; generating different types of samples by using the trained denoising diffusion model, expanding an original data set, and forming a new data set; and outputting the new data set to the constructed convolution network to complete fault diagnosis. According to the method, fault diagnosis is carried out by combining the convolutional neural network, the accuracy and efficiency of a diagnosis model are improved by utilizing the enhanced data set, and compared with the traditional method, the method can achieve higher diagnosis accuracy under the condition of a small sample.","['G06F18/10', 'G06F18/213', 'G06F18/214', 'G06F18/24', 'G06F18/253', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06F2218/04']"
CN118170992A,"Object recommendation method, device, medium and computing equipment","The embodiment of the invention provides an object recommendation method, an object recommendation device, a medium and computing equipment. The method comprises the steps of constructing an attention layer based on interactive objects and interactive object category sequences in a forward diffusion network, acquiring a historical interactive object sequence and a historical interactive object category sequence of a target user in a specified recommendation scene to represent user preference, modeling the historical interactive object sequence of the user and the corresponding historical interactive object category sequence into Gaussian distribution, setting a reverse diffusion network and the forward diffusion network to adopt the same structure and parameters, generating Gaussian representation of a predicted object through the forward diffusion network and the reverse denoising network according to the historical interactive sequence and the introduced Gaussian noise, and accordingly performing object recommendation according to the Gaussian representation, guiding recommendation result generation by utilizing a plurality of historical sequence information such as the historical interactive object and the object category sequence, and improving the accuracy of personalized recommendation for the user in the specified recommendation scene.","['G06F16/9535', 'G06N3/0499', 'G06N3/08']"
CN117893570A,A multi-target tracking method with diffusion model empowered tracking proposal propagation,"The invention provides a multi-target tracking method for giving tracking proposal propagation to a diffusion model, which is applied to the technical field of target identification. The method and the device can remarkably improve the detection and association capability of target tracking and ensure the tracking capability in complex scenes.","['G06T7/246', 'G06N3/0455', 'G06N3/08', 'G06T2207/10016']"
CN117636481B,A multimodal joint gesture generation method based on diffusion model,"The invention discloses a multi-mode joint gesture motion generation method based on a diffusion model, which comprises an encoder, a multi-mode self-evaluation joint network and a lightweight diffusion model, wherein the encoder comprises a word vector model, an audio encoder, an expression encoder, a face encoder and an identity encoder, and the multi-mode self-evaluation joint network comprises a mode cross attention layer and an activation function; the light diffusion model is composed of a U-net network; constructing multi-mode data; and (3) encoding the multi-mode data by adopting an encoder to obtain each single-mode characteristic, inputting each single-mode characteristic into a multi-mode self-evaluation joint network to perform characteristic fusion, and inputting the fused characteristic into a lightweight diffusion model to perform gesture motion generation. According to the method, the correlation between the gesture actions and each mode is automatically learned through the multi-mode self-evaluation joint network, and the relation importance between each mode and the gesture actions is mined, so that the generated gesture actions are richer and more flexible.","['G06V40/28', 'G06N20/00', 'G06V10/806', 'G06V40/166', 'G06V40/168', 'Y02T10/40']"
CN117745933A,Three-dimensional point cloud generation method based on diffusion model,"The invention relates to a three-dimensional point cloud generation method based on a diffusion model, and belongs to the technical field of point cloud generation and processing. The method specifically comprises the following steps: s1: extracting characteristics of the point cloud by adopting a point coding module; s2: constructing a diffusion model based on a multi-layer Sheard MLP group U-Net network structure, wherein the diffusion model comprises a forward process and a reverse process; s3: training a diffusion model: fusing the point cloud characteristics extracted in the step S1 and time sequence information into a reverse process of a diffusion model through an embedding layer, and then calculating a difference value between noise predicted by the model and real noise, so as to finish iterative updating of model parameters; s4: and sampling from noise by using the trained diffusion model to obtain the finally generated high-quality vivid three-dimensional point cloud. The invention realizes more accurate prediction of noise of each step in the back diffusion process, thereby improving the generation quality.",[]
CN118134800A,Image shadow removing method based on wavelet non-uniform diffusion model,"The invention belongs to the technical field of image processing, and particularly relates to an image shadow removing method based on a wavelet non-uniform diffusion model; comprising the following steps: the shadow image to be processed and a corresponding mask image are obtained, and the shadow image and the mask image are preprocessed to obtain a processed shadow image and a processed mask image; performing haar wavelet decomposition on the preprocessed shadow image and the mask image to obtain a low-frequency component and a high-frequency component of the two images; inputting the low-frequency components and the high-frequency components of the two images into a trained wavelet non-uniform diffusion model for processing to obtain shadowless image low-frequency global information and shadowless image high-frequency detail information; performing wavelet inverse transformation on the low-frequency global information of the shadowless image and the high-frequency detail information of the shadowless image to obtain the shadowless image; the invention can reconstruct a finer shadowless image, realizes a good image enhancement effect, reduces the iterative sampling time of the diffusion model and is beneficial to practical application deployment.","['G06T5/70', 'G06N3/0464', 'G06N3/08', 'G06T3/40', 'G06T5/92', 'G06T7/11', 'G06T7/168', 'G06T2207/20064', 'Y02T10/40']"
CN117115818A,Diffusion model-based transformation defect data small sample expansion method and system,"The invention discloses a diffusion model-based transformation defect data small sample expansion method and a diffusion model-based transformation defect data small sample expansion system, and relates to the technical field of transformation defect data generation and small sample generation. Comprising the following steps: s1, data acquisition, S2, data preprocessing, S3, image labeling, S4, model training, S5, training ending and S6, defect prediction. The invention uses normal transformation defect data to train the image encoder of the diffusion model; then, a diffusion model is finely adjusted by using a small amount of defect data, and finally, a transformation defect text description is input into the finely adjusted diffusion model to obtain corresponding transformation defect image data; the method can generate a large amount of transformation defect data which are difficult to acquire based on a large amount of normal transformation defect data and a small amount of transformation defect data which are easy to acquire, has the advantages of good availability, high universality and the like, gives consideration to model generalization capability, can be well applied to transformation defect data generation, and provides data support for a transformation defect detection model.","['G06V20/70', 'G06N3/04', 'G06V10/30', 'G06V10/774', 'G06V10/82', 'Y04S10/50']"
CN117893409A,Face super-resolution reconstruction method and system based on illumination condition constraint diffusion model,"The invention discloses a face super-resolution reconstruction method based on an illumination condition constraint diffusion model, which comprises the steps of collecting face images under different illumination conditions and constructing a training data pair of a low-resolution non-uniform illumination face image and a high-resolution uniform illumination face image; then, the low-resolution non-uniform illumination face image is sent to an illumination estimation network for rough illumination compensation prediction, local illumination and global illumination constraint are constructed according to illumination compensation information, and the local illumination and global illumination constraint are respectively embedded into a conditional denoising network; then the face image after rough illumination compensation is sent into a noise guide to generate priori Gaussian noise; training a conditional denoising network using a comparative diffusion loss function; and finally, continuously iterating and refining the noise image by using the trained conditional denoising network, and reconstructing the uniform illumination high-resolution face image. The invention can realize the super-resolution reconstruction and illumination normalization of the human face at the same time, and restore the real high-resolution uniform illumination human face image from the low-resolution non-uniform illumination human face image.","['G06T3/4076', 'G06N3/0464', 'G06N3/048', 'G06T5/50', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201']"
CN117952843A,Remote sensing image fusion method based on multi-scale conditional diffusion model,"The invention discloses a remote sensing image fusion method based on a multi-scale conditional diffusion model, which comprises the following steps: step 1, data preprocessing; step 2, forward direction process of conditional diffusion model: changing the a priori data distribution x 0 into a noisy data distribution; step 3, training a multi-scale denoising depth model: the depth model adopts a model comprising a space branch and a spectrum branch, the space branch extracts space details, and then the space details are integrated into the spectrum branch; spectrum branches extract spectrum information and adaptively combine space details to perform fusion; step 4, reverse process of conditional diffusion model: the depth model designed in step 3 is learned to eliminate degradation from the forward process and sampled from x T to x 0. According to the invention, hrMSI is decomposed into spatial and spectral branches, so that spatial details and spectral characteristics can be more effectively learned, and a fusion image with higher quality can be produced.","['G06T5/50', 'G06N3/0455', 'G06N3/0464', 'G06N3/0499', 'G06N3/08', 'G06T2207/10036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US20250078810A1,Controllable diffusion-based speech generative model,"Systems and techniques described herein relate to a diffusion-based model for generating converted speech from a source speech based on target speech. For example, a device may extract first prosody data from input data and may generate a content embedding based on the input data. The device may extract second prosody data from target speech, generate a speaker embedding from the target speech, and generate a prosody embedding from the second prosody data. The device may generate, based on the first prosody data and the prosody embedding, converted prosody data. The device may then generate a converted spectrogram based on the converted prosody data, the speaker embedding, and the content embedding.","['G10L13/10', 'G10L13/027']"
US12266065B1,Visual indicators of generative model response details,"Systems and methods for providing visual indications of generative model responses can include obtaining a user input and processing the user input with a generative model to generate a model-generated-response. The systems and methods can process the model-generated response and an image of an environment to generate an augmented image. The augmented image can include visual indicators of the model-generated response, which can include annotating the image based on detected features within the image. Generation of the augmented image can include object detection and annotation based on the content of the model-generated response.","['G06V20/20', 'G06T19/006']"
CN116580267A,"Defect sample generation method and device, electronic equipment and storage medium","The application discloses a method and a device for generating a defect sample, electronic equipment and a storage medium; the method comprises the following steps: randomly sampling standard Gaussian noise, taking the noise distribution obtained by sampling as the noise characteristic of the current time step, inputting the noise characteristic and a semantic tag corresponding to the target defect into a defect generation network, and predicting the diffusion noise distribution of the last time step; randomly sampling based on the disturbance noise distribution to obtain the diffusion noise of the last time step; according to the diffusion noise and the noise characteristics of the current time step, calculating the noise characteristics of the last time step; repeating the above operation until the noise characteristic of the 0 th time step is calculated; generating a local defect image corresponding to the target defect based on the noise characteristic of the 0 th time step; inputting the image into a defect fusion network to generate a defect sample corresponding to the target defect. The embodiment of the application can generate the high-fidelity local defect and naturally blend the local defect into a normal sample.","['G06V10/774', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06T7/0002', 'G06V10/80', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'Y02P90/30']"
TW202004947A,Targeted recall of semiconductor devices based on manufacturing data,"A system for providing a targeted recall includes a metrology sub-system for performing in-line measurements on semiconductor dies after one or more fabrication steps to generate in-line measurement profiles, a failure analysis sub-system for determining a manufacturing fingerprint of a failed die, and a controller. The metrology sub-system may further perform one or more measurements of the semiconductor dies after one or more packaging steps to generate package characterization profiles. The controller may generate manufacturing fingerprints for the semiconductor dies based on the in-line measurement profiles and the package characterization profiles, which are referenced to unique electronic chip identifiers. The controller may further identify at-risk dies by comparing the manufacturing fingerprints of the semiconductor dies with the manufacturing fingerprint of the failed die and direct a targeted recall for the one or more at-risk dies.","['H01L21/67242', 'G01R31/2894', 'H01L22/34', 'G01R31/2831', 'G06Q30/014', 'H01L22/10', 'H01L22/20', 'H01L22/30', 'H01L23/544', 'H01L22/12', 'H01L22/14', 'H01L2223/54433']"
WO2024127303A1,Reinforcement learning for final setups and intermediate staging in clear tray aligners,"Systems and techniques for generating a transformation for a three-dimensional (3D) representation of oral care data are disclosed. The method involves receiving oral care data describing the current state of a treatment and providing it as input to a reinforcement learning (RL) model. The processing circuitry executes one or more trained neural networks using the oral care data to generate a representation that specifies a predicted action associated with the current state of the treatment. By utilizing the current state and the predicted action, the processing circuitry generates a predicted next state of the treatment. These systems and techniques enable the generation of accurate and personalized transformations for 3D representations of oral care data, facilitating improved treatment planning and decision-making processes.","['G16H50/30', 'G16H50/20']"
CN118644092B,Pipeline siltation risk assessment method and system based on desilting detection,"The application relates to the technical field of pipeline detection and discloses a pipeline siltation risk assessment method and system based on dredging detection. The method comprises the following steps: collecting a historical image dataset and a historical acoustic dataset inside the pipeline and creating a pipeline fouling profile and a fouling feature dataset; r-type cluster analysis and variation coefficient calculation are carried out on the siltation characteristic data set, a siltation influence factor index set is obtained, and a multi-level siltation risk assessment index system is constructed; inputting a pipeline siltation distribution diagram and a siltation characteristic data set into a preset double-layer deep belief network model for model training to obtain a siltation identification model; collecting a real-time image data set and a real-time acoustic data set in a pipeline, and carrying out siltation identification through a siltation identification model to obtain a target siltation identification result; according to the multi-level siltation risk assessment index system, risk assessment is carried out on the target siltation identification result, and a pipeline maintenance decision scheme is generated.","['G06Q10/0635', 'G06F18/2131', 'G06F18/23213', 'G06F18/2415', 'G06N3/047', 'G06N3/084', 'G06Q10/20', 'G06Q50/26', 'G06V10/806', 'G06V10/82', 'G06F2123/02']"
US12181844B2,Building management system with natural language model-based data structure generation,"Systems and methods are disclosed relating to building management systems with language model-based data structure generation. For example, a method can include receiving a query to select, from a plurality of data sources of a building management system, a selected one or more data sources according to a characteristic indicated by the query in at least one of a natural language representation or a semantic representation. The method can further include applying the query as input to a machine learning model to cause the machine learning model to generate an output indicating the selected one or more data sources, the machine learning model configured using training data comprising sample data and metadata from the plurality of data sources. The method can further include presenting, using at least one of a display device or an audio output device, the output.","['G05B13/027', 'G06F16/248', 'G06N3/0895']"
CN107490878A,Electronic type ophthalmic lens with medical monitoring,"This document describes a kind of ophthalmic lens with electronic system, the electronic system is used for the medical conditions that wearer is monitored using at least one sensor and at least one question template.In another embodiment, question template includes pattern and/or threshold value.In at least one embodiment, eyeglass combines the second eyeglass and/or external device (ED) works, to monitor the test procedure of medical conditions or execution to wearer.The example of at least one sensor includes eyelid position sensor system, eye movement sensing system, biology sensor, bio-impedance sensor, temperature sensor and pulse oximetry.","['A61B3/113', 'A61B3/0025', 'A61B3/10', 'A61B3/112', 'A61B3/14', 'A61B5/0002', 'A61B5/0015', 'A61B5/01', 'A61B5/1103', 'A61B5/14555', 'A61B5/398', 'A61B5/6821', 'A61B5/7246', 'A61B5/7271', 'A61B5/742', 'A61B5/746', 'G02C7/04', 'G02C7/083', 'G04G11/00', 'A61B2560/0475', 'A61B2562/0219', 'A61F2/16']"
CN117745371A,A fair recommendation method and system based on conditional diffusion model,"The invention discloses a fairness recommendation method based on a conditional diffusion model, which comprises the steps of obtaining an original data set of a recommendation system, screening, encoding and filtering the original data set, and obtaining a user-object interaction matrix after data normalization processing; processing the user-object interaction matrix through a diffusion model to obtain an initial recommended matrix, training parameters of the diffusion model by reducing the total loss function value of the model, converging the parameters of the diffusion model when the total loss function value of the model is reduced to the minimum value, and optimizing the diffusion model by the model parameters at the moment to obtain a trained user-object scoring matrix; sorting according to the item scores in the trained user-item scoring matrix, and recommending items with high item scores for the user; the invention also provides a fairness recommendation system based on the conditional diffusion model; the method has the advantages that the recommended utility is realized, the recommended fairness is guaranteed, and the recommended fairness, the utility target and the fairness target are comprehensively considered.",[]
CN116304705A,A flow data set generation method and device based on conditional diffusion model,"The invention discloses a flow data set generation method and device based on a conditional diffusion model, wherein the method comprises the following steps: collecting a flow data set with a label; preprocessing an original flow data set to obtain a gray level map; taking the gray level diagram as input, and performing forward process training of the diffusion model; after the diffusion model converges, a trained noise predictor is obtained and used for the reverse process of the diffusion model; generating a noise image with the same size as the target gray level image by using Gaussian noise as an initial value of the noise-containing image, and performing reverse process training; training a reverse process in a circulating iteration mode, and finally obtaining a target gray scale image; and converting the generated gray level map into a corresponding numerical matrix to finish the generation of flow data. The invention avoids the defects that partial key features are possibly lost due to undersampling and the classifier is possibly over-fitted due to oversampling, and compared with GAN, the invention can obtain better picture generation effect and avoid the defect of unstable training in the original generation countermeasure model.","['G06N3/084', 'Y02D30/50']"
CN117854470A,"Speech synthesis method, device, electronic equipment and readable storage medium","The invention provides a voice synthesis method, a device, an electronic device and a readable storage medium, wherein the method comprises the following steps: acquiring a text to be synthesized given by a user, and performing coding processing on the text to be synthesized to obtain an initial spectrum representation; transforming the initial spectral representation into a target spectral representation based on the improved generation model; analyzing and synthesizing the target frequency spectrum representation to obtain a target voice signal corresponding to the text to be synthesized; the improved generation model is obtained based on noise schedule improvement, sampling algorithm improvement and network parameterization target improvement of the traditional generation model. The method transforms the rough frequency spectrum representation through the improved generation model, overcomes the defects of low synthesis efficiency and low synthesis quality of the existing voice synthesis method, greatly improves the quality of the synthesized voice signal and also effectively improves the synthesis efficiency of the voice signal.",[]
CN116977489A,Text-guided image processing method based on diffusion model,"The invention realizes a text-guided image processing method based on a diffusion model. And aligning words in the target text with the source image by using a cross attention mechanism, and generating auxiliary editing perception keywords and source perception prompts to respectively enhance editing effect and improve fidelity. In the denoising process, attention mapping between the editing perception keywords and the source image is injected into the denoising process to improve the alignment degree of the generated image and the target text, and a soft mask is automatically generated to balance semantics and fidelity by comparing diffusion model predictions between auxiliary source perception prompts and the target text. The method is the first soft mask based, non-optimized, text driven image processing method, requiring no additional annotations. A large number of experiments on both data sets show the effectiveness of the method of the invention, which rapidly generates high quality, diverse image operations while achieving a better balance between semantics and fidelity.","['G06T11/60', 'G06T9/00']"
CN116312489A,A kind of model training method and related equipment,"The application discloses a model training method and related equipment, and a speech model obtained through training can have excellent performance, so that a speech task of a user can be accurately completed, and user experience is improved. The method comprises the following steps: acquiring training data associated with a voice task, wherein the training data comprises a first text and a first voice; inputting the first voice into a first model to obtain a first voice characteristic; inputting the first text into a second model to obtain a second voice feature; inputting the first voice characteristic into a first model to be trained to obtain a processing result of the first voice; inputting the second voice characteristic into a first model to be trained to obtain a processing result of the first text; and training the first model to be trained based on the processing result of the first voice and the processing result of the first text to obtain a third model, wherein the model formed by the first model and the third model is used for completing the voice task.","['G10L15/063', 'G10L15/02']"
US12355931B2,Generation of three-dimensional images with digital magnification,A system for generating three-dimensional (3D) images from captured images of a target when executing digital magnification. A controller executes a digital magnification on the first image of the target captured by the first image sensor and on the second image captured by the second image sensor of the target. The controller crops the first image and the second image to overlap a first portion of the target captured by the first image sensor with a second portion of the target captured by the second image sensor. The controller adjusts the cropping of the first image and the second image to provide binocular overlap of the first portion of the target with the second portion of target. The displayed cropped first image and the cropped second image display the 3D image at the digital magnification to the user.,"['G02B27/017', 'G06T3/40', 'H04N13/106', 'H04N13/239', 'H04N13/246', 'H04N13/296', 'H04N23/53', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0178', 'G02B27/646', 'G06T2210/22']"
US20240105328A1,Neural network simulator for ultrasound images and clips,An ultrasound image simulator includes a generative neural network to receive ultrasound probe position and orientation and to generate at least one simulated ultrasound image or clip of a body part of a subject. The generative neural network is trained on a multiplicity of 2D ultrasound images or clips of said body part taken from a plurality of ultrasound probe positions and orientations.,"['G06N3/045', 'A61B8/4245', 'A61B8/4254', 'A61B8/523', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T15/08', 'G06T17/00', 'G09B23/286', 'G16H30/40', 'G16H40/63', 'G06T2207/10132', 'G06T2210/41']"
WO2024127315A1,Neural network techniques for appliance creation in digital oral care,"Systems and methods are disclosed for generating a three-dimensional (3D) representation of oral care data for use in oral care treatment. The systems and methods involve receiving an input 3D representation of a patient's dentition and encoding the 3D representation into a lower-dimensional first latent representation using a trained first machine learning (ML) module. Subsequently, a trained second ML module, comprising a trained transformer encoder model or a trained transformer decoder model, is executed to generate a second latent representation using the first latent representation. The second latent representation is then reconstructed into a 3D oral care representation (e.g., a tooth restoration design, an appliance component, a fixture model component, etc.) by a decoder. Finally, the processing circuitry outputs the reconstructed 3D representation of oral care data. These systems and methods enable efficient and accurate generation of oral care data, facilitating improved oral care appliance generation, treatment planning and analysis.","['G06F18/213', 'A61C13/0004', 'A61C7/002', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/096', 'G06T19/00', 'G16H20/30', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06N3/092', 'G06N3/098', 'G06T2210/41']"
CN118229569A,Document image transmission removal method and device based on fuzzy diffusion model,"The invention discloses a document image transmission removal method and device based on a fuzzy diffusion model, wherein the method comprises the following steps: constructing a basic diffusion framework, and describing a diffusion process in the form of a random differential equation; constructing a preset U-Net noise network to predict Gaussian noise in an image; the inputs to the network include transmission images, noise images, and time information; training a noise network using the authored synthetic transmission image dataset to minimize loss of network prediction noise and original added noise; updating network parameters by back propagation to minimize loss errors; and generating a test set transmission image restoration graph, and restoring a non-transmission image through a sampling formula after the noise network training is completed. The device comprises: a processor and a memory. The document transmission removal provided by the invention effectively learns key characteristic information in the image by adopting a method of combining fuzzy operation with a diffusion model, and retains more image textures.","['G06T5/70', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/084', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US20240169701A1,Affordance-based reposing of an object in a scene,"Systems and methods for inserting an object into a background are described. Examples of the systems and methods include obtaining a background image including a region for inserting the object, and encoding the background image to obtain an encoded background. A modified image is then generated based on the encoded background using a diffusion model. The modified image depicts the object within the region.","['G06T5/50', 'G06T7/194', 'G06T7/70', 'G06V10/774', 'G06V10/82', 'G06T2207/20221']"
US12380059B2,Super system on chip,"A Super System is disclosed and its inputs/outputs are coupled with a Mach-Zehnder interferometer (MZI), wherein the Mach-Zehnder interferometer (MZI) can be coupled with a first optical waveguide either in a two-dimensional (2-D) or in a three-dimensional (3-D) arrangement. The first optical waveguide can be then coupled with (i) a semiconductor optical amplifier (SOA) and/or (ii) a second optical waveguide (that can include an optical resonator) either in a two-dimensional (2-D) or in a three-dimensional (3-D) arrangement. The Super System can include multipliers of matrices and/or graphic processors.","['G01S17/08', 'G06F15/803', 'G01S7/4917', 'G02F1/212', 'G02F1/365', 'G02F3/00', 'H04W12/06', 'G02F2203/70']"
US20240404144A1,Color conditioned diffusion prior,"Systems and methods for image processing are described. Embodiments of the present disclosure, via a multi-modal encoder of an image processing apparatus, encodes a text prompt to obtain a text embedding. A color encoder of the image processing apparatus encodes a color prompt to obtain a color embedding. A diffusion prior model of the image processing apparatus generates an image embedding based on the text embedding and the color embedding. A latent diffusion model of the image processing apparatus generates an image based on the image embedding, where the image includes an element from the text prompt and a color from the color prompt.","['G06N3/08', 'G06F40/40', 'G06N3/045', 'G06N3/047', 'G06T11/001', 'G06T11/60']"
CN116978132A,"Living body detection method, living body detection device, electronic equipment and storage medium","The invention provides a living body detection method, a living body detection device, an electronic device and a storage medium, wherein the living body detection method comprises the following steps: after noise is added for the target image based on the trained first diffusion model, noise is removed for the noise added target image based on the trained second diffusion model, and a restored image corresponding to the target image is obtained; subtracting the restored image from the target image to obtain the image noise of the target image; inputting the target image and the image noise into a trained double-branch depth detection model, and determining whether the target image is a real face image according to a depth map output by the double-branch depth detection model; the first diffusion model is obtained based on training of a real face image data set and a fraudulent face image data set; the second diffusion model is obtained based on training of a real face image data set; the double-branch depth detection model is obtained by training based on a real face image data set and a fraudulent face image data set. Thereby improving the generalization performance and stability of living body detection.","['G06V40/45', 'G06T7/55', 'G06V10/82', 'G06V40/16', 'G06V40/168', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
CN117370797A,Method and device for enhancing channel data set,"The application discloses a method and a device for enhancing a channel data set, comprising the following steps: acquiring real channel data and recording scene labels of the real channel data; training a diffusion model according to the number of the types of the scene labels; generating a plurality of virtual channel data based on the trained diffusion model; mixing the real channel data and the virtual channel data as a new training set for AI model training. The method solves the problem of how to generate high-quality virtual channel data under the condition that the collected channel data volume is limited, generates the high-quality virtual channel data by training the diffusion model, and mixes the data sets of the real channel data and the virtual channel data, namely, the enhanced channel data set is beneficial to improving the convergence performance and the training quality when the AI model is trained.","['G06F18/214', 'G06F18/241', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
US20240386348A1,Building management system with building lifecycle workflow applcation,"A method of servicing a building can include creating a workflow for a service by stitching building lifecycle data together with enterprise data from a plurality of sources, augmenting the workflow by stitching, into the workflow using at least one AI model, specific information associated with an object involved in the service, and facilitating completion of the service in accordance with the augmented workflow by guiding a user through the augmented workflow.","['G06Q10/0633', 'G06Q10/06316']"
CN117541668A,"Virtual character generation method, device, equipment and storage medium","The application discloses a virtual character generation method, device, equipment and storage medium, and relates to the field of artificial intelligence. Comprising the following steps: acquiring character posture information, prop masks and description texts; based on the character posture information and the description text, character feature extraction is carried out through a character control network, so that character conditional features are obtained; based on the prop mask and the description text, prop feature extraction is carried out through a prop control network, so that prop conditional features are obtained; based on the descriptive text, the character conditioning features and the prop conditioning features, generating a virtual character image through a stable diffusion model, wherein a virtual character in the virtual character image accords with character posture information, the appearance and the position of a virtual prop in the virtual character image accord with prop masks, and the interaction relationship between the virtual character and the virtual prop accords with the descriptive text.","['G06T11/00', 'G06F18/253', 'G06F40/205', 'G06N3/0455', 'G06N3/08']"
US20250209712A1,"Method of generating fullbody animatable person avatar from single image of person, computing device and computer-readable medium implementing the same","A computer-implemented method of generating fullbody animatable avatar of a person from a single image of the person includes: obtaining an image of a person body and a parametric body model defined by pose parameters and shape parameters of the person body in the image, and by camera parameters used when capturing the image; defining, based on the parametric body model, a texturing function including a mapping between each pixel corresponding to a part of the person body shown in the image and corresponding texture coordinates in a texture space, and corresponding texture coordinates in the texture space for a part of the person body not shown in the image; sampling RGB texture of the person body based on the mapping and obtaining a map of sampled pixels.","['G06T13/40', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T15/04', 'G06T15/20', 'G06T17/20', 'G06T3/4046', 'G06T5/60', 'G06T5/70', 'G06T5/77', 'G06T2207/20081', 'G06T2207/20084']"
WO2024127313A1,Metrics calculation and visualization in digital oral care,"Systems and techniques are disclosed for visualizing oral care metrics. The method involves receiving one or more three-dimensional (3D) oral care representations and utilizing processing circuitry to compute the oral care metrics based on these representations. The processing circuitry further converts the computed oral care metrics into a multidimensional format. To enhance visualization, the dimensionality of the oral care metrics in the multidimensional format is reduced, forming a reduced- dimensionality version of the metrics. Finally, the processing circuitry renders the reduced-dimensionality version of the oral care metrics in a visualized form. These systems and techniques enable the effective visualization of oral care metrics, providing valuable insights and facilitating improved analysis and decision-making in oral care applications.","['G16H20/30', 'G16H30/40', 'G16H50/20']"
US12099781B1,Automatic generation of data models,Systems and methods to generate new equipment models and/or connectors to integrate the new equipment models are described herein. Generation of new equipment models can include retrieving information from one or more publicly accessible data sources.,['G06F30/17']
US20240346629A1,Prior guided latent diffusion,"Systems and methods for image processing are described. Embodiments of the present disclosure obtain a text prompt for text guided image generation. A multi-modal encoder of an image processing apparatus encodes the text prompt to obtain a text embedding. A diffusion prior model of the image processing apparatus converts the text embedding to an image embedding. A latent diffusion model of the image processing apparatus generates an image based on the image embedding, wherein the image includes an element described by the text prompt.","['G06T5/73', 'G06F40/279', 'G06T11/00', 'G06T5/50']"
CN118155023B,"Text graph and model training method and device, electronic equipment and storage medium","The application relates to the technical field of artificial intelligence, in particular to a method, a device, electronic equipment and a storage medium for training a text-generated graph and a model, which are used for improving the accuracy of text-generated graph model output. The method comprises the following steps: respectively inputting a single concept sample image and a corresponding first descriptive text, and a multi-concept sample image and a corresponding second descriptive text into a to-be-trained text-to-be-trained graph model comprising a plurality of expert LoRA networks, determining first prediction noise of the single concept sample image according to first expert activation information based on first descriptive text prediction, and determining second prediction noise of the multi-concept sample image according to second expert activation information based on second descriptive text prediction; each expert LoRA network corresponds to an object; expert activation information includes the probability that each expert LoRA network is activated during the text-to-graphics process; based on the first prediction noise, the second prediction noise, the first expert activation information and the second expert activation information, the text-to-be-trained graph model is called.","['G06V10/774', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'G06V10/30', 'G06V10/764', 'G06V10/82', 'G06V20/70']"
US20240161403A1,High resolution text-to-3d content creation,"Text-to-image generation generally refers to the process of generating an image from one or more text prompts input by a user. While artificial intelligence has been a valuable tool for text-to-image generation, current artificial intelligence-based solutions are more limited as it relates to text-to-3D content creation. For example, these solutions are oftentimes category-dependent, or synthesize 3D content at a low resolution. The present disclosure provides a process and architecture for high-resolution text-to-3D content creation.","['G06T17/20', 'G06F40/30', 'G06T15/04', 'G06T17/005', 'G06T19/20', 'G06T3/40']"
WO2025010950A1,"Text-to-image generation method, apparatus and device, and storage medium","Disclosed in the present application are a text-to-image generation method, apparatus and device, and a storage medium. In the present application, by means of the language capability of a large language model, the large language model is caused to execute a task of performing processing on original text description content, wherein the task is a task that makes edited text description content, which is obtained by the large language model, have a higher richness than the original text description content. A text representation, which is extracted by an output layer of the large language model, is acquired, and the text representation can serve as a feature representation corresponding to the edited text description content output by the large language model. Since the edited text description content has a higher information richness than the original text description content, the acquired text representation, which is extracted by the output layer, has a stronger feature expression capability than a conventional encoded feature of the original text description content. The text representation is sent to a pre-configured text-to-image generation model, so as to obtain an image generated by the model. The generated image better matches text content, that is, the image achieves a better effect.","['G06T11/60', 'G06F40/289', 'G06F40/30', 'G06V10/44', 'G06V10/774', 'G06V10/86']"
US11978466B2,"Systems, methods, and apparatuses for restoring degraded speech via a modified diffusion model","Systems, methods, and apparatuses to restore degraded speech via a modified diffusion model are described. An exemplary system is specially configured to train a diffusion-based vocoder containing an upsampler, based on pairing original speech x and degraded speech mel-spectrum mT samples; train a deep convoluted neural network (CNN) upsampler based on a mean absolute error loss to match the estimated original speech {circumflex over (x)}â² outputted by the diffusion-based vocoder by extracting the upsampler, generating a reference conditioner, and generating a weighted altered conditioner cT n â². The system further optimizes speech quality to invert non-linear transformation and estimate lost data by feeding the degraded mel-spectrum mT through the CNN upsampler and feeding the degraded mel-spectrum mT through the diffusion-based vocoder. The system then generates estimated original speech {circumflex over (x)}â² based on the corresponding degraded speech mel-spectrum mT. Other related embodiments are described.","['G10L21/02', 'G10L19/028', 'G10L25/18', 'G10L25/30', 'G10L21/038']"
CN117036880A,Sea surface temperature image complement method and network based on denoising diffusion generation model,"The invention belongs to the technical field of image processing, and discloses a sea surface temperature image complement method and a network based on a denoising diffusion generation model, wherein the sea surface temperature image complement method comprises a Zhou Junzhi generation module, a daily deviation generation module and a multiscale fusion module based on Zhou Junzhi and daily deviation, and a denoising diffusion generation module I of the Zhou Junzhi generation module is utilized to generate a complement Zhou Junzhi image; obtaining a daily deviation image by using a daily deviation generating module, and obtaining a completed daily deviation image by using a denoising diffusion generating module II of the daily deviation generating module; and respectively inputting the completed daily deviation image and the completed Zhou Junzhi image into a multiscale deviation feature decoupling extraction module and a multiscale mean feature decoupling extraction module of a multiscale fusion module based on Zhou Junzhi and daily deviation to obtain three different-scale decoupling features, then fusing the decoupling features on the same scale, and finally fusing the features to obtain the completed image. The detail and definition of the image are improved by the method, and the high-quality output image is obtained.","['G06V10/806', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06V10/30', 'G06V10/52', 'G06V10/82']"
TW202518324A,Efficient diffusion machine learning models,"Certain aspects of the present disclosure provide techniques and apparatus for improved machine learning. During a first iteration of processing data using a denoising backbone of a diffusion machine learning model, a first latent tensor is generated using a lower resolution block of the denoising backbone, and a first feature tensor is generated based on processing the first latent tensor using a higher resolution block of the denoising backbone, the higher resolution block using a higher resolution than the lower resolution block. A second latent tensor is generated based on processing the first latent tensor using an adapter block of the denoising backbone. During a second iteration of processing the data using the denoising backbone, a second feature tensor is generated based on processing the second latent tensor using the higher resolution block.","['G06N3/044', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/096', 'G06N5/01', 'G06T11/00']"
US20250191242A1,Generating synthetic representations,"Systems, methods, and computer programs disclosed herein relate to generating synthetic representations, such as synthetic radiologic images.","['G06T11/00', 'A61K49/108', 'G06T5/60', 'G06T5/70', 'G06T5/94', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2210/41']"
CN116485655A,CT image super-resolution processing method based on diffusion model,"The invention discloses a CT image super-resolution processing method based on a diffusion model, which comprises the following steps of S1: construction of a high resolution CT image dataset X h And interpolating CT image dataset X s The method comprises the steps of carrying out a first treatment on the surface of the S2: establishing a diffusion process of a super-resolution diffusion model; s3: establishing a noise prediction network e Î¸ (x t T), using data set X h Training the device; s4: establishing noise level prediction network Ï Î¸ (x s ) Using data set X s Training the device; s5: to interpolate CT image x s Input network Ï Î¸ (x s ) In the process, the liquid crystal display device comprises a liquid crystal display device,obtaining a corresponding time sequence t est And by x s And t est Performing de-noising reconstruction of inverse diffusion for the initial value; s6: in the back diffusion process, DPM-Solver is used for solving the inverse ODE, and finally the super-resolution CT image is obtainedThe super-resolution CT image generated by the invention has rich detail texture characteristics, and simultaneously, the processing time is greatly shortened and the computing resource is saved by optimizing the sampling process.","['G06T3/4053', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06T3/4046']"
CN113516136A,"A kind of handwritten image generation method, model training method, device and equipment","The embodiment of the specification provides a handwritten image generation method, a model training device and equipment, and can be applied to the technical field of artificial intelligence. The method comprises the following steps: acquiring a handwritten sample image; the handwriting sample image corresponds to handwriting character content; extracting sample handwriting style characteristics of the handwriting sample image; the sample handwriting style characteristic is used for representing a style corresponding to the content of the handwritten character; inputting the handwritten character content and the sample handwriting style characteristics into a diffusion model to obtain at least two target sample images corresponding to the handwritten sample images; the diffusion model is used to adjust the generated target sample image according to noise. The method improves the diversity of the target handwritten image, and ensures the accuracy of the trained model in recognizing handwritten images of different styles when the corresponding model is trained by using the target handwritten image.",['G06F18/214']
US20240377792A1,Machine learning architectures for building management system with building equipment servicing,"Systems and methods are disclosed relating to building management systems with building equipment servicing. For example, a system can include at least one machine learning model configured using training data that includes at least one of unstructured data or structured data regarding items of equipment. The system can provide inputs, such as prompts, to the at least one machine learning model regarding an item of equipment, and generate, according to the inputs, responses regarding the item of equipment, such as responses for detecting a cause of an issue of the item of equipment, performing a service operation corresponding to the cause, or guiding a user through the service operation.",['G05B13/027']
CN115357941B,Privacy removing method and system based on generating artificial intelligence,"The application discloses a privacy removing method and a privacy removing system based on generative artificial intelligence, wherein the method comprises the following steps: carrying out feature coding, constraint difference calculation and normalization processing on target data; training the generative countermeasure network according to the monitoring index based on the processed target data; inputting random variables into the generative confrontation network to obtain synthetic data of the target data; calculating statistical characteristics and coverage range of the target data and the synthetic data of the target data, and determining the target data as to-be-tested data if set conditions are met; and performing connection attack on the target data and the data to be tested, and if a set condition is met, determining the synthetic data of the target data as privacy-removed data of the target data. The data is subjected to privacy-removing processing efficiently and with high quality.","['G06F21/6254', 'G06N3/08']"
CN117152304A,A method to generate images from text based on improved stable diffusion,"The invention provides a method for generating an image based on a text of improved stable diffusion, which comprises the following steps: step 1: mapping the image from the pixel space to a potential space, and learning an implicit expression of the image; step 2: the hint word description is encoded into a 768-dimensional text vector using a CLIP text encoder: ÏÎ¸ (y); step 3: diffusing the potential space vector Z in the potential space; step 4: taking the diffused potential vector ZT as input to obtain a feature mapStep 5: map the characteristic mapInputting the spatial conditions provided by the user into a Box module to output a feature mapStep 6: generating Z, and decoding the Z through a decoder to obtain an image X1; step 7: image X1 is put into a cascaded DiffuseGAE module and output as image X. Through the improved U-net network and the cascade of the DiffuseGAE model after the image generation, the semantic and structural information of the image is captured better, the image generation with more diversity and controllability is realized, and the quality of the generated image is improved.","['G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06T5/50', 'G06T2207/20221', 'Y02D10/00']"
US20250173816A1,"Noise Schedules, Losses, and Architectures for Generation of High-Resolution Imagery with Diffusion Models","The present disclosure relates generally to machine learning. More particularly, the present disclosure relates to improved noise schedules, losses, and architectures for generation of high-resolution imagery with diffusion models.","['G06T11/001', 'G06T3/40', 'G06T11/00', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
US20240153194A1,Generation of curated training data for diffusion models,"Systems and methods are provided that include a processor executing a program to match sentences from a sentence dataset with artistic phrases from an artistic phrase dataset to generate a plurality of safe phrases. The processor is further configured to, for each of the safe phrases, generate a safe image by, for a predetermined number of iterations, performing steps to input an initial image into a diffusion process to generate a processed image, wherein the diffusion process includes a first diffusion model, back-propagate the processed image through a text-image match gradient calculator to calculate a gradient against the safe phrase, and update the initial image by applying the gradient to the processed image. The processor is further configured to pair each of the generated safe images with their respective safe phrase to form a plurality of safe phrase-image pairs.","['G06F18/214', 'G06T15/02', 'G06F18/22', 'G06F40/289', 'G06F40/30', 'G06N3/0455', 'G06N3/084', 'G06N3/096', 'G06N5/041', 'G06T5/002', 'G06T5/70', 'G06V10/774', 'G06F40/216', 'G06T2207/20081']"
WO2024131025A1,"Data processing method and apparatus, electronic device, and storage medium","A data processing method and apparatus, an electronic device, and a storage medium. The method comprises: acquiring physiological characteristic data of a target object under at least one physiological index (S110); determining a data processing type corresponding to the physiological characteristic data, and calling a target network model corresponding to the data processing type (S120); and processing the physiological characteristic data on the basis of the target network model to obtain target physiological characteristic data (S130).","['G16H50/50', 'G16H10/20', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/40', 'Y02A90/10']"
WO2024121190A1,Generating combined diagnostic imaging and pathology images,A computer-implemented image generation method (100) for generating combined diagnostic imaging and pathology images is described. The method (100) comprises: acquiring with a first imaging modality pathological image data (110) of a subject; acquiring with a second imaging modality diagnostic image data (120) of the subject; mapping (140) the pathological image data to the diagnostic image data; and applying an image generation algorithm (150) in order to generate a combined diagnostic and pathology image based on the mapping of the data.,"['G06T11/00', 'G06T2207/10056', 'G06T2207/10072', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20121', 'G06T2210/41']"
US20100287628A1,Genetically Modified Rat Models for Cancer,"This invention relates to the engineering of animal cells, preferably mammalian, more preferably rat, that are deficient due to the disruption of tumor suppressor gene(s) or gene product(s). In another aspect, the invention relates to genetically modified rats, as well as the descendants and ancestors of such animals, which are animal models of human cancer and methods of their use.","['A01K67/0278', 'A01K67/0276', 'C12N15/8509', 'A01K2217/075', 'A01K2217/203', 'A01K2227/105', 'A01K2267/0331', 'C12N15/85', 'C12N2015/8527', 'C12N2015/8536', 'C12N2015/8572', 'C12N2800/90']"
CN118627276A,"A method, device, equipment and readable storage medium for generating driver behavior strategy","The application discloses a method, a device, equipment and a readable storage medium for generating a driver behavior strategy, wherein the method comprises the following steps: constructing simulation data based on natural driving data of the vehicle; training the initial driver behavior strategy model for a plurality of times based on the simulation data to obtain a trained driver behavior strategy model; and generating a driver behavior strategy based on the trained driving behavior strategy model. Thus, the multi-mode distribution and details of the simulation data can be captured through the conditional diffusion strategy network, so that the diversity of the driver behavior strategies generated by the driver behavior strategy model is improved; the driver behavior strategy model is trained for multiple times based on the simulation data, so that the driver behavior strategy model can be ensured to generate a driver behavior strategy close to the real driving behavior, and more driving behaviors can be explored, and meanwhile, the generalization capability of the driver behavior strategy model is improved, and the diversity and the authenticity of the generated driver behavior strategy are improved.",['G06F30/20']
CN118864690A,High-fidelity 3D image reconstruction method based on brain EEG signals,"The invention relates to a high-fidelity 3D reconstruction method based on brain EEG signals, which comprises the steps of firstly obtaining fine characteristics of brain activities through EEG associated characteristics which are reconstructed by facing 3D image signals so as to realize accurate coding of visual perception or imagination contents of participants; then, mapping EEG signals to 2D images, and performing fine adjustment on the pre-trained 2D image generation module and the CLIP model by utilizing the characteristics obtained by encoding so as to realize imaging expression of EEG signal semantics and obtain the pre-trained 2D image generation module; finally, combining the pre-trained 2D image generation model with a 3D representation technology, parameterizing the 3D scene through a joint loss function to realize visual mapping from EEG signal coding features to specific 3D images, and generating the 3D image with high fidelity and rich details. The invention generates the corresponding 3D image through EEG signals generated by the participants on the object, and provides a new visual angle and tool for the research in the fields of cognitive science, psychology and neuroscience.","['G06T15/205', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06T11/00', 'G06T17/00', 'G06T7/70', 'G06T2207/30244', 'G06T2211/441']"
US20240420205A1,Using generative artificial intelligence to optimize product search queries,"Methods and systems are provided for using generative AI to optimize product search queries. In embodiments described herein, product descriptions and product images for a plurality of products are obtained. A multi-modal style classification model classifies each product into a corresponding style of a plurality of styles based on the product's product description and product image. Relationships of each product to other products in the plurality of products are stored in a knowledge graph based on the corresponding style of each product and the corresponding product description of each product. An image is generated by a text-to-image diffusion model with a set of products of the plurality of products based on the relationships of each product of the plurality of products to other products in the plurality of products.","['G06T11/00', 'G06Q30/0625']"
WO2025081021A1,Systems and methods for material-related determination models,"Systems, computer program products, and methods are described herein for material- related determination models. With reference to an example method, the method receives a first dataset including one or more first data entries associated with a material, generates a second dataset including one or more second data entries associated with the material, and outputs the second dataset associated with the material. The one or more first data entries include a material identifier, and generating the second dataset includes providing material identifier data and material composition data to an artificial intelligence (AT) model, simulating the material composition data in a first set of contextual conditions, generating one or more material properties, via the simulation, of the material in the first set of contextual conditions, and generating the second dataset including one or more second data entries associated with the one or more material properties for the material.","['G06F30/12', 'G06F30/13', 'G06F30/27', 'G06N20/00', 'G06N3/04', 'G06Q10/063', 'G06Q10/06313', 'G06Q50/08']"
US20240403343A1,Building management system with building equipment servicing,"A building management system (BMS) can include one or more memory devices storing instructions thereon that can, when executed by one or more processors, cause the one or more processors to receive a plurality of information, generate a data model to represent the plurality of information in a common format associated with the BMS, execute a pre-processing routine, receive a query that corresponds to a building associated with the BMS, identify a given vector embedding of a plurality of vector embeddings that correlates to first information associated with the building, generate a response to the query that includes at least one of a graphical representation of the first information associated with the building or a textual summary of the first information associated with the building.","['G05B15/02', 'G06F16/3347', 'G05B13/028', 'G06F16/345', 'G05B2219/2642']"
CN119299806A,A method and system for creating AIGC multimodal audiovisual content,"The invention discloses AIGC multi-mode audiovisual content creation method and system, which belong to the technical field of multi-mode audiovisual content creation and automatic creation, and comprise an input module, a AIGC generation module, a video intelligent editing module, an output module and a media format, wherein the input module is used for inputting text description and materials required by creation by a user, the AIGC generation module is used for converting the text description and the materials input by the user into video sequences and music fragments, the multi-mode fusion and alignment module is used for fusing and aligning the generated video sequences and the music fragments to obtain audios and videos, the video intelligent editing module is used for splicing the audios and videos and keeping visual continuity and smooth connection between the two audios and videos, and the output module is used for outputting the generated audios and videos into the media format required by the user. The method solves the problems that in the prior art, the multi-mode audiovisual content creation lacks the capacity of cross-mode collaborative work, the generated content is inconsistent in rhythm, semantics and emotion during multi-mode information fusion and alignment, lacks the support of a later editing process, is not natural enough during content connection, and has low creation speed.","['H04N21/854', 'G06F40/205']"
US12161698B2,Synthetic platelets,"A synthetic platelet including a biocompatible flexible nanoparticle, the nanoparticle having an outer surface and a plurality of site targeted peptides conjugated to the surface, the synthetic platelet also including a therapeutic agent, wherein the therapeutic agent is encapsulated by the nanoparticle, wherein the synthetic platelet adheres to the site targeted and promotes delivery of the therapeutic agent onto sites of the synthetic platelet adhesion, and wherein the therapeutic agent is released at the site targeted via a site-relevant enzyme.","['A61K38/39', 'A61K38/00', 'A61K38/177', 'A61K38/1774', 'A61K38/185', 'A61K47/62', 'A61K47/6911', 'A61K9/0019', 'A61K9/127', 'A61K9/1271', 'A61K9/19', 'A61K9/4825', 'C07K14/195', 'C07K14/70596', 'C07K14/745', 'C07K14/78', 'B82Y5/00']"
CN117496025B,Multi-mode scene generation method based on relation and style perception,"The invention discloses a multi-mode scene generation method based on relation and style perception, which is applied to the technical fields of computer vision and 3D multi-mode. And (3) enhancing context relation information of scene graph data by using a multi-mode large model-CLIP, and simultaneously adopting a double-flow structure based on a graph convolution neural network to respectively predict scene layout and corresponding 3D shape. Wherein in the shape branch, an implicit diffusion model is selected as a generation model, and a decoder decodes the relational shape embedding as its implicit condition. The user may enter style text, for example: chinese wind, middle century wind, european style, etc., then the generated shape prior and nerve radiation field are utilized, CLIP is used as guidance in optimization, and finally a fine-grained 3D scene is obtained. The method can realize controllable scene generation and style perception through the scene graph and the style text input by the user, and solve the defects of the existing scene generation method.","['G06T15/005', 'G06N3/0464', 'G06N3/08', 'G06T15/04', 'G06T17/00']"
US20240331071A1,Machine learning systems and methods for building security recommendation generation,"Systems and methods are disclosed relating to autonomous building security recommendation generation. For example, a method can include receiving, by one or more processors, sensor data from one or more sensors associated with a building system. The method can further include determining, by the one or more processors using a machine learning model and the sensor data, a recommended action for an operator to perform, the machine learning model trained using training data comprising data retrieved from one or more data sources maintained by at least one of a first entity associated with the building system or a second entity associated with the one or more sensors. The method can further include presenting, by the one or more processors using at least one of a display device or an audio output device, a notification corresponding to the recommended action.","['G06Q50/265', 'G08B13/04', 'G08B13/08', 'G08B13/1436']"
US20240221308A1,3d dental arch model to dentition video correlation,"A method includes receiving a selection of an image of a face of an individual from a plurality of images of the face of the individual, determining an orientation of a jaw of the individual in the selected image, and updating an orientation of a three-dimensional (3D) model of a dental arch of the individual to match the orientation of the jaw of the individual in the selected image.","['G06T17/00', 'G16H50/50', 'G06T11/00', 'G06T19/20', 'G06T7/0012', 'G06T7/11', 'G06T7/13', 'G06T7/174', 'G06T7/90', 'G16H30/40', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/30036', 'G06T2207/30168', 'G06T2219/2012', 'G06T2219/2016']"
WO2024182169A1,Prompt modification for automated image generation,"Examples disclosed herein describe prompt modification techniques for automated image generation. An image generation request comprising a base prompt is received from a user device. A plurality of prompt modifiers is identified. A processor-implemented scoring engine determines, for each prompt modifier, a modifier score. The modifier score for each prompt modifier is associated with the base prompt. One or more of the prompt modifiers are automatically selected based on the modifier scores. A modified prompt is generated. The modified prompt is based on the base prompt and the one or more selected prompt modifiers. The modified prompt is provided as input to an automated image generator to generate an image, and the image is caused to be presented on the user device.","['G06F3/04845', 'G06V10/993', 'G06F40/30', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T11/00', 'G06V10/82', 'G06V20/30', 'G06F40/12', 'G06F40/216', 'G06F40/279', 'G06T2200/24']"
US20240386040A1,Building management system with building equipment service and parts recommendations,"A method includes fine-tuning at least one large language model (LLM) using building domain data comprising information regarding equipment types, equipment parameters, and output conditions, facilitating generation of an input query for the at least one LLM by providing an interactive interface configured to guide input of a relevant equipment type, a relevant equipment parameter, a relevant output condition, and a request type by a user and generating the input query based on the input of the relevant equipment type, the relevant equipment parameter, the relevant output condition, and the request type, and providing a response to the input query as an output of the at least one LLM by using the input query as an input to the LLM.","['G06Q10/20', 'G06F16/3329', 'G06Q30/012']"
CN118037711A,An image anomaly detection method based on self-supervised learning and diffusion generation model,"The invention discloses an image anomaly detection method based on a self-supervision learning and diffusion generation model, which comprises the following steps: s1: acquiring a normal image sample and preprocessing the normal image sample to be used as a training sample; s2: sending the training sample into a diffusion generation model, defining a noise prediction loss function, and continuously updating noise prediction network parameters through back propagation until training is completed; step S3: acquiring a normal sample, preprocessing, and simultaneously, synthesizing pseudo-anomalies by utilizing an anomaly data set to serve as a training sample of the segmentation network; step S4: the training sample in the step S3 is sent into a diffusion generation model for reasoning to obtain a reconstructed sample; step S5: splicing the original training samples and the reconstructed samples in the step S4, sending the spliced samples and the reconstructed samples into a segmentation network, defining a loss function, and continuously updating network parameters through back propagation until training is completed; step S6: obtaining a test sample, preprocessing the test sample, sending the test sample into a diffusion generation model to obtain a reconstructed sample, and splicing the reconstructed sample with the preprocessed test sample; the segmentation results are post-processed to obtain image-level and pixel-level anomaly detection results. The diffusion model is used for image reconstruction, so that the quality of image reconstruction is improved; by adopting a random step number noise adding method, the model can simultaneously give consideration to the overall characteristics and detail characteristics of reconstruction. Meanwhile, the invention additionally adds a segmentation network based on the traditional image reconstruction method, and builds a self-supervision learning task for the segmentation network through pseudo-anomaly generation, thereby realizing more accurate anomaly detection and positioning effects.","['G06T7/0002', 'G06N3/045', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
WO2024173597A2,Atrial flutter classification system,"A system for generating a machine learning (ML) model to identify an atrial flutter (AFL) type of a cardiac arrhythmia is provided. For each of a plurality of cardiograms, the system generates training data by identifying one or more portions of that cardiogram that relate to the AFL type to which that cardiogram is mapped. For each of a plurality of the portions, the system generates a feature vector that includes the portion and the additional features and a label that is based on the AFL type. The system trains the ML model using the training data to learn weights for the ML model. The ML model inputs a cardiogram and additional features and outputs an AFL type.","['G16H50/20', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'G16H50/70']"
KR102592596B1,System and method for generating human model automatically based on artificial intelligence,"Provided are a system and method for automatically generating a human model based on artificial intelligence, which may implement a more user-friendly human model in real time and thus enhance the purchasing power of fashion items. The system for automatically generating a human model based on artificial intelligence according to one embodiment of the present invention comprises: a first wearing image input unit which receives a first wearing image in which a fashion item is worn; a human model estimation unit which analyzes the first wearing image to determine a body part in the first wearing image and analyzes a type, style, and color of the fashion item to estimate a virtual human model expected to maximize the sales of the fashion item; a second wearing image generation unit which synthesizes the human model in the body part in the first wearing image to generate a second wearing image; and an advertisement page rendering unit which inserts the second wearing image into a set advertisement page to be rendered on a user terminal. The human model estimation unit estimates the human model based on the number of clicks of the second wearing image inserted into the advertisement page.","['G06Q30/0643', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06Q30/02', 'G06Q30/0242', 'G06Q30/0277', 'G06Q30/06', 'G06T11/60', 'G06T13/40']"
CN117615075A,"Watermark adding and watermark identification method, device, equipment and readable storage medium","The embodiment of the application provides a watermark adding and watermark identifying method, device, equipment and readable storage medium; the method comprises the following steps: acquiring information to be processed; inputting information to be processed into a first generation model to obtain first multimedia content; the first multimedia content comprises preset watermark information; wherein the first generation model and the identification model are obtained by combined training; the authentication model is used to authenticate whether the multimedia content is generated for the first generation model.","['G06N3/045', 'G06N3/098', 'H04N1/32165', 'H04N1/32288', 'H04N1/32352']"
CN119548117B,MPI magnetic particle imaging method and system for early detection of AD patients,"The invention belongs to the technical field of magnetic nanoparticle imaging, in particular relates to an MPI magnetic particle imaging method and system for early detection of AD patients, and aims to complete MPI time sequence imaging by using a diffusion model and solve the problem that the characteristic dimension of an input signal in the diffusion model is not matched with the resolution of an expected generated image. The method comprises the steps of constructing a generating network model, training in stages, collecting MPI time sequence one-dimensional signals, carrying out image reconstruction based on the generating network model to obtain MPI time sequence images, registering and dividing brain areas, constructing a functional connection diagram and a functional connection matrix by utilizing RV coefficients, and drawing a brain network. According to the invention, the step network of the Seq-VAE/Regression/Sig-LDM is constructed and trained in stages, so that the signal sequence with fixed characteristic dimension is freely input, the image sequence reconstruction effect is improved, and the default mode network is drawn based on the reconstructed image sequence, so that accurate data is provided for subsequent application.","['G06N3/0475', 'A61B5/0515', 'A61B5/4064', 'A61B5/4088', 'A61B5/7203', 'A61B5/7267', 'G06N3/08', 'G06N5/04', 'G06T17/00', 'G06T5/60', 'G06T5/70']"
CN109978850A,A kind of semi-supervised deep learning segmenting system of Multimodal medical image,"The invention discloses a kind of semi-supervised deep learning segmenting systems of Multimodal medical image, it include: data collection module, it is labeled for collecting the different modalities i.e. image data of multichannel, and to the area-of-interest in one of modality images, and splits data into training set and test setï¼Model construction module for realizing the building of parted pattern, and is trained training setï¼Test module realizes segmentation test function for test set data input model to be split.Present system can quickly, accurately and efficiently realize the segmentation of multi-mode image area-of-interest.","['G06F18/2155', 'G06T7/0012', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/032']"
US20240265505A1,Multimodal diffusion models,"Systems and methods for image processing are described. Embodiments of the present disclosure obtain a noise image and guidance information for generating an image. A diffusion model generates an intermediate noise prediction for the image based on the noise image. A conditioning network generates noise modulation parameters. The intermediate noise prediction and the noise modulation parameters are combined to obtain a modified intermediate noise prediction. The diffusion model generates the image based on the modified intermediate noise prediction, wherein the image depicts a scene based on the guidance information.","['G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN119295647A,Self-supervised diffusion method and system for generating view-consistent 3D Gaussians,"The invention provides a self-supervision diffusion method and a system for generating a three-dimensional Gaussian with consistent views, which relate to the technical field of image recognition, and the method comprises the steps of obtaining an input image, performing geometrically consistent multi-view generation on the input image, and obtaining a refined multi-view image; generating a geometric correlation priori based on the input image and the multi-view image, taking the geometric correlation priori as geometric supervision of a preset three-dimensional Gaussian model, optimizing the preset three-dimensional Gaussian model to obtain a final three-dimensional Gaussian model with consistent view, and rendering the final three-dimensional Gaussian model to obtain a high-fidelity image result. The present invention aims to develop an efficient solution to achieve view-consistent and high quality three-dimensional generation.","['G06T17/00', 'G06N3/0895', 'G06T15/00']"
WO2024127316A1,Autoencoders for the processing of 3d representations in digital oral care,"Systems and techniques for encoding and reconstructing three-dimensional (3D) representations of oral care data are disclosed. The method involves receiving an input 3D representation of oral care data and utilizing the processing circuitry to execute an encoder of a trained autoencoder network. The encoder encodes the input 3D representation into a latent space representation with a lower dimensionality. Subsequently, the processing circuitry executes a decoder of the trained autoencoder network to reconstruct the latent space representation, generating an output 3D representation that closely resembles the original input. To quantify the accuracy of the reconstruction, the processing circuitry computes a reconstruction error, which measures the difference between at least one mesh element of the input 3D representation and the corresponding mesh element of the output 3D representation. Efficient encoding and reconstruction of 3D representations of oral care data, facilitating improved analysis, diagnosis, and treatment planning in oral care applications is realized.","['G06T17/00', 'G06T2210/41']"
WO2025118634A1,"Video generation method, electronic device, and computer readable storage medium","Provided are a video generation method, an electronic device, and a computer readable storage medium, relating to the technical fields of computers and video processing. The video generation method comprises: acquiring a target text, wherein the target text is used for describing video content to be generated (S21); and using a target video generation model to perform video generation processing on the target text to obtain a target video, wherein the target video generation model is a model obtained by performing model alignment on an initial video generation model and a preset reward model in a fine-tuning manner (S22). The present invention solves the technical problems in the related art that a video generated by a video generation model obtained by training based on network data has poor quality and does not meet user expectations.","['G06F16/7844', 'G06F16/7335', 'G06F16/74', 'G06F3/04842', 'Y02T10/40']"
WO2019011577A1,Membrane-coupled cathode for the reduction of carbon dioxide in acid-based electrolytes without mobile cations,"The invention relates to a method for the electrolysis of CO2, wherein the electrolytic cell has a salt bridge space, having a fluid and/or dissolved acid, said electrolytic cell comprising: a cathode chamber having a cathode; a first ion exchanger membrane containing an anion exchanger and/or an anion transporter and adjacent to the cathode chamber, wherein the cathode directly contacts the first ion exchanger membrane; an anode chamber having an anode; and a diaphragm adjacent to the anode chamber; wherein a salt bridge space is also provided, which is arranged between the first ion exchanger membrane and the diaphragm. The invention also relates to an electrolysis system comprising the electrolytic cell, and the use of the electrolytic cell or the system for the electrolysis of CO2.","['C25B9/23', 'C25B1/00', 'C25B9/19', 'C25B9/63']"
WO2024127309A1,Autoencoders for final setups and intermediate staging in clear tray aligners,"Systems and techniques for generating transforms from three-dimensional (3D) representations of oral care data are disclosed. The method involves receiving a first 3D representation of oral care data and providing it as input to a trained autoencoder network. The processing circuitry executes the trained autoencoder network to encode the first 3D representation into one or more latent space representations with a lower dimensionality. These latent space representations are then reconstructed into a second 3D representation that closely resembles the original input. The processing circuitry further provides the latent space representations to a trained machine learning (ML) model, distinct from the autoencoder network. By executing the trained ML model, a transform is generated. These systems and techniques enable the generation of accurate and efficient transforms from 3D representations of oral care data, facilitating improved analysis, diagnosis, and treatment planning in oral care applications.","['G06T19/20', 'G06V10/467', 'G06T2210/41', 'G06T2219/2021']"
US12079292B1,Proactive query and content suggestion with generative model generated question and answer,"Systems and methods for proactive query and content suggestion can include obtaining web data, determining a change event occurred, and generating a query and content suggestion. Generating the query and content suggestion can include processing data descriptive of the change event with a generative model to generate one or more model-generated query suggestions. One or more web resources can be obtained then processed to generate a change event summary. The one or more query suggestions and the change event summary can then be provided for display.","['G06F16/9535', 'G06F16/345', 'G06F16/90324', 'G06F16/9532', 'G06F16/9538', 'G06F16/954', 'G06F16/9566', 'G06F16/957', 'G06F40/20', 'G06N3/045', 'G06N3/0475']"
WO2024167651A1,Enhancement of machine-generated product image,"Methods, systems, and computer programs are presented for enhancing a machine-generated product image. One method includes an operation for receiving a. request on a user interface (UI) to generate an image, where the request comprises a description of the image to be generated and identification of a product for inclusion in the image. The method further includes operations for generating, by a generative artificial intelligence (GAI) model, a first image based on the request., analyzing the first image to identify a presentation of the product- in the first image, and selecting a product image from a database of product images based on the identification of the product. The method further includes replacing the presentation of the product in the first image with the selected product image to obtain a. second image, and causing presentation in the UI of the second image.","['G06Q30/0643', 'G06T11/60', 'G06N3/0475']"
US20240193729A1,Systems and Methods for Synthetic Image Generation based on RNA Expression,"Systems and methods for synthetic image generation include a method of generating synthetic histological slide images that includes translating each of several RNA-Seq records into a latent space, training a first diffusion model to produce a first synthetic histological slide image at a lower resolution using the translated RNA-Seq records and associated histological slides, training a second diffusion model to upscale lower resolution synthetic histological slide images produced by the first diffusion model to higher resolution synthetic histological slide images, obtaining a given RNA-Seq record, translating the given RNA-Seq record into the latent space, providing the latent representation of the given RNA-Seq record to the trained first diffusion model to generate a given lower resolution synthetic histological slide image, and providing the given lower resolution synthetic histological slide image to the trained second diffusion model to generate a given higher resolution synthetic histological slide image.","['G06T3/4053', 'G06T3/4046', 'G06T5/50', 'G16B35/20', 'G16B40/00', 'G06T2207/10056', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US20240169623A1,Multi-modal image generation,Systems and methods for multi-modal image generation are provided. One or more aspects of the systems and methods includes obtaining a text prompt and layout information indicating a target location for an element of the text prompt within an image to be generated and computing a text feature map including a plurality of values corresponding to the element of the text prompt at pixel locations corresponding to the target location. Then the image is generated based on the text feature map using a diffusion model. The generated image includes the element of the text prompt at the target location.,"['G06T11/60', 'G06F40/295', 'G06T7/11', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084']"
WO2025021719A1,Forecasting of subject-related attributes using generative machine-learning models,"A computer-implemented method of predicting, simulating, or forecasting values of one or more specified subject-related attributes during a clinical trial comprises: receiving input data comprising: a medical history of a subject, the medical history comprising values of a plurality of subject-related attributes of a subject; and data specifying a requested output, the data comprising: the one or more specified subject-related attributes of the subject and a time frame; and applying a trained generative machine-learning model to the received input data, the trained generative machine-learning model configured to generate output data based on the input data, the output data comprising: respective values of the one or more specified subject-related attributes of the subject in the specified time frame.","['G16H10/20', 'G06F16/81', 'G06F16/9017', 'G06N3/0455', 'G06N3/0475', 'G06N3/09', 'G06N3/096', 'G16H20/10', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G16H70/40']"
CN118298087A,Method and device for generating three-dimensional portrait from text based on GAN priori,"The invention discloses a method and a device for generating a three-dimensional portrait from text based on GAN priori, which belong to the technical field of three-dimensional portrait generation and comprise the following steps: training can generate three-dimensional perception GAN of a rough three-dimensional portrait, and the three-dimensional perception GAN is used as a priori for generating a high-quality three-dimensional portrait; inputting the text prompt into a diffusion model to generate a two-dimensional portrait image conforming to the text prompt; projecting the two-dimensional portrait image into the hidden space of the trained three-dimensional perception GAN model to obtain an optimal hidden code, and generating a target three-dimensional representation according to the optimal hidden code; distilling knowledge of the diffusion model into a target three-dimensional representation through fractional distillation sampling to obtain a target three-dimensional portrait; rendering the target three-dimensional portrait to obtain a rendering chart, and further optimizing the target three-dimensional portrait as training data after the rendering chart is optimized by a diffusion model to obtain a high-quality three-dimensional portrait. The method provided by the invention can generate the three-dimensional portrait which has high quality, consistent view, reality and consistent with the prompt of the input characters.","['G06T15/005', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06N3/096', 'G06T11/60', 'G06T17/00']"
CN117131271A,Content generation method and system,"In the content generation process, target prompt data input by a target object and a content template set corresponding to the target object are obtained, wherein the content template set is obtained based on a plurality of historical content generation data of the target object; matching the target prompt data with the content template set, and determining a target content template from the content template set; in the process of generating the target content, the target content template is used as a reference for content generation based on the target prompt data at the same time, and the target content is generated. The method and the system can adaptively select the matched historical data from the historical data of the target object as the reference template, so that the individuation and controllability of the generated content are ensured while the content generation efficiency is improved.","['G06F16/9535', 'G06F16/3329', 'G06F40/186', 'G06F40/30', 'G06N3/04', 'G06N3/08']"
CN117710349A,Small sample surface defect image generation method and system based on feedback reinforcement learning,"The invention discloses a method and a system for generating a small sample surface defect image based on feedback reinforcement learning, wherein the method comprises the following steps: acquiring a small amount of surface defect image samples, marking semantic tags, and constructing a training set; constructing a conditional diffusion model, and training the conditional diffusion model by using a training set to finish preliminary fine adjustment of the conditional diffusion model; expanding semantic tags, and generating a plurality of initial surface defect images under each semantic tag by using the trimmed conditional diffusion model; manually scoring the plurality of initial defect images under each semantic label to construct an evaluation data set; constructing a reward model, and training the reward model by using an evaluation data set; expanding semantic tags, constructing a semantic tag library, and generating an optimal surface defect image corresponding to each semantic tag based on a reward model secondary optimization condition diffusion model. The invention can effectively improve the generation performance of the surface defect image sample and the data enhancement capability.","['G06T7/0004', 'G06N3/0464', 'G06N3/092', 'G06V10/764', 'G06V20/70', 'Y02P90/30']"
CN118587369B,"Point cloud image data generation method, device, equipment, medium and program product","The invention provides a point cloud image data generation method, a device, equipment, a medium and a program product, and relates to the field of automatic driving, wherein the method comprises the following steps: after obtaining road scene data, inputting the road scene data into a preset potential diffusion model for processing to obtain output three-dimensional scene data; the potential diffusion model is a model which is obtained based on historical road scene data training and is used for learning corresponding three-dimensional scene data; constructing a three-dimensional scene based on the three-dimensional scene data; acquiring initial point cloud data corresponding to the three-dimensional scene based on a ray projection result of ray projection on the three-dimensional scene; and fusing the initial point cloud data with the time dimension information to obtain target point cloud data based on a time sequence. By the method, the problem of insufficient sparsity and diversity of point cloud data can be effectively solved, and powerful data support is provided for an automatic driving system.","['G06T17/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/084']"
WO2025176167A1,"Virtual try-on method and apparatus, and storage medium","A virtual try-on method and apparatus, and a storage medium. The method comprises: acquiring a clothing image to be subjected to try-on and a first model image; on the basis of the clothing image to be subjected to try-on, determining a target clothing image; on the basis of the first model image, determining a try-on area image and a first key point, wherein a try-on area comprises an area of model clothing, a body area which is in contact with the model clothing, and a background area which is in contact with the model clothing; and on the basis of the target clothing image, the try-on area image and the first key point, generating a try-on effect image by means of a trained diffusion model.",[]
CN116958326A,"Image editing method, device, electronic equipment and storage medium","The application discloses an image editing method, an image editing device, electronic equipment and a storage medium, and relates to the technical field of image processing. The method comprises the following steps: the method comprises the steps of obtaining an image to be edited and a target text, carrying out image reconstruction on the image to be edited based on the target text, carrying out fine adjustment on the target text based on image reconstruction loss in the image reconstruction process, obtaining a fine-adjusted target text, obtaining an attention feature map corresponding to the image to be edited based on the fine-adjusted target text, and carrying out editing processing on the image to be edited based on the attention feature map to obtain a target image. According to the application, the target text fine adjustment and the attention feature map editing are combined to obtain the target image, so that the controllable image editing is realized according to the target text, and the user requirement in actual application is met.",['G06T11/60']
CN118248318A,Early intelligent brain disease classifying and screening system based on multi-mode calculation,"The invention relates to a brain disease early intelligent classification screening system based on multi-modal calculation. The method comprises the steps that a multi-mode data acquisition unit acquires multi-mode data of a target patient under a specified screening level to form a screening data set; the multi-modal feature generation completion and fusion calculation unit generates and completes feature data of each modal feature in the screening data set to obtain complete modal features, extracts pathological features and calculates to obtain a first screening result; the knowledge intelligent screening unit encodes feature data of each modal feature in the screening data set into corresponding graph structure data features, matches the graph structure data features by utilizing the multi-modal associated graph optimized by expert knowledge to obtain knowledge associated features, and obtains a second screening result according to the knowledge associated features; and the intelligent grading screening unit performs weighted calculation on the first screening result and the second screening result to obtain a final screening result. Early screening of patients for brain disease with accuracy is achieved herein.","['G16H50/20', 'G06F18/213', 'G06N5/022', 'G16H50/30', 'A61B6/501', 'A61B6/506']"
CN116976461A,"Federal learning method, apparatus, device and medium","The present disclosure provides a federal learning method, apparatus, device, and medium. Relates to the technical field of data processing, in particular to the technical fields of artificial intelligence, deep learning and the like. The specific implementation scheme is as follows: acquiring performance parameters of a plurality of edge devices; performing cluster analysis on the plurality of edge devices based on performance parameters of the plurality of edge devices to obtain a plurality of device clusters; performing knowledge distillation on the cloud global model for a plurality of equipment clusters to distill out a plurality of first sub-models; and distributing the plurality of first sub-models to corresponding equipment cluster groups for federal learning. Aiming at the heterogeneous edge model, the embodiment of the disclosure can divide a plurality of equipment cluster groups through cluster analysis, and train the adaptive model for different equipment cluster groups by distilling through a knowledge distillation mode, so that the communication burden can be reduced.","['G06N20/00', 'G06F18/214', 'G06F18/23213', 'G06F18/24', 'G06F18/25']"
US20230208858A1,"Automated cyberattack detection using time-sequential data, explainable machine learning, and/or ensemble boosting frameworks","Various embodiments of the present disclosure provide systems, methods, and computer program products for detecting unauthorized memory access cyberattacks, such as Spectre and Meltdown, which are intended to maliciously reveal information stored in concealed or restricted memory of a targeted device.",['H04L63/1416']
CN118948293A,A method for generating electrocardiograms based on diffusion model to synthesize customizable cardiac cycles,"An electrocardiogram generating method capable of customizing heart cycle based on diffusion model synthesis relates to an electrocardiogram generating method, and aims to solve the problems that electrocardiogram signals generated by the existing electrocardiogram generating method are unbalanced in data, poor in privacy protection and incapable of generating specific pathological signals. The invention takes an electrocardiogram semantic tag as a condition input, and simultaneously inputs noise and diffusion time steps to a depth generation model to generate an electrocardiogram; the depth generation model takes a diffusion model as an overall framework, introduces a converter model to learn long-term dependency in electrocardiogram signals, and simultaneously introduces a semantic electrocardiogram batch normalization module to accurately learn local ECG semantic features. The method has the beneficial effects that the generated electrocardiogram signal can accurately follow provided electrocardiogram semantic information, and the electrocardiogram with true physiological significance is customized, so that the problem of data unbalance can be solved, and the privacy protection is strong.","['A61B5/318', 'A61B5/353', 'A61B5/355', 'A61B5/366', 'A61B5/7203', 'A61B5/7225', 'A61B5/7232', 'A61B5/7264', 'G06F18/22', 'G06F18/251', 'G06N3/0464']"
CN118709746A,"Generative model optimization method and device, electronic device and storage medium","The disclosure relates to a method and a device for generating model optimization, an electronic device and a storage medium, wherein the method comprises the following steps: acquiring a plurality of weight data stored in a plurality of checkpoints of a generating model to be optimized, wherein the weight data stored in each checkpoint comprises all weights of the generating model in each checkpoint; dividing the weight data of each check point into a plurality of weight groups to obtain a plurality of weight groups corresponding to each check point; searching a target coefficient combination which optimizes the image quality generated by the generation model from a designated coefficient search space; and based on the target coefficient combination, carrying out weighted summation on each weight group divided by the weight data of the checkpoints to obtain target weight data of the generating model so as to execute a text-generated graph or text-generated video task by using the generating model with the target weight data. Therefore, the model performance of the generated model is effectively improved, and the image quality of an image or video generated by the generated model is improved.","['G06N3/086', 'G06N3/0475', 'G06T11/00', 'H04N21/854']"
US20250225659A1,Method and apparatus with machine learning based image processing,"A method and apparatus will machine learning-based image processing is provided. The method includes generating a plurality of output images using a generative model that is provided a raw image of an image sensor, generating, using a machine vision model that is provided the plurality of output images, plural output data respectively corresponding to the plurality of output images, generating result data of the machine vision model by performing an ensemble on the plural output data.","['G06T7/10', 'G06N3/0475', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N3/094', 'G06V10/82', 'G06T2207/20084']"
CN118842975A,"Digital human video generation method, device, equipment and medium","The application discloses a digital human video generation method, a device, equipment and a medium, which relate to the technical field of computers and comprise the following steps: acquiring a target speaking object image and target audio data in a consultation dialogue scene; inputting the target speaking object image and the target audio data into a target digital human model, and predicting a key point sequence according to the target audio data through the target digital human model so as to obtain a target key point sequence for controlling the head action and the upper body limb action of the digital human speaking; and controlling and synthesizing continuous digital human videos through the target digital human model according to the target key point sequence, the target speaking object image and the audio characteristics of the target audio data. The limb actions and the head gestures are fused into an audio-driven diffusion network, so that the generated digital human video fully considers the audio and action interaction in a dialogue scene and the time sequence information provided by the audio.","['H04N21/816', 'G10L15/26', 'H04N21/4394', 'H04N21/4415', 'H04N21/4758', 'Y02T10/40']"
WO2024124261A2,Learned image compression by ai generated content,"A method implemented by a decoder. The method includes receiving a vision-language control latent feature, a vision-language latent feature of an original image, and a diffusion latent feature of the original image, where the vision-language latent feature comprises text and integers; computing, based on the vision-language latent feature, a decoded vision-language feature; computing, based on the vision-language control latent feature and the decoded vision-language feature, an encoded control feature; reconstructing, based on the encoded control feature and the decoded vision-language feature, a baseline image output; computing, based on the diffusion latent feature, the encoded control feature, and the decoded vision-language feature, a supplementary output; and reconstructing, based on the supplementary output and the baseline image output, a final decoded image output.","['H04N19/59', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'H04N19/46', 'H04N19/80']"
CN117649344B,"Magnetic resonance brain image super-resolution reconstruction method, device, equipment and storage medium","The application relates to a magnetic resonance brain image super-resolution reconstruction method, a device, equipment and a storage medium. The method comprises the following steps: based on the bidirectional reconstruction loss and the countermeasures loss of the brain image data of each mode in the training set, training to obtain a decoupling self-encoder of the brain image of each mode; respectively inputting the target modal brain image and the auxiliary modal brain image into a decoupling self-encoder of a corresponding mode, and extracting target coding information of the target modal brain image and auxiliary coding information of the auxiliary modal brain image; forward and reverse noise processing is carried out based on the target coding information and the auxiliary coding information, and updated target coding information of the target modal brain image is generated; and inputting the updated target coding information into a decoupling self-encoder of the target modal brain image, and outputting the target modal super-resolution brain image. The method solves the problems of low brain image reconstruction quality and high complexity in the prior art, realizes super-resolution brain image reconstruction, and improves the accuracy and the authenticity of the reconstructed brain image.","['G06T3/4053', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20221', 'G06T2207/30016']"
US20250078446A1,System and a method for detecting computer-generated images,"A system and a method for detecting computer-generated images. The system includes an image processing engine arranged to analyze an input digital image embedded with image traces created during generation and/or post-generation processing operation of the input digital image, and to determine whether the input digital image is a computer-generated image or a natural photographic image based on the analysis of the image traces.","['G06T7/0002', 'G06V10/771', 'G06N3/0464', 'G06T7/12', 'G06T7/40', 'G06V10/26', 'G06V10/30', 'G06V10/42', 'G06V10/44', 'G06V10/56', 'G06V10/82', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US20250022099A1,Systems and methods for image compositing,"Systems and methods for image compositing are provided. An aspect of the systems and methods includes obtaining a first image and a second image, wherein the first image includes a target location and the second image includes a target element; encoding the second image using an image encoder to obtain an image embedding; generating a descriptive embedding based on the image embedding using an adapter network; and generating a composite image based on the descriptive embedding and the first image using an image generation model, wherein the composite image depicts the target element from the second image at the target location of the first image.","['G06T1/0021', 'G06T5/50', 'G06T5/70', 'G06T9/00', 'G06T2207/20081', 'G06T2207/20221']"
US20240394281A1,Artificial intelligence generated correlators for building digital twin,"A building system can include one or more storage devices storing instructions thereon, that, when executed by one or more processors, cause the one or more processors to generate a building graph, the building graph including nodes representing entities of a building and edges between the nodes, the edges representing relationships between the entities. The building system can execute an artificial intelligence service, the artificial intelligence service to receive at least one of data describing the entities, at least one node of the nodes, or at least one edge of the edges as an input and output a correlator type that identifies that a first entity type of a first entity of the entities impacts a second entity type of a second entity of the entities. The building system can update the building graph to include data representing a correlator based on the correlator type.","['G06F16/243', 'G06F16/248', 'G06F16/288', 'G06F16/9024']"
US20250104290A1,Automatic image generation using latent structural diffusion,Examples described herein relate to automatic image generation. A plurality of inputs is accessed. The inputs include first input data and second input data. The first input data includes a text prompt describing a desired image and the second input data is indicative of one or more structural features of the desired image. One or more intermediate outputs are generated via a first generative machine learning model that uses the plurality of inputs as first control signals. An output image is generated via a second generative machine learning model that uses at least a subset of the plurality of inputs and at least a subset of the one or more intermediate outputs as second control signals. The output image is presented at a user device of a user.,"['G06V10/44', 'G06T11/00']"
WO2024072749A1,Retrieval augmented text-to-image generation,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating an output image using a text-to-image model and conditioned on both the input text and image and text pairs selected from a multi-modal knowledge base. In one aspect, a method includes, at each of multiple time steps: generating a first feature map for the time step; selecting one or more neighbor image and text pairs based on their similarities to the input text; for each of the one or more neighbor images and text pairs, generating a second feature map for the neighbor image and text pair; applying an attention mechanism over the one or more second feature maps to generate an attended feature map; and generating an updated intermediate representation of the output image for the time step.","['G06F16/783', 'G06N3/042', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06T11/006', 'G06N3/082', 'G06T2211/456']"
CN118702074A,A helium recovery and purification method and purification device used in the process,"The application discloses a helium recovery and purification method and a purification device used in the process, wherein the method comprises the following steps: intelligent pretreatment is carried out on helium-containing industrial waste gas; recovering waste heat of the helium-containing industrial waste gas by utilizing a multi-stage heat recovery system; removing impurities from the helium-containing industrial waste gas using a multistage catalytic reactor system; helium enrichment and preliminary purification are carried out by adopting a gas separation technology; rectifying and purifying helium through a rectifying module; fine purification of helium is realized by using a purification technology; predictive maintenance is performed using an intelligent monitoring and maintenance system.","['C01B23/0094', 'B01D3/14', 'B01D50/00', 'B01D53/06', 'B01D53/229', 'B01D53/30', 'B01D53/32', 'B01D53/40', 'B01D53/42', 'B01D53/523', 'B01D53/58', 'B01D53/68', 'B01D53/75', 'B01D53/78', 'B01D53/82', 'B01D53/869', 'F28D21/0014', 'B01D2257/2045', 'B01D2259/818', 'C01B2210/0003', 'C01B2210/0009', 'C01B2210/001', 'C01B2210/0014', 'C01B2210/0015', 'C01B2210/0057', 'C01B2210/0064', 'C01B2210/0065', 'C01B2210/0068', 'C01B2210/007', 'C01B2210/0071']"
CN118632012A,"Image digital watermark embedding method, extraction method and system","The invention provides an image digital watermark embedding method, an extracting method and a system, wherein an image digital watermark embedding party encodes original secret information to generate binary secret information, acquires a carrier image, superimposes original gauss generated randomly for a plurality of times to obtain potential noise, integrates the binary secret information and the potential noise through an encoder to generate secret-containing potential noise, inputs the secret-containing potential noise into a denoising diffusion implicit model to obtain estimated gauss noise, and generates a target image containing a digital watermark according to the secret-containing potential noise and the estimated gauss noise; the image digital watermark extraction method comprises the steps of inputting a target image into a denoising diffusion implicit model, outputting estimated Gaussian noise, overlapping the estimated Gaussian noise for a plurality of times on the target image to obtain secret-containing potential noise, inputting the secret-containing potential noise into a decoder, outputting binary secret information, restoring the secret information into original secret information, keeping the image semantic consistency before and after embedding the image digital watermark, and improving the quality and the anti-detection capability of the image.","['H04N19/467', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06T9/002', 'H04L1/246']"
CN116630200A,Method and system for denoising medical image feature map based on diffusion model,"The invention provides a medical image feature map denoising method and system based on a diffusion model, and relates to the field of medical image segmentation. Extracting an original feature map from the model; adding Gaussian noise into the original feature map in a progressive manner to obtain a series of noise feature maps; sequentially inputting the finally obtained noise feature images into a plurality of FMD modules connected in series for denoising, obtaining denoising results corresponding to a series of noise feature images, and training the FMD modules by using the noise feature images and the corresponding denoising results; and inputting the original feature map into a trained FMD module for denoising. According to the invention, based on the designed denoising diffusion probability model, denoising processing is carried out on the information of the feature map, so that the medical image segmentation model can more accurately identify the features of organs or focuses; meanwhile, the plug-and-play feature map denoising module can be conveniently combined with various existing medical image segmentation models, the model is not required to be retrained, and development time and cost are greatly saved.","['G06T5/70', 'G06T2207/20081', 'G06T2207/20084', 'Y02T90/00']"
US20240394768A1,Search with Machine-Learned Model-generated Queries,"Systems and methods for searching using machine-learned model-generated outputs can provide a user with a medium for generating a theoretical dataset that can then be matched to a real world example. The systems and methods can include selecting a plurality of terms, which can be utilized to generate a prompt input that can be processed by a dataset generation model to generate a plurality of model-generated datasets. A selection can then be received that selects a particular model-generated database to utilize to query a database.","['G06F16/532', 'G06F16/538', 'G06F16/54', 'G06F16/5854', 'G06N3/0475', 'G06Q30/0621', 'G06Q30/0627', 'G06Q30/0643']"
CN116913436B,A hyperatom reverse design method based on LDM-PNN and particle swarm algorithm,"The invention discloses a super-atom reverse design method based on an LDM-PNN and a particle swarm algorithm, which combines a coder and decoder in a pre-trained LDM model with the particle swarm algorithm on the basis of the PNN model, and searches a global optimal super-atom structure in a potential space based on LDM model coding through the particle swarm algorithm according to a given target spectral response. The invention can not only predict the corresponding spectral response of the super atom, but also realize the reverse design of the super atom to the spectral response, and solve the problem of 'one-to-many' in the reverse design. Compared with the traditional method for reverse design by numerical simulation, the method saves a great deal of manpower time and cost and has accurate design result.","['G16C60/00', 'G06F30/27', 'G06N3/006']"
US20240339217A1,Medical Condition Visual Search,"Systems and methods for diagnostic visual search can include processing a search query with a plurality of classification models to determine a search query intent and predict potential diagnosis. The search query can include an image that is processed to determine the presence of a body part and may be processed to determine if the search query is descriptive of a diagnostic search query. Based on the intent determination, the image may then be processed by a conditions classification model to determine one or more predicted condition classifications. Condition information can then be obtained and provided based on the one or more predicted condition classifications.","['G16H30/40', 'G06T7/0012', 'G16H30/20', 'G16H50/20', 'G16H50/70', 'G06T2207/20104', 'G06T2207/30088']"
US20240354823A1,Personalizing articles using generative artificial intelligence,"A computer-implemented method generates a requested image based on an image style. An image style is selected, and an image generation model is trained using the selected image style. In some examples, the image generation model is a diffusion model. An image request input is received (e.g., text input, drawing input, and/or voice input) and, based on the received image request input, an image is generated using the trained image generation model. The generated image is in the selected image style. The generated image is then output in response to the received image request input. Further, in some examples, feedback associated with the generated image is received and the image generation model is further trained based on the received feedback to improve the quality of its image generation. Additionally, in some examples, the generated image is applied to an item for sale, enabling users to personalized items with generated images.","['G06Q30/0621', 'G06Q30/0643', 'G06T11/203', 'G06T11/60', 'G06T2210/16']"
US8771713B2,Method and process for the production of multi-coated recognitive and releasing systems,"The present invention includes compositions, methods, systems for the controlled delivery of an active agent in a tablet polymer comprising two or more layers, wherein each of the two or more layers comprises at least one active agent and at least one molecular recognition polymer, wherein the two or more layers are compressed into a single tablet.","['A61K9/0004', 'A61K31/137', 'A61K38/28', 'A61K47/34', 'A61K9/1676', 'A61K9/209', 'A61K9/5073', 'A61K9/5084']"
WO2025025805A1,"Motion generation model-based motion generation method and apparatus, and device","A motion generation model-based motion generation method and apparatus, and a device, relating to the technical field of artificial intelligence. The method comprises: acquiring a text containing motion information (210); generating text features of the text by means of a text encoder (220); by means of a first diffusion model and in a feature space of a first dimension, generating an intermediate motion sequence on the basis of the text features (230); and by means of a second diffusion model and in a feature space of a second dimension, performing detail enhancement processing on the intermediate motion sequence so as to obtain an output motion sequence matched with the text, the second dimension being greater than the first dimension (240). The present application preliminarily generates the intermediate motion sequence by means of the first diffusion model, and performs detail enhancement processing on the intermediate motion sequence by means of the second diffusion model, thus improving the detail richness of the output motion sequence.","['G06F40/126', 'G06F18/214', 'G06F18/22', 'G06F40/30', 'G06N20/00', 'Y02T90/00']"
WO2023183504A1,Deep learning super resolution of medical images,"A method for super-resolution processing of medical images includes receiving, as input, a medical image of a modality and a first resolution. The method further includes concatenating the medical image with a noise vector of a desired resolution higher than the first resolution. The method further includes passing the noise vector concatenated with the medical image though a neural network trained to remove noise and treating an output of the neural network as a new noise vector to be concatenated with the medical image and passed through the neural network. The method further includes repeating the concatenating and passing steps a plurality of times to produce, an image output from the neural network which comprises a super-resolution version of the medical image having the desired resolution.","['G06N3/0455', 'G06N3/047', 'G06N3/09', 'G06T3/4046', 'G06T3/4053', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
WO2025055514A1,"Three-dimensional model generation method and apparatus, computer device, and storage medium","A three-dimensional model generation method. The method comprises: obtaining prompt information for describing an object category, and determining a target network model that matches the object category indicated by the prompt information (202), the target network model comprising a first sub-network model and a second sub-network model; obtaining a first generative intensity, a second generative intensity, and a generative seed, wherein the first generative intensity indicates a quantity of iteration rounds of performing first processing by the first sub-network model, the second generative intensity indicates a quantity of iteration rounds of performing second processing by the second sub-network model, and the generative seed is a random number generated randomly, wherein each round of the first processing comprises at least one instance of first encoding and decoding processing, each round of the second processing comprises at least one instance of second encoding and decoding processing, and the first encoding and decoding processing and the second encoding and decoding processing each comprise at least encoding processing and decoding processing (204); by means of the first sub-network model and on the basis of the first generative intensity and the generative seed, performing at least one round of the first processing, to obtain a three-dimensional rough model (206); and by means of the second sub-network model and on the basis of the second generative intensity and the three-dimensional rough model, performing at least one round of the second processing, to obtain a three-dimensional object model that meets a preset high resolution condition and pertains to the object category (208).","['G06F40/284', 'G06F40/289', 'G06N3/0464', 'G06N3/08', 'G06T17/00', 'G06V10/80']"
CN117541459A,Training method and device for image generation model,"The embodiment of the specification relates to a training method and a training device for an image generation model, wherein the image generation model comprises a face consistency module and a trained diffusion model, the diffusion model comprises a noise adding module and a first denoising network, and the method comprises the following steps: inputting an original face image into a noise adding module to obtain a first noise image, inputting the first noise image into a first noise removing network to obtain a first face image with a first style, inputting the first noise image into a first fusion module formed by fusion of the first noise removing network and a face consistency module to perform fusion processing to obtain a second face image, determining a first loss according to the face similarity between the original face image and the second face image, determining a second loss according to the style similarity between the first face image and the second face image, and finally adjusting parameters of the face consistency module based on the total loss of the first loss and the second loss.","['G06T5/50', 'G06N3/0455', 'G06N3/08', 'G06V10/761', 'G06V10/774', 'G06V10/82', 'G06V40/172', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201']"
CN116311279A,"Sample image generation, model training and character recognition methods, equipment and media","The invention relates to the technical field of image processing, in particular to a method, a device and a medium for generating a sample image, training a model and identifying characters, wherein the generating method comprises the steps of obtaining a target text and style characteristics and a first sample character in a target scene, wherein the target text and style characteristics are obtained by carrying out text style coding on a real character image in the target scene; processing the first sample character, the target text and the style characteristics based on a target diffusion model to obtain a sample character image under a target scene, wherein the target diffusion model is used for migrating the font style of the first sample character into a real character image to generate a sample character image; and splicing the sample character image with the background image in the target scene to obtain a sample image. And migrating the font style of the first sample character into the real character image by using the target diffusion model, realizing style unification, and obtaining a vivid sample image.","['G06V30/18143', 'G06N20/00', 'G06V30/147', 'G06V30/19147']"
EP4517610A1,Method and system for training image generation model using content information,"The present disclosure relates to a method of training an image generation model performed by at least one processor. The method of training an image generation model includes receiving a training image in a first domain style, extracting, by the at least one processor, first content information for the training image, generating, by the at least one processor, a plurality of pieces of augmented content information perturbed from the first content information as part of image processing by augmenting the first content information, and training an image generation model to generate a synthetic image in the first domain style from an input image in a second domain style different from the first domain style, wherein the training of the image generation model is based on the training image, the first content information, and the plurality of pieces of augmented content information.","['G06T11/60', 'G06T11/00', 'G06N20/00', 'G06N3/045', 'G06T2211/441']"
US20250104399A1,Data attribution for diffusion models,"Embodiments of the present disclosure perform training attribution by identifying a synthesized image and a training image, where the synthesized image was generated by an image generation model that was trained with the training image. A machine learning model computes first attribution features for the synthesized image using a first mapping layer and second attribution features for the training image using a second mapping layer that is different from the first mapping layer. Then, an attribution score is generated based on the first attribution features and the second attribution features, where the attribution score indicates a degree of influence for the training image on generating the synthesized image.","['G06V10/7715', 'G06N3/045', 'G06N3/0895', 'G06V10/761', 'G06V10/774', 'G06V10/82']"
WO2025026045A1,"Method and apparatus for image processing based on artificial intelligence, electronic device, computer readable storage medium, and computer program product","The present application provides a method and apparatus for image processing based on artificial intelligence, an electronic device, a computer readable storage medium, and a computer program product. The method comprises: performing noise addition processing on an object image, to obtain a noise image coding vector, and performing text coding processing on an action instruction text, to obtain a first action text coding vector; performing denoising processing on the noise image coding vector based on the first action text coding vector, to obtain a first action image, and updating the first action text coding vector on the basis of the difference between the first action image and the object image, to obtain a second action text coding vector; fusing the first action text coding vector and the second action text coding vector, to obtain a fused action text coding vector; and performing denoising processing on the noise image coding vector based on the fused action text coding vector, to obtain a second action image.","['G06T5/50', 'G06T9/00', 'G06T2207/10004', 'G06T2207/20221', 'Y02D10/00']"
CN117934657B,Language tracking image editing method based on text graph generation model,"The invention discloses a language tracking image editing method based on a text-to-image generation model, which belongs to the technical field of image processing and comprises the following steps: acquiring a source text prompt, a target text prompt and an editing word; obtaining all words related to the editing words and forming a vocabulary pair set; inputting the source text characterization information, the target text characterization information and the noise image into the diffusion model is repeatedly performed: updating a noise image input in the process of generating the target editing image; extracting self-attention force diagrams of the source image in the generation or reconstruction process and replacing the self-attention force diagrams of the target editing image in the generation process; thresholding and merging to obtain a mask; updating the noise image of the target editing image by using the mask; outputting a noise image until t steps are executed; and decoding the noise image to obtain a source image and a target editing image. The language tracking image editing method based on the text graph generation model solves the problem that an editing result of an existing image editing method is not ideal.","['G06T11/001', 'G06F40/211', 'G06F40/284', 'G06N3/042', 'G06N3/0455']"
CN119722513A,A medical image denoising and reconstruction method based on unsupervised learning,"The invention discloses a medical image noise reduction and reconstruction method based on unsupervised learning, relates to the technical field of medical image processing, and solves the technical problem that the existing diffusion model is not ideal in effect of detail recovery and noise reconstruction on a medical image. The method comprises the steps of constructing at least two different first frequency domain subsets and second frequency domain subsets according to a medical image, inputting the first frequency domain subsets and the second frequency domain subsets into a trained generation parallel network to generate a preliminary reconstruction image, wherein the generation parallel network comprises at least two mutually independent first generation networks and second generation networks, mapping features of the preliminary reconstruction image to a potential space, performing diffusion reconstruction in a denoising process, encoding to obtain diffusion reconstruction features, and decoding the diffusion reconstruction features through a decoder to obtain a final reconstruction image of the medical image. The invention can realize the high-frequency detail recovery of the medical image and reconstruct and generate the medical image with high quality.",['Y02T10/40']
CN117115291A,CT image generation method and device based on large model,"The invention relates to the technical field of image generation, in particular to a CT image generation method and device based on a large model. Aiming at the problem of poor quality of images generated by the prior method, the adopted method comprises the following steps: the method comprises the steps of obtaining text information, wherein the text information is used for describing characteristics of a target CT image, and further inputting the text information into a preset CT image generation model to obtain a corresponding target CT image, wherein the CT image generation model is a stable diffusion model which is adjusted in advance, and the content of the adjustment in advance comprises adjusting a U-net network of the stable diffusion model so as to generate a fine-granularity CT image. In the method, since the CT image generation model has the capability of generating case-specific images according to the detailed description, the corresponding fine-grained CT images can be generated, and the method has important significance for solving the problem that medical image data are limited and expensive.","['G06T11/003', 'G06F16/35', 'G06F18/241', 'G06F40/289', 'G06N3/0464', 'G06N3/084', 'G16H15/00', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
CN117745522A,"Image extension method, device, equipment and medium based on generated image model","The application provides an image extension method, device, equipment and medium based on a generated image model, and the method is applied to the technical field of artificial intelligence. The method comprises the following steps: acquiring an image to be extended in a target demand scene; adopting a fine-tuned model in the image model to extend the image to be extended according to preset extension parameters to obtain a first extension image; the image model is obtained by combining the fine-tuned model and the fine-tuned low-rank adaptive model based on the target combining weight; adopting a fine-tuned low-rank adaptive model in the image model to extend the image to be extended according to preset extension parameters to obtain a second extension image; and combining the second extension image and the first extension image by adopting a target combination weight in the image model to generate a target extension image of the image to be extended. The method can not only rapidly generate the target extension graph of the image to be extended, but also improve the extension effect of the target extension graph.",[]
WO2025055505A1,"Image processing method, device, and storage medium","Embodiments of the present application provide an image processing method, a device, and a storage medium. In the embodiments of the present application, target object detection is performed on a fused image to be processed to obtain image position information of a target object; an image of the target object is acquired on the basis of the image position information of the target object; and then a transparent background layer comprising the image of the target object is generated on the basis of the image of the target object and the image position information of the target object. Therefore, image materials for image design are acquired from existing fused images by performing automatic layer separation on the existing fused images, thereby enriching the image materials, and improving the diversity of the image materials.","['G06T11/60', 'G06N3/045', 'G06N3/08', 'G06T7/10', 'G06V10/25', 'G06V10/82', 'G06V2201/07']"
WO2024254051A1,Autonomous visual information seeking with machine-learned language models,"Systems and methods for generating a response to a visual information query can include obtaining input data, processing the input data with one or more machine-learned models, transmitting data to one or more data processing tools, and generating a response based on the input data and the one or more outputs of the one or more data processing tools. The one or more machine-learned models may iteratively process data to generate planning data that may include application programming interface calls to the one or more data processing tools. The one or more machine-learned models may be utilized for planning, reasoning, and response generation when obtaining and generating a response to a visual information query.","['G06F16/532', 'G06F16/53', 'G06N20/00', 'G06V10/74', 'G06V10/82']"
CN116485983A,"Texture generation method of virtual object, electronic device and storage medium","The application discloses a texture generation method of a virtual object, electronic equipment and a storage medium. Wherein the method comprises the following steps: reading a virtual object pre-constructed in a virtual scene; capturing descriptive information for expressing textures overlaid on the surface of the virtual object; performing unsupervised learning on textures of the surface of the virtual object based on the description information to obtain a target texture map corresponding to the virtual object; the virtual object is rendered based on the target texture map. The method and the device solve the technical problem that the rendering efficiency of the virtual object in the related technology is low.","['G06T15/04', 'G06T19/006']"
US20240176321A1,Implementing Rendered Fabrication Results with Computer Numerically Controlled Machines Based on Natural Language Descriptions of Desired Fabrication Results,"Embodiments include one or more computing systems configured to perform functions comprising: (i) receiving a natural language description of a desired fabrication result; (ii) causing a software engine to generate machine-created rendering instructions based on the natural language description of the desired fabrication result; and (iii) executing, by a laser CNC machine, the machine-created rendering instructions to generate a rendered fabrication result.","['G05B19/182', 'B33Y50/00', 'G06T19/00', 'G05B2219/45041', 'G06F40/30', 'G06T2200/24']"
CN118365507A,A human posture conversion method based on pre-trained Stable Diffusion,"The invention discloses a human body posture conversion method based on a pre-trained Stable Difference, which is characterized in that a pre-trained Stable Difference model is enhanced to adapt to a target posture image, a source human body image and text description, and a target human body image of the source human body image under the target posture image is generated; extracting the characteristics of a source human body image by adopting a pre-trained VAE encoder and DINO-V2 model, and constructing a VAE cross attention module and a style cross attention module; a text cross attention module in a Stable diffration model is reserved; denoising loss and perception loss are calculated on the source-target image pair and the single image to fine tune the Stable diffration model, so that human body posture conversion is realized. Compared with the prior art, the method has the characteristics of fully utilizing the pre-trained Stable diffration model and remarkably improving the image quality, is simple, has low training cost, and well solves the problems of high training cost and poor generated image quality caused by underutilization of the pre-trained Stable diffration.","['G06T3/04', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
WO2025050813A1,"Three-dimensional ultrasonic modeling method and system, electronic device and readable storage medium","The present invention provides a three-dimensional ultrasonic modeling method and system, an electronic device and a readable storage medium. The method comprises: using a first generation model to carry out domain conversion on each frame of ultrasonic image in an acquired target organ ultrasonic image sequence, so as to acquire a corresponding pseudo target domain image sequence, wherein the target organ ultrasonic image sequence comprises multiple frames of ultrasonic images collected by an ultrasonic probe in the cavity of a target organ at different poses and different depths; on the basis of the pseudo target domain image sequence, acquiring a sparse pseudo target domain three-dimensional image, and on the basis of the sparse pseudo target domain three-dimensional image, acquiring a dense pseudo target domain three-dimensional image; carrying out target organ anatomical structure segmentation on the dense pseudo target domain three-dimensional image to acquire a target organ structure image; and on the basis of the target organ structure image, carrying out three-dimensional reconstruction to acquire a target organ three-dimensional model. The present invention can acquire a finer and clearer target organ three-dimensional model, such that a doctor can accurately analyze tiny lesions and abnormal areas.","['G06T17/00', 'G06T7/10', 'G06T2200/04', 'G06T2207/10136', 'G06T2207/30004']"
US12136197B2,Neural network systems and methods for removing noise from signals,A neural network is used to remove noise from a data signal. The noise removed by the neural network is compared to simulated noise that represents noise expected to be present in the data signal. The results of the comparison are used to train the neural network and improve its ability to remove noise from the data signal.,"['G06N3/08', 'G01S13/9021', 'G01S17/89', 'G01S7/414', 'G01S7/417', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224']"
US12355932B2,Methods and systems for personalized image generation,"A method and a system for personalized image generation are provided. The method includes: determining a facial description text specified by a user; generating, based on the facial description text, a facial image by using a generative algorithm; obtaining a first dressing effect image of a target garment, the first dressing effect image presenting a wearing effect of the target garment on a digital model; and generating a second dressing effect image of the target garment by performing a fusion operation on the facial image and the first dressing effect image, the second dressing effect image presenting a wearing effect of the target garment on a fused digital model. The provided solution not only enables the rapid, high-quality generation of garment images but also ensures that the fused images maintain feature consistency, meeting users' personalized display preferences.","['H04N13/111', 'G06T17/00', 'G06F40/284', 'G06F40/40', 'G06T11/00', 'G06T15/00', 'G06T7/11', 'G06T7/174', 'G06V10/7715', 'G06V20/20', 'G06V20/64', 'G06V40/171', 'H04N13/398', 'G06T2207/20221']"
WO2017029488A2,Methods of generating personalized 3d head models or 3d body models,"There is provided a method of generating an image file of a personalized 3D head model of a user, the method comprising the steps of: (i) acquiring at least one 2D image of the user's face; (ii) performing automated face 2D landmark recognition based on the at least one 2D image of the user's face; (iii) providing a 3D face geometry reconstruction using a shape prior; (iv) providing texture map generation and interpolation with respect to the 3D face geometry reconstruction to generate a personalized 3D head model of the user, and (v) generating an image file of the personalized 3D head model of the user. A related system and computer program product are also provided.","['G06T17/00', 'G06T17/20', 'G06T15/04', 'G06T13/40', 'G06T19/00', 'G06T19/20', 'G06T7/50', 'G06T7/529', 'G06T7/55', 'G06T7/70', 'G06V40/165', 'G06V40/166', 'G06V40/168', 'G06V40/172', 'G06T2200/04', 'G06T2200/08', 'G06T2200/24', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06T2215/16', 'G06T2219/2012', 'G06T2219/2021', 'G06V40/178', 'H04N23/64']"
CN114387365B,Method and device for coloring line manuscript,"The invention discloses a method and a device for coloring a line manuscript, wherein the method comprises the following steps: collecting color images, preprocessing the collected color images, generating a line draft according to the preprocessed color images, extracting corresponding color prompts by adopting a random covering fuzzy method, and constructing a training data set; introducing an attention screening mechanism at a jump connection part of a generator model of the pix2pixGAN model to improve the pix2pixGAN model to obtain a line draft coloring model; training the draft coloring model by utilizing the training data set; and coloring the line manuscript to be colored by using the trained line manuscript coloring model. The invention can improve the accuracy of the coloring result of the line manuscript and the quality of the generated picture, can better converge during training, and can prevent oscillation.","['G06T5/70', 'G06F18/214', 'G06N3/045', 'G06N3/048', 'G06T11/001', 'G06T7/50']"
CN117252791A,"Image processing method, device, electronic equipment and storage medium","The application discloses an image processing method, an image processing device, electronic equipment and a storage medium, wherein the image processing method comprises the following steps: acquiring a first portrait image, a second portrait image and a target keyword corresponding to a target portrait style, wherein the first portrait image comprises a first face, and the second portrait image comprises a human body with a target gesture; generating a third portrait image with the target portrait style based on the target keywords and the second portrait image through a pre-trained large language model, wherein the gesture of a human body in the third portrait image is matched with the target gesture; and replacing the face in the third face image with the first face image based on the first face image to obtain a fourth face image. The method can improve the generation efficiency of the portrait images.","['G06T5/50', 'G06N3/0464', 'G06N3/088', 'G06T7/11', 'G06V10/774', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201']"
CN117093739A,"Image generation and image-text alignment method and device, terminal equipment and storage medium","The embodiment of the application discloses an image generation and image-text alignment method, an image generation and image-text alignment device, a terminal device and a storage medium.","['G06F16/5866', 'G06F16/583', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/44', 'G06V10/764', 'G06V10/806', 'G06V10/82']"
CN118357083A,Three-dimensional paint spraying system and method based on generative large model texture generation,"The invention discloses a three-dimensional pigment spraying system and method based on texture generation by using a large generation model. The system comprises a turntable, a working platform with a sliding rail, a mechanical arm, a spraying pump and an RGB-D camera; and a user operation platform. The method includes S1, collecting multi-view image data; s2, carrying out data processing on the image, and then reconstructing the image to obtain a grid model of the object to be sprayed; s3, combining the grid model, and generating a specific digital texture and a UV mapping relation between the specific digital texture and the grid model according to user requirements; s4, texture spraying path planning; s5, texture spraying. The invention combines the generation type large model with the technologies of three-dimensional object reconstruction, path planning and the like, can convert digital textures into physical textures, and then carries out fine adjustment and correction on the model through physical world textures, thereby realizing interaction between the virtual world and the physical world and realizing high-quality and personalized digital texture spraying on the three-dimensional object.","['B05B9/0403', 'B05B12/12', 'B05B12/14', 'B05B13/0431', 'B05D1/02', 'B05D5/065', 'G06N20/00', 'G06T15/04', 'G06T17/00']"
WO2025111544A1,3d scene content generation using 2d inpainting diffusion,"Provided is a general approach to inpainting 3D content by using a 2D inpainting diffusion model trained on static scenes as a generative prior. In particular, while existing methods for 3D inpainting focus on the specific task of object removal, systems and methods of the present disclosure aim to generate realistic content in any masked 3D region while preserving the complexity of the original scene at the object and scene scale. The proposed techniques can be used in various applications such as 3D object removal, 3D inpainting and novel view synthesis.","['G06T5/77', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
CN117892142A,"Method, device and storage medium for judging source of generated content","The invention discloses a method for judging a generated content source, which is characterized in that a target context vector is obtained by training a target class sample set generated by a generation model, a non-target context vector is obtained by training a non-target class sample set obtained randomly, text features of a sample to be detected are respectively compared with prompt word features of the target context vector and prompt word features of the non-target context vector, and if the text features are close to the prompt word features of the target context vector, the source and the generation model of the sample to be detected are proved. The invention also discloses a device for judging the source of the generated content and a storage medium.","['G06F18/22', 'G06F18/2431', 'G06F40/216', 'G06F40/279']"
US20250166267A1,Interactive point-based image editing,"Embodiments of the disclosure relate to interactive point-based image editing. According to example embodiments of the present disclosure, a user edit input for a source image is obtained to indicate at least one handle point and at least one target point in the source image. A feature map is extracted from the source image using a diffusion model at an iteration step of an inverse denoising diffusion process performed on the source image. The feature map is then updated based on the user edit input. Then a target image is generated based on the updated feature map using the diffusion model through a denoising diffusion process performed on the updated feature map.","['G06T11/60', 'G06V10/48', 'G06V10/82']"
US20240362842A1,Utilizing a diffusion prior neural network for text guided digital image editing,"The present disclosure relates to systems, methods, and non-transitory computer readable media for utilizing a diffusion prior neural network for text guided digital image editing. For example, in one or more embodiments the disclosed systems utilize a text-image encoder to generate a base image embedding from the base digital image and an edit text embedding from edit text. Moreover, the disclosed systems utilize a diffusion prior neural network to generate a text-image embedding. In particular, the disclosed systems inject the base image embedding at a conceptual editing step of the diffusion prior neural network and condition a set of steps of the diffusion prior neural network after the conceptual editing step utilizing the edit text embedding. Furthermore, the disclosed systems utilize a diffusion neural network to create a modified digital image from the text-edited image embedding and the base image embedding.","['G06T11/60', 'G06T5/70', 'G06T2200/24', 'G06T2207/20084']"
CN118199161A,A distribution network flexibility resource scheduling method based on denoising probability diffusion model,"The invention relates to a power distribution network flexible resource scheduling method based on a denoising probability diffusion model, which comprises the following steps: generating a scene describing inherent uncertainty of renewable energy sources by adopting a denoising probability diffusion model; and constructing a flexible resource scheduling model, and solving the scheduling model by utilizing flexible resource constraint and voltage security opportunity constraint based on a scene to realize flexible resource scheduling of the power distribution network. Compared with the prior art, the method and the device accurately describe the uncertainty environment through the denoising probability diffusion model, reduce the system error and realize accurate scheduling of flexible resources of the power distribution network.","['G06N3/0464', 'G06N3/08', 'H02J3/06', 'H02J3/466', 'H02J3/48', 'H02J3/50', 'H02J2203/10', 'H02J2203/20', 'H02J2300/24', 'H02J2300/28']"
US12271978B1,Content synthesis using generative Artificial Intelligence model,"A method including receiving a prompt describing a desired characteristic of an image. The method further including generating, using a set of encoding models, a prompt encoding based on the prompt. The method further including generating, using a first transformer block of a diffusion transformer model, a first prompt embedding and a first image embedding based on the prompt encoding and a noise input. The method further including generating, using a second transformer block of the diffusion transformer model, a second image embedding based on the first image embedding and the first prompt embedding. The method further including generating the image based on the second image embedding.","['G06T11/00', 'G06F40/40']"
US20240394754A1,Digital Content Creation,"Methods, systems, and apparatus, including computer-readable storage media for generating model-generated digital content based on prompts and other inputs. The prompts may be, for example, inputs for modifying digital content associated with an existing campaign. The prompts may include national language input. The natural language prompts may include, for example, a theme, information related to an upcoming event, the topic of the campaign, or the like. The other inputs may also include information associated with the campaign creator's style. The information associated with the campaign creator's style may be in the form of embeddings. A system implementing the methods described herein can generate the digital content for the modified campaign based on the received inputs received from the campaign. The generated digital content may be in the form of text, image, or the like.","['G06Q30/0276', 'G06T11/60', 'G06V10/70', 'G11B27/031', 'G06T2211/441']"
US20240152668A1,Methods and models for direct molecular conformation generation,"Disclosed herein is a method of generating a 3D conformation of a molecule used in in-silico drug discovery. The method includes obtaining a 2D graph of the molecule. A first tensor including molecular graph information and a second tensor including graph, coordinate and distance information of atoms of the molecule are generated. A first set of feature vectors corresponding to the first tensor and a second set of feature vectors corresponding to the second tensor are further generated. The first set of feature vectors are fed to a first encoder of a generative model to generate a first output. The second set of feature vectors are fed to a second encoder of the generative model to generate a second output. The first output and the second output are combined to form an input in a decoder of the generative model to generate the 3D conformation of the molecule.",['G06F30/25']
US20240378921A1,Facial expression-based detection method for deepfake by generative artificial intelligence (ai),"A facial expression-based detection method for deepfake by generative artificial intelligence (AI) constructs an AIR-Face facial dataset for generative AI-created face detection training, and uses an untrained information feature space for real and fake classification. Nearest linear detection is performed in this space to significantly improve the generalization ability of detecting fake images, especially those created by new methods such as diffusion models or autoregressive models. The detection method improves the performance of extracting features of generative AI-created faces through phased trainings, and detects generative AI-created faces through the feature space. Compared with other methods, the detection method scientifically and effectively improves the accuracy of generative AI-created face recognition, and fully mines the potential semantic information of generative AI-created faces through phased trainings. In this way, the detection method improves reliability and accuracy in generative AI-created face detection, meeting the needs of generative AI-created face detection.","['G06V40/174', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V40/168', 'G06V40/172', 'Y02D10/00']"
CN117576248A,Image generation method and device based on posture guidance,"An image generation method and device based on gesture guidance are provided. The image generation method based on gesture guidance comprises the following steps: acquiring a source image, a noise image and a target attitude image, wherein the noise image is different from the source image; extracting a source posture image from the source image; obtaining an image to be processed by fusion based on at least the source image, the noise image, the target attitude image and the source attitude image; inputting the source image into an image feature extractor of the image generation model to extract therefrom source image composite features, the source image composite features comprising texture features; and inputting the comprehensive characteristics of the image to be processed and the source image into an image denoising device of the image generation model to obtain a target image, wherein the target image represents an image of an object in the source image under a target posture.","['G06T11/001', 'G06N3/0464', 'G06N3/0499', 'G06N3/08', 'G06T3/4038', 'G06T3/4046', 'G06V10/454', 'G06V10/54', 'G06V10/806', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US20250171017A1,Scene modeling using trajectory predictions and tokenized features,"In various examples, systems and methods are disclosed relating to generating scene mode conditioned trajectory predictions that are usable for interfacing with an LLM. A system can obtain traffic scene data associated with movement of one or more agents relative to a vehicle navigating through an environment. The system can encode the traffic scene data to determine latent representations of the movement of the one or more agents relative to the vehicle navigating through the environment. Then the system can determine a joint scene mode distribution based at least on the latent representations. The system can then decode the joint scene mode distribution into one or more trajectory predictions and one or more categorical predictions for each agent of the one or more agents.","['B60W30/095', 'B60W30/0956', 'B60W30/18163', 'B60W60/00276']"
US11900979B2,Probabilistic in-memory computing,"Embodiments of the present disclosure are directed toward probabilistic in-memory computing configurations and arrangements, and configurations of probabilistic bit devices (p-bits) for probabilistic in-memory computing. concept with emerging. A probabilistic in-memory computing device includes an array of p-bits, where each p-bit is disposed at or near horizontal and vertical wires. Each p-bit is a time-varying resistor that has a time-varying resistance, which follows a desired probability distribution. The time-varying resistance of each p-bit represents a weight in a weight matrix of a stochastic neural network. During operation, an input voltage is applied to the horizontal wires to control the current through each p-bit. The currents are accumulated in the vertical wires thereby performing respective multiply-and-accumulative (MAC) operations. Other embodiments may be described and/or claimed.","['G11C11/1673', 'G06F7/5443', 'G06N3/045', 'G06N3/047', 'G06N3/065', 'G06N3/084', 'G06N7/01', 'G11C11/1659', 'G11C11/1675', 'G11C11/1697', 'G11C11/18', 'G11C11/223', 'G11C11/2259', 'G11C11/2273', 'G11C11/2275', 'G11C11/54', 'G11C11/5607', 'G11C11/5657']"
CN117670733A,A low-light image enhancement method based on wavelet spectrum learning,"The invention discloses a low-illumination image enhancement method based on small spectrum learning, which comprises the steps of firstly inputting a low-illumination image and a label image, and obtaining a priori knowledge true value through a potential encoder; then training a diffusion model by using priori knowledge, and obtaining the priori knowledge by using random noise in a prediction stage; then using priori knowledge P to construct a wavelet-based transducer module; constructing a symmetrical hierarchical network architecture by utilizing a wavelet-based transducer module; and finally, optimizing the network model by using the output image and the priori knowledge truth value. The invention successfully solves the problem of recovering the detail part of the image under the low illumination condition, and provides a high-efficiency solution for enhancing the low illumination image.","['G06V10/764', 'G06N3/0455', 'G06V10/774', 'G06V10/806', 'G06T2207/10004', 'Y02T10/40']"
US20240346342A1,Generative machine learning models for genealogy,"Disclosed herein are methods, systems, and non-transitory computer readable mediums for generating a shareable genealogical summary for a target individual. An example method includes receiving a request from a user to generate a shareable genealogical summary about a target user. The method generates the shareable genealogical summary comprising a genealogical history of the target user. The method provides genealogical information for the target user to a machine-learning language model. The genealogical information includes a family tree. The method receives a response generated by executing the machine-learning language model from a model serving system. The method provides the shareable genealogical summary for display to the user.","['G06N5/022', 'G06F40/106', 'G06F40/284', 'G06F40/30', 'G06F40/56', 'G06N3/044', 'G06N3/045', 'G06N5/01', 'G06N7/01']"
CN118152860A,"Emotion recognition-based regulation and control content generation method, system, equipment and medium","The embodiment of the application discloses a regulating content generation method, a regulating content generation system, regulating content generation equipment and a regulating content generation medium based on emotion recognition, which comprise the following steps: preprocessing the original electroencephalogram data, and extracting relevant electroencephalogram features for identifying tasks; inputting the relevant electroencephalogram characteristics into a emotion recognition classification model for emotion recognition to obtain the current user emotion state; inputting the current user emotion state into the large language model and outputting auxiliary prompt words; and inputting the auxiliary prompt words into the multi-modal generation model to generate emotion regulation guide content for emotion regulation. Unlike invasive implantable electrically stimulated nerve regulation, the application adopts non-invasive brain-computer interface scheme, and can realize emotion monitoring under daily conditions based on scalp brain-electrical information; unlike direct nerve regulation which may bring additional risk, the scheme adopts AIGC-based content generation and feedback form, thereby realizing safe, noninvasive and easy-to-use emotion regulation; greatly reduces the use threshold.","['G06F18/24', 'A61B5/165', 'A61B5/369', 'A61B5/372', 'A61B5/7203', 'A61B5/7235', 'A61B5/7267', 'G06F18/10', 'G06F18/213', 'G06F18/214', 'G06F18/25', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0499', 'G06N3/084', 'G06N3/088']"
US20250086843A1,"Method and data processing system for lossy image or video encoding, transmission and decoding","A method for lossy image and video encoding, transmission and decoding, the method comprising the steps of: receiving an input image at a first computer system; encoding the input image using a first trained neural network to produce a latent representation; performing a quantization process on the latent representation to produce a quantized latent; transmitting the quantized latent to a second computer system; decoding the quantized latent using a denoising process to produce an output image, wherein the output image is an approximation of the input image.","['H04N19/90', 'G06T9/002', 'G06N3/0455', 'G06N3/0464', 'G06N3/084']"
US12131406B2,Generation of image corresponding to input text using multi-text guided image cropping,"Systems and methods are provided that include a processor executing a program to receive an input from a user, where the input including a first input text and a second input text. The processor is further configured to provide an initial image and, for a predetermined number of iterations, define a first and second regions of the initial image associated with the first and second input texts, respectively, define a plurality of patches of the initial image, input the initial image into a diffusion process to generate a processed image, back-propagate the processed image through a text-image match gradient calculator by generating an image embedding based on the processed image, generating a text embedding based on the region and the input text that are associated with a patch, and calculating a differential between the image embedding and the text embedding.","['G06T11/00', 'G06F18/214', 'G06F18/22', 'G06F40/30', 'G06F40/40', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T5/70']"
US12106318B1,Prompt management systems for moderating generative artificial intelligence operations,"Operations of a prompt management system are disclosed. The operations may include: receiving a prompt for performing a set of tasks, assigning an agent group that includes a plurality of agents to perform a set of roles associated with a dataset in support of the set of tasks, causing the plurality of agents to perform the set of roles using a first machine-learning model, receiving a set of role results from the plurality of agents responsive to performing the set of roles, performing the set of tasks using at least a second machine-learning model, and providing a task result for display on a user interface device. The set of tasks may include executing an operation on the set of role results using the second machine-learning model, and generating a task result that includes a product of the operation executed on the set of role results.","['G06Q10/063112', 'G06Q30/016', 'G06Q30/0204']"
US12136141B2,Generation of image corresponding to input text using dynamic value clipping,"Systems and methods are provided that include a processor executing a program to receive input text from a user. The processor is further configured to, for a predetermined number of iterations, input an initial image into a diffusion process to generate a processed image, back-propagate the processed image through a text-image match gradient calculator to calculate a gradient against the input text, and update the initial image with an image generated by applying the calculated gradient to the processed image. The pixel values of the processed image during a first portion of the predetermined number of iterations are value clamped to a first range, and pixel values of the processed image during a second portion of the predetermined number of iterations are value clamped to a second range that is a subset of the first range.","['G06N5/041', 'G06T11/00', 'G06F40/30', 'G06F40/40', 'G06N3/0455', 'G06N3/084', 'G06T5/20', 'G06T5/70']"
US20250117126A1,Media content item processing based on user inputs,"A method, apparatus, non-transitory computer readable medium, and system for media processing includes obtaining a variation parameter and a number of variations, identifying a first variation input and a second variation input for the variation parameter, and obtaining a first media content item and a second media content item based on the first variation input and the second variation input, respectively. The first media content item and the second media content item vary from each other with respect to the variation parameter. The method, apparatus, non-transitory computer readable medium, and system for media processing further includes displaying the first media content item and the second media content item in a grid comprising a grid size based on the number of variations.","['G06T11/00', 'G06F16/43', 'G06F3/04845', 'G06F3/04847', 'G06F3/0486', 'G06T2200/24']"
US20190017374A1,Generating Spectral Responses of Materials,"In one non-limiting embodiment, the present disclosure is directed to a controller having a memory; and a processor coupled to the memory and configured to: cause a neural network to receive current measurements of a current material; instruct the neural network to determine dominant features of the current measurements; instruct the neural network to provide the dominant features to a decoder; and instruct the decoder to generate a generated spectral response of the current material based on the dominant features. In another non-limiting embodiment, the present disclosure is directed to a method including the steps of receiving current measurements of a current material; determining dominant features of the current measurements; providing the dominant features; and generating a generated spectral response of the current material based on the dominant features.","['E21B49/00', 'G01N24/081', 'G01R33/448', 'G01V3/14', 'G01V3/32', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084']"
CN116962593A,"Video frame inserting method, device, equipment and storage medium","The embodiment of the application discloses a video frame inserting method, a device, equipment and a storage medium, and the related embodiment can be applied to various scenes such as artificial intelligence, intelligent traffic and the like and is used for improving the video frame inserting effect and the video frame rate. The method of the embodiment of the application comprises the following steps: carrying out forward noise adding processing on a current video frame, and obtaining a first noise image obtained through t steps of noise adding processing, wherein t is a random time step, and t is an integer greater than 0; carrying out forward noise adding processing on the next video frame, and obtaining a second noise image obtained by t steps of noise adding processing; acquiring a mean value between the first noise image and the second noise image and a noise mean value image corresponding to the mean value; and (3) carrying out inverse denoising treatment on the noise mean image based on the mean value until the noise mean image is restored to the 0 th step from the t, generating a first video plug-in frame image, and inserting the first video plug-in frame image between the current video frame and the next video frame.","['H04N5/21', 'H04N5/14']"
CN109035163A,A kind of adaptive denoising method based on deep learning,"The adaptive denoising method based on deep learning that the present invention relates to a kind of, includes the following steps: that step 1) establishes image setï¼Step 2) constructs adaptive depth convolutional neural networksï¼The adaptive depth convolutional neural networks of step 3) training: the learning rate and momentum parameter of setting depth convolutional neural networks network, by the deep learning frame training adaptive depth convolutional neural networks until training reaches iteration maximum times, the adaptive depth convolutional neural networks model after generating trainingï¼Step 4) image denoising: image to be denoised is input to trained adaptive depth convolutional neural networks model, obtains corresponding residual image, then the image wait denoise is subtracted into the image after residual image is denoised.The utility model has the advantages that this method further increases and stablize the training performance of convolutional neural networks, and guarantee denoising performance, save the time, without adjusting ginseng manually, is able to achieve the blind denoising of unknown noise grade image.","['G06T5/70', 'G06T2207/10004', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084']"
CN119649320B,Diffusion model-based vehicle re-identification data set generation method and device,"The invention provides a vehicle re-recognition data set generation method and device based on a diffusion model, which belong to the technical field of vehicle re-recognition, and the method comprises the steps of constructing a prompt word template based on vehicle attributes and performing iterative optimization; and based on the optimized prompt word template and the diffusion model after fine adjustment, optimizing by combining target detection and semantic filtering, constructing a vehicle re-identification data set generation model, and generating a vehicle re-identification data set. The method can obtain better effect than the existing virtual data set generation method on the downstream vehicle re-identification data set, the quantity of the real data required by the generation method is only 1% of that of the real data required by the existing method, the real data does not need to be marked, and the method is beneficial to privacy protection and data marking cost reduction.",['Y02T10/40']
US11954862B2,Joint estimation of heart rate and respiratory rate using neural networks,"A neural network system leverages dual attention, specifically both spatial attention and channel attention, to jointly estimate heart rate and respiratory rate of a subject by processing images of the subject. A motion neural network receives images of the subject and estimates heart and breath rates of the subject using both spatial and channel domain attention masks to focus processing on particular feature data. An appearance neural network computes a spatial attention mask from the images of the subject and may indicate that features associated with the subject's face (as opposed to the subject's hair or shoulders) to accurately estimate the heart and/or breath rate. Channel-wise domain attention is learned during training and recalibrates channel-wise feature responses to select the most informative features for processing. The channel attention mask is learned during training and can be used for different subjects during deployment.","['G06T7/10', 'A61B5/0077', 'A61B5/024', 'A61B5/0816', 'A61B5/087', 'A61B5/7267', 'G06T7/0016', 'G06T7/11', 'G06T7/194', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088', 'G06T2207/30201']"
WO2025010888A1,"Image generation method and apparatus, electronic device, storage medium, and program product","An image generation method and apparatus, an electronic device, a storage medium, and a program product. The method comprises: acquiring a first source image in a predetermined style and a second source image comprising a predetermined person image (S21); performing feature extraction on the first source image by means of at least one image encoder to obtain at least one image feature (S22); performing face recognition on the second source image by means of a face recognition model to obtain a face feature of the predetermined person image (S23); splicing the at least one image feature and the face feature to obtain a spliced feature (S24); and inputting the spliced feature into a trained diffusion model to generate a target image in the predetermined style and comprising the predetermined person image (S25).","['G06N3/0464', 'G06N3/08', 'G06T3/40', 'G06V10/77', 'G06V10/774', 'G06V10/80', 'G06V10/82', 'G06V40/16']"
US20240338859A1,Multilingual text-to-image generation,"Systems and methods for image processing are provided. One aspect of the systems and methods includes obtaining a text prompt in a first language. Another aspect of the systems and methods includes encoding the text prompt using a multilingual encoder to obtain a multilingual text embedding. Yet another aspect of the systems and methods includes processing the multilingual text embedding using a diffusion prior model to obtain an image embedding, wherein the diffusion prior model is trained to process multilingual text embeddings from the first language and a second language based on training data from the first language and the second language. Yet another aspect of the systems and methods includes generating an image using a diffusion model based on the image embedding, wherein the image includes an element corresponding to the text prompt.","['G06V10/82', 'G06F40/30', 'G06F40/58', 'G06T11/00', 'G06V10/74', 'G06V10/774']"
CN118153658A,"Offline reinforcement learning training method, action prediction method, device and medium","The application discloses an offline reinforcement learning training method, an action prediction method, a device and a medium, wherein the method comprises the following steps: acquiring a first static data set of a robot controlled by a model to be trained; the first static data set comprises a plurality of historical running tracks of the robot; the network of the model to be trained comprises a cost function network, a diffusion model network and an inverse dynamic network; training a value function network based on the first static data set; generating performance labels corresponding to each track segment of the historical running track based on the trained cost function network; the diffusion model network and the inverse dynamic network are trained based on the track segments and the performance labels. The method and the device provided by the application improve the learning accuracy of the diffusion model and improve the training efficiency and the prediction accuracy of the model to be trained.","['G06N3/092', 'G06F18/214', 'G06N3/0985']"
CN116112685A,Image steganography method based on diffusion probability model,"The invention provides an image steganography method based on a diffusion probability model, which comprises the following steps of: s1, training a diffusion probability model to generate a carrier image set; s2, training a message extractor to establish a message-carrier set mapping; s3, using the stage 1, hiding the secret message; s4, using the stage 2, extracting the secret information ï¼ The invention can combine the message extractor with the convolutional neural network structure on the basis of any generator of the diffusion probability model which is directly driven by Gaussian noise to generate the image, so that the generated image can contain secret messages; in addition, by virtue of the gradual iteration of the diffusion probability model, the generated image is free from distortion caused by reconstruction, and the stability of training has higher image quality than the generator based on the generation countermeasure network structure.","['H04N19/467', 'H04N19/149']"
US11956560B2,Digital pixel sensor having reduced quantization operation,"In some examples, a sensor apparatus comprises: a pixel cell configured to generate a voltages, the pixel cell including a photodiode configured to generate charge in response to incoming light, and a charge storage device to convert the charge to a voltage; an integrated circuit configured to: determine a first captured voltage converted by the charge storage device during a first time period; compare the first captured voltage to a threshold voltage value; and in response to determining that the first captured voltage meets or exceeds the threshold voltage value: determine first time data corresponding to the first time period; and prevent the charge storage device from further generating a charge; and an analog-to-digital converter (ADC) configured to generate a digital pixel value based on the first captured voltage, and a memory to store the digital pixel value and the first time data.","['H03M1/123', 'H03M1/1295', 'H03M1/56', 'H04N25/581', 'H04N25/583', 'H04N25/59', 'H04N25/709', 'H04N25/77', 'H04N25/771', 'H04N25/772', 'H04N25/778', 'H04N25/78', 'H04N25/79']"
US20240273308A1,System and method for visual content generation and iteration,"Systems, methods, and other embodiments described herein relate to enhancing and complementing a creative process of a user that includes generating and iterating visual content with an emphasis on diverse design ideas. In one embodiment, a method includes generating a plurality of texts that are related and semantically diverse based on one or more prompts using a generative language model and generating a plurality of images based on at least a portion of the plurality of texts using a generative visual model.","['G06F40/40', 'G06F40/56']"
US20240144480A1,Dental treatment video,"A method and/or system generates a video of teeth of an individual over time. In one example, images comprising teeth of an individual are received, wherein the images are arranged in a sequence and each image is associated with a different stage of treatment of the teeth. One or more of the images are modified and/or replaced to align the images to one another. One or more synthetic images are generated, wherein each synthetic image is generated based on a pair of sequential images in the sequence and is an intermediate image that comprises an intermediate state of the teeth between a first state of a first image of the pair of sequential images and a second state of a second image of the pair of sequential images. A video is then generated that comprises the images and the one or more synthetic images.","['G06T7/0012', 'A61B5/4547', 'A61B5/4836', 'G06T11/60', 'G06T3/0006', 'G06T3/02', 'G06T3/40', 'G06T5/10', 'G06V10/242', 'G06V10/44', 'G06V10/56', 'G06V10/82', 'G06V40/171', 'G06V40/174', 'G16H30/40', 'A61B2576/00', 'G06T2207/20084', 'G06T2207/30036']"
US20240170003A1,Audio Signal Enhancement with Recursive Restoration Employing Deterministic Degradation,An audio processing system and method for processing audio is disclosed. The audio processing system collects an input audio signal indicative of degraded measurements of a target audio waveform. The input audio signal is restored with recursive restoration that recursively restores the input audio signal until a termination condition is met. A current iteration of the recursive restoration applies a restoration operator configured to restore a degraded audio signal conditioned on a current level of severity of degradation and degrades the degraded audio signal deterministically with a level of severity less than the current level of severity. A target signal estimate indicative of enhanced measurements of the audio waveform is generated as output.,"['G10L21/0308', 'G10L25/30']"
US20240338554A1,Systems and methods for generating descriptions of data sets and/or models,"A method for generating a description of a data set may include generating a data dictionary that associates fields of the data set with descriptions of the fields based on analysis data and context data. The analysis data may indicate results of analysis of the data set including values of the fields and a value of an outcome variable. The context data may characterize a use case of the data set. The method may include generating a summary of the analysis data based on the analysis data and the dictionary; generating a description of a relationship between the outcome variable and a subset of the fields based on the context data, the summary of the analysis data, and the dictionary; generating a potential explanation for the relationship based on the context data and the description of the relationship; and outputting data based on the potential explanation.","['G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06N5/045']"
CN117078798A,Automatic editing prompting method for improving text-to-image generation based on reinforcement learning,"The invention relates to a method for improving text-to-image generation automatic editing prompts based on reinforcement learning. The method uses a reward network and an edit network. The reward network estimates the quality of the generated images corresponding to the edit cues and the degree of semantic alignment between them. To pre-train the bonus network, hint image alignment scores and image aesthetic scores obtained from an established database of diffiondb or the like are used as labels. The GPT architecture-based editing network generates modifiers for input hints. It trains in offline reinforcement learning, producing the desired cues given the target rewards. The method can effectively edit the prompt without repeatedly running the generated model. Experimental results show that the prompt edited by the method can generate a high-quality image which is consistent with the original input semantics and accords with human preference.","['G06T11/60', 'G06N20/00', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
CN119273810A,"Image generation method, electronic device and storage medium","The application discloses an image generation method, which comprises the steps of obtaining a reference face image, text prompt words and source noisy data Z T, wherein the text prompt words are used for describing the characteristics of a customized image, Z T is noisy data obtained by gradually adding Gaussian noise for T time steps to the reference face image through a diffusion model, generating a word element embedded vector based on the reference face image and the text prompt words, inputting the word element embedded vector into a denoising device of the diffusion model to obtain a denoising device on the condition of the word element embedded vector, inputting Z i into the denoising device on the condition of the word element embedded vector to perform noise estimation to obtain first noise data E i, and generating second noise data according to E iãZi and the reference face imageAccording toAnd Z i generates noisy data Z iâ1 of the ith-1 time step, the initial value of i is T, the i is accumulated and subtracted by 1, the step is circularly executed until i=0, the noiseless data Z 0 is obtained, and a customized image corresponding to the reference face image is generated based on Z 0.","['G06T11/60', 'G06V10/30', 'G06V10/80', 'G06V10/82', 'G06V40/161', 'G06V40/172']"
CN118230191A,SAR image generation method based on denoising diffusion probability model,"The invention belongs to the technical field of SAR image generation, and discloses a SAR image generation method based on a denoising diffusion probability model, which comprises the steps of firstly acquiring an SAR data set and constructing a training data set; the method comprises the steps of constructing a denoising diffusion probability model main frame, wherein the denoising diffusion probability model main frame comprises a Gaussian diffusion network and a UNet network, the Gaussian diffusion network carries out forward denoising and backward denoising on a real SAR image x 0, and the UNet network is used for carrying out noise prediction; randomly sampling a batch of images from the SAR training data set as input data, sampling a random Gaussian noise from standard Gaussian distribution, and adding the Gaussian noise to the sampled data according to the time step t until the sampled data becomes random noise which tends to normal distribution; sampling random noise x t from standard Gaussian distribution, carrying out heavy parameter skill sampling on x t through noise mean and variance predicted by a UNet network to obtain x tâ1, and carrying out denoising in T steps to generate a high-fidelity false SAR image x' 0. The method and the device avoid the problem of mode collapse in the training process, and improve the quality and diversity of the generated SAR image.","['G06V20/13', 'G06N3/0464', 'G06N3/08', 'G06V10/82']"
US11959968B2,Method and system with battery management,"A battery management method and system are provided. The method includes acquiring one or more parameters associated with the battery. The one or more parameters includes a current level, a voltage level, a State of Charge (SOC), and a temperature. The method includes determining a load and energy estimation model based on the one or more acquired parameters. The method includes identifying a power limit of the battery based on the load and energy estimation model. The method includes determining a power margin of the battery at a first usage time interval based on the identified power limit. The method includes performing one or more actions, based on a determination that the power margin of the battery exceeds a predefined threshold level.","['G01R31/367', 'B60L58/12', 'B60L58/16', 'G01R31/371', 'G01R31/382', 'G01R31/392', 'B60L2240/545', 'B60L2240/547', 'B60L2240/549', 'Y02T10/70']"
US12373494B2,Speculative decoding in autoregressive generative artificial intelligence models,"Certain aspects of the present disclosure provide techniques and apparatus for generating a response to a query input in a generative artificial intelligence model. An example method generally includes receiving a plurality of sets of tokens generated based on an input prompt and a first generative artificial intelligence model, each set of tokens in the plurality of sets of tokens corresponding to a candidate response to the input prompt; selecting, using a second generative artificial intelligence model and recursive adjustment of a target distribution associated with the received plurality of sets of tokens, a set of tokens from the plurality of sets of tokens; and outputting the selected set of tokens as a response to the input prompt.","['G06F16/9027', 'G06F40/284']"
US20240282025A1,Text-based image generation,"Systems and methods for image generation are provided. An aspect of the systems and methods includes obtaining a text prompt, generating a style vector based on the text prompt, generating an adaptive convolution filter based on the style vector, and generating an image corresponding to the text prompt based on the adaptive convolution filter.","['G06T11/60', 'G06F40/284', 'G06F40/126', 'G06F40/151', 'G06T11/001', 'G06T5/20', 'G06T2207/20004', 'G06T2207/20081', 'G06T2207/20084']"
US20240311405A1,Dynamic selection from among multiple candidate generative models with differing computational efficiencies,"Implementations disclose selecting, in response to receiving a request and from among multiple candidate generative models (e.g., multiple candidate large language models (LLMs)) with differing computational efficiencies, a particular generative model to utilize in generating a response to the request. Those implementations reduce latency and/or conserve computational resource(s) through selection, for various requests, of a more computationally efficient generative model for utilization in lieu of a less computationally efficient generative model. Further, those implementations seek to achieve such benefits, through utilization of more computationally efficient generative models, while also still selectively utilizing less computationally efficient generative models for certain requests to mitigate occurrences of a generated response being inaccurate and/or under-specified. This, in turn, can mitigate occurrences of computational and/or network inefficiencies that result from a user issuing a follow-up request to cure the inaccuracies and/or under-specification of a generated response.",['G06F16/3329']
CN116580156A,Text generation 3D printing model method based on big data deep learning,"The application provides a text generation 3D printing model method based on big data deep learning, which directly generates the text or image into implicit function parameters which can be presented as texture grids and nerve radiation fields, and then renders the text or image into a three-dimensional model. Compared with explicitly generated model Point-E based on Point cloud, the method has the advantages that the convergence is faster, and the comparable or better sample quality is achieved when modeling a high-dimensional and multiple representation output space.","['G06T17/00', 'G06N3/045', 'G06N3/08', 'G06T19/20', 'Y02P90/30']"
CN118606707A,Training method and system of EEG signal enhancement model based on diffusion model,"The embodiment of the invention provides a training method of an electroencephalogram signal enhancement model based on a diffusion model. The method comprises the following steps: inputting the original electroencephalogram signals into an electroencephalogram signal enhancement model; performing forward diffusion of the t steps on the original brain electrical signal by using a diffusion model to obtain a t-1 step diffusion enhancement result x tâ1 and a t step diffusion enhancement result x t; inputting the enhancement result x t and the corresponding emotion label into a semantic segmentation model for control output, and outputting specified electroencephalogram enhancement parameters through the semantic segmentation model; resampling by utilizing the electroencephalogram enhancement parameters to obtain the mean value and variance of the diffusion in the t-1 step and a penalty term for controlling sampling, and estimating an enhancement result x' tâ1 of the diffusion in the t-1 step based on the mean value, variance and penalty term; the electroencephalogram enhancement model is trained based on the error loss of the enhancement result x tâ1 and the enhancement result x' tâ1. According to the embodiment of the invention, the electroencephalogram signal enhancement model is trained based on the diffusion model, and penalty items are introduced, so that the diversity of generated samples is increased.","['A61B5/372', 'A61B5/7267', 'G06F18/214', 'G06F18/2163', 'G06F18/241']"
US20240161468A1,Techniques for generating images of object interactions,"Techniques are disclosed herein for generating an image. The techniques include performing one or more first denoising operations based on a first machine learning model and an input image that includes a first object to generate a mask that indicates a spatial arrangement associated with a second object interacting with the first object, and performing one or more second denoising operations based on a second machine learning model, the input image, and the mask to generate an image of the second object interacting with the first object.","['G06T5/77', 'G06T5/002', 'G06T5/005', 'G06T5/70', 'G06T7/11', 'G06V10/774', 'G06V10/82', 'G06V40/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
WO2024215877A1,Building management system with generative ai-based equipment services,"A method includes receiving, by one or more processors, a plurality of first unstructured service reports corresponding to a plurality of first service requests handled by technicians for servicing building equipment. The plurality of first unstructured service reports may include unstructured data not conforming to a predetermined format or conforming to a plurality of different predetermined formats. The method may include training, by the one or more processors, a generative Al model using the plurality of first unstructured service reports. The method may include performing, by the one or more processors using the trained generative Al model, one or more actions with respect a second service request subsequent to training the generative Al model.","['G06Q10/20', 'G06Q50/08', 'G06N20/20']"
CN116703747A,Virtual fitting image restoration method based on diffusion condition generation algorithm,"The invention discloses a virtual fitting image restoration method based on a diffusion condition generation algorithm, which belongs to the field of deep learning image restoration, wherein an improved Unet is used as a skeleton network, and image restoration reconstruction is carried out by introducing a virtual fitting related picture condition code in a cross attention fusion mode. And continuously iterating by using a supervision training mode according to paired pictures acquired by the virtual fitting images to obtain the diffusion step number and the head number of the multi-head attention suitable for the repair model. Finally, the optimal evaluation index is obtained on the plurality of image generation class indexes IS, SSIM, FID. The method exceeds the existing image restoration algorithm realized based on deep learning on many indexes, and improves the fitting effect of the traditional virtual fitting.","['G06V10/806', 'G06N3/0455', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'Y02T10/40']"
US20240330580A1,Generation of Personalized and Structured Content Using a Collaborative Online Generator,"Systems and methods for generating personalized and structured content using a collaborative generator provide a user interface to a user computing system and receive a prompt from the user computing system via the user interface. The systems and methods provide the prompt to a generative model, with the generative model being a machine-learned model trained to process language input prompts to generate a language output. The systems and methods receive a generative output generated by the generative model in response to the prompt. Additionally, the systems and methods generate a modified output by modifying the generative output based at least in part on historical user data for a user associated with the prompt, and then provide the modified output via the user interface.","['G06F40/56', 'G06F40/103', 'G06F40/30', 'G06F40/186', 'G06F40/20']"
CA3108596C,Controlling wellbore equipment using a hybrid deep generative physics neural network,"A system includes equipment for at least one of formation of, stimulation of, or production from a wellbore, a processor, and a non-transitory memory device. The processor is communicatively coupled to the equipment. The non-transitory memory device contains instructions executable by the processor to cause the processor to perform operations comprising training a hybrid deep generative physics neural network (HDGPNN), iteratively computing a plurality of projected values for wellbore variables using the HDGPNN, comparing the projected values to measured values, adjusting the projected values using the HDGPNN until the projected values match the measured values within a convergence criteria to produce an output value for at least one controllable parameter, and controlling the equipment by applying the output value for the at least one controllable parameter.","['E21B44/00', 'E21B47/06', 'E21B7/04', 'E21B47/07', 'G01V20/00', 'G05B13/027', 'G05B13/042', 'G06F30/27', 'G06N3/045', 'G06N3/0475', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'E21B2200/20', 'E21B2200/22', 'G06F17/00']"
US20210142168A1,Methods and apparatuses for training neural networks,"Method of classifying data may include training, by processing circuitry, a neural network based on labeled inputs of a training data set; identifying, by the processing circuitry, a refinement subset of unlabeled inputs of a pool data set by determining, for each unlabeled input, a first distance of the unlabeled input to the labeled inputs of the training data set and a second distance of the unlabeled input to other unlabeled inputs of the pool data set; submitting, by the processing circuitry, the refinement subset to a labeling process to produce a labeled subset; training, by the processing circuitry, the neural network based on the labeled subset to produce a trained neural network; and classifying, by the processing circuitry, new data using the trained neural network.","['G06N3/08', 'G06N3/084', 'G06N3/045', 'G06N3/0454', 'G06N3/063']"
CN116484858A,Text Summarization Method Based on Diffusion Model,"The invention discloses a text abstract generating method based on a diffusion model, which comprises the steps of firstly, performing word segmentation operation on a source text by using a natural language processing model; then, pre-encoding and converting the text data into sentence representation by the pre-processed source text through an input module by utilizing a word embedding method, and then mapping the text vector onto a space dimension capable of being continuously transformed by utilizing an evaluation module to realize controllable linear continuous transformation of the text vector; and finally, acquiring a target text through a condition guiding module, generating samples through gradient guiding in the sampling process of the diffusion model, reducing errors of generated text vectors and real text vectors by using a control module, and finally generating a text abstract through an output module according to the acquired sample vectors. The method realizes the generation of the text abstract based on the generated model, is beneficial to improving the accuracy of the text abstract and improves the semantic generalization of the model.","['G06F40/289', 'G06F18/214', 'G06F40/211', 'G06F40/30', 'Y02D10/00']"
CN118096578A,"Infrared and visible light image fusion method and device, electronic equipment and storage medium","The invention provides an infrared and visible light image fusion method, an infrared and visible light image fusion device, electronic equipment and a storage medium. The method comprises the following steps: performing feature extraction on the stacked infrared image and visible light image based on an encoder in the trained self-encoder network to obtain hidden space features of the infrared image and the visible light image; wherein the self-encoder network comprises an encoder and a decoder; noise adding and denoising are carried out on the hidden space features based on the trained diffusion network, so that the combined features of the infrared image and the visible light image are obtained; and carrying out feature extraction, splicing and reconstruction on the hidden space features and the combined features based on the trained fusion network to obtain fusion images corresponding to the infrared image and the visible light image. The invention can realize the image fusion with high efficiency and high color fidelity.","['G06T5/50', 'G06N3/0455', 'G06N3/08', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
CN116934907A,"Image generation method, device and storage medium","The application provides an image generation method, device and storage medium, wherein the method comprises the following steps: responding to an image generation request, and acquiring an original image to be processed, which is designated by the generation request; extracting a main image of a target object in the original image and an edge image of the original image, and acquiring a description text corresponding to the original image; generating a plurality of new visual images according to the edge images and the descriptive text, wherein the plurality of new visual images respectively comprise the same spatial scene as the original images and different visual information; and respectively carrying out image fusion on the plurality of new visual images and the main image to obtain a plurality of target images of the target object in different scenes. According to the method, the scene images of the target object are automatically generated in batches based on the original images, and the generation efficiency of the scene images of the target object is improved.","['G06T11/60', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06T7/13', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'Y02D10/00']"
US20150213392A1,System and Method of Using Task Fingerprinting to Predict Task Performance,"A novel method of using task fingerprinting to predict outcome measures such quality, errors, and the likelihood of cheating, particularly as applied to crowd sourced tasks. The technique focuses on the way workers work rather than the products they produce. The technique captures behavioral traces from online crowd workers and uses them to build predictive models of task performance. The effectiveness of the approach is evaluated across three contexts including classification, generation, and comprehension tasks.","['G06Q10/06398', 'G06N20/00', 'G06N20/10', 'G06N5/04', 'G06Q10/067', 'G06Q50/01']"
US20250022071A1,Generating social media content for a user associated with an enterprise,"Systems and methods disclosed herein relate to fine-tuning machine learning (ML) chatbots for an enterprise. The systems and methods may use ML chatbots and/or generative ML to generate social media content for a user associated with an enterprise. The systems and methods may fine-tune a base ML model, and use the fine-tuned ML model for the ML chatbot. A user profile may indicate user attributes, and a fine-tuned ML model may be loaded for the ML chatbot based upon an identified user profile.","['H04L51/02', 'G06Q50/01']"
US20240394593A1,Providing information based upon user interaction at a portal,"Systems and methods disclosed herein relate to fine-tuning machine learning (ML) chatbots for an enterprise. The systems and methods may use ML chatbots and/or generative ML to provide information to a user based upon the user's interaction at a portal of an enterprise. The systems and methods may fine-tune a base ML model, and use the fine-tuned ML model for the ML chatbot. The user's interactions may be classified as a type of user activity. A fine-tuned ML model may be loaded as the ML chatbot based upon the type of user activity.","['G06N20/00', 'G06N3/006', 'G06N5/022']"
US20240428481A1,Generating ground truths for generative ai applications,"A first neural network is trained to generate a ground truth using a small set of example images that illustrate the goal ground truth output images, which can be full-body images of people in an AR style. The first neural network is used to generate ground truth output images from random input images. Example methods of the first neural network include determining poses in input images, changing values of pixels within areas of the input images, inputting the poses, the areas of the changed input images, and a text prompt describing the input images, into a neural network, to generate output images. The methods further include determining losses between the output images and the input images and updating weights of the neural network based on the losses. A second neural network is then trained using the generated ground truth. And, an application is generated that uses the second neural network.","['G06F40/40', 'G06F40/279', 'G06T11/60', 'G06T7/73', 'G06V10/82', 'G06V40/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2210/12']"
CN118229860A,A 3D human body generation method based on text prompts,"The invention discloses a method for generating a high-resolution three-dimensional human body based on text prompt. 1) Three-dimensional gaussian splatter representation: directly encoding textures into three-dimensional Gaussian attributes by randomly initializing texture mapping, sampling at fixed positions on each standard field shell, and rendering the shell surface by using Gaussian splatter technology; (2) parameterizing human programming: the shell deformation of the SMPL model is carried out by using micro transformation, so that the natural fusion of Gaussian shells is realized; (3) diffusion model generation guidance: and (3) through variational distillation sampling, the human body generation is guided by using large-scale pre-training knowledge of a diffusion model. According to the invention, through differential rendering, under the guidance of the diffusion model, an avatar supporting animation is generated, and real-time rendering is supported.","['G06T15/005', 'G06N3/04', 'G06N3/08', 'G06T15/04']"
WO2023081413A2,Methods and systems for discovery of embedded target genes in biosynthetic gene clusters,"The present disclosure relates to computer-based methods and systems for identifying genes associated with biosynthetic gene clusters (BGCs), including embedded target genes (ETaGs) that are homologs of potential therapeutic targets, using comparative genomics techniques and machine learning models.","['G16H20/10', 'G16B40/20', 'G06N20/20', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06N5/01', 'G06N7/01', 'G16B10/00', 'G16B20/30', 'G16B30/10', 'G16H50/20', 'G16H50/70']"
CN117876519A,A chord diagram recovery method and system based on diffusion model,"The invention discloses a chord graph recovery method and a chord graph recovery system based on a diffusion model, wherein the method comprises the following steps: constructing a maximum posterior distribution under the condition of known projection data according to the CT projection noise generation model; decoupling the maximum posterior distribution into a plurality of fractional functions, and training the fractional functions of the approximate chord graph priori of the denoising network by using a diffusion probability model; constructing an inverse random differential equation process for given chord graph data and received quantum numbers according to an original diffusion model and the fractional function, and gradually recovering the chord graph from Gaussian distribution by sampling; the invention has effective chord chart restoration capability, can learn the distribution condition of data from the prior chord chart image, and can restore the data through a diffusion model, thereby providing more accurate and complete chord chart information.",['G06T11/008']
CN118410199A,Method and device for generating image based on text,"The embodiment of the application discloses a method and a device for generating an image based on text, and relates to the technical field of artificial intelligence and computer vision. According to the application, the encoder of the large language model is introduced into encoding the prompt text, and the fine granularity understanding of the encoder of the large language model to the prompt text is fully utilized, so that the semantic details of the prompt text can be better understood by the result image generated by the image generation model, and the following capability of the generated result image to the text is improved. In addition, the image-text pair used in training can acquire images from a high-quality image data set as image samples, and then generate high-quality text samples for the image samples by means of the text generation capacity of the image-text model, so that the performance of the image generation model is improved.","['G06F16/5846', 'G06F40/30', 'G06N3/0464', 'G06N3/08', 'G06N5/04']"
WO2025001846A1,Method and system for enhancing sense of reality of virtual model on basis of generative network,"Provided in the present disclosure are a method and system for enhancing the sense of reality of a virtual model on the basis of a generative network. The method comprises: acquiring a rendered image of a virtual model wearing digital clothing; determining whether parsing information about the digital clothing in the rendered image is known; if the parsing information is unknown, performing extraction on the basis of a preset algorithm; converting the parsing information and then inputting converted parsing information into a generative network; under the control of a generative control condition, making the generative network generate a model character with a stronger sense of reality in a model area on the basis of model information; and converting the model character to obtain a generated image of a model wearing the digital clothing. By means of the solution in the present disclosure, on the basis of generative AI technology with high controllability, the sense of reality of clothing models can be significantly improved by fully utilizing priori information of digital clothing and priori information of a virtual model; and the high fidelity of modeled clothing is also kept, such that the solution is applied at a high adaptability to the alignment from the virtual model in a digital world to a real person model in a real world.","['G06T17/00', 'G06V10/44']"
CN118298127B,"Three-dimensional model reconstruction and image generation method, device, storage medium and program product","The embodiment of the application provides a three-dimensional model reconstruction and image generation method, equipment, a storage medium and a program product. In the method, multi-stage three-dimensional reconstruction is performed based on a single image of a target object, in a first stage, generation of a plurality of view images is performed based on an image generation model, and reconstruction of an initial three-dimensional model is performed based on the plurality of view images; in the second stage, the association relation between the target object and the set mark information is learned by utilizing the meridional graph model based on a plurality of view images and the initial prompt word containing the set mark information, and a plurality of scene images are generated on the basis, so that compared with the plurality of view images, the resolution of the scene images generated in the second stage is higher, the image details are more abundant, and the initial three-dimensional model is optimized based on the plurality of scene images, so that the target three-dimensional model with higher resolution and clearer model details can be obtained, and conditions are provided for the floor application of the three-dimensional reconstruction scheme based on a single image.","['G06T17/20', 'G06T3/4038', 'G06T7/55', 'G06T2200/04', 'G06T2200/32']"
US12165276B2,Generative films,"Obtaining input video data depicting footage of an object, obtaining current values of a set of adjustable parameters of an object representation model comprising a neural network and arranged to generate animated representations of the object using the neural network in which a geometry of the object is controllable by the set of adjustable parameters. For a plurality of iterations, using the object representation model to generate a video layer comprising an animated representation of the object in which the geometry of the object corresponds to the current values of the set of adjustable parameters, presenting composite video data comprising the video layer overlaid on the object in the input video data, and updating the current values of the set of adjustable parameters in response to user input via the user interface.","['G06T19/20', 'G06T13/40', 'G06T3/4046', 'G10L15/02', 'G10L25/30', 'G10L25/57', 'H04N5/2224', 'H04N5/272', 'G06T2200/24', 'G06T2219/2021', 'G10L2015/025', 'G10L21/10']"
US12387404B2,Generating memes and enhanced content in electronic communication,"Methods and systems are described for generating memes and enhanced content in electronic communication. The communication is received, analyzed, and assessed for determining whether the enhanced content should be included in the communication. A content, context, intent, and/or mood of the communication is determined. For meme generation implementations, images and captions are generated based on the communication. Some candidate memes incorporate an image of one of the participants in the communication. Enhanced content candidates are generated and presented to the user for inclusion in the communication. Artificial intelligence systems, including neural networks, and models are utilized to improve the enhanced content generation. Related apparatuses, devices, techniques, and articles are also described.","['G06F3/0482', 'G06F40/30', 'G06T11/60', 'H04L51/10', 'G06T2200/24']"
US12182149B1,Application prediction based on a visual search determination,"Visual search in an operating system of a computing device can process and provide additional information on the content being provided for display. The computing device can include an operating system that includes a visual search interface that obtains and processes display data associated with content currently being provided for display. The visual search interface can generate display data based on the current content provided for display, process the display data with one or more on-device machine-learned models, and provide additional information to the user. The visual search interface may transmit data associated with the display data to perform additional data processing tasks. Application suggestions may be determined and provided based on the visual search data.","['G06F16/248', 'G06V30/147', 'G06Q30/0641', 'G06F16/434', 'G06F16/532', 'G06F16/538', 'G06F16/54', 'G06N20/00', 'G06V30/148', 'G06V30/19147', 'H04L51/04', 'G06F9/451']"
US12231151B1,Federated large codeword model deep learning architecture with homomorphic compression and encryption,"A system and method for a federated deep learning platform utilizing homomorphically-compressed and encrypted data. The system comprises multiple client devices, each with a local dataset, and a central server hosting a deep learning core. Client devices convert local data into codewords, which are also homomorphically encrypted. The central server processes these encrypted codewords without decryption, preserving data privacy. The platform supports at least two architectural variants: a conventional Transformer trained on codewords, and a Latent Transformer operating on latent space vectors. Both variants eliminate the need for embedding and positional encoding layers. The system aggregates encrypted model updates from clients, enabling collaborative learning while maintaining data confidentiality. Additional features comprise differential privacy implementation and adaptive federated optimization techniques. This innovative approach allows for efficient, privacy-preserving distributed learning across diverse datasets, addressing key challenges in federated learning such as data heterogeneity, non-IID distributions, and communication efficiency.","['H03M7/3059', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'H03M7/6005']"
US20250085700A1,Generative ai for industrial automation design environment,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.","['G05B19/4183', 'G05B19/41885']"
US20250076836A1,Generative ai for industrial automation design environment troubleshooting,"An integrated development environment (IDE) for designing, programming, and configuring aspects of an industrial automation system uses a generative artificial intelligence (AI) model and associated neural networks to generate portions of an industrial automation project in accordance with functional requirements provided to the industrial IDE system in intuitive formats, such as spoken or written plain language text. The system uses generative AI to translate plain language requests or functional specifications into industrial control code, human-machine interface (HMI) applications, device configuration settings, or other aspects of an industrial control project.","['G05B19/054', 'G05B19/042', 'G05B19/056', 'G05B19/058']"
CN117351299A,"Image generation and model training methods, devices, equipment and storage media","The disclosure provides an image generation and model training method, device, equipment and storage medium, relates to the technical field of artificial intelligence, in particular to the technical fields of computer vision, deep learning, large models and the like, and can be applied to scenes such as image processing and the like. The training method of the image generation model comprises the following steps: acquiring a first generation result of a teacher model; obtaining a second generation result of the student model; the student model generates a model for an image to be trained; constructing a loss function based on the first and second generation results; updating the first parameter matrix and the second parameter matrix based on the loss function, and obtaining an updated target parameter matrix according to the updated first parameter matrix and the updated second parameter matrix; the rank of the first parameter matrix and the rank of the second parameter matrix are both smaller than the rank of the target parameter matrix. The present disclosure may reduce computing resource overhead.","['G06V10/774', 'G06F17/16', 'G06V10/82']"
US20250259057A1,Multi-dimensional generative framework for video generation,"Generating a multi-dimensional video using a multi-dimensional video generative model for, including, but not limited to, at least one of static portrait animation, video reconstruction, or motion editing. The method including providing data into the multi-dimensionally aware generator of the multi-dimensional video generative model, and generating the multi-dimensional video from the data by the multi-dimensionally aware generator. The generating of the multi-dimensional video includes inverting the data into a latent space of the multi-dimensionally aware generator, synthesizing content of the multi-dimensional video using an appearance component of the multi-dimensionally aware generator and corresponding camera pose and formulating an intermediate appearance code, developing a synthesis layer for encoding a motion component of the multi-dimensionally aware generator at a plurality of timesteps and formulating an intermediate motion code, introducing temporal dynamics into the intermediate appearance code and the intermediate motion code, and generating multi-dimensionally aware spatio-temporal representations of the data.","['H04N19/188', 'G06N3/08', 'G06N3/047', 'G06N3/088', 'H04N19/172', 'H04N19/187', 'H04N19/33', 'H04N19/53', 'H04N19/59', 'G06T2207/20081']"
CN117974950A,Virtual fitting method and system for generating portrait fitting effect according to image reversal,"The invention relates to the technical field of virtual fitting, and discloses a virtual fitting method and a virtual fitting system for generating a portrait fitting effect according to image reversal, wherein the virtual fitting method comprises the following steps: constructing a virtual try-on model comprising a diffusion model, an appearance flow deformation module, three encoders and a discriminator, wherein the encoders respectively extract the characteristics of clothes images, character images and clothes style data, and the appearance flow deformation module generates predicted deformed clothes; taking the clothes image and the marked person image as a training set training virtual try-on model, adding noise to the clothes image, inputting a diffusion model and a discriminator to generate an image, performing edge softening treatment on the generated image, detecting shielding information of the person and clothes in the generated image, and feeding back the shielding information to the corresponding image; and acquiring the clothes to be virtualized and the character images, and inputting the clothes to be virtualized and the character images into the trained model to obtain a virtual try-on result. The invention can fully extract detail characteristics of clothes, adjust image boundaries and consider limb shielding relations, and enhances fidelity and detail expressive force of a result diagram.","['G06T19/20', 'G06N3/0464', 'G06T19/006', 'G06T2207/20084', 'Y02P90/30']"
CN117853686A,Free text guided arbitrary track three-dimensional scene construction and roaming video generation method and system,"The invention discloses a method and a system for constructing a free-text guided arbitrary track three-dimensional scene and generating a roaming video. An initial scene graph and a depth graph are generated from the input text. And selecting a plurality of poses near the initial camera pose, generating corresponding images, and forming a support data set. To realize the generation of a new view angle scene graph, a three-plane feature extraction model and a nerve radiation field decoding model are designed. Adopting a frame-by-frame rendering mode, and processing aiming at each pose: and performing rough rendering by utilizing the three-plane characteristics to obtain a preliminary result, and then inputting a geometric perception optimization model for fine correction. The process is repeated to complete all sampling points and update the support data set. And extracting an image sequence from the support data set according to the preset camera track, and synthesizing the roaming video. The method adopts three-plane characteristics to effectively reduce the parameter quantity, and the geometric optimization model can correct the rough result to improve the generation quality. The invention can generate indoor and outdoor scenes of random track roaming, and solves the limitation of the traditional method.","['G06T19/003', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06T15/005', 'G06T15/08', 'G06T15/50', 'G06T17/10', 'G06V10/42', 'G06V10/454', 'G06V10/7715', 'G06V10/806', 'G06V10/82', 'H04N21/44012', 'H04N21/816', 'G06N3/048', 'Y02T10/40']"
US20250200293A1,Natural language generation,"Techniques for using a model to generate a response to a user input, where the response is associated with a personality determined to be relevant to the user input, are described. The system receives a user input and context data associated with the user input. Using the user input data and/or the context data, the system determines a personality (e.g., including a personality type and/or personality characteristics) relevant to the user input. The system generates a prompt instructing a model to generate a response to the user input that corresponds to the personality. The model processes the prompt to generate a response to the user input that corresponds to the personality. In some embodiments, the model generates a request for another component of the system to generate information responsive to the user input. The model may transform the responsive information into the personality-associated response.","['G06F40/40', 'G06F40/35', 'H04L67/306', 'G10L13/00', 'G10L15/22']"
CN117195872A,Context awareness prompt-based generated event argument extraction method,"The invention discloses a context awareness prompt-based generation type event argument extraction method, which belongs to the technical field of event argument extraction and comprises the following steps: acquiring a text, and designing an initial prompt for event argument extraction; based on the initial prompt, obtaining a context representation and a perceived prompt of the context; based on the context awareness prompt, obtaining the starting position and the ending position of each argument span inquirer; extracting the span of the relevant argument in the context representation to obtain the span of the predicted argument corresponding to each slot position; and constructing and training an event argument extraction model, aligning the context perception prompt with the context by using the trained event argument extraction model, and extracting to obtain an event argument. The invention solves the problem that the computational complexity is difficult to be reduced while extracting all arguments.",['Y02D10/00']
CN119006617A,Dream decoding method based on functional magnetic resonance imaging signals,"The invention relates to a dream decoding method based on functional magnetic resonance imaging signals, which comprises the following steps: collecting fMRI data of the tested sleep stage and recording a dream report; preprocessing different tested fMRI signals, and converting the signals into uniform 2D brain activation images; training among a plurality of tested to obtain a unified model, namely a real visual stimulus perception reconstruction model; transferring the trained real visual stimulus perception reconstruction model to a dream visual image decoding task, outputting to obtain a plurality of independent dream visual decoding images, and obtaining a plurality of dream segments; based on an intelligent director framework comprising three stages of single shot dream description, dream story description and video integration, a plurality of dream segments are integrated into one coherent narrative video. Compared with the prior art, the invention can correlate the brain activity mode at each moment with the corresponding illusive visual frame to obtain the corresponding dream image, and the image is dynamically assembled to construct the complete visual narrative of the dream.","['G06T9/002', 'G06N3/0464', 'G06V10/774', 'G06V10/82']"
US12390738B2,Plotting behind the scenes with learnable game engines,"A framework trains game-engine-like neural models from annotated videos to generate a Learnable Game Engine (LGE) that maintains states of the scene, objects and agents in it, and enables rendering the environment from a controllable viewpoint. The LGE models the logic of the game and the rules of physics, making it possible for the user to play the game by specifying both high- and low-level action sequences. The LGE also unlocks a director's mode where the game is played by plotting behind the scenes, specifying high-level actions and goals for the agents using text-based instructions. To implement the director's mode, a trained diffusion-based animation model navigates the scene using high-level constraints, to enable play against an adversary, and to devise the strategy to win a point. To render the resulting state of the environment and its agents, a compositional neural radiance field (NeRF) representation is used in a synthesis model.","['A63F13/67', 'A63F13/57', 'A63F2300/66']"
WO2025102946A1,"Picture processing method and apparatus, device, and storage medium","The present application relates to the technical field of image processing, and discloses a picture processing method and apparatus, a device, and a storage medium. The method comprises: generating conditional embedding information on the basis of an original portrait picture and description text; on the basis of the original portrait picture, the conditional embedding information, and a facial mask map, generating a cross attention map corresponding to the original portrait picture; and on the basis of the conditional embedding information and the cross attention map, performing editing to obtain a processed portrait picture corresponding to the original portrait picture. The method can be applied to various scenarios such as cloud technology, artificial intelligence, intelligent transportation, and assisted driving. According to the method, a facial feature of a person in the original portrait picture and a person expression feature in the description text are fused, thereby ensuring a high similarity between the person in the generated processed portrait picture and the person in the original portrait picture and significantly improving the person fidelity in an editing process.","['G06T11/60', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0985', 'G06V40/168']"
US20250119354A1,Generative models to create network configurations through natural language prompts,"In one implementation, a device obtains a natural language-based description of a network via a user interface. The device generates, based on the natural language-based description, network configuration parameters for the network using a generative model. The device conducts a simulation of traffic in the network using the network configuration parameters, to obtain telemetry data. The device uses the telemetry data to train a machine learning model to perform network analytics.","['H04L41/147', 'H04L41/0846', 'H04L41/12', 'H04L41/142', 'H04L41/145', 'H04L41/149', 'H04L41/16']"
US20250182858A1,Large Language Model for Unified Text and Point Cloud Molecular Input,"A transformer model architecture is described. The transformer model architecture comprises a point cloud input module, a text input module, a point cloud encoder module operatively coupled with the point cloud input module, a large language model module operatively coupled to the text input module and point cloud encoder module and configured to receive data therefrom, and a text output module operatively coupled to the large language model module. The text output module is configured to output molecular data in line notation format.","['G16B15/00', 'G06N3/0455', 'G06N3/042', 'G06N3/088', 'G06N5/041', 'G06T7/75', 'G16B15/30', 'G16B40/00', 'G16B40/30', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
CN120295469A,Human-computer interaction method and equipment,"The embodiment of the specification provides a man-machine interaction method and equipment. The method comprises the steps of carrying out emotion semantic analysis on the obtained man-machine conversation data of the current conversation user, determining the current emotion state of the current conversation user, and generating and displaying a corresponding visual element based on the current emotion state of the current conversation user. According to the technical scheme of the embodiment of the specification, different emotion states of the user can be mapped to different visual elements, visual feedback expression of the emotion of the user is achieved, and therefore personalized vivid feedback can be carried out on the user in the process of the user and the AI dialogue.",[]
CN116884004A,"Image processing methods, devices, electronic equipment and storage media","The disclosure provides an image processing method, an image processing device, electronic equipment and a storage medium, relates to the technical field of artificial intelligence, and particularly relates to the technical fields of computer vision, image processing and machine learning. The image processing method comprises the following steps: responding to the image expansion request, and performing visual language identification on the first original image to obtain an image description text; generating a second original image and a first mask image based on the first original image by using a target aspect ratio and a first target resolution included in the image expansion request; taking the image description text and the second original image as semantic references, and generating an image based on the first mask image to obtain a first target mask image; and performing image stitching on the first target mask image and the second original image to obtain a target expansion image.","['G06V20/70', 'G06N3/0464', 'G06N3/08', 'G06T3/4038', 'G06V10/30', 'G06V10/82']"
US11381471B2,System and method for predicting and handling short-term overflow,"A system for early predicting of impending data overflow situations in data networks, comprising one or more sensors being networked computers that do not provide services, for collecting monitored data regarding network traffic volume from content providers to an Internet Service Provider (ISP) entering or exiting the ISP via peering autonomous systems connected to the ISP via physical links; one or more processors executing one or more deep learning models, being adapted to: identify over the data network being handovers alternative peering links, which are not inherent Private Network Interconnects (PNI) between the content providers and the ISP; determine static or dynamic threshold for dataflow anomaly associated with overflow; for each alternative handover, predict impending overflow situation by applying ML algorithms to the collected data that corresponds to the each alternative handover.","['H04L43/0876', 'G06N20/20', 'G06N3/04', 'H04L41/0654', 'H04L41/16', 'H04L43/04', 'H04L43/062', 'H04L43/067', 'H04L43/0888', 'H04L47/11', 'H04L47/127']"
US20240386202A1,Tuning generative models using latent-variable inference,Systems and methods for generative language model tuning can include training the generative language model to generate sets of output text tokens with set of intermediary text tokens with training examples that include input and output pairs. The training can include processing the input with the language model to determine a predicted output and a predicted set of intermediary text tokens. The predicted set of intermediary text tokens can then be evaluated based at least in part on the output associated with the input and the predicted output.,"['G06F40/56', 'G06F40/284', 'G06F40/30', 'G06F40/35']"
US11024404B2,System and method for medical image based cardio-embolic stroke risk prediction,"A system and method for medical image based patient-specific ischemic stroke risk prediction is disclosed. Left atrium (LA) and left atrium appendage (LAA) measurements are extracted from medical image data of a patient. Derived metrics for the LA and LAA of the patient are computed using a patient-specific computational model of cardiac function based on the LA and LAA measurements extracted from the medical image data of the patient. A stroke risk score for the patient is calculated based on the extracted LA and LAA measurements and the computed derived metrics for the LA and LAA of the patient using a trained machine learning based classifier, which inputs the extracted LA and LAA measurements and the computed derived metrics for the LA and LAA as features.","['G16H10/60', 'G06F17/11', 'G06T7/12', 'G06T7/149', 'G16H30/20', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G06N3/08', 'G06N7/005', 'G06N7/01', 'G06T2207/20081', 'G06T2207/30048']"
US20240404632A1,Method for Sequence-Based Prediction of Controlled Terms and Generating Protein Sequences from Controlled Terms using Enhanced Large Language Models,"The present invention relates to a method for enhancing the creativity of a generative pre-trained Large Language Model (LLM) in protein sequence generation and predicting controlled terms from protein sequences. The method includes incorporating 22 novel names representing the 22 amino acids into the vocabulary of the pre-trained LLM, conducting self-supervised learning using protein sequences encoded with the novel names to improve the LLM's comprehension and generation of coherent protein sequences, performing supervised learning using protein sequences to refine the LLM's ability to predict controlled terms based on protein sequences, and performing supervised learning to refine the LLM's ability to generate protein sequences based on controlled terms. The method includes generating the novel names either through a computer program or manually and utilizing datasets of protein sequences and their corresponding controlled terms from a protein database. The self-supervised learning employed is a masked language model (MLM). Additionally, an alternative method is disclosed, which involves identifying a set of 22 amino acid names from the original vocabulary of the pre-trained LLM and proceeding with self-supervised and supervised learning steps using the selected names. The two methods can be used independently or in combination to enhance the creativity of the LLM in achieving protein sequence generation and predicting controlled terms from protein sequences.","['G06N3/09', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G16B20/30', 'G16B30/00', 'G16B40/20']"
CN118279440A,Alignment optimization method and device for diffusion model of text-generated graph based on reinforcement learning,"The application discloses a method and a device for aligning and optimizing a diffusion model of a text-generated graph based on reinforcement learning, and relates to the technical field of reinforcement learning and computer vision; constructing and initializing a time difference evaluation model based on the obtained pre-trained reward function model; and carrying out fine adjustment updating on the pre-trained text-generated graph diffusion model and the initialized time difference evaluation model based on a set reinforcement learning strategy of multi-round iterative optimization until the generation result of the text-generated graph diffusion model is aligned with an optimization target. The method and the device can accelerate the model optimization process and reduce the potential optimization target deviation.","['G06T11/60', 'G06N3/092', 'Y02T10/40']"
CN118570064A,"Super-division method, device and storage medium for using priori knowledge in diffusion model without training","The invention discloses a super-division method, a device and a storage medium for using priori knowledge in a diffusion model without training, which comprise the following steps: inputting the image into a preliminary super-resolution model based on GAN, and generating a preliminary high-resolution image; extracting semantic tags of the input image; forward noise adding is carried out on the preliminary high-resolution image; inputting the preliminary high-resolution picture subjected to forward noise addition into a pre-trained diffusion model for denoising, controlling a restored image through a semantic tag, and restoring to obtain high-frequency detail information; and (3) obtaining a low-frequency contour map through Gaussian blur of an input image, and combining the low-frequency contour map with high-frequency detail information to obtain a super-resolution image. The invention can finish superdivision task with high quality in extremely low time. The invention can be easily adapted to different pre-training models without additional training. And because there is no module trained for a certain model, but works according to the principle of the diffusion model itself, any pre-trained text-to-graph diffusion model can be adapted.","['G06T3/4053', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN116109733A,"Text-driven image editing method, device, electronic equipment and storage medium","The invention provides a text-driven image editing method, a text-driven image editing device, electronic equipment and a storage medium, wherein the method comprises the following steps: acquiring an original image, a positioning text and a target text, wherein the positioning text is used for positioning an object to be edited in the original image, and the target text is used for generating a new object; determining a spatial mask of the forward noisy latent image, the direction-enhancing latent image, and the positioning text in the original image based on the original image, the positioning text, and the target text; and performing image reconstruction based on the forward noise adding latent image, the direction enhancement latent image and the space mask to generate a target image, wherein the target image is an image generated after the object to be edited in the original image is replaced by a new object. The method and the device can realize the aim of editing the image based on the text description without artificial mark masking and pre-training an countermeasure network, improve the convenience, the high efficiency, the reliability and the high quality of editing the image based on the text description, and greatly improve the application range of editing the image based on the text description.","['G06T11/60', 'G06T5/50', 'G06T5/70', 'G06T7/73', 'G06T2207/10024', 'G06T2207/20081']"
CN116721179A,"A method, device and storage medium for image generation based on diffusion model","The application discloses a method, equipment and storage medium for generating an image based on a diffusion model. The method comprises the following steps: collecting a noise image from the initial noise distribution; reversely transmitting the noise image to a target diffusion step number according to the optimal transmission mapping so as to obtain optimal initial diffusion distribution for generating the target image by reverse diffusion; and performing a reverse diffusion operation using a pre-trained diffusion model based on the optimal initial diffusion profile to generate the target image. By using the scheme of the application, the diffusion step length is reduced, the efficiency is improved, the mode confusion is avoided, and the quality of the generated image is improved.","['G06T11/206', 'G06N3/0475', 'G06N3/084', 'Y02T10/40']"
CN116796212A,Time sequence anomaly detection method and device based on conditional diffusion model with increasing weight,"The invention discloses a time sequence abnormality detection method and device based on a conditional diffusion model with increasing weight. The observation value is flexibly selected by adopting a strategy based on the density ratio, so that the method can be easily applied to the condition of abnormal concentration. The invention enhances the estimation performance of the missing value through the conditional diffusion of the weight increment, and can obviously improve the quality of the generated data, thereby improving the stability of anomaly detection. In addition, the invention also designs a multi-scale state space model to capture the long-term dependency of time series data. Experimental results show that the performance of the method is obviously superior to that of the current most advanced model; the abnormality detection performance can be improved; in the case of marked data scarcity or outlier concentration, a flexible solution is provided.","['G06F18/2321', 'G06F18/10', 'G06N3/0464']"
CN117556009A,Multi-turn dialogue generation method and system based on conditional diffusion model,"The invention provides a multi-round dialogue generation method and system based on a conditional diffusion model, a storage medium and electronic equipment, and relates to the technical field of natural language processing. Firstly, acquiring a plurality of dialogue contexts based on a pre-trained conditional diffusion model; secondly, obtaining a context representation of the multi-round dialogue context, and randomly sampling a Gaussian noise from a standard Gaussian distribution; progressively denoising under the guidance of the context representation, based again on the conditional diffusion model, reducing the gaussian noise to a latent variable conforming to the multi-turn dialog context; and finally, generating a final reply according to the context representation and the potential variables. And a conditional diffusion model is introduced to fit potential variable distribution, and abundant potential information in training data is fully utilized, so that the generated recovery correlation and diversity are stronger.","['G06F16/3329', 'G06F40/35', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
CN118152996A,Image copyright protection method based on diffusion model,"The invention discloses an image copyright protection method based on a diffusion model, which comprises the following steps: acquiring a target image, and obtaining a noise image through a noise adding process of a diffusion model; performing discrete wavelet transformation on the noise image to obtain a corresponding frequency domain coefficient; embedding watermark information into the frequency domain coefficient by changing the sign of the frequency domain coefficient to obtain the frequency domain coefficient embedded with the watermark information; performing inverse discrete wavelet transformation on the frequency domain coefficient embedded with the watermark information to obtain a corresponding watermark noise image; reconstructing the watermark noise image into a watermark image with the same visual effect as the target image based on the diffusion model. According to the invention, watermark information is added into the noise image transformed by the target image by using the diffusion model, so that the image quality after embedding the watermark is improved, the concealment of the watermark information is improved, and the robustness of the watermark to various watermark elimination algorithms is improved.","['G06F21/1063', 'G06N3/0455', 'G06N3/094', 'G06T1/0021', 'G06T5/10', 'G06T2207/20064']"
CN118037672A,Generated image anomaly detection method based on diffusion model and uncertainty estimation,"A generated image anomaly detection method based on a diffusion model and uncertainty estimation. The method comprises the steps of obtaining a data set, setting parameters, completing diffusion model training, calculating KL divergence of an image to be detected, generating a noise-added image with input information, and obtaining a mean value of a reconstructed image; setting a threshold value, obtaining a weighted difference graph, judging whether the image to be detected has defects, generating a defect position image and the like. The invention adopts a diffusion generation mode, can train the image anomaly detection model for deep learning under the condition of only a large number of normal samples, and has better generation effect. When the diffusion model is trained, noise can be predicted, image variance can be predicted, and reconstructed image quality and detection accuracy can be improved. The original input information of the image is reserved, the KL divergence control and noise adding process is adopted, enough effective information can be saved to reconstruct a defect-free sample corresponding to the input image, the generated image has high resolution and good diversity, and training is easy, so that effective detection of unknown defects on the surface can be realized.","['G06T7/0004', 'G06N3/0475', 'G06N3/084', 'G06T7/0012', 'G06V10/774', 'G06V10/82']"
CN118172435A,A magnetic resonance image reconstruction method and system based on fast diffusion model,"The invention discloses a magnetic resonance image reconstruction method and a system based on a rapid diffusion model, and relates to the field of undersampling reconstruction of magnetic resonance images. The invention aims to solve the problem that the aliasing of the undersampled artifact of the data in the current magnetic resonance imaging reduces the imaging quality, and solves the problem that the diffusion model method is slow in reasoning in order to improve the accuracy of the reconstructed image and shorten the reconstruction time. The invention comprises the following steps: (1) acquiring magnetic resonance full-sampling real training data; (2) establishing a reconstruction model based on a diffusion model method; (3) establishing an image reconstruction rapid reasoning process; (4) Training a diffusion model by using the existing data to obtain a diffusion priori; (5) And reconstructing the undersampled magnetic resonance image by using the trained diffusion priori and reasoning flow. The invention can reconstruct high-quality magnetic resonance image by using less sampling data under the condition of high-power undersampling, and greatly shortens the reconstruction time.","['G06T11/006', 'G06N3/0475', 'G06N3/094', 'G06T5/60', 'G06T5/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
CN116524307A,Self-supervision pre-training method based on diffusion model,"The invention provides a self-supervision pre-training method based on a diffusion model, which comprises the following steps: step 1, training a diffusion model on a pre-trained data set based on a noise prediction mode, and taking the diffusion model as a teacher network; step 2, extracting the feature map of the up-sampling part in the U-Net network in the diffusion model trained in the step 1, and splicing; step 3, aligning the feature images output by the student network with the feature images extracted in the step 2, so as to train the student network; and 4, obtaining a global feature map of the image through the student network trained in the step 3. According to the method, semantic relevance of different areas in the image is explicitly modeled, regularization constraint on global features of the image is added, and therefore performance of the model obtained through pre-training by the method in downstream tasks such as image classification, target detection and semantic segmentation is greatly improved.","['G06V10/778', 'G06N3/0455', 'G06N3/0895', 'G06V10/26', 'G06V10/42', 'G06V10/774', 'G06V10/82', 'G06V20/70', 'Y02T10/40']"
CN117239730A,Priori knowledge-based wind power prediction method for diffusion model,"The invention discloses a prior knowledge-based wind power prediction method for a diffusion model, and belongs to the field of wind power prediction. Obtaining a historical prediction error by taking the difference between a real value and a predicted value of the actual historical power of the wind turbine generator, and obtaining corresponding Gaussian distribution parameters by fitting the normalized prediction error through Gaussian distribution; acquiring sampling noise under the corresponding diffusion step length, and gradually transmitting the information of wind power history prediction error distribution as priori knowledge to a diffusion model in the form of sampling noise; establishing a prediction model based on priori knowledge, and completing diffusion in the forward sample noise adding process under the guidance of historical distribution of wind power prediction errors, wherein the prediction model comprises a deep learning network and a diffusion model which are sequentially combined; and inputting wind power data to perform wind power prediction by a prediction model based on priori knowledge, so as to obtain a final prediction result. The prediction method is high in prediction precision, convenient to use and wide in practicability.",[]
CN117219104A,Video restoration method based on diffusion model,"The invention provides a video restoration method based on a diffusion model, which comprises the following steps: s1, generating video noise: generating video noise according to the current frame and the adjacent frame video, wherein the noise carries dependency information required for repairing the current frame; s2, adding noise to the diffusion model: sequentially adding video noise into a neural network layer of the diffusion model to replace original Gaussian noise of the diffusion model; s3, training a diffusion model: and constructing a training data set for the diffusion model based on the deep neural network, and carrying out training before reasoning and deployment on the diffusion model. The method solves the problem of huge model calculation amount caused by large data amount of the disposable multi-frame video in the existing method, and the algorithm realizes the function of repairing the video by utilizing the data generation capacity of the diffusion model.",[]
CN118296944A,Industrial Internet of things digital twin modeling method and system based on diffusion model,"The invention relates to an industrial Internet of things digital twin modeling method and system based on a diffusion model, and belongs to the technical field of computer vision. The method comprises the following specific implementation steps: (1) data preparation: (2) constructing a diffusion model and determining a noise injection strategy: creating a diffusion model comprising a generator network and corresponding loss functions; (3) performing data dimension reduction by adopting principal component analysis: and (4) performing diffusion model training: and (5) model hyper-parameter adjustment: (6) outputting the real digital twin data. When digital twin modeling is carried out on equipment in the industrial Internet of things, the method carries out dimension reduction on high-dimensional data by utilizing Principal Component Analysis (PCA), and then trains based on DDPM, so that low-dimensional representation of system data can be learned, high-dimensional complex data are compressed into more compact and more real dimension reduction data, the dimension and complexity of the data are reduced, and the calculation efficiency and representation capacity of the digital twin model are improved.","['G06F30/27', 'G06F18/2135', 'G06F18/214']"
CN113793685B,Cognitive decision evaluation method and system based on multi-dimensional hierarchical drift diffusion model,"The invention discloses a cognitive decision evaluation method and system based on a multi-dimensional layered drift diffusion model. The method comprises the following steps: for healthy subjects, establishing a multi-dimensional layered drift diffusion model on a group level, and obtaining sensitivity thresholds and probability distributions of the healthy subjects in each cognitive domain and sensitivity thresholds and probability distributions of overall meta-cognitive processing efficiency as healthy person norms; for each MCI patient, establishing a multi-dimensional hierarchical drift diffusion model on an individual level, and obtaining a sensitivity threshold and probability distribution of the MCI patient in each cognitive domain and a sensitivity threshold and probability distribution of overall element cognitive processing efficiency as indexes to be measured. By comparing the relative positions of the parameters of the MCI patient distributed in the normal model of the healthy person, the method can accurately evaluate the damaged ability of the MCI patient, and promote early discovery, early intervention and early treatment of the damaged decision-making ability.","['G16H50/20', 'G16H50/70']"
CN117095199A,Industrial visual anomaly detection system based on simplex diffusion model,"The invention discloses an industrial visual abnormality detection system based on a simplex diffusion model, which comprises a data preprocessing module, a coding module based on the simplex diffusion model and a decoding module fusing a cooperative attention mechanism, wherein the decoding module is used for decoding the data; the use of simplex noise instead of gaussian noise during diffusion makes it easier to repair industrial image surface microfeature anomalies during denoising. In the back diffusion process, based on the structure of the classical U-net, a spatial attention mechanism is added, so that the U-net can process details of different areas more flexibly and accurately in the denoising process, and the quality of the generated image is improved. The convolutional neural network which integrates the cooperative attention mechanism is a high-precision classification algorithm, and the channel attention and the spatial attention are combined, so that the expression capability of a decoding block on image features can be improved, key features are enhanced, noise and redundant information are suppressed, the interpretation of a model is improved, and the identification performance is improved.","['G06V10/764', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06V10/774', 'G06V10/80']"
CN118192797A,"Diffusion model gesture generation method, system and readable storage medium with attention mechanism","The invention relates to the field of computer technology and artificial intelligence, and discloses a diffusion model gesture generation method, a system and a readable storage medium with an attention mechanism, which comprise the following specific steps: constructing a conditional embedding model comprising an encoder and an attention-based fusion network; embedding the multimodal data input conditions into the model; acquiring comprehensive characteristics of the multi-mode data through an encoder; fusing the comprehensive characteristics and constructing a gesture generation framework through a fused network based on attention; constructing a denoising model based on a potential diffusion model, wherein the denoising model comprises a self-attention network; inputting the gesture generating frame into a denoising model; and extracting condition information from the denoising model, generating an initial potential gesture sequence, and then carrying out forward diffusion and backward diffusion on the initial potential gesture sequence according to the condition information to generate a final gesture sequence. The invention solves the problems of the prior art that the diversity and the fidelity of the characteristics are limited, and has the characteristics of high generation efficiency and high quality.","['G06F3/017', 'G06F16/636', 'G06F18/253', 'G06N3/0455']"
CN119293511A,A method for purifying adversarial samples based on conditional diffusion model,"The invention discloses an anti-sample purifying method based on a condition Diffusion model, which comprises the steps of obtaining a clean sample data set containing clean samples, attacking a classification model by using a white box attack algorithm, generating a pair of anti-samples for each clean sample, pairing the clean samples and the anti-samples one by one to form a training data set, obtaining a pre-trained Stable Diffusion model, designing a fine tuning process and a fine tuning loss function, and presetting iteration rounds and batch sizes, and fine tuning network parameters of a cross attention layer in the Stable Diffusion model by using the training data set to obtain a fine-tuned condition Diffusion model for purifying the anti-samples. According to the invention, the countermeasure sample is used as the condition information to be input Unet to the neural network to guide the model to learn, so that the model can learn the disturbance countermeasure characteristics, and the calculation efficiency, the robustness and the stability can be improved.","['G06F18/214', 'G06F18/241', 'G06N3/0455']"
CN117649368A,Weak light enhancement method based on self-adaptive sparse attention diffusion model,"The invention discloses a weak light enhancement method based on a self-adaptive sparse attention diffusion model, which comprises the steps of firstly, adding noise to a normal light image to obtain a pure noise picture; then, preprocessing the low-light image, including curve fine adjustment, initial denoising enhancement and edge detection, so as to obtain better input; and then, combining the pure noise image and the preprocessed image through an improved noise prediction module to obtain a noise characteristic diagram. Based on these preparations, a weak light image enhancement network based on a sparse attention diffusion model is constructed, a denoising formula of the diffusion model is applied in a reverse process to iteratively denoise a pure noise image, and an enhanced image is finally generated. By training a sparse attention spreading model network, different types of low-light images can be adaptively processed. In the whole, the method can remarkably improve the quality of the weak light image and enhance the details and definition of the image through effective data processing, noise modeling and self-adaptive network optimization.","['G06T5/50', 'G06N3/0464', 'G06T7/13', 'G06T7/62', 'G06T2207/20084', 'G06T2207/20221']"
CN116109824A,Method and device for generating medical images and pixel-level annotations based on diffusion model,"The application provides a medical image and pixel-level label generation method and device based on a diffusion model, which relate to the field of medical image processing and comprise the following steps: acquiring a medical image sample, labeling the medical image sample, and determining a pixel-level segmentation labeling sample corresponding to the medical image sample; normalizing the medical image sample, and splicing the medical image sample with the pixel level-separated labeling sample to obtain spliced data; preprocessing the spliced data to generate training data; training the training data to obtain a diffusion model, wherein the diffusion model takes U-Net as a network structure; and inputting random sampling Gaussian noise into a diffusion model, and generating medical images and corresponding pixel level classification labels through multiple iterations. The method automatically generates the large-scale medical image and the pixel-level label in a deep learning mode, is beneficial to improving the accuracy and the stability of an automatic segmentation method by adding training data under the condition that real data are limited, and avoids privacy problems caused by real data leakage.","['G06V10/26', 'G06F21/6245', 'G06T7/143', 'G06V10/774', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
CN119889026A,Traffic flow prediction method and system based on diffusion model,"The invention discloses a traffic flow prediction method and a traffic flow prediction system based on a diffusion model, wherein the traffic flow prediction method comprises the steps of obtaining historical traffic data, carrying out data preprocessing to form a sample data set, taking road sections of a road network as nodes, constructing edges according to geographic adjacency between the road sections and historical traffic association relations to form a space-time dependent structure diagram, carrying out periodic feature extraction and target feature extraction, measuring similarity of periodic features and target features in time dimension by using a dynamic time regularization method, carrying out selective migration and weighted fusion on the periodic features based on the similarity to obtain fusion features, inputting the fusion features into a traffic flow prediction model constructed based on the diffusion model for training, outputting a representation vector of predicted future traffic flow, inputting traffic data at the current moment into the trained prediction model for traffic flow prediction, and outputting a traffic flow prediction result of the future time period.","['G08G1/0129', 'G06Q10/04', 'G08G1/0108', 'G08G1/0137', 'G08G1/048']"
CN116503513A,Sketch guided image editing method based on conditional diffusion model,"The invention discloses a sketch guided image editing method based on a conditional diffusion model, which comprises the following steps: acquiring an image to be repaired and a sketch, and randomly generating a mask image; performing dimension reduction coding on the image to be repaired and the sketch by using two encoders to obtain two low-dimension vectors, and sampling a mask image to obtain a mask vector; using the two low-dimensional vectors and the mask vector as guide conditions, and generating a repair vector by using a conditional diffusion model based on inverse diffusion of the guide conditions; and decoding and reconstructing the repair vector by using a decoder to obtain an image editing result. According to the method, a sketch is introduced as a guide in the whole process, so that effective editing of a target area in the image is realized, and the global consistency of the image is ensured.","['G06T11/60', 'G06N3/08', 'G06T3/4046', 'G06T9/002', 'Y02T10/40']"
CN117541883B,"Image generation model training, image generation method, system and electronic equipment","The application provides an image generation model training method, an image generation system and electronic equipment, wherein the training data set is acquired; inputting training data into an image generation model to be trained, and obtaining a model generation image output by the model; generating an image and an actual acquisition image based on an optimal transmission theory and a model, and determining a loss function value; and optimizing the internal parameters of the model according to the loss function value to obtain a trained image generation model. The loss function value is determined based on the optimal transmission theory, the model generation image and the actual acquisition image, so that the human eye perception can be more closely achieved; and optimizing the internal parameters of the image generation model to be trained based on the loss function value, and generating a more real image which is perceived by human eyes by the obtained trained image generation model. The method provided by the application can be oriented to application fields such as metauniverse, digital twin, intelligent planning and design and the like.","['G06V10/764', 'G06V10/40', 'G06V10/774']"
CN118608660B,A method of dynamic image editing based on diffusion model,"The invention provides an image dynamic editing method based on a diffusion model, which divides single-stage denoising of a traditional diffusion model into two stages, wherein the two stages comprise editing effect initialization performed in early denoising and sequence frame smoothing performed in later time steps. The image dynamic editing method constructed by the invention is different from the original diffusion model in that only a single editing result is generated, but the sequence frames with different editing intensities are generated at one time, so that the problem that the single generation is difficult to meet the requirement of a user is solved. Meanwhile, the invention introduces self-attention and interpolation of prediction noise, so that the generated sequence frames can be played continuously in a video form, and can keep good space-time consistency with the original image.","['G06T11/60', 'G06N3/045', 'G06N3/08', 'G06T17/00', 'G06T5/70', 'Y02T10/40']"
CN117729370A,A method and system for text generation video based on latent diffusion model,"The invention discloses a text generation video method and a system based on a potential diffusion model, comprising the following steps: expanding a 2D text-generated graph model to a time-space domain through an expansion potential diffusion model network, and decomposing a source video frame by frame to obtain a video frame sequence; extracting features of the video frame sequence by utilizing a preprocessor to obtain a conditional frame sequence, and introducing a multi-frame rendering machine to manufacture a diffusion process used for each current generated frame; selecting a specific time step to apply smooth optimization operation to the current generated frame sequence, and completing the processing of all video frames through continuous time steps; outputting a generated video frame sequence according to the result, and synthesizing a generated video; the invention adopts a fine tuning method to expand the model to a space domain through network expansion to realize the video generation task, and has low cost and easy realization; in order to reduce the flicker of the whole structure of the generated video, the invention filters and smoothes the generated frame sequence by utilizing the video frame inserting technology so as to improve the consistency of details of adjacent frames.",[]
CN118857268A,Autonomous navigation mapping system and method based on semantic information guided diffusion model,"The invention discloses an autonomous navigation mapping system and method based on a semantic information guided diffusion model, wherein the method comprises the following steps: the prediction module based on semantic priori takes a measurement map as input, and obtains a new measurement map through prediction of the space layout, wherein the measurement map is used as a part of robot observation; the global strategy module based on the diffusion model generates a long-term target point according to real-time observation of the robot, guides the robot to explore an unknown environment, trains a global strategy network by using observation data collected by the robot to the target point and updates network parameters of the global strategy network until the strategy converges; under the guidance of robot observation, the converged strategy firstly generates an initial target point coordinate based on a Gaussian process, and then generates a current exploration target point by continuously removing noise. The method can improve the exploration efficiency of the robot, simultaneously enables the robot to have the capability of adapting to real-time autonomous mapping in different environments, and provides an active exploration strategy with high efficiency and generalization capability.","['G01C21/3804', 'G01C21/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/44', 'G06V10/761', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V20/10', 'Y02T10/40']"
US20250160641A1,Method for automatically generating fluorescein angiography images based on noninvasive fundus images,"A method for automatically generating fluorescein angiography images based on noninvasive fundus images, using noninvasive fundus images and matched multi-timepoint fluorescein angiography images as training data to train and generate a conditional generative adversarial network, and to construct the fluorescein angiography images based on the noninvasive fundus images. After the fluorescein angiography images are constructed, it can take noninvasive fundus images as input to generate corresponding early, middle, and late phase fluorescein angiography images. The generated fluorescein angiography images can clearly display the retinal structure and the fluorescence characteristics of various lesions. The method can reduce the reliance on fluorescein angiography, an invasive diagnostic technology with significant risk of side effects, and enhance the ability to diagnose eye diseases.","['A61B3/1241', 'A61B3/0025', 'A61B3/12', 'A61B3/14', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30101']"
CN118196227A,Texture synthesis method based on diffusion model and re-weighting strategy,"The invention discloses a texture synthesis method based on a diffusion model and a re-weighting strategy, which relates to the field of texture image generation in computer vision. In the pre-training phase, the texture image is encoded with a self-encoder, ensuring an efficient conversion from pixel space to potential space. In the forward noise stage, the model performs diffusion simulation of texture through the potential diffusion model. In the backward sampling stage, the potential representation of the image is restored by a denoising process, and then decoded back into pixel space, generating the final texture image. The invention improves the generation quality and efficiency in the field of texture synthesis, and simultaneously shows the practical application potential of the deep learning and causal reasoning technology in image generation.","['G06T11/001', 'G06T5/50', 'G06T5/70', 'G06T7/42', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20221']"
CN117689761B,Plug-and-play magnetic particle imaging reconstruction method and system based on diffusion model,"The invention belongs to the field of biomedical molecular image and magnetic particle imaging reconstruction, in particular relates to a plug-and-play magnetic particle imaging reconstruction method and system based on a diffusion model, and aims to solve the problems that an inverse problem is unfixed and difficult to solve in a system matrix reconstruction process in the conventional MPI image reconstruction method. The method comprises the following steps: acquiring a voltage signal of a target object to be reconstructed by MPI imaging as an input signal; and obtaining an optimal solution of magnetic particle concentration distribution by a pre-constructed system matrix unconstrained optimization method, and further reconstructing a magnetic particle image to obtain a reconstructed MPI image. The invention solves the problems of unfit and difficult solving of the inverse problem and improves the quality of MPI image reconstruction.","['G06T11/003', 'A61B5/0515', 'A61B5/7267', 'G06N3/0455', 'G06N3/08', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
WO2024199270A1,Method for generating and screening amino acid sequence and system therefor,"A method for generating and screening a virus amino acid sequence, comprising: S1, a pre-training step: on the basis of an unlabeled amino acid sequence database, constructing a data set for a pre-training model, and carrying out preliminary training on the pre-training model to learn grammar semantic information of an amino acid sequence; S2, a conditional generation step: on the basis of a pre-trained model, preliminarily generating the amino acid sequence by using a virus amino acid sequence data set; S3, a rational design step: on the basis of an amino acid sequence obtained after ""conditional generation"", carrying out optimization design on the amino acid sequence by means of a rational design module, and on the basis of existing positive sample data having a required function, carrying out further optimization and transformation, by using a heuristic algorithm, on an amino acid sequence outputted by a generation model, so that a sequence space is evolved towards a positive sample direction, and the sequence is optimized; and S4, a filtering step: carrying out function prediction on the virus amino acid sequence in a target virus amino acid sequence library, carrying out function prediction according to a required amino acid sequence function, and filtering out an amino acid sequence with poor function. Further provided are a system for implementing the method and a key amino acid sequence in an AAV viral capsid sequence screened out on the basis of the system.","['G16B25/00', 'G16B25/10', 'G16B40/00']"
CN116309992A,"Intelligent meta-universe live person generation method, equipment and storage medium","The invention discloses a method, equipment and storage medium for generating intelligent meta-universe living broadcast characters, wherein the method comprises the following steps: respectively training a voice recognition module, a figure generation module, an action simulation module, a makeup simulation module and a clothing simulation module to obtain multi-mode data; according to the multi-modal data, converting the multi-modal data of the character into a unified format; inputting the converted multi-modal data into a first multi-modal model; training all data in the first multi-mode model simultaneously to obtain a steady-state diffusion model; migrating the steady-state diffusion model into a second multi-modal model; the method comprises the steps of training each module respectively, and then recombining the modules into a large model, so that the model can be used for generating large unified universe live broadcast digital persons with different styles and different scenes, realizing the combined training of each field and global optimum, enabling the system to fully utilize the advantages of each module, enabling the model to exert the maximum characterization capability, and realizing the stronger expressive capability of the person.","['G06T13/40', 'G06N3/08', 'H04N21/2187']"
US20240070816A1,Diffusion model image generation,"Systems and methods for image processing are described. Embodiments of the present disclosure receive a reference image depicting a reference object with a target spatial attribute; generate object saliency noise based on the reference image by updating random noise to resemble the reference image; and generate an output image based on the object saliency noise, wherein the output image depicts an output object with the target spatial attribute.","['G06T5/50', 'G06T5/002', 'G06T5/70', 'G06V10/761', 'G06V10/764', 'G06V10/774', 'G06V20/70', 'G06T2207/20081', 'G06T2207/20084']"
CN118842782A,IPv6 active address detection method based on diffusion model,"The invention belongs to the technical field of network space mapping, and discloses an IPv6 active address detection method based on a diffusion model. Acquiring an IPv6 seed address data set, and classifying addresses according to mode types; performing address expansion after the address classification is completed to form a group of character strings consisting of 32-bit half-byte forms without colon numbers; mapping the character string address to the continuous word vector by adopting a word embedding mode; each character is assigned a word vector with a fixed length for representation; the diffusion process obtains a data sample noisy to a time t; recovering the inverse diffusion process to obtain uncorrupted data; identifying the alias address of the candidate target address set through the known alias prefix, and eliminating the alias address; and outputting the generated IPv6 candidate target address set. The generated target address set through the method has more active addresses, and the hit rate is improved.","['H04L61/5007', 'H04L61/5046', 'H04L2101/659']"
CN118411682B,A method for marine ship target recognition in visible light images based on conditional diffusion model,"The invention provides a visible light image marine ship target identification method based on a conditional diffusion model, which comprises the following steps: step S1: extracting noise labels and image features of an image to be identified; step S2: splicing the noisy label and the priori information, and inputting the noisy label and the priori information into a trained conditional diffusion model together with image features for denoising; step S3: and (3) repeating the step S2 for T-round iteration to obtain a noise-free label of the image to be identified so as to identify the ship target. When complex background and multi-target scenes are processed, the method has great application potential and development prospect in the field of marine ship target recognition, and can effectively improve detection accuracy, robustness and efficiency.","['G06V20/54', 'G06N3/084', 'G06V10/764', 'G06V10/82']"
WO2025107948A1,"Determination method and apparatus for artificial palm print generation model, and determination method and apparatus for palm print recognition model","The present application provides a determination method and apparatus for an artificial palm print generation model, and a determination method and apparatus for a palm print recognition model. The determination method for an artificial palm print generation model comprises: acquiring a first training set, wherein the first training set comprises real palm print images and identity control curves of a plurality of users; performing data augmentation on a first real palm print image of a first user in the first training set to obtain a first real palm print image subjected to the data augmentation; obtaining a first artificial palm print image corresponding to the first user and generated by a deep learning model by using the first real palm print image subjected to the data augmentation and a first identity control curve of the first user; when the first artificial palm print image subjected to the data augmentation is the same as the first real palm print image subjected to the data augmentation or the similarity between the first artificial palm print image subjected to the data augmentation and the first real palm print image subjected to the data augmentation is not greater than a preset similarity threshold, adjusting parameters of the deep learning model; and when the first artificial palm print image subjected to the data augmentation is different from the first real palm print image subjected to the data augmentation or the similarity between the first artificial palm print image subjected to the data augmentation and the first real palm print image subjected to the data augmentation is less than the similarity threshold, determining the deep learning model as an artificial palm print generation model.","['G06V10/774', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06V10/20', 'G06V10/82', 'G06V40/12']"
CN117611697A,"Image processing method, apparatus, device, storage medium, and program product","The application discloses an image processing method, an image processing device, image processing equipment, a storage medium and a program product, which relate to the technical field of artificial intelligence and can be used for generating limb images, wherein a reference limb texture image is acquired and is used for indicating textures of a limb image to be generated; acquiring reference limb posture information for indicating a posture in which a limb image is desired to be generated; determining a target image size of a limb image to be generated, and acquiring a Gaussian noise image with the image size being the target image size; according to the reference limb texture image and the reference limb posture information, the predicted Gaussian noise of the corresponding Gaussian noise image is obtained through a noise prediction model, and according to the predicted Gaussian noise, the Gaussian noise image is subjected to noise reduction processing, and the corresponding limb image is generated. Compared with the related art, the method and the device can improve flexibility in generating the limb image.","['G06T11/001', 'Y02T90/00']"
CN119991967A,A 3D human body reconstruction method based on implicit neural network and diffusion model,"A three-dimensional human body reconstruction method based on an implicit neural network and a diffusion model belongs to the field of three-dimensional reconstruction. The invention constructs a diffusible density volume representation, and realizes the rendering based on identity by using a diffusion model. By adopting parameterized three-dimensional distribution representation, pareto optimization, balanced realism rendering and feasible prediction are realized in an unbalanced optimization framework. To speed up rendering training without sacrificing quality, hybrid multi-resolution hash grid features are employed to enhance directional feature representation capabilities. Meanwhile, a multi-scale structure similarity constraint (MSSC) is proposed to maintain identity distinguishability and ensure geometric consistency, thereby realizing synthesis with high calculation efficiency and satisfactory visual effect. The method can reconstruct the three-dimensional human body model from a single image based on limited geometric and appearance information, has excellent performance in the aspects of topological credibility and visual fidelity, and provides a more flexible and efficient solution for practical application scenes.",[]
US20250005825A1,Real scene image editing method based on hierarchically classified text guidance,"Provided is a real scene image editing method based on hierarchically classified text guidance, including: firstly selecting a hierarchical multi-label text classification model and hierarchically classify an input style description text; obtaining a latent vector of an indoor scene image and dividing the latent vector; training latent space residual mappers which are divided into four groups for generating details of a layout, an object, an attribute, and a color in the scene image, and selectively training a mapping model with a secondary word obtained by a text classification model; inputting a tertiary word obtained by the text classification model to a contrastive language-image pre-training (CLIP) network and controlling training of the mapping network by utilizing a CLIP loss; hierarchically inputting the latent vector to the mapping network to obtain a bias vector, summing the bias vector with an original vector for inputting to the StyleGAN to obtain an edited image.","['G06V20/70', 'G06F18/24', 'G06F40/30', 'G06F40/40', 'G06N3/0475', 'G06N3/094', 'G06T11/001', 'G06T11/60', 'G06V10/774', 'G06V10/82', 'Y02D10/00']"
US20240362427A1,Generating digital content,"In implementations of systems for generating digital content, a computing device implements a generation system to receive a user input specifying a characteristic for digital content. The generation system generates input text based on the characteristic for processing by a first machine learning model. Output text generated by the first machine learning model based on processing the input text is received. The output text describes a digital content component. The generation system generates the digital content component by processing the output text using a second machine learning model. The generation system generates the digital content including the digital content component for display in a user interface based on the characteristic.","['G06F40/106', 'G06F40/103', 'G06F40/169', 'G06F40/30', 'G06F40/56']"
CN117475462A,Automatic identification and matching system and method for graphic elements and features of distribution network lines,"The invention discloses a matching system for automatically identifying graphic elements and characteristics of a distribution network line, wherein a graphic element and a text detection module thereof identify the category, text and graphic element information and prediction frame information of the graphic element from the distribution network line graph by using a YOLOv7 algorithm combined with an SE-Net channel attention mechanism and an overlapping sliding window mechanism; the content recognition module is used for constructing an image data set by utilizing the prediction frame information aiming at the text region, and carrying out distribution network circuit diagram text content recognition through a convolutional cyclic neural network algorithm and transfer learning according to the image data set; and the graphic primitive and text matching module performs collaborative generation and association matching of the equipment graphic primitive and the text through a MiniGPT-5 algorithm based on a generation formula Vokens according to the text content and the predicted frame information of the identified distribution network circuit diagram. The invention improves the recognition and matching efficiency of the imaging elements and the characteristics of the distribution network line.","['G06V30/418', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/096', 'G06N3/0985', 'G06V10/82', 'G06V30/147', 'G06V30/148', 'G06V30/18057', 'G06V30/19173', 'G06V30/1918', 'G06V30/422', 'Y04S10/50']"
CN117830510A,A method for generating 3D digital core with multiple constraints based on diffusion model,"The invention discloses a diffusion model-based multi-condition constraint three-dimensional digital core generation method, and particularly relates to the technical field of digital cores. According to the method, after a plurality of three-dimensional digital core samples are obtained and labels are marked to serve as training samples, a multi-condition three-dimensional digital core generation model is built based on a 3dUnet network, the multi-condition three-dimensional digital core generation model is trained by the training samples in the digital core training set, random noise and multi-constraint conditions are fused to generate a three-dimensional digital core, the trained multi-condition three-dimensional digital core generation model is utilized, and the multi-condition constraint three-dimensional digital core is generated according to the random noise, the self-defined porosity, the average pore diameter value and the pore diameter standard difference value. According to the invention, the generated three-dimensional digital rock core is subjected to various condition constraints, so that the internal pore structure of the rock is truly restored, the quality of the three-dimensional digital rock core generated by the model is improved, and technical support is provided for reservoir research.","['G06T17/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
CN118898549A,A small sample font generation method based on diffusion model,"The invention discloses a small sample font generation method based on a diffusion model, which comprises the following steps: constructing a font image dataset, continuously adding noise to a target font image to pure noise, selecting a content and style reference image, respectively using a content and style encoder to encode, and extracting structural and semantic information. The diffusion model is trained to predict the noise of the noise image, the hidden coding noise is gradually removed, and the final target is an original image without noise. In the denoising process, the content and the style reference image are used as denoising conditions, the style characteristics are enhanced through a style refining module, the style-content fusion module promotes the interaction of the content and style information, calculates the total loss function update model parameters, and generates a font image based on new fonts and Chinese characters; compared with the prior art, the method has the advantages that the training process is more stable, the problem of incomplete or incorrect Chinese character generation is solved, the model can learn style information such as thickness and stroke style, the method is simple and convenient, the effect is good, and the method has good application prospect.","['G06T5/70', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06T3/04', 'G06T5/50', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20172', 'G06T2207/20221']"
WO2024223621A1,Transitive and commutative multimodal models and uses,"Computer-implemented methods for analysing multimodal data are described. A computer-implemented method comprises generating an output data set by processing an input data set comprising data from one or more of a set of at least three modalities, using a machine learning model comprising a transitive and commutative machine-learning model. Related methods, products and systems are described.","['G06N3/0455', 'G06N3/044', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/766', 'G06V10/774', 'G06V10/778', 'G06V10/803', 'G06V10/82', 'G06V10/87', 'G06V2201/03']"
WO2024172807A1,Generative sampling for unbalanced of classes in images and videos dataset,"In example implementations described herein, there are systems and methods for training a machine-trained model for industrial failure detection based on an initial set of training data comprising a plurality of input-output data sets each comprising input data and output data regarding at least one classification of the input data. The method may include identifying at least one classification of the input data, in a plurality of classifications that is under-represented. The method may also include automatically generating, for inclusion in a modified set of training data, additional input-output data sets for the identified at least, one classification to balance a representation of the classifications in the modified set of training data. Finally, the method may include training the machine-trained model based on the modified set of training data comprising at least a subset of the initial set of training data and the additional input-output data sets.","['G05B23/024', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06F11/07']"
US20240412319A1,Generating polynomial implicit neural representations for large diverse datasets,A Polynomial Implicit Neural Representation generator framework (Poly-INR framework) may be trained to generate polynomial implicit neural representations for large diverse training datasets and learn a polynomial order representing the training datasets. The Poly-INR framework may include a mapping network and a synthesis network. The mapping network may map latent code extracted from the plurality of input images of the training dataset into an affine parameters space and generate affine transformation parameters from the affine parameters space. The synthesis network may obtain the affine transformation parameters and pixel coordinate locations from the mapping network and parameterize the affine transformation parameters using the latent code extracted from the plurality of input images of the training dataset as a known distribution. The Poly-INR framework may train an AI model to learn the polynomial order representing the training dataset from the affine transformation parameters parameterized and output the AI model.,"['G06T3/02', 'G06T3/4046']"
CN102648600B,Low-complexity electronic circuitry protected by custom masking,"The subject of the invention is a cryptographic circuit protected by masking, said circuit comprising means for using at least one key kr cA module for encrypting a binary word, a module for applying linear processing operations (216) and non-linear processing operations (226) to the word, and a module for masking the word. By usingMask kr iUnmasking (214) the binary word upstream of the non-linear processing operation and by using a mask kr+1 iMasking (215) the binary word downstream of the processing operation, the mask kr iAnd kr+1 iA set of masks selected specific to each instance of the circuit.","['H04L9/002', 'H04L9/003', 'H04L9/0618', 'H04L2209/046', 'H04L2209/12']"
CN117496299A,"A method, device, terminal equipment and medium for augmenting defect image data","The application is applicable to the technical field of image processing, and provides a method, a device, terminal equipment and a medium for amplifying defect image data, wherein original defect image training data are obtained; training a pre-constructed denoising diffusion probability model by using original defect image training data to obtain a trained denoising diffusion probability model, and inputting the original defect image training data into the trained denoising diffusion probability model to generate surface defect image data; evaluating high-quality image data from the surface defect image data, and constructing new surface defect image data according to the high-quality image data and the original defect image training data; progressively training a denoising diffusion probability model by utilizing new defect image numbers meeting preset quality requirements, and amplifying acquired target defect image data by utilizing the trained denoising diffusion probability model; the method and the device can improve the generation quality of the defect image.","['G06V10/774', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06T7/0004', 'G06V10/82', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'G06T2207/30168', 'Y02P90/30']"
US20250218531A1,Unlocking de novo antibody design with generative artificial intelligence,"A computing system for generating structural information of a biomolecule includes a processor; and one or more non-transitory computer-readable media having stored thereon instructions that, when executed by the one or more processors, cause the computing system to: receive training inputs; process the training inputs with a machine-learned biomolecule prediction model; evaluate a loss function; and modify parameters of the machine-learned model. A computing system for generating structural information of a target biomolecule includes a processor and one or more non-transitory computer-readable media having stored thereon a machine-learned biomolecule prediction model and instructions that, when executed by the one or more processors, cause the computing system to receive a target input; and predict the structural information of the target biomolecule. A computing system for predicting an affinity of a target biomolecule includes a processor and a computer-readable media having stored thereon: a machine-learned affinity prediction artificial neural network, including: (i) one or more biomolecule prediction layers trained to predict biomolecule structural information from target inputs; (ii) one or more docking layers trained to generate docked complexes from two or more input three-dimensional biomolecules; and (iii) one or more affinity prediction layers trained to predict affinity from input docked complexes; wherein the one or more biomolecule prediction layers, the one or more docking layers, and the one or more affinity prediction layers are connected; and instructions that, when executed by the one or more processors, cause the computing system to: receive a target input; and process the target input using the affinity prediction artificial neural network to generate a docked complex corresponding to the target input and a corresponding structural affinity value.","['G16B15/30', 'G06N3/044', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G16B15/00', 'G16B15/20', 'G16B40/20']"
KR102618644B1,Method and apparatus for generating composite image using 3d model,The present disclosure provides a composite image output method. The composite image output method includes the steps of: displaying an interactive object viewer for a three-dimensional model of a target object on a display; receiving information on a viewing position associated with the target object from a user using the interactive object viewer; receiving information on a background of the composite image from the user; and outputting the composite image generated based on the information on the viewing position associated with the target object and the information on the background on the display.,"['G06T19/20', 'G06F3/0484', 'G06Q30/0643', 'G06T11/60', 'G06T15/08', 'G06T17/20']"
CN117011420A,Virtual fitting method based on hidden diffusion model,"The invention discloses a virtual fitting method based on a hidden diffusion model, which comprises the following steps: acquiring a two-dimensional character image and a target clothing image of a user; acquiring key point information of human body posture; mapping the information of the two-dimensional character image of the user and the target clothing image to the hidden space respectively to obtain hidden space information of the two-dimensional character image of the user and hidden space information of the target clothing image; and generating a virtual try-on image by combining the human body posture key point information, the hidden space information of the two-dimensional character image of the user and the hidden space information of the target clothing image. The invention can automatically generate a real virtual try-on effect according to the two-dimensional character image and the two-dimensional target clothing image of the user.","['G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06Q30/0643', 'G06T2207/20084', 'G06T2207/30196']"
WO2024230843A1,"Three-dimensional model construction method and system, and related device","The present invention relates to the technical fields of computer graphics and computer-aided graphic designs. Provided are a sketch-based three-dimensional model construction method and system, and a related device. The three-dimensional model construction method comprises: step one, receiving a user input on an interactive interface; step two, converting the user input into one or more sketches, and then presenting same on the interactive interface; step three, a user selecting an appropriate sketch from the interactive interface; and step four, generating a three-dimensional model by using the sketch. By means of converting a user input into a sketch which is relatively easily edited, and then converting the sketch into a three-dimensional model, the sketch is used as an intermediary between the three-dimensional model and other data modalities, such that the performance consumption by the rendering of an interactive interface can be reduced.",['G06T17/00']
US20240296596A1,Personalized text-to-image diffusion model,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a text-to-image model so that the text-to-image model generates images that each depict a variable instance of an object class when the object class without the unique identifier is provided as a text input, and that generates images that each depict a same subject instance of the object class when the unique identifier is provided as the text input.","['G06V10/82', 'G06T11/00', 'G06V10/764', 'G06V10/774', 'G06V2201/07']"
US20250117972A1,Modality specific learnable attention for multi-conditioned diffusion models,"A method, apparatus, non-transitory computer readable medium, and system for image generation include encoding a text prompt to obtain a text embedding. An image prompt is encoded to obtain an image embedding. Cross-attention is performed on the text embedding and then on the image embedding to obtain a text attention output and an image attention output, respectively. A synthesized image is generated based on the text attention output and the image attention output.","['G06V10/771', 'G06T11/00', 'G06T11/60']"
CN117671055A,"Data processing method, text graph generation method and related devices","A data processing method, comprising: taking the input text of the user as the input of the large language model, and outputting a plurality of prompt texts; and taking the plurality of prompt texts as input of a text graph generation model, and outputting a plurality of corresponding images. Processing the text input by the user and the plurality of images to obtain a reward point of each image, wherein the reward points are related to the integral information points and the local information points. At least one alert text including a bonus point that is a target point is determined to be a target alert text. The user input text and the target prompt text are used as first training samples, and a plurality of first training sample pairs form a first training set. The large language model is trained using the first training set. That is, the large language model is trained, so that the large language model can expand the text input by the user to obtain the prompt text. Further, since the hint text includes rich details and scene information, the document map generation model may generate images that contain rich information.","['G06T11/00', 'G06F18/22', 'G06N20/00']"
WO2024163624A1,Video editing using diffusion models,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating an output video. One of the methods include: obtaining an input video; obtaining input text that includes a description of an output video; generating, based at least on applying downsampling to the input video, a degraded version of the input video; and generating the output video based on the description in the input text by updating the degraded version of the input video by using a video diffusion model across a plurality of reverse diffusion steps.","['G11B27/031', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06T11/00', 'G06T13/00']"
US20240177310A1,Method and device for preparing data for identifying analytes,"A method for preparing data for identifying analytes by coloring one or more analytes with markers in multiple coloring rounds, the markers in each case being specific for a certain set of analytes, detecting multiple markers using a camera, which for each coloring round generates at least one image containing multiple pixels and color values assigned thereto, which may contain color information of one or more markers, and storing the color information of the particular coloring rounds for evaluating the color information, a data point in each case including one or more contiguous pixels in the images of the multiple coloring rounds that are assigned to the same location in a sample.","['G06T7/0012', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081']"
US20240184982A1,Hierarchical text generation using language model neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating long textual works using language model neural networks. For example, the textual works can be generated hierarchically by performing a hierarchy of generation steps using the same language model neural network.","['G06F40/20', 'G06F40/56']"
CN117273074A,Data processing method and device,"A data processing method is applied to the field of artificial intelligence, and comprises the following steps: acquiring data to be processed; according to the neural network model, processing data to be processed to obtain a processing result; the neural network model comprises a linear transformation layer and weighting factors corresponding to the linear transformation layer, and is used for fusing the output of the linear transformation layer and the corresponding weighting factors when processing data to be processed; and determining loss according to the processing result, and updating the weighting factors in the neural network model according to the loss to obtain the trimmed neural network model. By the method, when the neural network model is finely tuned, the updatable weighting factors are added after the linear transformation layer, so that the number of other updated model parameters can be reduced under the condition that the accuracy of the finely tuned model is ensured, and further the cost of fine tuning the model is reduced.","['G06N3/0464', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06V10/82', 'G06V10/95', 'G06V20/40', 'G10L25/30', 'H04L67/51']"
US20250139160A1,Methods and systems for automatically generating queries and displaying visual representations of query results using graphics processing units,"An aspect relates to determining if a request received from a user device is sufficiently similar to a cached request, wherein the request requesting an identification of streamable content meeting one or more criteria. The determination comprises comparing a vector corresponding to the received request with vectors of previously received, cached requests. If the vector corresponding to the received request is sufficiently similar to a first vector of a first previously received, cached request, then a previously generated response corresponding to the first previously received, cached request may be accessed and transmitted to the user device. If a sufficiently similar vector is not identified, then at least a portion of the received request may be transmitted, in association with an identification of content items in a library, to an artificial intelligence learning engine. The response from the artificial intelligence learning engine may be transmitted to the user device.","['G06F40/40', 'G06F16/732', 'G06F16/7867', 'H04N21/251', 'H04N21/25891']"
CN118351028A,An artificial intelligence image restoration method with enhanced sampling,"The invention relates to the technical field of image processing, in particular to an artificial intelligent image restoration method for enhanced sampling, which is improved based on an LDM architecture, a mixed head self-attention mechanism is designed by improving an noise predictor module, and an artificial intelligent image restoration model is trained and evaluated by self-establishing a data set; the data is then compressed by the variational self-encoder into a low-dimensional random variable, which is mapped back into the original data space by the decoder after a diffusion process iterated over a prescribed time step. The invention can effectively solve the problem of image restoration under the irregular mask.","['G06T5/77', 'G06N3/0455', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T7/90', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'Y02T10/40']"
US20240419835A1,Incorporating large language model prompts in graph query language,"Systems and methods are directed to incorporating large language model (LLM) prompts into graph queries using graph query language and executing these graph queries. The system receives a graph query that includes a LLM prompt in the graph query language. The LLM prompt comprises an input context and a query to be answered. Based on the graph query, the system traverses a knowledge graph to obtain context data associated with the input context. The context data may be constrained by access control policies of an enterprise providing the knowledge graph. A context table may be generated using the context data based on the input context indicated in the LLM prompt. The system then invokes an LLM to determine a result by applying the query of the LLM prompt to the context data obtained from the traversal of the knowledge graph. The result is then presented on a user interface of a client device.","['G06F16/9024', 'G06F21/6227', 'G06F16/243', 'G06F16/24522', 'G06F16/24575', 'G06F16/3329', 'G06N3/04', 'G06N5/022', 'G06F2221/2113', 'G06F2221/2141']"
US20250225165A1,Machine learned models for search and recommendations,"A system may generate a prompt based in part on a search query from a customer client device. The prompt instructs a machine learned model to provide item predictions. And the model was trained by: converting structured data describing items of an online catalog to annotated text data (unstructured data), generating training examples based in part on the annotated text data, and training the model using the training examples. The system may receive item predictions generated by the prompt being applied to the machine learned model, the item predictions may have corresponding item identifiers. The item predictions are processed to identify a recommended item from the item predictions. The processing includes determining item information for the recommended item using an item identifier associated with the recommended item. The item information is provided to the customer client device.","['G06F16/3344', 'G06F16/338', 'G06N20/00']"
CN117936105A,Multimode melanoma immunotherapy prediction method based on deep learning network,"The invention discloses a multimode melanoma immunotherapy prediction method based on a deep learning network, which relates to the field of multimode melanoma immunotherapy prediction, and comprises the steps of firstly carrying out data acquisition, preliminary screening and image standardization processing, then carrying out image semantic segmentation through an image segmentation module, wherein the image segmentation module comprises a convolutional neural network and a deep self-attention network, then carrying out computer generation on image information which is missing in a pathological section graph through a diffusion model and natural language coding prompt, and carrying out screening and dimension reduction on the image again, then extracting image characteristics and non-image information, and evaluating the PD-1 prognosis of a patient through a graph neural network; the invention discloses a multi-mode melanoma immunotherapy prediction method based on a deep learning network, and aims to solve the problem of how to obtain a prognosis evaluation model with high accuracy in prognosis evaluation of melanoma PD-1 immunotherapy based on a limited number of training samples.","['G16H50/30', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06T7/11', 'G16H30/00', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088']"
CN117830580A,"Image generation method, device, electronic device and storage medium","The disclosure provides an image generation method, an image generation device, electronic equipment and a storage medium. The disclosure relates to the technical field of automatic driving, in particular to the technical fields of simulation test, image processing and the like. The specific scheme is as follows: determining an original image and a target prompt word matched with a target style; acquiring a rendered image of an original image obtained by a game engine and auxiliary enhancement information; inputting target prompt words, rendered images and auxiliary enhancement information into a target model; and obtaining a simulation image of the target style of the original image generated by the target model. According to the scheme, the image migration and the enhanced accurate control can be realized, so that the multi-style image migration requirement of the automatic driving simulation data can be met, and the accuracy of the automatic driving simulation test is improved.","['G06T19/20', 'G06F30/20', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06T15/005', 'G06T2219/2024']"
CN118298160A,Target detection method and system combining diffusion model and deformable convolution under complex weather,"The invention discloses a target detection method combining a diffusion model and deformable convolution in complex weather, which comprises the following steps: obtaining an image to be detected in complex weather, carrying out data enhancement processing on the image to be detected in complex weather to obtain an image after data enhancement, carrying out denoising processing on the obtained image after data enhancement to obtain a denoised image, and inputting the denoised image into a target detection network which is trained in advance and combines a diffusion model and a deformable convolution to obtain a final detection result. The method can solve the technical problems that the existing method based on image restoration and reconstruction only can remove single weather degradation, can not realize end-to-end image restoration, and has low detection speed and poor model universality and practicability, and the existing method based on deep learning is difficult to acquire a large amount of marked and representative training data, and has low recognition accuracy in complex weather.","['G06V10/25', 'G06N3/0464', 'G06N3/084', 'G06V10/30', 'G06V10/764', 'G06V10/766', 'G06V10/82', 'G06V20/10', 'G06V2201/07', 'Y02A90/10']"
KR102613781B1,Training data generation method and apparatus for deep learning model,"According to the present invention, a method for generating training data for training a deep learning model comprises the steps of: receiving a text prompt; generating 2D image data corresponding to the text prompt, which includes at least one 2D image; generating 2D video data corresponding to the text prompt, which includes at least two 2D images in a continuous frame relationship; generating 3D data corresponding to the text prompt, which includes at least one 3D image; and selecting some of the 2D image data, the 2D video data, and the 3D data to generate training data. According to the invention, it is possible to easily generate various pieces of high-quality image data.","['G06N3/0475', 'G06N3/08']"
WO2024028616A1,Image segmentation,"A computer implemented method of training an artificial neural network to perform image segmentation is provided. The method comprises providing a set of images as an input to an artificial neural network. The set of images comprises labelled images and unlabelled images. The artificial neural network is used to determine a prediction of whether each pixel within each of the unlabelled images is within a classification or not within the classification. A pseudo-label for each pixel of the unlabelled images is generated by comparing a confidence of the prediction to a threshold value. The artificial neural network is used to determine a prediction of whether each pixel within each of the labelled images is within the classification or not within the classification. An objective function is calculated, comprising a labelled loss determined by comparing the predictions for the labelled data and corresponding labels, and an unlabelled loss term determined by comparing the predictions for the unlabelled data and corresponding pseudo-labels. The artificial neural network is updated to optimise the objective function. The threshold value is varied during the training.","['G06T7/11', 'G06T2207/20081', 'G06T2207/20084']"
CN116416376A,"Three-dimensional hair reconstruction method, system, electronic equipment and storage medium","The invention discloses a three-dimensional hair reconstruction method, a system, electronic equipment and a storage medium, and relates to the technical field of computer graphics and computer vision, wherein the method comprises the following steps: acquiring RGB human images to be reconstructed; inputting the RGB portrait to be rebuilt into a three-dimensional voxel hair rebuilding model to obtain target three-dimensional voxel hair; the three-dimensional voxel hair reconstruction model is obtained by training a reconstruction network by using a training portrait set, a three-dimensional hair training set and corresponding texts; the reconstruction network comprises an image encoder and a trained voxel decoder, the trained voxel decoder is determined according to the trained VAE-patch_SNGAN network, and the trained VAE-patch_SNGAN network is obtained by training the VAE-patch_SNGAN network by utilizing a three-dimensional hair training set; reconstructing a target three-dimensional hair image from the target three-dimensional voxel hair. The invention improves the reconstruction speed and precision of the three-dimensional hair.","['G06T17/00', 'G06N3/08', 'G06T15/005']"
WO2025059185A1,Reliability assessment analysis and calibration for artificial intelligence classification,Disclosed herein is a system and method for the calibration of image classification from machine learning models and interactive artificial intelligence systems based thereon. An example of an interactive AI system using the same is disclosed. The system and method may provide a means for user interaction with the system and method.,"['G06V10/82', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/08', 'G06V2201/03']"
CN117764815A,"Model training method, video prediction method, device, equipment and storage medium","The invention discloses a model training method, a video prediction method, a device, equipment and a storage medium. The method comprises the following steps: determining the scene context of the initial video frame by utilizing the initial video frame and/or scene description metadata of the initial video frame acquired by the target vehicle; determining a vehicle movement instruction of the target vehicle by utilizing the initial video frame and/or track data of the target vehicle corresponding to the initial video frame; and training an initial model by using the initial video frame and a corresponding control text to obtain a video prediction model, wherein the control text comprises a scene context and a vehicle movement instruction. According to the technical scheme, natural language instructions and automatic labeling of scene context are carried out on a large-scale data (video frame) set without labels, so that a model can output frame images predicted for future frames according to existing frames and control texts based on natural language, and the problem that a video prediction model is limited by the label data set and layout information is solved.",['Y02T10/40']
CN116501432A,"Vehicle wallpaper generation method and device, electronic equipment and readable storage medium","The application provides a vehicle wallpaper generation method, a vehicle wallpaper generation device, electronic equipment and a readable storage medium. The method comprises the following steps: acquiring multi-mode information of a user, wherein the multi-mode information comprises image data, position data and human-vehicle interaction data of the user in a driving process; acquiring a keyword component according to the multi-mode information, wherein the keyword component comprises emotion information, position information and interaction information of a user; inputting the keyword component into a preset deep learning model for wallpaper generation to obtain an output wallpaper picture; the wallpaper picture is sent to a vehicle driven by the user. According to the technical scheme, the personalized vehicle wallpaper meeting the user state can be provided.","['G06F9/451', 'G06F3/0481', 'G06N3/0464', 'G06N3/08']"
US20230267652A1,Generating artistic content from a text prompt or a style image utilizing a neural network model,"The present disclosure relates to systems, methods, and non-transitory computer readable media that utilize an iterative neural network framework for generating artistic visual content. For instance, in one or more embodiments, the disclosed systems receive style parameters in the form a style image and/or a text prompt. In some cases, the disclosed systems further receive a content image having content to include in the artistic visual content. Accordingly, in one or more embodiments, the disclosed systems utilize a neural network to generate the artistic visual content by iteratively generating an image, comparing the image to the style parameters, and updating parameters for generating the next image based on the comparison. In some instances, the disclosed systems incorporate a superzoom network into the neural network for increasing the resolution of the final image and adding art details that are associated with a physical art medium (e.g., brush strokes).","['G06T11/00', 'G06T3/4046', 'G06T3/4053', 'G06T2210/22', 'G06T2210/36']"
CN118365408A,Image generation method and device,"One or more embodiments of the present disclosure provide an image generating method and apparatus, where the method includes obtaining a commodity image to be processed and a reference background image, performing text description processing on the reference background image to obtain a description text corresponding to the reference background image, generating a target background image based on the reference background image and the description text by using a generating model, and performing fusion processing on the commodity image to be processed and the target background image to obtain a target commodity image. In the embodiment of the specification, the reference background image is combined to generate the target commodity image for the target commodity, the similar commodity effect image can be automatically generated by using the generation model based on the reference background image as the style and composition reference, the drawing efficiency and the image quality of the commodity image are improved, the method is suitable for large-scale commodity image batch generation, and the drawing difficulty and the drawing cost of merchants are reduced.","['G06Q30/0643', 'G06T11/001', 'G06T11/60']"
US20250124236A1,Using llm functions to evaluate and compare large text outputs of llms,"A method for evaluating textual output of one or more machine-learned language models is presented. The method includes receiving, from a user of a client device, a first prompt for input to one or more machine-learned language models, providing the first prompt to the one or more models for execution, and receiving a set of generated responses to the first prompt from the one or more models. The method further includes generating a user interface (UI) on the client device displaying the first prompt and generated responses as a table user interface element. The method applies a selected evaluation function to the generated response to evaluate the response with respect to an evaluation objective and identifies words that influence the evaluation. The method generates one or more UI elements on the UI to display the results of the evaluation for the generated responses.","['G06F40/40', 'G06F40/103', 'G06F40/30']"
WO2025086884A1,"Advertisement generation method and system, medium and device","Provided are an advertisement generation method and system, a medium and a device. The method comprises: acquiring standard-product information and environment information of at least one standard product (S201); generating a standard-product image corresponding to the standard-product information on the basis of artificial intelligence generated content (AIGC), measuring each dimensionality of the standard-product image to obtain label information of each dimensionality of the standard-product image, and performing semantic combination on the label information of each dimensionality and the environment information to generate an advertisement copywriting (S202); and matching an advertisement template from an advertisement template library according to the label information of each dimensionality, and combining the standard-product image and the advertisement copywriting into the advertisement template to generate a standard-product advertisement (S203). The solution has the technical advantages of simplicity and high efficiency.","['G06Q30/0276', 'G06F40/186', 'G06Q30/0253', 'G06Q30/0277']"
US20250175456A1,Ai-controlled sensor network for threat mapping and characterization and risk adjusted response,"A system and method for an AI-controlled sensor network for threat mapping and characterization. The system deploys a network of honeypots and sensors across various geographic locations and network segments, collecting and aggregating data on network traffic and potential threats. An AI orchestrator analyzes this data using advanced machine learning models, generating dynamic honeypot profiles and a comprehensive threat landscape. The system can adapt in real-time to emerging threats, optimize resource allocation, and provide actionable intelligence. By correlating data across multiple points, the system offers enhanced threat detection capabilities and proactive cybersecurity measures, surpassing traditional security information and event management (SIEM) tools.","['H04L9/0643', 'G06F16/909', 'G06F16/951', 'G06N7/01', 'H04L63/0428', 'H04L63/061', 'H04L63/0807', 'H04L63/0815', 'H04L63/12', 'H04L63/123', 'H04L63/1408', 'H04L63/1425', 'H04L63/1433', 'H04L63/145', 'H04L9/0894', 'H04L9/14', 'H04L9/3236', 'H04L9/3297', 'G06N20/00', 'G06N5/01', 'G06N5/045', 'G06N5/046', 'H04L2463/121', 'H04L63/0442', 'H04L9/50']"
CN118260483A,A multimodal personalized content generation method,"A multi-modal personalized content generation method comprising the steps of: s1, converting various forms of user behavior data into natural language description by using a large language model; s2, extracting user preferences and target scene features from various user behaviors described by natural language by using a large language model, wherein the user preferences are characterized by generating explicit keywords and implicit vectors in a mixed mode; and S3, inputting user preference and scene information which are characterized by mixing the explicit keywords with the implicit vectors into a multi-mode content generator module, and generating multi-mode content by integrating the user preference and the scene information in a weighted manner, so as to realize multi-mode personalized generation of the personalized degree of the generated content and the joint adjustment of the matching degree of the generated content and the target scene. The method improves the generation quality of the multi-mode personalized content and realizes the controllability of the personalized degree of the multi-mode content.","['G06F16/9535', 'G06F16/3329', 'G06F40/151', 'G06F40/289', 'G06N3/045', 'G06N3/0475', 'G06N3/0985']"
WO2025129870A1,"Calculation and inference method for physical characteristics of tissue, and related device","Disclosed in the present invention are a calculation and inference method for the physical characteristics of tissue, and a related device. The method comprises: acquiring a data set, and training and testing a generative deep neural network model on the basis of the data set, so as to obtain a target network model; selecting target tissue, selecting a target area from the target tissue, scanning the target area to obtain tissue imaging information under the target area, and extracting an ultrasonic echo signal from the tissue imaging information; inputting the ultrasonic echo signal into the target network model, and simulating a wave transmission disturbance map of a mechanical wave in the target area; and obtaining trajectory information of the mechanical wave on the basis of the wave transmission disturbance map, and then obtaining the physical characteristics of the tissue in the target area on the basis of the trajectory information. In the present invention, a propagation disturbance process of the mechanical wave in the target area is simulated, and thus the wave transmission disturbance map can be obtained without actually generating such a mechanical wave disturbance, and the propagation speed of the mechanical wave can be obtained from the wave transmission disturbance map, and then physical properties related to the propagation speed are obtained.","['A61B8/485', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T7/0012', 'G06V10/82', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/03']"
US11926332B1,Assessing surprise for autonomous vehicles,"Aspects of the disclosure provide for controlling an autonomous vehicle. For instance, a first probability distribution may be generated for the vehicle at a first future point in time using a generative model for predicting expected behaviors of objects and a set of characteristics for the vehicle at an initial time expected to be perceived by an observer. Planning system software of the vehicle may be used to generate a trajectory for the vehicle to follow. A second probability distribution may be generated for a second future point in time using the generative model based on the trajectory and a set of characteristics for the vehicle at the first future point expected to be perceived by the observer. A surprise assessment may be generated by comparing the first probability distribution to the second probability distribution. The vehicle may be controlled based on the surprise assessment.","['B60W60/0017', 'B60W50/0098', 'B60W30/18', 'G05B13/048', 'G05D1/0088', 'G05D1/0212', 'B60W2050/0014', 'B60W2400/00', 'G05D2201/0213']"
CN116563459A,Text-driven immersive open scene neural rendering and mixing enhancement method,"The invention relates to a text-driven immersive large scene nerve rendering and mixing enhancement method, which comprises the following steps: 1. creating a data set; 2. reconstructing a large scene based on the improved progressive neural radiation field; 3. predicting a foreground and background matte value of the rendered image based on a convolutional neural network; 4. generating a background from the text using the stable diffusion model; 5. calculating background motion through camera parameter changes between adjacent frames; sixth, it is not necessary to use a special tool; fusing the rendering foreground and the background and performing illumination coordination. The invention realizes the background enhancement of the editable large scene driven by the real-time text, allows the rendering of any observation position of the immersive large scene with the city scale, generates the observation image with the effect consistent with that of the real scene, and performs mixed reality on the basis, thereby meeting the personalized customization of the scene by a user and obtaining the visual effect of the film and television special effect level. The technology can be applied to the fields of three-dimensional visualization, digital maps, virtual reality games and the like.","['G06T17/00', 'G06N3/0464', 'G06T15/50', 'G06T19/006', 'G06T7/70']"
US11776171B2,Systems and methods for magnetic resonance image reconstruction,The disclosure relates to systems and methods for magnetic resonance imaging (MRI). A method may include obtaining k-space data associated with MR signals acquired by an MR scanner. The k-space data may corresponding to a first sampling rate. The method may also include generating one or more estimated images based on the k-space data and a target neural network model. The one or more estimated images may correspond to a second sampling rate that exceeds the first sampling rate. The method may further include determining one or more target images based on the one or more estimated images and the k-space data using a compressed sensing model. The compressed sensing model may be constructed based on the one or more estimated images.,"['G06T11/006', 'G01R33/543', 'G01R33/5608', 'G01R33/561', 'G06N3/08', 'G06T11/005', 'G06N3/045', 'G06N3/047', 'G06T2211/424']"
CN114998548A,Image reconstruction method and system,"The invention discloses a method, a system and a computer program product for image reconstruction, wherein the method comprises the following steps: acquiring images of a plurality of existing perspectives of a scene; taking the images of the existing visual angles as training samples, training a nerve radiation field model, wherein in the training process, the input of the nerve radiation field model is the visual angles of the training samples and the characteristics stored in a hash table, and the characteristics stored in the hash table are obtained by performing hash coding on the positions of sampling points and indexing the characteristics stored in the hash table according to coding values; and displaying the three-dimensional model of the scene corresponding to the trained neural radiation field model. Compared with the prior art, the image reconstruction method disclosed by the invention has the advantages that the accuracy of the reconstructed model is higher, and the training speed is higher.","['G06T17/20', 'G06N3/08']"
US20250131677A1,Training machine learning models to perform neural style transfer in three-dimensional shapes,"One embodiment of the present invention sets forth a technique for training a machine learning model to perform style transfer. The technique includes applying one or more augmentations to a first input three-dimensional (3D) shape to generate a second input 3D shape. The technique also includes generating, via a first set of neural network layers, a style code based on a first latent representation of the first input 3D shape and a second latent representation of the second input 3D shape. The technique further includes generating, via a second set of neural network layers, a first output 3D shape based on the style code and the second latent representation, and performing one or more operations on the first and second sets of neural network layers based on a first loss associated with the first output 3D shape to generate a trained machine learning model.","['G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'G06T17/00', 'G06T17/10', 'G06T19/20', 'G06T2210/56', 'G06T2219/2021', 'G06T2219/2024']"
CN119788938A,"Video generation method, device, electronic equipment and storage medium","The embodiment of the disclosure discloses a video generation method, a device, an electronic device and a storage medium, wherein a first potential feature of a start frame image and a second potential feature of an end frame image are extracted by acquiring the start frame image and the end frame image of a target video to be generated, a first optical flow between the start frame image and an intermediate frame image to be generated in the target video and a second optical flow between the end frame image and the intermediate frame image are extracted, the first potential feature is distorted based on the first optical flow, the second potential feature is distorted based on the second optical flow, the distorted first potential feature and the distorted second potential feature are fused to obtain a first distortion feature of the intermediate frame image, the first potential feature, the first distortion feature and the second potential feature are respectively spliced with random noise and then are input into a diffusion model to be denoised, and the target video is obtained, so that the video generation quality can be improved.",[]
CN115424088A,Image processing model training method and device,"The embodiment of the specification provides an image processing model training method and device, wherein the image processing model training method comprises the following steps: carrying out noise adding processing on a target image in the image sample pair to obtain a noise image; inputting the original image in the image sample pair into an initial image processing model for processing to obtain an initial image; generating a restored image according to the noise image and the initial image, wherein the original image and the restored image have the same attribute characteristics; and training the initial image processing model according to the restored image and the noise image until a target image processing model meeting the training condition is obtained, wherein the target image processing model is a machine learning model. When the initial image processing model is trained according to the restored image and the noise image, the image characteristics of different noise images can be gradually introduced into the initial image processing model in the training process, the stability of model training can be effectively improved, the prediction accuracy of the model is improved, and the actual image processing requirements of users are met.","['G06V10/774', 'G06N3/04', 'G06V10/30']"
WO2023200866A1,Computer representations of peptides for efficient design of drug candidates,"In some aspects, the present disclosure describes a method for obtaining a latent representation. In some cases, the method comprises providing a peptide graph comprising a plurality of nodes and a plurality of edges. In some cases, the plurality of edges encodes bonded interactions and nonbonded interactions between the plurality of nodes. In some cases, the method comprises generating the latent representation for a node in the plurality of nodes. In some cases, the generating is based at least partially on the peptide graph. In some cases, the latent representation encodes short-range interactions and long-range interactions between the node and at least a subset of nodes in the plurality of nodes.","['G16B15/30', 'G06N20/10', 'G06N20/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/01', 'G16B40/20', 'G06N3/0442', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/126', 'G06N5/045']"
CN116991990A,"AIGC-based program development auxiliary methods, storage media and equipment","The application provides a program development assisting method, a storage medium and equipment based on AIGC. Collecting prompt words input by a user in a pre-trained AIGC model; matching the prompting words with a preset sensitive information base, and confirming whether the prompting words are compliant; and when confirming the compliance of the prompt word, controlling the AIGC model to generate information matched with the prompt word. The program development assisting method based on the AIGC can help program developers reduce repetitive work based on the AIGC model, simplify the program development work and simultaneously avoid leakage of sensitive information in the interaction process with the AIGC model.","['G06F16/3329', 'G06F16/3344', 'G06F16/35', 'G06F40/289', 'G06F40/30', 'G06F8/30']"
CN107128356A,Steering controller,"Present invention offer is a kind of can more suitably to pass to pavement state as handling maneuver reaction force the steering controller of driver.Second elastic reactance torque of the preferable auto model to the first elastic reactance torque based on target little gear angle and at least based on transverse acceleration carries out computing as the composition of the elastic component of handling maneuver auxiliary force.Preferable auto model by with defined usage rate by first and second elastic reactance torque phase Calais's computing elastic component.Preferable auto model determines the usage rate of the first and second elastic reactance torque based on the distribution gain set by the difference according to the first and second elastic reactance torque.The difference of first and second elastic reactance torque more increases, and preferable auto model more increases the usage rate of the second elastic reactance torque.","['B62D5/04', 'B62D5/0463', 'B62D3/12', 'B62D5/0412', 'B62D6/00', 'B62D6/006', 'B62D6/008']"
US12397519B2,Multi-material halftoning of additively manufactured optics,"A device comprises an array of voxels of solidified material defining at least one scan path, along which an error in a variable dielectric quantity at a target voxel is distributed by successive deposition and solidifying of a selected material along the scan path, in accordance with a prescription for the device. The prescription defines the dielectric quantity over the array of voxels.","['B29C64/386', 'B29D11/00355', 'B29C64/112', 'B33Y10/00', 'B33Y50/00', 'B33Y50/02', 'B33Y70/00', 'B33Y80/00']"
WO2024233961A2,Non-invasive analysis of electrophysiological processes using imaging and deep learning,"This invention provides new and useful methods for accurately imaging heart rhythm disorders. Novel panoramic optical mapping methods, and recent advances in machine learning techniques, are used to create a mechano-electrical model effective in predicting electrical activity of a tissue based on motion of the tissue. Deep learning techniques for constructing three-dimensional intramural electrical wave patterns from surface data, imaging chambers for performing panoramic optical mapping methods, and deep learning techniques for motion tracking tissue via optical and/or ultrasound data are also provided. The optical mapping and deep learning techniques of the disclosure may be applied in a plurality of different ways, individually or in combination, to improve the diagnosis and treatment of heart rhythm disorders. Also provided are systems for performing the methods described herein as well as non-transitory computer readable storage media and computer products.","['G16H50/20', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/50', 'G16H50/70']"
US11861827B2,Techniques for automatically characterizing liver tissue of a patient,"The disclosure relates to techniques for automatically characterizing liver tissue of a patient, comprising receiving morphological magnetic resonance image data set and at least one magnetic resonance parameter map of an imaging region comprising at least partially the liver of the patient, each acquired by a magnetic resonance imaging device, via a first interface. The techniques further include applying a trained function comprising a neural network to input data comprising at least the image data set and the parameter map. At least one tissue score describing the liver tissue is generated as output data, which is provided using a second interface.","['G06T7/0012', 'G06T7/0014', 'A61B5/004', 'A61B5/055', 'A61B5/4244', 'A61B5/7267', 'G01R33/4828', 'G01R33/5608', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B2576/02', 'G06N20/10', 'G06N3/047', 'G06N5/01', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30056']"
US10818063B2,Repurposing existing animated content,"Systems and methods for automatically animating a character based on an existing corpus of animation are described. The character may be from a previously produced feature animated film, and the data used for training may be the data used to animate the character in the film. A low-dimensional embedding for subsets of the existing animation corresponding to different semantic labels may be learned by mapping high-dimensional rig control parameters to a latent space. A particle model may be used to move within the latent space, thereby generating novel animations corresponding to the space's semantic label, such as a pose. Bridges may link a first pose of a first model within the latent space that is similar to a second pose of a second model of the space. Animations corresponding to transitions between semantic labels may be generated by creating animation paths that traverse a bridge from one model into another.","['G06T13/40', 'G06T13/20', 'G06T17/20', 'G06T7/20', 'G06T2200/04']"
CN117422788B,Method for generating DWI image based on CT brain stem image,"The invention discloses a method for generating a DWI image based on a CT peduncle image, which relates to the technical field of image cross-mode synthesis, and comprises the following steps of firstly dividing a peduncle lesion of the CT image to obtain a division mask of a peduncle lesion region; step two, generating a cross-modal of a CT image to a DWI sequence to obtain a generated brain stem image DWI sequence, and providing a unique method by combining medical image segmentation and medical image cross-modal synthesis, wherein a traditional medical image cross-modal generating task is divided into two stages, namely brain stem lesion region segmentation and brain stem image cross-modal synthesis; the segmentation network and the generation network are improvements to the prior art, can be rapidly generated, and can display clear lesion areas, so that the generation effect reaches a very high level.","['G06T11/003', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T3/4038', 'G06T7/11', 'G06T2200/32', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
CN116993848A,"CBCT image reconstruction method, system, computer device and storage medium","The application discloses a CBCT image reconstruction method, a CBCT image reconstruction system, a CBCT image reconstruction computer device and a CBCT image storage medium. The method mainly comprises four steps of acquisition of multi-mode image data of a patient for training, registration of the multi-mode image data of the patient, training of a denoising diffusion probability model based on conditions and use of the denoising diffusion probability model based on the conditions. According to the application, the CBCT image shot by the patient in the follow-up stage process can be utilized, the CT image for positioning shot before treatment is combined, the image quality is optimized through the denoising diffusion probability model based on the condition, and the synthetic CT image corresponding to the time point is finally generated. The quality of the synthesized CT image generated by the method completely meets the requirement of clinical diagnosis, has higher clinical value, can be directly used for auxiliary diagnosis, helps a clinician to recalculate the radiation dose of radiotherapy, improves the accuracy of dose calculation, further helps to improve the efficiency of self-adaptive treatment, and simultaneously eliminates subjectivity.","['G06T11/003', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06T7/30', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US20240320476A1,"System and method for capturing, managing and enriching prompts in a data processing environment","A prompt capture and enrichment system having a prompt capture unit for receiving prompts from different data sources to form input prompts; a prompt enrichment unit for automatically enriching one or more prompt attributes of the input prompts and for generating enriched prompts; a prompt filtering unit for filtering the enriched prompts based on prompt attributes and then generating filtered prompts and for generating a truthfulness score associated with the filtered prompts indicative of a truthfulness of the filtered prompts; a prompt matching unit for matching one of the enriched or filtered prompts with one of the input prompts to determine if a match exists based on user information and prompt attributes; and a storage unit including a blockchain for storing the input prompts, the enriched prompts, and the filtered prompts.","['G06N3/0475', 'G06N20/00', 'G06N5/022']"
CN115762464A,"Speech synthesis model training method, electronic device and storage medium","The invention discloses a training method of a speech synthesis model, electronic equipment and a storage medium, wherein the training method of the speech synthesis model comprises the following steps: training an acoustic model without emotional input, wherein a diffusion process is used in the training process of the acoustic model, and the training target of the acoustic model is to estimate the logarithmic gradient of data distribution at any intermediate moment in the diffusion process; training an emotion classifier, wherein the input of the emotion classifier at least comprises a logarithmic gradient corresponding to a certain intermediate moment in the diffusion process; and performing emotion-controllable speech synthesis sampling by using a soft label guidance technology, wherein the diffusion process corresponds to a reverse denoising process of the speech synthesis sampling, a gradient item of the reverse denoising process is a target estimated by a speech synthesis model, and a soft label guidance item is mathematically equivalent to cross entropy and comprises one side of output of the emotion classifier and the other side of distribution corresponding to target emotion intensity.",[]
US20240256831A1,Unsupervised pre-training of neural networks using generative models,"In various examples, systems and methods are disclosed relating to generating a response from image and/or video input for image/video-based artificial intelligence (AI) systems and applications. Systems and methods are disclosed for a first model (e.g., a teacher model) distilling its knowledge to a second model (a student model). The second model receives a downstream image in a downstream task and generates at least one feature. The first model generates first features corresponding to an image which can be a real image or a synthetic image. The second model generates second features using the image as an input to the second model. Loss with respect to first features is determined. The second model is updated using the loss.","['G06V10/7753', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06T5/70', 'G06V10/82']"
US20240095537A1,Unknown-class (out-of-distribution) data detection in machine learning models,"Described, herein, relates to a system of and method for digitally monitoring a large-scale dataset on a computing device and automatically detecting, in real-time, unknown class data in order to aid a machine learning model. Once machine learning models are deployed in the real-world applications, the models tend to encounter unknown-class (i.e., out-of-distribution) (hereinafter âOODâ) data during inference. Detecting out-of-distribution data is a crucial task in safety-critical applications to ensure safe deployment of deep learning models. It is desired that the machine learning model should only be confident about the type of data that has already seen in-distribution (hereinafter âIDâ) class data which reinforces the driving principle of the OOD detection. The system and method may rely on contrastive feature learning of the largescale datasets, where the embeddings lie on a compact low-dimensional space. Additionally self-supervised fine-tuning may then be performed by mapping an ID class feature into uni-dimensional sub-space.",['G06N3/0895']
CN116012492A,Prompt word intelligent optimization method and system for character generation image,"The application discloses a prompt word intelligent optimization method and a system for a text generated image, wherein the method is characterized in that input text input by a user is obtained, the input text is input into a text classification model to obtain main body intention of the input text, and the main body intention is used for representing that drawing intention of the user comprises figures and does not comprise figures; inputting an input text into a pre-trained text-to-text generation model, and outputting a supplementary prompt word text based on the generation parameters of the text-to-text generation model; if the main body is not intended to contain the person, eliminating the artist names with the character drawing trend attribute in the prompt word text according to a pre-generated artist list, and obtaining the optimized input prompt word. The method and the device solve the technical problems that the method for supplementing and optimizing the promtt in the related technology is low in efficiency and high in trial and error cost, and the intention of inputting the promtt by the user cannot be accurately supplemented, and realize the intention of accurately supplementing the promtt by the user with high efficiency and low trial and error cost.",[]
WO2024233636A2,Systems and methods for inline quality control of slide digitization,"Described herein is a system for digitizing a slide. A system may include an optical system including at least an optical sensor; and a computing device configured to perform a scan of the slide by capturing at least a first image and capturing at least a second image, wherein performing the scan includes identifying a first scanning parameter; using the optical system, capturing the at least a first image as a function of the first scanning parameter; determining a first quality metric as a function of the at least a first image; determining a second scanning parameter as a function of the first quality metric; and using the optical system, capturing the at least a second image as a function of the second scanning parameter.","['G06V20/69', 'G02B21/365']"
US20240273871A1,Multi-dimensional image stylization using transfer learning,A method for generating a multi-dimensional stylized image. The method includes providing input data into a latent space for a style conditioned multi-dimensional generator of a multi-dimensional generative model and generating the multi-dimensional stylized image from the input data by the style conditioned multi-dimensional generator. The method further includes synthesizing content for the multi-dimensional stylized image using a latent code and corresponding camera pose from the latent space to formulate an intermediate code to modulate synthesis convolution layers to generate feature images as multi-planar representations and synthesizing stylized feature images of the feature images for generating the multi-dimensional stylized image of the input data. The style conditioned multi-dimensional generator is tuned using a guided transfer learning process using a style prior generator.,"['G06V10/28', 'G06T19/20', 'G06N3/0475', 'G06N3/096', 'G06T17/10', 'G06V10/454', 'G06V10/7715', 'G06T2219/2012', 'G06T2219/2024']"
WO2025101309A1,Adaptive video compression using generative machine learning,"Various embodiments of the technology described herein relate to compression of video data, including selecting a pivot image from a video including a plurality of images and causing a first machine learning model to generate a descriptor of the pivot image, where the descriptor includes a language description associated with the pivot image. In one example, the pivot image and the descriptor are provided to a decoder for reconstruction of the video. In an embodiment, the decoder includes a generative machine learning model that takes as an input the pivot image and the descriptor. The decoder uses the pivot image to generate an image based at least in part on the descriptor. The image is combined with other images generated by the generative machine learning model to reconstruct the video.","['H04N21/26603', 'G06V10/761', 'G06F40/40', 'G06N3/045', 'G06N3/088', 'G06V10/82', 'G06V20/46', 'H04N19/463', 'H04N19/503', 'H04N21/84', 'G06V2201/07']"
US20240320475A1,Systems and methods for data processing using machine learning,"A method, non-transitory computer readable medium, apparatus, and system for data processing are described. An embodiment of the present disclosure includes receiving, from a content provider via a user interface, a query about a chart that includes information related to a domain. A machine learning model generates a response to the query based on the chart and a corpus of documents in the domain. The response includes information from the corpus of documents. The user interface provides at least a portion of the response to the content provider.","['G06F40/40', 'G06F16/242', 'G06F16/285', 'G06F30/27', 'G06F9/453', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/084', 'G06Q30/0204', 'G06Q30/0244', 'G06Q30/0254', 'G06Q30/0276', 'G06Q30/0277', 'G06F40/186']"
CN117709248A,Automatic integrated circuit testing method based on generation type AI,"The invention discloses an automatic test method for an integrated circuit based on a generation type AI, which comprises the steps that a first generation type AI model generates a test plan according to an acquired target document, the test plan is decomposed into a plurality of test subtasks, an agent generates a test subtask document based on the test subtask, the generated test subtask document is integrated to generate a test program of target test equipment, and the test program is operated in the target test equipment, so that the integrated circuit is tested. The automatic test method for the integrated circuit based on the generated AI, which is provided by the invention, can efficiently and reliably generate the required test program according to the product document, the test document and the automatic test equipment document, can replace or assist a test engineer to better complete the test work, improves the efficiency of developing and debugging the test scheme of the integrated circuit, and accelerates the development period of chip products.","['G06F30/33', 'G06F30/27', 'G06N20/00', 'G06N3/006']"
US12393788B2,Matrix user interface for LLM-powered data analysis and generation,"A data analytics system uses a grid-based data structure to improve the usability of LLMs in the analysis of large data sets, to synthesize information for use in other generative AI contexts, and to improve a user's ability to interface with an LLM. A grid-based data structure is a data structure or database that stores the results of column prompts applied to sources. The grid-based data structure may store the results in a relational manner. For example, a grid-based data structure may have rows that correspond to sources (e.g., documents, files, or databases) and columns that correspond to prompts. Each cell of the grid-based data structure stores the output of the column prompt applied to a source using an LLM. Thus, each column prompt may be systematically applied to each source to generate information based on the sources in an organized way.","['G06F16/221', 'G06F16/243', 'G06F16/24578', 'G06F16/248', 'G06F16/332', 'G06F16/3344', 'G06F16/338', 'G06F16/383', 'G06F40/35']"
EP4407567A1,Zero-shot prompt ensembling for zero-shot classification with text-image models,Systems and methods for zero-shot prompt ensembling for zero-shot classification with text-image models can include utilizing a pre-trained text-image model to perform downstream tasks based on prompt-based weighting. The systems and methods may adjust for frequency-based bias and may automatically determine different prompt associations with a given downstream task. The systems and methods can aggregate weighted text embeddings and then determine a classification output based on similarity measures between an image embedding and the aggregated weighted text embeddings.,"['G06V10/7753', 'G06V20/70', 'G06F40/40', 'G06N3/045', 'G06N3/08', 'G06V10/761', 'G06V10/764', 'G06V10/776', 'G06V10/82']"
CN117079110A,Travel image video system and method based on diffusion,"The invention belongs to the technical field of image video management, in particular to a travel image video system and a travel image video method based on diffusion, wherein the travel image video system based on the diffusion comprises a server, a user registration login module, a diffusion model generation optimization module, an image video processing module and a processing supervision analysis module; according to the invention, the diffusion model special for the video of the travel image is generated through the diffusion model generation optimization module, and the diffusion model is continuously optimized in the use process so as to ensure the use performance of the diffusion model, the image video processing module processes the input image or video by using the diffusion model and fine-tunes the processed image or video, the processing effect can meet the professional requirements, and the management personnel can timely and pertinently make corresponding improvement measures by effectively analyzing and feeding back early warning the processing efficiency, the periodic operation condition and the public praise condition, so that the stable and efficient operation and comprehensive popularization of the system are ensured.","['G06V10/96', 'G06F16/583', 'G06F16/78', 'G06V10/30', 'Y02T10/40']"
CN117727374A,A multi-target molecule generation method and system based on diffusion model,"The invention discloses a multi-target molecule generation method based on a diffusion model, which comprises the following steps: acquiring an active molecular data set with a label, inputting the active molecular data set into a pre-established substructure search model to acquire a semantic substructure S of the active molecular data set, and converting the semantic substructure S into a noisy semantic substructure simplified molecular linear input specification SMILES sequence y noise And the noise-containing semantic substructure SMILES sequence y is processed noise Further toConversion to noisy semantic sub-structure term y 0 Will contain the semantic substructure sequence y of noise 0 Inputting a pre-trained diffusion model to obtain multi-target molecules. The invention can solve the technical problems that the existing model based on the generation countermeasure network can generate samples with high quality, but is difficult to train and easy to collapse in training, so that the generated samples have poor uniqueness.",[]
US20250225277A1,Sensitive data protection,A method and system is disclosed which enable sensitive data to be protected during interactions with a generative model.,['G06F21/6254']
CN119227549B,Editable condition printing image generation method,"The invention discloses a method for generating an editable conditional printing image, and belongs to the field of image generation. The method comprises the steps of constructing a printing image generation model, training the model to obtain a generation model with editable conditions, and generating a printing design image required by the composite conditions by using the model. According to the invention, different advanced features of each element of the printing plane image are extracted through downsampling, the elements and style information in the printing plane image are captured through multiscale feature extraction and information exchange, hidden space vectors corresponding to the features of different printing plane images are analyzed, fusion of specific styles is realized in hidden space, decoding of the printing design image is realized through a decoder, decoupling of element information is realized, personalized design and diversified requirements can be met, and expansibility is realized.","['G06F30/27', 'G06N3/0464', 'G06N3/08', 'G06T11/00', 'G06F2111/04']"
CN117911588A,"Virtual object face driving and model training method, device, equipment and medium","The disclosure provides a virtual object face driving and model training method, device, equipment and medium, relates to the technical field of artificial intelligence, and particularly relates to the technical fields of augmented reality, virtual reality, computer vision, deep learning and the like. The virtual object face driving method comprises the following steps: acquiring image features, the image features comprising: reference features of the first facial image of the virtual object and mask features of the mask image; the mask image is obtained by masking the mouth area of the second face image of the virtual object; acquiring audio characteristics of target audio, wherein the target audio is used for driving the second face image; performing diffusion processing on the image features and the audio features to obtain generated features; decoding the generated features to generate a driving image; the driving image is an image obtained after the target audio drives the second face image. The virtual object face driving method and device can improve virtual object face driving efficiency.",['G06T13/205']
US20250061634A1,Audio-driven facial animation using machine learning,"Systems and methods of the present disclosure include animating virtual avatars or agents according to input audio and one or more selected or determined emotions and/or styles. For example, a deep neural network can be trained to output motion or deformation information for a character that is representative of the character uttering speech contained in audio input. The character can have different facial components or regions (e.g., head, skin, eyes, tongue) modeled separately, such that the network can output motion or deformation information for each of these different facial components. During training, the network can use a transformer-based audio encoder with locked parameters to train an associated decoder using a weighted feature vector. The network output can be provided to a renderer to generate audio-driven facial animation that is emotion-accurate.","['G10L21/10', 'G06T13/205', 'G06N20/00', 'G06N3/0464', 'G06T13/40', 'G10L15/16', 'G10L2021/105']"
US20240155071A1,Text to video generation,"A method and system for text-to-video generation. The method includes receiving a text input, generating a representation frame based on the text input using a model trained on text-image pairs, generating a set of frames based on the representation frame and a first frame rate, interpolating the set of frames to a higher frame rate, generating a first video based on the interpolated set of frames, increasing a resolution of the first video based on a first and second super-resolution model, and generating an output video based on a result of the super-resolution models.","['H04N7/0117', 'G06T11/00', 'G06T3/4046', 'G06T3/4053', 'H04N7/013', 'H04N7/0135']"
WO2025024608A2,Imaging device and a method for image generation of a specimen,An imaging device for image generation of a specimen is disclosed. Layers of images may be captured by an optical system and then compiled to create an integrated image. Each layer may include a different focal point. A consolidated image may then be created by combining one or more integrated images.,"['G06T7/0014', 'G06T5/50', 'G06T7/11', 'G06T7/80', 'H04N23/69', 'H04N23/695', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/30024']"
US20250069343A1,Using Machine Learning Models to Create a Closet and Effect Virtual Try-On and Styling On Actual Users,"Disclosed are example implementations of systems and methods for virtual digital closet of available digital fashion items. An example method of creating and using a virtual digital closet comprises retrieving a shopper avatar to render in a user interface according to a shopper likeness, the shopper avatar previously configured by a user of a virtual try-on system; receiving data representing a plurality of garments from a database associated with the virtual try-on system, the data including a stored outfit comprising at least one garment from the plurality of garments; providing the shopper avatar wearing the stored outfit in the user interface in the virtual try-on system; generating a user interface element in the user interface, the user interface element comprising a visual representation of a select garment of the plurality of garments; receiving a user selection of the user interface element; rendering the select garment on the shopper avatar for display in the user interface; and adding the select garment to the virtual digital closet.","['G06T19/006', 'G06T3/18', 'G06T5/77', 'G06T7/12', 'G06V10/24', 'G06V10/26', 'G06V10/44', 'G06V10/454', 'G06V10/82', 'G06V20/20', 'G06V40/103', 'G06T2210/16', 'G06T2219/2012']"
CN115908640A,"Method, device, readable medium and electronic device for generating image","The embodiment of the disclosure relates to a method and a device for generating an image, a readable medium and an electronic device. The method comprises the following steps: acquiring a first text for describing a target object, and acquiring a second text; inputting the first text and the second text into a pre-generated target image generation model to obtain a target image output by the target image generation model; the target image comprises a target object and character information corresponding to a second text, the target image generation model comprises a first text encoder and a second text encoder, the first text encoder is used for encoding the first text to obtain first text characteristics corresponding to the first text, the second text encoder is used for encoding the second text to obtain second text characteristics corresponding to the second text, and the target image generation model is further used for generating a target image according to the first text characteristics and the second text characteristics. In this way, clear text information can be included in the generated target image.",[]
CN117611708A,Method and computing device for generating graphics context,"The application provides a method and computing equipment for generating graphics context. The method comprises the following steps: generating a corresponding prompt message by using the photo provided by the user; inputting the prompt text into a large language model for grouping and generating a photo text; generating a document layer by using the photo document; selecting photos according to the groupings; generating a photo layer using the selected photo; inputting the photo text and/or at least part of selected photos into a pre-trained graphic generating model to generate a personalized background layer in real time; and uniformly synthesizing the photo layer, the text layer and the background layer into an output picture, and providing the output picture for a user. According to the technical scheme, corresponding pictures and texts can be automatically generated based on the input pictures, and the labor time cost can be saved.","['G06T11/60', 'G06V20/70']"
CN117611453A,A nuclear magnetic resonance image super-resolution recovery method and model construction method,"The invention discloses a nuclear magnetic resonance image super-resolution recovery method and a model construction method, which can recover high-quality high-resolution nuclear magnetic resonance images from low-resolution nuclear magnetic resonance images acquired in nuclear magnetic resonance imaging equipment. The model construction method comprises a forward diffusion process structure of a progressive reconstruction and denoising diffusion model, a loss function structure of the progressive reconstruction and denoising diffusion model and model training, a low-resolution nuclear magnetic resonance image is obtained, and the initial step number of reverse sampling and a noise degradation image corresponding to the initial step number are determined according to the collected low-resolution image; and then starting from the noise degradation image corresponding to the starting point, alternately executing the iterative change step and the progressive diffusion sampling step based on the model until the noiseless high-resolution nuclear magnetic resonance image is recovered, and training network parameters by adopting a plurality of groups of high-resolution nuclear magnetic resonance image data so that the image output of the network and the noiseless high-resolution image are approximated as much as possible.","['G06T3/4053', 'G06T11/005', 'G06T2207/10088']"
CN116542347A,A federated learning optimization method based on diffusion model,"The invention relates to the technical field of privacy calculation, in particular to a federal learning optimization method based on a diffusion model, which comprises the following steps: collecting a large number of high-accuracy models; training a diffusion model; performing federal learning tasks; processing the training model by using the obtained denoising model DM, and denoising the training model; the beneficial effects are as follows: the federal learning optimization method based on the diffusion model uses the diffusion model capable of eliminating noise as a generator, takes the model trained by each client of federal learning as the input of the diffusion model, and uploads the model after denoising to a parameter server for the subsequent federal learning process. The invention combines the diffusion model technology, regards the difference of the data distribution of each client as noise, and removes the noise by using the diffusion model, so that the model uploaded by each client is more similar to the final expected model, thereby improving the training speed and the final training effect of federal learning.","['G06N20/20', 'Y02T10/40']"
WO2024212160A1,Method and apparatus for diffusion model,"A computer-implemented method for diffusion model is provided. The method comprises: providing a model with inputs, wherein the model is used to estimate a score function in the diffusion model, and the inputs have been perturbed with noises gradually in time to form a diffusion path starting from an original input to a noise; obtaining outputs from the model; and optimizing the model by reducing an error between the outputs and velocities along the diffusion path.","['G06F30/27', 'G06F30/10', 'G06N3/00', 'G06N3/047', 'G06T11/00', 'G06F2111/10']"
CN118070673A,Road network constraint track generation method and system based on diffusion model,"The invention provides a road network constraint track generation method and system based on a diffusion model, and belongs to the field of intelligent traffic. The method comprises the steps of firstly collecting track data in a road network, and representing the track data as a road network constraint track represented by adopting a mixture of discrete type road sections and continuous type mobility; preprocessing the road network constraint track, and converting the hybrid representation into a continuous representation in a vector form; constructing a road network constraint track generation model based on a diffusion model, wherein the road network constraint track generation model comprises forward noise adding and reverse noise reducing processes, and obtaining a noise reduction network for fitting noise after training is completed; randomly sampling noise from Gaussian noise, inputting the noise into a trained road network constraint track generation model, and obtaining a vectorized road network constraint track through a multi-step reverse noise reduction process; and carrying out vectorization decoding on the vectorized road network constraint track, and outputting the road network constraint track of the mixed representation. The invention expands the track data set and protects the privacy of users.","['G06F30/27', 'G06F30/18', 'G06N3/0464', 'G06F2111/04']"
CN118089702A,Signal generation and road reconstruction method and system based on Riemann diffusion SchrÃ¶dinger bridge,"The invention discloses a signal generation and road reconstruction method and system based on a Riemann diffusion Schrodinger bridge, which relate to the technical field of road reconstruction, wherein a motion signal generated when an inertial sensor moves along a road to be reconstructed is used as input, a trained segmentation model is utilized to determine segmentation points so as to segment the motion signal to obtain a plurality of segments of sub-signals, and then a motion parameter corresponding to the sub-signals is predicted by the trained motion model so as to generate a motion track of the inertial sensor, namely the road to be reconstructed, which is obtained by reconstruction, the trained motion model is obtained by utilizing a sample training based on the Riemann diffusion Schrodinger bridge, a large number of training samples are generated by utilizing the Riemann diffusion Schrodinger bridge so as to support training an artificial intelligent model, so that road reconstruction can be completed based on the motion signal acquired by the inertial sensor and the artificial intelligent model, and the cost is low, and the efficiency and the accuracy are high.","['G01C21/3815', 'G01C21/3837', 'G06F30/13', 'G06F30/27', 'Y02T10/40']"
WO2025111118A1,Content management tool for capturing and generatively transforming content item,"Systems and methods for transforming a captured content item are provided. In particular, a computing device may receive a capture request to capture a content item, in response to the capture request, capture the content item and provide the content item in a first user interface element of a content management tool, apply a generative transformation function to the content item to generate a transformed content item, write the transformed content item in a second user interface element of the content management tool, receive a paste request to paste the transformed content item at a requested location, and in response to the paste request, provide the transformed content item at the requested location.","['G06F9/543', 'G06F40/166', 'G06N20/00', 'G06N3/0475', 'G06T11/60', 'G06F2209/545']"
CN117911548A,Target scene synthesis using generative AI,"Embodiments of the present disclosure relate to target scene synthesis using a generative AI. Embodiments of the present disclosure provide techniques for generating synthetic target scenes using natural language cues. The method includes receiving a natural language description of an image to be generated using a machine learning model. The method further includes extracting control elements and sub-hints from the natural language description of the image to be generated. The method further includes identifying a relationship between the control element and the sub-hint based on the natural language description of the image to be generated. The method also includes generating, by the machine learning model, an image based on the control elements, the sub-hints, and the relationships. The image includes visual elements corresponding to the control elements and the sub-cues.","['G06T11/00', 'G06F40/253', 'G06F40/30', 'G06N20/00', 'G06T2210/22', 'G06T2210/61']"
US20120133664A1,System and method for painterly rendering based on image parsing,"A system and method for synthesizing painterly-looking images from input images (e.g., photographs). An input image is first interactively decomposed into a hierarchical representation of its constituent components named parse tree, whose nodes correspond to regions, curves, and objects in the image, with occlusion relations. According to semantic information in the parse tree, a sequence of brush strokes is automatically prepared according a brush dictionary manually built in advance, with their parameters in geometry and appearance appropriately tuned, and blended onto the canvas to generate a painterly-looking image.",['G06T11/001']
CN117095257A,"Multi-mode large model fine tuning method, device, computer equipment and storage medium","The embodiment of the invention discloses a multi-mode large model fine tuning method, a multi-mode large model fine tuning device, computer equipment and a storage medium. The method comprises the following steps: acquiring training data related to equipment defect, environmental hidden danger and personnel violation monitoring; processing and analyzing the training data to obtain a processing result; carrying out data expansion on training data which are unevenly distributed and the quantity of which is not in accordance with the requirement, and combining the training data with the processing result to obtain an expansion result; training and fine-tuning the multi-mode large model by adopting an expansion result to obtain a detection model; and testing and reasoning by using the detection model. By implementing the method of the embodiment of the invention, the multimode large model can be finely tuned, the model illusion is lightened, the model illusion brought by fine tuning is reduced, the cost is low, and the efficiency is high.","['G06V10/774', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06V10/82', 'G06V20/70']"
CN115438210A,"Text image generation method, text image generation device, terminal and computer readable storage medium","The invention provides a text image generation method, a text image generation device, a terminal and a computer readable storage medium, wherein the text image generation method comprises the following steps: displaying a plurality of candidate text segments, receiving a text segment determination instruction of a user, and determining a current text segment in the plurality of candidate text segments; inputting the current text segment into a pre-trained text generation model, and extracting current text representations corresponding to texts after the current text segment is spliced with all historical text segments; and acquiring historical image representations corresponding to all historical images, inputting the current text representations and the historical image representations into a pre-trained image generation model, and generating current candidate images corresponding to the spliced text. According to the invention, the current text representation of the spliced text is extracted, and the current text representation and the historical image representations corresponding to all the historical images are input into the image generation model together, so that each image has consistency, and further the long text can be matched with a series of corresponding images with consistency.","['G06F16/5846', 'G06F16/3346', 'G06N3/08']"
US12158929B1,Watermarking digital media for authenticated content verification,"The present disclosure provides a method of watermarking digital media for subsequent decoding. The method includes receiving a secure content package comprising digital audiovisual content, source entity information, content annotations, and digital signatures. The package is validated using public-key cryptography. A content identifier is generated and embedded as a watermark into the digital audiovisual content. The watermark is configured to be machine readable and visually inconspicuous. A content database entry is recorded in a remote database, retrievable using the content identifier and comprising the content annotations and source information. The watermarked digital audiovisual content is stored and transmitted to the media source. The method may further include generating and storing content hashes for future authentication comparisons.","['H04L63/12', 'G06F21/16', 'H04L9/0643', 'H04L9/3247', 'H04N21/8358', 'H04L2209/608', 'H04L9/3239', 'H04L9/50']"
CN117671146A,Single-view three-dimensional reconstruction method based on circulation diffusion model,"The invention discloses a single-view three-dimensional reconstruction method based on a cyclic diffusion model, which comprises the following steps of: extracting and fusing to obtain a fused feature vector, and predicting the mean value and variance of the conditional feature vector of the image; sampling the mean value and the variance of the predicted image condition feature vector to obtain an image condition feature vector; performing furthest point sampling to obtain a three-dimensional model point cloud, and training a denoising network in a diffusion model; the guiding capability of the image condition feature vector to the denoising network is improved through cyclic denoising; the denoising network is guided to gradually denoise the pure noise point cloud conforming to the standard Gaussian distribution through the input sheet Zhang Shitu, and finally, the three-dimensional model point cloud consistent with the geometric structure of the single view is obtained; the invention aims to provide a single-view three-dimensional reconstruction method based on a cyclic diffusion model, which has the advantages of stable training and higher operation efficiency and can improve the guiding capability of views.","['G06T17/00', 'Y02T10/40']"
CN116958423A,"Text-based three-dimensional modeling method, image rendering method and device","The embodiment of the application discloses a text-based three-dimensional modeling method, an image rendering method and a device. The main technical scheme comprises the following steps: acquiring a prompt text and a reference image; initializing a three-dimensional characterization model, and training the three-dimensional characterization model according to a preset training target; in the training process, acquiring point cloud data of a reference image by using a point cloud generation model, acquiring density field data and color hidden features output by a three-dimensional characterization model, integrating the color hidden features with a noise image to obtain a noise-added image, inputting shape constraint information, a prompt text and the noise-added image obtained by using the density field data into an image diffusion model, and carrying out noise removal processing by using the image diffusion model; the training targets include: minimizing shape differences between the point cloud data and the density field data, and minimizing differences between the noise and noise images predicted during the denoising process. The application can improve the shape controllability of the three-dimensional modeling and the consistency between viewing angles.","['G06T17/00', 'G06T15/00', 'Y02T10/40']"
US20240427995A1,Identifying visual text using vision-language models,"A method includes receiving a text to be used for generating an image. The method further includes determining whether the text is a visual text using a machine learning model trained to classify whether an input text is non-visual text or visual text. The method further includes responsive to determining that the text is a visual text, generating the image using a second machine learning model based on the text. The method further includes displaying the image and the text.","['G06F40/205', 'G06F40/289', 'G06T11/00', 'G06T11/60']"
CN117591880A,Data generation method based on generation type artificial intelligent model and blockchain network,"The invention provides a data generation method and a blockchain network based on a generation type artificial intelligence model, which can be used in the technical field of artificial intelligence, and the method comprises the following steps: acquiring primary input data and secondary input data; the improved generation type AI model is adopted, the generation type data is obtained according to the primary input data and the secondary output data through the business intelligent contract, the improved generation type AI model comprises a neural network model and a diffusion model which are deployed based on a blockchain network, the original generation type AI model is improved through the neural network model and the diffusion model, the improved generation type AI model is subjected to distributed transformation based on the blockchain network, the training time of the model and the calculation force requirement on equipment are reduced, so that the construction cost of the generation type AI model is saved, the construction efficiency is improved, and the popularization and the use of model development are facilitated.","['H04L67/104', 'G06F18/214', 'G06N3/04', 'G06N3/08']"
CN110675339A,Image inpainting method and system based on edge inpainting and content inpainting,"The disclosure discloses an image restoration method and system based on edge restoration and content restoration, which preprocesses an original defect image to obtain a gray defect image after processing; carrying out smoothing treatment on the gray defect image; extracting incomplete edge images and image masks from the gray defect images after the smoothing processing; taking the image mask, the gray defect image and the incomplete edge image as input values of an edge generator, and generating a complete edge structure chart by the edge generator; and taking the complete edge structure diagram and the original defect image as input values of a content generator, and generating an image with the filled missing area by the content generator. Therefore, image restoration is realized, the method is considered more comprehensively than the traditional method, and practice proves that the method is effective to the actual data set.","['G06T5/77', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN117252984A,"Three-dimensional model generation method, device, apparatus, storage medium, and program product","The application discloses a three-dimensional model generation method, a device, equipment, a storage medium and a program product, and relates to the technical field of computers. The method comprises the following steps: acquiring a noise adding characteristic representation; when denoising processing is carried out on the denoising feature representation through the denoising network layer corresponding to each of the plurality of view angles, determining the input feature representation of the denoising network layer corresponding to each of the plurality of view angles; extracting three-dimensional shared information shared among the three-dimensional conversion matrixes respectively corresponding to the multiple input characteristic representations; and adjusting the multiple input characteristic representations by using the three-dimensional shared information, and generating view angle images corresponding to the multiple view angles respectively by the multiple adjustment characteristic representations. Through the mode, the representation and characterization of the input features can be constrained by means of the three-dimensional shared information, so that stronger correlation exists between view images, and the three-dimensional model with stronger geometric consistency is generated based on integration of a plurality of view images. The method and the device can be applied to various scenes such as cloud technology, artificial intelligence, intelligent traffic and the like.","['G06T17/00', 'G06T15/005', 'G06T7/73']"
CN117424232B,Short-term photovoltaic power prediction method based on three-dimensional meteorological data multi-source fusion,"The invention provides a short-term photovoltaic power prediction method based on three-dimensional meteorological data multisource fusion, which is characterized in that a space-time condition diffusion model is constructed for generating a prediction satellite cloud image, space-time characteristics in historical satellite images and historical ERA5 meteorological data are extracted through space-time LSTM, a high-precision prediction satellite cloud image is generated by combining condition generation countermeasure network, and then a mapping relation between two-dimensional cloud characteristics and three-dimensional meteorological element characteristics and photovoltaic power is established through a U-shaped meteorological characteristic embedding network, so that high-precision photovoltaic power prediction is realized. The method fully considers the influence of cloud layer height, sun position and meteorological conditions on photovoltaic power, can realize high-precision short-term photovoltaic power prediction, helps an electric company to better manage an electric power network and an electric transmission line, and ensures the safe and stable operation of the system.",['Y04S10/50']
CN116309682A,A Medical Image Segmentation Method Based on Conditional Bernoulli Diffusion,"The invention belongs to the technical field of medical image analysis, and particularly relates to a medical image segmentation method based on conditional Bernoulli diffusion. The invention uses Bernoulli noise as a diffusion kernel to enhance the segmentation capability of a diffusion model, thereby generating a more accurate segmentation map; generating a series of diversified segmentation maps by randomly sampling the initial Bernoulli noise and the intermediate hidden variables a plurality of times by utilizing the randomness of the diffusion model, thereby highlighting the salient regions of interest and providing valuable references for radiologists; furthermore, according to the principles of DDIM, sub-sequences are efficiently sampled from the entire trajectory of the back diffusion, thereby speeding up the segmentation process. The superior performance of the segmentation method of the invention is proved in qualitative and quantitative aspects through a large number of experiments on real data.","['G06T7/194', 'G06T5/70', 'G06V10/774', 'G06T2207/10081', 'G06T2207/20021', 'G06T2207/30061', 'Y02T10/40']"
CN116701692B,"Image generation method, device, equipment and medium","The invention discloses an image generation method, device, equipment and medium, which are applied to the technical field of image generation and comprise the following steps: inputting the first input data into a target diffusion model for reasoning, and acquiring an output result of each iteration in a reasoning process; the first input data includes first noise and first text information; calculating the divergence based on the output results of two adjacent iterations to obtain a divergence sequence; grouping the divergence sequences to obtain divergence groups, and carrying out parameter quantization on a target diffusion model in an inference stage corresponding to each divergence group in sequence; the reasoning stage is the reasoning stage corresponding to the iteration times corresponding to each divergence in the divergence group; generating an image based on the second input data and the parameter quantized target diffusion model; the second input data includes second noise and second text information. The problem of low model reasoning speed can be solved, the model reasoning speed is improved, and further the image generation efficiency is improved.","['G06F16/5866', 'G06N5/04', 'Y02D10/00']"
US20240330381A1,User-Specific Content Generation Using Text-To-Image Machine-Learned Models,"Techniques for presenting a content item using text-to-image machine-learned models are presented. For example, a system can obtain user personalization data associated with a user and merchant assets data of a merchant. Additionally, the system can process the user personalization data and the merchant assets data with a text generation model to generate one or more model-generated terms. Moreover, the system can process the one or more model-generated terms with an image generation model to generate one or more model-generated images. Furthermore, the system can determine a content item based on the one or more model-generated images. Subsequently, the system can present, on a display of a user device of the user, a graphical user interface having the content item.","['G06Q30/0271', 'G06F16/9535', 'G06F16/53', 'G06F16/9538', 'G06F3/04845', 'G06Q30/0276', 'G06Q30/0641', 'G06T11/00', 'G06T2200/24']"
CN116883530A,Text-to-image generation method based on fine granularity semantic rewards,"The invention discloses a text-to-image generation method based on fine granularity semantic rewards, which comprises the following steps: acquiring a prompt text; inputting the prompt text into a text-to-image diffusion model trained in advance to obtain a target image corresponding to the prompt text; the training step of the text-to-image diffusion model comprises the following steps: inputting training texts into an untrained text-to-image diffusion model to obtain a plurality of training images; determining global semantic alignment scores of each training image and determining local semantic alignment scores of each training image; determining a training sample from the plurality of training images according to the global semantic alignment score and the local semantic alignment score; training a text-to-image diffusion model with the training sample to obtain a trained text-to-image diffusion model. The invention can realize the matching of the semantics of the generated image and the input text, and can be widely applied to the fields of deep learning and computer vision.","['G06T11/00', 'G06V10/764', 'G06V10/774', 'Y02D10/00']"
CN118014858A,"Image fusion method and device, electronic equipment and storage medium","The disclosure relates to an image fusion method, an image fusion device, an electronic device and a storage medium, wherein the method comprises the following steps: acquiring at least two images to be fused, and encoding each image to be fused by an image encoder to obtain a plurality of image characteristics to be fused; obtaining text features corresponding to the features of each image to be fused according to the trained image-text conversion model and the features of the plurality of images to be fused; and performing diffusion processing on the standard noise data according to the trained image diffusion model to obtain noise information containing the image information of each image to be fused, and generating a fused image. Through adopting the method and the device, the image and the text are mutually translated by adopting the image-text conversion model, the image characteristics of a plurality of images and the corresponding text semantic characteristics are obtained, the fusion image containing high-level semantic characteristics is generated by denoising in the diffusion model, the fusion image is matched with the image information of each image to be fused, the fusion image with vivid visual effect can be generated, and the quality of the generated fusion image is improved.","['G06T5/50', 'G06N3/0455', 'G06N3/0464', 'G06V10/806', 'G06V10/82', 'G06T2207/20221']"
CN117474748A,"Image generation method and device, electronic equipment and storage medium","The application relates to an image generation method, an image generation device, electronic equipment and a storage medium. The method comprises the following steps: acquiring a target facial image, target facial features corresponding to the target facial image, content description features corresponding to an expression image to be migrated and priori image features corresponding to a first description text, wherein the first description text is used for indicating to generate an expression image of the target facial with a target expression, the target facial is the face corresponding to the target facial image, and the target expression is the expression corresponding to the expression image to be migrated; inputting the target facial features, the content description features and the priori image features into an expression personalized fusion model to carry out expression personalized fusion, so as to obtain personalized expression features; and inputting the target facial image and the personalized expression characteristics into an expression image generation model to generate an expression image, so as to obtain the target personalized expression image. By means of the scheme, the original facial features can be better kept while expression migration is achieved, and personalized expression requirements of users are met.","['G06T5/50', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201']"
CN116205820A,"Image enhancement method, target identification method, device and medium","The application relates to an image enhancement method, a target identification method, equipment and a medium, belonging to the technical field of computers, wherein the method comprises the following steps: inputting a target image to be enhanced into a pre-trained image enhancement network, encoding the target image through a self-encoder in the image enhancement network, inputting the obtained encoding features into a first diffusion model in an image enhancement model for enhancement, and inputting the obtained enhanced encoding features and the obtained encoding features into a self-decoder in the image enhancement model after fusion to obtain an enhanced image corresponding to the target image; the output result of the self-encoder is corrected based on a preset lookup table when the image enhancement network is trained, and the image enhancement network is trained based on the corrected encoding result; the problem that the traditional neural network model for image enhancement is poor in enhancement effect on images with more characteristics missing can be solved; the adaptability of the network to extreme scenes is improved, and the enhancement effect of the target image is improved.","['G06T5/00', 'G06N3/08', 'G06T9/001', 'G06T9/002', 'G06V10/774', 'G06V10/80', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
JP2024161345A,"Image style transition method, device, electronic device, and storage medium","To provide an image style transition method, a device, an electronic apparatus and a storage medium in the present disclosure.SOLUTION: This disclosure relates to an artificial intelligence technology field, and relates to a technical field, such as deep learning, and an AIGC (Artificial Intelligence Generated Content). An image style transition method includes: acquiring a reference image and a description text; extracting a text feature of the description text; and calculating a first cross attention feature between a first image feature and the text feature in each time step of a diffusion model on the basis of the diffusion model trained in advance, acquiring a second cross attention feature between a second image feature of the reference image and the text feature, editing the first cross attention feature on the basis of the second cross attention feature, acquiring a third cross attention feature, generating a result image feature of the time step on the basis of the third cross attention feature and the text feature, decoding the result image feature in a last time step, and generating a target image by performing operation for generating the target image.SELECTED DRAWING: Figure 2","['G06T3/04', 'G06V10/44', 'G06N3/045', 'G06N3/0475', 'G06T11/60', 'G06T9/00', 'G06V10/806', 'G06V10/82']"
CN120176714B,A visual language navigation method for mobile robots based on diffusion strategy,"The invention relates to a mobile robot vision language navigation method based on a diffusion strategy, which comprises the steps of S1, constructing RGB and depth space-time fusion coding modules, S2, constructing a natural language instruction key semantic query coding module, effectively condensing and compressing natural language instructions, S3, fusing vision, language, local history displacement and global displacement information, constructing a multi-mode condition cross attention coding module, S4, constructing a condition diffusion transducer decoding module, decoding based on a condition vector to obtain a noise vector, acting on a multi-step denoising process, outputting a plurality of candidate multi-step navigation tracks, S5, constructing a navigation track discriminator based on a comparison learning method, and used for efficiently and autonomously discriminating matching scores of candidate tracks and target points. The invention has stronger anti-interference capability and higher task completion rate, can adapt to various complex environments and dynamic changes, has stronger generalization capability and expandability, and can stably operate in diversified application scenes.","['G01C21/3629', 'G01C21/343', 'G01C21/3446', 'G01C21/3635']"
CN118393900B,"Automatic driving decision control method, device, system, equipment and storage medium","The invention relates to the technical field of automatic driving, in particular to an automatic driving decision control method, an automatic driving decision control device, an automatic driving decision control system, automatic driving decision control equipment and a storage medium, wherein when an automatic driving decision model is utilized to control the movement of a target vehicle, the automatic driving decision model is optimized according to the interaction process of the target vehicle and a driving environment, a first real vehicle driving sample is collected in the optimization process, vehicle risk driving data is extracted from the first real vehicle driving sample to be used as a risk driving sample, the risk driving sample is subjected to sample expansion to generate a synthetic risk driving sample, the first real driving sample and the synthetic risk driving sample are utilized to carry out model parameter adjustment on the automatic driving decision model, the model targeting fine adjustment for the risk driving behavior is realized with smaller environment interaction cost on the basis of the prior experience of the automatic driving, the automatic driving decision control system is supported to quickly adapt to the application environment, and the applicability and generalization of the automatic driving decision control system to unknown new scenes are improved.",['G05B13/042']
WO2025123814A1,"Image generation method and apparatus, and device and storage medium","Provided in the present disclosure are an image generation method and apparatus, and a device and a storage medium. The method comprises: acquiring prompt text including food description information, wherein the food description information comprises a target food name and target cooking state information which represents whether the food is uncooked food or cooked food; inputting the prompt text into a pre-training-based image generation model, such that the image generation model generates, on the basis of the inputted prompt text, a food image matching the target food name and the target cooking state information, wherein training samples of the image generation model include food description samples and corresponding food image samples, and the food description samples include food name samples and cooking state information samples of foods in the food image samples; and outputting the food image generated by the image generation model. The present embodiment can generate a high-quality food image reflecting an accurate cooking state.","['G06T11/60', 'G06Q30/0643', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
CN118172432B,"Posture adjustment method, device, electronic device and storage medium","The application discloses a gesture adjustment method, a gesture adjustment device, electronic equipment and a storage medium, wherein the gesture adjustment method comprises the following steps: acquiring a picture to be adjusted and gesture information; extracting an initial character image and a background image of a target character from the picture to be adjusted through a region segmentation model; and generating a target picture with the adjusted posture based on the initial character image, the background image and the posture information through a diffusion model. The application solves the technical problem of high complexity of the operation for adjusting the figure posture in the photo in the related technology.","['G06T11/00', 'G06N3/0455', 'G06N3/0475', 'G06T5/60', 'G06T5/70', 'G06T7/11', 'G06T7/194', 'G06T2207/20084', 'G06T2207/30196']"
US20250157114A1,Animatable character generation using 3d representations,"In various examples, systems and methods are disclosed relating to generating animatable characters or avatars. The system can assign a plurality of first elements of a three-dimensional (3D) model of a subject to a plurality of locations on a surface of the subject in an initial pose. Further, the system can assign a plurality of second elements to the plurality of first elements, each second element of the plurality of second elements having an opacity corresponding to a distance between the second element and the surface of the subject. Further, the system can update the plurality of second elements based at least on a target pose for the subject and one or more attributes of the subject to determine a plurality of updated second elements. Further, the system can render a representation of the subject based at least on the plurality of updated second elements.","['G06T19/20', 'G06T13/40', 'G06T17/00', 'G06T17/20']"
CN115206457A,"Three-dimensional molecular structure generation method, device, equipment and storage medium","The embodiment of the application provides a method, a device, equipment and a storage medium for generating a three-dimensional molecular structure, which are at least applied to the fields of artificial intelligence and drug synthesis, wherein the method comprises the following steps: acquiring atom type noise and atom coordinate noise at the current time step; constructing a fully-connected adjacency matrix based on the atom type noise; carrying out three-dimensional equal transformation processing on the atom type noise, the atom coordinate noise and the full-connection adjacency matrix to obtain a molecular structure distribution average value under the current time step; iteratively generating the molecular structure of the molecule based on the average molecular structure distribution value at the current time step to obtain the molecular representation of the molecule; constructing the three-dimensional molecular structure from the molecular representation. By the method and the device, the generation efficiency of the three-dimensional molecular structure can be accelerated, and accumulative errors are avoided, so that the three-dimensional molecular structure of the effective molecules can be accurately generated.","['G16C20/50', 'G16C20/40', 'G16C20/70']"
WO2024072140A1,Apparatus and method for controlling a robot photographer with semantic intelligence,"An electronic device for controlling a photographic system may obtain a video stream and a user query for a target event, obtain a set of photos from the video stream, obtain at least one photoshoot suggestion based on the user query via a language model, obtain a snapped photo for the target event based on the at least one photoshoot suggestion, in response to a given video frame included in the video stream satisfying a target content criterion, and output one or more photos selected from the set of photos and the snapped photo as event photos.","['B25J9/1679', 'B25J11/00', 'B25J13/003', 'B25J19/023', 'B25J9/163', 'B25J9/1697', 'G06F3/167', 'G06F40/00', 'G06T7/70', 'H04N23/61', 'H04N23/64', 'H04N23/66', 'H04N23/667', 'H04N23/695', 'H04N23/90', 'G06T2207/10016', 'G06T2207/30244']"
CN117972585A,Fault enhancement diagnosis method based on PCA-DDPM and CNN under small sample condition,"The invention discloses a fault enhancement diagnosis method based on PCA-DDPM and CNN under a small sample condition, which comprises the following steps: first, the original fault signature data is subjected to a dimension reduction process using Principal Component Analysis (PCA). Secondly, inputting the fault characteristic data after dimension reduction into DDPM for training, and sampling by using the trained model to generate a new sample. Thirdly, carrying out dimension lifting operation on the generated new sample by utilizing the inverse transformation of PCA, wherein the number of features after dimension lifting is equal to the number of fault features of the original sample, and completing the amplification of the fault sample. Fourth, training a CNN model by using the original fault sample, and constructing a fault diagnosis model. And finally, inputting the amplified sample into a CNN fault diagnosis model trained in the fourth step, and realizing fault enhancement diagnosis under the condition of a small sample.","['G06F18/2431', 'G06F18/2135', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/084']"
CN118334144A,"Fitting picture generation method, system, and fitting picture generation model training method","The embodiment of the application provides a fitting picture generation method, a fitting picture generation system and a fitting picture generation model training method. The test-drawing generation method comprises the following steps: acquiring a first image of a target model and a second image of a garment to be tried on; performing image processing on the first image to obtain a plurality of third images expressing different information; performing garment deformation processing on the garment to be tried on in the second image based on the first image, and acquiring a fourth image, so that the garment form of the garment to be tried on in the fourth image is aligned with the posture of the target model; based on the third image, the fourth image, the first image and the second image, control is performed to generate a fitting pattern for fitting the clothing to be fitted in a corresponding posture by the target model. Because the control signals for generating the try-on patterns comprise the information after the clothing deformation processing and the original characteristics of the clothing to be tried on in the second image, the generated try-on patterns effectively keep the detailed information of the clothing to be tried on and are more fit with the body state of the target model.","['G06T19/20', 'G06T11/00', 'G06N3/04', 'G06N3/08', 'G06Q30/0643', 'G06T3/4038', 'G06T3/4046', 'G06T5/70', 'G06V10/74', 'G06V10/82', 'G06T2207/20081', 'G06T2207/30196', 'G06T2210/16', 'G06T2219/2021']"
WO2024242624A1,Image generation method,"Provided in the embodiments of the present disclosure is an image generation method, the image generation method comprising: inputting an object description text containing at least two objects into an image generation model, and determining an initial text vector of the object description text; determining pre-stored object vectors of the at least two objects, the pre-stored object vectors being generated with respect to the training text vectors of the at least two objects during a training process of the image generation model; and, by means of the pre-stored object vectors, processing the initial text vector to obtain a target text vector and, according to the target text vector, generating an object image containing the at least two objects. Therefore, the present disclosure avoids the problem that a large number of multi-concept customized statements cause the low training efficiency of a neural network model and waste a large number of computing resources, ensures the smooth operation of an image generation model and provides a stable image generation capability.","['G06F16/33', 'G06F40/126', 'G06N3/04', 'G06N3/08', 'G06T11/00', 'G06N3/0455']"
US20160054409A1,Fmri-based neurologic signature of physical pain,"Described herein is a novel fMRI-based neurologic signature that predicts pain. Further described are methods for detecting pain, for diagnosing pain-related neuropathic conditions and for predicting or evaluating efficacy of an analgesic based on the neurologic signature.","['G01R33/4806', 'A61B5/055', 'A61B5/4824', 'A61B5/4839', 'A61B5/4848', 'G01N33/4925', 'A61B2576/026']"
US12294387B2,Decoding of error correction codes based on reverse diffusion,"Disclosed herein are systems and method for training neural network based decoders for decoding error correction codes, comprising obtaining a plurality of training samples comprising one or more codewords encoded using an error correction code and transmitted over a transmission channel where the training samples are subject to gradual interference over a plurality of time steps and associate the encoded codeword(s) with an interference level and a parity check syndrome at each of the plurality of time steps, using the training samples to train a neural network based decoder to decode codewords encoded using an error correction code by (1) estimating a multiplicative interference included in the encoded codeword(s) based on reverse diffusion applied to the encoded codeword(s) across the time steps, (2) computing an additive interference included in the encoded codewords based on the multiplicative interference, and (3) recovering the codeword(s) by removing the additive interference.","['H03M13/1575', 'G06N3/045', 'G06N3/084', 'H03M13/03', 'H03M13/1108', 'H03M13/6597', 'H04L1/0045']"
CN116958131B,"Image processing method, device, equipment and storage medium","The application provides an image processing method, an image processing device, image processing equipment and a storage medium, which are applied to various image-based detection scenes such as cloud technology, artificial intelligence, intelligent traffic, auxiliary driving, industrial application and the like; the image processing method comprises the following steps: performing information reconstruction based on the to-be-reconstructed characteristics of the to-be-detected image to obtain an information reconstruction result, wherein the to-be-detected image is imaging information of the to-be-detected entity; determining a first anomaly score map based on the difference of the information reconstruction result relative to the image to be detected; denoising the mask image of the image to be detected to obtain a denoised image; determining a second anomaly score map based on a difference between the denoised image and the image to be detected; determining a target anomaly score map by combining the first anomaly score map and the second anomaly score map; and determining a detection result of the entity to be detected based on the target anomaly score graph. Through this application, can promote the detection accuracy.","['G06T7/001', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/30108']"
CN116524299A,"A method, device, equipment and storage medium for image sample generation","The invention discloses an image sample generation method, device, equipment and storage medium, which overcome the problem of difficult acquisition of machine vision image samples, can acquire a small amount of positive samples by using the method, can generate a large amount of positive sample images, and can generate available negative samples according to various defect types learned in a data set. Meanwhile, the problem of poor stability of the existing image sample generation method is solved, and the network and the training method used by the method can accurately keep the characteristics of the product sample and generate a near-real sample image.","['G06V10/774', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06T7/0004', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'Y02P90/30']"
CN117876535A,"Image processing method, device, equipment, medium and program product","The embodiment of the application discloses an image processing method, an image processing device, a medium and a program product, wherein the method comprises the following steps: acquiring a first image to be processed and style prompt information; performing image coding processing on the first image to obtain image coding characteristics; performing linear transformation on the first image and the style prompt information by adopting an attention algorithm, and embedding image coding features into the linear transformation to generate target semantic features; a second image is generated based on the target semantic features. By adopting the embodiment of the application, the image coding features can be embedded in the image generation process, so that the image generation cost is reduced and the image quality is improved.","['G06T11/60', 'G06N3/0455', 'G06N3/08']"
CN118429493A,Method and system for generating interactive actions between human body and multiple objects in VR/AR scenes,"The invention provides a human body and multi-object interaction generating method and system in VR/AR scene, comprising: collecting a motion capture data set of human body interaction with multiple objects; based on the motion capture data set, establishing and training a text generation diffusion model of human interaction with an object; and using a trained diffusion model, describing the generated text of the interaction between the person and the object as a diffusion condition by using the geometric information of the object and the initial gesture of the object and the person, and obtaining a corresponding human body action and object motion sequence through Gaussian diffusion denoising. The invention provides a data set for interaction between a 3D human body and multiple objects, and simultaneously provides a diffusion model for generating motion of the human body and the objects through texts based on the data set; compared with the prior art, the invention can generate more real and natural character interaction sequences, and has wider application.","['G06T13/40', 'G06N3/0455', 'G06T19/006', 'G06T5/70']"
CN115824645A,Steam Turbine Vibration Fault Diagnosis Method and System,"The invention discloses a turbine vibration fault diagnosis method, which relates to the technical field of turbine vibration fault diagnosis, and is characterized in that denoising diffusion, amplification and other calculations are carried out on turbine normal operation vibration data and various fault vibration data to obtain a denoising diffusion model, a fault diagnosis model and a seed library, then a sample of an actual fault is processed by the denoising diffusion model, the fault diagnosis model and the seed library to obtain a fault type distribution P (A | B) and a probability distribution P (B) of a noise level in a current operation state, and then a fault diagnosis result in the current operation condition is obtained through calculation; the invention also discloses a steam turbine vibration fault diagnosis system which comprises the sensor, the calculation server and the industrial personal computer, and the process is executed, so that more fault samples can be generated to improve the diagnosis effect, avoid noise interference and improve the diagnosis stability.",['Y02T90/00']
WO2024086333A1,Uncertainty-aware inference of 3d shapes from 2d images,"Provided are computing systems, methods, and platforms that infer an object shape from an image using a neural radiance field (NeRF) model. A NeRF model can infer a 3D shape from a 2D image by performing a plurality of iterations to generate a plurality of sample 2D images of a 3D scene. For each iteration, an object code can be sampled from a posterior distribution of learned priors on NeRF models associated with the 3D scene, the object code can be processed with a hypernetwork to generate a set of NeRF weights from the object code, and a NeRF model with the set of NeRF weights predicted by the hypernetwork can generate a sample 2D image of the 3D scene. The sample 2D images generated during the iterations can be provided as an output.","['G06N3/047', 'G06N3/0455', 'G06N3/084', 'G06N3/088', 'G06N3/0464']"
US20240185396A1,Vision transformer for image generation,"Apparatuses, systems, and techniques to generate images. In at least one embodiment, one or more machine learning models generate an output image based, at least in part, on calculating attention scores using time embeddings.","['G06T5/002', 'G06T1/20', 'G06T5/60', 'G06T5/70', 'G06T7/0002', 'G06T2207/20081', 'G06T2207/20182']"
CN116452706A,Image generation method and device for presentation file,"The invention provides a method and a device for generating images of a presentation, which can be used in the financial field or other fields. The method comprises the following steps: acquiring an image generation guide language sent by a user side, and inputting the image generation guide language into a pre-established image generation model; processing the image generation guide language by using an encoder and a preamble network in the image generation model to obtain a plurality of image features; and processing the image characteristics by using a decoder in the image generation model to obtain a presentation image, and sending the presentation image to the user side. According to the invention, the image generation guide language is processed through the image generation model, so that the presentation file image required by a user is obtained, the image is accurately and rapidly generated through characters, the fidelity of the generated image and the matching degree of character information are high, the image generation comprises different resolutions and different style capacities, iteration is not required in the processing process, the calculated amount is reduced, and the working efficiency is improved.","['G06T11/60', 'G06V10/761', 'G06V10/774']"
EP4553759A2,"Image editing method, apparatus, and storage medium","A computer-implemented image editing method includes: obtaining an editing instruction input by a user in a current round of a dialogue and history dialogue information in at least one history round of the dialogue, wherein the history dialogue information comprises a history dialogue text and at least one history image; determining a source image to be edited from the at least one history image based on the editing instruction and the history dialogue information; and editing the source image to generate a target image based on the editing instruction.","['G06F40/216', 'G06F40/174', 'G06F40/186', 'G06F40/30', 'G06F40/35', 'G06F40/40', 'G06T11/60', 'G06T5/60', 'G06T5/70', 'G06F40/289', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092']"
CN117830451A,"Text illustration generation method, device, equipment and storage medium","The invention relates to the field of computers and discloses a text illustration generation method, a device, equipment and a storage medium. The method comprises the following steps: receiving a text illustration generation request, and acquiring an input text according to the text illustration generation request; acquiring an input prompt word, and carrying out semantic extraction on the input text through a trained large language model according to the input text and the prompt word to obtain a target text, wherein the prompt word is a condition met by the generated target text; encoding the target text by an encoder of a pre-trained neural network model to obtain a text code; according to the text encoding, a text illustration corresponding to the target text is generated by transmitting randomly sampled noise through a learned denoising process using a trained diffusion model. According to the embodiment of the invention, the process of text map matching can be simplified, the text map can be automatically generated, and the efficiency of generating the text map can be improved.","['G06T11/001', 'G06F40/30', 'G06N3/0455', 'G06N3/08', 'G06T11/60']"
CN118429531A,"Method, device, equipment and storage medium for generating three-dimensional objects","The disclosure provides a method, a device, equipment and a storage medium for generating a three-dimensional object, and belongs to the technical field of computers. The method comprises the following steps: in the ith iteration process, fine tuning is carried out on a first multi-view image through a three-dimensional object generation model to obtain a second multi-view image, wherein the first multi-view image is a plurality of two-dimensional images obtained by rendering a target three-dimensional object represented by first three-dimensional information from different view angles; based on the difference between the first multi-view image and the second multi-view image, updating the first three-dimensional information for multiple times to obtain second three-dimensional information, wherein the second three-dimensional information is used for representing a target three-dimensional object generated by the ith round of iteration; and generating a target three-dimensional object based on the second three-dimensional information in response to the iteration end condition being satisfied. The method can greatly reduce the total forward calculation times of the three-dimensional object generation model required in the process of generating the target three-dimensional object, and improves the generation efficiency of the three-dimensional object.","['G06T17/00', 'G06T15/10']"
CN118365544A,"A natural scene visual reconstruction method, system, device and medium based on cerebral cortex surface model","A natural scene visual reconstruction method, system, equipment and medium based on a cerebral cortex surface model, wherein the method comprises the following steps: firstly, acquiring functional magnetic resonance imaging (fMRI) data through a stimulus image, preprocessing the fMRI data, extracting characteristics of the stimulus image, reconstructing a low-level image of the preprocessed fMRI data, training a model through the preprocessed fMRI data and the extracted characteristics of the stimulus image, obtaining fMRI characteristics of a CLIP space through the trained model, and reconstructing the stimulus image based on the reconstructed low-level image and the fMRI characteristics of the CLIP space; the system, the equipment and the medium are used for realizing a natural scene vision reconstruction method based on a cerebral cortex surface model; the invention can accurately extract the information which is vital to image reconstruction from complex fMRI data, and enhances the quality and accuracy of image generation.","['G06T5/60', 'G06N3/0455', 'G06N3/082', 'G06V10/454', 'G06V10/464', 'G06V10/7715', 'G06T2207/10088']"
WO2024184153A1,Data processing systems and methods for detection of anomalous data,"The present disclosure relates to computer-implemented methods of detecting anomalous data that deviates from a first training dataset, comprising: a) generating synthetic anomalous images from images of randomly generated noise using a first reverse diffusion network and a second reverse diffusion network; b) generating a second training dataset comprising a plurality of images from the first training dataset and the plurality of synthetic anomalous images; c) training a binary classifier using the second training dataset, the binary classifier configured to classify a received image as normal data or anomalous data that deviates from the first training dataset; d) using the binary classifier to determine whether a received image is normal data or anomalous data. The invention further relates to methods of generating synthetic anomalous data, methods of training of the binary classifier, data processing systems, and data structures, computer programs, machine-readable storage media, or data carrier signals.","['G06N3/0455', 'G06T7/0002', 'G06F18/214', 'G06F18/2178', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06T2207/20081', 'G06T2207/20084']"
US20250251917A1,Transpiler to extract and use intermediate representations of a code base,"Provided is a process including: obtaining, with a computer system, access to a code base; decomposing, with the computer system, the code base into parts; classifying, with the computer system, the parts according to content type; selecting, with the computer system, processing templates based on the content types, with at least some different content types having different selected processing templates; and generating natural language documentation for the parts, with one or more generative language models, using the processing templates selected for the parts.","['G06F16/334', 'G06F16/31', 'G06F40/30', 'G06F40/40', 'G06F8/427', 'G06F8/73']"
EP4591228A1,Forward-forward training for machine learning,"Example implementations provide a computer-implemented method for training a machine-learned model, the method comprising: processing, using a layer of the machine-learned model, positive input data in a first forward pass; updating one or more weights of the layer to adjust, in a first direction, a goodness metric of the layer for the first forward pass; processing, using the layer, negative input data in a second forward pass; and updating the one or more weights to adjust, in a second direction, the goodness metric of the layer for the second forward pass.","['G06N3/084', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N20/10', 'G06N3/048', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N5/01', 'G06N7/01']"
US20240248765A1,Integrated platform graphical user interface customization,"Systems and methods initiate displaying a first GUI of an integrated platform that interconnects transfer source(s) and transfer destination(s), wherein access to the integrated platform is restricted to registered users, and end user data of at least one of the transfer destination(s) are at least partially obtained from user responses to system prompts displayed via the first GUI and from user activities of user(s) of the transfer destination(s). End user data is applied to a deployed AI model to identify resource(s) available for transfer to generate a listing of the resource(s), and a probability score indicating a likelihood the user(s) will be interested is assigned to the resource(s) and sorted to prioritize highest scored resources. Display of a customized second GUI including the listing of the resource(s) is initiated.","['G06F9/5038', 'G06Q30/0241', 'G06F9/541', 'G06Q10/0633', 'G06Q10/067', 'G06Q10/103', 'G06Q30/015', 'G06Q30/018', 'G06Q30/0201', 'G06Q30/06', 'G06Q50/01', 'G06Q50/16']"
CN118154997B,Insulator quality detection method,"The invention discloses an insulator quality detection method, which comprises the following steps: collecting an insulator image for marking defects, and expanding data of the marked image; constructing an improved feature extraction model, a feature dimension reduction model and a classifier, training the improved feature extraction model by using the expanded data, training the feature dimension reduction model by using the output of the trained improved feature extraction model, training the classifier by using the output of the trained feature dimension reduction model, and putting the trained improved feature extraction model, the trained feature dimension reduction model and the trained classifier into insulator quality detection; according to the invention, the modal conversion mechanism is utilized to generate the countermeasure network to generate diversified training data, the ant colony optimization neural network and the odor emission mechanism are adopted, the ant colony optimization neural network algorithm based on the odor emission model is introduced to perform feature extraction, and the improved sparse self-coding neural network is adopted to perform feature dimension reduction, so that the stability and the accuracy in the insulator detection process are improved.","['G06V10/764', 'G06N3/006', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/094', 'G06V10/44', 'G06V10/82']"
CN118314341A,A method for semantic segmentation of mural figures based on deep learning,"A mural character semantic segmentation method based on deep learning is used for researching semantic segmentation technology based on convolutional neural network CNN and Transformer. 1) In view of the lack of high quality semantic segmentation datasets available for the disclosure of mural character images today, a multi-category mural character semantic segmentation private dataset is constructed. 2) Considering that the Transformer model has a certain advantage in terms of processing global context information of an image by virtue of a self-attention mechanism, the classical convolutional neural network CNN has a certain advantage in terms of effectively extracting local features of the image and constructing edge information of local continuity, and is inspired by Conformer, a double-branch feature fusion network model DTFB _Net based on CNN and Transformer is provided. 3) Based on DTFB _Net, an improved network model DTFBR _Net based on uniform focus loss and receptive field attention is provided. The method is used for relieving the problem of unbalanced categories in the constructed multi-category mural character semantic segmentation special data set and further improving the extraction capability of the bottom layer features.","['G06V10/26', 'G06N3/0464', 'G06N3/08', 'G06V10/82', 'G06V20/70', 'G06V40/10']"
CN117252958A,"Method, device, electronic equipment and storage medium for generating image based on text","The embodiment of the application provides a method, a device, electronic equipment and a storage medium for generating an image based on text, and relates to the technical field of artificial intelligent drawing. Extracting an entity mark and entity position information corresponding to the entity mark in the descriptive text in response to receiving the descriptive text, wherein the entity mark is used for describing an entity; searching a target image corresponding to the entity mark in an image library, wherein each image in the image library corresponds to one entity mark and comprises an entity described by the corresponding entity mark; and generating an image corresponding to the descriptive text according to the entity mark, the entity position information corresponding to the entity mark and the target image, so that the function of generating a highly controllable image based on the text end to end is realized, and the efficiency and the accuracy of generating the image based on the text are improved.","['G06T11/60', 'G06F40/289', 'G06F40/30', 'G06N3/0464', 'G06T2207/20081']"
WO2023086902A1,Machine-learning based design of engineered guide systems for adenosine deaminase acting on rna editing,"Systems and methods for predicting deamination efficiency or specificity associated with a guide RNA (gRNA) are provided. A nucleic acid sequence for the gRNA is received. Responsive to inputting a data structure into a model, a metric for an efficiency or specificity of deamination by a first Adenosine Deaminase Acting on RNA (ADAR) protein of a target nucleotide position in mRNA transcribed from a target gene is obtained as output from the model. The data structure includes an encoding of the nucleic acid sequence for the gRNA.","['G16B30/00', 'G16B35/10', 'G16B35/20']"
US20240281504A1,Decentralized platform for artificial intelligence data provenance and commodification,"Systems and methods for managing rights for creative work are provided. One aspect of the systems and methods includes receiving, at a rights contract on a distributed virtual machine operated based on a public blockchain, input data including an ownership token identifier for an ownership token, where the ownership token indicates ownership of a creative work. Another aspect of the systems and methods includes obtaining, at the rights contract, an indication of usage rights for the creative work corresponding to the ownership token. Yet another aspect of the systems and methods includes minting, via the rights contract, a rights token corresponding to the ownership token, where the rights token includes a reference to the indication of the usage rights for the creative work.","['G06F21/105', 'H04L9/3213', 'H04L9/3239', 'H04L9/3247', 'H04L9/50', 'H04L2209/603']"
CN117726721B,"Image generation method, device and medium based on theme drive and multi-mode fusion","The application relates to an image generation method, device and medium based on theme drive and multi-mode fusion. The method comprises the following steps: constructing an image generation model; the image generation model comprises a multi-mode alignment module, a text coding module, a condition coding module and an image generation module; training a multi-mode alignment module according to a pre-designed loss function, coding a theme image and a theme category by using the trained multi-mode alignment module, fusing a prompt text and a multi-mode theme semantic vector by using a text coding module, extracting the theme image according to a general facial characterization neural network, performing feature conversion on the obtained visual image by using a condition coding module, and reversely removing dryness on the input semantic feature vector and the mixed multi-mode feature vector by using an image generating module to generate an image corresponding to the prompt text. The method can improve the image generation efficiency of theme drive.",[]
CN118627582A,"Method, system and medium for model training","Embodiments of the present disclosure relate to methods, systems, and media for model training, to unsupervised learning with fused data and attention masking. According to an example embodiment of the present disclosure, a plurality of sample images are generated by providing a plurality of text prompt words into a trained generative model, respectively. For a sample image of the plurality of sample images, at least one attention map is obtained from the generative model, the at least one attention map being determined by the generative model used to generate the sample image, the attention map indicating visual elements of the object within the sample image. Training of a target model is performed according to unsupervised learning based at least on the plurality of sample images and the attention-seeking map of the plurality of sample images, the target model being configured to perform an image processing task.","['G06N3/088', 'G06T11/00', 'G06F40/186', 'G06N3/0455', 'G06V10/82']"
US20240202846A1,"Real estate listing, matching, and transactions with multi-level verification using blockchain","Embodiments include systems and methods for listing, matching, and transacting properties on a blockchain network with different levels of verification. Embodiments are configured to obtain, by a smart contract operating on a blockchain-based distributed computer network, public information for a real estate property and private information for the real estate property. In response to a public request for information, embodiments then provide, by the smart contract, the public information via a public access layer of the blockchain-based distributed computer network. In response to a private request for information, embodiments provide, by the smart contract, the private information via a privileged access layer of the blockchain-based distributed computer network.",['G06Q50/16']
US20240289861A1,Generating queries for users of an online system using large language machine-learned models and presenting the queries on a user interface,"Responsive to an input query from a user, an online system presents a list of recommended items that are related to the input query. The input query may be formulated as a natural language query. The online system performs an inference task in conjunction with the model serving system to generate one or more additional queries that are related to the input query and/or are otherwise related to the recommended items presented in response to the input query. The additional queries may be presented to the user in conjunction with the list of recommended items.","['G06Q30/0635', 'G06Q30/0627', 'G06Q30/0631', 'G06Q30/0643']"
CN117422851A,Virtual clothes changing method and device and electronic equipment,"The embodiment of the application provides a virtual clothes changing method, a device and electronic equipment thereof, wherein the method comprises the following steps: acquiring first characteristic data of a human body image of a target object, and acquiring second characteristic data of a selected clothes image; feature fusion is carried out on the human body image and the clothes image based on the first feature data and the second feature data, and a target segmentation feature and a target clothes light flow graph are obtained; generating a deformation image of the clothing image according to the target clothing light flow graph and the target segmentation feature, and acquiring a mask segmentation image of the clothing image according to the deformation image; and obtaining an initial clothing changing image according to the deformation image and the mask segmentation image, and performing image restoration on the clothing changing image based on a diffusion model to obtain a target clothing changing image after the clothing changing operation is performed on the target object. According to the method and the device, the missing part of the human body in the figure image, which is fused with the clothes during virtual dressing, can be repaired.","['G06T19/20', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T5/50', 'G06T7/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2219/2024']"
WO2024226842A1,Method for synthesizing an audio waveform from a text description,"An aspect of the present disclosure relates to a method for synthesizing an audio waveform from a text description indicating a desired sound, the method comprising: determining a text embedding from the text description; determining an image embedding from the text embedding; synthesizing a spectrogram by inputting the image embedding to a generative model trained to synthesize a spectrogram given an input image embedding; and converting the synthesized spectrogram to the audio waveform.","['G10L25/30', 'G06N3/045', 'G06N3/047', 'G10L13/047', 'G10L13/08']"
JP2024163064A,Visual Citations for Refining Information Provided in Response to Multimodal Queries,"To present, to users, information retrieved in response to multimodal queries.SOLUTION: Result images are retrieved based on a similarity to a query image. A set of textual inputs is processed with a machine-learned language model to obtain a language output comprising textual content. The set of textual inputs comprises textual content from source documents that include the result images, and a prompt associated with the query image. The language output and the result images are provided to a user computing device. Information is received descriptive of an indication by a user that a first result image is visually dissimilar to the query image. Textual content associated with the source document that includes the first result image from the set of textual inputs is removed. The set of textual inputs is processed with the machine-learned language model to obtain a refined language output. The refined language output is provided to the user computing device.SELECTED DRAWING: Figure 2","['G06F16/53', 'G06V10/761', 'G06F16/538', 'G06F16/583', 'G06F16/5846', 'G06F16/5866', 'G06F18/22', 'G06N20/00']"
CN116168108A,"Method and device for generating image from text, storage medium and electronic device","The present disclosure relates to the field of image data processing or generating technologies, and in particular, to a method and apparatus for generating an image by using text, a computer readable storage medium, and an electronic device, where the method includes: coding natural language text describing the image to obtain text coding data; fusing the text coding data with first Gaussian noise of a first preset time step to obtain intermediate text data; sequentially processing the intermediate text data corresponding to the time step by using the coded image generation models with different time steps to obtain image coded data; decoding the image coding data to obtain a target image; wherein the set of time steps of the plurality of encoded image generation models completely covers the first preset time step. The technical scheme of the embodiment of the disclosure improves the precision of the image generated by the text and the matching degree with the text semantic information.","['G06T11/00', 'G06F40/126', 'G06T3/4053']"
CN117951200A,"Space-time sequence data complement method, equipment and medium","The embodiment of the disclosure provides a space time sequence data complement method, equipment and medium, which belong to the technical field of data processing and specifically comprise the following steps: step 1, inputting original space-time data into a convolution model with global attention to obtain element pairs corresponding to the original space-time data, and changing receptive fields of the original space-time data; and step 2, obtaining a convolution kernel of a convolution model according to the element pair product and softmax activation function, and convolving the original space-time data of the changed receptive field to complete data. According to the scheme, the convolution model with global attention is used, convolution kernels and data processed through receptive fields are generated at the same time, time long-term dependence and short-term dependence are modeled efficiently and synchronously, and data complement efficiency and adaptability are improved.","['G06F16/2474', 'G06F16/215', 'G06F16/2465', 'G06F17/16', 'G06N3/0464', 'G06N3/084']"
WO2025066457A1,Image generation processing method and electronic device,"Embodiments of the present application disclose an image generation processing method and an electronic device. The method comprises: determining an image to be processed, and separating a target main body image from the image to be processed; generating for the target main body image a design base image having a transparent background, and performing backup processing; using an artificial intelligence (AI) large language model to provide a background image complementing the transparent background part in the design base image, so as to obtain an AI-generated image, wherein in the AI-generated image, the area of the background image is greater than the area of the transparent background in the design base image; covering the AI-generated image with the backed-up design base image and performing image fusion processing to generate a target image, the target image comprising a complete target main body image, and shielding the edge of the boundary in the background image between the background image and the target main body image. According to the embodiments of the present application, high-quality images can be produced more efficiently and at lower costs.","['G06T7/194', 'G06Q30/0643', 'G06T5/50']"
US20240420437A1,"Systems and methods for defurnishing and furnishing spaces, and removing objects from spaces","An example system may access data of a multidimensional space representing a physical environment and identify interior elements within the multidimensional space using a first machine learning model. The interior element may represent furniture in the physical environment. The system may mask one or more of the interior elements with masks and fill each of the masks with imagery of the physical environment to create an appearance of a defurnished space, the defurnished space having the one or more interior elements appearing as missing from the multidimensional space representing the physical environment. The system may provide all or some of the defurnished space for display.","['G06V10/82', 'G06T17/20', 'G06T19/20', 'G06V20/70', 'G06T2200/24', 'G06T2210/04', 'G06T2219/004', 'G06T2219/2024']"
US12026843B2,Systems and methods for using machine learning models to effect virtual try-on and styling on actual users,"Disclosed are example embodiments of systems and methods for virtual try-on of articles of clothing. An example method of virtual try-on of articles of clothing includes selecting a garment from a pre-existing database. The method also includes loading a photo of a source model wearing the selected garment. Additionally, the method includes generating a semantic segmentation of the model image. The method also includes extracting the selected garment from the photo of the model. Additionally, the method includes determining a correspondence between a target model and the source model by performing a feature point detection and description of the target model and the source model, and performing feature matching and correspondence validation. The method also includes performing garment warping and alignment of the extracted garment. Additionally, the method includes overlaying and rendering the garment.","['G06T11/60', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/096', 'G06T19/006', 'G06T3/18', 'G06T5/77', 'G06T7/12', 'G06V10/44', 'G06V10/54', 'G06V10/56', 'G06V10/60']"
US20240169662A1,Latent Pose Queries for Machine-Learned Image View Synthesis,"An example method includes obtaining, by a computing system, one or more source images of a scene; obtaining, by the computing system, a query associated with a target view of the scene, wherein at least a portion of the query is parameterized in a latent pose space; and generating, by the computing system and using a machine-learned image view synthesis model, an output image of the scene associated with the target view.","['B25J9/1697', 'G06T15/205', 'G06T7/73', 'G06T2207/20081', 'G06T2207/20084']"
CN118247391B,"Animation generation method, device, computer equipment and computer readable storage medium","The present application relates to an animation generation method, an animation generation device, a computer-readable storage medium, and a computer program product. The method comprises the following steps: acquiring a gesture sequence representing gesture change and a reference image aiming at the gesture sequence and used for representing the character image; for at least a part of gesture information in the gesture sequence, carrying out attenuation processing on the reference image according to image attenuation information matched with the gesture information, and updating the reference image corresponding to the gesture information; generating respective images corresponding to each posture information based on respective reference images of each posture information to generate guide information; and generating an animation based on the change of the expression posture of the character image under the guidance of the image generation guide information. By adopting the method, the high-quality animation for restoring the character image and the gesture change can be generated only by inputting the gesture sequence and the reference image, thereby being beneficial to improving the working efficiency of the animation generation process.","['G06T13/00', 'G06N3/0464', 'G06N3/08']"
US20250225773A1,Common sense reasoning for deepfake detection,"An exemplary method for detecting deepfake images and providing customized analysis comprises: receiving, from a user, a textual user inquiry regarding an image; inputting the textual inquiry and the image into a deepfake detection model, wherein the deepfake detection model comprises: an image encoder for generating a plurality of image embeddings based on the image; a text encoder for generating a plurality of textual embeddings based on the textual inquiry; one or more layers for generating a plurality of answer embeddings; and a language model for generating a textual analysis based on the plurality of answer embeddings; and outputting the textual analysis, wherein the textual analysis includes a classification result of whether the image is fake and further includes one or more visual features in the image and one or more attributes of the one or more visual features that contribute to the classification result.","['G06V10/7715', 'G06V10/82', 'G06V40/168']"
US20240347142A1,Method and electronic device for ligand generation,"Embodiments of the present disclosure relate to a method and an electronic device for ligand generation. The method comprises: obtaining a trained ligand generation model, wherein the trained ligand generation model is generated based on decomposition of a ligand by modeling of atom positions, atom types, and chemical bonds; and obtaining, based on a target protein, a target ligand molecule corresponding to the target protein by using the trained ligand generation model. According to the method, the ligand generation model in the embodiments of the present disclosure considers the decomposition of the ligand and also models the chemical bonds, so that it can generate the target ligand molecule with higher affinity.","['G16B15/30', 'G16C20/50', 'G06N3/042', 'G06N3/045', 'G06N3/084', 'G16B40/00', 'G16C20/30', 'G16C20/70']"
CN118474476A,"AIGC-based travel scene video generation method, system, equipment and storage medium","The invention provides a method, a system, equipment and a storage medium for generating a video of a travel scene based on AIGC, wherein the method comprises the following steps: collecting relevant texts on the network based on the names of the travel scenes, and extracting at least tag combinations from the texts, wherein the tag combinations comprise at least two kinds of tag subgroups; generating a video script sequence based on label combination through a text generation model; matching corresponding images through an image search model according to each video sub-script language, and establishing a mapping relation between the video sub-script language and the matched images; generating a sub-video by adopting a AIGC video generation method based on the image; and sequentially arranging the sub-videos based on the corresponding video sub-script language, adding the subtitle file and the audio file converted by voice to generate the travel scene video. The invention can combine various technologies of AIGC and the traditional video processing method, and connect the modules generated by each content in series through the matching technology, thus forming a complete automatic video production flow.","['H04N21/816', 'H04N21/8106', 'H04N21/8133', 'H04N21/8153']"
CN118555461B,"Video generation method, device, equipment, system and computer program product","The embodiment of the invention provides a video generation method, a device, equipment, a system and a computer program product. The method comprises the following steps: acquiring an image to be processed, wherein the image to be processed comprises an image foreground and an image background, and the image background comprises preset image elements capable of generating dynamic effects; determining foreground information of an image foreground and static prompt information of an image to be processed; inputting the static prompt information and the image to be processed into a multi-modal large language model for expansion operation to obtain dynamic prompt information, wherein the multi-modal large language model is obtained by training based on multi-modal samples; and generating a target video corresponding to the image to be processed based on the image to be processed, the foreground information and the dynamic effect prompt information. In the embodiment, the target video can be quickly and automatically generated based on the image, so that the cost and the technical threshold of video production operation are reduced, and the fluency and the rationality of the dynamic effect in the video are ensured as the target video is generated by combining the dynamic effect prompt information.","['H04N21/8153', 'H04N21/4662', 'H04N21/8126']"
US20250014148A1,Method and system for generating composite image,"The present disclosure relates to a method for generating a composite image, executed by one or more processors. The method for generating a composite image includes receiving a foreground image, receiving a background image, generating information on a position and size within the background image from the foreground image and the background image using a first artificial neural network, and generating a composite image based on the foreground image, the background image, and the information on the position and size within the background image.","['G06T11/00', 'G06T5/50', 'G06N3/08', 'G06V10/25', 'G06V10/44', 'G06V10/60', 'G06T2207/20084', 'G06T2207/20221', 'G06V2201/07']"
CN117876522A,Detail controllable personalized image generation method and system based on decoupling self-enhancement,"The invention provides a detail controllable personalized image generation method and system based on decoupling self-enhancement, comprising the following steps: acquiring a reference conceptual image and a text instruction, constructing attribute description of the text instruction, generating a plurality of initial images based on conceptual features and attribute description of the conceptual image, screening, and taking each screened initial image and the attribute description corresponding to each screened initial image as a training sample; adding noise to an initial image in a training sample to obtain a noise image, sending the noise image and the attribute description corresponding to the noise image into a diffusion network comprising a text encoder, predicting the noise added in the noise image by the diffusion network according to the attribute description, and constructing a loss function training diffusion network according to a prediction result and the truly added noise to obtain an image generation model; inputting the image generation text instruction with the target attribute and the noise image into an image generation model, denoising the noise image by the image generation model according to the image generation text instruction, and obtaining an image generation result corresponding to the image generation text instruction.","['G06T11/00', 'G06F40/205', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
US20250021820A1,Attribution of generative model outputs,"The present invention sets forth a technique for analyzing a generative output of a generative model. The technique includes determining a first latent representation of the generative output and a plurality of latent representations of a plurality of data samples associated with the generative model. The technique also includes computing a plurality of similarities between the first latent representation and the plurality of latent representations. In response to determining that a first similarity that is included in the plurality of similarities and computed between the first latent representation and a second latent representation included in the plurality of latent representations exceeds a threshold, the technique includes causing output to be generated that indicates a high similarity between the generative output and a first data sample that is included in the plurality of data samples and corresponds to the second latent representation.","['G06N3/0895', 'G06F16/55', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06Q10/04', 'G06Q10/10', 'G06Q30/0276', 'G06Q50/184', 'G06N3/047', 'G06N3/096']"
CA3070505A1,Formulations of a compound modulating kinases,"Provided herein are compositions composition comprising 40% to about 60% WAV of a crystalline HC1 salt of Compound I, wherein the crystalline HC1 salt of Compound I has an X-ray powder diffractogram comprising peaks (Â±0.2Â°) at 7.3, 23.3 and 28.2 ""20 as determined on a diffractometer using Cu-Ka radiation; 20% to 35% W/W of poloxamer 407; 10% to 22% WAV of mannitol; 1% to 5% W/W of crospovidone; and 0.5% to 3% W/W of magnesium stearate. Methods of making and using same are also disclosed. The described compositions are useful for treating diseases and conditions modulated by CSF1R, c-Kit and/or FLT3, and have improved dissolution profiles.","['C07D471/04', 'A61K31/444', 'A61K45/06', 'A61K47/10', 'A61K47/12', 'A61K47/22', 'A61K47/26', 'A61K9/4825', 'A61K9/4858', 'A61K9/4866', 'A61P19/10', 'A61P25/00', 'A61P25/08', 'A61P25/18', 'A61P25/28', 'A61P27/00', 'A61P27/02', 'A61P27/06', 'A61P29/00', 'A61P31/18', 'A61P35/00', 'A61P35/02', 'A61P35/04', 'A61P43/00', 'A61P9/00', 'A61K2300/00', 'C07B2200/13']"
CN107145702A,Cardiogenic embolism stroke risk prediction system and method based on medical images,"There is provided cardiogenic embolic type of stroke Risk Forecast System and method based on medical image.Disclose the system and method for the specific ishemic stroke risk profile of patient based on medical image.Atrium sinistrum is extracted from the medical image data of patientï¼LAï¼And left auricle of heartï¼LAAï¼Measurement result.Based on LA the and LAA measurement results of the medical image data extraction from patient, the export measurement for the LA and LAA of patient is calculated using the specific heart function computation model of patient.The export calculated based on LA the and LAA measurement results extracted and for the LA and LAA of patient is measured, the stroke risk score value for patient is calculated using the housebroken grader based on machine learning, it inputs the export that the LA and LAA measurement results that extract and LA and LAA for patient calculate and measured as feature.","['G16H10/60', 'A61B5/00', 'A61B90/00', 'G06F17/11', 'G06N3/0464', 'G06N3/09', 'G06T11/008', 'G06T7/0012', 'G06T7/12', 'G06T7/149', 'G16H30/20', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G06N3/08', 'G06N7/01', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10136', 'G06T2207/20081', 'G06T2207/30048', 'G06T2211/441']"
CN118037896A,"Method and device for generating image based on text, electronic device and storage medium","The embodiment of the disclosure discloses a method and a device for generating an image based on text, an electronic device and a storage medium, wherein the method comprises the following steps: acquiring initial information of an image to be generated, wherein the initial information comprises image category information; inputting initial information into a pre-trained text generation model to obtain at least one text description information, wherein the text description information comprises image category information and image effect information; determining target text information based on the at least one text description information; and inputting the target text information into a pre-trained image generation model to obtain at least one target image.","['G06T11/60', 'G06N5/04', 'G06V10/806', 'G06V20/70', 'Y02T10/40']"
CN120239861A,Fractional Interpolation Diffusion Model,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output sequence of discrete tokens using a diffusion model. In one aspect, a method includes initializing an output sequence by assigning a respective embedding to each of a plurality of output locations, repeatedly performing, at each of a plurality of back-diffusion steps, a current continuous representation of the output sequence, processing a diffusion model input including the current continuous representation using the diffusion model to generate a diffusion model output, processing the respective initial score using a softmax function to generate a plurality of embedded probability distributions in an embedded vocabulary for each of the plurality of output locations, and updating the continuous representation of the output sequence using the probability distributions and the embedded vocabulary.","['G06N3/0475', 'G06N3/0455', 'G06N3/047', 'G06N3/048', 'G06N3/084']"
CN119741183B,Digital image watermarking method and device based on diffusion model and spread spectrum technology,"The invention provides a digital image watermarking method and device based on a diffusion model and a spread spectrum technology, and relates to the technical field of image processing and artificial intelligence. The method comprises the steps of obtaining carrier images and watermark information, carrying out downsampling and forward diffusion on the carrier images by using a variation self-encoder to obtain first potential vectors, carrying out channel dimension division on the first potential vectors, selecting one-dimensional channels of the first potential vectors, carrying out frequency domain transformation by using a discrete cosine transformation technology, extracting high-frequency coefficients to obtain an embedding matrix, carrying out spread spectrum modulation on the watermark information by using orthogonal codes to obtain spread spectrum watermarks, embedding the spread spectrum watermarks into the embedding matrix by using a bonding strength factor to obtain watermark potential vectors, carrying out inverse denoising on the watermark potential vectors by using a denoising network, restoring the watermark potential vectors into a watermark image by using the variation self-encoder, and combining the watermark image to obtain a final watermark image. The invention greatly enhances the imperceptibility and the robustness of the watermark and can also effectively resist the regeneration type attack.",[]
CN117218217A,"Training method, device, equipment and storage medium of image generation model","The application discloses a training method, device and equipment for an image generation model and a storage medium, and relates to the technical field of artificial intelligence. Comprising the following steps: acquiring first sample image characteristics corresponding to a first sample image and first text sample characteristics corresponding to a first sample description text; carrying out noise adding processing on the first sample image characteristics to obtain first sample noise image characteristics; inputting the first sample noise image characteristic and the first sample characteristic into a denoising network to obtain prediction noise; training a denoising network based on the predicted noise and the actual noise added in the noise adding process; and under the condition that the training of the denoising network is completed, constructing an image generation model based on the denoising network, a text decoder and an image encoder, wherein the image generation model is used for generating an image conforming to the image description text, the text encoder is used for vector encoding of the text, and the image encoder is used for image reconstruction based on image characteristics.",[]
US20240378654A1,Machine-learned large language model for sentiment analysis for curating replacements for an online system,"An online system determines whether to recommend a replacement item to a user based on a predicted sentiment score. The online system receives one or more comments from user feedback on the replacement items. The online system generates a prompt for each user comment for input to a machine-learned model. The online system generates a sentiment score for the ordered item and a replacement item based on the inferred sentiments by the model serving system. Using the sentiment score, the online system determines whether to recommend the replacement item.","['G06Q30/0631', 'G06Q30/0282', 'G06Q30/0629']"
US20250086213A1,Machine learned language model based natural language interface for querying databases,"A system, such as an online system, allows users to ask natural language questions requesting information stored in a database. The system receives a natural language question. The system determines database tables and database queries associated with the natural language question. The system generates a prompt for input to a machine learned language model. The prompt specifies the natural language question, information describing database tables, and the example database queries. The system sends the prompt to the machine learned language model for execution and receives a response generated by the machine learned language model. The response includes a database query corresponding to the natural language question. The system sends the database query for execution on a database system and provides the result of execution of the database query to the client device.","['G06F16/3344', 'G06F16/243', 'G06F16/24522', 'G06F16/31', 'G06F16/3329', 'G06F16/90332']"
CN118196231A,A lifelong learning method based on concept segmentation,"The invention discloses a lifelong learning text-to-image method based on concept segmentation, and belongs to the field of computer vision. Firstly, constructing text description containing categories corresponding to pictures, inputting category information and images into SAM, so as to extract target concepts from training images, inputting segmented images into a variable automatic encoder for dimension reduction, then, denoising the dimension-reduced images through a forward process to obtain noise images consistent with the dimensions of the images, taking the noise images as the input of U-Net and using the text description corresponding to the images as the text representation of the concepts, and finally, enabling a network to predict real Gaussian noise added in the forward process and finally, subtracting the noise from the denoised images to restore original images; the invention fully plays the advantages of concept segmentation, effectively learns a plurality of different concepts, has good stability and generalization, and provides a more accurate and objective method for evaluating the literature graph model.","['G06T11/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
US20150224345A1,Acoustic shock wave therapeutic methods,"A method of treating a patient having a nerve injury or spinal cord injury or spinal cord lesions, or disease or any pathology that has compromised an autonomic nervous system of a patient to stimulate regeneration or reactivation of the autonomic nervous system comprises the steps of: treating the patient with injured or damaged nerves; activating an acoustic shock wave generator or source to emit acoustic shock waves from a shock wave head; and administering an effective exposure of acoustic shock waves in a pulse or wave pattern having a low energy density less than 1.0 mJ/mm2 per shock wave directly onto a treatment zone in a region extending from the medulla oblongata in the lower brain stem to the lower end of the spinal cord.","['A61N7/00', 'A61B17/225', 'A61N2007/0004', 'A61N2007/0021']"
US20240378656A1,Streamlined image to message and action replacement workflow with multi-modality machine-learned large language model,"A computer system receives an image from a picker, which indicates an out-of-stock target item and potential replacements items. The system provides, to a machine learning model, a prompt requesting identification of the target item and the potential replacement items in the image. The system receives identification of the target item and a list of potential replacement items in the image. The system generates a first list of potential replacements items based on the list of potential replacement items identified in the image and a second list of replacement items from the target item by applying one or more replacement models to the identified target item. The system may merge the two lists and assign replacement scores to each item in the merged list to create a list of recommended replacement items. The system generates a message based on the image and the list of recommended replacement items.","['G06Q30/0631', 'G06Q30/0633', 'G06Q30/0639', 'G06V10/774']"
US20240169636A1,Physics-guided motion diffusion model,"Systems and methods are disclosed that improve performance of synthesized motion generated by a diffusion neural network model. A physics-guided motion diffusion model incorporates physical constraints into the diffusion process to model the complex dynamics induced by forces and contact. Specifically, a physics-based motion projection module uses motion imitation in a physics simulator to project the denoised motion of a diffusion step to a physically plausible motion. The projected motion is further used in the next diffusion iteration to guide the denoising diffusion process. The use of physical constraints in the physics-guided motion diffusion model iteratively pulls the motion toward a physically-plausible space, reducing artifacts such as floating, foot sliding, and ground penetration.","['G06T13/40', 'G06T13/80', 'G06T5/002', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN116484868A,Cross-domain named entity recognition method and device based on diffusion model generation,"The method and the device for identifying the cross-domain named entity based on the generated diffusion model are provided, and feature extraction is carried out on source data through a first generated diffusion model to obtain an original generation set, wherein the source data are text data with completed labeling; fine tuning the first generated diffusion model according to the original generation set and a preset excitation model to obtain a first target generated diffusion model; extracting characteristics of target data through a second generation diffusion model and the first target generation diffusion model to obtain a target generation set, wherein the second generation diffusion model and the first target generation diffusion model have the same network framework, and the target data and the source data belong to different fields; and inputting the target generation set into a pre-trained named entity recognition model to obtain an entity naming result aiming at the target data, and realizing named entity recognition among different domains quickly and efficiently.","['G06F40/295', 'G06N3/0442', 'G06N3/08']"
CN118567232A,A large model driven robot operation task execution method and system,"The invention provides a large model driven robot operation task execution method and system, which relate to the technical field of intelligent robot control, and specifically comprise the following steps: acquiring an object image to be operated and a language instruction to be executed; inputting an object image and a language instruction into a trained instruction-guided operation availability prediction network, generating an operation availability map, and further determining an operation area of the object, wherein the operation availability map is formed by distributing an availability value for each pixel point of the object image; based on the language instruction and the operation area, generating executable actions to guide the intelligent robot to complete the operation task; the invention provides an instruction guided operation availability prediction network, which predicts an availability map of an instruction guided robot operation task by using a strong priori trained on a data set after data enhancement, so as to obtain executable actions.","['G05B13/042', 'G06F18/253', 'G06N3/0464', 'G06N5/041']"
CN116958325A,"Training method and device for image processing model, electronic equipment and storage medium","The application provides a training method, a training device, electronic equipment, a computer program product and a computer readable storage medium of an image processing model; the method comprises the following steps: acquiring a sample set of the target image field corresponding to the training task; based on each sample original image and a sample editing text corresponding to each sample original image, calling an image processing model to carry out image editing processing to obtain an edited image of each sample original image, wherein the edited image is obtained by editing according to an editing instruction corresponding to the sample editing text; determining a quality parameter of each edited image; selecting a plurality of edited images according to the quality parameters to serve as sample edited images; the image processing model is trained based on each sample edited image, the sample original image corresponding to each sample edited image, and the sample edited text. The method and the device can improve the accuracy of image generation processing in the field of target images.","['G06T11/60', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/084', 'G06T7/0002', 'G06V10/40', 'G06V10/765', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
CN116758882A,Tone color generation method and system,"The application discloses a tone color generation method, which comprises the following steps: acquiring required tone fine granularity characteristics, pitch characteristics and musical instrument type characteristics; performing feature fusion on the tone fine granularity feature, the pitch feature and the musical instrument type feature; inputting the fused characteristic data into a trained generation model for denoising diffusion to obtain a Mel spectrogram of the target tone; and processing the Mel spectrogram through a vocoder to generate the audio of the target tone. The application also discloses a tone generating system, an electronic device and a computer readable storage medium. Therefore, tone color generation can be performed by utilizing the inductive capacity of the neural network and the generation capacity of the generation model, and the tone colors to be generated are subjected to fine-grained control by fusing the characteristics of three different scales of musical instrument types, pitches and fine-grained tone color descriptive information.","['G10H1/06', 'G10H1/0025', 'G10H2210/195']"
CN117593595B,Sample augmentation method and device based on artificial intelligence and electronic equipment,"The application provides a sample augmentation method, a device, electronic equipment, a computer readable storage medium and a computer program product based on artificial intelligence, which can be applied to various scenes such as cloud technology, artificial intelligence, intelligent traffic, auxiliary driving and the like; the method comprises the following steps: acquiring a first data sample; the first data sample comprises a first sample image and a corresponding image tag; performing image description generation processing on the first sample image to obtain image description of the first sample image; splicing the image tag of the first sample image with the image description to obtain a spliced text; performing image generation processing according to the spliced text to obtain a second sample image; and constructing a second data sample according to the second sample image and the image label of the first sample image. According to the application, the diversity of the data samples can be improved, so that the robustness of the machine learning model is better enhanced.","['G06V10/764', 'G06V10/30', 'G06V10/44', 'G06V10/82']"
EP4432130A1,Text to image generation using k-nearest-neighbor diffusion,"A method and system for text-to-image generation using a KNN-diffusion model. The method includes receiving a text input, and determining K nearest image embeddings to text embeddings of the text input from a dataset in an embedding space, the embedding space being, for example, a CLIP embedding space. The method also includes concatenating the text embedding and the K nearest image embeddings. The method also includes mapping the concatenated embeddings into a feature space and generating an image associated with the input text based on the feature space. The feature space being, for example, a joint multi-modal text-image space.","['G06F16/906', 'G06T11/60', 'G06F16/583', 'G06F16/5846', 'G06F16/9032', 'G06F16/90335', 'G06N5/041']"
US20250004558A1,"Systems and methods that involve bci (brain computer interface), extended reality and/or eye-tracking devices, detect mind/brain activity, generate and/or process saliency maps, eye-tracking information and/or various control(s) or instructions, implement mind-based selection of ui elements and/or perform other features and functionality","Systems and methods associated with mind/brain-computer interfaces are disclosed. Certain implementations may include or involve processes of collecting and processing brain activity data, such as those associated with the use of a brain-computer interface that enables, for example, decoding and/or encoding a user's brain functioning, neural activities, and/or activity patterns associated with thoughts, including sensory-based thoughts. Consistent with various aspects of the disclosed technology, systems and methods herein include functionality whereby a user can hands-free select or click UI elements in a mixed reality environment or on a 2D computer, phone or other such screen. In some embodiments, the disclosed technology may involve a brain-interface that can decode where the user is looking (i.e., determine their visual attention) and also decode their intention to select or âclickâ the UI element desired. The user's intention to select or âclickâ the UI element (the 2nd step) can be achieved through an imagined movement or an imagined word.","['G06F3/011', 'G06F3/013', 'G06F3/015', 'G06F3/0482', 'G06F3/04842', 'A61B5/0066', 'A61B5/14553', 'A61B5/372', 'A61B5/378', 'G06F2203/011']"
CN118278290B,Mould temperature missing value filling method for casting integrated aluminum alloy structural part,"The invention discloses a filling method of a die Wen Queshi value for casting an integrated aluminum alloy structural part, which comprises the following steps: and identifying castings with die temperature deficiency and/or die temperature acquisition abnormality, inputting corresponding process data into a die Wen Queshi value filling model, and finishing die temperature deficiency value filling. The training process of the model is as follows: obtaining casting data with complete mold temperature, and adding noise at the missing part of a mold Wen Jiading to obtain noise-added data; the method comprises the steps of dividing noisy data with different lengths into a plurality of first sub-tensors, calculating the attention of a time sequence relation, and combining to obtain an intermediate tensor; dividing the intermediate tensor into a plurality of second tensors, calculating the characteristic attention, and combining to obtain a noise predicted value of the casting data at the assumed missing position; the time sequence length of the noise predicted value is the same as that of the casting data; training is carried out by taking the mean square error between the noise predicted value and the actually added noise as a loss function.","['G06F30/27', 'G06N3/045', 'G06N3/0464', 'G06F2119/08', 'G06F2119/10', 'Y02P90/30']"
CN118365744A,Single sample font generation method based on multi-scale style fusion and font control,"The invention discloses a single sample font generation method based on multi-scale style fusion and font control. The method comprises the following steps: 1. inputting style images and content images of characters; 2. extracting features of the input style image by using a style encoder, and collecting the output of each layer of the encoder network to obtain multi-scale style features; 3. connecting the content image and the noise image on the channel and then taking the connected content image and noise image as the input of a noise prediction model; 4. the extracted multi-scale style features are fused into a noise prediction model by using a cross attention mechanism; 5. training a style encoder and a noise prediction model according to the loss function; 6. and sampling the trained model to generate a font image of the target style and the target content. According to the invention, the diffusion model is used for a single sample font generation task, and the character structure accuracy is improved through the control of the content image on the fonts. And the multi-scale style is integrated into the diffusion model, so that more comprehensive reservation of style image information is realized.","['G06T11/203', 'G06N3/0455', 'G06N3/08', 'G06T5/60', 'G06T5/70', 'G06V10/82', 'G06V30/18', 'G06V30/1918', 'Y02T10/40']"
US20240303711A1,Conversational and interactive search using machine learning based language models,"A system, for example, an online system uses a machine learning based language model, for example, a large language model (LLM) to process high-level natural language queries received from users. The system receives a natural language query from a user of a client device. The system determines contextual information associated with the query. Based on this information, the system generates a prompt for the machine learning based language model. The system receives a response from the machine learning based language model. The system uses the response to generate a search query for a database. The system obtains results returned by the database in response to the search query and provides them to the user. The system allows users to specify high level natural language queries to obtain relevant search results, thereby improving the overall user experience.","['G06Q30/0627', 'G06Q30/0635', 'G06F16/9532']"
US20240419837A1,Securing Machine Learning (ML) Pipelines Using Data Loss Prevention,"Aspects of the disclosed technology include techniques and mechanisms for securing machine learning (ML) training pipelines and ML pipeline models using data loss prevention (DLP). A DLP ML engine may use different levels of detection to determine whether a command manipulates or disseminates sensitive data. The DLP ML engine may progress through the different levels of detection where each level of detection may engage different methods for determining whether the command is used for generative AI purposes. Based on determining a command is not used for generative AI purposes, the DLP ML engine may allow execution of the command. Alternatively, based on determining the command is used for generative AI purposes, the DLP ML engine may trigger preventive measures.","['G06F21/604', 'G06F21/6245', 'G06F2221/2113', 'G06F2221/2141']"
CN117173497B,"Image generation method and device, electronic equipment and storage medium","The application relates to an image generation method, an image generation device, electronic equipment and a storage medium. The method comprises the following steps: acquiring an original expression image containing a target expression object and an image description text containing expression detail information corresponding to a target expression control dimension; inputting the image description text into a priori feature extraction model to obtain a priori image feature; inputting the prior image characteristics into an expression characteristic generation model to perform expression detail control, and generating target expression characteristics corresponding to the target expression objects; inputting the original expression image and the target expression characteristic into an expression image generation model to generate an expression image, so as to obtain a target generated expression image; the expression feature generation model is obtained after guiding the preset expression feature generation model to perform expression detail control learning based on sample expression detail information and a multidimensional expression control model corresponding to a plurality of preset expression control dimensions. By means of the scheme, the detail control accuracy and the content richness of the expression image can be improved.",['Y02T10/40']
US20240330718A1,Generating knowledge graph databases for online system using large language machine-learned models,"An online system generates a knowledge graph database representing relationships between entities in the online system. The online system generates the knowledge graph database by at least obtaining descriptions for an item. The online system generates one or more prompts to a machine-learned language model, where a prompt includes a request to extract a set of attributes for the item from the description of the item. The online system receives a response generated from executing the machine-learned language model on the prompts. The online system parses the response to extract the set of attributes for the item. For each extracted attribute, the online system generates connections between an item node representing the item and a set of attribute nodes for the extracted set of attributes in the database.","['G06F40/40', 'G06F16/9024', 'G06F40/205', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N5/022']"
US20240289632A1,Aligning large language models with specific objectives using reinforcement learning and human preference,"An online system trains a specific-purpose LLM. The online system obtains training examples and divides training examples across batches. The online system generates a specific response by applying parameters of the specific-purpose LLM to a batch of training examples. The online system generates a general response by applying parameters of a general-purpose LLM to the batch of training examples. The online system computes a human readability score representing the difference between the specific response and the general response. The online system computes an objective compliance score by applying an evaluation model to the specific response, the evaluation model trained to score the first response based on a specific objective. The online system updates the parameters of the specific-purpose LLM based on the human readability score and the objective compliance score.","['H04L51/02', 'G06N3/092']"
US20250036604A1,Automated correction of attributes using machine-learned large language models (llms),"An online system maintains a product catalog including products from various retailers, from which users can purchase products. Each of the products are associated with attributes such as a size value and a size unit of measure (UOM). The online system identifies products with erroneous product attributes using taxonomy attribute value homogeneity. The online system performs an inference task in conjunction with the model serving system or the interface system to infer a correct size value and size UOM of the product. The online system evaluates the accuracy of the inferred size value and size UOM of the product. Responsive to determining that the inferred data is accurate, the online system updates the product catalog with the corrected product attribute information.","['G06F40/205', 'G06F16/215', 'G06F16/2365']"
US20190021880A1,Method And System For Designing A Biomechanical Interface Contacting A Biological Body Segment,"A method and associated system for designing a biomechanical interface of a device contacting a biological body segment of a subject includes forming a quantitative model of the biological body segment from subject specific data, conducting a biophysical analysis, such as a finite element analysis, to thereby establish a relationship, such as a functional relationship, between the quantitative model and at least one feature of the biomechanical interface contacting the biological body segment, and applying the relationship to the at least one feature of the biomechanical interface contacting the biological body segment to thereby obtain an interface design for the mechanical interface of the device. The subject-specific data can include geometry of the biological body segment and the at least one feature can be associated with physiological benefit of the biological body segment.","['A61F2/5046', 'A61F2/60', 'A61F2/78', 'A61F2/80', 'G06F17/5009', 'G06F30/20', 'G06F30/23', 'A61F2002/5049', 'A61F2002/505', 'A61F2002/607']"
US20190311813A1,Realizing private and practical pharmacological collaboration,"Computationally-efficient techniques facilitate secure pharmacological collaboration with respect to private drug target interaction (DTI) data. In one embodiment, a method begins by receiving, via a secret sharing protocol, observed DTI data from individual participating entities. A secure computation then is executed against the secretly-shared data to generate a pooled DTI dataset. For increased computational efficiency, at least a part of the computation is executed over dimensionality-reduced data. The resulting pooled DTI dataset is then used to train a neural network model. The model is then used to provide one or more DTI predictions that are then returned to the participating entities (or other interested parties).","['G06N3/084', 'G16H80/00', 'G06N20/00', 'G06N3/048', 'G16C20/90', 'G16H10/40', 'G16H50/50', 'G16H70/40', 'G06N20/10', 'G06Q50/00', 'G16B15/30', 'G16C20/50', 'G16C20/70']"
CN118658200A,"Image processing method, electronic device, storage medium and computer program product","The application discloses an image processing method, electronic equipment, a storage medium and a computer program product, and relates to the technical fields of large model technology and computer technology. Wherein the method comprises the following steps: the method comprises the steps of obtaining a target object image, a gesture guiding image and a target text, wherein the display content of the target object image at least comprises: the target object image is used for guiding a target scene image to be generated to retain input features associated with the target object, the gesture guiding image is used for guiding a specified gesture to be generated by the target object in the target scene image, and the target text is at least used for describing specified content to be displayed in the target scene image; a target scene image is generated based on the target object image, the gesture guidance image, and the target text. The application solves the technical problems of low generation efficiency and poor generation effect in the personalized generation process of the images in the related technology.","['G06V40/20', 'G06N3/0464', 'G06N3/08', 'G06V10/82']"
CN116523799A,Text-guided image restoration model and method based on multi-granularity image-text semantic learning,"The invention discloses a text-guided image restoration model and a method based on multi-granularity image-text semantic learning, which belong to the field of image processing and comprise a three-stage generator, a mask reconstruction module and a double discriminator which are sequentially arranged; the three-stage generator is used for repairing the damaged image in a global coarse-grain repairing stage, a local fine-grain repairing stage and a global fine-grain repairing stage respectively; the mask code reconstruction module is used for punishing the generation of the target object in the damaged image in the model training stage; and the double discriminator is used for discriminating the repaired image from the global and local angles respectively. According to the text-guided image restoration model and method based on multi-granularity image-text semantic learning, the visual semantic information of objects in a damaged area can be predicted better according to given text and damaged images, more fine-granularity textures are generated, and the quality of image restoration is improved effectively.","['G06T5/77', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06V10/25', 'G06V10/42', 'G06V10/44', 'G06V10/82', 'G06V20/62', 'G06T2207/20081', 'G06T2207/20084', 'Y02D10/00']"
CN118015637A,"Text generation image model training method, text generation image method and device","The embodiment of the disclosure provides a text generation image model training method, a text generation image method, a device, electronic equipment and a storage medium. The method comprises the following steps: acquiring a training sample comprising a plurality of image-text pairs; inputting the training sample into an image-text comparison learning model for training to obtain a first loss function; inputting the training sample into an image-text generation learning model for training to obtain a second loss function; training the text generation image model based on the first loss function and the second loss function to obtain a target text generation image model. According to the method, the image-text comparison learning model is introduced on the basis of the image-text comparison learning model, so that image-text correlation can be learned in training, the requirements of a text-to-image task can be met in advance, and the correlation model can pay attention to the characterization capability of fine-grained information.","['G06V30/19147', 'G06N3/088', 'G06N3/09', 'G06V10/82', 'G06V30/1448', 'G06V30/19093', 'G06V30/19173']"
US20250111139A1,Design document generation from text,"A method, apparatus, non-transitory computer readable medium, and system for generating a design document from a text prompt include obtaining a design prompt that describes a document type and selecting a design template for the document type based on the design prompt. An image generation model generates an image for the design template based on the design prompt and a design document is generated based on the design template. The design document has the document type and includes the image at a location indicated by the design template.","['G06T11/60', 'G06F40/186', 'G06F40/40']"
CN117237606A,"Interest point image generation method, interest point image generation device, electronic equipment and storage medium","The embodiment of the disclosure discloses a method, a device, an electronic device and a storage medium for generating an interest point image, wherein the method comprises the following steps: acquiring image description information of a target interest point, wherein the image description information comprises an image description text; inputting the image description information into a pre-trained static image generation joint model, and executing the pre-trained static image generation joint model to generate a static image of the target interest point, wherein the static image generation joint model comprises a first large-scale language model and a aragonic graph model, the first large-scale language model is used for generating text vectors according to the image description information, and the aragonic graph model is used for generating the static image of the target interest point according to the text vectors. The technical scheme can quickly generate the high-quality interest point image.",[]
CN116980538A,"Video generation method, device, equipment, medium and program product","The embodiment of the application discloses a video generation method, a device, equipment, a medium and a program product, wherein the method comprises the following steps: acquiring an audio text corresponding to the target audio; performing mood segmentation on the audio text to obtain at least one mood segment text, and determining mood audio segments corresponding to the at least one mood segment text in target audio; respectively carrying out imaging processing on the mood scenes described by at least one mood fragment text to generate mood images matched with each mood audio fragment; and carrying out fusion processing on the target audio and at least one mood image to generate a target video. The embodiment of the application can automatically generate the audio type video based on the target audio, and improves the generation efficiency of the audio type video.","['H04N5/262', 'G10L15/26', 'G10L25/30', 'G10L25/51', 'G10L25/57', 'H04N21/439', 'H04N21/44', 'H04N21/440236', 'H04N21/8113', 'H04N5/265']"
WO2017091617A1,Triazole acc inhibitors and uses thereof,"The invention provides triazole compounds of formula (I) inhibiting Acetyl CoA Carboxylase (ACC), compositions and uses thereof for the treatment of obesity or as fungicides.","['C07D495/04', 'A01N43/90', 'A61P3/04', 'A61P31/04', 'A61P31/10', 'A61P33/00', 'A61P43/00', 'C07D487/04', 'C07D491/048', 'C12N9/93', 'C12Y604/01002']"
CN118314038A,A method for image shadow removal based on mask thinning,"The invention discloses an image shadow removing method based on mask refinement, which comprises the following steps: constructing a shadow removing network and designing a combined loss function; constructing a model training set, and training a shadow removing network based on the model training set and a combined loss function to obtain an optimal network; acquiring an initial shadow mask of a shadow image to be processed through a shadow detection network; generating a random noise image, and splicing the random noise image, the shadow image to be processed and the initial shadow mask according to the channel dimension to obtain a spliced image; and presetting iteration times, inputting the spliced images into an optimal network, and removing image shadows. According to the invention, by introducing a learnable weight parameter, the contribution degree of self-attention and spatial attention is dynamically adjusted, the performance of the model in different application scenes is improved, a combined loss function is designed, which comprises a perception loss, lab color space loss and structural similarity loss, the model is guided to train and optimize, and the convergence rate of the model is accelerated.","['G06T5/70', 'G06N3/045', 'G06N3/0464', 'G06T3/4038', 'G06T3/4046', 'G06T5/60', 'G06T2207/20084', 'G06T2207/20221', 'Y02T10/40']"
CN117494722A,"Information processing method, device, equipment and computer readable storage medium","The embodiment of the application discloses an information processing method, an information processing device, information processing equipment and a computer storage medium, wherein the method comprises the steps of acquiring a first sample text of a target pattern of a sample introduction text of a sample product, a sample image of the sample product, description information of the sample image and a second sample text of the target pattern of the sample image; training the initial text generation model based on the first sample text and the sample introduction text to obtain a target text generation model; training the initial image generation model based on the sample image, the description information and the second sample text to obtain a target image generation model; acquiring demand parameters input by a user and processing the demand parameters to obtain first description information and second description information aiming at a target product; processing the first description information by adopting a target text generation model to obtain a target text; processing the second description information by adopting a target image generation model to obtain a target image; and processing the target text and the target image to obtain introduction information of the target product.","['G06F40/30', 'G06F18/214', 'G06F18/241', 'G06F40/289', 'Y02P90/30']"
US12321355B2,Unified search systems and methods,"A genealogy online system may cause to display, at a graphical user interface associated with a genealogy online system, a search box, the genealogy online system configured to provide functions comprising family-tree building and historical record search. The genealogy online system may receive a query from a user entered at the search box. The genealogy online system may use a machine learning language model to determine an intent of the user associated with the query. The genealogy online system may cause to display, at the graphical user interface as a result of the query, one or more links to one or more functions of the genealogy online system based on the intent determined by the machine learning language model.","['G06F16/24575', 'G06F16/243', 'G06F18/2415', 'G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06V10/82']"
EP3368540A1,Acc inhibitors and uses thereof,"The present invention provides compounds I and II useful as inhibitors of Acetyl CoA Carboxylase (ACC), compositions thereof, and methods of using the same.","['C07D495/04', 'A01N43/90', 'A61K31/519', 'A61P3/04', 'A61P3/06', 'A61P31/00', 'A61P35/00', 'C07D487/04', 'C07D491/048']"
CN115641485A,Generative model training method and device,"The embodiment of the specification provides a generative model training method and a device, wherein the generative model training method comprises the following steps: acquiring an original image; performing diffusion processing on the original image, and performing attenuation processing on the image component of the original image to obtain a noise-added image set; determining a noise-added image according to the original image and the noise-added image set, and inputting the noise-added image into an initial generation model for processing to obtain a restored image; and performing parameter adjustment on the initial generation model based on the reduction image and the original image until a target generation model meeting a training stop condition is obtained. In the diffusion and inverse diffusion processing processes, attenuation processing of image components is combined, so that the generated model can learn the image change processes of different dimensions, and the model training precision is effectively improved.",[]
US11755888B1,Method and system for accelerating score-based generative models with preconditioned diffusion sampling,"A method for accelerating score-based generative models (SGM) is provided, including setting a frequency mask (R) and a space mask (A) and a target sampling iteration number (T); sampling an initial sample (x0); conducting iteration comprising steps as follows: sampling a noise term; applying a preconditioned diffusion sampling (PDS) operator (M) to the noise term and thus generate a preconditioned noise term; calculating a drift term; applying the transpose of the PDS operator (MT) and then applying the PDS operator (M) to the drift term, and thus generate a preconditioned drift term; diffusing the sample of each iteration (xt); and outputting the result.","['G06N3/0475', 'G06N3/084', 'G06N3/094']"
CN117077787A,"Text generation method and device, refrigerator and storage medium","The invention provides a text generation method, a text generation device, a refrigerator and a storage medium. According to the invention, the multi-source heterogeneous multi-mode data is obtained by simultaneously taking real-time voice data, real-time text data and real-time audio/video data as training and input data of a network model. Moreover, by constructing a neural network fused with an countermeasure network, a transducer model, a distillation diffusion model and an attention mechanism, semantic feature information of the text can be extracted more abundantly and sufficiently. The whole model structure has excellent deep learning characterization capability, and the generated text has higher accuracy. After the text information is obtained and output through multiple channels, the voice recognition accuracy and the text classification accuracy are remarkably improved, the interaction mode is more convenient and rapid, and the user experience is greatly improved.","['G06N5/041', 'F25D29/003', 'G06F16/3329', 'G06F16/483', 'G06N3/042', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/094', 'G06N3/096', 'G06V10/82', 'G06V20/46', 'G10L15/16', 'G10L15/26']"
US20250133037A1,Guided conversation context compression with adversarial hypothetical questions and evaluating relevance of contextual information for llms,A system may smartly edit the context of a conversation to be input into a chatbot LLM by using a conversation compression algorithm to prune and compress redundant elements. The system evaluates the conversation context compression algorithm using both a chatbot LLM and an adversarial LLM. The system retrieves a logged conversation and generates a compressed conversation context from the logged conversation. The system generates a synthetic user response by applying the adversarial LLM and generates a test conversation by replacing a user response in the conversation with the synthetic user response. The system generates a compressed context of the test conversation. The system generates a test chatbot LLM response by prompting the chatbot LLM with the compressed context of the test conversation. The system evaluates the conversation context compression algorithm by comparing the test chatbot response with a benchmark chatbot response.,['H04L51/02']
US20240366962A1,Generative model of phase space,Systems and methods are disclosed for simulating dose deposition. The systems and methods perform operations comprising: receiving a set of training data representing phase space of a radiotherapy treatment device comprising propagation and scattering of particles inside the radiotherapy treatment device; training a generative machine learning model based on the set of training data to generate one or more samples of the phase space of the radiotherapy treatment device; and simulating dose deposition at a particular region of interest based on the one or more samples of the phase space generated by the generative machine learning model.,"['A61N5/1031', 'A61N5/1039', 'G16H20/40', 'G16H50/20', 'G16H50/50', 'G16H50/70']"
CN116543240A,A defense method for machine learning against attacks,"The invention discloses a defending method for machine learning to fight against attacks, which belongs to the field of automatic driving information safety. The denoised sample obtained by the diffusion model of the challenge sample is input to the authenticator to be lost to guide the denoising of the diffusion model. Training the diffusion model can ensure that the model can remove noise information added to the challenge sample without altering the information contained in the sample itself. Then, each challenge sample to be defended is input into the trained diffusion model, and slight disturbance existing in the challenge sample is removed by the model, so that the defense of the machine learning challenge sample against the challenge attack is effectively realized. The invention can provide effective protection without definitely resisting attack types, and can be applied to resisting attack defense of classification tasks and regression tasks in automatic driving.","['G06V10/764', 'G06F17/11', 'G06F21/55', 'G06N20/00', 'G06V10/774', 'Y02T10/40']"
US20250137675A1,Systems and methods for learning and utilizing occupant tolerance in demand response,"A building system of a building, the building system including one or more memory devices storing instructions thereon that, when executed by one or more processors, cause the one or more processors to update a building condition of an HVAC system of a space in a building at a time t1, wherein the building condition is updated from a default building condition. The instructions when executed by the one or more processors, cause the one or more processors to update the building condition of the space at a time t2 and receive an occupant response of an occupant from the space. The instructions when executed by the one or more processors, cause the one or more processors to update an artificial intelligence (AI) model based on the occupant response and generate, using the AI model, one or more actions for the HVAC system of a plurality of spaces.","['F24F11/63', 'F24F11/38', 'F24F11/56', 'G05B15/02', 'F24F11/47', 'F24F2120/10', 'F24F2120/20', 'G05B2219/2614']"
US12033050B1,Generating context specific electronic communications utilizing a neural network,"This disclosure describes embodiments of systems, methods, and non-transitory computer readable storage media that can utilize language neural networks to automatically generate draft electronic communications for a user account. For example, the disclosed systems leverage composition parameters of a user account (determined from historical electronic communications of the user account, digital content items corresponding to the user account, and/or other application data) with a neural network to automatically generate draft electronic communications that reflect a composition style of a user account and accurately addresses a context of a communication thread. In addition, the disclosed systems can generate electronic communications using the communication generation neural network and save the electronic communication as a draft (e.g., for review by a user of the user account) and/or automatically transmit the electronic message to a recipient user account.","['G06N3/02', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04L51/216']"
WO2024019331A1,Apparatus and method for performing image authentication,An electronic device may be provided to identify fake pixels from an image that is processed via an image processor that uses artificial intelligence (AI) technology and/or an AI camera module to perform image authentication. The electronic device may be configured to: obtain an input image; obtain a processed image of the input image via AI-based model; generate authentication metadata that indicates fake pixels that have been generated by the AI-based model; store the authentication metadata in association with the processed image in the at least one memory; and output the processed image with an indication of the fake pixels.,"['G06V20/95', 'G06F21/16', 'G06V10/82']"
WO2025090955A1,Efficiently serving machine-learned model computations with high throughput and low latency,"An example method includes receiving input requests to process a plurality of input sequences using the machine-learned sequence processing model to generate a plurality of output sequences respectively corresponding to the plurality of input sequences; generating a plurality of initial attention tensors respectively for the plurality of input sequences, wherein: one or more respective initial attention tensors are generated for each respective input sequence in parallel over input elements of the respective input sequence; and the one or more respective initial attention tensors are generated in one or more batches having a first batch size using a prefill system that comprises one or more prefill computing devices and executes one or more layers of the machine-learned sequence processing model; and autoregressively generating, using the plurality of initial attention tensors, a plurality of output elements for each of the plurality of output sequences in one or more batches having a second batch size, wherein: the plurality of output elements are generated using a generation system that comprises one or more generation computing devices.","['G06F9/5044', 'G06F9/5027', 'G06N3/063', 'G06F2209/509', 'G06N3/045']"
WO2024103076A2,Method and apparatus for semantic based learned image compression,"A method of image compression implemented by a coding device. The method comprises receiving an input latent image comprising latent image patches containing latent image data, selecting a subset of the latent image patches; applying the latent image patches to the input of a first encoder in the coding device, receiving conditioning side information, encoding, by the first encoder, the subset of latent image patches based on the conditioning side information to generate encoded latent image patches. The method further includes combining the encoded latent image patches with a plurality of mask tokens, applying the combined encoded latent image patches and plurality of mask tokens to the input of a decoder in the coding device, decoding the combined encoded latent image patches and plurality of mask tokens based on the conditioning side information to generate a reconstructed latent feature map, and rearranging the reconstructed latent feature map to produce an output latent image.","['H04N19/82', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'H04N19/13', 'H04N19/132', 'H04N19/46']"
CN119722468A,Low-light image enhancement method based on Fourier transform wavelet diffusion model,"The invention relates to the technical field of low-light image enhancement, in particular to a low-light image enhancement method based on a wavelet diffusion model of Fourier transform. The method comprises the steps of S1, performing wavelet transformation on an input image, transferring a diffusion process to a wavelet low-frequency domain, S2, extracting frequency spectrum priori information of the input image through Fourier transformation, embedding a sampling process, S3, reconstructing an enhanced fine granularity structure of a wavelet high-frequency domain of a low-light image through a high-frequency detail enhancement module, and S4, transforming a restored wavelet low-frequency domain x 0 and a high-frequency domain L H into an enhanced image through discrete wavelet inverse transformationAccording to the low-light image enhancement method based on the wavelet diffusion model of Fourier transform, provided by the invention, the generation of redundant content is effectively restrained by extracting the sampling process of embedding the Fourier priori of an input image into the wavelet diffusion model, and the fine granularity restoration of the high-frequency information of the image is realized by the high-frequency detail enhancement module, so that the perception-oriented visual enhancement effect is achieved.",['Y02T10/40']
WO2024238919A1,Automated tool generation for machine-learned model,"An example method includes receiving, by a computing system, a tool request for a tool for performing a task. The example method includes generating, by the computing system and using a primary machine-learned model, the tool based on the tool request by generating tool code. The example method includes validating, by the computing system, the tool. The example method includes outputting, by the computing system, the tool to a tool repository that is accessible by a toolkit interface of a downstream system to use the tool in conjunction with a secondary machine-learned model.",['G06N20/00']
US20250231957A1,Compression-Based Data Instance Search,"A knowledge management system may receive a set of data instances. The system may extract a plurality of entities from the set of data instances. The system may convert the plurality of entities into a plurality of entity embeddings, each entity embedding representing an entity in a latent space. The system may generate a reference embedding that has the same length as the plurality of entity embeddings. The system may compare, for each value in each entity embedding, the value to a corresponding value of the reference embedding. The system may generate a plurality of entity fingerprints, each entity fingerprint corresponding to an entity embedding, each entity fingerprint comprising Boolean values that are generated based on comparing values in each entity embedding to corresponding values of the reference embedding. The system may store the plurality of entity fingerprints to represent the plurality of entities.","['G06F16/254', 'G06F16/3347', 'G06F16/93', 'H04L9/008']"
US12182179B1,Apparatus and methods for generating obfuscated data within a computing environment,"An apparatus for generating obfuscated data within a computing environment, comprising a processor and a memory containing instructions configuring the processor to access a database containing a plurality of private data elements belonging to at least a private record, generate a set of obfuscated data elements, representative of the at least a private record, as a function of the plurality of private data elements using an generative model, determine a first distance measure between at least an obfuscated data element within the set of obfuscated data elements and at least a private data element of the plurality of private data elements within the database, and verify the first distance measure is within a distance range, wherein a minimum threshold of the distance range is determined as a function of a deidentification parameter and a maximum threshold of the distance range is determined as a function of an obfuscation parameter.","['G06F16/285', 'G06F21/6218', 'G06F21/6254', 'G06F40/20']"
CN110309114A,"Processing method, device, storage medium and the electronic device of media information","The invention discloses a kind of processing method of media information, device, storage medium and electronic devices.Wherein, this method comprises: obtaining searching request, wherein carry the first keyword in searching requestï¼Pass through first object model, the representation data of first keyword and the first object, determine the first media information under multiple target types, wherein, first object model is by the second media information under multiple types, second keyword of the second media information, what the representation data of the second object and the first operation information obtained pre-determined model training, first operation information is used to indicate the object run that the second media information is executed by the second object, the maximum probability that first media information is operated in media information associated with the first keyword by the first object performance objectiveï¼Show the first media information under multiple target types.The present invention solves the technical issues of low efficiency of media information processing in the related technology.","['G06F16/182', 'G06F16/434', 'G06F16/48', 'G06F16/9535', 'G06F40/289', 'G06F40/30', 'G06Q30/0271', 'G06Q30/0276']"
US20230297886A1,Cluster targeting for use in machine learning,"A system and method for training, using a supervised learning process, a first learning model with a first dataset; applying the first learning model to a second dataset thereby generating a first learning model output; training, using an unsupervised learning process, a second learning model with the first learning model output thereby generating a clustering output of the second learning model; determining a bias assessment based on the clustering output; and training, using a third dataset, a bias assessment modified learning model using supervised learning.",['G06N20/00']
CN107045560A,The method and apparatus of outline are etched by surface kinetics model optimization,"The present invention relates to the method and apparatus that outline is etched by surface kinetics model optimization.The method for disclosing optimizing computer model, it is associated with groups of independent input parameter by the etch features profile on semiconductor devices by using multiple model parameters.The etching outline that the optimization method can change model parameter to generate using model is so that it reduces the yardstick for combining difference represented between the etching outline that the experiment etch process that the different groups of values using groups of independent input parameter are performed is obtained and calculating etching outline produced from model and corresponding to experiment etching outline.The yardstick can be projected for calculating on the poor subspace through dimensionality reduction between these profiles by will calculate etching outline and corresponding experiment etching outline and calculated.There is disclosed herein the system of the model using this optimization, and the method for approx determining using this model the profile of etch features.","['H01L21/3065', 'G05B19/4188', 'G06F30/367', 'G05B17/02', 'G06F30/39', 'H01L21/31116', 'H01L21/32136', 'H01L21/67069', 'H01L22/12', 'G05B2219/45031', 'G05B2219/45212', 'H01L2924/30111']"
WO2024193188A1,"Method and apparatus for generating simulation scene data, and device","A method and apparatus for generating simulation scene data, and a device, applicable to the technical field of computers, and used for improving the diversity of simulation scene data. The method comprises: acquiring road test data collected by performing a travel test on an autonomous vehicle on a real road; performing traffic scene generalization on the road test data to obtain generalized road test data; and converting an obstacle behavior in the generalized road test data into an interactive behavior to obtain simulation scene data. Real road test data is expanded into road test data having more traffic scene types, so that real and diversified simulation scenes can be generated by using the road test data of more traffic scene types; an obstacle behavior in the road test data is converted into an interactive behavior, so that the obstacle can have the capability of interacting with an autonomous vehicle, and thus a simulation scene can respond to a change of an autonomous driving system, thereby effectively ensuring the interactivity of simulation scenes.","['G06F30/27', 'G06F17/18']"
US12333691B2,Utilizing a generative machine learning model to create modified digital images from an infill semantic map,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06F3/0482', 'G06F3/04842', 'G06F3/04845', 'G06T11/60', 'G06T5/60', 'G06T5/70', 'G06T5/77', 'G06T7/11', 'G06V10/25', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/70', 'G06T2200/24', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US20230404673A1,"Apparatus, system, and method for generating patient-specific implants and/or instrumentation for osteotomies","An apparatus, system, and method is disclosed for correcting a condition present in a patient. In some aspects, the apparatus may include a resection guide having: a body, resection features that define trajectories that are at least partially determined based on a bone model of at least a portion of the patient's foot. The bone model can be based on medical imaging of the patient's foot. The apparatus includes a first bone attachment feature and second bone attachment feature configured to secure the resection guide to the bone. Also, the apparatus may include at least one complementary component selected from the group having of: an alignment guide; a rotation guide; a compression guide; a correction guide; a positioning guide; a pin guide; and a fixation guide.","['A61B34/10', 'A61B17/151', 'A61B17/152', 'A61B17/1775', 'A61B17/8095', 'G06F30/12', 'G06F30/17', 'G06F30/27', 'A61B17/0642', 'A61B17/8866', 'A61B2017/00526', 'A61B2017/565', 'A61B2017/568', 'A61B2017/681', 'A61B2034/101', 'A61B2034/102', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'A61B2034/108', 'A61B2034/2065', 'G06F2111/16', 'G06F2113/10']"
EP4540832A1,Mesh segmentation and mesh segmentation validation in digital dentistry,"Systems and techniques for training one or more neural networks to automatically generate tooth segmentation data used in digital dentistry are disclosed including predicting one or more segmentation labels pertaining to aspects of dental geometry, generating an accuracy score that specifies a difference between the one or more predicted representations and one or more respective reference and modifying at least one aspect of the neural network based on the accuracy score.","['G16H30/40', 'G06V10/82', 'G16H50/20']"
US20250117897A1,System and method for parallel denoising diffusion,"A pioneering parallel diffusion technique individually represents and diffuses each bit or groups of bits. The approach addresses inefficiencies observed in traditional diffusion processes. The approach may reduce the number of iterations required for denoising, thereby decreasing denoising latency and improving overall processing speed. These advantages are especially crucial in the realm of codec applications where real-time processing and resource efficiency are paramount.","['G06V10/28', 'G06T5/10', 'G06T5/70', 'G06T2207/20182']"
CN117475031A,"Image generation method, device and storage medium","The embodiment of the application provides an image generation method, device and storage medium. In the embodiment of the application, a preset context graph model is introduced into a scene graph reconstruction scene, prompting words required by the context graph model are constructed through scene style images and images or scene description information of target objects, namely, the scene description information and the scene style information are used as the prompting words of the preset context graph generation model to be input into the context graph generation model, so that initial scene graph generation is performed by using the context graph generation model, the initial scene graph is further adjusted to obtain the target scene graph, a scene effect graph generation scheme based on a large model is realized, the capability of conveniently and rapidly generating the effect graph can be provided, intelligent generation of the scene effect graph is realized, the graph efficiency can be improved, and the graph cost is reduced.","['G06T11/60', 'G06F3/0481', 'G06F3/04845', 'G06N20/00', 'G06N3/04', 'G06Q30/0643', 'G06T17/00', 'G06V10/82', 'G06V20/70']"
US20230419549A1,Systems and methods for determining and using a multidimensional measure of apparent skin color,"Systems and methods can compute a multidimensional score of apparent skin color to capture skin color variation and provide a comprehensive representation of its constitutive complexity. The multidimensional apparent skin color score can be used to reveal biases related to skin color in image datasets and computer vision models. The multidimensional skin color score can focus on the perceptual lightless, L*, as a measure of skin tone ranging from light to dark, and the hue angle h*, as a measure of skin hue ranging from red to yellow. The multidimensional skin color scale offers a more representative assessment to surface socially relevant biases due to skin color effects in computer vision. This could help to (i) enhance the diversity in the data collection process, by encouraging specifications to better represent skin color variability; and (ii) improve the identification of dataset and model biases in fairness benchmarking, by highlighting their limitations.","['G06V40/162', 'G06T7/90', 'G06T7/11', 'G06V10/50', 'G06V10/762', 'G06V40/171', 'G06V40/172', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30201']"
US20240256964A1,Pretraining Already-Pretrained Models for Diverse Downstream Tasks,"An example method includes obtaining a pretrained machine-learned model that was initially pretrained using a pretraining dataset and further pretraining the model by generating, using a pretraining objective framework, a plurality of corrupted training examples from one or more training examples obtained from the pretraining dataset. A first set of one or more training examples can be corrupted according to a first set of configuration parameters of the pretraining objective framework. A second set can be corrupted according to a second set of configuration parameters of the pretraining objective framework. The example method includes inputting the plurality of corrupted training examples into model; obtaining from the model, a plurality of outputs respectively generated by model based on the plurality of corrupted training examples; and updating one or more parameters of model based on an evaluation of the plurality of outputs.","['G06F7/483', 'G06N20/00', 'G06N3/045']"
CN118397120A,A Fidelity Virtual Dressing Method Based on Latent Space Diffusion Model,"The invention belongs to the technical field of image generation, and particularly relates to a fidelity virtual reloading method based on a hidden space diffusion model. The invention improves the training of the traditional hidden space diffusion process in two aspects: providing a model with a priori clothing by using affine clothing as a starting point and local conditions to mitigate increased randomness in the initial and in-process, respectively; the fidelity supervision of the consistency of the clothes is provided through the clothes flattening network, additional image-level constraint is brought from the original flat clothes, and the fidelity of virtual reloading is improved; in addition, the reasoning process is improved for designing the noise sampling mode based on affine clothes, and the performance of the model is further improved.","['G06T11/001', 'G06Q30/0643', 'G06T3/02', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US20250103778A1,Molecule generation using 3d graph autoencoding diffusion probabilistic models,Methods and systems for molecule generation include embedding an input template molecule into a latent space to generate a vector. The vector is decoded using a denoising diffusion implicit model (DDIM) to generate a new molecule specification that is based on the input template molecule. The new molecule is produced using the new molecule specification.,"['G06F30/27', 'G06N3/045', 'G06N3/047', 'G06N7/01']"
CN119094814B,Data processing method and device,"The embodiment of the application discloses a data processing method and a data processing device, which relate to the technical field of computers, and the method comprises the steps of obtaining a target text, and obtaining P continuous frame texts through the target text; the method comprises the steps of obtaining P noise images, obtaining target frame texts from P continuous frame texts, determining target noise images from the P noise images, processing the target noise images through a target video generation model to obtain target forward noise vectors, processing service texts, service images and target frame texts through the target video generation model to obtain fusion coding features, denoising the target noise images according to the target forward noise vectors and the fusion coding features to obtain target predicted images corresponding to the target frame texts, and taking the target predicted images as next frame images positioned in the service images in a video to be generated. By adopting the application, the consistency of the overall key of the text video can be improved, and the quality of the text video can be ensured.","['H04N21/23418', 'G06F18/213', 'G06F18/253', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06T11/00', 'G06T3/4007', 'G06T7/269', 'H04N21/44008']"
US20240221242A1,Using stable diffusion to generate seamless content tile sets in content generation systems and applications,"Approaches presented herein can utilize a network that learns to generate a set of content tiles that represent a type of content (e.g., texture) and satisfy a set of rules or boundary conditions. The network can be a diffusion network that learns or adapts to the boundary conditions over several iterations. An indication of a type of content, along with a set of noisy prior images, can then be provided as input to the trained diffusion network, which can generate a set of content images. The content images can then be placed using a random (or other) selection process, as long as each selection satisfies the respective boundary conditions. Such an approach enables a small number of content tiles to be used for a texture region with a repeatability or pattern that may not be obviously detectable by a typical human viewer.","['G06V10/82', 'G06T11/001', 'G06T5/002', 'G06T5/70', 'G06T7/13']"
US20220405583A1,Score-based generative modeling in latent space,"One embodiment of the present invention sets forth a technique for training a generative model. The technique includes converting a first data point included in a training dataset into a first set of values associated with a base distribution for a score-based generative model. The technique also includes performing one or more denoising operations via the score-based generative model to convert the first set of values into a first set of latent variable values associated with a latent space. The technique further includes performing one or more additional operations to convert the first set of latent variable values into a second data point. Finally, the technique includes computing one or more losses based on the first data point and the second data point and generating a trained generative model based on the one or more losses, wherein the trained generative model includes the score-based generative model.","['G06N3/0475', 'G06N3/08', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/088']"
US12249048B2,Score-based generative modeling in latent space,One embodiment of the present invention sets forth a technique for generating data. The technique includes sampling from a first distribution associated with the score-based generative model to generate a first set of values. The technique also includes performing one or more denoising operations via the score-based generative model to convert the first set of values into a first set of latent variable values associated with a latent space. The technique further includes converting the first set of latent variable values into a generative output.,"['G06V10/82', 'G06T5/70', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06V10/30', 'G06T2207/20084']"
CN117611709A,"Image editing methods, devices, equipment, storage media and program products","The embodiment of the application discloses an image editing method, an image editing device, a storage medium and a program product, which belong to the technical field of image processing, and the method comprises the following steps: acquiring a description text of an editing object in an image to be edited; inputting the description text and the image to be edited into the visual language big model to obtain a first text embedding feature output by the visual language big model; inputting the first text embedded feature and the image to be edited into an image segmentation model to obtain an editing object mask output by the image segmentation model, wherein the first text embedded feature is a text prompt feature of the image segmentation model; and performing image editing on the image to be edited through the image editing model based on the editing object mask and the editing target text to obtain a target image. By adopting the method provided by the embodiment of the application, a user can control the computer equipment to edit the appointed editing object in the image through the natural language instruction, and meanwhile, the accuracy of image editing is improved.","['G06T11/60', 'G06T7/11']"
CN116954437A,"Information interactive processing methods, devices, equipment and computer storage media","The application provides an information interaction processing method, an information interaction processing device, information interaction processing equipment and a computer readable storage medium; the method comprises the following steps: displaying information content comprising first target text content on an information display interface; in response to receiving an image generation instruction for the first target text content, displaying at least one first candidate image corresponding to the first target text content; determining a first target image from the at least one first candidate image in response to the received image selection instruction; and determining a target display area of the first target image based on a first display area of the first target text content in the information display interface, and displaying the first target image in the target display area, wherein the target display area is different from the first display area. According to the application, the interest and immersion of information reading can be improved, and the viscosity of a user can be improved.","['G06F3/0483', 'G06F3/04886']"
CN117808906A,"Data processing method, device, equipment and readable storage medium","The application discloses a data processing method, a device, equipment and a readable storage medium, wherein the method comprises the following steps: the method comprises the steps of obtaining a source domain image, carrying out structuring treatment on the source domain image to obtain a structured image, encoding the source domain image into a first potential encoding image, and encoding the structured image into a second potential encoding image; forward diffusion is carried out on the first potential coding image, and a Gaussian noise image is obtained; converting natural language parameters into language input vectors; and converting the second potential coding image into an image input vector, performing backward diffusion on the Gaussian noise image based on the language input vector and the image input vector to obtain a Gaussian denoising image, and decoding the Gaussian denoising image into a target domain image belonging to a target domain scene. By adopting the method and the device, the universality of the generated target domain image can be considered, and meanwhile, the accuracy of the generated target domain image can be improved.","['G06T9/002', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06T5/20']"
US12333788B2,System and method for subjective property parameter determination,"In variants, the method for subjective property scoring can include determining an objective score for a subjective characteristic of a property using a model trained using subjective labels for a set of training properties. In examples, the model can be trained on subjective property rankings, determined using the subjective labels, for the set of training properties.","['G06V10/774', 'E04F13/0817', 'E04F13/0894', 'G06Q30/0278', 'G06Q50/16', 'G06T7/0002', 'E04F2201/026', 'E04F2201/043', 'G06T2207/20081']"
US20240303873A1,Systems and methods for image generation via diffusion,"Embodiments described herein provide a method of generating an image. the method comprises receiving, via a data interface, a natural language prompt, obtaining a noised image vector, and generating a denoised image vector by a first forward pass of a plurality of iterations of a denoising diffusion model with the noised image vector as an input and conditioned on the natural language prompt. The method further includes calculating a gradient of a loss function based on the denoised image vector with respect to the noised image vector, and updating the noised image vector based on the gradient. A final image is generated using a final forward pass of the denoising diffusion model with the updated noised image vector as an input and conditioned on the natural language prompt.","['G06T11/00', 'G06T5/60', 'G06T5/70', 'G06T2207/20084']"
CN112820105B,Road network abnormal area processing method and system,"The application relates to a method and a system for processing road network abnormal regions, wherein the method for processing the road network abnormal regions comprises the following steps: the method comprises the steps of generating an antagonistic network based on historical road network time sequence characteristic data, generating sample data according to a generated model, updating network parameters of a generated real sample and the generated model according to a discrimination model and regular data feedback, finally achieving the effect that the generated time sequence characteristic data meets the detection and prediction of an abnormal region, analyzing and processing the generated road network abnormal region, directly treating the abnormality with small scale, and performing comprehensive topology and abnormal transmission segmentation processing and treatment on the abnormal region with large scale, thereby finally achieving the effect of treating the abnormal region of the road network. By the method and the device, the problems that the real-time performance and the practicability of model application are poor and the division of an abnormal area is unclear in the prior art are solved, and the identification, prediction and treatment effects of the abnormal area of the road network are improved.","['G08G1/0104', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06N3/088', 'G08G1/0125']"
CN116934924A,Cartoon image generation method and device and computer equipment,"The embodiment of the application provides a cartoon image generation method, a cartoon image generation device and computer equipment, and relates to the technical field of video image processing. Firstly, extracting text description information in a real person image; then, receiving expression base parameters for generating the cartoon image; and then, inputting the text description information and the expression base parameters into a cartoon image generation model comprising a low-rank self-adaptive factor model and a cartoon stable diffusion technology sub-model for prediction to obtain a cartoon image corresponding to the real image. Compared with the method for generating the cartoon image by the countermeasure network GAN in the prior art, the cartoon image generation model combining the low-rank self-adaptive factor model and the cartoon stable diffusion technology submodel can be used for better reducing the true man on the global characteristic and the detail characteristic, has higher sense of reality, and can optimize the cartoon image generation effect and promote the interactive experience of users.","['G06T13/40', 'G06N3/045', 'G06N3/0475', 'G06T17/00', 'G06V40/176', 'Y02T10/40']"
US20230149092A1,Systems and methods for compensating for obstructions in medical images,"A method for determining an attribute associated with anatomy of interest of a patient includes receiving first image data capturing the anatomy of interest of the patient and at least one obstruction obscuring at least a portion of the anatomy of interest of the patient; generating, using at least one machine learning model, second image data in which at least a portion of the obstruction is replaced; and determining at least one attribute associated with the anatomy of interest based on the second image data.","['A61B34/10', 'A61B90/37', 'A61B34/25', 'G06N3/0455', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06T5/60', 'G06T5/77', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'A61B2034/2065', 'A61B2034/254', 'A61B2090/365', 'A61B2090/376', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008']"
US12211203B2,Optical coherence tomography-based system for diagnosis of high-risk lesion and diagnosis method therefor,The disclosure purposes to provide an optical coherence tomography (OCT)-based system for diagnosing a high risk lesion such as a vulnerable atheromatous plaque by using an artificial intelligence model through deep learning. A deep learning-based diagnostic method of diagnosing a high risk lesion of a coronary artery includes: acquiring an OCT image of a coronary artery lesion of a patient; extracting a first feature of a thin cap from the OCT image; setting a region of interest included in the OCT image on a basis of the first feature; and determining whether the region of interest includes a high risk lesion.,"['G06T7/0012', 'A61B5/0066', 'A61B5/02007', 'A61B5/02021', 'A61B5/7264', 'A61B5/7267', 'A61B5/7275', 'A61B5/7278', 'A61B5/7485', 'G06N20/00', 'G06T7/0014', 'G16H30/40', 'G16H50/20', 'A61B2576/00', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096', 'G06T2207/30101']"
CN117315149B,"Three-dimensional object generation method, device, equipment and storage medium","The application provides a three-dimensional object generation method, a device, equipment and a storage medium, wherein the method acquires a text and a first image; determining an initial model for generating a three-dimensional object; determining a loss function according to the text and the first image; training an initial model according to the loss function to obtain a final model; and generating the three-dimensional object according to the final model. The method provided by the application generates the three-dimensional object according to the text and the image, so that the three-dimensional object not only accords with the description of the text, but also accords with the shape depicted by the image, and the generated three-dimensional object is accurate and controllable.","['G06T17/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/761']"
CN114170472A,"Image processing method, readable storage medium and computer terminal","The application discloses an image processing method, a readable storage medium and a computer terminal. Wherein, the method comprises the following steps: acquiring an image to be processed; processing the image to be processed by using an image translation model to obtain a target image with a target style, wherein the image to be processed corresponds to the target image in semantic meaning, the image translation model is obtained by training a plurality of groups of pre-generated image pairs, and each group of image pairs comprises: a first image and a second image of a target style. The image translation method and device solve the technical problem that in the related art, the image translation model is trained through a large number of stylized images, so that the processing cost is increased.","['G06F18/214', 'G06N3/045', 'G06N3/08']"
CN116630465B,Model training and image generating method and device,"The application relates to the technical field of artificial intelligence, in particular to a model training and image generating method and device. During model training, a sample image included in an image text pair is input into an input layer, noise of target noise intensity is increased for the sample image, a target noise image and a first feature vector are obtained, a first word embedded vector corresponding to the first feature vector and the sample text is input into a transducer encoder, a second feature vector is obtained and is input into a full-connection layer, predicted noise intensity is obtained, noise reduction is carried out on the target noise image according to the predicted noise intensity, a generated image is obtained, loss values are determined according to the predicted noise intensity and the target noise intensity, a target generation model capable of generating the image is obtained, automatic generation of the image is achieved, sample image acquisition efficiency during model training is improved, and model training efficiency is further improved. The technical scheme provided by the application has the characteristics of instantaneity and controllability, and accords with the credibility characteristic.","['G06T11/00', 'G06N3/0455', 'G06N3/08', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN117475082A,"3D content generation method, device and storage medium","The application provides a 3D content generation method, device and storage medium, wherein the method comprises the following steps: text information is acquired, and a plurality of first color images, a plurality of normal images and a plurality of depth images which are obtained by rendering the 3D characterization model under a plurality of camera poses are determined. Inputting the text information and the plurality of first color images into a first text-to-image model, and inputting the text information, the plurality of camera poses, the plurality of normal images and the depth images into a second text-to-image model to obtain a first 3D characterization model by optimizing geometric parameters of the 3D characterization model through the first text-to-image model and the second text-to-image model. And determining a plurality of second color images obtained by rendering the first 3D representation model under a plurality of camera poses, and inputting text information and the plurality of second color images into the first text-generated graph model to optimize the material parameters of the first 3D representation model so as to obtain a second 3D representation model. According to the second 3D characterization model, 3D content with better geometric quality and material quality can be generated.","['G06T17/00', 'G06T15/005', 'Y02T10/40']"
US20250069701A1,Deep Learning Methods For Biosynthetic Gene Cluster Discovery,"The present disclosure relates to computer-implemented methods and systems for identifying biosynthetic gene clusters (BGCs) that encode pathways for the production of secondary metabolites. Secondary metabolites that target genes or gene products that are homologous to, e.g., human genes or gene products may have utility as potential drug compounds.","['G16B20/30', 'G16B40/00', 'G06N20/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06N5/01', 'G16B25/10', 'G16B30/10']"
CN117218138A,Melanoma image segmentation method based on deep learning,"The invention discloses a melanoma image segmentation method based on deep learning, which combines an optimized U-Net segmentation network with a Diffusion probability Diffusion network to realize efficient segmentation of a melanoma image. The invention combines deep learning and traditional image processing technology, obviously improves the segmentation precision and speed, and has higher accuracy than the current mainstream segmentation method. In order to facilitate doctors and patients to check the segmentation result and the original image, the invention also adopts a visual interface, which is convenient for analysis and judgment; the interface supports data export, which is beneficial to subsequent research and processing. By providing an API interface, the invention can be conveniently integrated into the existing medical system and mobile application, provides real-time and accurate auxiliary diagnostic tools for clinicians, and is beneficial to improving the diagnostic efficiency and reducing the misdiagnosis rate. Besides image segmentation of melanoma focus areas, the invention can be popularized to detection and analysis of other skin disease focuses, and has wide application prospects.",[]
CN117058271A,Method and computing device for generating commodity main graph background,"The application provides a method and computing equipment for generating commodity main graph background. The method comprises the following steps: providing an industrialized background information option to a user, wherein the background information option comprises an industry category, a theme type and key elements associated with the industry category; receiving commodity graphs, background information and custom description submitted by a user; generating a prompt message according to the background information and the custom description; extracting a commodity main diagram from the commodity diagram; inputting the commodity main graph and the prompt text into a pre-trained graph-text generation graph model, wherein the graph-text generation graph model is based on the prompt text and diffuses out a background graph from the commodity main graph. According to the technical scheme, personalized industrial scene creative customization of the commodity main map can be realized, and purchasing decisions of buyers are promoted.","['G06T11/60', 'G06Q30/0643']"
WO2025156888A9,"Gesture data completion method and apparatus for three-dimensional object, device, storage medium, and product","The present application relates to the technical field of artificial intelligence, and discloses a gesture data completion method and apparatus for a three-dimensional object, a device, a storage medium, and a product. The method comprises: acquiring three-dimensional incomplete gesture data of a three-dimensional object in a preset gesture, wherein the three-dimensional incomplete gesture data comprises first three-dimensional joint point data of some joint points of the three-dimensional object; calling a text-to-image model to generate a two-dimensional gesture image of the three-dimensional object in the preset gesture on the basis of the three-dimensional incomplete gesture data and a gesture description text, wherein the gesture description text is used for describing the preset gesture; performing joint point recognition on the two-dimensional gesture image to obtain second three-dimensional joint point data of missing joint points; and adding the second three-dimensional joint point data to the three-dimensional incomplete gesture data to obtain three-dimensional complete gesture data of the three-dimensional object. The method can quickly complete the missing joint points in gesture data of the three-dimensional object.","['G06T19/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06T19/003', 'G06T19/006', 'G06T7/73', 'G06V10/82', 'G06V10/86', 'G06V40/20', 'Y02P90/30']"
CN116757970B,"Training method of video reconstruction model, video reconstruction method, device and equipment","The application discloses a training method of a video reconstruction model, a video reconstruction method, a device and equipment, and belongs to the technical field of computer vision. The method comprises the following steps: acquiring a first video and a second video with the same content, wherein the resolution of the second video is higher than that of the first video; noise adding processing is carried out on any frame of first image in the first video through the neural network model to obtain prediction noise information, denoising processing is carried out on the prediction noise information to obtain a reconstructed image corresponding to any frame of first image, and the resolution of the reconstructed image corresponding to the first image is the same as that of the second image corresponding to the first image in the second video; and training the neural network model based on the second image and the reconstructed image corresponding to each frame of the first image to obtain a video reconstruction model. Through denoising processing, detailed information in the image can be reserved, and the definition of the reconstructed image is improved, so that the accuracy of the model is improved.","['G06T5/50', 'G06N3/08', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US20250162150A1,Action planning for robot control,"Embodiments of the disclosure provide a solution for action planning. A method includes: generating a sequence of images for an action execution plan based on description information and a reference image related to an environment with an action executor located, the description information describing the action execution plan to be executed by the action executor; extracting a sequence of visual feature representations from the sequence of images, respectively; and for a respective visual feature representation of the sequence of visual feature representations, determining control information for controlling an action to be executed by the action executor in the environment to complete the action execution plan at least based on the respective visual feature representation, a reference visual feature representation prior to the respective visual feature representation in the sequence and observed information of the action executor in the environment during execution of a reference action prior to the action.",['B25J9/1664']
CN118737119A,"Audio multi-scenario noise processing method, device, equipment and medium","The application relates to an audio multi-scene noise processing method, a device, equipment and a medium, wherein the method comprises the following steps: the audio service system acquires the noise type in the target acoustic scene and the original audio which needs to be subjected to audio multi-scene noise adding processing; the audio service system takes each noise type as text embedding and transmits the text embedding to a potential diffusion model in the noise generation system, and Gaussian noise distribution and text embedding are adopted as starting points in the potential diffusion model to gradually generate noise audio samples; copying each noise audio sample according to a plurality of preset volume multiple thresholds to determine noise audio samples corresponding to the preset volume multiple thresholds; randomly selecting one or more noise audio samples corresponding to a preset volume multiple threshold value from each noise type, and synthesizing the noise audio samples with the original audio which needs to be subjected to audio multi-scene noise adding processing to obtain noise adding audio. The application can make the model better adapt to the actual environment and improve the robustness.","['G10L13/02', 'G10L13/04', 'G10L25/18', 'G10L25/30']"
CN118015159A,"Character video generation method and device, electronic equipment and storage medium","The application provides a character video generation method, a character video generation device, electronic equipment and a storage medium. The method comprises the following steps: extracting features of the character description text and the character reference graph by using an encoder; splicing the text semantic features and the reference picture semantic features to obtain first fusion features, and inputting the first fusion features and the reference picture feature information into a feature learning network to fuse to obtain second fusion features; encoding the angular gesture image by using a gesture guide to generate gesture image features, and inputting the gesture image features into a gesture network for processing; carrying out noise adding processing on the character video frames to obtain multi-frame noise images, inputting the multi-frame noise images into a diffusion network, and carrying out sequence denoising on the multi-frame noise images by using the diffusion network; and performing iterative decoding on the characteristics output by the diffusion network for a plurality of times by using a decoder, and finally outputting continuous character video frames. The application can generate the character video with higher quality and more robustness.","['G06T13/40', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/806', 'G06V20/46', 'G06T2207/20081', 'G06T2207/20084']"
CN119444896A,A training-free local video style transfer method and system,"The invention discloses a local video style migration method and a local video style migration system without training, wherein the method comprises the steps of carrying out denoising inversion on video frames of an original video by a content branch to obtain content potential characteristics Z t (t=1âT) with different time stamps, masking a first frame video frame of the original video in the denoising inversion process of the original video, transmitting the mask to all video frames of the original video based on point matching, and carrying out denoising inversion on a reference image by a style branch to obtain style potential characteristics with different time stampsIn editing branches, let initial migration latent featuresDenoising is carried out based on the initial migration potential characteristics, and style migration is carried out on the migration potential characteristics based on a AdaIN style migration technology in the denoising process, so that a style migration result is obtained, and the pixel representation is decoded by a decoder frame by frame to be used as a video after local style migration. The invention can meet the requirement of users on local area migration, and reduce flicker and artifacts brought in the migration process.","['G06T11/001', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06T11/60', 'G06T3/04']"
US20250103856A1,Local cross-attention operations in neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for using a neural network to generate a network output that characterizes an entity. In one aspect, a method includes: obtaining a representation of the entity as a set of data element embeddings, obtaining a set of latent embeddings, and processing: (i) the set of data element embeddings, and (ii) the set of latent embeddings, using the neural network to generate the network output. The neural network includes a sequence of neural network blocks including: (i) one or more local cross-attention blocks, and (ii) an output block. Each local cross-attention block partitions the set of latent embeddings and the set of data element embeddings into proper subsets, and updates each proper subset of the set of latent embeddings using attention over only the corresponding proper subset of the set of data element embeddings.","['G06N3/0455', 'G06N3/045', 'G06N3/0495', 'G06N3/084']"
US20250103779A1,Learning unsupervised world models for autonomous driving via discrete diffusion,A method learns unsupervised world models for autonomous driving via discrete diffusion. The method includes encoding an observation of an actor for a geographic region using an encoder to generate a prior frame of prior tokens. The method further includes processing the prior frame with a spatio-temporal transformer to generate a predicted frame of predicted tokens. The spatio-temporal transformer includes a spatial transformer and a temporal transformer. The method further includes processing the predicted frame to generate a predicted action for the actor. The method further includes decoding the predicted frame to generate a predicted observation of the geographic region.,"['G06F30/27', 'B60W50/0097', 'B60W60/001']"
WO2024193061A1,"Image processing method and apparatus, computer readable storage medium, and electronic device","The present disclosure relates to the technical field of image processing, and provides an image processing method, an image processing apparatus, a computer readable storage medium, and an electronic device. The image processing method comprises: acquiring an original image and a mask image, wherein the mask image is used for identifying an area to be edited of the original image; determining a crop box according to said area, cropping the original image by using the crop box so as to obtain a sub-image to be edited, and cropping the mask image by using the crop box so as to obtain a mask sub-image; generating an edited sub-image on the basis of the sub-image to be edited, the mask sub-image, and text information; and fusing the edited sub-image with the original image. The present disclosure improves an image editing effect.","['G06T11/60', 'G06T3/4038', 'G06T7/11']"
US10402289B2,Fine-grained causal anomaly inference for complex system fault diagnosis,"A computer-implemented method for diagnosing system faults by fine-grained causal anomaly inference is presented. The computer-implemented method includes identifying functional modules impacted by causal anomalies and backtracking causal anomalies in impaired functional modules by a low-rank network diffusion model. An invariant network and a broken network are inputted into the system, the invariant network and the broken network being jointly clustered to learn a degree of broken severities of different clusters as a result of fault propagations.","['G06F11/2257', 'G06F17/50', 'G06F30/00', 'G06N5/048', 'G06F30/3323', 'G06N20/00']"
UA127515C2,"ANTI-VSMA ANTIBODY, A BISPECIFIC ANTIGEN-BINDING MOLECULE THAT BINDS VSMA AND CD3, AND THEIR USES","Provided herein are antibodies that immunospecifically bind to BCMA. Also described are related polynuclcotides capable of encoding the provided BCMA-spccific antibodies or antigen-binding fragments, cells expressing the provided antibodies or antigen-binding fragments, as well as associated vectors and detectably labeled antibodies or antigen-binding fragments. In addition, methods of using the provided antibodies are described. For example, the provided antibodies may be used to diagnose, treat, or monitor BCMA-expressing cancer progression, regression, or stability; to determine whether or not a patient should be treated for cancer; or to determine whether or not a subject is afflicted with BCMA-expressing cancer and thus may be amenable to treatment with a BCMA-specific anti-cancer therapeutic, such as the multispecific antibodies against BCMA and CD 3 described herein.","['C07K16/28', 'A61K39/39558', 'A61K45/06', 'A61P35/00', 'A61P35/02', 'C07K16/2809', 'C07K16/2878', 'C07K16/3061', 'A61K2039/505', 'C07K2317/21', 'C07K2317/24', 'C07K2317/31', 'C07K2317/33', 'C07K2317/34', 'C07K2317/515', 'C07K2317/565', 'C07K2317/76', 'C07K2317/92']"
US20250086187A1,Executing a Client Model Using a Task Prompt Produced by a Main System,"A technique executes a client machine-trained model (âclient modelâ) on a client device. In operation, the client device submits a description of a task to be performed by the client device to a network-accessible main system. The main system uses a main-system machine-trained model (âmain-system modelâ) to produce a task prompt based on the task description. The client device subsequently uses the task prompt to process queries pertaining to the task. The main-system is trained to increase the accuracy of responses produced by the client model, while reducing the sizes of task prompts produced by the main system. The training process is performed by holding weights of the client model constant.","['G06F16/24564', 'G06N20/00', 'G06N3/045']"
CN120051770A,Revisions and attributions of output of a text generation model,"Existing Language Models (LM) can perform tasks such as questions and answers, reasoning and conversations excellently. However, they may sometimes generate unsupported or inaccurate content. Accordingly, in the present disclosure, systems and methods are provided for improving the reliability of LM generated outputs. First, systems and methods are provided for editing generated content based on a machine-learned comparison between LM generated content and relevant evidence excerpts, which may be retrieved and extracted using a machine-learned query generation model and a machine-learned relevance model. Second, systems and methods are provided for attributing portions of LM generated content (e.g., fact claims) to relevant evidence excerpts. Thus, the present disclosure can improve the reliability of LM output by both increasing the factual accuracy of edited content and by allowing a user or computing system to know whether a portion of the generated content is supported by or contradicted by external evidence.","['G06F16/3329', 'G06F16/90332', 'G06F40/169', 'G06F40/216', 'G06F40/30']"
CN117808945A,Digital person generation system based on large-scale pre-training language model,"The invention discloses a digital person generating system based on a large-scale pre-training language model, which relates to the technical field of virtual digital persons, and comprises the following components: a server and a holographic display module; the server comprises a proprietary large model generation module, a preset action geometric model generation module, a digital human figure generation module and a personalized digital human generation module; the proprietary large model generation module is used for fine tuning the large-scale pre-training language model by adopting the customized data set to obtain a proprietary large model; the preset action geometric model generation module is used for carrying out static scanning modeling on target personnel to obtain a plurality of preset action geometric models; the digital human figure generating module is used for generating digital human figures according to a plurality of preset action geometric models; the personalized digital person generation module is used for loading the exclusive large model, the customized voice and the action into the digital person image. The invention realizes that the personalized digital person displayed by the holographic display module is generated by the personalized digital person generation module.","['G06T13/40', 'G06F18/256', 'G06N20/00', 'G06T13/205', 'G06T13/80']"
WO2023242757A1,"Geometry generation for dental restoration appliances, and the validation of that geometry","Systems and techniques for training one or more machine learning models to generate digital representations of dental restoration tooth geometry are disclosed including generating one or more digital representations that define a restored state for a first digital representation, determining one or more differences between the one or more predicted representations for the restored state and the one or more reference representations of the restored state, and modifying the machine learning model based on the determined differences.","['G16H50/50', 'G16H20/00', 'G16H30/00']"
KR102612572B1,audio data generation using artificial intelligence,"Disclosed are various embodiments regarding audio data generation using artificial intelligence. In accordance with one embodiment, an audio data generation method includes the following steps of: (a) generating first audio data based on inputted first musical instrument digital interface (MIDI) data; and (b) generating second audio data using a generative artificial intelligence model based on inputted second MIDI data and the generated first audio data. Therefore, the present invention is capable of converting an existing sound source into a high-quality sound source.","['G10H1/0025', 'G06N3/08', 'G10H1/0066', 'G10H2210/111', 'G10H2240/021', 'G10H2240/031', 'G10H2240/056', 'G10H2250/311']"
CN119992742A,Fire monitoring and early warning method and device based on big data analysis,"The embodiment of the invention discloses a fire monitoring and early warning method and device based on big data analysis, and belongs to the technical field of data analysis. According to the embodiment of the invention, the satellite remote sensing heat source image, the meteorological environment parameters, the historical fire event records, the geographic information grid data and other multi-source data are integrated to construct a space-time associated dynamic monitoring system, so that the environmental abnormality symptom before the occurrence of a fire can be comprehensively captured. The space-time fusion processing eliminates space-time reference differences of data from different sources, so that heat source distribution, weather change and historical fire modes form multidimensional correlation under a unified geographic framework, the sensitivity and reliability of early fire point identification are obviously improved, and further, follow-up accurate fire risk prediction is realized.",['Y02A90/10']
EP4404081A1,Dynamically generated virtual environments,"A system enabling dynamically generated virtual environments comprises a virtual environment creation module comprising one or more virtual environment building blocks used in the generation of at least one virtual environment, each building block comprising predefined dimensions and shapes; and a search engine configured to search one or more databases. In response to receiving a search query, the search engine retrieves, from the at least one database, data representing a plurality of virtual objects indexed based on at least one attribute associated with at least one search term and sends the data to the virtual environment creation module, which is configured to select virtual environment building blocks based on the virtual objects and to generate a virtual environment by arranging the selected virtual environment building blocks within the virtual environment and placing the virtual objects within the selected virtual environment building blocks.","['G06F16/58', 'G06T11/60', 'G06F16/444', 'G06T17/00', 'G06F16/432', 'G06F16/438', 'G06F16/9538', 'G06T19/003', 'G06T19/20', 'G06F16/635', 'G06F16/638']"
WO2025112948A1,"Image generation method, automatic question answering method, and parameter generation model training method","Embodiments of the present disclosure provide an image generation method, an automatic question answering method, and a parameter generation model training method. The image generation method comprises: acquiring an image description text; inputting the image description text and generation prompt information into a parameter generation model to obtain image generation parameters corresponding to the image description text, wherein the image generation parameters are used for describing visual features of an image, and the parameter generation model is obtained by performing training on the basis of a plurality of sample image and text pairs and sample parameter information carried by the plurality of sample image and text pairs; and inputting the image generation parameters and the image description text into an image generation model to obtain a target image corresponding to the image description text. By using a parameter generation model to perform semantic decomposition on visual elements of an image to obtain image generation parameters, and further completing accurate image generation on the basis of the image generation parameters, a target image can clearly express an image description text and the image generation parameters, thereby improving the interpretability and controllability of image generation.","['G06T11/001', 'G06F40/30']"
CN118298062A,"Image generation method, device, electronic equipment and storage medium","The embodiment of the disclosure provides a method, a device, an electronic device and a storage medium for generating an image. The method comprises the following steps: extracting an original image containing target face characteristics from a video fragment uploaded by a user, training to obtain a first style model based on the original image, and acquiring a second style model and a prompt word corresponding to a target style appointed by the user aiming at the target style; fine tuning a basic image generation model based on the first style model and the second style model to obtain a target image generation model, and inputting the prompt word into the target image generation model to obtain an initial style synthesized image output by the target image generation model; and carrying out fusion processing on the face region in the initial style synthesized image and the face region in the standard image containing the target face features, and outputting the processed target style synthesized image to the user.","['G06T11/001', 'G06N3/045', 'G06N3/082', 'G06T5/50', 'G06V40/168', 'G06T2207/20221', 'G06T2207/30201']"
WO2024035972A1,"Systems and methods that involve bci (brain computer interface) and/or extended reality/eye- tracking devices, detect mind/brain activity, generate and/or process saliency maps, eye-tracking information and/or various controls or instructions, implement mind-based selection of ui elements and/or perform other features and functionality","Systems and methods associated with mind/brain-computer interfaces are disclosed. Certain implementations may include or involve processes of collecting and processing brain activity data, such as those associated with the use of a brain-computer interface that enables, for example, decoding and/or encoding a user's brain functioning, neural activities, and/or activity patterns associated with thoughts, including sensory -based thoughts. Consistent with various aspects of the disclosed technology, systems and methods herein include functionality whereby a user can hands-free select or click UI elements in a mixed reality environment or on a 2D computer, phone or other such screen. In some embodiments, the disclosed technology may involve a brain-interface that can decode where the user is looking (i.e., determine their visual attention) and also decode their intention to select or 'click' the UI element desired. The user's intention to select or 'click' the UI element (the 2nd step) can be achieved through an imagined movement or an imagined word.","['G06F3/04842', 'G06F3/011', 'G06F3/013', 'G06F3/015', 'G06F2203/011']"
WO2024049441A1,Latent prior embedded network for restoration and enhancement of images,"Novel tools and techniques are provided for implementing latent prior embedded network for restoration and enhancement of images (e.g., facial image, or the like). In various embodiments, a computing system may map, using an embedding network (""Network M"") that was previously trained, an input image into a first vector, the input image being a low quality image suffering from one or more unknown degradation effects; may perform, using a latent prior embedded network (""LPEN"") that was previously trained, reverse diffusion on the first vector to produce a second vector, based on a trained diffusion model (""DM"") of the LPEN, the second vector being a denoised version of the first vector; and may decode, using a trained decoder of the LPEN, the second vector to produce an output image corresponding to the input image, the output image being a restored and enhanced version of the input image.","['G06T5/70', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/0464', 'G06N3/0495', 'G06N3/094', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11421656B2,Generative system,A generative sensing system includes a plurality of fairings attached to a carrier via a plurality of mechanical links and further associated with a plurality of actuators in communication with a computing system and a memory in communication with the computing system storing a plurality of fairing groups. The computer system is configured to receive and input from a sensor and adjust the fairing groups to capture an agent flow which is transduced to a voltage and transferred to an electrical energy storage and/or distribution system.,"['F03D9/11', 'B25J9/08', 'B25J19/005', 'B25J9/1617', 'F03D7/00', 'H02J7/0042', 'Y02E10/72', 'Y02E70/30']"
CN118097363B,Face image generation and recognition method and system based on near infrared imaging,"The invention relates to the field of image recognition, and provides a face image generation and recognition method and system based on near infrared imaging, which converts a collected near infrared face image into a high-quality visible face synthetic image according to preset guiding information by designing an image conversion generation module, solves the problem of modal difference between the near infrared image and the visible face image, and designs a recognition network, the characteristics of the visible light face synthesized image and the near infrared face image are fused, the problems of gender conversion, face widening and consistent color tone of the visible light image generated after conversion are solved, and the spatial attention mechanism and the channel attention mechanism are combined through the multi-head attention module, so that the key characteristics of face recognition are further enhanced, and the face recognition efficiency and the anti-interference capability are greatly improved.","['G06V10/806', 'G06V40/161', 'G06V40/168']"
WO2025136469A1,Storage device with generative ai capability,"A storage device, comprises a storage controller, a flash memory and a neural processor. The neural processor is configured to retrieve a base asset from memory and generate a derivative asset using the base asset.","['G06F3/0679', 'G06F3/0658', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06F3/0604']"
CN118401958A,Diffusion-based multi-modal image fusion,"The image guided diffusion network has two Convolutional Neural Networks (CNNs). The RGB and IR images are stitched together with gaussian noise images and input to a denoising neural network that combines information from the RGB and IR images while removing noise through multiple iterations. The enhanced neural network then upsamples the Super Resolution (SR) and convolves it to generate a condition vector, controlling the Global Feature Modulation (GFM) of the three convolved layers, thereby generating SRGFM enhanced fusion images. Embedding time steps within an Adaptive Block Residual (ABR) block using an adaptive packet normalization block in a denoising network, the network being a UNet having a plurality of ABR levels; in enhanced networks, this embedding approach is also used prior to feature modulation. Global image features are detected by three convolved images input to an enhancement network to generate a condition vector that controls feature modulation blocks on three convolved layers.",[]
US20240199071A1,Generating a driving assistant model using synthetic data generated using historical shadow driver failures and generative rendering with physical constraints,"A method for generating a driving assistant model, comprising: computing at least one semantic driving scenario by computing at least one permutation of at least one initial semantic driving scenario; providing the at least one semantic driving scenario to a simulation generator to produce simulated driving data describing at least one simulated driving environment; training a driving assistant model using the simulated driving data to produce a trained driving assistant model; and providing by the trained driving assistant model at least one driving instruction to at least one autonomous driving model while the at least one autonomous driving model is operating.","['B60W60/001', 'G06F30/27', 'B60W50/06', 'B60W2050/0019', 'B60W2050/0075', 'B60W2556/00']"
US20250200353A1,Techniques for augmented machine learning with respect to variations of objects,"A system and method for augmented machine learning. A method includes synthesizing a plurality of second visual content samples, wherein synthesizing the plurality of second visual content samples further comprises removing at least a portion of a plurality of first visual content samples with respect to an object in order to create a plurality of removed portion visual content items and providing the plurality of removed portion visual content items to a generative machine learning model, wherein the generative machine learning model is trained to generate at least a portion of visual content with respect to the plurality of removed portion visual content items; creating a training set including the synthesized visual content samples; and training a machine learning model using the training set, wherein the machine learning model is trained to classify visual content with respect to the object.","['G06N3/08', 'G06N3/0455', 'G06N3/0475']"
WO2024249830A2,Systems and methods for synthesizing image data,"Systems, methods, and software that generate synthetic image data based on an original dataset. Some embodiments utilize a variational autoencoder trained on an original dataset to generate a latent space dataset to train a denoising diffusion model to generate synthetic latent space data which is then converted to a synthetic image by the trained decoder circuitry of the variational autoencoder. Some embodiments include enhanced privacy protection in which the original images and the synthetic images are converted to vectors, the L2 distance between a synthetic image vector and each original image vector is compared, and synthetic images for which the L2 distance is below a selected threshold are removed from the synthetic dataset.","['G16H30/20', 'G16H30/40']"
US12361689B1,System and method for augmenting autonomous vehicle training data,"In variants, a method for generating synthetic data can include: determining an initial dataset, determining characteristics of the initial dataset, generating a set of prompts based on the characteristics, prompting a model to generate the synthetic data using the set of prompts, and training an AV model using the synthetic data.","['G06V20/64', 'B60W50/00', 'B60W60/001', 'G06T11/00', 'G06V10/7715', 'G06V10/774', 'G06V10/7747', 'G06V20/41', 'G06V20/56', 'B60W2050/0028', 'G06T2210/61']"
US20240203005A1,Automated evaluation of spatial relationships in images,"This document relates to automated analysis of images. One example method involves obtaining an image and text associated with the image, detecting two or more objects in the image, and determining respective locations of the two or more detected objects in the image. The example method also involves determining whether a spatial relationship between the two or more detected objects matches a corresponding spatial relationship expressed by the text based at least on the respective locations of the two or more detected objects. The example method also involves outputting a value reflecting whether the spatial relationship between the two or more detected objects matches the corresponding spatial relationship expressed by the text.","['G06F40/40', 'G06T11/60', 'G06T7/11', 'G06T7/60', 'G06T7/75', 'G06T2207/20081']"
US20250133238A1,Network intermediary transcoding for diffusion-based compression,"A method includes receiving input frames of video information. An uplink channel receives a requirements indication from a mobile device configured to implement a diffusion model. Based upon the requirements indication, a current video coding modality is selected from among a first video coding modality and a second video coding modality where the first video coding modality utilizes diffusion, and the second video coding modality does not utilize diffusion. Video coding data is generated by processing the input frames of video information using the current video coding modality. The video coding data is sent to the mobile device.","['G06V10/82', 'H04N19/70']"
US12100383B1,Voice customization for synthetic speech generation,"Voice customization is an application of voice synthesis that involves synthesizing speech having certain voice characteristics, and/or modifying the voice characteristics of human speech. Certain techniques for voice customization may be used in conjunction with compressing speech for storage and/or transmission. For example, speech may be received at a first device and transformed into a latent representation and/or compressed for storage and/or transmission to a second device. The system may use normalizing flows to transform the source audio to a latent representation having a desired variable distribution, and to transform the latent representation back into audio data. A flow model may conditioned using first speech attributes when transforming the source audio, and an inverse flow model may use second speech attributes when transforming the latent representation back into audio data. The first and/or second speech attributes may be modified to alter voice characteristics of the transmitted speech.","['G06N3/045', 'G10L13/047', 'G10L25/30']"
US20250156300A1,Confusion Matrix Estimation in Distributed Computation Environments,"An example method includes: serving content to a plurality of client devices associated with a plurality of tag values; predicting, using a prediction system, a plurality of attributes respectively associated with the plurality of tag values; generating a data sketch descriptive of the plurality of predicted attributes; noising the data sketch, wherein the noised data sketch satisfies a differential privacy criterion; transmitting the noised data sketch to a reference system; and receiving, from the reference system, estimated performance data associated with the predicted attributes, wherein the estimated performance data is based on an evaluation of: reference attribute data associated with one or more of the plurality of tag values and the predicted attributes for the one or more of the plurality of tag values.","['G06N20/00', 'G06F11/3452', 'G06F16/2255', 'G06F21/6254', 'G06N3/084', 'G06N3/092', 'G06N3/098', 'H04L63/0428']"
CN116959625A,A material formula optimization method and system based on rheological data and machine learning,"The invention discloses a material formula optimization method and system based on rheological data and machine learning. The invention takes rheological characteristics as input of a machine learning model, so as to optimize material parameters, formula variables and process parameters of the polymer. The method does not directly statistically correlate physical response with material variables, but embeds the middle layer based on basic polymer physics principles and rheology theory for communicating the structural variables with the bottom layer and the top layer of the response, and realizes integration and predictive modeling of three layers based on a rheology data set.","['G16C20/70', 'G16C20/10', 'G16C20/20']"
CN112417467B,An image encryption method based on anti-neural cryptography and SHA-controlled chaos,"The invention discloses an Image encryption method based on antagonistic neurocryptography and SHA control chaos, based on Antagonistic Neurocryptography (ANC), secure Hash Algorithm (SHA) and Image Encryption (IE) algorithm, all pixels in an Image P are input into a hash function SHA-256 to obtain a hash value, and the hash value is represented as a binary number with the length of 256 and normalized to a value in the range of (0,1); and the method of generating the key to control the chaotic mapping by relying on the SHA-256 algorithm of the plaintext greatly improves the diffusion performance of the encryption system, so that the system can further resist differential attack and can resist common attacks such as only ciphertext attack, ciphertext attack selection attack, known plaintext attack, plaintext attack selection and the like. The method can be used in the field of information security transmission such as image storage and transmission of the Internet, mobile phones and video conferences.","['G06F21/602', 'G06N3/045', 'G06N3/08']"
US12367234B2,Gaze assisted search query,"A system enables a user to query based on a user's gaze by receiving a query from the user and capturing, via an eye tracking system on a headset, the user's gaze location near an object in a local area. The system captures one or more images of the local area with the object and formats the images based in part on a region of interest in the one or more images that includes the object. The system generates a formatted query based in part on the query. The formatted query is provided to a search engine. Information describing the object determined from the one or more formatted images and information describing the query are used by the search engine to determine an answer to the query about the object. The system presents the answer to the query about the object.","['G06F16/532', 'G06F16/9535', 'G06F16/9538', 'G06F3/013', 'G06T3/40']"
US20240212228A1,"Image generating and retrieving apparatus, image generating and retrieving system, and image generating and retrieving method","Provided is an image generating and retrieving apparatus that enables a user to easily find a desired image from a large number of image generation results. A similarity is calculated from a text feature amount and an image feature amount, a similar image similar to a retrieval target is retrieved from an image text database using the similarity, and an image generation process held in the image text database is visualized.","['G06T11/00', 'G06F16/532', 'G06F16/583', 'G06V10/44', 'G06V2201/07']"
WO2024212997A1,"Image processing method, weather image restoration method, and image data processing method","Provided in the embodiments of the present description are an image processing method, a weather image restoration method, and an image data processing method. The image processing method comprises: acquiring an image to be processed; and inputting said image into an image processing model, so as to obtain a target image, wherein the image processing model is obtained by means of performing training by using a sample image set, which is obtained by means of performing image mapping on at least one initial image in an initial image set by using a preset mapping relationship, the preset mapping relationship is a mapping relationship between a historical source image and a historical target image, and the historical source image and the historical target image are used for training the image processing model in advance. On the basis of a predetermined mapping relationship between a historical source image and a historical target image, features of a historical image are restored, the storage of a large number of historical images is avoided, and a sample image set that includes the current knowledge and historical knowledge is obtained for training an image processing model, thereby ensuring the comprehensiveness and accuracy of image processing, reducing the storage cost, and improving the processing efficiency.","['G06T5/00', 'G06N3/04', 'G06N3/08', 'G06V10/44', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/30192']"
CN116188250A,"Image processing method, device, electronic equipment and storage medium","The disclosure relates to an image processing method, an image processing device, an electronic device and a storage medium. The method comprises the following steps: displaying an image stylization processing page, wherein the image stylization processing page is provided with a content image input area and a style information input area; and responding to the first image input by the content image input area and the style characterization information input by the style information input area, and displaying the second image processed into a target style on the image stylized processing page in an increment mode, wherein the target style is the style indicated by the style characterization information. According to the technical scheme provided by the disclosure, the efficiency and the precision of image stylization processing can be improved.","['G06T3/04', 'G06V10/74']"
CN117351937A,"Speech synthesis method, device, electronic equipment and storage medium","The invention provides a voice synthesis method, a device, an electronic device and a storage medium, wherein the method comprises the following steps: extracting features of the target voice to obtain target voice features, wherein the target coarse-granularity voice features and the target fine-granularity voice features in the target voice features are different in characterization information; determining a voice feature to be synthesized based on the target voice, the text to be synthesized and the target voice feature, wherein the voice feature to be synthesized comprises a coarse-granularity voice feature to be synthesized and a fine-granularity voice feature to be synthesized; based on the characteristics of the voice to be synthesized, the synthesized voice corresponding to the text to be synthesized is determined, and the voice synthesis is performed through the characteristics of the voice to be synthesized, which are rich in pronunciation and tone on two layers of coarse and fine granularity, so that the effect of the voice synthesis can be effectively improved, the defects of the existing synthesized voice in tone and pronunciation habits and poor voice synthesis effect are overcome, the fidelity of the synthesized voice in tone and pronunciation habits is optimized, and the reality and nature of the synthesized voice are ensured.","['G10L13/08', 'G10L13/02', 'G10L25/30']"
CN116797768A,Method and device for reducing reality in panoramic images,"The disclosure provides a method and a device for reducing reality of a panoramic image, which are applied to indoor scenes and comprise the following steps: generating layout features based on the obtained masked layout boundary image, the mask image and the masked panoramic image, wherein the layout features represent structural features of the original panoramic image on a layout layer, generating a style matrix corresponding to a structured area of an indoor scene based on the obtained masked panoramic image and the original panoramic image, wherein the style matrix represents structural semantic information corresponding to the structured area, filling a preset structured mask according to the style matrix to obtain structural area texture features, carrying out panoramic image restoration processing according to the layout features and the structural area texture features to obtain a predicted image corresponding to the masked panoramic image, and combining reality restoration capability with a boundary structure, and also keeping the structure of the indoor scene while generating a background texture comprising reality.","['G06T19/20', 'G06T19/006']"
CN118197329A,Tone color generation method based on voice conversion,"A tone color generation method based on speech conversion, comprising: processing the input raw acoustic features using a speaker encoder based on a variance-from-encoder VAE to extract speaker-embedded vectors and map the speaker-embedded vectors into a continuous potential space; based on the speaker embedded vector, using HuBERT-based soft speech units as a content encoder, obtaining a new clustering sequence by reasoning and reclustering training data, and predicting the clustering sequence to generate acoustic characteristic representations related to language content; training a discriminant to reduce its ability to distinguish between generated data points and resampled data points using representation of speaker characteristics through countermeasure training using empirical and factorial posterior distributions in the variational self-encoder; based on the speaker characteristic representation adjusted by the countermeasure training, acoustic characteristic information of the target tone color is generated using a decoder.","['G10L21/007', 'G10L19/18', 'G10L25/18']"
CN119251413B,Method and device for generating three-dimensional model of building space design,"The application provides a generation method and a generation device of a three-dimensional model of a building space design, wherein the generation method comprises the steps of obtaining a planar structure diagram and text description information based on a target building to generate a three-dimensional model of a space layout of the target building, generating an object sequence corresponding to a scene by utilizing a plurality of facility three-dimensional models to be screened, determining a plurality of target facility three-dimensional models and space attributes of each target facility three-dimensional model from the plurality of facility three-dimensional models to be screened based on the object sequence, and placing each target facility model in a model area corresponding to the scene in the three-dimensional model of the space layout based on the space attributes of each target facility three-dimensional model so as to generate the three-dimensional model of the space design meeting the indoor design requirement. By the method and the device, the reconstructed indoor layout and the generated facility model are organically combined, and the overall space design aiming at the specific scene is completed.","['G06T17/00', 'G06F30/13', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06T15/04']"
US20250266121A1,A method for protein design,"Provided is a computer implemented method for designing at least one protein includes creating at least one amino acid sequence to be tested, wherein ones of the amino acids, contained in the amino acid sequence to be tested, are selected according to a probability distribution; predicting, from the aligned at least one amino acid sequence, structural properties of the at least one protein; calculating, based on the structural properties of the at least one protein, a value of a fitness function for the at least one amino acid sequence to be tested; selecting or deselecting, dependent on the value of the fitness function, the at least one amino acid sequence to be tested. The amino acid sequence may be post-processed to be more native-like, have enhanced solubility, and/or improved expression.","['G16B15/20', 'G16B15/30', 'G16B30/00', 'G16B40/20']"
AU2024200505A1,Animated facial expression and pose transfer utilizing an end-to-end machine learning model,"OF THE DISCLOSURE The present disclosure relates to systems, methods, and non-transitory computer readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06T13/40', 'G06V40/176', 'G06T13/80', 'G06T19/20', 'G06T5/60', 'G06T5/70', 'G06T5/77', 'G06T7/10', 'G06T7/11', 'G06T7/251', 'G06V10/82', 'G06V10/95', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30196', 'G06T2207/30201']"
US20240403714A1,Generative artificial intelligence user interface server,"Systems and methods are disclosed relating to building management systems with building equipment servicing. For example, a system can include at least one machine learning model configured using training data that includes at least one of unstructured data or structured data regarding items of equipment. The system can provide inputs, such as prompts, to the at least one machine learning model regarding an item of equipment, and generate, according to the inputs, responses regarding the item of equipment, such as responses for detecting a cause of an issue of the item of equipment, performing a service operation corresponding to the cause, or guiding a user through the service operation.","['G06N20/00', 'G06N3/045', 'G06N3/047']"
WO2025112801A1,Deep learning model training method and deep learning model training system,"Embodiments of the present disclosure provide a deep learning model training method and a deep learning model training system. The deep learning model training method comprises: acquiring an initial deep learning model and a sample data set; and performing distributed training on the deep learning model on the basis of the sample data set according to a preset distributed training policy, and during the adjustment parameter calculation for distributed training, storing model parameters of the deep learning model on the basis of target storage parameters, wherein the target storage parameters are determined on the basis of model specification information of the deep learning model and the preset distributed training policy. The target storage parameters are determined on the basis of the model specification information of the deep learning model and the preset distributed training policy, which fully takes into account the iteration patterns of distributed training, and during the adjustment parameter calculation, the model parameters of the deep learning model are stored on the basis of the target storage parameters, so that high efficiency is achieved while enabling the training of the deep learning model to have high fault tolerance.","['G06N3/098', 'G06N3/084', 'Y02D10/00']"
US20190294754A1,Systems and methods for growth-based design,"Systems and methods are disclosed for generating designs for mechanical parts in a computer aided design (CAD) context. One method includes generating a mechanical part modeling design space including a first cell, the first cell comprised of a parameterized representation of a physical material property; determining, for the first cell, fixed location parameters and a first growth vector; receiving a target location inside the modeling design space; associating the received target location with the first growth vector; generating, along the first growth vector, a second cell, the second cell being positioned between the first cell and the target location; and generating a third cell positioned between the second cell and the target location.","['G06F17/5086', 'G06F30/17', 'G06F30/00', 'G06F30/20', 'G06F30/23', 'G06F2111/02', 'G06F2119/18', 'G06F30/333', 'H04L67/10']"
CN106873178A,Electronic type ophthalmic lens with oscillator frequency regulation,"The present invention is entitled "" having the electronic type ophthalmic lens of oscillator frequency regulation "".The present invention describes a kind of eyelid position sensor system for the ophthalmic lens including electronic system, and the eyelid position sensor system is used to adjust the oscillator frequency on eyeglass.In at least one embodiment, frequency regulation is based at least one signal received by haptic lens.In another embodiment, at least one signal includes the signal for providing multiple transformations with the transformation in comparison oscillator output signal.In at least one embodiment, the source of external signal is lighting apparatus.In at least one embodiment, the oscillator frequency between two eyeglasses is updated.","['G02C7/047', 'G02C11/10', 'A61B3/11', 'A61B3/101', 'A61F9/00', 'G02C7/04', 'H03L7/00', 'H03L7/085']"
CN117170559A,"Image generation method and device, electronic equipment and storage medium","The present disclosure provides an image generation method, an image generation device, an electronic device, and a storage medium, where the method includes: and responding to the prompt word input operation, inputting a target prompt word, displaying the target prompt word on a drawing operation interface, generating a target keyword according to the target prompt word, displaying the target keyword on the drawing operation interface, generating a target image according to the target keyword, and displaying the target image.",[]
CN116258874A,SAR recognition database sample gesture expansion method based on depth condition diffusion network,"The invention discloses a SAR recognition database sample gesture expansion method based on a depth condition diffusion network, which comprises the following steps: constructing a training data set by utilizing a plurality of real SAR images, wherein the training data set comprises a plurality of target categories, and each category comprises a plurality of image samples; the method comprises the steps of constructing a depth condition diffusion network, wherein the depth condition diffusion network comprises a time step coding module, a category label coding module, an azimuth angle coding module, a coding fusion module, a feature map construction module, a plurality of downsampling modules, a plurality of intermediate transition modules, a plurality of upsampling modules and an image restoration module; training the depth condition diffusion network by utilizing a training data set to obtain a trained depth condition diffusion network; SAR images are generated using a trained depth condition diffusion network. The SAR image processing method and the SAR image processing system can generate the SAR image with high quality and specified category and azimuth angle, thereby realizing the expansion of the sample number and the gesture of the SAR recognition database.","['G06V10/72', 'G06N3/08', 'G06V10/44', 'G06V10/764', 'G06V10/80', 'G06V10/82', 'G06V20/10']"
CN118174918A,"Electric power Internet of things attack behavior detection method, system, device and medium","The invention belongs to the technical field of information security of the Internet of things, and particularly relates to a method for detecting an attack behavior of the Internet of things by electric power. Aiming at the defect of poor recognition effect of the existing anomaly detection method based on the generation countermeasure, the invention adopts the following technical scheme: the electric power Internet of things attack behavior detection method based on boundary generation countermeasure network comprises the following steps: grabbing network flow data, and preprocessing to obtain statistical characteristics; normalizing the statistical characteristics to obtain a stream characteristic vector; constructing an intrusion detection model of the boundary-based generation countermeasure network; inputting the stream feature vector into a generator for training, so that the feature vector generated by the generator is not only inside a malicious flow sample, but also covers the whole boundary of real data distribution; training a discriminator, namely positioning the generated sample at the boundary of the real attack data distribution through super-parameter trimming, and outputting the score as a judging threshold; a fraction of the power network traffic is calculated. The beneficial effects of the invention are as follows: and the detection effect is improved.","['H04L63/1416', 'H04L63/1425', 'Y04S40/20']"
US12079902B2,Generation of images corresponding to input text using multi-algorithm diffusion sampling,"Systems and methods are provided that include a processor executing a program to process an initial image through a first diffusion stage to generate a final first stage image, wherein the first diffusion stage includes using a diffusion model, a gradient estimator model smaller than the diffusion model, and a text-image match gradient calculator. The processor further executes the program to process the final first stage image through a second diffusion stage to generate a final second stage image. The second diffusion stage includes, for a second predetermined number of iterations, inputting the final first stage image to through the diffusion model, back-propagate the image through the text-image match gradient calculator to calculate a second stage gradient against the input text, and update the final first stage image by applying the second stage gradient to the final first stage image.","['G06T11/00', 'G06F18/214', 'G06F18/22', 'G06F40/30', 'G06F40/40', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T5/70']"
CN120145864A,A comparative learning topology optimization method and system based on residual network,"The invention discloses a contrast learning topology optimization method and system based on a residual error network, aiming at optimizing structural design to meet specific physical constraint. In the first step, a multi-channel tensor format is constructed by preparing a physical domain, a volume fraction, a displacement boundary condition, and a load condition as input data. And the second step and the third step respectively utilize two cGAN networks to generate stress and strain distribution fields, so as to provide necessary physical information for subsequent structural optimization. And fourthly, inputting the generated stress field and the generated strain field into a third cGAN in combination with the original physical domain to generate a final topological optimization structure. And fifthly, introducing a contrast learning discriminator, and enhancing the identification capability of the network to the topological feature by comparing the reference structure generated by the SIMP method with the structure output by the generator. Finally, the output optimized topological structure realizes the optimal configuration of material distribution on the premise of conforming to physical constraint. The method combines deep learning and structure optimization, and is expected to provide an effective design scheme in engineering practice.","['G06F30/27', 'G06F30/18', 'G06F30/23', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/0895', 'G06N3/094', 'G06F2119/14']"
US20250139487A1,Differentiable generative modelling using a hybrid computer including a quantum processor,"Disclosed is an approach for learning probability distributions as differentiable quantum circuits (DQC) that enable efficient quantum generative modelling (QGM) and synthetic data generation. A method includes training of a differentiable quantum circuits (DCQ) based model, where data is encoded in a latent space with a phase feature map, followed by a variational quantum circuit. The trained model is then mapped to the bit basis using a fixed unitary transformation, coinciding with a quantum Fourier transform circuit in the simplest case. This allows fast sampling from parametrized distributions using a single-shot readout. Simplified latent space training provides models that are automatically differentiable. Samples from propagated stochastic differential equations (SDEs) can be accessed by solving a stationary Fokker-Planck equation and time-dependent Kolmogorov backward equation on a quantum computer. A route to multidimensional generative modelling is opened with qubit registers explicitly correlated via a (fixed) entangling layer.","['G06N10/60', 'G06N10/20', 'G06N3/0475']"
CN116645950A,"Audio generation method, device, electronic equipment and storage medium","The invention discloses an audio generation method, an audio generation device, electronic equipment and a storage medium. The audio generation method comprises the following steps: acquiring a first input voice and determining first text information corresponding to the first input voice; acquiring target sensing data, and determining target text characteristics according to the first text information and the target sensing data, wherein the target text characteristics comprise requirements, scenes and fault information; and carrying out audio generation on the input target text features through an audio generation large model to obtain target audio corresponding to the target text features, wherein the audio generation large model is obtained by training an artificial intelligence generation content large model based on a vehicle operation instruction and a vehicle operation image, and the vehicle operation instruction comprises vehicle operation schemes under the conditions of various requirements, scenes and fault information. According to the technical scheme provided by the embodiment of the invention, the universality and the efficiency of the audio generation can be improved, and the accuracy of the generated target audio can be improved.","['G10L13/02', 'G10L13/08', 'G10L15/063', 'G10L15/26', 'G10L2015/0631', 'Y02T10/40']"
CN118069820B,"Conversational data analysis method, device, equipment and storage medium","The invention discloses a dialogue type data analysis method, a device, equipment and a storage medium, which relate to the technical field of medical informatization processing and comprise the following steps: acquiring dialogue texts input by a user, and executing information extraction operation on the dialogue texts based on keyword extraction rules so as to obtain extracted text contents; acquiring corresponding real data based on the extracted text content, and acquiring a current function to be executed, which is obtained by analyzing a dialogue text through a pre-trained target session model; determining a current operation to be executed corresponding to the previous function to be executed so as to execute the current operation to be executed based on the extracted text content and obtain a corresponding execution result; and generating corresponding result display information based on the execution result and the user requirement and outputting the result display information. According to the invention, the current data analysis requirement of the user is extracted in a natural language dialogue form, the index and the dimension information are directly determined and analyzed, the final analysis requirement of the user is met, the communication process is simplified, and the data analysis efficiency is improved.","['G06F16/3329', 'G06F16/3344', 'Y02D10/00']"
US20240331344A1,Method and system for anonymizing facial images,A computer-implemented method for anonymizing a facial image includes detecting one or more sets of facial keypoints in the facial image. The method further includes standardizing the facial image. The method further includes preparing a masked facial image by separating one or more areas comprising skin-pixels and one or more areas comprising pixels related to non-skin information. The method further includes generating a synthetic image comprising photo-realistic skin patterns. The method further includes obtaining an anonymized facial image by concatenating the masked facial image with the generated photo-realistic skin patterns.,"['G06T11/60', 'G06V10/462', 'G06N3/088', 'G06T3/4046', 'G06T9/002', 'G06V10/141', 'G06V10/22', 'G06V40/161']"
US20250117973A1,Style-based image generation,"A method, apparatus, non-transitory computer readable medium, and system for media processing includes obtaining a text prompt and a style input, where the text prompt describes image content and the style input describes an image style, generating a text embedding based on the text prompt, where the text embedding represents the image content, generating a style embedding based on the style input, where the style embedding represents the image style, and generating a synthetic image based on the text embedding and the style embedding, where the text embedding is provided to the image generation model at a first step and the style embedding is provided to the image generation model at a second step after the first step.","['G06T11/00', 'G06T11/001', 'G06T11/60', 'G06T2211/441']"
CN116109719A,Fair controllable image generation method based on structured network priori knowledge,"The invention discloses a fair controllable image generation method based on structured network priori knowledge, and belongs to the field of computer vision. In the first stage, the loss is guided by the structural priori knowledge, good initialization parameters are provided for the encoder network, so that the encoder has the differential representation capability of representing the real image before formal training, and direction guiding and initial guarantee are provided for the encoder to more comprehensively cover the real image data. In the second stage, a good encoder guided by the structured priori knowledge is used for providing attribute control constraint for the generation reactance network, and the sustainability of the real image representation extraction capability learned by the encoder is ensured through auxiliary similarity loss. In addition, the invention provides a higher characteristic dimension and linear layer batch standardization strategy, so that the representation and extraction capacity of the model is further improved; the fairness of the model in the image generation process is remarkably improved, and meanwhile, the accuracy of attribute control of the model is improved.","['G06T11/00', 'G06N3/08', 'G06V10/761']"
CN112419203B,Diffusion-weighted image compression sensing restoration method and device based on confrontation network,"The application discloses a diffusion weighted image compressed sensing restoration method and device based on an countermeasure network, wherein the method comprises the following steps: acquiring a diffusion weighted image DWI airspace image; undersampling the DWI airspace image to obtain an undersampled airspace image; inputting the undersampled spatial image into a generator, and inputting the DWI spatial image into a discriminator; alternately training the generator and the discriminator to perform countermeasure, and obtaining network parameters corresponding to the neural network of the generator and/or the discriminator; and recovering the undersampled DWI which needs to be recovered by using the obtained network parameters. The method solves the problem that the existing artifact and noise removing method does not have learning ability, calculates by using the neural network model, so that the neural network model has learning type, improves the calculation efficiency, and saves hardware calculation resources to a certain extent.","['G06T5/70', 'G06N3/045', 'G06N3/08', 'G06T2207/10088', 'G06T2207/20081']"
US20240395278A1,Universal speech enhancement using generative neural networks,"The disclosure relates to a neural network based system for speech enhancement, comprising a generative network for generating an enhanced audio signal and a conditioning network for generating conditioning information for the generative network. The conditioning network comprises a plurality of layers and is configured to receive an audio signal as input: propagate the audio signal through the plurality of layers; and provide one or more first internal representations of the audio signal or processed versions thereof as the conditioning information, wherein the one or more first internal representations of the audio signal are extracted at respective layers of the conditioning network. The generative network is configured to receive a noise vector and the conditioning information as input; and generate the enhanced audio signal based on the noise vector and the conditioning information. The disclosure further relates to a method of training the system.","['G10L21/02', 'G10L21/0216', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G10L21/0264', 'G10L25/30', 'G06N3/084']"
CN116386725A,Method and system for predicting tumor differential gene expression profile by combining pathological characteristics,"The invention belongs to the technical field of computers, and provides a method and a system for predicting a tumor differential gene expression profile by combining pathological characteristics. The model training method comprises the steps of obtaining a nuclear characteristic spectrum of a specific tumor area of a digital pathological section according to data of the data pathological section; obtaining a queue gene expression matrix according to transcriptomics data; determining cancer tissues, normal tissue samples and clinical diagnosis stages of the cancer samples according to the queue gene expression matrix and clinical information of patients, and carrying out gene differential expression analysis to obtain differential gene expression profiles of specific tumors and differential gene expression profiles of specific tumor stages; taking the nuclear characteristic spectrum of a specific tumor area of the digital pathological section as input, and taking the differential gene expression spectrum of the specific tumor and the differential gene expression spectrum of the specific tumor stage as output, training and generating a formula model. The invention greatly reduces the sample sequencing cost and improves the prognosis efficiency of the subsequent diagnosis.","['G16B25/10', 'G06V10/82', 'G06V20/69', 'G06V20/695', 'G16B30/10', 'G16B40/00', 'Y02A90/10']"
US12346386B2,Visual and audio multimodal searching system,"A multimodal search system is described. The system can receive image data captured by a camera of a user device. Additionally, the system can receive audio data associated with the image data. The audio data can be captured by a microphone of the user device. Moreover, the system can process the image data to generate visual features. Furthermore, the system can process the audio data to generate a plurality of words. The system can generate a plurality of search terms based on the plurality of words and the visual features. Subsequently, the system can determine one or more search results associated with the plurality of search terms and provide the one or more search results as an output.","['G06V10/255', 'G06F16/9532', 'G06F16/538', 'G06F16/9032', 'G06F40/40', 'G06F16/00', 'G06F3/167']"
US20240314164A1,Detecting cyber threats using artificial intelligence,"Approaches in accordance with various illustrative embodiments provide for the generation of synthetic communications for use in training and fine-tuning threat detection models for various categories of recipients. In at least one embodiment, guidelines can be determined for a category of recipient that can be used to generate multiple types of content using generative artificial intelligence (AI), as may include text, image, and file content. A training communication can be generated using these types of content, such as to generate an email message that corresponds to a potential spear phishing attack. The generated messages can be checked for quality, and any messages that are caught by existing filters can be deleted or regenerated so that only high quality examples of spear phishing are provided as output. These training communications can be used to train a spear phishing detector for a specific category of recipient, in order to accurately flag and prevent access to actual spear phishing communications.",['H04L63/1483']
CN117437365A,"Medical three-dimensional model generation method, device, electronic equipment and storage medium","The application provides a method and a device for generating a medical three-dimensional model, electronic equipment and a storage medium, and relates to the technical field of computers. The method for generating the medical three-dimensional model comprises the following steps: responding to input operation in the interactive interface, and acquiring medical text; invoking a first generation network, and under the guidance of a medical text, learning a first tensor input into the first generation network to obtain a medical two-dimensional image conforming to the description of the medical text; the first generation network is a trained deep learning model with the capability of generating two-dimensional images from medical text to medical science; inputting the medical two-dimensional image into a second generation network to generate a medical three-dimensional model; the second generation network is a trained deep learning model with generation capabilities from a medical two-dimensional image to a medical three-dimensional model; and displaying the medical three-dimensional model generated by the second generation network in the interactive interface. The method and the device solve the problem of poor reality of the medical three-dimensional model in the related technology.","['G06T17/00', 'G06F3/04815']"
CN111445546A,"Image reconstruction method and device, electronic equipment and storage medium","The invention discloses an image reconstruction method, an image reconstruction device, electronic equipment and a storage medium. The method comprises the following steps: acquiring a first diffusion weighted image in the process of controlling scanning equipment to scan a target object by using a diffusion weighted sequence with a diffusion sensitivity coefficient of zero; inputting the first diffusion weighted image into a plurality of image reconstruction models, wherein the plurality of image reconstruction models are used for carrying out image reconstruction on the input diffusion weighted image; performing exponential distribution fitting on the prediction weighted images with different diffusion sensitivity coefficients respectively output by the plurality of image reconstruction models to obtain a first exponential model; and acquiring a target diffusion sensitivity coefficient, and determining a diffusion weighted image for the target object according to the first exponential model and the target diffusion sensitivity coefficient. Therefore, the DWI calculation problem of a single b value is converted into the cDWI calculation problem of multiple b values, and the problem of low cDWI calculation precision caused by DWI images with less b values is solved.","['G06T11/003', 'G06T2210/41']"
CN114580534A,"Industrial data anomaly detection method and device, electronic equipment and storage medium","The application discloses an industrial data anomaly detection method, an industrial data anomaly detection device, electronic equipment and a storage medium, wherein the method comprises the following steps: acquiring historical operating data of the industrial equipment, obtaining a training data set according to the historical operating data, and dividing the training data set into a first training set and a second training set; establishing an initial classification model and an initial neural network judgment model; inputting the first training set and the second training set into an initial classification model and an initial neural network judgment model respectively for training to obtain a classification model with complete training and a neural network judgment model with complete training; and acquiring real-time industrial operation data, and respectively inputting the real-time industrial operation data into a classification model and a neural network judgment model which are trained completely, and judging whether the real-time industrial operation data is abnormal or not. The method improves the robustness and accuracy of the industrial data abnormity judgment, completes the reconstruction of the data while effectively judging the abnormal data, has the data cleaning capability, reduces the false alarm rate and improves the production efficiency.","['G06F18/241', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'Y02P90/02']"
US20240020336A1,Search using generative model synthesized images,"Disclosed embodiments provide techniques for search using generative model synthesized images. An image, or set of images, is generated based on a text query, and the generated image or images are used as input to an image-based search query. In some instances, this technique provides more comprehensive and effective search results. In cases where a user wishes to search for something for which no known image currently exists, disclosed embodiments can provide more effective results than a text-based query. Disclosed embodiments generate an input image based on the text query using generative model synthesized image techniques. The input image is used to perform an image-based search, and sorted results are returned. Disclosed embodiments are particularly useful when searching for visual art in the form of images and/or videos.","['G06F16/738', 'G06F16/735', 'G06F16/739', 'G06F16/7844', 'G06V10/82']"
US20240135513A1,Utilizing a warped digital image with a reposing model to synthesize a modified digital image,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06T5/005', 'G06T3/0093', 'G06T3/18', 'G06T5/60', 'G06T5/77', 'G06T7/11', 'G06T7/143', 'G06T7/194', 'G06T7/40', 'G06T7/70', 'G06V10/26', 'G06V10/44', 'G06V10/54', 'G06V10/764', 'G06V10/771', 'G06V10/806', 'G06V10/82', 'G06V20/20', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20036', 'G06T2207/20056', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30196', 'G06T2207/30201']"
WO2025066458A1,"Try-on image generation method and generation system, electronic device, and storage medium","Provided in the embodiments of the present application are a try-on image generation method and generation system, an electronic device, and a medium. The try-on image generation method comprises: acquiring the category of a target clothes and try-on image generation configuration information input by a user, and a user-uploaded image; in response to the user selecting a system dress form to generate a model try-on image, acquiring a target dummy model image, and model posture information of the target dummy model image; on the basis of the user-uploaded image and the target dummy model image, synthesizing a clothes canvas image; and on the basis of the clothes canvas image, the model posture information, the category and the try-on image generation configuration information, generating a first try-on image generation task, so that a preset server end generates a model try-on image of the target clothes on the basis of the first try-on image generation task. The method generates model try-on images on the basis of model postures selected by users, thereby improving the quality of model try-on images.","['G06Q30/0643', 'G06T19/20', 'G06T2200/04', 'Y02D10/00']"
WO2024233814A1,Prompt-driven image editing using machine learning,"A media application receives an initial image and a textual request to change the initial image, the initial image including a subject with a face. The media application generates, from the initial image, a preserving mask that corresponds to the face of the subject. The media application provides the textual request, the initial image, and the preserving mask as input to a diffusion model. The diffusion model outputs a denoised initial image based on the initial image; performs text conditioning of the textual request and forward diffusion to generate a noisy translated image that satisfies the textual request; and outputs based on the noisy translated image, extracted features, and self-attention maps, a denoised translated image. The media application blends the denoised initial image, the preserving mask, and the denoised translated image to form an output image, wherein the preserving mask prevents modification to the face from the initial image.","['G06T5/70', 'G06N3/0464', 'G06T11/00', 'G06T11/60', 'G06T5/50', 'G06T5/60', 'G06T2207/30201']"
US20240304010A1,Method and electronic device for detecting ai generated content in a video,"A method for detecting artificial intelligence (AI) generated content in a video, includes: receiving the video comprising a plurality of frames; detecting, an object, a person, and a background in each frame; determining pixel-motion information of each pixel in each frame; determining a relationship among the object, the person, and the background and the corresponding pixel-motion information in each frame; determining one or more intrinsic properties of the object, the person, and the background in each frame based on the relationship among the object, the person, and the background and the corresponding pixel-motion information; detecting inconsistent motion of the object, the person, and the background in at least one frame of the video based on the one or more intrinsic properties of the object, the person, and the background; and indicating AI generated content in the at least one frame based on the detected inconsistent motion.","['G06V10/774', 'G06T7/11', 'G06T7/20', 'G06V10/764', 'G06V10/806', 'G06V20/41', 'G06V20/46', 'G06V20/95', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30241', 'G06V10/82']"
WO2025006112A1,Controllable diffusion model based image gallery recommendation service,"Aspects of the disclosure include methods and systems for leveraging a controllable diffusion model for dynamic image search in an image gallery recommendation service. An exemplary method can include displaying an image gallery having a plurality of gallery images and a dynamic image frame. The dynamic image frame can include a generated image and an interactive widget. The method can include receiving a user input in the interactive widget and generating, responsive to receiving the user input, an updated generated image by inputting, into a controllable diffusion model, the user input. The method can include replacing the generated image in the dynamic image frame with the updated generated image.","['G06T11/60', 'G06F16/532', 'G06F16/535', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06T11/00', 'G06T7/13', 'G06T7/73', 'G06T2200/24', 'G06T2207/20092', 'G06T2207/30196']"
CN116503515A,Brain lesion image generation method and system based on text and image multi-mode,"The invention discloses a brain focus image generation method and system based on text and image multi-mode, comprising the following steps: and a data collection module: collecting a public data set of related brain lesions, matching each image with a text template to form a text-image template data set; and a fine adjustment module: the image and the text are respectively encoded and converted into a common embedded space, and then similarity is calculated for matching. And a data expansion module: and performing image generation and variant generation according to the required text requirement by using the trimmed DALLE2 model. And the annotation image generation module is used for editing the target image by using the circularly fine-tuned model, providing a mask specified editing area and carrying out text description to generate a target focus. Thereby generating a lesion image with labels. The invention has the advantages that: the method can process the image and the text information simultaneously to generate more real, accurate and various brain disease focus images, realize the unsupervised brain disease focus segmentation task and be more efficient, accurate and diversified.","['G06T11/60', 'G06F18/22', 'G06N3/0455', 'G06N3/0475', 'G06N3/088', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06V20/70', 'Y02T10/40']"
US12176007B1,Automated video generation,"Disclosed systems and methods convert user-supplied textual content into animated videos. Textual input is received and processed to identify narrative elements such as characters, settings, and events. These elements are then transformed into visual scene components. Still images generated based on these components are subsequently animated in line with the narrative context. The system can automatically implement storytelling techniques adapted to incorporate neuroscience principles. The system also synthesizes speech for dialogues or narrations using voice synthesis technology that considers emotional markers, tone, and pace. Generated media and metadata are stored in a data storage system that maintains data integrity and enables efficient retrieval. Users can interact with an export interface to choose video resolution, format, and sharing options. A feedback system employing machine learning algorithms collects and analyzes user feedback for real-time adjustments to the generated animated video.","['G11B27/031', 'G06F21/10', 'G06F40/20']"
WO2021146466A1,Methods and systems for model generation,"Provided herein are methods and systems for generating computer representations of three-dimensional (3D) biological or physiological objects. Further, provided herein are methods and systems for generating a three-dimensional (3D) structure corresponding to a biological material. Also provided herein are bio-printed three-dimensional matrices based at least in part on the computer representations.","['C12M33/00', 'B29C64/386', 'B33Y50/00', 'C12M25/14', 'C12N5/0686', 'C12N2513/00']"
US11961004B2,Predicting brain data using machine learning models,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for predicted brain data of a patient. One of the methods includes receiving montage configuration data for a specified montage; receiving raw EEG data captured using the specified montage from a brain of a particular subject; generating, using the montage configuration data and the raw EEG data, EEG connectivity data for the specified montage; using a generative neural network to map the EEG connectivity data to predicted fMRI connectivity data, the generative neural network having been trained using training EEG-fMRI connectivity data pairs, each pair comprising EEG connectivity data of a subject and fMRI connectivity data of the same subject; and taking an action based on the predicted fMRI connectivity data.","['G06N3/088', 'A61B5/0042', 'A61B5/055', 'A61B5/369', 'A61B5/372', 'A61B5/377', 'A61B5/7257', 'A61B5/7267', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G16H20/30', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'A61B2576/026']"
US12322013B2,Image manipulation device and method for controlling the same,"An image manipulation device including an interface configured to receive an image; an encoder configured to transform the received image into a vector Ws; a quantifier configured to output a source quantitative value Qs for the received image based on a training data set including a plurality of images arranged into classes, and receive a target quantitative value Qt different than the source quantitative value Qs; a navigator configured to receive the source quantitative value Qs, target quantitative value Qt and the vector Ws, and output a vector Wt indicating a modified vector of the vector Ws based on the source quantitative value Qs and target quantitative value Qt; a decoder configured to decode the output vector Wt into a modified image It corresponding to a modification of the received image; and a display configured to display the modified image.","['G06T11/60', 'G06V10/764', 'G06V10/82', 'G06V40/16']"
CN118279786A,Time sequence action positioning method based on diffusion model,"The invention relates to the technical field of computer vision, in particular to a time sequence action positioning method based on a diffusion model, which comprises the following steps: acquiring video data to be processed; inputting the video data into a time sequence feature extractor to obtain features of the video data; inputting the features into a constructed multi-scale time sequence characterization sensing TRP encoder to obtain long-term dependence time sequence feature information of video features; and inputting the long-term dependence time sequence characteristic information into a trained diffusion detector model to obtain a time sequence action positioning result of the video data. The invention designs a progressive and refinement method, which enables accurate boundary positioning to be feasible. And a time sequence modeling method is introduced, and time sequence evolution information and long-term dependence information of the features are captured through strengthening time sequence modeling, so that the accuracy of motion positioning is further improved.","['G06V20/41', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/62', 'G06V10/82', 'G06V20/46', 'G06V40/20']"
EP4485368A1,System and method for extracting object information from digital images,"Described herein are systems, methods, devices, and other techniques for comprehensive and automated evaluation of digital images generated from artificial intelligence (Al) models in order to promote accurate representations of real-world content. Prompts are received at the system that are then passed to both a search engine and a generative Al model. Synthesized digital images are obtained from the generative Al model. The top-matching image from the search engine is used as a verification of the ground truth of the synthesized digital images. A realism score is generated for each synthesized digital image that characterizes the accuracy of the synthesized digital image with reference to the verification image. The realism score can be used to assist and expedite the image selection process, as well as serve as input to fine-tune the performance of generative models.","['G06V10/764', 'G06T5/20', 'G06T7/50', 'G06V10/26', 'G06V10/435', 'G06V10/74', 'G06V10/761', 'G06V10/82', 'G06V20/70', 'G06V2201/07']"
JP2024157533A,SYSTEM AND METHOD FOR COLLABORATIVE CONTENT CREATION IN A COMPUTING ENVIRONMENT - Patent application,"To provide a method for executing collaborative content creation in a computing environment using artificial intelligence.SOLUTION: The method includes: receiving, by a content creation system, a first input from a first user and a second input from a second user; analyzing, by an input fusion system, the first input and the second input to determine the presence of duplicate data, redundancy data and/or prompt data by using a machine learning model; upon determining the presence of the prompt data from at least one of the first and second inputs, transmitting, by the input fusion system, the prompt data to an action generation system; generating, by the action generation system, first action data based on the prompt data and the machine learning model; and executing, by the action generation system, a first action based on the first action data.SELECTED DRAWING: Figure 6","['G06Q10/101', 'G06Q50/10', 'G06F3/04842', 'G06F16/215', 'G06F16/958', 'G06F3/011', 'G06F3/0481', 'G06F3/04847', 'G06F3/04883', 'G06N20/00', 'G06Q10/103', 'G06T19/006']"
US20240289585A1,Device and method for providing benchmark result of artificial intelligence based model,"Disclosed is a method for providing a benchmark result, performed by a computing device. The method may include obtaining model type information of an artificial intelligence-based model inputted for a benchmark, and target type information for identifying a model type which is a subject of the benchmark. The method may include determining whether to convert the artificial intelligence-based model, based on the model type information and the target type information. The method may include providing a candidate node list including candidate nodes determined based on the target type information; determining at least one target node, based on input data which selects the at least one target node within the candidate node list. The method may include providing a benchmark result obtained by executing a target model obtained according to whether to convert the artificial intelligence-based model at the at least one target node.","['G06F11/3428', 'G06F11/3447', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08']"
US20240289247A1,Device and method for providing benchmark result of artificial intelligence based model,"Disclosed is a method for providing a benchmark result, which is performed by a computing device. The method may include obtaining a first input data including an inference task and a dataset. The method may include determining a target model which is a subject of a benchmark for the inference task and at least one target node at which the inference task of the target model is to be executed. The determined target model corresponds to an artificial intelligence-based model, and the benchmark for the inference task of the determined target model is performed at the at least one target node based on the dataset. The method may include providing the benchmark result obtained by executing the target model at the at least one target node.","['G06F11/3428', 'G06F11/3058', 'G06F11/3423', 'G06N20/00', 'G06N3/04', 'G06N3/063', 'G06N3/08', 'G06F11/3447']"
US20250200613A1,Proactively-generated content creation based on tracked performance,"Methods, systems, and computer programs are presented for proactively generating content based on performance of previous content. One method includes an operation for transmitting a set of first items for presentation. The first items are multimodal, and each first item has values for attributes associated with the first item. The method further includes tracking performance of the transmitted set of first items, selecting values of attributes based on the tracked performance, and proactively generating, using one or more generative artificial intelligence (GAI) tools, a set of second items based on the selected values of the attributes. Further, the method includes operations for providing a user interface (UI) with an option to select from the set of second items, receiving in the UI a selection of selected second items for transmittal, and transmitting the selected second items to one or more users.","['G06T11/60', 'G06F16/9577', 'G06Q30/0242', 'G06Q30/0271', 'G06Q30/0276', 'G06T2200/24']"
US20250095338A1,"Device and computer-implemented methods for machine learning, for providing a machine learning system, or for operating a technical system","A device and a computer-implemented method for machine learning. The method includes: providing a latent variable of a diffusion model representing the synthetic digital image, wherein providing the latent variable comprises sampling the latent variable from random noise, or providing a digital reference image, and adding noise with the diffusion model to the digital reference image to determine the latent variable, or mapping the digital reference image with an encoder to an input of the diffusion model, and adding noise with the diffusion model to the input to determine the latent variable, mapping the latent variable with the diffusion model depending on parameters of the diffusion model to features of the diffusion model, mapping the features with the diffusion model depending on parameters of the diffusion model to an output of the diffusion model.","['G06N3/0455', 'G06N3/047', 'G06N3/088', 'G06N3/09', 'G06T9/00', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V20/582', 'G06V20/588', 'G06N3/0464', 'G06N3/084', 'G06V2201/07']"
US20220139062A1,"Learning apparatus, learning method, and learning program, region-of-interest extraction apparatus, region-of-interest extraction method, and region-of-interest extraction program, and learned extraction model","An extraction model is constituted of an encoder that extracts a feature amount of a first image of a first representation format to derive a feature map of the first image, a first decoder that derives a second virtual image of a second representation format different from the representation format of the first image on the basis of the feature map, a first discriminator that discriminates a representation format of an input image and whether the input image is a real image or a virtual image, and outputs a first discrimination result, a second decoder that extracts a region of interest of the first image on the basis of the feature map, and a second discriminator that discriminates whether an extraction result of the region of interest by the second decoder is an extraction result of a first image with ground-truth mask or an extraction result of a first image without ground-truth mask, and outputs a second discrimination result.","['A61B6/5211', 'A61B6/5247', 'G06V10/25', 'G06V10/40', 'G06V10/7715', 'A61B6/03', 'G06V2201/03']"
CN115691770A,"Cross-modal medical image completion method, device and equipment based on conditional score","The invention provides a cross-modal medical image completion method, a device and equipment based on condition scores, which comprises the following steps: acquiring MRI image data under multiple modes, optionally selecting image data of one or more modes as original target mode image data, and using the rest as conditional mode image data; inputting original target modal image data into a multi-modal condition forward stochastic differential equation based on a Markov diffusion process to obtain complete diffusion image data; and the conditional modal image data remains unchanged; and (3) taking the condition modal image data as a cross-modal condition distribution condition, and obtaining the complete target modal image data by passing the complete diffusion image data through a multi-modal condition reverse random differential equation. The method is based on the cross-modal condition score generation model, and the incompatibility of information complementarity between actual multi-modal data based on the traditional cross-modal mapping method is overcome; and the resulting MRI image may exhibit more detail and more sharp textural features.",[]
CN120380463A,Machine learning structured result generation,"Aspects of the present application relate to Machine Learning (ML) structured result generation. In an example, instructions of the programmatic code invoking the ML model are used to indicate the result interface in which the model output is to be stored. The result interface is processed to generate a data format description for the result interface such that the input of the ML model also includes the data format description. As a result of providing the data format description as input to the ML model, the ML model is directed to generate a structured model output corresponding to the result interface. The results model output is processed to generate an instance of the results interface, e.g., with one or more corresponding attributes from the structured model output. Thus, the program code can reliably perform subsequent processing based on the generated instance of the result interface.",['G06F8/35']
US20250258956A1,Federated distributed computational graph architecture for biological system engineering and analysis,"A federated distributed computational system enables secure collaboration across institutions for unified biological and multiomics data analysis. It comprises interconnected computational nodes managed by a central federation manager. Each node includes specialized components: a local computational engine for biological data processing, a privacy-preservation system, a knowledge integration component leveraging dynamic knowledge graphs, and a secure communication interface. The federation manager coordinates computational activities while ensuring security, privacy, legality, and contractual adherence. This architecture allows institutions, citizen scientists, and patients to collaborate on complex biological analyses without compromising sensitive data. By enabling shared computational resources and expertise, the system facilitates breakthrough discoveries while maintaining confidentiality. Additionally, it supports pro-rata or contractually defined participation in resultant benefits or knowledge, ensuring equitable collaboration.","['G06F21/53', 'G06F21/6245']"
US20230342886A1,Method and system for low-field mri denoising with a deep complex-valued convolutional neural network,"MR image data can be improved by using a complex de-noising convolutional neural network such as a non-blind C-DnCNN, a network for MRI denoising that leverages complex-valued data with phase information and noise level information to improve denoising performance in various settings. The proposed method achieved superior performance on both simulated and in vivo testing data compared to other algorithms. The utilization of complex-valued operations allows the network to better exploit the complex-valued MRI data and preserve the phase information. The MR image data is subject to complex de-noising operations directly and simultaneously on both real and imaginary parts of the image data. Complex and real values are also utilized for block normalization and rectified linear units applied to the noisy image data. A residual image is predicted by the C-DnCNN and a clean MR image is available for extraction.","['G06T5/70', 'G06T5/002', 'G06T11/008', 'G06T5/50', 'G06T5/60', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2211/424']"
WO2023069793A1,Robotic system,"A robotic post system includes one or more robotic posts having a processor and a memory. The robotic posts may include a manipulation arm and/or a swiveling and/or otherwise moveable trunk and/or base. Sensors provided on the robotic post enable the robotic post to rotate, tilt or move toward another robotic post to orient and secure a lockable band on one post with a lock on another post. A manipulation arm may grasp a lockable band and attach it to a lock, and either post may move away from the other to extend the length of a guide path.","['B25J11/008', 'B25J5/007', 'B60B19/12']"
CN116630189A,Remote sensing image panchromatic sharpening method and device based on denoising diffusion probability model,"The application provides a remote sensing image full-color sharpening method and device based on a denoising diffusion probability model. The method comprises the following steps: performing differential processing on a high-resolution multispectral HRMS image and an interpolated multispectral IMS image obtained based on a low-resolution multispectral LRMS image to obtain an original differential DM image; then forward diffusion processing is carried out on the original differential image by using the denoising diffusion probability model, so as to obtain a corresponding noise image; then, extracting key features from the full-color PAN image and the LRMS image by using a feature extraction model; performing inverse denoising processing on the noise image based on the key features by using a denoising diffusion probability model to obtain a reconstructed differential DM image; then, training a denoising diffusion probability model and a feature extraction model by taking the data distribution of the reconstructed differential DM image approaching to the data distribution of the original differential DM image as a target; finally, adding the interpolated multispectral IMS image to the reconstructed DM image, and obtaining the full-color sharpening result for the LRMS image and the full-color PAN image.","['G06T5/73', 'G06N3/0464', 'G06N3/08', 'G06T5/70', 'G06T2207/10036', 'G06T2207/10041', 'G06T2207/20081', 'G06T2207/20084']"
CN118799230A,A high dynamic range imaging method based on multi-scale progressive reconstruction network,"The invention belongs to the technical field of high dynamic range imaging, and particularly relates to a high dynamic range imaging method based on a multi-scale progressive reconstruction network, which comprises the following steps: constructing a multi-scale progressive reconstruction network MPRNet, including an encoder module, a multi-scale progressive reconstruction module MSPRM, a dual-stream exposure recovery module DERM, and a decoder module; the encoder module is used for extracting the characteristics to obtain a corresponding characteristic diagram E 1,E2,E3; MSPRM is used for carrying out multi-scale progressive reconstruction and global context modeling on the feature map E 1,E2,E3 to obtain fusion featuresDERM are used to map fusion featuresPerforming exposure recovery of the overexposed region to obtain an exposure recovery feature F expo; also for fusing featuresPerforming complement restoration of content details to obtain a content reconstruction feature F rec; self-adaptive weighting is carried out to obtain an optimized recovery characteristic F fused; the decoder is used for decoding the optimized restoration feature F fused to obtain HDR image predictionThe invention can solve the problems of ghost, blurring, distortion and the like generated in large-scale motion and extreme exposure scenes.","['G06T5/77', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06T5/50', 'G06T5/60', 'G06T2207/20221']"
WO2025106451A1,Object detection using visual language models via latent feature adaptation with synthetic data,"Systems and techniques are described herein for adapting a pretrained machine learning model. For instance, a process can include encoding a training image into a first feature vector, the training image including a first object located at a first location; generating a second feature vector based on a set of sinusoidal functions using a set of weights; combining the first feature vector with a second feature vector to generate a combined feature vector; processing the combined feature vector using a visual language model to obtain a second location for the first object; and adjusting the set of weights based on a comparison between the first location and the second location.","['G06V10/82', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06V10/774', 'G06V20/70']"
CN117131520A,Two-stage image privacy protection method and system based on dynamic mask and generative recovery,"The invention discloses a two-stage image privacy protection method and system based on dynamic mask and generation recovery, wherein the method comprises the following steps: s1, establishing a data set ImgDataset, preprocessing the data set ImgDataset, labeling the category of each target, and dividing the data set into a training set D in proportion tr Verification set D v Test set D te For training set D tr Performing classification training; s2, judging important attention areas of the images, generating corresponding binary masks, and masking the original image by using the masks; s3, inputting the mask image into a generator for training,encrypting the trained parameters; and S4, respectively transmitting the mask image and the parameter ciphertext obtained in the step S3 to a receiving end, decrypting the parameter ciphertext by the receiving end, loading the network weight parameter into a generator with the same network structure as the transmitting end in the receiving end, and repairing the mask image by the generator. According to the invention, by encrypting the training model parameters, the encryption operation on massive image data is avoided, the calculation cost is reduced, and the encryption and decryption rate is improved.","['G06F21/602', 'G06F18/241', 'G06F21/6245', 'G06N3/0464', 'G06N3/08']"
US20240037812A1,Modifying stable diffusion to produce images with background eliminated,"Techniques are described for guiding stable diffusion to produce images with a contrasting foreground/background. Po stprocessing is implemented using segmentation and chromakeying to remove the background. These techniques extract an alpha channel in generated images to force stable diffusion to generate output with a background in a specified color, which is then removed from the image in output post-processing. Present techniques leverage the img2img inpainting pipeline with a noise mask that covers the image edges, applying noise (and generating content) only in the center of the image, thereby forcing a strong background/foreground distinction.","['G06T11/001', 'G06T3/60', 'G06T7/194', 'G06V10/56', 'G06V10/82', 'H04N5/272', 'G06T2207/10024']"
CN119299645A,"A 3D image generation method, device, equipment and storage medium","The application provides a method, a device, equipment and a storage medium for generating a 3D image. The method comprises the steps of obtaining a left view of a target environment, obtaining a parallax map according to the left view, wherein the left view represents the target environment seen by a left eye, the parallax map represents pixel difference values of the left view and the right view, obtaining a right view of the target environment according to the left view and the parallax map, wherein the right view represents the target environment seen by a right eye, and obtaining a 3D image of the target environment according to the left view, the parallax map and the right view. The right view is clearer through the left view and the parallax map, so that the finally obtained 3D graph is clearer.","['H04N13/204', 'H04N13/261']"
CN117952485B,"Community emergency method, device and medium based on digital twinning","The invention discloses a community emergency method, device and medium based on digital twinning, wherein the method comprises the following steps: constructing a digital twin model based on target data, and training the digital twin model through historical data to generate a deduction model; setting decision initial conditions, inputting the decision initial conditions into a deduction model, and performing multi-branch deduction simulation to generate a pre-deduction result; judging whether the initial conditions corresponding to the emergency and each pre-deduction result are consistent when the emergency occurs in the target community, and if so, selecting the consistent pre-deduction result as the target deduction result; if the result is inconsistent, determining the influence range of the emergency, and determining a target deduction result; and determining a target emergency link according to the structural components, the target deduction result and the preset evaluation index, and finally generating and outputting a community emergency processing instruction. The invention can adapt to the emergency event with dynamic change, considers the resource allocation and resident escape route, provides a proper and actual response emergency treatment scheme, and improves the overall resource planning.","['G06Q10/067', 'G06F18/241', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'G06N5/045', 'G06Q10/0631', 'G06Q50/265']"
US20230178250A1,A method for inferring epileptogenicity of a brain region,"The method for inferring epileptogenicity of a brain region not observed as recruited or not observed as not recruited, in a seizure activity of an epileptic patient brain, includes: providing a computerized model modelling various regions of a primate brain and connectivity between the regions; providing the computerized model with a model able to reproduce an epileptic seizure dynamic in the primate brain; providing structural data of the epileptic patient brain and personalizing the computerized model using the structural data to obtain a virtual epileptic patient (VEP) brain model; translating a state-space representation of the VEP brain model into a probabilistic programming language (PPL) using probabilistic state transitions to obtain a probabilistic virtual epileptic patient brain model (BVEP); and acquiring electro- or magneto-encephalographic data of the patient brain and fitting the probabilistic VEP brain model against the data to infer the epileptogenicity of the brain region that is not observed.","['G06N20/00', 'G06N5/04', 'G16H30/20', 'G16H50/20', 'G16H50/50']"
US12387388B2,Scene-based text-to-image generation with human priors,"In one embodiment, a method includes accessing a text input and a scene input corresponding to the text input, wherein the scene input comprises semantic segmentations, generating text tokens for the text input and scene tokens for the scene input by machine-learning models, generating predicted image tokens based on the text tokens and the scene tokens by the machine-learning models, and generating an image corresponding to the text input and the scene input based on the predicted image tokens by the machine-learning models.","['G06T11/00', 'G06T7/13', 'G06T9/00', 'G06V10/26', 'G06V10/82', 'G06V20/70', 'G06V40/171', 'H04L9/3213', 'G06T2207/30201']"
CN119179929A,Electrocardiosignal enhancement and classification method based on gating circulation diffusion model,"The invention provides an electrocardiosignal enhancement and classification method based on a gate-controlled circulation diffusion model, which comprises the steps of 1, obtaining an electrocardiosignal data set, 2, setting parameters and super parameters of the diffusion model, 3, building a neural network structure of the diffusion model, 4, training the diffusion model, supplementing the electrocardiosignal data set through the trained diffusion model, 5, setting super parameters of a classification model, 6, building the classification model, and 7, training the classification model by adopting the electrocardiosignal data set obtained in the step 4, and using the trained classification model for electrocardiosignal classification. Compared with the traditional generation model, the method can capture the time sequence information of electrocardiosignals better by introducing the supplementary data of the gating circulation diffusion model, thereby simulating the characteristic of heart rate.","['A61B5/346', 'A61B5/7267', 'G06F18/24', 'G06N3/0442', 'G06N3/0464', 'G06F2218/12']"
US20250157628A1,Apparatus and methods for synthetizing medical images,"An apparatus for synthetizing medical images, wherein the apparatus includes a process and a memory containing instructions configuring the processor to receive an organ model related to a patient's organ, identify a region of interest within the organ model, wherein identifying the region of interest includes locating at least a point of view on the organ model and determining a view angle corresponding to the at least a point of view, wherein the at least a point of view and the corresponding view angle define at least one field of view that include at least a portion of the organ model, and generate at least a medical image as a function of the region of interest using an image generator, wherein the at least a medical image captures an anatomical structure of the at least a portion of the organ model.","['G16H30/20', 'G06F18/214', 'G06T11/00', 'G06T15/20', 'G06T17/00', 'G06V10/25', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2210/41']"
CN118357922A,A robotic arm control method based on two-stage reinforcement learning of imitation and variable parameters,"The invention provides a mechanical arm control method based on simulation and parameter-changing two-stage reinforcement learning, which comprises the following steps: 1) Acquiring expert motion trail of a manual control mechanical arm for completing a designated task, and performing normalization processing to obtain an imitation learning data set; 2) Training a mechanical arm close to an expert strategy to simulate a learning strategy by using the acquired data set; 3) Designing a parameter efficient fine-tuning strategy based on the imitation learning strategy, performing interactive training with the environment, and guiding strategy learning by using a value network to obtain a final reinforcement learning strategy; 4) And outputting a control action sequence of the mechanical arm by using the reinforcement learning strategy, and executing and completing various tasks. According to the invention, by designing a two-stage reinforcement learning method and utilizing a parameter efficient fine adjustment strategy, a small amount of expert demonstration information and environment interaction times can be utilized, and the strategy can be quickly trained and learned on the premise of ensuring safety and stability, so that the mechanical arm is controlled to complete a designated task.",['B25J9/163']
US20220398360A1,Remaining useful life predictions using digital-twin simulation model,"A method for remaining useful life prediction includes generating parameter data related to a performance of an electro-mechanical element. The method includes generating simulated behavior data of the electro-mechanical element by executing a digital-twin simulation model based on estimated operating conditions, and generating deviation data that characterizes how the parameter data deviates from the simulated behavior data. The deviation data includes a deterministic component and a stochastic component. The method includes generating extrapolated deviation data by extrapolating the deterministic component and the stochastic component of the deviation data forward in time, calculating a remaining useful life of the electro-mechanical element in response to the extrapolated deviation data, and reporting the remaining useful life to a person associated with the vehicle.","['G06F30/20', 'G05B17/02', 'G05B23/0254', 'G05B23/0283', 'G05B2219/2637', 'G06F2111/08']"
CN115984485A,High-fidelity three-dimensional face model generation method based on natural text description,"The invention discloses a high-fidelity three-dimensional face model generation method based on natural text description. The method comprises the following steps: designing a face description questionnaire based on a three-dimensional face data set, manually labeling the questionnaire, and generating description sentences according to a fixed sentence pattern; the three-dimensional face model topology is consistent, a 3DMM model is established by utilizing a principal component analysis method, and a texture map is generated by utilizing texture remapping; embedding a text after being coded by using a face-described one-hot code and a CLIP model into a training text analysis network, inputting the text, and outputting a predicted one-hot code of the shape and the texture; respectively training a shape prediction network and a texture generation network to generate a three-dimensional face model with textures; the 3DMM coefficients and texture maps are optimized to conform the face model to the abstract description and generate the final result. The method comprises the steps of constructing a large-scale text-three-dimensional face data set, predicting a 3DMM coefficient and a texture mapping by using a neural network, and further generating a three-dimensional face model conforming to description from a natural text.",['Y02T10/40']
WO2021154350A2,Quantum generative models for sampling many-body spectral functions,Quantum generative models for sampling many-body spectral functions are provided. Quantum approximate Bayesian computation is provided for NMR model inference.,"['G06N10/20', 'G06N10/60', 'G06N7/01']"
US20240202582A1,Multi-stage machine learning model chaining,"A skill chain comprised of a set of ML model evaluations with which to process an input is generated and used to ultimately produce a model output accordingly. Each ML model evaluation corresponds to a âmodel skillâ of the skill chain. Intermediate output that is generated by a first ML evaluation for a first model skill of the skill chain may subsequently be processed as input to a second ML evaluation for a second model skill of the skill chain, thereby ultimately generating model output for the given input. Such a skill chain can include any number skills according to any of a variety of structures and need not be evaluations using the same ML model.","['G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
US20240419705A1,Data intelligence model for operator data queries,"Operators managing a cloud RAN collect vast amounts of data, e.g., node-level data, gNodeB level data, user level data, and flow-level data, which are utilized for network monitoring, evaluating key performance indicators (KPIs), and nodes management. Retrieving and visualizing information and values of different metrics is critical to managing network operation; however, data retrieval on large datasets is challenging. While foundation models perform poorly on large datasets, an accurate answer to a data query is generated by providing semantically similar metrics as context to a foundation model, thereby limiting the number of counters needed for processing the data query. The foundation model then generates a first output of metrics relevant to answering the data query and, based on the first output, generates a second output comprising query code (e.g., SQL or KQL) for computing the answer, thereby improving mathematical accuracy of the answer.","['G06F16/3344', 'G06F16/243', 'G06F16/313', 'G06F16/3329', 'G06F16/338', 'G06F40/30', 'G06N3/0455', 'G06N3/0475', 'G06N5/041']"
US12400124B1,Incremental learning method and apparatus for large vision-language model for autonomous driving,"An incremental learning method and apparatus for a large Vision-Language Model for autonomous driving are provided. The incremental learning method includes: expanding a first training sample set to obtain a second training sample set, wherein the second training sample set includes a plurality of image samples annotated with road scene targets; inserting a plurality of fine-tuning sub-networks respectively into specified positions in a first large Vision-Language Model to generate a second large Vision-Language Model; processing the image samples in the second training sample set using the second large Vision-Language Model to obtain a target prediction result; calculating a loss value using the target prediction result and a target annotation result; and preserving parameters of the first large Vision-Language Model unchanged, and updating parameters of the fine-tuning sub-networks using the loss value.","['G06V10/778', 'G06N3/096', 'G06N3/04', 'G06N3/0455', 'G06N3/082', 'G06V10/774', 'G06V10/82', 'Y02T10/40']"
US20240095987A1,Content generation,"Techniques for generating content associated with a user input/system generated response are described. Natural language data associated with a user input may be generated. For each portion of the natural language data, ambiguous references to entities in the portion may be replaced with the corresponding entity. Entities included in the portion may be extracted, and image data representing the entity may be determined. Background image data associated with the entities and the portion may be determined, and attributes which modify the entities in the natural language sentence may be extracted. Spatial relationships between two or more of the entities may further be extracted. Image data representing the natural language data may be generated based on the background image data, the entities, the attributes, and the spatial relationships. Video data may be generated based on the image data, where the video data includes animations of the entities moving.","['G06T13/00', 'G06F16/5866', 'G06F3/167', 'G06F40/166', 'G06F40/279', 'G06F40/40', 'G06F40/56', 'G06T11/00', 'G10L13/02', 'G10L15/18', 'G10L15/22']"
US20240386197A1,System and method for enhanced model interaction integration within a website building system,Embodiments provide for integrating enhanced model interaction within a website building system. Models leveraged according to embodiments may include trained generative artificial intelligence models that are leveraged to customize structure and content within a website building system. Improved generation of composite prompts leads to improved generation of customized structure and content within the website building system.,"['G06F16/958', 'G06F40/186', 'G06F3/0482', 'G06F3/0484', 'G06F9/547']"
CN115908606A,Coloring method and computer equipment for pile embroidery thread drawing based on generative confrontation network,"The invention discloses a method for coloring a heap-embroidery-thread draft based on a generation confrontation network and a computer device, wherein the method comprises the following steps: collecting cartoon and embroidery color images, preprocessing the cartoon and embroidery color images, extracting corresponding line draft and color prompt information, and constructing a training data set; constructing a coloring model of the embroidery thread stacking draft; the embroidery thread stacking and coloring model comprises a feature extraction module, a generator added with a CSA module and a discriminator; firstly, training a color model of the embroidery thread stacking draft by using an animation training data set, and then performing migration training on the embroidery training data set; and inputting the embroidery thread stack to be processed and the corresponding color prompt information into the trained embroidery thread stack coloring model, and outputting a target embroidery coloring image. The method completes the coloring of the embroidery thread manuscript by generating the confrontation network, improves the generalization capability of the model by introducing the feature extraction module in the network, improves the coloring precision by introducing the CSA module, reduces the problem of color overflow and has better coloring effect.",['Y02P90/30']
WO2020120238A1,System and method for providing stroke lesion segmentation using conditional generative adversarial networks,"A system and method for performing image processing. The method includes receiving an image of a first modality and a real image of a second modality, the image of the first modality and the image of the second modality capturing respective images of a same subject, applying a first trained model to the image of the first modality to generate an artificial image mimicking the image of the second modality, applying a second trained model to the artificial image mimicking the image of the second modality and data of the image of the first modality, and outputting at least one conclusion regarding the generated artificial image.","['G06T7/11', 'G06T7/0012', 'G06N3/045', 'G06N3/088', 'G06T11/008', 'G06T7/174', 'G16H30/40', 'G06N3/047', 'G06N3/084', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06T2207/30104', 'G06T2211/408']"
US20240265630A1,System and method for 3d modeling,"In variants, the method for 3D modeling can include: determining a property of interest, determining property information for the property of interest, determining property component parameter values based on property information, determining a 3D model based on property component parameter values, and optionally determining a set of property attributes. However, the method can additionally and/or alternatively include any other suitable elements.","['G06V10/25', 'G06F30/13', 'G06F30/23', 'G06F30/27', 'G06Q10/06', 'G06Q10/103', 'G06Q30/0201', 'G06Q30/0278', 'G06Q30/0282', 'G06Q30/0283', 'G06Q50/16', 'G06Q50/26', 'G06T17/00', 'G06V10/44', 'G06V20/176', 'G06T2210/04', 'G06V2201/07']"
US20240054394A1,Generating new data based on class-specific uncertainty information using machine learning,"A system and related methods for generating class-specific data are disclosed. The data belong to an input space with an unknown initial probability distribution and a known classification scheme. From a relatively small, unbalanced dataset of samples with respect to the classification scheme in the input space, the system is programmed to learn a series of invertible transformations from the input space to a target space, a target probability distribution for the samples in the target space, and a trainable parameter probability distribution for each parameter of the target probability distribution to represent uncertainty information related to the target probability distribution. The system is programmed to further identify how to sample from each parameter probability distribution, which determine how to sample from the target probability distribution, to generate samples in the input space that are more likely to belong to specific classes.","['G06N3/0475', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/0985', 'G06N7/01', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G16H30/40']"
CN111105338B,Image encryption method based on GAN and chaotic system,"The invention discloses an image encryption method based on a GAN and a chaotic system, relates to the technical field of image encryption, and solves the problems of poor randomness of a secret key, high complexity of a scrambling-diffusion algorithm, low encryption algorithm efficiency and the like in the existing image encryption method. The quantum cell neural network hyper-chaotic system has higher key dimension, larger key space, stronger sensitivity and stronger capability of resisting various security attacks, and meanwhile, the quantum chaotic system is a novel nanoscale device which mutually transmits information by the coulomb action of quantum dots and quantum cell automaton, and has the advantages of ultrahigh integration level, low power consumption, no lead integration and the like.",['G06T1/0021']
CN118896684A,A noise matching and separation method for substations,"The invention relates to a transformer substation noise matching separation method, which comprises the following steps: acquiring original time domain array data of a transformer substation site by using a microphone array system, and estimating direction-of-arrival estimation data; obtaining non-stationary component data and residual mixed signal data according to the array structure and the direction of arrival estimation data of the microphone array system; 3D scene analysis is carried out on the non-stationary component data and the residual mixed signal data to obtain space-time distribution characteristic data; modeling and analyzing the space-time distribution characteristic data according to the field environment and equipment layout information of the transformer substation to obtain high-order noise semantic characterization data; real-time tracking is carried out on the change track of the noise based on the high-order noise semantic characterization data, so that collaborative tracking scene data are obtained; and generating a noise map based on the collaborative tracking scene data, and then separating independent noise source components with parallel edges to obtain final separation result data. The invention can separate non-stationary and mixed noise.","['G01H17/00', 'G01D21/02', 'G01R23/167', 'G01R31/001', 'G01S17/08', 'G01S3/8083', 'G01S5/20', 'G06F18/10', 'G06F18/21', 'G06F18/2131', 'G06F18/2415', 'G06F2218/04', 'G06F2218/08', 'G06F2218/12']"
CN119719869B,Data augmentation method and system for biomedical signals based on self-training,"The invention belongs to the technical field of data processing. The data amplification method and system based on the self-training oriented biomedical signals are provided, a plurality of amplification samples corresponding to any one of the preprocessed real samples and a pre-trained diffusion model are obtained, the similarity between the real sample and each amplification sample is calculated, one unique amplification sample which is most similar to the real sample is selected according to the similarity, the amplification samples corresponding to all the real samples are calculated, the pseudo-labels of the amplification samples are calculated according to the amplification samples and a downstream model based on the initial training of the real samples, and the unique amplification samples consistent with the labels are used as final amplification samples according to the comparison of the pseudo-labels and the real labels. The invention solves the problems of insufficient data quantity and diversity of biomedical signals, data and label noise and the like, and obviously improves the performance of a downstream model.",[]
CN111476863A,"Method and device for coloring black and white cartoon, electronic equipment and storage medium","The embodiment of the invention provides a method and a device for coloring black and white comics, electronic equipment and a storage medium, wherein the method comprises the following steps: extracting a target line draft and a target screen from a target black-and-white cartoon to be colored; coloring the target line draft to obtain an image of a color channel; inputting the target line draft to a pre-trained gray level image to generate a network model, and acquiring a target gray level image; superposing the target gray image and the target screen to obtain an image of a gray channel; and carrying out channel fusion on the image of the color channel and the image of the gray channel to obtain the target color cartoon. According to the embodiment of the invention, the target gray level image can be generated according to the characteristics of the line draft, the gray level is rich and natural, and the coloring effect on the black and white cartoon is good.","['G06T11/40', 'G06N3/045', 'G06N3/08', 'G06T7/90']"
WO2025065335A1,"Image inpainting method, model training method, electronic device, and storage medium","The present disclosure may be applied to the technical field of artificial intelligence technology, and provides an image inpainting method, a model training method, an electronic device, and a storage medium. The image inpainting method comprises: performing an image quality evaluation operation on a first image to be undergo inpainting, and obtaining image quality evaluation information, the image quality evaluation information comprising image quality evaluation values respectively corresponding to at least one image quality evaluation item, and the image quality evaluation values representing the degree of interference of the image quality evaluation item on the first image to undergo inpainting; and, on the basis of the image quality evaluation information, performing an inpainting operation on the first image to undergo inpainting, and obtaining a first inpainted image.",['G06T5/00']
WO2020102260A1,Compositions and methods for printing three-dimensional structures corresponding to biological material,"Provided herein are methods and systems for bio-printing of three-dimensional cell-containing matrixes. Further, provided herein are methods and systems for generating a three-dimensional (3D) structure corresponding to a biological material, such as a kidney or lung comprising either nephron or alveolar structures. Also provided herein are bio-printed three-dimensional matrices for use in the generation nephron and/or alveolar structures.","['C12N5/0062', 'B33Y80/00', 'A61L27/3804', 'A61L27/44', 'A61L27/54', 'A61L31/125', 'A61L31/16', 'B29C64/124', 'B29C64/30', 'B29C64/386', 'B33Y10/00', 'B33Y50/00', 'B33Y70/00', 'C12N5/0686', 'C12N5/0688', 'A61L2430/26', 'B29K2105/0002', 'B29K2995/0056', 'B29L2031/7532', 'C12N2513/00']"
CN118277887A,Cement-based material performance optimization method and system based on machine learning,"The invention discloses a cement-based material performance optimization method and system based on machine learning, wherein the method comprises the following steps: acquiring historical cement-based material data, and preprocessing the historical cement-based material data to obtain a training set and a testing set; acquiring a plurality of preset machine learning models, and performing model training and model screening on the plurality of preset machine learning models according to a training set and a testing set to obtain an initial performance optimization prediction model; performing model optimization processing on the initial performance optimization prediction model to obtain a performance optimization prediction model; and acquiring current cement-based material data, inputting the current cement-based material data into the performance optimization prediction model, and outputting a cement-based material performance optimization result. According to the invention, by constructing the performance optimization prediction model and carrying out interpretable analysis and multi-objective optimization treatment, the accurate prediction and optimization of the cement-based material performance can be realized, so that the proportioning guidance of the cement-based material is realized.","['G06F18/2411', 'G06F18/214', 'G06F18/24147', 'G06F18/24155', 'Y02P90/30']"
CN118570614A,Convolutional neural network method for remote sensing image semantic segmentation integrating diffusion semantic features,"The invention belongs to the technical field of deep learning semantic segmentation, and in particular relates to a remote sensing image semantic segmentation convolutional neural network method integrating diffusion semantic features, which comprises the steps of acquiring a data set of land utilization and land coverage of a basin area based on a remote sensing image; constructing a convolutional neural network model suitable for semantic segmentation based on the encoder and decoder structures; performing unsupervised training on the training set and the verification set by using the SR3 super-resolution image generation model, and generating a pre-trained SR3 image generation model to train the convolutional neural network model so as to obtain optimal parameters; and processing the remote sensing image samples in the test set by using the trained convolutional neural network model to generate a remote sensing semantic segmentation result graph. The invention relieves the unbalance of ground object segmentation, improves the performance and efficiency of the model in an image processing task, obviously improves the edge segmentation and detail resolution, and enhances the outline visualization and classification accuracy.","['G06V10/82', 'G06N3/0464', 'G06N3/088', 'G06V10/26', 'G06V10/763', 'G06V20/70']"
US20250111573A1,Enhanced system for generation and optimization of facial models and animation,"Systems and methods are provided for enhanced animation generation based on generative modeling. An example method includes training models based on faces and information associated with persons. The modeling system being trained to reconstruct expressions, textures, and models of persons.","['G06T13/80', 'G06T3/4053', 'G06T13/40', 'G06T15/04', 'G06T17/00', 'G06T19/20', 'G06T2219/2021', 'G06T2219/2024']"
CN117194620A,"Information processing method, device, equipment and storage medium","The application is applicable to the technical field of artificial intelligence, and provides an information processing method, an information processing device, information processing equipment and a storage medium, wherein the information processing method comprises the following steps: determining user intention according to the input information of the user; selecting a large language model or a target interface of a target local knowledge base from the large language models or the alternative interfaces of at least one alternative local knowledge base according to the user intention; and calling a large language model of the target local knowledge base or the target interface to output feedback information corresponding to the user intention. According to the scheme, the intention of the user is realized by combining a large language model of the local knowledge base and calling an external interface, and the problem of information lag of the local knowledge base can be solved by the two feedback modes, so that more comprehensive, real-time and accurate information can be provided for the user.",[]
CN117575908A,Multi-mode image reconstruction method based on reversible guiding and circulating knowledge distillation,"The invention discloses a multimode image super-resolution reconstruction method based on reversible guiding and circulating knowledge distillation, which comprises the following steps: 1) Preparing data; 2) Training a DDPM model; 3) Multimode distribution constraint MDCS; 4) Reversible guidance; 5) Circulating knowledge distillation; 6) Model evaluation and optimization. The method can effectively understand the high-level semantics and the context information in the image, and solves the problems of model collapse, high-frequency detail loss and long-tail data correlation.","['G06T3/4053', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/0495', 'G06N3/082', 'G06N3/096', 'G06T3/4046', 'Y02D10/00']"
CN116596593A,"Content generation method and device based on interaction, electronic equipment and storage medium","According to the embodiment of the application, a target content generation model matched with content generation requirements can be determined, wherein the content generation requirements have corresponding content description information, a plurality of current candidate contents are generated based on the content description information and the target content generation model, the current target content selected from the plurality of current candidate contents is determined, the current target content is optimized by using a content optimization model, the current target content with optimized display effect is obtained, and finally the current target content with optimized display effect is provided. By adopting the scheme, the designer can be assisted in making the display content in the commercial scene, the efficiency of designing the commercial display content by the designer is improved, and the requirement of batch generation of the content is met.","['G06Q30/0276', 'G06F3/0484']"
US20240412491A1,Using neural networks to generate synthetic data,"Apparatuses, system, and techniques use one or more first neural networks to generate one or more synthetic data to train one or more second neural networks based, at least in part, on one or more performance metrics of one or more second neural networks.","['G06N3/045', 'G06V40/171', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06T11/00', 'G06V10/751', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/168', 'G06V40/172']"
US20240320912A1,Optimizing Generative Machine-Learned Models for Subject-Driven Text-to-3D Generation,"A fractional training process can be performed training images to an instance of a machine-learned generative image model to obtain a partially trained instance of the model. A fractional optimization process can be performed with the partially trained instance to an instance of a machine-learned three-dimensional (3D) implicit representation model obtain a partially optimized instance of the model. Based on the plurality of training images, pseudo multi-view subject images can be generated with the partially optimized instance of the 3D implicit representation model and a fully trained instance of the generative image model; The partially trained instance of the model can be trained with a set of training data. The partially optimized instance of the machine-learned 3D implicit representation model can be trained with the machine-learned multi-view image model.","['G06T15/20', 'G06F40/30', 'G06T15/08', 'G06T17/00', 'H04N13/279', 'H04N13/351']"
CN118776479A,A bridge health monitoring method integrating machine vision and edge computing,"The invention discloses a bridge health monitoring method integrating machine vision and edge calculation, which comprises the following steps: forming an integrated deformation monitoring device instrument; attaching the target to the side surface of the bridge; placing a loading trolley on the surface of a bridge; placing a light intensity meter near the target to measure the light intensity of the target in the experiment, starting a deformation monitoring device meter, pulling a loading trolley to move on the surface of the bridge, and collecting bridge data video and strain data in real time by the deformation monitoring device meter; dividing an image with a passive target, which is acquired by a deformation monitoring equipment instrument, into a plurality of ROI areas for motion monitoring; and comparing the current frame image with the reference frame by taking the first frame of video acquisition as the reference frame, identifying and matching the characteristic points at the passive targets of the two frames of images by adopting a characteristic point detection and matching algorithm, carrying out coordinate difference averaging on the characteristic points in the sequence image and the initial image to obtain the pixel displacement of the image, and obtaining the real displacement of the bridge by utilizing the displacement calibration coefficient.","['G01B11/16', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G06V10/25', 'G06V10/757', 'G06V10/82', 'G06V10/95', 'G06V20/176']"
US11982725B2,Parallel transmission magnetic resonance imaging with a single transmission channel RF coil using deep learning,"Magnetic resonance images with improved image quality consistent with those obtained using parallel radio frequency (âRFâ) transmission (âpTxâ) techniques are generated from data acquired using single transmission hardware (e.g., single channel RF transmission). A deep-learning framework is used to train a deep neural network to convert images obtained with single transmission into pTx-like images. The pTx-like images have reduced signal variations and dropouts that may otherwise be attributable to B1+ inhomogeneities.","['G01R33/5608', 'G01R33/5659', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/088', 'G06N3/0985', 'G06N3/0464', 'G06N3/0475']"
CN112883227B,Video abstract generation method and device based on multi-scale time sequence characteristics,"The embodiment of the application provides a video abstract generating method and device based on multi-scale time sequence characteristics. The method comprises the following steps: generating a model by utilizing a pre-trained video abstract to obtain a multi-scale time sequence fusion characteristic sequence; determining the importance score of each video frame in the multi-scale time sequence fusion characteristic sequence by utilizing a pre-trained video abstract generation model; based on a shot segmentation algorithm, segmenting the multi-scale time sequence fusion feature sequence into a basic segment set taking basic shots as a unit; generating a model by utilizing a pre-trained video abstract, and dynamically selecting core segments in a basic segment set based on each importance score and the basic segment set; and generating a dynamic video abstract by utilizing the pre-trained video abstract generation model based on the core segment, and outputting the dynamic video abstract. According to the scheme, a video abstract generation model obtained through unsupervised training is utilized, video key frames can be extracted, video abstracts with diversity and representativeness are obtained, the workload of manual intervention is reduced, and video retrieval and video monitoring are facilitated.","['G06F16/739', 'G06F16/75', 'G06F18/214', 'G06F18/241', 'G06F18/25']"
CN116309056A,"Image reconstruction method, device and computer storage medium","The invention provides an image reconstruction method, an image reconstruction device and a computer storage medium. The method comprises the steps of obtaining a target model; training of the target model involves a reverse process, which is: sequentially performing T-step denoising processing on the noise added sample with the first resolution by utilizing the predicted T-step data distribution so as to reconstruct a sample image; aiming at a target image smaller than the first resolution, utilizing the noise image matched with the first resolution obtained by sampling and the image matched with the first resolution after the target image is up-sampled to obtain a target noise adding image matched with the first resolution; sequentially executing W steps of target processing on the target noise adding graph based on the reverse process of the target model; the last step in the step W corresponds to the ith step in the step T, and i is smaller than a preset threshold step number N; and determining a repair image from the reconstructed image processed by the final target. By reducing the number of steps of the denoising process, the balance of image perceived distortion is ensured to some extent.","['G06T3/4053', 'G06N3/0464', 'G06N3/08', 'G06T3/4046']"
CN120069233A,Environment emergency auxiliary decision-making method and system based on artificial intelligence,"The invention discloses an artificial intelligence-based environment emergency auxiliary decision-making method and system, which comprise the steps of obtaining a plurality of historical environment disaster event examples, constructing multi-mode event characteristics of each historical environment disaster event, analyzing event triggering rules and corresponding disposal scheme triggering rules of each historical environment disaster event based on the multi-mode event characteristics, constructing a disaster environment knowledge graph, obtaining environment condition sensing information, carrying out environment emergency event prediction by combining the disaster environment knowledge graph, constructing an event situation prediction model, predicting situation change of a current environment emergency event, obtaining candidate disposal schemes of real-time environment emergency events of a target area by utilizing the disaster environment knowledge graph, introducing a multi-objective gray wolf optimization algorithm to conduct disposal scheme optimization to generate an optimal disposal scheme to conduct environment emergency decision-making auxiliary disposal, improving instantaneity, reliability and global optimality of environment emergency decision, and realizing quick and accurate environment emergency event.","['G06Q10/04', 'G06F18/20', 'G06N3/006', 'G06N5/025', 'G06Q50/26']"
US20230143198A1,System and method for viewshed analysis,"In variants, a method for viewshed analysis can include: determining a location, determining a set of location viewpoints for the location, determining a viewshed for the location, determining a set of view factors for the location, and determining a view factor representation for the location based the viewshed and the set of view factors, optionally determining a view parameter for the location, and/or any other suitable elements.","['G06Q30/0278', 'G06Q50/16', 'G06Q50/165', 'G06V20/176', 'G06V20/38', 'G06V2201/12']"
US20230385882A1,System and method for property analysis,"In variants, a method for property analysis can include: determining a property of interest, determining property information for the property, determining property attributes for the property, determining a value for the property, and optionally adjusting the value for the property. However, the method can additionally and/or alternatively include any other suitable elements.","['G06Q30/0278', 'G06Q50/16', 'G06Q50/163']"
CN118450191A,"Video script generation method, device, electronic equipment, storage medium and computer program product","The application provides a video script generation method, a device, electronic equipment, a storage medium and a computer program product, and relates to the technical field of: the technical field of video script, the method comprises the following steps: processing script demand data acquired from a user based on a preset large language model to form an initial script; acquiring optimized feedback data aiming at an initial script; and optimizing the initial script based on a preset large language model and optimizing feedback data to obtain a target script. According to the method and the device, the initial script is generated through the script demand data, the initial video script is optimized based on the feedback data, and the script meets the requirements better through optimizing the initial video script, so that the video script meeting the user demand better is generated. The scheme imitating the human authoring of the video script can promote the innovation and individualization of the video script.","['H04N21/44', 'H04N21/234']"
US20230377540A1,System and method for generating and/or adapting musical notations,"Aspects of embodiments to a method for providing a user with musical notations for playing a musical instrument. The method may comprise receiving source musical notation data descriptive of source musical notation information that can be played with a musical instrument and/or sung by one or more users; analyzing the received source musical notation data for generating a source notation analysis output; receiving at least one target requirement defining target musical notation information; and providing, based on the source notation analysis output and the at least one target requirement, target musical notation data descriptive of target musical notation information.","['G10G1/04', 'G10G1/00']"
CN119494522A,Employee job matching and deployment method and system based on artificial intelligence,"The invention provides an employee post matching and adjusting method and system based on artificial intelligence, which relate to the technical field of artificial intelligence and comprise the following steps: generating an optimized employee capability feature vector and extracting an employee capability development trend based on employee historical work data, combining team cooperation data, obtaining an employee comprehensive capability vector by utilizing a cross-modal comparison learning network, calculating a development potential index, constructing a post skill knowledge graph based on post explanation data and historical recruitment data, generating a post skill feature matrix and a team structure feature vector through a dynamic abnormal patterning neural network and an adaptive graph attention network, combining the employee comprehensive capability vector, calculating an employee-post matching degree score matrix, inputting the matching degree score matrix and the development potential index into a distributed multi-agent reinforcement learning model, constructing a reward function, generating and evaluating a deployment scheme through hierarchical task decomposition and Monte Carlo tree search, and finally outputting a deployment execution scheme.","['G06Q10/063118', 'G06F18/213', 'G06N3/042', 'G06N3/0464', 'G06Q10/063112']"
US20250232471A1,Visual localization of image viewpoints in 3d scenes using neural representations,"Approaches presented herein provide for visual localization by matching features of a query image with features obtained from representation of a three-dimensional (3D) environment. A model such as a neural radiance field (NeRF) can be trained to represent the 3D environment. When a query image is received, query features can be extracted at two different resolutions. A lower resolution set of query features can be compared against NeRF descriptor features for a set of training images, to narrow the search space by finding a set of coarse matches. Higher resolution query features can then be compared against sampled features of these coarse matches, to identify 2D-3D correspondences that can be used to calculate camera pose information for the query image.","['G06T7/74', 'G06T7/75', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
CN119990786A,A method and system for early warning of risk perception of oil and gas pipeline network operation status,"The invention discloses a risk perception early warning method and a system for the running state of an oil-gas pipe network, wherein the method comprises the steps of fusing multidimensional features of the running state of the pipe network according to real-time running data of the oil-gas pipe network to generate a space-time feature matrix; the method comprises the steps of inputting a space-time feature matrix into a deep Gaussian process model, carrying out probabilistic modeling on abnormal features in the running state of a pipe network, outputting a risk feature vector with confidence, constructing a three-dimensional risk concentration distribution field according to the risk feature vector, predicting the propagation path and the diffusion trend of the risk concentration distribution field, constructing a self-adaptive early warning threshold generation model based on the generation of an countermeasure network aiming at a prediction result, generating a multi-level early warning threshold changing along with the running state of the pipe network, and realizing risk perception early warning of the running state of the oil-gas pipe network according to the comparison result of the real-time risk feature and the early warning threshold. By utilizing the embodiment of the invention, dynamic risk assessment and self-adaptive early warning can be realized, and the safety and emergency response capability of the pipe network are enhanced.",[]
KR102473778B1,Artificial intelligence based smart fire detection device and non-fire alarm analysis system comprising the same,"The present invention relates to an artificial intelligence-based smart fire detection device and a non-fire alarm analysis system including the same. The artificial intelligence-based smart fire detection device comprises: a plurality of child detection devices which detect the occurrence of a fire by a heat detection method and smoke detection method, when a fire is detected in at least one detection device, transmit a fire detection signal through a first wireless communication network, when a fire occurrence determination signal is received, propagate the fire occurrence determination signal to the remaining detection devices through the first wireless communication network, and output a voice alarm and a flash alarm according to the fire occurrence determination signal; and a mother detection device which, when the fire detection signal is received, determines whether the signal is a non-fire alarm using a deep learning model based on standard non-fire alarm information, and transmits, when it is determined that a fire has occurred, the fire occurrence determination signal to the plurality of child detection devices through the first wireless communication network. By using the deep learning model, a non-fire alarm according to environmental factors can be effectively determined, and in case of a fire, human casualties can be minimized by performing a prompt interlocking alarm to an entire place where the fire detection devices are installed.","['G08B17/10', 'G06N3/08', 'G06Q50/10', 'G08B17/12', 'G08B25/10', 'G08B25/14', 'G08B29/12', 'G08B7/06']"
WO2023095460A1,System and method for automated transfer learning with domain disentanglement,"A system and method for automated construction of an artificial neural network architecture are provided. The system includes a set of interfaces and data links configured to receive and send signals, wherein the signals include datasets of training data, validation data and testing data, wherein the signals include a set of random number factors in multi-dimensional signals, wherein part of the random number factors are associated with task labels to identify, and nuisance variations. The system further includes a set of memory banks to store a set of reconfigurable deep neural network (DNN) blocks, hyperparameters, trainable variables, intermediate neuron signals, and temporary computation values including forward-pass signals and backward- pass gradients. The system further includes at least one processor, in connection with the interface and the memory banks, configured to submit the signals and the datasets into the reconfigurable DNN blocks, wherein the at least, one processor is configured to explore hyperparameters of regularization modules, pre-processing and post-processing methods such that the reconfigurable DNN blocks achieve nuisance-robust Bayesian inference to be transferable to new datasets with domain shifts.","['G06N3/0985', 'G06N3/045', 'G06N3/082', 'G06N3/096', 'G06N7/01', 'G06N3/084', 'G06N3/086', 'G06N3/092', 'G06N3/094']"
CN116682070B,Infrared video detection method and system for dangerous gas leakage under complex scene,"The invention discloses an infrared video detection method for dangerous gas leakage in a complex scene, which comprises the following steps: s1, inputting a fire smoke video to be tested under natural illumination into a pre-trained generation countermeasure network to generate infrared leakage gas data under a virtual complex scene; s2, inputting infrared leakage gas data into a pre-trained Flow FASTER RCNN network; s3, the Flow FASTER RCNN network respectively extracts the space texture information and the optical Flow motion information of the infrared leakage gas through a parallel space feature extraction channel and a motion optical Flow feature extraction channel, and inputs the space texture information and the optical Flow motion information into an RPN module after splicing to generate an area suggestion frame and a corresponding feature map sub-block; and judging whether dangerous gas leaks or not and judging the position of the leaked gas through the two full-connection layers. The invention can better fuse the motion information of gas leakage and improve the detection accuracy.","['G06V20/52', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T7/269', 'G06V10/54', 'G06V10/62', 'G06V10/766', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06V20/46', 'G06T2207/10016', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232']"
CN115834935B,"Multimedia information auditing method, advertisement auditing method, device and storage medium","The application provides a multimedia information auditing method, advertisement auditing method, equipment and storage medium, wherein the multimedia information auditing method comprises the following steps: acquiring multimedia information; based on a pre-trained multi-mode model, auditing elements in the multimedia information to obtain an auditing result of the multimedia information; when the type of the multimedia information is a multi-mode type, the auditing result indicates that the auditing is not passed, the auditing result comprises a multi-mode auditing result, the multi-mode type is used for indicating that the multimedia information comprises at least two multimedia types, the multi-mode auditing result is used for indicating non-compliant multi-mode elements in the multimedia information, and the multi-mode elements are elements comprising at least two multimedia types. And illegal elements in multiple modes are effectively identified based on the multiple-mode model, so that the comprehensiveness and accuracy of the multimedia information auditing are improved.",[]
CN117009491A,Corpus generation method and related device,"The application provides a corpus generation method and a related device. The embodiment of the application can be applied to intelligent customer service. The method comprises the following steps: after the standard query statement is obtained, a plurality of similar statements similar to the standard query statement are generated based on a natural language processing technology, then the similar statements are screened according to the semantic matching degree between the standard query statement and the obtained similar statements, only the similar statements with high semantic matching degree with the standard query statement can be used as effective warehousing statements, and after the warehousing statements are imported into a corpus, the corresponding relation between the warehousing statements and standard answers is established, so that corpus accumulation is realized, and compared with a corpus accumulation method which is manually exhausted, corpus generation efficiency is effectively improved, so that a corresponding automatic question-answering system has higher query recognition capability.","['G06F16/3329', 'G06F16/3344', 'G06F40/194', 'G06F40/30', 'Y02D10/00']"
US20250003899A1,Method and system of image analysis and critical dimension matching for charged-particle inspection apparatus,"Systems and methods for image analysis include obtaining a plurality of simulation images and a plurality of non-simulation images both associated with a sample under inspection, at least one of the plurality of simulation images being a simulation image of a location on the sample not imaged by any of the plurality of non-simulation images; and training an unsupervised domain adaptation technique using the plurality of simulation images and the plurality of non-simulation images as inputs to reduce a difference between first intensity gradients of the plurality of simulation images and second intensity gradients of the plurality of non-simulation images.","['G06T5/60', 'G01N23/2251', 'G06T7/001', 'G01N2223/401', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US20240249459A1,Data-driven physics-based facial animation retargeting,"One embodiment of the present invention sets forth a technique for retargeting a facial expression to a different facial identity. The technique includes generating, based on an input target facial identity, a facial identity code in an input identity latent space. The technique further includes converting a spatial input point from an input facial identity space of the input target facial identity to a canonical-space point in a canonical space. The technique still further includes generating one or more canonical simulator control values based on the facial identity code, an input source facial expression, and the canonical-space point. The technique still further includes generating a simulated active soft body based on one or more identity-specific control values, wherein each identity-specific control value corresponds to one or more of the canonical simulator control values and is in an output facial identity space associated with an output target facial identity.",['G06T13/40']
WO2021108382A1,Characterizing intra-site tumor heterogeneity,A method and a system for measuring intra-site heterogeneity in a tumor using magnetic resonance imaging (MRI). The method includes acquiring magnetic resonance (MR) images using MRI modality; segmenting tumor sites in the MR images; dividing each of the tumor sites into a plurality of sub-regions; deriving image biomarkers from each voxel or pixel in the plurality of sub-regions; classifying each voxel or pixel in the plurality of sub-regions into genotypes or molecular subtypes based on the extracted image biomarkers and a classifier model including associations between image biomarkers and genotypes or molecule subtypes; creating a distribution of genotypes or molecular subtypes in the each of the plurality of sub-regions based on classifications of voxels or pixels; generating spatial information of genotypes or molecular subtypes in the tumor sites based on the distribution; and measuring intra-site heterogeneity in the tumor sites.,"['G16H30/40', 'G06T7/0014', 'A61B5/0042', 'A61B5/055', 'A61B5/4064', 'G06T7/0012', 'G06T7/11', 'G06T7/168', 'G16H50/30', 'G06T2207/10088', 'G06T2207/10096', 'G06T2207/20021', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096']"
CN119107519A,"A controllable data generation method, system and medium based on potential diffusion model","The invention relates to a controllable data generation method, a system and a medium based on a potential diffusion model, wherein the method comprises the steps of U1. carrying out image coding on a noise picture and a target ROI picture through an image coder of the potential diffusion model to obtain data information embedded by the noise picture and ROI embedded data information, inputting target box information into an MLP model for identification to obtain target box embedded data information, coding a scene prompt word through a natural language editor of the potential diffusion model to obtain the prompt embedded data information, U2. carrying out splicing embedding on data based on the prompt embedded data information, the target box embedded data information and the ROI embedded data information by adopting a cross attention splicing algorithm based on self-adaptive learning. The invention not only solves the problems of difficult acquisition of a target detection part scene and an extreme sample, but also introduces target ROI information and box information to solve the problem of inaccurate controllability of the generated content of the diffusion model.","['G06V10/774', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06T11/00', 'G06V10/25', 'G06V10/765', 'G06V10/80', 'G06V10/82', 'G06V2201/07', 'Y02T10/40']"
US20240202584A1,Machine learning instancing,"Aspects of the present disclosure relate to machine learning instancing, where an instance of an agent (e.g., including processing of user input by a machine learning model to generate model output) is encapsulated as an agent object. In examples, an agent object is stored as a file, as a document, and/or in a database, among other examples. An agent object includes a persona definition and/or an object embedding memory, thereby defining various aspects of the agent. Thus, an agent object permits portability the agent, for example between users, across contexts, and/or for a variety of subsequent processing, among other examples.",['G06N20/00']
US20250097439A1,System and method for complementing video compression using video diffusion,"A computer-implemented method includes generating a set of weights for a diffusion model. The generating includes reducing fidelity of training frames of training image data to create frames of reduced-fidelity training image data, encoding the frames of reduced-fidelity training image data to create frames of compressed reduced-fidelity training image data, and training a first artificial neural network using the frames of compressed reduced-fidelity training image data where values of the weights are adjusted during the training. The values of the weights are sent to a computing device configured to use the values of the weights to establish a second artificial neural network configured to substantially replicate the first artificial neural network.","['H04N19/463', 'H04N19/136', 'H04N19/172', 'H04N19/42']"
CN118314022A,Multimode image fusion and super-resolution method based on conditional diffusion probability model,"The application belongs to the technical field of image processing, and discloses a multi-mode image fusion and super-resolution method based on a conditional diffusion probability model.","['G06T3/4053', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06T3/4046', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/20221', 'Y02T10/40']"
US20250180536A1,"Water quality management device, operation method thereof, and water quality management method","The present invention may provide a water quality management device including a spectral camera, a memory, and a processor, and an operating method thereof. The processor is configured to collect the plurality of spectral images for at least a portion of the stored water in response to a predefined event occurrence, classify the plurality of spectral images into a suspended material data set and a non-suspended material data set based on a presence or absence of a suspended material in the spectral images, perform learning to generate a water quality detection model used to detect water quality by using at least a portion of the suspended material data set and the non-suspended material data set, and store the water quality detection model generated through the learning.","['G01N21/25', 'G01N33/18', 'G01J3/2823', 'G06N3/08', 'G06Q50/06', 'G06Q50/10', 'G06V10/762', 'G06V10/764', 'G06V20/70', 'G01N2021/1765', 'G01N2201/1296']"
EP2571285A2,"Sound-reproducing apparatus, lighting apparatus, and suspended opening and closing apparatus","A sound-reproducing apparatus includes plural coupling portions, plural rods, plural shell portions, an actuator, and first, second, and third speakers.","['H04R1/028', 'F21V33/0056', 'H04R1/026', 'H04R1/227', 'H04R1/40', 'F21S8/061', 'F21V1/12', 'F21Y2115/10', 'Y10T74/18856']"
CN119672158B,"Remote sensing optical time sequence image reconstruction method, device, terminal and storage medium","The invention provides a remote sensing optical time sequence image reconstruction method, a device, a terminal and a storage medium, which belong to the technical field of remote sensing; inputting the cloud optical time sequence image with noise, the first SAR time sequence image, a shooting date sequence of the cloud optical time sequence image with noise and a noise diffusion step number t into a target sampler, and iteratively calling a t-time trained diffusion model to obtain a reconstructed cloud optical image sequence, wherein the reconstructed remote sensing optical time sequence image is composed of the cloud optical time sequence image and the reconstructed cloud optical image sequence. According to the invention, SAR time sequence images and shooting date sequences are introduced as priori information, and the cloud images are guided to be reconstructed by combining the high-quality image generating capability of the multi-mode diffusion model, so that the reliability of remote sensing optical time sequence image reconstruction can be effectively improved.",[]
CN115880187A,Single Image Reflection Removal Method and Related Equipment Based on Denoising Diffusion Probability Model,"The invention discloses a single-image reflection removing method based on a denoising diffusion probability model and related equipment, wherein the method comprises the steps of constructing the denoising diffusion probability model, and acquiring an original training image and a clean image corresponding to the original training image; when the original training image and the clean image are trained, inputting different Gaussian noises to the denoising diffusion probability model to obtain a target noise after the denoising diffusion probability model is fitted to the Gaussian noises; and performing inverse sampling on the original image based on the target noise to obtain a target clean image of the original image. The method uses the denoising diffusion probability model to remove the reflected light of the single image, and the denoising diffusion probability model has the capability of preserving the data semantic structure and stronger restoration capability in the aspect of fine granularity of the image, so that the image restoration after the reflected light removal achieves the effect of better reconstruction quality.",['Y02T10/40']
CN117934996A,A generative model training method and generation method for a vehicle top-down semantic segmentation map,"The invention relates to a model training method and a model generating method for generating a vehicle overlook semantic segmentation map, wherein the training method comprises the following steps: acquiring a training sample set of a vehicle overlook semantic segmentation map; constructing a generating model; inputting the vehicle overlook semantic segmentation graph into a variation self-encoder module to obtain a first hidden space representation; adding noise based on a forward process of the diffusion module, and generating a first hidden space representation containing the noise; inputting the image data and the point cloud data into an auxiliary module for representation fusion to obtain a second hidden space representation; generating a predicted vehicle top-view semantic segmentation map based on a backward process of the diffusion module and the auxiliary module; based on the difference between the predicted vehicle overlook semantic segmentation map and the vehicle overlook semantic segmentation map corresponding to the training sample set, parameters of the generated model are adjusted, and the training process of the generated model is completed. Compared with the prior art, the invention has the advantages of good fusion of various sensor data, good generalization performance and the like.","['G06V10/774', 'G06T3/4038', 'G06V10/26', 'G06V10/80', 'G06V20/56', 'G06T2200/32', 'Y02T10/40']"
CN118097318B,Controllable defect image generation method and device based on visual semantic fusion,"The patent provides a controllable defect image generation method and device based on visual semantic fusion. By using the large language model ChatGPT, the text description of the defect image is automatically generated in a specified format, so that the problem of time and labor-consuming data labeling is solved. And designing a defect generation model, wherein the model directly learns the characteristic representation of various foreground images from an encoder network through training the quantization variation without participation of positive samples, so that the problem that the positive and negative samples must be paired is solved. And the embedded space of the quantized variation self-encoder network is discretely sampled by using a transducer network in combination with semantic information, so that the problem of defect image controllability is solved. Finally, the feature images are fused through a U-NET network, and a controllable defect image generation method capable of generating visual semantic fusion of defects on a background image according to text information is researched.","['G06V10/764', 'G06N3/048', 'G06V10/80', 'G06V10/82']"
US20240105277A1,Drug discovery via reinforcement learning with three-dimensional modeling,"Reinforcement learning is coupled to a deep generative model based on a three-dimensional scaffold model to generate drug candidates targeting a particular protein, building up atom or functional groups from a starting core scaffold. A reward function can use parallel graph neural network models and take the particular protein into account when calculating reward based on criteria such as binding, synthetic accessibility, and the like. In an agent-critic reinforcement learning model, the agent learns to build molecules in three-dimensional space while optimizing the criteria.","['G16B15/30', 'G16B15/20', 'G16B40/00', 'G16B40/20']"
US20120197105A1,Methods for detecting abnormalities and degenerative processes in soft tissue using magnetic resonance imaging (MRI),"The present invention provides methods to detect degenerative processes and abnormalities in soft tissues at high spatial resolution, high signal-to-noise ratio and short scanning times, based on quantitative tissue properties. These methods might provide a useful tool to detect and assess abnormalities in soft tissues and to monitor disease progression.","['A61B5/055', 'G01R33/50', 'A61B2576/026', 'A61B5/0042', 'A61B5/1073', 'A61B5/4064', 'A61B5/4076', 'G16H30/40']"
CN107007255A,Electronic type ophthalmic lens with sleep monitor,"This document describes the eyelid position sensor system and/or eye movement sensing system for the ophthalmic lens with electronic system, for recording the data associated with the sleep of wearer.Eyelid position sensor system is bonded to a part for the electronic system in ophthalmic lens.In at least one embodiment, electronic system includes system controller and data management system.In at least one embodiment, eyelid position sensor system is used for determining eyelid position, and eye movement sensing system is used for determining eye position, is clear-headed, sleeping so that the system controller determines wearer, is in REM sleep.","['A61B5/4809', 'A61B5/4806', 'A61B5/002', 'A61B5/1103', 'A61B5/18', 'A61B5/4812', 'A61B5/6821', 'A61B5/7225', 'G01J1/42', 'G02C11/10', 'G02C7/04', 'A61B2560/0209', 'A61B3/113']"
US20240310515A1,Acoustic depth map,"A depth sensing apparatus configured to generate a depth map of an environment, the apparatus including an audio output device, at least one audio sensor and one or more processing devices configured to cause the audio output device to emit an omnidirectional emitted audio signal, acquire echo signals indicative of reflected audio signals captured by the at least one audio sensors in response to reflection of the emitted audio signal from the environment surrounding the depth sensing apparatus, generate spectrograms using the echo signals and apply the spectrograms to a computational model to generate a depth map, the computational model being trained using reference echo signals and omnidirectional reference depth images.","['G01S13/86', 'G01S13/89', 'G01S15/104', 'G01S15/86', 'G01S15/876', 'G01S15/89', 'G01S15/931', 'G01S17/86', 'G01S17/89', 'G01S17/931', 'G06T7/593', 'G01S13/02', 'G01S15/02']"
CN116704580A,A face forgery detection method based on depth information decoupling,"The invention provides a generalization face counterfeiting detection method based on depth information decoupling, which comprises the steps of firstly inputting a face image into a face feature extraction basic network, extracting corresponding face characterization information, and then transmitting the face characterization information to a depth information decoupling module, wherein the depth information decoupling module decouples the face characterization information into true and false judging related information and true and false judging unrelated information, and the true and false judging unrelated information comprises face image generation method related information and other information such as a face expression and the like; meanwhile, the depth information decoupling module also restricts the information related to the true and false discrimination and the information unrelated to the true and false discrimination to be mutually independent, so that the robustness and generalization of the fake detection model are improved.","['G06V40/168', 'G06N3/0464', 'G06N3/08', 'G06V10/774', 'G06V10/82', 'G06V40/172', 'G06V40/40']"
CN110728636A,"Monte Carlo rendering image denoising model, method and device based on generative confrontation network","The invention discloses a Monte Carlo rendering image denoising model based on a generative confrontation network and a construction method thereof, wherein the Monte Carlo rendering image denoising model comprises the following steps: constructing a training sample, constructing a generating countermeasure network, including a denoising network and a discrimination network, wherein the denoising network is used for denoising an input noise rendering image and auxiliary characteristics and outputting the denoising rendering image, and the discrimination network is used for classifying the input denoising rendering image and a target rendering image corresponding to the noise rendering image and outputting a classification result; the network parameters of the generative countermeasure network are optimized by utilizing the training sample, the denoising network determined by the network parameters is used as a Monte Carlo rendering image denoising model, and the method and the device for denoising the Monte Carlo rendering image are further disclosed, so that denoising of the Monte Carlo rendering image containing noise can be realized.","['G06T5/70', 'G06N3/045', 'G06T5/20', 'G06T5/60', 'G06V10/30', 'G06V10/7715', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US20210022335A1,Use of cyclodextrins as agrochemical delivery system,The present invention relates to the use of cyclodextrins for increasing biological activity and improving retention and/or bioavailability of agrochemicals such as pesticides.,"['A01N25/10', 'A01P3/00', 'A01N25/22', 'A01N37/34', 'A01N43/653', 'A01P7/00']"
US20250057161A1,Use of cyclodextrins as agrochemical delivery system,"The present invention relates pesticidal complexes, pesticidal delivery systems and compositions, as well as processes of preparation and uses thereof. The present invention also relates to the use of cyclodextrins for increasing biological activity and improving uptake, penetration, retention and/or bioavailability of agrochemicals such as pesticides.","['A01N43/38', 'A01N31/06', 'A01N33/18', 'A01N43/56', 'A01N43/88', 'A01N47/04', 'A01N47/14', 'A01N47/34', 'A01N47/38', 'A01N47/40', 'A01P13/00', 'A01P3/00', 'A01P7/04']"
US20240320433A1,Speculative decoding in autoregressive generative artificial intelligence models,"Certain aspects of the present disclosure provide techniques and apparatus for generating a response to an input query using generative models. The method generally includes generating, based on an input query and a first generative model, a first plurality of sets of tokens. The first plurality of sets of tokens are output to a second generative model for verification. While waiting to receive an indication of a selected set of tokens from the first plurality of sets of tokens, a second plurality of sets of tokens are speculatively generated. The indication of a selected set of tokens from the first plurality of sets of tokens is received. Tokens from the second plurality of sets of tokens associated with the selected set of tokens are output to the second generative model for verification, and the selected set of tokens is output as a response to the input query.","['G06F40/284', 'G06F16/2246']"
US20240362468A1,Hybrid generative artificial intelligence models,"Certain aspects of the present disclosure provide techniques and apparatus for generating a response to an input query using a generative artificial intelligence model. An example method generally includes receiving an input for processing. A prompt representing the received input is generated based on the received input, contextual information associated with the received prompt, and a prompt-generating artificial intelligence model. The generated prompt is output to a generative artificial intelligence model for processing. A response to the generated prompt is received from the generative artificial intelligence model and output as a response to the received input.","['G06N3/0475', 'G06N3/045', 'G06N3/047']"
US12119090B1,Utilizing masked autoencoder generative models to extract microscopy representation autoencoder embeddings,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for training and utilizing generative machine learning models to generate embeddings from phenomic images (or other microscopy representations). For example, the disclosed systems can train a generative machine learning model (e.g., a masked autoencoder generative model) to generate predicted (or reconstructed) phenomic images from masked version of ground truth training phenomic images. In some cases, the disclosed systems utilize a momentum-tracking optimizer while reducing a loss of the generative machine learning model to enable efficient training on large scale training image batches. Furthermore, the disclosed systems can utilize Fourier transformation losses with multi-stage weighting to improve the accuracy of the generative machine learning model on the phenomic images during training. Indeed, the disclosed systems can utilize the trained generative machine learning model to generate phenomic embeddings from input phenomic images (for various phenomic comparisons).","['G16B45/00', 'G06T5/73', 'G16B20/00', 'G16B40/00', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084']"
WO2024086143A1,Native expansion of a sparse training dataset into a dense training dataset for supervised training of a synonymous variant sequence generator,"Disclosed is a data representation and computational process robust to data sparsity and lack of annotative/target sequences in deep learning applications referred to as Auto-Pairing. Auto-Pairing enables the expansion of initially inadequate datasets from n to ~n2 data points, providing sufficient learning instances to produce accurate therapeutic predictions. Auto-Pairing also enables the transformation of initially unsupervised datasets to supervised datasets, allowing a direct mapping from an input therapeutic to a target therapeutic. The Auto-Pairing process and representation comprises a novel integration of four existent general purpose computational sub-processes with domain-specific fine tunings: Clustering, Pairing, Pre-processing, and Modeling, enabling the generation of functional therapeutic variants of any desired small dataset of a certain therapeutic family, and even non-biological data.","['G16B15/20', 'G06N20/10', 'G06N20/20', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/0499', 'G06N3/084', 'G06N3/086', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N5/01', 'G06N7/01', 'G16B40/20']"
WO2024131652A1,"Special effect processing method and apparatus, and electronic device and storage medium","Provided in the embodiments of the present disclosure are a special effect processing method and apparatus, and an electronic device and a storage medium. The special-effect processing method comprises: in response to a special effect trigger operation, presenting a special effect drawing canvas; receiving a drawing operation of a trigger object, which drawing operation acts on the special effect drawing canvas, presenting a drawing silhouette picture corresponding to the drawing operation, and filling the drawing silhouette picture with first content for presentation; and when a preset presentation condition is met, filling the drawing silhouette picture with second content to obtain a special effect picture, and presenting the special effect picture. By means of the embodiments of the present disclosure, personalized customization and an interesting experience of a special effect texture map can be realized, so as to enrich filling content of an image, thereby improving the usage experience of a user.","['G06F3/04845', 'G06T11/20', 'G06T11/40']"
US12367630B2,Generative films,"A computer implemented method includes receiving, from a remote system, object data comprising values of a set of adjustable parameters of a respective object representation model for each object of a plurality of objects and compositing data indicating at least a respective trajectory of each of the plurality of objects relative to a reference frame. The method includes processing the object data and the compositing data using the respective object representation models to generate output video data depicting a scene including an animated representation of each object of the plurality of objects following the respective trajectory relative to the reference frame. For each object of the plurality of objects, the respective object representation model comprises a respective neural network and is arranged to generate, using the respective neural network, animated representations of the object in which a geometry the object is controllable by the set of adjustable parameters.","['G06T13/40', 'G06T2200/24']"
US11846692B2,Motion compensation for MRI imaging,"Training a neural network to correct motion-induced artifacts in magnetic resonance images includes acquiring motion-free magnetic resonance image (MRI) data of a target object and applying a spatial transformation matrix to the motion-free MRI data. Multiple frames of MRI data are produced having respective motion states. A Non-uniform Fast Fourier Transform (NUFFT) can be applied to generate respective k-space data sets corresponding to each of the multiple frames of MRI; the respective k-space data sets can be combined to produce a motion-corrupted k-space data set and an adjoint NUFFT can be applied to the motion-corrupted k-space data set. Updated frames of motion-corrupted MRI data can be formed. Using the updated frames of motion corrupted MRI data, a neural network can be trained that generates output frames of motion free MRI data; and the neural network can be saved.","['G01R33/5608', 'G01R33/56509', 'G06T5/60', 'G06T5/73', 'G06T7/262', 'G01R33/482', 'G01R33/4824', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084']"
US20240233285A1,System and method for user actionable virtual image generation for augmented & virtual reality headsets,A system for generating and providing an object in the field of view (FOV) of a user's augmented reality or virtual reality (AR/VR) session responsive to a verbal request for the object is described herein. An AR/VR communication component receives a verbal request for an object from the user and produces a text request for the object based on the verbal request. 2D image and 3D model generation components generate a 3D model of the object which is provided within the FOV of the user's AR/VR session.,"['G06F3/167', 'G06F3/011', 'G06F3/013', 'G06T17/00', 'G06T17/20', 'G06T19/006', 'H04L65/1089']"
EP4593027A1,Method for converting medical images by means of artificial intelligence by using image quality conversion and device therefor,"An aspect of the present invention relates to a method for converting medical images and, more specifically, to an image conversion method for converting medical images by using a generative adversarial network (GAN). An embodiment of the present invention provides a new model learning method wherein a learning model is trained to intentionally generate a blurred target image obtained by blurring a target image and to compare and distinguish the blurred target image with the target image such that an output image having an improved contrast ratio can be obtained.","['G06N3/08', 'A61B5/055', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/096', 'G06V10/75', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'A61B6/5211']"
CN103148507A,Secondary air distribution method and system for pulverized coal boiler with swirling combustion of front-back hedging,"The invention discloses a secondary air distribution method for a pulverized coal boiler with swirling combustion of front-back hedging. The method comprises the steps of establishing a mesh structure model of the boiler; according to the mesh structure model, establishing a mathematical model of each process which is formed by the pulverized coal combustion; according to the established mathematical model, simulating the process of the pulverized coal combustion, and obtaining a proportion of an air volume with complete combustion in a total secondary air volume when the gas concentration distribution inside the boiler meets a preset index; and when the boiler is in operation, according to the proportion of the air volume with the complete combustion in the total secondary air volume, executing air distribution of the secondary air for the boiler. In addition, the invention further discloses a secondary air distribution system for the pulverized coal boiler with swirling combustion of front-back hedging. According to the method and the system provided by the invention, the problem that the accuracy caused by manual air distribution is not high to lead to unstable combustion inside the boiler is overcome, and the combustion efficiency of the boiler is improved. Meanwhile, the contaminants which are produced during the combustion process are greatly reduced.",[]
CN103148506A,Secondary air distribution method for pulverized coal boiler with swirling combustion of front-back hedging,"The invention discloses a secondary air distribution method for a pulverized coal boiler with swirling combustion of front-back hedging. The method comprises the steps of establishing a mesh structure model of the boiler; according to the mesh structure model, establishing a mathematical model of each process formed during the pulverized coal combustion; according to the established mathematical model, simulating the process of the pulverized coal combustion; obtaining the proportion of an air volume with complete combustion in a total secondary air volume when the temperature field distribution in the boiler meets a preset index; and when the boiler is in operation, executing air distribution of the second air for the boiler according to the proportion of the air volume with complete combustion in the total secondary air volume. In addition, the invention further discloses a secondary air distribution system for the pulverized coal boiler with swirling combustion of front-back hedging. According to the method and the system provided by the invention, the problem that the accuracy caused by manual air distribution is not high to lead to unstable combustion inside the boiler is overcome, and the combustion efficiency of the boiler is improved. Meanwhile, the contaminants which are produced during the combustion process are greatly reduced.",[]
CN112560456A,Generation type abstract generation method and system based on improved neural network,"The invention relates to the technical field of natural language processing, in particular to a method and a system for generating a generative abstract based on an improved neural network, which comprises the following steps: the text is divided into words, is processed in a partitioning mode and is converted into a one-hot coded vector; carrying out word coding processing on the one-hot coded vector to obtain a training parameter matrix and word codes with high representation; introducing a context matrix and word codes to perform softmax operation to obtain a word attention matrix, performing dot product on the word attention matrix and the results of the hidden layer, and weighting to obtain a sentence vector; sentence coding processing is carried out on the sentence vectors to obtain sentence codes with high representation; introducing a random sentence attention matrix and sentence codes to perform softmax operation to generate a document vector; and inputting the text vector as an initialization parameter of a decoder into the decoder for decoding operation to generate a text abstract. The invention improves the attention granularity of the model, can more accurately capture the key information in the article and improves the accuracy of generating the abstract.","['G06F40/258', 'G06N3/044', 'G06N3/045']"
CN117495993A,Image generation model construction method and system,"The invention discloses a method and a system for constructing an image generation model, and relates to the field of image processing. The construction method comprises the following steps: constructing a first countermeasure neural network, a second countermeasure neural network and a third countermeasure neural network, and respectively training by utilizing a first training set to obtain an image segmentation teacher model, an image shadow removal teacher model and an image color clustering teacher model; constructing an initial image generation model; and training the image generation model by using the image segmentation teacher model, the image shadow removal teacher model and the image color clustering teacher model by using a second training set to obtain a final image generation model. Compared with the prior art, the model constructed by the invention can realize the conversion of multi-model inference such as complex image conversion and the like into single-model inference for image generation, and can greatly reduce the consumption of computing resources and shorten the processing time.","['G06T11/001', 'G06N3/0455', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06N3/096', 'G06T11/206', 'G06V10/26', 'G06V10/52', 'G06V10/56', 'G06V10/762', 'G06V10/764', 'G06V10/806', 'G06V10/82']"
US11386555B2,Assessment of arterial calcifications,Embodiments discussed herein facilitate employing a pretrained model to determine risk(s) of adverse event(s) based on Computed Tomography (CT) image volume(s) of an artery and/or training a model to determine such risk(s). Example embodiments can determine risk based on territory-specific calcium score(s) and/or intensity/morphological/location features discussed herein. Various embodiments can determine risk(s) based on a single CT image volume and/or change(s) in CT image volumes taken over a series of time points.,"['G06T7/0012', 'G06F18/241', 'G06K9/6268', 'G06N20/00', 'G06T3/4053', 'G06T7/33', 'G06T7/38', 'G06T7/62', 'G06V10/40', 'G06V10/454', 'G06V10/82', 'G16H30/40', 'G16H50/30', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N5/01', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30101', 'G06T2211/424']"
CN118865993A,"Speech signal noise reduction method, system and device","The present invention relates to the field of speech signal processing technologies, and in particular, to a method, a system, and an apparatus for noise reduction of speech signals. The method comprises the following steps: performing self-adaptive framing treatment on the voice signal data to be processed to obtain framing voice signal data; carrying out semantic embedding space processing according to the framing voice signal data to obtain semantic embedding space data; carrying out semantic vector field construction according to the semantic embedded space data to generate voice semantic vector field data; voice noise area marking is carried out on voice semantic vector field data, and semantic noise area data are generated; performing noise frame restoration processing according to the semantic noise region data to generate noise-reduced voice signal data; auditory masking spectrum correction is performed on the noise-reduced speech signal data to generate enhanced speech signal data. According to the invention, the voice signal is guided to be noise-reduced through semantic information accurately, and even under complex scenes such as low signal-to-noise ratio, excellent noise reduction effect can be obtained, so that user experience is improved remarkably.","['G10L21/0224', 'G10L15/187', 'G10L21/0232', 'G10L25/18', 'G10L25/24']"
US12292915B1,Security for generative models using attention analysis,"Devices and techniques are generally described for security threat mitigation for generative machine learning models. In some examples, first prompt data including first data associated with a first natural language input and a first span may be determined. An LLM may determine first plan data using the first prompt data. The first plan data may include a call to the first API. A first classifier model may determine a first trust score for the first span. A first attention score may be determined for the first span and the first action plan. Second plan data may be generated based on at least one of the first trust score and the first attention score or the second trust score and the second attention score.","['G06F16/35', 'G06F16/383', 'G06F40/30', 'G06F40/40']"
US20250029212A1,Method and apparatus for restoring a target restoration region in an image,"A method may include acquiring a first image that is obtained by adding noise to a second image, the second image comprising a target restoration region. The method may include performing at least one first denoising process on the first image using a first artificial intelligence (AI) network to obtain a first denoising result. The method may include restoring the target restoration region based on the first denoising result using a second AI network to obtain a restored image.","['G06T3/4046', 'G06T5/10', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T5/77', 'G06T2207/20021', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
CN116167023A,Plug-and-play black-box model watermark embedding method and device,"The invention provides a plug-and-play black box model watermark embedding method and equipment. The method comprises the following steps: step 1, generating a watermark detection network M_ pty and a watermark verification sample X_v; and 2, embedding the watermark detection network M_ pty obtained in the step 1 into a target network M_target to be protected. The method for embedding the watermark into the target model by inserting the trained exclusive watermark verification model into the target model is realized without fine adjustment of parameters of the target model, so that the fidelity of the model is ensured to a great extent, the training time and the training resource cost are saved, the model with different structures and different data sets is highly universal, and the method can be applied to a real scene to process a real task with a complex DNN model.","['G06F21/16', 'G06N3/08']"
US20250123902A1,Hybrid Cloud-Edge Computing Architecture for Decentralized Computing Platform,"Disclosed are systems and methods for a hybrid cloud-edge computing platform using decentralized networks for solving resource-intensive computation tasks such as machine learning and video processing tasks. In some respects, the cloud-edge computing platform comprises a coordinator cluster and worker nodes partitioned into shards, which include cloud-based networks and edge networks, and which cater to a wide range of computation requirements. The coordinator cluster manages workloads by selecting the appropriate shard and worker nodes to execute tasks based on computed efficiency scores. Worker nodes may be incentivized with rewards such as cryptocurrency tokens for successful completion of tasks. The disclosed architecture also supports the pipelining of multiple tasks in a workload, where the output of one task is used as input for another task. In some respects, the computing architecture includes a blockchain-supported edge network, which enables verifying compute tasks and managing reward distribution for worker nodes using smart contracts.","['G06F9/5083', 'H04L9/50', 'G06F9/4881', 'G06F9/5027', 'G06F9/5066', 'G06F9/5072', 'G06F2209/5017', 'H04L9/3218']"
CN119152319A,"Pre-training model fine tuning method, application method and device for data protection","The application discloses a pre-training model fine tuning method, an application method and a device for data protection, wherein the method comprises the steps of creating a proxy model for data protection; the method comprises the steps of carrying out iterative fine adjustment on a proxy model for a preset time step according to a preset face image set and a description text thereof to obtain a proxy personalized generation model, carrying out attack on the proxy personalized generation model by using the preset countermeasure sample set and the description text to obtain a disturbance value, adding the disturbance value into the preset countermeasure sample set, continuously executing the step of carrying out attack on the proxy personalized generation model until attack times reach a preset time threshold to obtain a target countermeasure sample, carrying out iterative fine adjustment on the proxy model for the preset time step again by using the target countermeasure sample, and obtaining a final proxy personalized generation model when the current fine adjustment times reach the preset disturbance threshold. By adopting the embodiment of the application, the calculation requirements in the actual training scene are less, and the waste of calculation resources is reduced.","['G06V10/774', 'G06N3/096', 'G06V10/82', 'G06V40/16']"
WO2018183355A1,Prebiotic formulations,"Provided herein are compositions comprising a biocompatible microsphere, a biofilm- generating probiotic bacterium, a prebiotic, and/or a prebiofilmic. Methods for preparing and formulating the compositions and methods for treating or preventing a disease using the compositions are also provided.","['A61K9/1647', 'A61K9/16', 'A61K9/1652']"
US20210329026A1,Reconstructing missing complex networks against adversarial interventions,"Methods, systems, devices and apparatuses for reconstructing a network. The network reconstruction system includes a processor. The processor is configured to determine an unknown sub-network of a network. The unknown sub-network includes multiple unknown nodes and multiple unknown links. The processor is configured to determine the unknown sub-network based on a known sub-network that has multiple known nodes and multiple known links, a network model and an attacker's statistical behavior to reconstruct the network. The processor is configured to determine one or more network parameters of the network. The network processor is configured to provide a probability of an outcome of an input or observation into the network or into a second network that has the one or more network parameters of the network.","['H04L41/145', 'G06N20/00', 'G06N7/005', 'G06N7/01', 'G06N7/08', 'H04L41/0866', 'H04L41/142', 'H04L41/147', 'H04L41/16', 'H04L63/1425', 'H04L63/1441', 'H04L41/12']"
EP4341889A1,Medical imaging,"The present disclosure relates generally to medical imaging, and more specifically to enhancing medical images (e.g., images taken in low-light conditions) using machine-learning techniques. An exemplary method of obtaining an enhanced fluorescence medical image of a subject comprises: receiving a fluorescence medical image of the subject (e.g., NIR images); providing the fluorescence medical image to a generator of a trained generative adversarial network (GAN) model trained using a plurality of white light images; and obtaining, from the generator, the enhanced fluorescence medical image of the subject.","['G06T5/94', 'G06T5/92', 'G06T11/00', 'G06T5/50', 'G06T5/60', 'G06T7/11', 'G06T2207/10064', 'G06T2207/10068', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2210/41']"
US12223431B2,Inverse neural network for particle detection in a solid-state-devices,"For training to and/or estimating location, energy level, and/or time of occurrence of incident radiation on a solid-state detector, a machine-learned model, such as a neural network, performs the inverse problem. An estimate of the location, energy level, and/or time is output by the machine-learned model in response to input of the detected signal (e.g., voltage over time). The estimate may account for material property variation of the solid-state detector in a rapid and easily calculated way, and with a minimal amount of data.","['G06N3/088', 'G06N3/045', 'G01T1/16']"
US20240289095A1,System and method providing interaction mechanism,"A website building system (WBS) includes at least one processor, and a mid-transition interaction system running on the at least one processor to enable a designer using the WBS, to build a transitional page. The mid-transition interaction system includes at least one database storing designer parameters and parameters of end-users accessing websites and transitional pages created by the WBS, and an input presenter to determine a personalized input mechanism to present at least content to the designer according to least the designer parameters and the parameters of end-users for use with at least one of: a transitional page creator to enable the designer to build the transitional page; and a communicator enabling communication between the designer and at least one end-user.","['G06F16/986', 'G06F16/958', 'G06F8/20', 'G06F8/38']"
CN115660147A,Information propagation prediction method and system based on influence modeling between propagation paths and in propagation paths,"An information propagation prediction method and system based on influence modeling between propagation paths and in propagation paths relates to the technical field of information propagation prediction and is used for solving the problem of prediction of popularity increase of information in a social network after a period of time. The technical points of the invention comprise: modeling the cascade graph by using a graph neural network to obtain node representation of aggregation neighbor node states and characteristics; sampling the whole cascade network graph by a deep walking algorithm to obtain a sequence set of the cascade graph, and splicing the graphic neural network embedded representation and the Deepwalk embedded representation to update information of each node in the sequence; the node representation sequence with the neighbor information is input into the bidirectional LSTM, and the sequence is integrated by the time sequence information guided by the attention mechanism, so that the comprehension capability and the prediction capability of the cascade prediction model are enhanced. The invention considers the influence transmissibility between cascade propagation paths and in the propagation paths, and the effectiveness of the complementarity of the included time sequence and the structural factors.",[]
JP2025051621A,Image Generation Method,"To provide an image generation method.SOLUTION: A method includes: receiving input text and layout information; decomposing the input text into one or more global features and one or more local features; coding the one or more global features into a global vector, and coding the one or more local features into a local vector; predicting a global noise from the global vector and an initial image representation using a trained neutral network (NN); predicting an initial local noise from the one or more local vectors and the initial image representation for each local feature by using the trained NN; determining a final local noise for each local feature using the initial local noise and the global noise; synthesizing the predicted global noise and the final local noise into a synthesized noise using the layout information; and removing noise in the initial image representation by using the synthesized noise and providing a next image representation.SELECTED DRAWING: Figure 10","['G06T11/00', 'G06F3/04845', 'G06T5/70', 'G06T2207/20084']"
CN119407199A,Electromagnetic-assisted nickel-based alloy laser melting deposition crack suppression method and system,"The invention provides an electromagnetic-assisted nickel-based alloy laser melting deposition crack suppression method and system, which relate to the technical field of automatic control, and are used for constructing an intelligent control system, carrying out deep fusion on multi-source heterogeneous sensing data, predicting in real time, generating a prediction result, setting a reward function and an action-value network, solving to obtain an optimal control strategy, analyzing and outputting, and constructing a three-dimensional electromagnetic field distribution matrix. The method comprises the steps of combining real-time feedback of the appearance of a molten pool, exciting directional flow and nonlinear oscillation of the molten pool according to a resonance effect, obtaining oscillation parameters, predicting thermodynamic behavior corresponding to the molten pool according to the oscillation parameters, feeding back thermodynamic prediction results to a central control unit, detecting the appearance of the surface of a part, extracting defect characteristic parameter vectors, inverting defect influence factors, generating a dynamic regulation curve, dispersing the dynamic regulation curve into multidimensional control instruction vectors, updating a preset regulation model, outputting optimized regulation model parameters, and performing crack suppression operation again.","['B22F10/28', 'B22F10/50', 'B22F10/85', 'B33Y10/00', 'B33Y50/02', 'Y02P10/25']"
US20230126877A1,Synthetic data generation and annotation for tumor diagnostics and treatment,"Certain aspects of the present disclosure provide techniques for training a tumor detection model. A method generally includes processing an input scan image of a tumor in a first state using a first computational model configured to simulate growth of the tumor in a first configuration to generate model output images of the simulated tumor comprising at least a first model output image representing the tumor in a second state, wherein the first model output image comprises a timestamp associated with the second state, training a first machine learning model to convert the first model output image to a first synthesized scan image, and training a second machine learning model to detect the simulated tumor in image data using the first synthesized scan image and the input scan image.","['G06T7/0014', 'G06V10/774', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
WO2017091600A9,Pyrazole acc inhibitors and uses thereof,"The invention provides pyrazole compounds of formula I inhibiting Acetyl CoA Carboxylase (ACC), compositions and uses thereof for the treatment of obesity or as fungicides.","['C07D495/04', 'A01N43/90', 'A61P3/04', 'A61P31/04', 'A61P31/10', 'A61P33/00', 'C07D487/04', 'C07D491/048', 'C12N9/93', 'C12Y604/01002']"
CN103546760A,"Image coding device, image coding method, camera and portable phone","Provided is an image processing apparatus which includes a setting unit assigning a control block, which is a control unit of a filter process that is locally performed with respect to an image, to an initial position of the image determined based on a predetermined reference point; a movement unit moving the control block, which has been assigned to the initial position of the image by the setting unit, a to a position in which the result of the filter process is improved; and a filter processing unit performing the filter process for the respective control blocks which has been moved by the movement unit.","['H04N19/117', 'H04N19/127', 'H04N19/172', 'H04N19/70', 'H04N19/82', 'H04N19/86']"
US20240404225A1,Avatar generation from digital media content items,"A system for generating avatars from user self-images is disclosed, whereby the system accesses a media content item of a user that includes a face of the user, analyzes data associated with the media content item using a first machine learning model to generate a first modified media content item, parses a portion of the first modified media content item corresponding to the face of the user, and analyzes data associated with the portion of the first modified media content item using a second machine learning model to generate a digital avatar for the user.","['G06F3/0482', 'G06T19/20', 'G06T7/74', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06T2219/2021']"
US11152123B1,Processing brain data using autoencoder neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing brain data using autoencoder neural networks. One of the methods includes obtaining brain data captured by one or more sensors characterizing brain activity of a patient; processing the brain data to generate modified brain data that characterizes a predicted local effect of a future treatment on the brain of the patient; processing the modified brain data using an autoencoder neural network to generate reconstructed brain data; and determining, using the reconstructed brain data, a predicted global effect of the future treatment on the brain of the patient.","['A61B5/7253', 'A61B5/0044', 'A61B5/4064', 'A61B5/4848', 'A61B5/7267', 'G06N3/045', 'G06N3/088', 'G16H20/30', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'A61B2505/09', 'A61B2576/026', 'A61B5/0042', 'A61B5/055', 'A61B5/14553', 'A61B5/372', 'G01R33/4806', 'G01R33/5608', 'G01R33/56341', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40']"
CN112419340A,"Generation method, application method and device of cerebrospinal fluid segmentation model","The embodiment of the invention provides a generation method, an application method and a device of a cerebrospinal fluid segmentation model. The embodiment of the invention obtains the head CT perfusion imaging CTP image which does not comprise the infarct focus, or the CTP image comprises an infarct focus but the infarct focus is not adhered to cerebrospinal fluid, a generating type confrontation network model and initial parameter values of the generating type confrontation network model are set according to the CTP image construction sample data, the generating type confrontation network model is trained by utilizing the sample data to obtain the trained generating type confrontation network model, the generated network model in the trained counternetwork model is used as a cerebrospinal fluid segmentation model, and the sample data required by training the cerebrospinal fluid segmentation model can be constructed by utilizing a normal head CTP image, and then training obtains the cerebrospinal fluid segmentation model, establishes the basis for utilizing the cerebrospinal fluid segmentation model to distinguish the cerebrospinal fluid and the infarct focus of adhesion from the CTP image.","['G06T7/11', 'G06N3/045', 'G06N3/08', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/30016']"
CN111917765A,Network attack flow generation system based on generation type countermeasure network,"The invention relates to a network attack flow generation system based on a generation type countermeasure network, belonging to the technical field of network security. The invention generates the network attack flow through training by applying the generating type confrontation network algorithm, is used for simulating the attack flow in the network environment, can be used for verifying the processing capacity of the safety protection system on abnormal data, and can also be applied to a network target range as a generation source of the attack flow.",['H04L63/1441']
CN112801911B,Method and device for removing text noise in natural image and storage medium,"The application discloses a method and a device for removing text noise in natural images and a storage medium, wherein the method comprises the following steps: the image semantic segmentation network detects an area containing literal elements in an image to be repaired, and takes a segmentation recognition area as an area mask to be repaired; repairing the region containing the literal elements in the image to be repaired by using the mask of the region to be repaired according to the image repairing model; the image restoration model is a generator that generates an countermeasure network. According to the method and the device for detecting the text element areas, the text element areas which are common in the image to be repaired can be detected rapidly and automatically, text noise elements in the natural image can be removed selectively and automatically, and the areas which need to be repaired can be corrected in a manual interaction mode. The image restoration method based on the generation countermeasure network is used, and the restored image is more natural and lifelike.","['G06T5/70', 'G06F18/214', 'G06T5/77', 'G06T7/11', 'G06T2207/20081', 'G06T2207/30176']"
US12039699B2,Method and system for simulating and constructing original medical images from one modality to other modality,"The present invention relates to an improved method and system for simulating and constructing original actual Magnetic Resonance Images MRI from first modality of a patient to second modality, wherein the system is configured to receive an input MRI image taken in first modality, pre-process the input MRI image, send the processed image to a Convolutional Neural Network (CNN), and obtain the new constructed MRI images in second modality that are identical at the pixel level to the actual image as captured by the MRI machines.","['G06T5/50', 'G01R33/5608', 'G06N3/08', 'G06T3/14', 'G06T3/40', 'G06T5/90', 'G16H30/40', 'G16H50/50', 'G01R33/5602', 'G01R33/56341', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10132', 'G06T2207/20084', 'G06T2207/30004']"
US20250225713A1,Electronic device and method for restoring scene image of target view,"A device and method for performing scene restoration, including: obtaining an input image of an object; based on an input viewpoint corresponding to the input image, determining a plurality of augmented viewpoints surrounding the object in a three-dimensional (3D) space including the object; generating a plurality of augmented images at the plurality of augmented viewpoints, wherein each augmented image from among the plurality of augmented images corresponds to a view of the object from a corresponding augmented viewpoint from among the plurality of augmented viewpoints, and wherein each augmented image is generated based on an image at a different viewpoint using a view change model; generating a scene restoration model based on the input image at the input viewpoint and the plurality of augmented images at the plurality of augmented viewpoints; and restoring a scene image of a target view of the object using the scene restoration model.","['G06T15/20', 'G06T15/10', 'G06T15/06', 'G06T15/205', 'G06T19/00', 'G06T3/18', 'G06T5/00', 'G06T7/90', 'G06V20/40', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US20240346311A1,Building management system with generative ai-based automated intervention,"A method includes training, by one or more processors, a generative AI model using training data including a plurality of first service requests indicating a plurality of first problems associated with building equipment and a plurality of first actions performed in response to the plurality of first service requests. The method may include receiving, by the one or more processors, a second service request indicating a second problem associated with building equipment. The method may include automatically determining, by the one or more processors using the generative AI model, one or more second actions to perform based on characteristics of the second service request. The method may include automatically initiating, by the one or more processors, the one or more second actions to address the second problem associated with the building equipment.","['G06N3/08', 'G06N20/00']"
US20240362544A1,Building management system with generative ai-based root cause prediction,"A method including training, by one or more processors, a generative AI model using a plurality of first service requests handled by technicians for servicing building equipment. The generative AI model may be trained to predict root causes of a plurality of first problems corresponding to the plurality of first service requests. The method may include receiving, by the one or more processors, a second service request for servicing building equipment. The method may include predicting, by the one or more processors using the generative AI model, a root cause of a second problem corresponding to the second service request based on characteristics of the second service request and one or more patterns or trends identified from the plurality of first service requests using the generative AI model.","['G05B23/0243', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G05B23/0275', 'G06N3/0475']"
CN116842606A,Design image generation system and method based on machine learning model,"The invention discloses a design image generation system and method based on a machine learning model, which relate to the fields of building design, urban planning design and environmental art design, and comprise an expected loading module and an image generation module, wherein the expected loading module is used for acquiring situation vocabulary selected by a user and generating natural language based on the situation vocabulary, and the image generation module is used for taking the natural language as input and generating a design image by using the machine learning model.","['G06F30/13', 'G06F3/0482', 'G06F3/04845', 'G06F30/12', 'G06F30/27', 'G06N20/00', 'G06T17/00', 'G06T3/4053', 'G06V10/26', 'G06V10/44', 'G06V10/82', 'G06V30/414', 'G06V30/422', 'G06T2210/04']"
US12254553B2,"Learning device, learning method, learning program, image generation device, image generation method, image generation program, and image generation model","An image generation device derives, for a subject including a specific structure, a subject model representing the subject by deriving each feature amount of the target image having the at least one representation format and combining the feature amounts based on the target image. A latent variable derivation unit derives a latent variable obtained by dimensionally compressing a feature of the subject model according to the target information based on the target information and the subject model. A virtual image derivation unit outputs a virtual image having the representation format represented by the target information based on the target information, the subject model, and the latent variable.","['G06N3/08', 'G06T15/00', 'A61B5/055', 'A61B6/03', 'G06N3/045', 'G06T17/00', 'G06T3/4046', 'G06T2210/41', 'G16H50/00']"
EP4593025A1,Method and device for converting medical image using artificial intelligence,"One aspect of the present invention relates to a method for converting a medical image and, more specifically, to an image conversion method for converting a medical image using a generative adversarial neural network (GAN). One embodiment of the present invention has the effect of providing a medical image conversion method that enables medical staff to perform medical examination, diagnosis, and treatment with accurate information, and enables patients to receive appropriate medical services through conversion between medical images by a learning model that performs machine learning.","['G06N3/08', 'A61B5/055', 'A61B6/03', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06V10/75', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'G06V2201/03']"
WO2025130597A1,"Picture processing methods, apparatuses and system, and electronic device and storage medium","Disclosed in the present application are picture processing methods, apparatuses and system, and an electronic device and a storage medium. A method is applied to a coding end, and the method comprises: extracting a one-dimensional feature vector of an original picture block; converting the original picture block into a multi-dimensional feature map on the basis of the one-dimensional feature vector; performing quantization coding on the one-dimensional feature vector, so as to obtain a first bitstream; performing discrete coding on the multi-dimensional feature map, so as to obtain a second bitstream, thereby realizing efficient compression of a spatial-independent vector and the multi-dimensional feature map; and sending the first bitstream and the second bitstream to a decoding end. Since a coded bitstream consists of two layers of bitstreams and includes information of different layers of a picture, not much information is lost even at low bitrates; therefore, the picture obtained by means of reconstructing the two layers of bitstreams can improve the visual effect and the visual experience.","['H04N19/13', 'H04N19/124', 'H04N19/176']"
WO2010060113A1,Real time generation of animation-ready 3d character models,"Systems and methods for automatically generating animation-ready 3D character models based upon model parameter and clothing comprising receiving the user defined model parameters and the clothing selection via a user interface Systems and methods may include generating a 3D anatomical mesh based upon the user defined model parameters using the generative model, applying the clothing mesh from the clothing mesh template corresponding to the user clothing selection to the generated 3D anatomical mesh to create a clothed mesh, adjusting the template skeleton of the clothing mesh template corresponding to the user clothing selection based upon the shape of the clothed mesh, generating skinning weights based upon the skinning weights of the clothing mesh template corresponding to the user clothing selection, and storing an animation-ready 3D character model including the clothed mesh, the adjusted skeleton, and the generated skinning weights","['G06T13/40', 'G06T15/04', 'G06T17/20', 'A63F2300/6607', 'G06T2210/16']"
CN115239593A,"Image restoration method, device, electronic device and storage medium","The embodiment of the application provides an image restoration method, an image restoration device, an electronic device and a storage medium, wherein a first face image is input to an image restoration model comprising a diffusion module; performing mask processing on the first face image to obtain a mask image; training the image restoration model until the first loss function value is optimal to obtain a trained image restoration model, in the training process, adding noise to the mask image for multiple times by a diffusion module to obtain a white noise image which obeys standard normal distribution, forming a noise function, and restoring the mask image by the image restoration model through a noise adding and reducing mode according to the white noise image, the standard normal distribution and the noise function; performing image restoration on the second face image through the trained image restoration model to obtain a target restoration image; the face image that can will shelter from fast recovers, and recovers the image authenticity height.","['G06T5/70', 'G06N20/00', 'G06T2207/20081', 'G06T2207/30201']"
US12078599B2,Inspection method based on edge field and deep learning,"Disclosed is a defect inspection device. The defect inspection device may include a lighting system designed for transmitting a lighting pattern having different illuminances for each area on a surface of an inspection object; a photographing unit for obtaining an image data of the inspection object; one or more processors for processing the image data; and a memory for storing a deep learning-based model. In addition, the one or more processors are adapted to control, the lighting system to transmit a lighting pattern having a different illuminance for each area on a surface of an inspection object, input, an image data obtained by the photographing unit into the deep learning-based model, wherein the image data includes a rapid change of illuminance in at least a part of the object surface; and determine, a defect on a surface of the inspection object using the deep learning-based model.","['G01N21/88', 'G01N21/8806', 'G01N21/8851', 'G06N3/0499', 'G06N3/08', 'G06T7/0004', 'G06V10/26', 'G06V10/765', 'G06V10/82', 'G01N2021/8809', 'G01N2021/8829', 'G01N2021/8883', 'G01N2021/8887', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108']"
US20210318565A1,Optic system using dynamic diffuser,Disclosed is a defect inspection device for determining anomaly of an inspection object. The defect inspection device may include: a lighting system which includes a light source for transmitting light onto the inspection object; and a dynamic diffuser located between the light source and the inspection object and capable of controlling a diffusivity of light transmitted onto the inspection object; and one or more processors for controlling the dynamic diffuser based on characteristics of the inspection object.,"['G02F1/13306', 'G01N21/8851', 'G01N21/8806', 'G01N21/01', 'G02B5/0226', 'G06T7/0004', 'H04N23/56', 'H04N5/2256', 'G01N2021/8812', 'G01N2021/8887', 'G01N2201/0634', 'G02F1/1334', 'G06T2207/20081', 'G06T2207/30108']"
WO2021242744A1,Systems and methods for machine learning biological samples to optimize permeabilization,"Systems and methods for machine learning tissue classification are provided herein. In one embodiment, a system includes a storage element operable to store datasets of a plurality of biological samples. The dataset of each biological sample includes image data of the biological sample and molecular measurement data of the biological sample captured at a plurality of capture areas of the biological sample. The capture areas of the biological sample are registered to corresponding locations in the image data of the biological sample. A processor is operable to train a machine learning model with the stored datasets to learn molecular measurements of the biological samples. The processor may then process an image from another biological sample through the trained machine learning module to predict molecular measurement data of the other biological sample.","['G16B20/00', 'G16B25/10', 'G06T7/0012', 'G16B25/00', 'G16B40/20', 'G06T2207/20081', 'G06T2207/30024']"
CN103225819A,Oxygen volume adjusting method and system for pulverized coal boiler after change of coal type,"The invention discloses an oxygen volume adjusting method for a pulverized coal boiler after a change of coal type. The method comprises the following steps: a grid structure model of the pulverized coal boiler is built; a mathematical model of various physical and chemical processes generated in pulverized-coal combustion is built; the pulverized-coal combustion process after the change of coal type is simulated to obtain the corresponding relation between various oxygen volumes and the burning performance indexes of the pulverized coal boiler; and the oxygen volume of the pulverized coal boiler is adjusted to allow the pulverized coal boiler to meet preset burning performance indexes. In addition, the invention further discloses an oxygen volume adjusting method for the pulverized coal boiler after the change of coal type. The method and system provided by the invention can improve the accuracy rate and security of pulverized coal boiler oxygen volume control after the change of coal type, solve the problems of unstable furnace combustion and low combustion efficiency easily caused by manual control, and simultaneously greatly reduce pollutants produced during the process of combustion.",[]
CN118982155B,Prediction and control method of local carbon emission hotspots in cities based on generative adversarial network,"The invention discloses a city local carbon emission hot spot prediction and regulation method based on a generated countermeasure network, which comprises the following steps of S1, data collection and preprocessing, S2, constructing a short-term memory module by utilizing hour-level carbon emission data, carrying out short-term space-time feature coding, S3, extracting periodic variation features by adopting a multi-scale convolution network based on day-week-level carbon emission data, carrying out medium-term space-time feature coding, S4, analyzing month-quarter-level carbon emission data by utilizing a long time sequence dependency model, obtaining long-term space-time features, carrying out global coding on city whole carbon emission distribution, S5, constructing and training to generate the countermeasure network, S6, carrying out weighted fusion on space-time features of different levels by utilizing a space-time attention mechanism, generating a regulation strategy by combining real-time data, and carrying out self-adaptive regulation and optimization on the effect. The invention adopts a generated countermeasure network and a space-time characteristic coding method to realize accurate prediction and dynamic regulation of urban carbon emission hot spots.","['G06Q10/063', 'G06F18/213', 'G06F18/24', 'G06F18/253', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/094', 'G06Q10/04', 'G06Q50/26', 'Y02A90/10']"
US20240112394A1,AI Methods for Transforming a Text Prompt into an Immersive Volumetric Photo or Video,"A text-to-image prompt is processed using a text-to-image machine learning model to obtain a non-immersive (e.g., rectilinear image). The non-immersive image may be enhanced by a superresolution machine learning model and processed with a monoscopic depth estimation model to obtain a depthmap. The non-immersive image and the depthmap may be converted to an immersive projection (e.g., F-theta) and corresponding depth map. The immersive projection may be out-painted. The immersive projection may be used to generate video with simulated camera movement, output on a VR headset, and/or processed to remove a background layer and displayed on an AR headset, or on an holographic glasses-free three-dimensional display.","['G06T17/00', 'G06T15/10', 'G06F3/011', 'G06F3/012', 'G06F40/30', 'G06F40/40', 'G06T13/20', 'G06T19/006', 'G06T5/005', 'G06T5/77', 'G06T2210/61']"
CN111192248B,"A multi-task relational learning method for vertebral body localization, recognition and segmentation in magnetic resonance imaging","The invention relates to a multi-task relation learning method for positioning, identifying and segmenting a vertebral body in nuclear magnetic resonance imaging. The invention fully utilizes the relation among multiple tasks based on deep learning, and greatly improves challenges caused by the similarity among vertebral bodies and the image quality. For automatic analysis of the spine, an effective multitasking learning framework is provided. The framework can be easily popularized to the application of other images, and a universal framework is provided for the effective solution of three tasks of image positioning, image recognition and image segmentation.","['G06T7/0012', 'G06F18/253', 'G06N3/045', 'G06T7/11', 'G06T7/66', 'G06T7/73', 'G06T2207/30012', 'Y02A90/30']"
US20240290011A1,Dual-domain self-supervised learning for accelerated non-cartesian magnetic resonance imaging reconstruction,Systems and methods for dual-domain self-supervised learning for accelerated non-Cartesian magnetic resonance imaging reconstruction are provided. The present techniques provide a method for training a machine-learning model that receives magnetic resonance (MR) data and generates a reconstruction of the MR data. The machine-learning model can be trained based on a set of losses comprising a first loss value corresponding to a frequency-domain and a second loss value corresponding to an image-based domain. The training process can be a self-supervised training process that can utilize under-sampled and non-Cartesian MR data. The machine-learning model is trained by optimizing both data consistency in the frequency domain and appearance consistency in the image-based domain.,"['G01R33/389', 'G01R33/5608', 'G01R33/44', 'G01R33/56', 'G06F17/14', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T11/003', 'G01R33/445', 'G01R33/4824', 'G01R33/561', 'G06N3/048', 'G06T2211/441']"
US20240407663A1,Synthetic contrast-enhanced mr images,"Systems, methods, and computer programs disclosed herein relate to training and using a machine learning model to generate contrast-enhanced magnetic resonance images.","['G16H30/40', 'A61B5/055', 'A61B5/7267', 'G01R33/5601', 'G01R33/5608', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06T5/60', 'G06T5/90', 'G16H50/70', 'G01R33/4828', 'G01R33/5602', 'G01R33/56341', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
US20240428494A1,Multimodal contextualizer for non-player character generation and configuration,"Systems and techniques for generating and animating non-player characters (NPCs) within virtual digital environments are provided. Multimodal input data is received that comprises a plurality of input modalities for interaction with an NPC having a set of body features and a set of facial features. The multimodal input data is processed through one or more neural networks to generate animation sequences for both the body features and facial features of the NPC. Generating such animation sequences includes disentangling the multimodal input data to generate substantially disentangled latent representations, combining these representations with the multimodal input data, and using a large-language model (LLM) to generate speech data for the NPC. Further processing using reverse diffusion generates face vertex displacement data and joint trajectory data based on the combined representation and generated speech data. The face vertex displacement data, joint trajectory data, and speech data are used to produce an animated representation of the NPC, which is then provided to environment-specific adapters to animate the NPC within a virtual digital environment.","['G06T13/40', 'A63F13/56', 'A63F13/67', 'G06N3/00', 'G06N3/045', 'H04N19/124']"
WO2016115392A1,Systems and methods for determining neurovascular reactivity to brain stimulation,"System and methods for stimulating the neurovascular system of the cerebral tissue through optimally placed devices, while simultaneously measuring the evoked neuronal and hemodynamic responses, also using optimally placed devices, is disclosed. Systems and methods for iteratively stimulating the neurovascular system and recording neuronal and hemodynamic responses are also disclosed. Further, a method for determining cerebral neurovascular functioning from the combined stimulation and measurement is disclosed, for use in diagnosis of neurovascular disorders.","['A61B5/4064', 'A61B5/0075', 'A61B5/026', 'A61B5/1455', 'A61B5/14551', 'A61B5/377', 'A61B5/6803', 'A61B5/6814', 'A61N1/08', 'A61N1/20', 'A61N1/36025', 'A61B5/369', 'A61N1/36014']"
US20240268700A1,Systems and methods for multi-contrast multi-scale vision transformers,"Methods and systems are provided for synthesizing a contrast-weighted image in Magnetic resonance imaging (MRI). The method comprises: receiving a multi-contrast image of a subject, where the multi-contrast image comprises one or more images of one or more different contrasts; generating an input to a transformer model based at least in part on the multi-contrast image; and generating, by the transformer model, a synthesized image having a target contrast that is different from the one or more different contrasts of the one or more images, where the target contrast is specified in a query received by the transformer model.","['A61B5/055', 'G06V10/82', 'G01R33/50', 'G01R33/5601', 'G06T7/0012', 'G06T7/11', 'G06T2207/10088', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/03']"
US20230377724A1,Temporal prediction in anatomic position monitoring using artificial intelligence modeling,"Systems and methods are disclosed for monitoring and estimating an anatomic position of a human subject for a radiotherapy treatment session, based on use of an artificial intelligence (AI) model (e.g., a generative AI model comprising a Transformer deep learning neural network), are described. An example method of monitoring anatomic position with a trained AI model includes: receiving position information corresponding to observed positions of a tracked anatomical area of a patient, observed during the radiotherapy treatment session; providing the position information as an input to a trained model trained with temporal sequences of observed anatomical positions from training data; determining an estimated position of the tracked anatomical area of the patient at a future time, based on output of the trained model; and controlling the radiotherapy treatment session based on the estimated position of the tracked anatomical area of the patient.","['G16H30/40', 'A61N5/1037', 'A61B5/113', 'A61B5/7285', 'A61N5/1039', 'A61N5/1049', 'A61N5/1067', 'G06N3/045', 'G06N3/09', 'G06T7/70', 'G16H20/40', 'G16H40/63', 'G16H50/20', 'G16H50/70', 'A61B5/7267', 'A61N2005/1041', 'A61N2005/1061', 'A61N5/1068', 'G06T2207/10016', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G16H50/30']"
US20240071178A1,Computer-implemented systems and methods for implementing matrix-based online gaming,"An apparatus, system, computer-readable medium, and/or process to perform a house-based game matrix and provide information to a display device. The house-based game matrix may include a plurality of selectable gaming units (e.g., squares for a squares game for a sports betting event). Each selectable gaming unit may be associated with a first gaming number from a first set of event gaming numbers and a second gaming number from a second set of event gaming numbers. The score of the event associated with the house-based game matrix may be monitored. For a selected gaming unit made by the display device, the first score number with the first gaming number of the selected gaming unit and the second score number with the second gaming number of the selected gaming unit may be compared.","['G07F17/3288', 'G07F17/3211', 'G07F17/3251', 'G07F17/326', 'G07F17/3272']"
WO2024163599A1,Generating a semantic search engine results page,"The present disclosure relates to generating semantic search engine results. Aspects of the present disclosure retrieve relevant information from a search engine based on user's search query. The query can be a classic search query (keyword or short phrase) or a conversational query (e.g., a chat messages between users and/or chatbots), a query based upon an email or other type of message, or a query generate based upon a content item (e.g., a webpage, image, video, document, etc.). Aspects of the disclosure leverage a large language model (LLM), such as, for example, a generative model, to summarizes the content according to the intent detected from the query. In some cases, aspects of the present disclosure may generate a direct answer to the query and provide relevant references to support the information.","['G06F16/9532', 'G06F40/30']"
US20250001296A1,Systems and methods for customized context-sensitive interfaces,"Systems and techniques for customized context-sensitive interfacing are described. In some examples, a content processing system receives a string of text through a user interface. The user interface is part of a video game. The content processing system receives context associated with the video game. The content processing system analyzes the string of text in light of the context to generate an evaluation of the string of text. The content processing system outputs the evaluation of the string of text in the video game.","['G06F40/20', 'A63F13/533', 'G06F40/253', 'G06F40/40', 'A63F13/67', 'G09B19/0053']"
US20240289686A1,Directed management of interactive elements in an interactive environment utilizing machine learning,"The present disclosure relates to systems and methods for using a director service as an intermediary management system to integrate interactive elements between a developer, a user, a generative machine learning (ML) model, and/or an interactive environment. In examples, the director service may receive input from a user or developer device relating to an interactive element from an interactive environment. The director service may process input from one or more of the developer, the user, and the interactive environment to recognize semantic context and intent objectives associated with the input. The director service may generate one or more prompts based on such input, which is processed by an ML model to generate output. In examples, the prompts may be provided to the ML model to direct it towards providing an output that is responsive to the input and one or more environment guidelines. The input and/or output may be multimodal.","['G06N20/00', 'G06N3/006', 'G06N3/045']"
CN111201540A,Optimizing semiconductor binning with feed-forward process tuning,"The one or more processors determine a predicted classification gear of the semiconductor device based on measurement and test data performed on the semiconductor device after the current metallization layer. The current predicted classification gear and the target classification gear are determined by a machine learning model of the semiconductor device; the target gear includes a higher performance semiconductor device than the predicted classification gear. The model determines the achievable performance level improvement by adjusting process parameters of subsequent metallization layers of the semiconductor device. Adjustments to process parameters are generated based on measurement and test data for a current metallization layer of the semiconductor device, and adjustment outputs for process parameters for subsequent metallization layers of the semiconductor device may be processed for the one or more subsequent metallization layers by a feed-forward mechanism.","['H01L21/67271', 'G06N20/00', 'G06N5/04', 'G06N5/046']"
US12182678B1,Systems and methods for aligning large multimodal models (LMMs) or large language models (LLMs) with domain-specific principles,A system and method aligns generative artificial intelligence (a large language model (LLM) or a large multimodal model (LMM) with the principles of a specific domain so that the generative artificial intelligence is better able to respond to a user query in the specific domain. The system and method may post-train an already trained generative artificial intelligence system or fine tune the training of the generative artificial intelligence system to align that generative artificial intelligence system with the principles of the specific domain. The system and method may be used to align the generative artificial intelligence system to a plurality of different domains.,"['G06N3/045', 'G06N20/00', 'G06N3/08']"
US12159364B2,User-interactivity enabled search filter tool optimized for virtualized worlds,"Systems, methods, and/or computer readable media for generating representations of searchable experiences in a virtual environment are disclosed. The virtual environment comprising a sector having one or more virtual structures is generated. A position of an avatar in the virtual environment is detected, and based on the detection, a sector data layer comprising data items related to a predetermined dataset is generated. The data items are associated with the sector, and an attribute of the sector is configured and displayed to the user. A second position of the avatar in the virtual environment is detected, and based on the detection, a subset of data using the set of items in the sector data layer is generated. An attribute of the virtual structure within the sector is configured and displayed to the user.","['G06T19/20', 'G06T19/003', 'G06T7/70', 'G06T2207/20084', 'G06T2219/2004']"
US12333220B2,Usage-pattern-based generation of digital product model,"A process is provided for usage-pattern-based generation of a digital model of a product. The process includes obtaining a usage pattern of a user of a product, where the usage pattern includes a set of usage pattern parameters. In addition, the process includes using a machine learning model of an artificial intelligence system to generate a 3-D virtual image of the product aligned with the usage pattern, and analyzing, by the artificial intelligence system, the 3-D virtual image of the product to facilitate identifying a requirement specification for the product based on the usage pattern. Further, the process includes generating a digital model of a new product for the user based on the identified requirement specification.","['G06F30/17', 'G06F30/27', 'G06F2111/18']"
US20240202460A1,Interfacing with a skill store,"Systems and methods for interfacing with a skill store are provided herein. In some examples, a task is processed, using a generate large model (GLM) to orchestrate skills for performing the task. The orchestrated skills include a plurality of skills related to the task. At least one skill in the orchestrated skills is determined to not be available to the GLM, and an indication corresponding to the at least one skill is transmitted to a remote skill store. The indication may be associated with descriptions of the at least one skill, based on which similarities may be determined for retrieving skills from the remote skill store. A remote skill is received from the remote skill score that corresponds to the transmitted indication, and the task is performed using the generative LLM. The generative LLM uses the remote skill to perform the task.",['G06F40/40']
WO2024112994A1,One-click photorealistic video generation using ai and real-time cgi,"A video clip Generator which generates a photorealistic video clip of a character expressively speaking the text of a user's message when the user takes no action relating to the generation of the video clip other than the activation of a single user interface button. The example given incorporates a seven-dimensional photorealistic video clip generator with the dimensions of scene, set, character, outfit, dialog, prop, and style. By default, the dialog is the user text message, but the user can edit the text. The system automatically selects an appropriate element from each of these dimensions, along with a language and text to speech voice With practical numbers of entries in each of these dimensions, the video clip Generator can generate more than ten to the 32nd power different animated video clips of the selected character reading the user's text while wearing the outfit and performing an action with the prop in the set with the scene as background. The clip is rendered on demand in the specified style in, or faster than, real time and streamed to the user and the recipient of the text message.","['G06T13/80', 'G06T11/00', 'G06N3/094', 'G06N3/0475', 'G06T17/20', 'G10L13/00']"
CN115295086A,"Modeling method, device, equipment and storage medium of air quality prediction model","The embodiment of the invention provides a modeling method, a modeling device, equipment and a storage medium of an air quality prediction model, and relates to the technical field of air quality prediction. This modeling method includes: s1, acquiring monitoring data of various monitoring objects. And S2, preprocessing the monitoring data to eliminate abnormal data in the monitoring data. And S3, calculating correlation coefficients among all monitored objects according to the preprocessed monitoring data. And S4, classifying the meteorological conditions according to the correlation coefficient, and obtaining a meteorological representative of each classification. And S5, acquiring feature sets of various pollutants from the preprocessed monitoring data according to the correlation coefficient and the meteorological representation. And S7, respectively constructing concentration prediction models of various pollutants based on the I nformer deep learning model according to the feature sets of the various pollutants. The prediction model constructed by the modeling method can more accurately predict the concentration of various pollutants, so that more accurate air quality index can be calculated.","['G16C20/20', 'G06N3/08', 'G16C20/70']"
CN119474672A,Early warning method for abnormal emissions from pollution facilities based on big data analysis,"The invention discloses a pollution facility abnormal emission early warning method based on big data analysis, which comprises the following steps of S1, collecting data and constructing a data set, S2, storing and preprocessing the data set, S3, constructing a space-time propagation network of an external event by utilizing a graph neural network model, S4, modeling and predicting a time sequence characteristic by using a mixed depth generation model, S5, analyzing a causal relation between the external event and facility emission behavior by using a causal inference model, S6, dynamically adjusting an emission early warning threshold by adopting a Bayesian optimization algorithm based on uncertainty estimation of strategies, S7, generating a new abnormal emission mode label by utilizing a self-supervision learning model and a few sample learning technology, S8, generating an abnormal source tracing report by adopting an interpretable artificial intelligence technology, and providing a coping proposal and an action scheme. The invention utilizes a cross-space-time event inference and self-supervision learning method to realize early warning of abnormal emission of the pollution facility.","['G06F18/10', 'G06F18/213', 'G06F18/24155', 'G06N3/042', 'G06N3/0895']"
US20240212144A1,Apparatus and method of determining a conditional profile adjustment datum,"An apparatus for determining a conditional profile adjustment datum may include at least a processor; and a memory connectively connected to the at least a processor, the memory containing instructions configuring the at least a processor to receive a first plurality of photographs related to a human subject; identify a first conditional indicator as a function of the first plurality of photographs and entries contained within an expert database; generate a first conditional profile by training a classifier on a training dataset including a plurality of example conditional indicators as inputs correlated to a plurality of example conditional profiles as outputs; and generating the first conditional profile as a function of the first conditional indicator using the trained classifier; determine a conditional profile adjustment datum as a function of the first conditional profile; and communicate the conditional profile adjustment datum to the human subject.","['G06N3/0464', 'G06N20/00', 'G06N5/04', 'G06N7/01', 'G06T7/0012', 'G06N5/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30016', 'G06T2207/30101', 'G06T2207/30196']"
US20210401904A1,Prebiotic formulations for prevention of sepsis and necroenterocolitis induced neurodevelopmental deficiencies,"Provided herein are methods and probiotic compositions for treating or preventing a disease or neurodevelopmental deficiency in a subject in need thereof using the compositions. Aspects and embodiments of this technology combine the health benefits of probiotic bacteria with prebiotic substances to help stimulate the exclusive growth of the probiotic species and, in one aspect, provide the bacteria in the form of a biofilm on a biocompatible microsphere.","['A61K9/1658', 'A61P1/00', 'A23L33/135', 'A23L33/21', 'A61K31/715', 'A61K35/74', 'A61K35/742', 'A61K35/744', 'A61K35/745', 'A61K35/747', 'A61K47/42', 'A61K9/1611', 'A61K9/1641', 'A61K9/1647', 'A61K9/1652', 'A61P25/00', 'A61P25/28', 'A61P3/02', 'A23V2002/00', 'A23V2200/322']"
US20240419246A1,"Human augmentation platform using context, biosignals, and language models","There are disclosed herein systems and methods for human agency support and facilitation through an integrated use of context information, historical work product, biosensors, explicit user input and a generative AI or generalist agent. The system comprises input means, tokenization, a generative AI or generalist agent and an output stage capable of enacting agency on a user's behalf using output tokens from the language model.","['G16H20/30', 'G06F3/015', 'A61N1/20', 'G06F40/284', 'G10L13/08', 'G16H20/70']"
US20240170122A1,Methods and systems for determining a prescriptive therapy instruction set,A system for determining a prescriptive therapy instruction set may include a computing device configured to receive a first subject prescription datum associated with a first subject; receive a first subject tolerance datum associated with the first subject; determine a prescriptive therapy instruction set by training a prescriptive therapy instruction set machine learning model on a training dataset including a plurality of example subject prescription data and subject tolerance data as inputs correlated to a plurality of example prescriptive therapy instruction sets as outputs; and generating the prescriptive therapy instruction set as a function of the subject prescription datum and the subject tolerance datum using the trained prescriptive therapy instruction set machine learning model; receive a second subject tolerance datum associated with the first subject; and retrain the prescriptive therapy instruction set machine learning model as a function of the second subject tolerance datum.,"['G16H20/10', 'G06N3/045', 'G06N20/00', 'G06N20/10', 'G06N3/047', 'G06N5/01', 'G06N7/01', 'G16H10/20', 'G16H10/60', 'G16H20/60', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G06N3/088', 'Y02A90/10']"
US20240256780A1,Generating security reports,"In some examples, a method of generating a security report is provided. The method includes receiving a user query and security data, and providing the user query and security data to a semantic model. The semantic model generates one or more first embeddings. The method further includes receiving, from a data model, one or more second embeddings. The data model is generated based on historical threat intelligence data. The model further includes generating an execution plan based on the one or more first embeddings and the one or more second embeddings, and returning a report that corresponds to the execution plan.","['G06F40/30', 'G06F16/3329', 'G06F21/577']"
CN116611478A,Industrial process data enhancement method for generating countermeasure network based on depth threshold,"Along with the development of the deep neural network, the development of artificial intelligence theoretical research and application technology in the industrial field is promoted. The industrial environment faces complex and variable uncontrollable factors, and if information useful for production can be obtained from the observed data, useful decisions can be made for the industrial production process, and a series of problems in the production process are avoided. However, industrial production process variables are difficult to collect, some variables cannot be collected, and thus industrial data modeling problems aiming at the problem of sample deficiency are caused, and an artificial neural network aims at learning data distribution and hiding information from observed data by using classical statistics as a theoretical basis. In the background, a depth threshold generation countermeasure network data enhancement method is provided for sample expansion of industrial data, and the generated sample and a real sample are combined for industrial data driving modeling, so that the effectiveness of the method is proved by experiments. The invention has good theoretical value and application prospect, and has important significance for monitoring and optimizing industrial production process.","['G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/094', 'G06Q10/04', 'G06Q10/06393', 'G06Q50/04', 'Y02P90/30']"
US20240289361A1,User interface for chat-guided searches,"A computer-implemented method is disclosed. The method includes: receiving, via a first user interface, a selection associated with an object; determining a first set of object attributes based on the selection; presenting, via a second user interface, a text prompt for a user to identify a subset of the first set of object attributes; receiving, via the second user interface, an indication of one or more preferred object attributes of the identified subset; and updating the first user interface to display content relating to objects associated with the one or more preferred object attributes.","['G06F40/40', 'G06Q30/0627', 'G06F16/3328', 'G06F40/284']"
US20240289365A1,Systems and methods for performing vector search,"A computer-implemented is disclosed. The method includes: receiving a search query input; generating input enhancement data based on the search query input, the generating comprising processing the search query input using a large language model (LLM); causing to transform at least one of the search query input or the input enhancement data into a first vector embedding; and performing a search of an embedding space based on the first vector embedding.","['G06F16/3347', 'G06F16/3329', 'G06F16/335']"
US20250046055A1,Generating color-edited digital images utilizing a content aware diffusion neural network,"This disclosure describes one or more implementations of systems, non-transitory computer-readable media, and methods that trains (and utilizes) an image color editing diffusion neural network to generate a color edited digital image(s) for a digital image. In particular, in one or more implementations, the disclosed systems identify a digital image depicting content in a first color style. Moreover, the disclosed systems generate, from the digital image utilizing an image color editing diffusion neural network, a color-edited digital image depicting the content in a second color style different from the first color style. Further, the disclosed systems provide, for display within a graphical user interface, the color-edited digital image.","['G06V10/60', 'G06T5/60', 'G06T5/70', 'G06V10/56', 'G06V10/82', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US20240273267A1,"Fluid state estimation system, learning device, learning program, estimation device, and estimation program","A fluid state estimation system includes: a learning device that learns an estimation model for estimating a state of a fluid in at least any one of an inside of a component of a plant, an outside of the component of the plant and an inside of a building of the plant, an outside of the building of the plant and an inside of a site of the plant, and a periphery of an outside of the site of the plant; and an estimation device that estimates a state of a fluid using the estimation model learned by the learning device. The estimation model gets a value of an input variable, and outputs a value of fluid state information representing a state of a fluid.","['G06F30/28', 'G01M99/00', 'G05B23/00', 'G06F30/27', 'G06F2113/08']"
US20240354903A1,Single-subject image generation,A method of generating an image is disclosed. A mask and descriptive text associated with a subject are received. The descriptive text comprises a text prompt. The mask is resized to fit within a predefined bounding box and the resized mask is centered on a background image. The centered mask is filled with noise. Output of an image of the subject on a solid background is received from a generative AI model in response to a passing of a request to the generative AI model. The request includes the noise-filled mask and the descriptive text.,"['G06T5/50', 'G06T7/194', 'G06T11/00', 'G06T13/80', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224']"
US20230260096A1,Ai-driven enhancement of motion blurred sequencing images,"Artificial intelligence driven enhancement of motion blurred sequencing images enables enhanced sequencing that determines a sequence of bases in genetic material with any one or more of: improved performance, improved accuracy, and/or reduced cost. A training set of images taken after unreduced and reduced movement settling times during sequencing is used to train a neural network to enable the neural network to recover enhanced images, as if taken after the unreduced movement settling time, from unenhanced images taken after the reduced movement settling time.","['G06T5/50', 'G06T5/73', 'G06T5/003', 'G06T5/20', 'G06T5/60', 'G06T7/0002', 'G16B30/00', 'G16B40/10', 'G16B40/20', 'G06T2207/10016', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20201', 'G06T2207/30004', 'G06T2207/30168']"
US20230296516A1,Ai-driven signal enhancement of sequencing images,"Artificial intelligence driven signal enhancement of sequencing images enables enhanced sequencing by synthesis that determines a sequence of bases in genetic material with any one or more of: improved performance, improved accuracy, and/or reduced cost. A training set of images taken at unreduced and reduced power levels used to excite fluorescence during sequencing by synthesis is used to train a neural network to enable the neural network to recover enhanced images, as if taken at the unreduced power level, from unenhanced images taken at the reduced power level.","['G01N21/6456', 'G06N3/08', 'G06T5/60', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084']"
CN119474768A,A method and system for multimodal fusion prediction of marine environment based on digital twin,"The invention relates to the technical field of marine environment prediction, in particular to a digital twinning-based marine environment multi-mode fusion prediction method and system. The method comprises the steps of capturing space-time associated features of multi-mode data of a marine environment based on a dynamic multi-mode graph neural network, carrying out multi-scale feature fusion on the space-time associated features by utilizing a multi-scale gating unit to obtain comprehensive feature representation, predicting the comprehensive feature representation by utilizing a mixed time sequence prediction frame to obtain preliminary marine environment prediction data, wherein the preliminary marine environment prediction data comprises short-term dynamic modeling and long-term trend modeling, and carrying out noise fitting on the preliminary marine environment prediction data by utilizing a generating countermeasure network to generate final marine environment prediction data. The invention effectively solves the problems of insufficient data fusion, limited prediction precision and poor dynamic response capability in the traditional marine environment monitoring and prediction technology through the innovative combination of the dynamic multi-mode data fusion, the mixed time sequence prediction framework and the multi-scale gating Tanh unit.","['G06F18/20', 'G06F18/15', 'G06F18/213', 'G06F18/253', 'G06N3/042', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'Y02A90/10']"
US11947893B1,Integrating multiple slides for a presentation using a generated common background,"A user device having a presentation application includes a processor; a memory storing the presentation application for implementation by the processor, alone or in combination with other processors. The application includes a user interface allowing a user to request integration of multiple slides into a single canvas with a common background generated by an Artificial Intelligence (AI) model based on backgrounds of the multiple slides being integrated into the single canvas.","['G06F40/106', 'G06F3/0481', 'G06F3/0482', 'G06F3/0483', 'G06Q10/10', 'G06T11/001', 'G06N20/00']"
US20240265114A1,An apparatus and method for enhancing cybersecurity of an entity,"An apparatus and method for enhancing cybersecurity of an entity, wherein the apparatus includes at least a processor and a memory containing instructions configuring the at least a processor to receive entity data including cybersecurity related data from an entity, compare the entity data to a cybersecurity metric, generate a cybersecurity enhancement program as a function of the comparison, wherein the cybersecurity enhancement program includes a cyber-attack simulation, and implement the cybersecurity enhancement program for the entity based on the entity data.","['G06F21/577', 'G06F21/566', 'G06F2221/034']"
EP4092621A1,Technique for assigning a perfusion metric to dce mr images,"Technique for assigning a perfusion metric to dynamic contrast-enhanced, DCE, magnetic resonance, MR, images, (104) the DCE MR images obtained from a MR scanner (102) and under a free-breathing protocol is provided. As to a neural network system (100) aspect, a neural network system (100) for assigning a perfusion metric to DCE MR images, comprises an input layer (112) configured to receive at least one DCE MR image (104a) representative of a first contrast enhancement state and of a first respiratory motion state and at least one further DCE MR image (104b) representative of a second contrast enhancement state and of a second respiratory motion state. The neural network (100) further comprises an output layer (116) configured to output at least one perfusion metric based on the at least one DCE MR image (104a) and the at least one further DCE MR image (104b). The neural network system (100) with interconnections between the input layer (112) and the output layer (116) is trained by a plurality of datasets, each of the datasets comprising an instance of the at least one DCE MR image (104a) and of the at least one further DCE MR image (104b) for the input layer (114) and the at least one perfusion metric for the output layer (116).","['G06T7/0016', 'G06T7/0012', 'G06N3/04', 'G06T5/92', 'G06T7/30', 'G06T2207/10076', 'G06T2207/10088', 'G06T2207/10096', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06T2207/30104']"
US20250125020A1,"Method and device, electronic equipment and storage medium for training and optimizing analysis model","The embodiment of the invention provides method, apparatus, device and a storage medium for training and optimizing an analysis model. The method of optimizing the analysis model includes: fine-tuning an analysis model with a first set of values regarding a first property of a target material to determine a second set of values regarding a second property of the target material; determining an association between the first property and the second property of the target material based on a first set of values and a second set of values; determining a target value of the target material regarding the first property with the association based on a reference value of the target material regarding the second property, the reference value being determined based on an experiment on target material; and optimizing the analysis model with the target value of the target material regarding the first property. In this way, embodiments of the present disclosure can utilize limited experimental data to optimize the analysis model.","['G16C20/10', 'G16C60/00', 'G06N3/042', 'G06N3/08', 'G16C20/30', 'G16C20/70']"
US20250045887A1,Systems and methods to generate high dynamic range scenes,"The present disclosure provides computer-implemented methods and systems to generate high dynamic range (HDR) panoramas to render virtual objects. A low dynamic range (LDR) panorama from a prompt describing a desired aspect of a panorama. The LDR panorama is then converted to an HDR panorama. The process can include generating a backplate image using a first machine learning model, projecting the image onto a sphere and inpainting it using a second machine learning model to generate an LDR panorama, and converting the LDR panorama to an HDR panorama using a third machine learning model. Each of the 10 first, second and third machine learning models can be diffusion models. Alternatively, the third machine learning model can be a convolutional neural network model. A physics-based rendering engine can then be used to render a virtual object in the HDR panorama.","['G06T5/90', 'G06V20/70', 'G06T5/20', 'G06T5/60', 'G06T5/77', 'G06T5/92', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
EP4208844A1,Deep unsupervised image quality enhancement,"A training system (TS) for training a machine learning model for image quality enhancement in medical imagery. The system comprises an input interface (Ä¨ IN) for receiving a training input image (Ä¨ IN). The system (TS) comprises artificial neural network model framework (G,D) of the generative adversarial type including a generator network (G) and a discriminator (D) network. The generative network (G) processes the training input image to produce a training output image (Ä¨ OUT). A down-scaler (DS) of the system downscales the training input image. The discriminator attempts to discriminate between the downscaled training input image (I') and training output image to produce a discrimination result. A training controller (TC) adjusts parameters of the artificial neural network model framework based on the discrimination result. Ä¨","['G06T5/70', 'G06N3/094', 'G06T3/40', 'G06T5/20', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'G16H30/40', 'G06T2200/24', 'G06T2207/10081', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212', 'G06T2207/30004']"
US12346831B2,Methods and systems for physiologically informed gestational inquiries,An apparatus for physiologically informed gestational inquiries is disclosed. The apparatus includes at least a processor and memory communicatively connected to the at least a processor. The memory instructs the processor to receive a biological extraction from the user. The memory instructs the processor to receive a gestational inquiry from the user. The memory instructs the processor to separate the gestational inquiry from a description of the gestational inquiry. The memory instructs the processor to determine a gestational target as a function of the gestational inquiry and the biological extraction. The memory instructs the processor to generate a gestational report as a function of the gestational target.,"['G16H50/70', 'G06N5/04', 'G06N20/00', 'G06N3/0455', 'G06N3/0475', 'G06N3/09', 'G16H20/10', 'G16H20/30', 'G16H20/60', 'G16H30/20', 'G16H50/20', 'G16H50/30', 'G06N5/048', 'G16H10/20']"
CN114402342A,Method for generating characteristic patterns and training machine learning models,"Methods of generating characteristic patterns for patterning processes and training machine learning models are described herein. A method of training a machine learning model configured to generate a characteristic pattern of a mask pattern, the method comprising: obtaining (i) a reference characteristic pattern (EFM) that meets an acceptance threshold associated with the manufacture of the mask pattern, and (ii) a Continuous Transport Mask (CTM) used to generate the mask pattern; and training the machine learning model based on the reference characteristic pattern and the CTM such that a first indicator between the characteristic pattern (EFM1) and the CTM is reduced and a second indicator between the characteristic pattern (EFM1) and the reference characteristic pattern (EFM) is reduced.","['G06N20/00', 'G03F1/36', 'G03F1/70', 'G03F7/70358', 'G03F7/70433', 'G03F7/70441', 'G03F7/705', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
GB2631145A,Text-to-image synthesis utilizing diffusion models with test-time attention segregation and retention optimization,"The present disclosure relates to systems, methods, and computer-readable media that utilizes attention segregation loss and/or attention retention loss at inference time of a diffusion neural network to generate a text-conditioned image. In one embodiment, the disclosed systems utilize the attention segregation loss to reduce overlap between concepts by comparing attention maps for multiple concepts of a text query corresponding to a denoising step, in another embodiments, the disclosed systems utilize the attention retention loss to improve information retention for concepts across denoising steps by comparing attention maps between different denoising steps. Accordingly, in some embodiments, by utilizing the attention segregation loss and the attention retention loss, the disclosed systems accurately maintain multiple concepts from a text query when generating a text-conditioned image.","['G06T11/60', 'G06N3/0455', 'G06F40/40', 'G06T11/00', 'G06N3/042', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212']"
CN101164267A,Sign version transmitting device and sign version receiving device,"Provided is a communication system which exploits status information expressed in the shift time of a code series. A code type transmitting device (1) for converting input data into the shift time of a code pulse train and transmitting the shift time comprises means (80) for generating a synchronizing signal to trap or hold a synchronism, means (50) for generating a sequential pulse train at a timing based on the synchronizing signal, means (70) for generating such a data code pulse train sequentially with the sequential pulse train as has a shift time determined according to the input data, and means (70) for generating and sending out a transmission signal, with the signal which is based on a transmission signal generating pulse train containing a fundamental pulse train having at least the data code pulse train.","['H04B1/707', 'H04B14/026', 'H04B1/69', 'H04B14/02', 'H04L25/49']"
CN109902615A,A multi-age image generation method based on adversarial network,"The invention discloses a kind of multiple age bracket image generating methods based on confrontation network, traditional GAN loss, circulation loss, inter- object distance loss, cosine similarity loss are combined, collectively as the objective function in training process, while reducing inter- object distance, cosine similarity loss is added to guarantee the correspondence of mapping.The present invention includes: one: face image data row is divided into training sample set and test sample collectionï¼Two: data prediction is carried out to the facial image that training sample is concentratedï¼Three: constructing the convolutional neural networks structure of generator, determining device in multiple age bracket images based on confrontation networkï¼Four: training sample set being input in model and is trainedï¼Five: saving each generator and determining device network model parameterï¼Six: generator and determining device model being tested using the test sample collection after data prediction, obtain test result.The present invention enhances for data and area of pattern recognition.",[]
US20250086864A1,Generative artificial intelligence content design tools,"A system leverages machine learning models to generate images, to customize and modify such images, and to generate additional images. The images can be generated within a digital canvas, allowing users to create sets of images, to compare such images, and to use such generated images to generate prompts and additional images. Tools can be provided to allow users to generate images with specific characteristics. For instance a color palette tool can allow users to specify particular colors and color shades for use in generating images. Likewise, a collage tool can allow users to generate and use a seed image to generate images for a collage of images. The system tracks states of images and other media content to promote user interaction with existing media content to generate new media content.","['G06T11/001', 'G06T11/00', 'G06T11/60', 'G06T2200/24', 'G06T2211/441']"
US20240331417A1,"Methods, Systems and Computer Programs for Processing Images of an Optical Imaging Device and for Training one or more Machine-Learning Models","A method, system, and computer program for processing images of an optical imaging device and for training one or more machine-learning models. A method for processing images of an optical imaging device comprises obtaining embeddings of a plurality of candidate molecules, obtaining, for each candidate molecule, one or more images of the optical imaging device, the one or more images showing a visual representation of a target property exhibited by the candidate molecule in a biological sample, processing, using a machine-learning model, for each candidate molecule, the one or more images and/or information derived from the one or more images to generate a predicted embedding of the candidate molecule. The machine-learning model is trained to output the predicted embedding for an input comprising the one or more images and/or the information derived from the one or more images.","['G06N3/045', 'G06N3/08', 'G06V10/766', 'G06V10/774', 'G06V10/7792', 'G06V10/82', 'G06V20/693', 'G06V20/695', 'G06V20/698', 'G16B15/30', 'G16B40/20', 'G16B40/30', 'G16C20/70', 'G16C20/30', 'G16C20/50']"
CN116072134A,Music audio repairing method and system based on DCT-DDPM,"The invention discloses a music audio repairing method and system based on DCT-DDPM, which belong to the field of voice processing and deep learning, and solve the problem that the prior art can only perform unconditional modification and can not restore original fragment information. The present invention includes 1) acquisition of music audio data; 2) Transforming the audio data to the frequency domain; 3) Processing to obtain a Mel spectrogram with Mask; 4) Training DCT-DDPM; 5) Repairing the audio based on the trained DCT-DDPM; 6) And transforming the repaired Mel spectrogram into a time domain. The invention is used for music audio repair.","['G10L21/01', 'G06N3/08', 'G10L19/0212', 'G10L19/18', 'G10L25/24', 'G10L25/30']"
CN102576469A,Drawing graphical objects in a 3D subsurface environment,"A system and method for drawing in a three-dimensional space. The drawings may include dots, line segments, arrows, polylines (open and closed), polygons, surfaces and 3D volumes. The method may include receiving user input that specifies a drawing in a displayed window and mapping the drawing into the 3D space. The mapping process may involve mapping the drawing onto a surface of an existing graphical object in the 3D space, or, mapping the drawing onto a user-specified plane in the 3D space. The drawing may represent a user's interpretation of a geological feature present on the graphical object surface. The graphical object may represent an object of significance in hydrocarbon exploration and production, e.g., an interpreted section or horizon in the earth's subsurface.","['G06T17/05', 'G06T11/203', 'G06T19/00']"
US20240420332A1,Systems and methods for determining information of regions of interest,"The present disclosure provides methods and systems for determining information of an ROI of a target subject. The methods may include determining positioning information of the ROI of the target subject by processing first medical imaging data of the target subject using a first determination model. The first medical imaging data may be acquired by performing a first scan with a first field of view (FOV) on the target subject. The methods may include acquiring second medical imaging data of the target subject by performing one or more second scans with a second FOV on the target subject based on the positioning information of the ROI. The methods may further include determining, based on the second medical imaging data, detection information of the ROI.","['G06T7/0014', 'G06N3/09', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G06T7/11', 'G06T7/73', 'G06T2207/10072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/30016', 'G06T2207/30101', 'G06T2207/30168']"
US20250039134A1,Trust scoring with intelligent traffic flow and load balancing in a network,"A system and method are provided for routing traffic through a network to ensure load balancing and avoid untrustworthy nodes. Based on network data (e.g., telemetry data), a machine learning model generates trust scores, which are used for routing decisions by determining preferred routes from a source to a destination. The trust scores for nodes along a potential route can be combined into a cumulative trust score. The potential route with the lowest cumulative trust score (i.e., most trustworthy) is preferred, when all other factors are equal. Traffic is routed along the preferred routes, until their capacity is exceeded. Then to achieve load balancing, traffic flows are extended to the next most preferred routes (e.g., the next lowest cumulative trust score), and so forth. When traffic flows include a mix of sensitive and non-sensitive data, the sensitive data is preferentially directed along the most preferred routes.","['H04L63/0236', 'G06F11/3636', 'H04L41/0806', 'H04L41/0816', 'H04L41/082', 'H04L41/0869', 'H04L41/0894', 'H04L41/0895', 'H04L43/50', 'H04L45/08', 'H04L45/24', 'H04L45/80', 'H04L63/0218', 'H04L63/0263', 'H04L63/0272', 'H04L63/0435', 'H04L63/123', 'H04L63/1425', 'H04L63/1433', 'H04L63/145', 'H04L63/166', 'H04L63/20', 'H04L9/3247']"
CN114866158A,Channel modeling and simulating method for underwater laser digital communication system,"The invention provides a channel modeling and simulating method for an underwater laser digital communication system, which comprises the following steps: firstly, an underwater laser digital communication experimental system is set up, actual measurement receiving signals under various water quality conditions are obtained, a data set is set up, and a training set and a testing set are divided; then, establishing a condition to generate a confrontation network model CGAN, wherein the model comprises a generator model G and a discriminator model D, and simultaneously introducing a gradient punishment algorithm to improve the training process; then, setting network parameters and training parameters, adopting a small batch random gradient descent algorithm, importing a training set alternative training generator model and a discriminator model, obtaining a final channel model and realizing channel simulation. The reliability of the model established by the method is better; the accuracy of channel simulation is better, and the obtained simulation signals are more in line with random distribution in a real application environment, so that the method is more suitable for guiding the design and practical application of the underwater laser digital communication system.","['H04B10/80', 'G06F30/27', 'G06N3/045', 'G06N3/08', 'H04B10/073', 'H04B10/112', 'H04B17/3912', 'Y02A20/152']"
US20230241403A1,Generating voltage-gradient geometries in biological tissue,An invention and method that generate dynamical shaped voltage-gradient geometries through a plurality of dual-modal electrode-contacts placed around the biological tissue in vivo. The geometry of the voltage gradient is optimized through a feedback mechanism from the plurality of dual-modal electrode-contacts that can record electric and magnetic field potentials in the biological tissue. A control controls the waveform signal between sets of electrode-contacts to generate dynamically shaped voltage gradients to modulate a specific set of properties in the biological tissue. A method of analysis for the recorded electric and magnetic field potentials is purposed to optimize the shape of the voltage-gradient geometry through modulation of the waveform signal that is sent through the dual-modal electrode-contacts.,"['A61N1/3727', 'A61N1/0534', 'A61N1/3606', 'A61N1/36139']"
WO2022242852A1,"Method for optimizing material properties of components of a battery, manufacturing a fiber network, an electrode and a battery","The present invention relates to a method for optimizing material properties of components of a battery comprising the following steps: Inputting material parameter data, with said material parameter data relating to properties of constituents of the components of the battery; simulating one or more components and/or constituents of components of the battery using a simulation model which takes the material parameter data as input to generate simulation result data as output, with the simulation result data comprising at least one of the following data: data on microscopic geometric features of the component, data on a conductivity of the component, data on a current collector, data on a binder phase, data on a diffusivity of the electrolyte and data on a charging and discharging potential of the component; training an AI model with the material parameter data as input and the simulation result data as output; evaluating a final accuracy of the AI model with respect to the simulation model using extended material parameter data; using the AI model to output material properties of the constituents of the components of the battery. The invention further relates to a method for manufacturing a fiber network, to an electrode and to a battery.","['H01M4/0471', 'H01M4/663', 'G06F30/23', 'G06F30/27', 'H01M10/0525', 'H01M4/1391', 'H01M4/1393', 'H01M4/1395', 'H01M4/505', 'H01M4/525', 'H01M4/623', 'H01M4/625', 'H01M4/661', 'H01M4/806', 'C25B11/031', 'C25B11/054', 'C25B11/056', 'C25B11/071', 'C25B11/077', 'C25B11/081', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'H01M10/054', 'H01M2004/021', 'H01M4/8605', 'H01M4/8803', 'Y02E60/10']"
US20240394483A1,Insights service for large language model prompting,"Systems and methods are provided herein for operating an insights service. For example, a method of operating an insights service includes observing, on a per-user basis with respect to each user in a group of observed users, the prompting associated with a large language model service, identifying, on the per-user basis with respect to each of the group of observed users, insights into the prompting, and enabling display of the insights in a user interface associated with a reviewing user.","['G06F40/40', 'G06Q10/06395']"
CN113646773A,Image expansion neural network,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating realistic image extensions. In one aspect, a method includes providing an input including a provided image to a generative neural network having a plurality of generative neural network parameters. The generative neural network processes the input according to the trained values of the plurality of generative neural network parameters to generate an extended image. The expanded image has (i) more rows, more columns, or more rows and more columns than the provided image, and (ii) is predicted to be a true expansion of the provided image. The generative neural network is trained using an opposition loss objective function.","['G06T5/77', 'G06V10/82', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06T7/10', 'G06T2207/20132']"
CN117368857A,Radar active deception jamming signal identification method based on denoising diffusion probability model,"The invention discloses a radar active deception jamming signal identification method based on a denoising diffusion probability model, which comprises the following steps: acquiring a radar active deception jamming signal with a jamming type tag; performing time-frequency analysis on the radar active deception jamming signals by adopting short-time Fourier transform to obtain a time-frequency image original sample set; training a pre-established label guide denoising diffusion probability model according to a time-frequency image original sample set; generating a time-frequency image generation sample according to the trained label guide denoising diffusion probability model and the interference type label, and establishing a time-frequency image generation sample set; generating a sample set according to the original sample set of the time-frequency image and the time-frequency image to establish an active deception jamming signal data set; and then training, verifying and testing the preset interference recognition model according to the active deception interference signal data set to obtain an interference recognition model passing the test. The method can effectively improve the identification accuracy of the interference identification model on the radar active deception interference signals.","['G01S7/36', 'G01S7/417', 'G01S7/418', 'Y02T10/40']"
CN103765196B,The light analytical equipment utilizing single incandescnet particle to detect and light analytical approach,"Provide and can the deviation of the testing result of the signal of the light of incandescnet particle be suppressed less and the light analysis technology of the light of incandescnet particle in can putting forward high-precision, test sample solution using to utilize in the scanning numerator counts method of the photo measure of confocal microscope or multiphoton microscope.The feature of light analysis technology of the present invention is, made the position of the photo detection area of optical system move at least two-wheeled along prescribed path in sample solution by the light path changing microscopical optical system, the light intensity data generating temporally sequence from the light of photo detection area is detected during the position of photo detection area is moved repeatedly along prescribed path, the light intensity data of the temporally sequence using photo detection area repeatedly to obtain along the touring movement of prescribed path detects the signal represented from the light of each incandescnet particle be present in prescribed path one by one.","['G01N21/64', 'G01N21/6408', 'G01N21/645', 'G01N21/6452', 'G01N21/6458', 'G01N21/6486', 'G02B21/0032', 'G02B21/0048', 'G02B21/0076', 'Y10T436/143333']"
CN117976153A,A method and system for assessing thrombosis risk based on cloud computing,"The invention discloses a thrombus risk assessment method and system based on cloud computing, and relates to the technical field of thrombus risk assessment, wherein the method comprises the following steps: pre-constructing a cloud computing risk assessment architecture; receiving a scanning region of interest, activating an MRI edge node, and positioning a target MRI edge node and target MRI entity equipment; performing equipment parameter adjustment analysis to obtain optimized imaging parameters; synchronizing the optimized imaging parameters to target MRI entity equipment, and carrying out scanning treatment on a target user to obtain an MRI image set; the target MRI entity equipment feeds back the MRI image set to a target MRI edge node for blood vessel image segmentation pretreatment to obtain a blood vessel image set; and receiving the blood vessel image set for thrombus risk assessment, and obtaining thrombus risk grade parameters. The invention solves the technical problems of complex operation, long inspection time and inaccurate positioning in the prior art, and achieves the technical effect of improving the treatment timeliness of users.","['G16H30/20', 'G06N3/0464', 'G06N3/084', 'G06T5/50', 'G06T7/0012', 'G06T7/10', 'G06V10/25', 'G16H50/30', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30101']"
US20250110789A1,Building management systems with sustainability improvement architectures,"A method for processing compute activities of a building management system of a building, the method including receiving, by one or more processors, a selection from a user of a sustainability tuning level from among a plurality of sustainability tuning levels, the plurality of sustainability tuning levels representing different levels of weighting to be placed on mitigating a sustainability impact of computing workloads balanced against one or more other factors, receiving, by one or more processors, a computing workload to be processed by the building system, determining, by the one or more processors, an execution plan for processing the computing workload based at least in part on the selected sustainability tuning level, and causing, by the one or more processors, the computing workload to be processed in accordance with the execution plan.","['G06F9/5094', 'G06F9/5027', 'G05B23/024', 'G05B23/027', 'G06F11/3612', 'G06F3/04847', 'G06Q50/163', 'G06F2209/501']"
WO2019172848A1,Method and apparatus for predicting occurrence of an event to facilitate asset maintenance,"An apparatus and method for predicting occurrence of an event to facilitate asset maintenance, the apparatus comprising: a processor for executing instructions in a memory to: receive a maintenance log comprising: asset identifiers; event markers; and timestamps;determine an asset ontology vector for a target asset comprising: a target asset functionality vector and an ontology location vector of the target asset comprising values of distances between an asset identifier of the target asset and asset identifiers of other assets; extract features from the maintenance log to form a vector defining values of an operation time window and a feature vector for the target asset; input the asset identifier of the target asset, the asset ontology vector and the feature vector to a neural network; and output from the neural network a predicted event that will occur and time of occurrence of the predicted event.","['G06Q10/06', 'G06N3/044', 'G06Q10/20', 'G06N3/045', 'G06N3/084', 'G06N5/02', 'G06Q50/40']"
CN112232488A,A new energy output scenario generation method based on deep learning and data-driven,"The method comprises the steps of constructing a generated countermeasure network based on a deep learning and data driving new energy output scene generation method, wherein the generated countermeasure network comprises a generator and a discriminator; the generation of the countermeasure network is based on creating conditions for the generation of the countermeasure network, the generator of the conditional generation countermeasure network having two inputs, one being gaussian noise and the other being a scene tag. The discriminator of the conditional generation countermeasure network has two inputs, one is the synthesized data generated by the generator, and the other is the real data; training the condition generation countermeasure network through training data to obtain a well-trained condition generation countermeasure network; and determining a label value of a scene to be generated, inputting the label value and Gaussian noise into a trained condition generation countermeasure network together, and obtaining output data of the corresponding scene. The fitting capability of the condition generation countermeasure network adopted by the invention far exceeds that of the traditional statistical model, so that the real distribution information can be better captured, and meanwhile, the robustness and the anti-interference capability are very strong.","['G06N3/045', 'G06N3/084', 'G06Q50/06']"
EP4591279A1,Null-text inversion for editing real images using guided diffusion models,"Implementations are directed to generating an edited synthetic image, that corresponds to a real image captured using a real camera, but that is generated based on, and reflects, edit(s) to an original natural language (NL) caption for the real image. For example, the original NL caption can be used in performing an inversion on the real image to generate a diffusion trajectory for the real image. Further, the diffusion trajectory can be used to optimize a sequence of unconditional embeddings, for the real image, that are not based on the NL caption for the real image. Yet further, the edited NL caption, the unconditional embeddings, and at least part of a noise vector (of the diffusion trajectory) can be processed, using a Large-scale language-image (LLI) model, to generate the edited synthetic image.",['G06T11/00']
CN103055669B,A kind of Method And Device For Exhaust Air Purifying Treatment,"The present invention relates to a kind of Method And Device For Exhaust Air Purifying Treatment.The present invention is undertaken by superoxide radical generative process being separated with the oxidation decomposition course of waste gas, avoid harmful components in waste gas directly to contact with superoxide radical generator and cause catalysqt deactivation, realize the high efficiency of equipment, energy saving, be specially adapted to volatile organic contaminant and the higher waste gas of sulfur content.Present invention achieves the automatic process of spray process spray liquid and recycle, and the automatic governing of spray liquid, solve the problem of conventional method secondary pollution and water content consumption.The each Unit Design of apparatus of the present invention is reasonable, and integration degree is high, and whole waste gas treatment process can realize Automatic Control, and treatment effeciency is high, and treatment effect can be guaranteed.",[]
WO2023108418A1,Brain atlas construction and neural circuit detection method and related product,"Provided in the embodiments of the present application are a brain atlas construction and neural circuit detection method and a related product. The method comprises: acquiring first target data according to a first image, and acquiring second target data according to a second image; determining a first brain atlas according to the first target data and the second target data, wherein the first brain atlas is used for representing the relationship between the first target data and the second target data; inputting the first brain atlas into a first neural network, so as to output a first feature, wherein the first feature is used for representing a high-order topological feature of the first brain atlas; and inputting the first feature into a second neural network, so as to output a first neural circuit, wherein the second neural network is used for decoupling areas in the first brain atlas, and the first neural circuit is used for representing a connection relationship between the areas of the first brain atlas. Therefore, the aim of detecting a neural circuit can be achieved.","['G06V10/774', 'G06V10/82']"
US12154203B2,Generating customized context-specific visual artifacts using artificial intelligence,"Methods and apparatuses are described for generating customized, context-specific visual artifacts using artificial intelligence (AI). A server computing device captures input data from one or more remote computing devices, the input data associated with one or more users. The server computing device creates one or more visual artifacts based upon the input data, each of the one or more visual artifacts associated with one or more of the users. The server computing device integrates the visual artifacts into a communication session associated with the remote computing devices.","['G06T11/60', 'G06N20/00', 'G06N3/04']"
US20220208173A1,Methods of Generating Speech Using Articulatory Physiology and Systems for Practicing the Same,"Provided are methods and systems of encoding and decoding speech from a subject using articulatory physiology. Methods of the present disclosure include receiving a physiological feature signal associated with a spatiotemporal movement of a vocal tract articulator, generating a speech pattern signal in response to the physiological feature signal, and outputting speech that is based on the speech pattern signal. Methods of the present disclosure further include acquiring one or more of a linguistic signal and an acoustic signal; associating a physiological feature with the linguistic or acoustic signal; generating a speech pattern signal in response to the physiological feature; and outputting speech that is based on the speech pattern signal. Speech decoding systems and devices using articulatory physiology for practicing the subject methods are also provided. Various steps and aspects of the methods will now be described in greater detail below.","['G10L13/02', 'G10L13/027', 'A61B5/1114', 'A61B5/369', 'A61B5/37', 'A61B5/374', 'A61B5/4803', 'A61B5/7267', 'A61B5/741', 'G06N3/04', 'G10L13/047', 'G10L15/24', 'G10L25/24', 'G10L25/30', 'G10L25/75', 'G10L15/16']"
EP4573489A1,Determining failure cases in trained neural networks using generative neural networks,"Methods, systems, and computer readable storage media for performing operations comprising: obtaining a plurality of initial network inputs that have been classified as belonging to a corresponding ground truth class; processing each of the plurality of initial network inputs using a trained target neural network to generate a respective predicted network output for each initial network input, the respective predicted network output comprising a respective score for each of a plurality of classes, the plurality of classes comprising the ground truth class; identifying, based on the respective predicted network outputs and the ground truth class, a subset of the initial network inputs as having been misclassified by the trained target neural network; and determining, based on the subset of initial network inputs, one or more failure case latent representations, wherein each failure case latent representation is a latent representation that characterizes network inputs that belong to the ground truth class but that are likely to be misclassified by the trained target neural network.","['G06N3/045', 'G06F18/23213', 'G06N3/0475', 'G06N3/09', 'G06N5/045', 'G06V10/764', 'G06V10/772', 'G06V10/776', 'G06V10/82']"
US11763049B1,Systems and methods for time series simulation,"Systems, apparatuses, methods, and computer program products are disclosed for generating time series. A time series simulator receives information corresponding to a request for time series. The information is formatted into input data by the time series simulator. The input data comprises at least one continuous condition. A generator network of the continuous condition generative adversarial network (CCGAN) generates the time series based directly on a value of the at least one continuous condition. The time series is provided such that the time series is at least one of (a) provided as input to an analysis pipeline or (b) received by a user computing device wherein a representation of at least a portion of the one or more time series is provided via an interactive user interface of the user computing device.",['G06F30/27']
WO2011022634A2,Genetically modified rat models for pain,"This invention relates to the engineering of animal cells, preferably mammalian, more preferably rat, that are deficient due to the disruption of gene(s) or gene product(s) resulting in altered nervous system function. In one aspect, the altered function results in pain in the mammal. In another aspect, the nervous system dysfunction results in prolonged hyperalgesia, allodynia, and loss of sensory function. In another aspect, the invention relates to genetically modified rats, as well as the descendants and ancestors of such animals, which are animal models of altered nervous system function mediated pain and methods of their use. In another aspect, the genetically modified rats, as well as the descendants and ancestors of such animals, are animal models of nervous system dysfunction resulting in prolonged hyperalgesia, allodynia, and loss of sensory function and methods of their use. In another aspect, the present invention provides a method of identifying a compound useful for the treatment or prevention of pain.","['A01K67/0276', 'A61K49/0008', 'C12N15/8509', 'G01N33/5088', 'G01N33/9486', 'A01K2207/05', 'A01K2217/075', 'A01K2217/15', 'A01K2227/105', 'A01K2267/0356', 'C12N2800/90', 'G01N2333/705', 'G01N2500/10']"
EP4521139A1,Radar signal interference mitigation with generative networks,"A system includes a transmitter configured to transmit a radar signal towards a target object. A receiver is configured to receive a received signal in response to the transmitted radar signal. The system includes a processor configured to receive, using the receiver, a received signal, execute an iterative procedure using a desired signal prior and an interference signal prior and to determine an estimate of an interference signal component of the received signal and an estimate of the desired signal component of the received signal, wherein the interference signal prior is determined using generative modeling and each iteration of the iterative procedure executes a data consistency operation, use the estimate of the interference signal component and the received signal to determine a desired signal, and processing the desired signal to determine an attribute of the target object.","['G01S13/931', 'G01S7/023', 'G01S7/354', 'G01S7/417']"
CN105172157A,Folded Composite Filler And Method For Its Manufacture,A method and apparatus for forming a composite filler. A composite ply is folded. The composite ply comprises fibers arranged at an angle relative to a central axis of the composite ply such that the composite filler has a varying cross-sectional orientation of fibers. A force is applied to the folded composite ply after folding to form a desired shape for the composite filler.,"['B29C53/80', 'B29C65/48', 'B29C65/70', 'B29C66/02241', 'B29C66/03', 'B29C66/301', 'B29C70/205', 'B29C70/34', 'B29D99/0005', 'B29D99/0014', 'B64C1/00', 'B64F5/10', 'B65H45/09', 'B29C53/04', 'B29K2105/0872', 'B29K2105/089', 'B29L2009/00', 'B29L2031/3076', 'B64C2001/0072', 'Y02T50/40']"
CN110728626A,Image deblurring method and apparatus and training thereof,"The application provides a training method, a device, a system and a storage medium for a generative confrontation network for image deblurring. The training method comprises the following steps: preparing a matched fuzzy training image and a clear true value image; generating a deblurring verification graph based on the fuzzy training graph by utilizing a generating network of a generating type countermeasure network; comparing training errors between the deblurred verification graph and the clear truth value graph by using a discriminant network of a generative confrontation network, wherein the discriminant network and the generative network are cascaded with each other; and back-propagating the training error through the generating network and the discriminating network to iteratively update parameters of the generating network and parameters of the discriminating network until the training error satisfies a convergence condition. The application also provides an image deblurring method and device using the trained generative confrontation network.","['G06T5/73', 'G06T2207/20081', 'G06T2207/20084']"
US20250094674A1,Model compensations,"Examples of methods are described herein. In some examples, a method includes generating, using a compensation machine learning model after training, a compensated model based on a three-dimensional (3D) object model. In some examples, the compensation machine learning model is trained by generating candidate compensation plans and evaluating, using a deformation machine learning model, the candidate compensation plans. In some examples, the method includes adjusting the 3D object model based on the compensated model to produce an adjusted model.","['B33Y50/00', 'B22F10/80', 'G06F30/17', 'G06F30/27', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/096', 'B29C64/386', 'G06F2113/10', 'G06F2119/18', 'G06N3/048', 'Y02P10/25']"
US20110023142A1,Genetically Modified Rat Models for Cytokine-Cytokine Signaling Pathways,"The present invention relates to the engineering of animal cells, preferably mammalian, more preferably rat, that are deficient due to the disruption of gene(s) or gene product(s) resulting in cytokine-cytokine mediated autoimmune and inflammatory disease. In another aspect, the invention relates to genetically modified rats, as well as the descendants and ancestors of such animals, which are animal models of human autoimmune and inflammatory disease and methods of their use. Specifically, the invention pertains to a genetically altered rat, or a rat cell in culture, that is defective in at least one of two alleles of a cytokine gene such as the Faslg gene, the Fas gene, etc. In one embodiment, the cytokine gene is the Faslg gene. In another embodiment, the cytokine gene is one of several known cytokine genes, such as Fas, IFNÎ³, TNF-Î±, IL-2, IL-10, and IL-12. The inactivation of at least one of these cytokine alleles results in an animal with a higher susceptibility to cytokine-cytokine mediated autoimmune and inflammatory disease induction. In one embodiment, the genetically altered animal is a rat of this type and is able to serve as a useful model for cytokine-cytokine mediated autoimmune and inflammatory disease and as a test animal for autoimmune and other studies.","['C12N15/8509', 'A01K67/0276', 'A01K2217/075', 'A01K2227/105', 'A01K2267/0325', 'A01K2267/0368']"
WO2011014721A2,Genetically modified rat models for pharmacokinetics,"The present invention provides a desired rat or a rat cell which contains a predefined, specific and desired alteration rendering the rat or rat cell predisposed to drug transport sensitivity or resistance drug transport resistance or sensitivity. Specifically, the invention pertains to a genetically altered rat, or a rat cell in culture, that is defective in at least one of two alleles of a drug transporter gene such as the Slc7all (NC_005101.2) gene, the Abcbl (NC_005103.2) gene, etc. The present invention also provides a desired rat or a rat cell which contains a predefined, specific and desired alteration rendering the rat or rat cell predisposed to drug transport sensitivity or resistancedrug transport resistance or sensitivity. Specifically, the invention pertains to a genetically altered rat, or a rat cell in culture, that is defective in at least one of two alleles of a drug transporter gene.","['C07K14/705', 'A01K67/0278', 'A01K67/0271', 'A01K67/0276', 'C12N15/8509', 'G01N33/5088', 'G01N33/94', 'A01K2207/05', 'A01K2207/12', 'A01K2207/15', 'A01K2207/20', 'A01K2217/052', 'A01K2217/075', 'A01K2217/15', 'A01K2227/10', 'A01K2227/105', 'A01K2267/03', 'A01K2267/0306', 'C12N2800/90', 'G01N2500/04', 'G01N2500/10']"
US20240185305A1,Artificial Intelligence Audience Generation System and Method,"A system includes at least one processor to execute computer-readable instructions to ingest data from at least one third party data source associated with determining an artificial intelligence audience, receive a response to each question associated with determining the artificial intelligence audience, generate a prompt based on the response to each question and transmit the prompt to a large language model (LLM) application programming interface (API), generate the artificial intelligence audience based on the response to each question and the LLM API, and transmit at least one generative image of a member of the artificial intelligence audience, demographic information associated with the member of the artificial intelligence audience, personality information associated with the member of the artificial intelligence audience, and a text box to receive input from a user to allow the user to ask at least one realtime query to the member of the artificial intelligence audience.","['G06F40/40', 'G06Q30/0242', 'G06Q30/0276']"
US20140041063A1,Genetically Modified Rat Models for Obesity and Diabetes,"This invention relates to a genetically modified or chimeric rat cell whose genome comprises chromosomal alleles of an obesity-diabetes gene (especially, the Mc4r gene or Lep gene), wherein at least one of the two alleles contains a mutation, or the progeny of this cell. The obesity or diabetes gene may affect any of the pathways of obesity and diabetes. The obesity or diabetes gene may predispose the rat to a phenotype of obese and diabetic, lean and diabetic, obese and non-diabetic, non-obese and diabetic or any of the combinations thereof. In another aspect, the invention relates to a desired rat or a rat cell which contains a predefined, specific and desired alteration rendering the rat or rat cell predisposed to obesity or diabetes.","['A61K49/0008', 'A01K67/0271', 'A01K67/0276', 'C07K14/715', 'C07K14/723', 'A01K2217/05', 'A01K2227/105', 'A01K2267/0362', 'C12N2800/90', 'G01N2800/042', 'G01N2800/044']"
US20240366183A1,Real-time super-resolution ultrasound microvessel imaging and velocimetry,Described here are systems and methods for super-resolution ultrasound microvessel imaging and velocimetry. The systems and methods utilize deep learning and parallel computing to realize real-time super-resolution microvascular imaging and quantitative analysis and display.,"['A61B8/0891', 'A61B8/481', 'A61B8/5207', 'A61B8/06']"
US20240230810A1,System and Method for Quantitative Magnetic Resonance Imaging Using a Deep Learning Network,"A method for generating magnetic resonance imaging (MRI) quantitative parameter maps includes receiving at least one multi-contrast magnetic resonance (MR) image of a subject, providing the image to an artifact suppression deep learning network of a two-stage deep learning network and generating at least one multi-contrast MR image with suppressed undersampling artifacts using the artifact suppression deep learning network. The method further includes providing the at least one multi-contrast MR image with suppressed undersampling artifacts to a parameter mapping deep learning network of the two-stage deep learning network, generating at least one quantitative MR parameter map and generating an uncertainty estimation map for the at least one quantitative MR parameter map using the parameter mapping deep learning network. The method further includes displaying at least one multicontrast MR image with suppressed undersampling artifacts, at least one quantitative MR parameter map, and the corresponding uncertainty estimation map on a display.","['G01R33/4828', 'G01R33/50', 'G01R33/5608', 'G06T7/0016', 'G01R33/4826', 'G01R33/5676', 'G06N3/0464', 'G06N3/08', 'G06T2207/10076', 'G06T2207/10096', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30056']"
CN113378472B,Mixed boundary electromagnetic backscattering imaging method based on generation countermeasure network,"The invention discloses a mixed boundary electromagnetic backscattering imaging method based on a generation countermeasure network, which comprises the following steps: 1, a data preparation stage, namely performing unified modeling by using a T-matrix method according to a measured scattering field, and quickly generating a low-resolution scatterer image by using a Back Propagation (BP) method; 2, in the stage of network structure building, a confrontation network generating framework is adopted, and meanwhile, an attention mechanism module is added in a generator; designing a loss function, and establishing an optimization target for generating a countermeasure network; and 4, generating a confrontation network through training, and reconstructing mixed boundary T-matrix coefficients. The method applies the method of generating the countermeasure network and combining the T-matrix to the mixed boundary electromagnetic backscatter imaging, adds an attention mechanism module in a generator, and provides a data balance strategy aiming at the problem of the imbalance of PEC and dielectric scatterer T-matrix coefficients, thereby realizing the quick and high-precision mixed boundary electromagnetic backscatter imaging.","['G06F30/27', 'G06F17/16', 'G06N3/045', 'G06N3/084', 'G06F2111/10']"
CN112437451A,Wireless network flow prediction method and device based on generation countermeasure network,"The invention discloses a wireless network flow prediction method and equipment based on a generation countermeasure network, wherein the method comprises the following steps: acquiring historical data of regional sampling, and constructing a two-dimensional sparse time sequence; performing feature extraction by using convolution LSTM, and performing preliminary prediction on a future two-dimensional flow map by using historical data; and taking the preliminary prediction result as a training set for generating the countermeasure network, and constructing a novel generation countermeasure network with a generation network, a resolution network and a precision guarantee network, so that a flow map prediction result with higher precision and smaller error is obtained. The method can be applied to large-scale regional flow trend prediction, and early warning is carried out on urban flow distribution by using crowd sensing.","['H04W16/22', 'H04W24/06', 'H04W28/0289']"
CN117522920A,Pedestrian track prediction method based on improved space-time diagram attention network,"The invention relates to a pedestrian track prediction method based on an improved space-time diagram attention network, and belongs to the technical field of computer vision. The technical problem of insufficient modeling of the dynamic characteristics of the pedestrian behavior by the conventional model is solved. The technical proposal is as follows: space-time modeling is carried out on the pedestrian track, and a time diagram and a space diagram are constructed; modeling spatial interactions and temporal dependencies between pedestrians using an attention mechanism; modeling coupled space-time interaction features by using a full connection layer; enhancing output spatial embedding using a temporal attention mechanism; combining random Gaussian noise to generate various random predictions; pedestrian position is predicted using the full connectivity layer. The beneficial effects of the invention are as follows: the modeling capability of the model on the dynamic characteristics of the pedestrian behavior is improved, so that the pedestrian interaction modeling is more compact and reasonable, and the accuracy of pedestrian track prediction is improved in different scenes.","['G06T7/251', 'G06N3/045', 'G06N3/049', 'G06V10/7715', 'G06T2207/20084', 'G06T2207/30241']"
WO2021223165A1,Systems and methods for object evaluation,"A method for object evaluation is provided. The method may include for each of one or more first virtual edges associated with a plurality of objects, obtaining first edge feature information of the first virtual edge. The first virtual edge may connect two objects of the plurality of objects. The first edge feature information of the first virtual edge may include feature information of an entity group that includes one or more entities associated with the two objects. The method may also include determining an object representation vector of at least one of the objects based on object feature information of the objects and the first edge feature information of the first virtual edges by applying an object representation model. The method may further include generating an evaluation result with respect to the at least one object based on the object representation vector by applying an object evaluation model.","['G06Q30/0207', 'G06Q30/0251', 'G06Q30/0282', 'G06Q30/0631']"
CN113113130A,Tumor individualized diagnosis and treatment scheme recommendation method,"The invention discloses a recommendation method of an individual tumor diagnosis and treatment scheme, which is used for predicting the biological behavior of tumor cells, so that the diagnosis and treatment scheme is made in an individual way, and the success rate of diagnosis and treatment is improved; the method specifically comprises the following steps: information acquisition: classifying and sorting the image data in the image database according to the registration number, wherein the image data corresponds to clinical data one by one; image extraction: directly extracting image parameters or extracting image parameters by adopting image omics software; establishing a model: establishing a model by adopting a traditional machine learning method and/or a deep learning method; and (3) evaluating a model: all corresponding models perform model evaluation on the application test data, and the evaluation of the models on a training set and a test set is given; and (4) verification result: and (4) carrying out verification analysis by adopting a method combining internal data verification and external data verification, and continuously and repeatedly carrying out model adjustment and optimization to obtain a prediction model.","['G16H50/20', 'G06N3/045', 'G06N3/08', 'G16H30/40', 'G16H50/70']"
CN119293235B,"A data processing method, device, computer, storage medium and program product","The embodiment of the application discloses a data processing method, a device, a computer, a storage medium and a program product, and relates to the technical field of computers; acquiring a first target type indicated by the business semantic information, acquiring a first business data set belonging to the first target type from the classification data respectively corresponding to N business types of the business database, performing information retrieval in the first business data set, acquiring retrieval content associated with a first target component, generating a business result aiming at a business processing request text based on intention requirement information and the retrieval content, and displaying the business result in an intelligent session page. By adopting the application, the data retrieval efficiency can be improved, and the labor cost can be saved.","['B64F5/60', 'G06F16/3329', 'G06F16/3344', 'G06F16/35', 'G06F16/367', 'G06F18/213', 'G06F18/22', 'G06F40/205', 'G06F40/279', 'G06F40/30', 'G06F40/35', 'G06T11/206', 'Y02P90/30']"
US11870939B2,Audio quality improvement related to a participant of a virtual three dimensional (3D) video conference,"A method for audio quality improvement related to a participant of a virtual three dimensional (3D) video conference, the method may include: determining participant generated audio, by a machine learning process and based on image analysis of a video of the participant obtained during the virtual 3D video conference; and generating participant related audio information based at least on the participant generated audio; wherein the participant related audio information, once provided to a computerized system of another participant, causes the computerized system of the other participant to generate participant related audio of higher quality than participant audio when the participant audio is included in sensed audio that is sensed by an audio sensor that is associated with the participant.","['H04M3/568', 'H04L12/1827', 'H04L65/403', 'H04L65/80', 'H04M2203/1025', 'H04M3/567']"
CN114424022A,"Distance measuring apparatus, distance measuring method, program, electronic device, learning model generating method, manufacturing method, and depth map generating method","The present technology relates to a distance measuring apparatus, a distance measuring method, a program, an electronic device, a learning model generation method, a manufacturing method, and a depth map generation method that enable more accurate distance measurement. The present invention has: a first determination unit that determines whether a difference in depth value between a first pixel and a second pixel adjacent to the first pixel in the depth map is greater than a first threshold; and a second determination unit that determines whether a reliability difference between the first pixel and the second pixel is greater than a second threshold value when the first determination unit determines that the difference in distance between the first pixel and the second pixel is greater than the first threshold value, wherein the second determination unit determines that the reliability difference between the first pixel and the second pixel is greater than the second threshold value, and confirms that the first pixel is a defective pixel. For example, the present technology may be applied to a ranging apparatus.","['G01C3/02', 'G01S17/894', 'G01C3/06', 'G01B11/22', 'G01C3/08', 'G01S17/89', 'G01S17/931', 'G01S17/933', 'G01S7/497', 'G06T7/50', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'H04N25/77']"
CN115063303B,Image 3D method based on image restoration,"The invention provides an image 3D method based on image restoration, which comprises the following steps: acquiring an image to be processed, and acquiring the depth of the image through a pre-trained depth extraction model; acquiring a primary background edge image based on a preset depth edge value, and then filtering the primary background edge image and detecting a connected domain to acquire an accurate background edge image; determining an image range to be repaired in the accurate background edge map according to a preset 3D effect, and acquiring content materials used for repairing from the image to be processed; inputting the image to be processed, the accurate background edge map, the background image range to be repaired and the content material into a pre-trained image repair model, so as to generate a repaired background image; and combining the foreground image with the restored background image, and outputting a converted video according to a preset 3D effect. The method can be widely applied to actual scenes, has strong robustness, and can obtain good processing effect on images with complex front background.","['G06T5/77', 'G06N3/04', 'G06N3/08', 'G06T15/005', 'G06T5/70', 'G06T7/12', 'G06T7/13', 'G06T7/194', 'G06T7/55', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
KR102558549B1,Apparatus and method for generating prediction result for tcr using artificial intelligence technology,"Disclosed is a method for generating a prediction result using artificial intelligence technology, which is performed by a computing device. The method comprises the steps of: obtaining a first input data set including first data corresponding to a peptide and second data corresponding to a major histocompatibility complex (MHC), the first data including an amino acid sequence corresponding to the peptide, and the second data including an amino acid sequence corresponding to the MHC; and obtaining a prediction result including third data related to CDR3Î± of a T cell receptor (TCR) corresponding to the peptide and the MHC, and fourth data related to CDR3Î² of the TCR corresponding to the peptide and the MHC from the first input data set using an artificial intelligence-based prediction model. Therefore, a peptide-MHC complex and a TCT coupled thereto can be predicted or distinguished more accurately in a more efficient manner.","['G16B40/20', 'G01N33/56977', 'G01N33/6818', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G16B15/30', 'G16B30/00', 'G16B50/00', 'G01N2333/70539']"
CN114209278A,Deep learning skin disease diagnosis system based on optical coherence tomography,"The invention provides a deep learning skin disease diagnosis system based on optical coherence tomography, which is characterized in that an image acquisition unit adopts an OCT imaging system to carry out three-dimensional OCT image imaging on a detected skin area, thereby realizing non-invasive extraction of skin deep information data; secondly, an image preprocessing unit carries out noise reduction and enhancement preprocessing on the original three-dimensional OCT image, the inherent speckle noise problem of OCT imaging and the limitation problem of low sampling rate are eliminated, and the resolution of the image is improved; then extracting the characteristics of skin anatomy and skin microvasculature by a characteristic extraction unit based on the preprocessed OCT image, and carrying out depth characteristic extraction and characteristic fusion by a depth learning diagnosis model of a depth learning diagnosis unit so as to detect corresponding skin disease information; the diagnosis system improves the accuracy of skin disease diagnosis, reduces the dependence on doctor diagnosis experience and level, and enables potential skin diseases to be discovered, diagnosed and treated as soon as possible without pathological biopsy.","['A61B5/0066', 'A61B5/02007', 'A61B5/441', 'A61B5/7267', 'Y02A90/10']"
WO2023170534A2,Methods and compositions for diagnosing diseases,"A composition for detecting a target polynucleotide in a sample, comprising: a polynucleotide isolation solution; a TnpB protein; a guide molecule comprising a sequence capable of binding the target polynucleotide and designed to form a complex with the TnpB protein; amplification reagents; and a detection construct comprising a polynucleotide component, wherein the TnpB protein exhibits collateral nuclease activity and cleaves the polynucleotide component of the detection construct once activated by the target polynucleotide sequence, thereby generating a detectable signal.",['C12Q1/6816']
CN111007566B,A Curvature-Driven Diffusion Fully Convolutional Network Seismic Data Bad Sector Reconstruction and Denoising Method,"The invention discloses a curvature-driven diffusion full-convolution network seismic data bad track reconstruction and denoising method, which is based on a curvature-driven diffusion layer, an eight-convolution structure, a high-low level combined structure and a multi-scale jumper structure and provides a curvature-driven diffusion and deep learning based bad track reconstruction and denoising method in order to overcome the limitations of weak generalization capability and low denoising precision of the traditional bad track reconstruction and denoising method. The method for reconstructing and denoising the bad traces of the seismic data disclosed by the invention not only can efficiently reconstruct the bad traces, but also can completely reserve the local details of the seismic data while suppressing the data after noise without generating false images.","['G01V1/282', 'G01V1/30', 'G06N3/045', 'G06N3/08']"
EP4478280A1,Diffusion-guided three-dimensional reconstruction,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for editing images based on decoder-based accumulative score sampling (DASS) losses.","['G06T17/20', 'G06T17/00', 'G06T11/00', 'G06T5/60', 'G06T5/70', 'G06T2200/04', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US20250036935A1,Coupled physics-informed neural network for solving displacement distribution of bounded vibration string under unknown external driving force,"A coupled physics-informed neural network for solving displacement distribution of a bounded vibration string under an unknown external driving force is provided. A novel PINN is proposed, called C-PINN, used for solving the displacement distribution of the bounded vibration string under an external driving force with little or even no priori information. It comprises two neural networks: NetU and NetG. NetU is used for approximating satisfying the displacement distribution of the bounded vibration string under study. NetG is used for regularizing u in the NetU to satisfy the displacement distribution of the approximation of NetU. The two networks are integrated into a data-physics-hybrid loss function. In addition, a proposed hierarchical training strategy is used for optimizing the loss function and realizing the coupling of the two networks. Finally, the performance of the C-PINN in solving the displacement distribution of the bounded vibration string under the external driving force is verified.","['G06F30/27', 'G06N3/045', 'G01M99/007', 'G06F17/13', 'G06N3/04', 'G06N3/044', 'G06N3/08', 'G06F2119/14', 'Y02T90/00']"
US20240296527A1,Reducing noise in ct images using synthetic data,"The current disclosure provides methods and systems to reduce an amount of noise in image data. In one example, a method for creating synthetic computed tomography (CT) images for training a model to reduce an amount of noise in acquired CT images is proposed, comprising performing a tissue segmentation of reference images of an anatomical region of a subject to determine a set of different tissue types of the reference images; and generating synthetic CT images of the reference images by assigning CT image values of the synthetic CT images based on the different tissue types.","['A61B6/5258', 'G06N3/04', 'A61B6/5247', 'G06N3/08', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T7/11', 'G06T7/143', 'G06T2207/10056', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
WO2024220902A1,Batch selection policies for training machine learning models using active learning,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a machine learning model. In one aspect, a method comprises: generating a set of candidate batches of model inputs; generating, for each candidate batch of model inputs, a respective score for the candidate batch of model inputs that characterizes: (i) an uncertainty of the machine learning model in generating predicted labels for the model inputs in the candidate batch of model inputs, and (ii) a diversity of the model inputs in the candidate batch of model inputs; and selecting the current batch of model inputs from the set of candidate batches of model inputs based on the scores; and training the machine learning model on at least the current batch of model inputs.","['G06N20/00', 'G06N3/045', 'G06N3/091', 'G06N20/10', 'G06N20/20', 'G06N3/082', 'G06N3/084', 'G06N5/01']"
US20220207212A1,Topology optimization with reaction-diffusion equations,"A computer-implemented method for designing a 3D modeled object representing a mechanical part. The method comprises providing a 3D finite element mesh and associated data. The data associated to the 3D finite element mesh comprise one or more forces each forming a respective load case, one or more boundary conditions, and one or more parameters related to a material. The method further comprises performing a topology optimization based on the finite element mesh and on the data associated to the finite element mesh. The topology optimization is performed among candidate material distributions each corresponding to a solution of a system of reaction-diffusion equations. This forms an improved method for designing a 3D modeled object representing a mechanical part formed in a material.","['G06F30/20', 'G06F30/18', 'G06F17/15', 'G06F30/12', 'G06F30/23', 'G06F2111/10']"
US11822325B2,Methods and systems for managing a pipe network of natural gas,"The present disclosure provides a method for managing a pipe network of natural gas. The method may comprise: obtaining pipe network information of natural gas in at least one area, the pipe network information including a running time of a system of the pipe network of the natural gas and gas leakage information of the pipe network; extracting feature information based on the running time and the gas leakage information; predicting a maintenance time of the pipe network by inputting the feature information into a maintenance time prediction model.","['G05B23/0283', 'G05B13/047', 'G05B13/048', 'G05B2223/04', 'G05B2223/06']"
US12182998B2,Self-supervised machine learning for medical image reconstruction,"For reconstruction in medical imaging, self-consistency using data augmentation is improved by including data consistency. Artificial intelligence is trained based on self-consistency and data consistency, allowing training without supervision. Fully sampled data and/or ground truth is not needed but may be used. The machine-trained model is less likely to reconstruct images with motion artifacts, and/or the training data may be more easily gathered by not requiring full sampling.","['G01R33/5608', 'G06T7/0012', 'G01R33/4818', 'G16H30/40', 'G01R33/5611', 'G01R33/56341', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
CN118521482B,A deep image-guided super-resolution reconstruction network model,"The invention provides a depth image guided super-resolution reconstruction network model which comprises a gradient feature extraction module, a depth feature extraction module, a feature fusion module and a diffusion module. The invention can reserve and fuse the color image characteristics similar to the depth characteristic domain, thereby avoiding the negative influence of the excessive transfer of the color image texture and improving the quality of the reconstructed image; the depth fusion of the fusion gradient features and the fusion depth features can be ensured through the feature fusion module, so that negative effects caused by insufficient feature fusion are avoided; in addition, the invention can ensure the generation of the high-resolution target depth image by utilizing the strong data distribution simulation capability of the diffusion module and under the guidance of the guide information, so that the target depth image is similar to the real image, thereby reducing the uncertainty of the generation of the high-resolution depth image.","['G06T3/4053', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06V10/806']"
US20200360728A1,Machine learning based dose guided real-time adaptive radiotherapy,"Techniques for adjusting radiotherapy treatment for a patient in real-time are provided. The techniques include obtaining a training patient anatomy at a first time within a training radiotherapy treatment fraction after a training radiotherapy treatment dose has been delivered by a radiotherapy device; computing a deviation between the training patient anatomy at the first time and reference training patient anatomy during the training radiotherapy treatment fraction, wherein the reference training patient anatomy indicates a prescribed training dose parameter to be delivered within the training radiotherapy treatment fraction; applying the computed deviation to a machine learning model to estimate one or more intra-fraction radiotherapy treatment parameters of a function that provides a radiotherapy device parameter adjustment based on the one or more intra-fraction radiotherapy treatment parameters; and training the machine learning model to establish a relationship between the computed deviation and the one or more intra-fraction radiotherapy treatment parameters.","['A61N5/1067', 'A61B5/0036', 'A61B5/7267', 'A61N5/1036', 'A61N5/1081', 'G06N20/00', 'G06N3/08', 'G16H20/40', 'G16H50/20', 'G16H50/70', 'A61B5/055', 'A61B6/032', 'A61B6/037', 'A61N2005/1041', 'A61N5/1038', 'G06N3/045', 'G06N3/047']"
WO2025161816A1,"Anomaly image generation method, training sample generation method, and detection method","The present application provides an anomaly image generation method, a training sample generation method for a detection model, a detection method, a related apparatus, an electronic device, and a medium, which are applied to the technical field of computer vision. The anomaly image generation method comprises: inputting a reference anomaly image and an initialized embedding vector into an image generation model to update the initialized embedding vector on the basis of the reference anomaly image, so as to obtain an updated embedding vector; then, inputting a reference normal image and the updated embedding vector into the image generation model to apply the updated embedding vector to the reference normal image, so as to obtain a generated anomaly image. Since the updated embedding vector comprises the anomaly image feature distribution obtained by learning on the basis of the reference anomaly image, the generated anomaly image can reflect the features of the anomaly image in the real world, and further, the generated anomaly image can serve as a negative sample for training a detection algorithm model, thereby facilitating improvement of the detection performance of the detection algorithm model.","['G06V10/774', 'G06N3/045', 'G06N3/08', 'G06T7/0004', 'G06V10/30', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US12154274B2,Systems and methods for generating clinically relevant images that preserve physical attributes of humans while protecting personal identity,"There is provided a method of generating a dataset of synthetic images, comprising: for each real image each depicting a real human anatomical structure: extracting and preserving a real anatomical structure region(s) from the real image, generating a synthetic image comprising a synthetic human anatomical structure region and the preserved real anatomical structure region(s), designating pairs of images, each including the real image and the synthetic image, feeding the pair into a machine learning model trained to recognize anatomical structure parts to obtain an outcome of a similarity value denoting an amount of similarity between the real image and the synthetic image, verifying that the synthetic image does not depict the real human anatomical structure when the similarity value is below a threshold, wherein an identity of the real human anatomical structure is non-determinable from the synthetic image, and including the verified synthetic image in the dataset.","['G06T7/0012', 'G06V10/82', 'G06T11/60', 'G06T5/50', 'G06T7/11', 'G06V10/25', 'G06V10/44', 'G06V10/46', 'G06V10/761', 'G06V10/772', 'G06V10/774', 'G06V40/16', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30104']"
US20240096479A1,Building a machine-learning model to predict semantic context information for contrast-enhanced medical imaging measurements,"In a computer-implemented method, a machine-learning model is pre-trained in an unsupervised manner to predict time-related information based on data obtained from a contrast-enhanced medical imaging measurement. This pre-trained machine-learning model is then used to build another machine-learning model to predict semantic context information for images determined from the contrast-enhanced medical imaging measurement.","['G16H30/40', 'G06T7/0012', 'G06T7/11', 'G16H30/20', 'G16H50/20', 'G16H50/70', 'G06T2207/10088', 'G06T2207/20081']"
CN117252753A,Image processing method and device based on generation type artificial intelligence technology,"The invention relates to an image processing method and device based on a generation type artificial intelligence technology, wherein the method comprises the following steps: 1) Uploading an image to be processed to a server by a user; 2) Image matting is carried out by using a Sam function based on stable diffusion, and an object required to be scratched by a user is extracted; 3) Clicking a preset style on the page by a user; 4) Redrawing the scratched object by using an inpainting function of a control network control Net and combining a style provided by a user to generate a final effect diagram; specifically, the target image is sent to an algorithm module for mask redrawing to be processed, and an inpaint function is used for combining with a prompt word selected by a user to adjust the image style; the invention can realize efficient, accurate and controllable image matting and redrawing, realize a simpler and more convenient user interaction mode, and overcome the problems of high skill level requirement and time and labor consumption in the operation process.","['G06T7/11', 'G06N3/08', 'G06T11/00']"
CN120071055B,Text-to-image generation model evaluation method and system based on multi-mode large model,"The invention discloses a text-to-image generation model evaluation method and system based on a multi-mode large model. The method comprises the steps of multi-level image information extraction and image feature matrix construction, layered text prompt generation and optimization, generated image batch generation, interactive image comparison and scoring, multi-dimensional feedback and prompt revision, and the generation strategy is dynamically adjusted by repeatedly executing the steps until the preset stop condition is met. Finally, comprehensively analyzing the performance of the target generation model according to the multidimensional visual evaluation results of the reference image and the optimal generation image. According to the evaluation method, through the image regeneration task, the generation model can be accurately generated based on the content and style of the reference image, the defect of the conventional evaluation method in the cross-modal information alignment aspect is overcome, and the evaluation method has high application value.","['G06V10/776', 'G06T11/00', 'G06T7/0002', 'G06V10/761', 'G06V10/82', 'G06T2207/20084', 'G06T2207/30168']"
US20240194213A1,Audio Source Separation using Hyperbolic Embeddings,"There is provided an audio processing system and method comprising an input interface that receives an input audio mixture and transforms it into a time-frequency representation defined by values of time-frequency bins, a processor that maps the values of time-frequency bins into a hyperbolic space by executing an embedding neural network trained to associate each time-frequency bin to a high-dimensional embedding and projecting each high-dimensional embedding into the hyperbolic space, and an output interface that accepts a selection of at least a portion of the hyperbolic space and renders selected hyperbolic embeddings falling within the selected portion of the hyperbolic space.","['G10L21/0308', 'G01H3/08', 'G10L21/0272', 'G10L21/06', 'G10L25/18', 'G10L25/21', 'G10L25/30', 'G10L25/51']"
WO2025066918A1,"Method, apparatus and device for generating artistic code image, and medium","Disclosed in the embodiments of the present description are a method, apparatus and device for generating an artistic code image, and a medium. The scheme may comprise: acquiring a code image generation request that is generated on the basis of a trigger operation of a user; on the basis of the code image generation request, generating initial QR code image data; acquiring feature information corresponding to a promotion object; and using a generative artificial intelligence algorithm, and using the feature information to process the initial QR code image data, so as to obtain an artistic code image.","['G06T11/001', 'G06K19/06037']"
CN117911246B,Multi-mode image super-resolution reconstruction method based on structured knowledge distillation,"The invention discloses a multi-mode image super-resolution reconstruction method for knotted knowledge distillation, and belongs to the technical field of computer image processing. The reconstruction network constructed by the invention comprises a text encoder, an image encoder and a multi-modal diffusion probability model, wherein the text encoder and the image encoder are used for acquiring text characteristic conditions to be transmitted into the multi-modal diffusion probability model, the multi-modal diffusion probability model comprises two branches, one branch is used for acquiring a super-resolution reconstruction image of an input low-resolution image under a given text prompt, and the other branch is used for acquiring the super-resolution reconstruction image of the input low-resolution image. The invention can carry out sparse coding on the text mode, and constrains the solution space of the reconstructed image by utilizing the coded sparse prior characteristic, thereby ensuring the detail consistency of the reconstructed image and the original image. Each iterative distillation of the invention can reduce the diffusion step number of the reconstruction model by 2 times, and the quality of the reconstructed image is hardly reduced in the distillation process.","['G06T3/4053', 'G06F18/213', 'G06N3/045', 'G06N3/0455', 'G06N3/096', 'G06V10/40', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US12057032B1,Auto-solving multiple-choice questions,"Automated solving of multiple-choice questions includes receiving a question and a set of answer options. It further includes performing a search for contextual passages pertaining to the question and the set of answer options. It further includes providing the question, the set of answer options, and the contextual passages resulting from the search as input to a generative question-answer model. It further includes receiving a model-generated answer as output from the generative question-answer model. It further includes determining a measure of confidence associated with answering of the question by the generative question-answer model. It further includes selecting an answer option from the set of answer options based at least in part on the model-generated answer.","['G09B7/08', 'G06F16/90332']"
US11276176B2,Intelligent boundary delineation of regions of interest of an organism from multispectral video streams using perfusion models,"Embodiments for implementing intelligent boundary delineation of a region of interest of an organism in two spatial dimensions in a computing environment by a processor. Time series data of a contrast agent in one or more regions of interest captured from multispectral image streams may be collected. One or more regions of interest having one or more perfusion patterns may be identified from the time series data. Boundaries of the one or more regions of interest may be delineated into at least two spatial dimensions, wherein the boundaries of the one or more regions of interest include one or more selected labels.","['G06T7/0012', 'G06F18/217', 'G06F18/2431', 'G06K9/6262', 'G06K9/628', 'G06T7/12', 'G06T7/13', 'G06V10/143', 'G06V10/255', 'G06K2209/05', 'G06T2207/10016', 'G06T2207/20081', 'G06V2201/03', 'G06V2201/032']"
CN114372926A,Traditional Chinese medicine tongue tenderness identification method based on image restoration and convolutional neural network,"The invention discloses a traditional Chinese medicine tongue tenderness identification method based on image restoration and a convolutional neural network, which comprises the steps of obtaining an original tongue image, and performing tongue segmentation on the tongue image by adopting a tongue semantic segmentation model to obtain a tongue segmentation image; performing tongue coating and tongue texture separation on the tongue body segmentation image by adopting a Gaussian mixture model; obtaining a tongue image; establishing a tongue image restoration model based on the generated image restoration network, and restoring the tongue image by using the tongue image restoration model to obtain a tongue restoration image with continuous texture characteristics and color changes; adopting an improved residual error network to carry out feature extraction and classification on a data set of the repaired tongue quality image, and establishing a tongue quality old and tender identification model; and identifying the old and tender tongue by using the old and tender tongue identification model. The method can avoid the influence of the tongue coating on the identification of the old and tender tongue quality, and the characteristics obtained by self-learning can reflect richer tongue quality color and texture characteristics, so that a better identification effect of the old and tender tongue quality is obtained.","['G06T5/77', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G06T2207/10024', 'G06T2207/20081', 'Y02P90/30']"
CN117593611B,"Model training method, image reconstruction method, device, equipment and storage medium","The application provides a model training method, an image reconstruction method, a device, equipment and a storage medium, wherein the model training method comprises the following steps: determining a first training data set comprising a plurality of image pairs, each of the image pairs comprising a first low-definition image and a first high-definition image; obtaining a low-definition feature vector of the first low-definition image and a first high-definition feature vector of the first high-definition image by using a feature extractor; inputting the low-definition feature vector and the first high-definition feature vector into a feature generation network for processing to obtain a reconstructed high-definition feature vector and prediction noise; inputting the first low-definition image and the reconstructed high-definition feature vector into an image reconstructor for processing to obtain a first reconstructed image; updating at least the reverse module in the feature generation network based on a first loss function between the first reconstructed image and the first high definition image and a second loss function between the prediction noise and random noise added by the forward module.","['G06V10/774', 'G06N3/045', 'G06N3/084', 'G06V10/30', 'G06V10/40', 'G06V10/82']"
US11631208B1,Systems and methods for generating clinically relevant images that preserve physical attributes of humans while protecting personal identity,"A computer implemented method of generating at least one anonymous image, comprises: extracting and preserving at least one real facial region from at least one real image of a real human face, and generating at least one anonymous image comprising a synthetic human face and the preserved at least one real facial region, wherein an identity of the real human face is non-determinable from the at least one anonymous image.","['G06T11/60', 'G06T11/00', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06V10/48', 'G06V10/82', 'G06V40/168', 'G06V40/171', 'G06V40/174']"
CN117291895A,"Image detection method, device, equipment and storage medium","The application discloses an image detection method, an image detection device, image detection equipment and a storage medium, and belongs to the technical field of artificial intelligence. The method comprises the following steps: acquiring a first image to be detected; acquiring spatial domain information of a first image and acquiring frequency domain information of the first image; the spatial domain information refers to pixel information in a spatial domain of the first image, and the frequency domain information refers to frequency spectrum information in a frequency domain of the first image; obtaining an authenticity detection result of the first image according to the spatial domain information and the frequency domain information through the image detection model; the image detection model is a deep neural network model for detecting authenticity of the image. According to the method, the model can extract more comprehensive features of the image from spatial domain information and frequency domain information of the image to detect authenticity of the image, the problem that generalization is poor due to training of the model based on only a single input feature of the image is solved, and the technical effects of improving generalization of the image detection model and accuracy of image detection results are achieved.","['G06T7/0002', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T7/90', 'G06V10/765', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
CN117995381A,Gastric cancer classification method and gastric cancer classification system based on multiple sets of mathematical data fusion,"The invention discloses a gastric cancer classification method and a gastric cancer classification system based on multi-group data fusion, which relate to the technical field of bioinformatics, and the gastric cancer classification method based on multi-group data fusion comprises the following steps: collecting a histopathological data set, a gene expression data set and a miRNA data set of a gastric cancer patient, and calculating the association difference between the data sets; fusing the histopathology data set, the gene expression data set and the miRNA data set to form a biological fusion data set, and detecting abnormal data of the biological fusion data set; constructing a migration classification model of unbalanced sampling by combining biological fusion data sets with the correlation difference among the data sets; and classifying the gastric cancer development stage of the gastric cancer patient by utilizing a migration classification model in combination with the historical clinical cases of the gastric cancer patient. The invention can more accurately know the diffusion range of the tumor and provide more beneficial information for the evaluation of the infiltration depth characteristics.","['G16H50/20', 'G06F18/2113', 'G06F18/23213', 'G06F18/241', 'G06F18/253', 'G06T7/0012', 'G16B25/10', 'G16B40/20', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30092']"
CN116978450A,"Protein data processing method, device, electronic equipment and storage medium","The application provides a method and a device for processing protein data, electronic equipment and a storage medium; the method comprises the following steps: acquiring first map data of a first protein and second map data of a second protein; respectively extracting features of the first image data and the second image data to obtain a first structural feature of the first protein and a second structural feature of the second protein; predicting an initialized protein complex formed by the combination of the first protein and the second protein based on the first structural feature and the second structural feature; performing iterative disturbance on third graph data of the second protein in the initialized protein complex to obtain fourth graph data; and adjusting the position of the second protein in the initialized protein complex based on the fourth graph data to obtain a protein docking result. According to the application, the accuracy of the protein docking result can be improved.","['G16B15/30', 'G06N3/0464', 'G06N3/08', 'G16B15/00', 'G16B40/00', 'G16B50/10', 'G16B50/30']"
CN117072253B,"Thermal barrier coating and design, manufacturing and evaluation methods of high-temperature blades of heavy-duty gas turbines","The invention discloses a thermal barrier coating of a high-temperature blade of a heavy-duty gas turbine and a design, manufacturing and evaluation method thereof, wherein a ceramic layer of the thermal barrier coating has both surface longitudinal cracks and gradient pores; the surface longitudinal crack meets the optimal longitudinal crack density range, and can play a role in relieving thermal mismatch strain of the thermal barrier coating and increasing spalling resistance of the coating; the gradient pore meets the optimal porosity range, and the gradient pore can play roles of heat insulation and sintering resistance. The design method of the thermal barrier coating comprises a design method of an optimal crack density range and an optimal porosity range, and a method of reversely designing required spraying parameters according to the optimal crack density range and the optimal porosity range; the manufacturing method of the thermal barrier coating is a process flow for preparing the thermal barrier coating containing surface longitudinal cracks and gradient pores on the whole high-temperature blade; the evaluation method of the thermal barrier coating is a method for testing the spalling resistance and a method for determining the failure evaluation standard of the thermal barrier coating.","['F01D5/288', 'C23C4/073', 'C23C4/11', 'C23C4/134', 'C23C4/18', 'F01D5/284', 'G06F30/23', 'G06F30/27', 'G06F30/28', 'G06N3/0464', 'G06N3/08', 'G16C20/10', 'G16C60/00', 'G06F2113/08', 'G06F2119/08', 'G06F2119/14']"
CN118115622B,"Image generation model processing method, device, equipment, storage medium and product","The embodiment of the application provides a processing method, a device, equipment, a storage medium and a product of an image generation model, wherein the method comprises the following steps: acquiring training images containing a plurality of objects and training texts corresponding to the training images; extracting image features and mask images of all objects from the training images, and extracting text features of all objects from training texts; generating an attention image of each object according to the image features and the text features of each object; and training the reference image generation model according to the training image, the training text, the attention image of each object and the loss data of the mask image of each object to obtain the target image generation model. According to the technical scheme, the attention images of the objects can be generated in the training process of the model, lost data are constructed with the mask images of the objects, the training of the model to correspond entity words in the text to the objects in the images is facilitated, and the accuracy of generating the images containing the objects by the model is improved.","['G06T11/00', 'G06F18/214', 'G06F40/284', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06V10/40', 'G06V10/774', 'Y02T10/40']"
CN102853293A,led light bulb,"The present invention provides an LED bulb capable of appropriately illuminating a wider area, wherein the LED bulb (101) comprises a light emitting part (200), a base (300), a power supply part (500), a heat radiating member (400), a lamp cap (550) and a globe (600), wherein the globe (600) bulges out to the X direction X1 side, surrounds the light emitting part (200), and diffuses and transmits light from the light emitting part (200), wherein, when a central axis extending along the X direction is 0 DEG, an area where the light quantity from the light emitting part (200) is 50% or more of the maximum light quantity is within +/-60 DEG, and when the central axis is 0 â, the light quantity from the globe (600) is 50% or more of the area where the light quantity is +/-125 DEG or more.","['F21V3/02', 'H05B47/10', 'F21K9/232', 'F21K9/238', 'F21V19/04', 'F21V23/00', 'F21V23/006', 'F21V29/70', 'F21V31/00', 'F21V5/00', 'H05B45/37', 'H10H20/851', 'F21V19/0055', 'F21V29/75', 'F21V29/773', 'F21Y2105/10', 'F21Y2105/16', 'F21Y2115/10', 'H01L2224/48091', 'H01L2224/48247']"
US20230386032A1,Lesion Detection and Segmentation,"Mechanisms are provided for detecting lesions in diffusion weighted imaging (DWI) images. The mechanisms receive a first set of DWI images corresponding to a anatomical structure, from medical imaging computer system(s). The first set of DWI images comprises a plurality of DWI images having at least two different b-values. The mechanisms generate a second set of DWI images from the first set of DWI images based on at least one predetermined criterion. The second set of DWI images comprises different DWI images having different b-values. The mechanisms extract feature data from the second set of DWI images, input the feature data into at least one computer neural network, and generate an output from the neural network(s) comprising at least one of a lesion classification or a lesion mask based on results of processing, by the neural network(s), of the feature data extracted from the second set of DWI images.","['G06T7/0014', 'G06T7/0012', 'G06T7/11', 'G06T9/002', 'G06V10/44', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
CN119647604B,"Training reasoning method of decision model, product, electronic equipment and medium","The invention discloses a training reasoning method of a decision model, a product, electronic equipment and a medium, and relates to the technical field of artificial intelligence. In the method, when the training reasoning process of the decision model is divided into a plurality of calculation tasks to be distributed on different cluster nodes, the load pressure on the nodes is reduced, a plurality of data subsets obtained after the input data corresponding to the calculation tasks are split are distributed on different calculation nodes, the load pressure on the calculation nodes is reduced, the utilization rate of node resources is improved, parallel processing of the data subsets corresponding to the input data is realized, and the training reasoning efficiency is improved. When the training reasoning process of the decision model is divided into one calculation task, a plurality of data subsets obtained by splitting input data corresponding to the calculation task are distributed to different calculation nodes, so that load balancing on the calculation nodes is ensured, reasonable load distribution for the nodes in the cluster is realized, and the utilization rate of node resources is improved.",[]
US11386818B2,Drone apparatus used in healthcare applications,"A rechargeable drone apparatus or arrangement is provided. The rechargeable drone device includes a series of sensors configured to receive information about a user and transmit the information to a computing system configured to assess the information collected from the drone device and a set of securable compartments configured to maintain samples or medications, wherein the series of securable compartments are configured to be openable by an approved individual.","['B60L53/60', 'B64B1/58', 'B64C39/024', 'B64U10/13', 'B64U20/60', 'B64U50/31', 'B64U80/25', 'G05D1/104', 'G09F21/12', 'B60L2200/10', 'B64C2201/027', 'B64C2201/042', 'B64C2201/101', 'B64C2201/108', 'B64C2201/12', 'B64C2201/128', 'B64C2201/143', 'B64U10/30', 'B64U2101/30', 'B64U2101/55', 'B64U2201/102', 'B64U80/80', 'Y02T10/7072', 'Y02T90/12', 'Y02T90/14', 'Y02T90/16']"
US20240161377A1,Physics-based simulation of human characters in motion,"In various examples, systems and methods are disclosed relating to generating a simulated environment and update a machine learning model to move each of a plurality of human characters having a plurality of body shapes, to follow a corresponding trajectory within the simulated environment as conditioned on a respective body shape. The simulated human characters can have diverse characteristics (such as gender, body proportions, body shape, and so on) as observed in real-life crowds. A machine learning model can determine an action for a human character in a simulated environment, based at least on a humanoid state, a body shape, and task-related features. The task-related features can include an environmental feature and a trajectory.","['G06N3/045', 'G06N3/006', 'G06N3/044', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N7/01', 'G06T13/40']"
CN118503430A,Network information intelligent analysis regulation and control system and method based on artificial intelligence,"The application discloses a network information intelligent analysis and regulation system and method based on artificial intelligence, wherein the system comprises the following steps: the data acquisition module is used for acquiring video release information and comment information in the target software; the data analysis module is used for analyzing hot spot comment information in comment information corresponding to the video posting information and determining hot spot commentators and hot spot comment contents in the hot spot comment information; the data isolation module is used for placing hot spot comment information or follow-up hot spot comments of a hot spot commenter in the first isolation area or the second isolation area; the virtual data sending module is used for sending virtual inquiry data to the target account corresponding to the isolated hot spot comment so as to acquire virtual data feedback information of the target account; the virtual data feedback information acquisition and analysis module is used for collecting virtual data feedback information of the target account and carrying out security analysis on the virtual data feedback information so as to determine the state of the isolated data in the first isolation area or the second isolation area.","['G06F16/353', 'G06F16/3329', 'G06F16/337', 'G06F40/216', 'G06Q50/01']"
WO2024113135A1,"Multi-modal brain network computation method and apparatus associated with structural function, device, and medium","Provided are a multi-modal brain network computation method and apparatus (20) associated with a structural function, a device (30), and a medium, which are applied to training a brain disease prediction model. The model comprises an association perception dual-channel generation module, a disease feature regression module, a topological structure discriminator, and a time-space joint discriminator. In a model training process, by means of performing multi-level interactive fusion learning on high-order topological features of brain function magnetic resonance data and magnetic resonance diffusion tensor imaging data to obtain a multi-modal time sequence activity signal of each brain region, in combination with overall directional causal inference based on a structural equation of a brain region activity, a directional causal relationship between various brain regions is described to achieve multi-modal effective connection computation, such that the trained model can carry out, by means of a multi-modal effective connection, intelligent auxiliary pathological analysis and focus tracing on a patient suffering from a neurodegenerative disease.",['A61B5/055']
US10246721B2,Sugar transporters,"A novel class of transporter protein, referred to as SWEET, GLUE or GlÃ¼, is disclosed. These transporters provide a novel system for the transportation of sugars across membranes within a cell and between the inside and outside of a cell. Such transporters are useful for understanding and altering the sugar concentration within certain organs of an organism, and within certain organelles within the cell. These transporters are also useful in protecting plants from a pathogen attack.","['C12N15/8279', 'A61P31/00', 'A61P37/00', 'A61P7/00', 'C07K14/415', 'C07K14/43545', 'C07K14/47', 'C12N15/8218', 'C12N15/8245', 'C12N15/8246']"
US20240193887A1,Neural vector fields for 3d shape generation,"Synthesis of high-quality 3D shapes with smooth surfaces has various creative and practical use cases, such as 3D content creation and CAD modeling. A vector field decoder neural network is trained to predict a generative vector field (GVF) representation of a 3D shape from a latent representation (latent code or feature volume) of the 3D shape. The GVF representation is agnostic to surface orientation, all dimensions of the vector field vary smoothly, the GVF can represent both watertight and non-watertight 3D shapes, and there is a one-to-one mapping between a predicted 3D shape and the ground truth 3D shape (i.e., the mapping is bijective). The vector field decoder can synthesize 3D shapes in multiple categories and can also synthesize 3D shapes for objects that were not included in the training dataset. In other words, the vector field decoder is also capable of zero-shot generation.","['G06T17/00', 'G06T19/20', 'G06F30/10', 'G06T2210/56', 'G06T2219/2021']"
US20240176993A1,Scalable Self-Supervised Graph Clustering,"A method of training a machine learning model includes receiving training data comprising a graph structure and one or more feature attributes and determining an encoded graph based on applying the machine learning model to the graph structure and the one or more feature attributes. The machine learning model comprises a graph convolutional network layer. The encoded graph comprises one or more nodes and one or more paths connecting the one or more nodes. The method also includes selecting a plurality of positive samples through random walks along the one or more paths of the encoded graph, selecting a plurality of negative samples from the encoded graph by randomly sampling the one or more nodes of the encoded graph, determining a loss value, and updating, based on the loss value, one or more learnable parameter values of the machine learning model.","['G06N3/0895', 'G06N3/045', 'G06N3/0464', 'G06N3/084']"
US20240412869A1,Systems and Methods for Training and/or Using Representation Learning Neural Networks for Electromyographic Data,"Systems and methods that use data augmentation during the training of representation learning networks on neuromuscular data (e.g., EMG) with reconstruction cost. The method may include training network(s) on neuromuscular data received from channel(s) of neuromuscular sensor(s). The training may include randomly generating a first augment and a different, second augment for each channel. The training may include augmenting the data of each channel by applying the first and second augments to the data to generate first and second augmented data. The training may include processing at least the first augmented data through at least a first representation learning neural network to determine a first latent representation of one or more neuromuscular activation state variables. The training may include determining a reconstruction cost using the first latent representation and the second augmented data. The training may include updating the first representation learning neural network based on the reconstruction cost.","['A61B5/7267', 'G16H50/20', 'A61B5/397', 'G06F3/015']"
CN118366160A,Multimodal medical imaging rectal tumor staging automatic 3D fine annotation system,"The invention discloses an automatic 3D fine labeling system for multi-mode medical image rectal tumor stage, which comprises an image preprocessing module, an image 3D feature extraction module, a fine 3D labeling training data set, a labeling model and a model self-correction module, wherein a large model is extracted by constructing and training 3D features based on non-labeling multi-mode medical image data, 3D features of medical image media of different modes are excavated and extracted, 3D fine labeling models of rectal tumor stage guided by design knowledge are used for segmenting and detecting rectal and lymph node focus, a 3D position structure of rectal tumor and pathological lymph is primarily sketched, a T stage diagnosis conclusion and an N stage diagnosis conclusion are provided, and finally 3D labeling models are subjected to self-correction by adopting a diffusion generation technology, and the 3D position structure of rectal tumor and pathological lymph is precisely sketched.","['G06V20/70', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G06V2201/03']"
CN118135114A,"Map generation method, apparatus, device, computer program product, and storage medium","The invention provides a method, a device, equipment, a computer program product and a storage medium for generating a map, which belong to the technical field of three-dimensional face modeling, wherein the method for generating the map comprises the following steps: extracting a texture map of the acquired image to be processed to obtain an initial target texture map; acquiring a target condition corresponding to the initial target texture map; and inputting the initial target texture mapping and the target condition into a target diffusion model to obtain a target texture mapping, wherein the target diffusion model processes mapping features corresponding to the initial target texture mapping based on the target condition to generate the target texture mapping. According to the embodiment of the invention, the problems that the types of texture mapping are fewer and the customization requirement of a user is difficult to meet in the prior art are solved.","['G06T17/00', 'G06N3/0464', 'G06N3/08', 'G06V10/54', 'G06V40/16']"
CN106649917A,Simulation method and apparatus for combustion characteristic generation value of power station boiler coal powder under variable oxygen content,"Embodiments of the invention disclose a simulation method and apparatus for a combustion characteristic generation value of power station boiler coal powder under variable oxygen content, and solve the technical problem that overall law characteristics of furnace internal combustion, flowing and heat transfer cannot be measured due to unpractical manufacturing of a test table of a full-size model caused by increasing size of a furnace chamber at present. The method comprises the steps of simulating a combustion process of boiler coal powder in a preset boiler combustor model after grid division under the condition of variable oxygen content through a basal conservation equation, a turbulent flow model, a turbulent gas-solid two-phase flow model, a gas-phase turbulent combustion model, a coal particle combustion model, a radiation heat exchange model and an NOX generation model; and determining coal powder burnout rate, fly ash carbon content, NOX emission, lower furnace chamber outlet temperature and average CO concentration distribution along furnace chamber height, of a boiler combustor according to a simulation result under the condition of variable oxygen content.","['G06F30/20', 'G06F2111/10']"
US20250284750A1,Search summary generation based on searcher characteristics,"Techniques are provided for presenting a summary with search results. One method includes operations for receiving a search query, performing a search based on the search query, and determining, by a machine learning (ML) model, a user intent based on input comprising the search query, user profile information, and activity information of the user. A prompt is generated based on the search query, the user intent, and relationships between the user and entities. The prompt generation comprises selecting a prompt template comprising fields for the user intent, the search query, and the relationships, and filling in the fields. The method further includes operations for feeding as input the prompt to a generative artificial intelligence (GAI) model, receiving a summary from the GAI model, and causing presentation of the summary and one or more results returned by the search on a user interface (UI) of the device of the user.","['G06F16/345', 'G06F16/9532', 'G06F16/9535', 'G06F16/9536', 'G06F16/9577']"
WO2017153187A1,"Generative layer construction method having improved detail resolution, and device for carrying out the same","The invention relates to a method for providing a control command set for a generative layer construction device, the method comprising the following steps: providing a first data set, in which points corresponding to an object cross section are marked; detecting, whether or not the length of a connection line between edges of an object cross section falls below a defined minimum dimension (m); generating a second data set, which differs from the first data set such that in the event the defined minimum dimension (m) is undercut, a point that is located within an object cross section on a connection line between edges thereof, the length thereof falls below the minimum dimension, is marked as a point not to be solidified, or marked as a point, to which a reduced amount of radiation energy is to be supplied, and/or for a point that is located outside an object cross section on a connection line between edges, the length of which falls below the minimum dimension (m), points of an object cross section adjacent to said point are marked directly above and/or below as points not to be solidified, or as points that are to be supplied with a reduced amount of radiation energy; integrating the second data set into the control command set.","['B29C64/153', 'B28B1/001', 'B28B17/0081', 'B29C64/165', 'B29C64/20', 'B29C64/386', 'B29C64/393', 'B33Y10/00', 'B33Y30/00', 'B33Y50/02', 'B22F10/28', 'B22F10/80', 'Y02P10/25']"
CN109872162A,A kind of air control classifying identification method and system handling customer complaint information,"This specification embodiment provides a kind of air control classifying identification method for handling customer complaint information, by the Classification and Identification for carrying out neural network to customer complaint information, the customer complaint information is divided into the air control type output, cooperate unsupervised learning sample, and then identifies new air control type.The cost of labor of air control case trial is greatly reduced as a result, realize automation Perceived Risk and is taken precautions against in advance, reduces various risks for adverse effect brought by total system.",[]
CN117316395A,Image-text interaction system combined with artificial intelligent model,"The invention relates to the technical field of artificial intelligence, in particular to a picture-text interaction system combined with an artificial intelligence model, which comprises a rapid imaging module, a high-speed imaging module and a control module, wherein the rapid imaging module is used for acquiring a low-magnetic-field magnetic resonance image and is also connected with an external magnetic resonance image database to acquire high-magnetic-field multi-source data; the first interaction module is used for receiving text content input from the outside and selecting answer content from a candidate answer set to generate response output; and the second interaction module is connected with the rapid imaging module and used for receiving the magnetic resonance image, identifying focus information of the magnetic resonance image and generating an identification report text. The invention can quickly improve the quality of the low-magnetic-field magnetic resonance image, improve the interaction accuracy, quickly identify the focus and generate a corresponding report.","['G16H30/40', 'G06F16/3329', 'G06N3/042', 'G06N3/0455', 'G06N3/0475', 'G06N5/041', 'G06T7/0012', 'G16H15/00', 'G16H30/20', 'G16H70/20', 'G06N3/044', 'G06N3/0464', 'G06T2207/10088', 'G06T2207/30016', 'Y02A90/30']"
CN110134756A,"Minutes generation method, electronic device and storage medium","The present invention relates to data processing technique, a kind of minutes generation method, electronic device and storage medium are provided.This method obtains the voice messaging of each spokesman in real time, and the voice messaging is converted into text information and is stored in database.Later, spokesman's identity information is identified according to the voice messaging and default recognition rule, to having identified that the spokesman of identity information is arranged different ID and numbers, establishes the mapping relations of the ID number and the text information.Default first algorithm is recycled to calculate the score of all words in the text information, the keyword of the text information is determined according to the score, minutes are generated using default second algorithm based on keyword and mapping relations, and the minutes are sent to pre-set user with mail he.Using the present invention, passes through and the voice of spokesman in meeting is converted into text and automatically generates minutes be sent to personnel participating in the meeting, improve the efficiency of meeting.","['G06F16/31', 'G06F40/284', 'G10L15/063', 'G10L15/12', 'G10L15/142', 'G10L15/16', 'G10L15/22', 'G10L15/26']"
CN114972062A,Image restoration model based on parallel self-adaptive guide network and method thereof,"The invention provides an image restoration model based on a parallel self-adaptive guide network and a method thereof, wherein the image restoration model comprises a feature extraction module, a mutual self-adaptive guide module, a multi-scale perception residual error module, a context joint attention module and a reconstruction module; the characteristic extraction module is used for extracting the characteristics of the damaged image; the mutual adaptive guide module comprises a plurality of guide filters; the multi-scale perception residual module comprises a multi-scale module, intra-layer residual connection and convolution attention groups; the contextual joint attention module includes a co-scale attention mechanism and a cross-scale attention mechanism. The structural features of the parallel branches and the complete features containing textures are guided mutually through jump connection and a guide filter, and prior knowledge is provided for the reconstruction process of the opposite side, so that the capability of the network for repairing the features is improved.","['G06T5/77', 'G06N3/045']"
CN118014894B,"Image restoration method, device, equipment and readable storage medium based on combination of edge priors and attention mechanisms","The application provides an image restoration method, device and equipment based on the combination of edge priori and attention mechanism and a readable storage medium, belonging to the technical field of image restoration. In the edge prediction stage, the model is an efficient transducer-based edge prediction (TEP) module, and compared with the previous method, the edge structure of the defect area can be better obtained, and the calculation cost is reduced. In the second stage, the present application proposes a multi-scale fusion attention (MFA) module that can extract valid features on a multi-scale feature level, and then fill layer by layer from deep semantics to shallow details to enhance local pixel continuity. The present application compares the proposed method qualitatively and quantitatively with other advanced methods on CelebA, facade and Places2 datasets corrupted using the NVIDIA mask dataset. Experimental results show that the method has good performance in repairing complex large holes.","['G06T7/13', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475']"
WO2025090243A1,Method and systems for dynamically featuring items within the storyline context of a digital graphic narrative,"A system and method are provided for generating a costume corresponding to graphic narrative (e.g., based, in part, on costumes depicted in images of a digital graphic narrative). Panels of the digital graphic narrative are segmented into elements (e.g., using semantic segmentation models like Fully Convolutional Networks), and clothing elements are identified as outfits/costumes worn by the characters. Based on multiple viewing angles provided by a plurality of images, data such as color and texture of the outfits/costumes is extracted and a digital costume model is created. The digital costume model can include animated and real-life components for rendering realistic and animated representations of the digital costume model. The digital costume model can be customized, shared on social media, used to help render a virtual environment, and used to fabricate a physical costume.","['G06T17/10', 'G06V10/40', 'G06T17/00', 'G06T19/006', 'G06T7/10', 'G06V10/82', 'G06T2210/16']"
CN101620740A,Interactive information generation method and interactive information generation system,"The invention relates to a method for generating interactive information in 3D scene rendering. During the 3D scene rendering, the method comprises the steps of: setting textures of all models in a 3D scene as a static interactive data texture diagram, and setting information merging mode parameters; and performing rendering operation on the 3D scene preset with the static interactive data texture diagram and the information merging mode parameters, and merging dynamic interactive information into a corresponding data unit in the static interactive data texture diagram to generate an interactive information mapping graph of the 3D scene. The invention also relates to a system for generating the interactive information in 3D scene rendering. The invention inserts a logic code used for generating human-computer interactive information data during the operation of a 3D scene rendering program based on a drawing engine, and generated interactive information is saved into a video memory and corresponds to screen coordinates of an original scene picture, thereby generating an additional interactive information mapping graph under the condition of not modifying an application program; and the graph provides basic data for an interactive information driving engine.",['G06T15/04']
CN104702826A,Image pickup apparatus and method of controlling same,"Provided are an image pickup apparatus and a method of controlling the same. The image pickup apparatus that makes it unnecessary to temporarily stop image pickup performed by an image pickup device to thereby improve operability of the image pickup apparatus, and achieves power saving. In an image pickup apparatus having an electronic viewfinder function, first image signals for live view are acquired by thinning read lines of an image pickup device, and second image signals for AF evaluation value calculation are acquired from the other read lines at a higher speed than the first image signals, for simultaneous output with the first image signals. Reading of the second image signals is started when the state of the object of image data changed or when one photographing mode is changed to another by a user's operation, and is terminated when a reading termination condition set in advance in association with the reading start condition is satisfied.","['H04N23/88', 'H04N23/611', 'H04N23/63', 'H04N23/672', 'H04N23/673', 'H04N25/42', 'H04N25/445', 'H04N25/707', 'H04N25/767', 'H04N25/78']"
US12266073B2,System and method for three dimensional creation of a virtual garment and simulating use of the virtual garment on an avatar of an end user,"A garment rendering system and associated method having a virtual garment generation unit, an avatar generation unit, a simulation engine, and a rendering unit. The virtual garment generation unit receives garment related data and generates in response to the garment related data virtual garment data. The garment related data includes garment image data and garment textual data. The avatar generation unit receives user data and generates, in response to the user data, user avatar data representative of an avatar of the user. The user data includes at least one of user image data and user biometric data. The simulation engine receives the user avatar and the virtual garment data and generates in response thereto simulated garment data representative of a simulated garment draped on the avatar. The rendering unit renders the simulated garment data received from the simulation engine and generates a rendered virtual image.","['G06T19/20', 'G06T19/00', 'G06T15/04', 'G06T17/20', 'G06T7/11', 'G06T7/60', 'G06T9/002', 'G06V10/26', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2210/16', 'G06T2219/2021']"
CN116643681A,"Method, apparatus, device and storage medium for interaction","According to embodiments of the present disclosure, methods, apparatuses, devices, and storage medium for interaction are provided. The method includes presenting an input control in a first user interface; presenting, in a first user interface, a pattern received via an input control, the pattern comprising one or more lines; acquiring a first image based on the pattern, the first image visually matching at least partially the pattern; presenting a first image; and presenting at least a portion of the second image captured in real-time with at least a portion of the first image in response to the preset condition being met. Thus, in the case where the user gives a simple pattern, a richer visual effect can be provided. This can enhance interactivity and interestingness in interaction, thereby improving the user's interaction experience.","['G06F3/0484', 'G06F9/451']"
CN115019891A,An individual driver gene prediction method based on semi-supervised graph neural network,"The invention relates to the technical field of gene data analysis, in particular to an individual driving gene prediction method based on a semi-supervised graph neural network, which comprises the following steps: 1) constructing an individualized gene interaction network (PGIN) by utilizing genome data of an individual patient; 2) attention to the network GAT by using a label reuse strategy training diagram, and identification of individualized driving genes are specifically as follows: a. obtaining an initial prediction tag by using an initial GAT model with the adjacency matrix, the initial node features and the node tags as inputs; b. applying a signature reuse strategy on GAT to predict cancer driver genes; c. the genes were voted and the gene scores were ranked to obtain a gene ranking for the individual patient. The present invention enables individual driver gene prediction to be preferably performed.","['G16B30/00', 'G16B20/50', 'G16B25/10', 'G16B40/00', 'Y02A90/10']"
CN101627298A,Method for determining characteristic properties of a sample containing particles,"The invention provides a method of determining a characteristic property of a sample containing particles of at least one species at a predetermined observation volumeA particle of a species that emits, scatters and/or refracts photons, the method comprising the steps of: 1) will be at the observation timeOf successive time intervals Î tiï¼[tiï¼1ï¼ti) (i 1, 2, 3..) the number n of photon events registeredi(count rate) registration and counting, 2) determining a distribution function P (n) of the number n of photon events within a predetermined time interval Î t, and 3) using a single particle distribution function P using the desired number n of photon events within the predetermined time interval Î t in an ideal experiment where each photon event originates from only a single particle, at the desired distribution function P (n), concentration c1(n) and effective capacity Veffï¼<m>C (wherein<m>Is the average number of particles contributing to each count rate) to determine P1(n)ãVeffConcentration c and/or other characteristic properties, wherein<m>Is the average number of particles contributing to each count rate, which can be determined by fitting these properties to the measured p .","['G01N21/6408', 'G01N2021/6417']"
CN106973246A,"Solid state image sensor and its control method, image sensing system and camera","The present invention provides a kind of solid state image sensor and its control method, image sensing system and camera.The solid state image sensor includesï¼Pixel, it is configured to picture element signal of the generation corresponding to incident lightï¼Amplifying circuit, it is configured to amplify the picture element signalï¼Circuit is set, and it is configured to the comparative result between the picture element signal that amplifies based on threshold value and by the amplifying circuit, to set the gain of the amplifying circuitï¼And correcting circuit, it is configured to by using the first corrected value and the second corrected value, to be corrected to the picture element signal for being exaggerated the gain set by the setting circuit.First corrected value is the value corresponding to gain error, and second corrected value is value corresponding with the amplifying circuit biasing in the gain.","['H04N25/70', 'H04N25/75']"
US20190138673A1,Growth-Based Design System,"A process for simulating cellular growth is implemented to determine geometry of an object within a simulated environment. Seed cells, which represent starting points for a cell body, are defined within the environment. A number of constraints and parameters, such as forces and target locations, are also imposed on the environment. The body of cells is then grown within the simulated environment, spawning and destroying cells as needed to meet the imposed constraints. A stable structure meeting the constraints can be exported and fabricated, such as by a three-dimensional printer, to produce a corresponding a real-world object.","['G06F17/5009', 'G06F30/20', 'G06T17/10', 'G06F2111/02', 'G06F2111/04', 'G06F2111/20', 'G06F2217/02', 'G06F2217/06']"
CN103733049B,"The light analytical equipment utilizing single incandescnet particle to detect, light analytical approach and light analysis computer program","To provide in the scanning numerator counts method of the light using the incandescnet particle in confocal microscope or multiphoton microscope test sample solution can with reduce the possibility that same incandescnet particle is detected as different particles as much as possible and make the size of photo detection area as much as possible, the mode of shape invariance makes photo detection area move the light analysis technology of the scanning carried out in sample solution along the path of wider region or longer distance.In light analysis technology of the present invention, make the generation along the detection carried out during the second path movement from the light of photo detection area and the temporally light intensity data of sequence in sample solution of the position of photo detection area, the light intensity data of temporally sequence is used to detect the signal represented from the light of each incandescnet particle be present in prescribed path one by one, wherein, the position in this second path is moved along the first path.","['G01N21/64', 'G01N15/14', 'G01N15/1429', 'G01N15/1434', 'G01N21/51', 'G01N21/6408', 'G01N21/645', 'G01N21/6452', 'G01N21/6458', 'G01N21/6486', 'G02B21/0032', 'G02B21/0076', 'G02B21/008', 'G01N2021/6419', 'G01N2021/6441', 'G01N2201/103', 'G01N2201/105']"
WO2021164904A1,Low coherence interferometry analysis of pharmaceutical compositions using machine learning,"A method of determining information indicative of a material attribute of a pharmaceutical composition (100), wherein the method comprises detecting detection data from the composition (100) by low coherence interferometry, and determining the information indicative of the material attribute based on the detection data and using machine learning.","['G01N21/8422', 'G01N21/9508', 'G06V20/66', 'G06V20/69']"
US20240305685A1,Dynamic transport protocol switching for collaborative content creation and distributed content experience systems and applications,"Approaches presented herein provide systems and methods for dynamic transport switching for messages transmitted within a compute environment. Messages generated by publishers may be evaluated within a client library against one or more rules to select a transmission protocol for the message. If a message has a parameter exceeding a threshold, a direct peer-to-peer transmission protocol may be selected to bypass transmission of the message to an intermediary. The client library may generate a smaller message for publication to one or more subscribers. The subscribers may then directly communicate with the client library in order to transmit the message.","['H04L67/104', 'H04L67/06']"
CN118447133A,"Image generation method, device, equipment, storage medium and program product","The application discloses an image generation method, an image generation device, image generation equipment, a storage medium and a program product, which can be applied to scenes such as image generation, artificial intelligence, cloud technology and the like. And if the secondary editing is needed, responding to the editing operation of the original image, and acquiring an editing description text. The method comprises the steps of obtaining first original features of an original description text and first editing features of an editing description text, obtaining first offset features of the original description text and second offset features of the editing description text, adding the first offset features to the first original features to obtain second original features, and adding the second offset features to the first editing features to obtain second editing features, so that to-be-edited content and non-edited content can be accurately distinguished based on the second original features and the second editing features. Therefore, when the image generation is carried out through the image generation model based on the second original feature and the second editing feature, the generation effect of the non-editing content can be kept unchanged, and the target image with higher rationality and fidelity can be generated.",['G06T11/60']
KR20240082184A,System for continuous integration and continuous deploy of service model using deep learning framwork and method thereof,"The present invention relates to a continuous integration and distribution system of a deep learning framework application service model and a method thereof. The system comprises: a plurality of edge servers providing a deep learning inference service; a deep learning distributed training cloud including a plurality of distributed servers, each having a deep learning database server based on a deep learning framework application query, and a main server managing the plurality of distributed servers, and performing distributed training on a learning model; a software configuration management (SCM) storage automatically processing revision, version management, backup, and rollback processes of a service model table, which is results of a service model which is the distributed trained learning model; and a controller distributing the service model table to be executed to the edge server according to a preset distribution policy when there is a change in the service model table in the SCM storage.","['G06N3/10', 'G06F8/60', 'G06F8/71', 'G06F9/44526', 'G06N3/098']"
US11222437B2,Methods and systems for in-bed pose estimation,"Non-contact methods and systems are disclosed for estimating an in-bed human pose. The method includes the steps of: (a) capturing thermal imaging data of a human subject lying on a bed using a long wavelength infrared camera positioned above the human subject; (b) transmitting the thermal imaging data to a computer system; and (c) processing the thermal imaging data by the computer system using a model to estimate the pose of the human subject, the model comprising a machine learning inference model trained on a training dataset of a plurality of in-bed human poses.","['G06T7/70', 'G06T7/20', 'G06V40/103', 'H04N23/23', 'G06T2207/10024', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/30196', 'H04N23/90', 'H04N5/247']"
US20240193827A1,Determining a confidence indication for deep learning image reconstruction in computed tomography,"There is provided a method and system for determining one or more confidence indications for machine learning image reconstruction in Computed Tomography, CT. The method comprises acquiring (S1) energy-resolved x-ray data, and processing (S2) the energy-resolved x-ray data based on at least one machine learning system to generate a representation of a posterior probability distribution of at least one reconstructed basis image or image feature thereof. The method further comprises generating (S3) one or more confidence indications for: the at least one reconstructed basis image, or at least one derivative image originating from the at least one reconstructed basis image, or image feature of the at least one reconstructed basis image or the at least one derivative image, based on the representation of a posterior probability distribution.","['G06T11/006', 'A61B6/032', 'A61B6/482', 'A61B6/5211', 'G01N23/046', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06T11/005', 'G06T11/008', 'G01N2223/401', 'G01N2223/419', 'G01N2223/423', 'G06T2211/408', 'G06T2211/441']"
CN110191699A,Hydrogen supplying material and its manufacturing method and method of supplying hydrogen,"A kind of stratiform solid agent as hydrogen supplying material of the invention, has: silicon fine particle or its aggregation with hydrogen generative capacityï¼And the physiologically acceptable medium contacted with the silicon fine particle or its aggregation.In addition, this hydrogen supplying material is the hydrogen supplying material for making above-mentioned hydrogen contact skin and/or mucous membrane by medium.","['A61K8/25', 'A61K33/00', 'A61K33/10', 'A61K8/0241', 'A61K8/19', 'A61P43/00', 'A61Q19/00', 'A61Q19/08', 'A61Q19/10', 'A61Q7/00', 'C01B3/08', 'C01B33/02', 'C02F1/68', 'C11D7/02', 'C11D7/06', 'A61K2800/413', 'Y02E60/36']"
WO2019025270A9,Non-invasive assessment and therapy guidance for coronary artery disease in diffuse and tandem lesions,"A method and system for non-invasive assessment and therapy planning for coronary artery disease from medical image data of a patient is disclosed. Geometric features representing at least a portion of a coronary artery tree of the patient are extracted from medical image data. Lesions are detected in coronary artery tree of the patient and a hemodynamic quantity of interest is computed at a plurality of points along the coronary artery tree including multiple points within the lesions based on the extracted geometric features using a machine learning model, resulting in an estimated pullback curve for the hemodynamic quantity of interest. Post-treatment values for the hemodynamic quantity of interest are predicted at the plurality of points along the coronary artery tree including the multiple points within the lesions for each of one or more candidate treatment options for the patient, resulting in a respective predicted post-treatment pullback curve for the hemodynamic quantity of interest for each of the one or more candidate treatment options. A visualization of a treatment prediction for at least one of the candidate treatment options is displayed.","['A61B34/10', 'A61B6/5217', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'Y02A90/10']"
US12405959B2,Methods and systems for arranging and displaying guided recommendations via a graphical user interface based on biological extraction,"A system for arranging and displaying guided recommendations using a graphical user interface based on biological extraction, the system comprising a computing device configured to receive, from a wearable device located at a user, biological extraction data and at least a datum of user activity data, classify the biological extraction and the at least a datum of user activity as a function of at least a datum of a user fingerprint, select at least a compatible element as a function of the training data and the user fingerprint, wherein the compatible element comprises a guided recommendation, and generate a representation using a graphical user interface of the compatible element.","['G06F16/24575', 'G06F16/24578', 'G06F16/248', 'G06F16/285', 'G06F9/451', 'G06N20/00', 'G06N5/04']"
US20230222262A1,Systems and methods for mechanical distortion compensation,The present invention is directed to systems and methods for automatically generating mechanical part designs and manufacturing specifications/instructions that account for geometric distortions that may occur during manufacturing or post-processing.,"['G06F30/20', 'G06F30/17', 'G06F30/23', 'G06F30/27', 'G06T17/20', 'G06F2113/10', 'G06F2113/22', 'G06F2119/18', 'Y02P90/02']"
US20230081232A1,Systems and methods for machine learning features in biological samples,"Systems and methods for machine learning tissue classification are provided herein. Datasets for a plurality of biological samples are first generated. The dataset of each biological sample includes image data of the biological sample and molecular measurement data of the biological sample captured at a plurality of capture areas of the biological sample. The capture areas of the biological sample are registered to corresponding locations in the image data of the biological sample. Then, a machine learning module is trained with the datasets. Another dataset for another biological sample is generated (e.g., in the same or similar manner as the other datasets). And, the other dataset of the other biological sample is processed through the trained machine learning module to predict features in the other biological sample.","['G06V20/69', 'G06F18/2413', 'G06V10/25', 'G06V10/774', 'G06V10/776', 'G06V20/695', 'G16H50/30']"
CN110321925A,A kind of more granularity similarity comparison methods of text based on semantics fusion fingerprint,"The invention discloses a kind of more granularity similarity comparison methods of text based on semantics fusion fingerprint, comprising the following steps: the training that term vector indicatesï¼Semantic feature extractionï¼Multiple features polymerizationï¼Level index constructï¼Similarity calculation.The present invention combines multi-dimensional semantic correlation and carries out term vector expression modeling, sufficiently excavate the semantic information between word, feature is extracted as unit of sentence, semantic feature is characterized using more weights, and text library statistics and distributed intelligence are excavated using statistical learning method, it realizes to the finer division of feature space, then generates the compact text fingerprints of high identification based on multiple features polymerization, effectively improve the descriptive power and discrimination of text fingerprintsï¼Using top-down thought, text similarity comparison is carried out using semantics fusion fingerprint fingerprint and local semantic feature, by building level index, can quickly and efficiently realize that text is compared from the overall situation to more granularity similarities of partï¼This method is with good expansibility.","['G06F16/35', 'G06F16/36', 'G06F18/22', 'G06F18/23213']"
US20240309320A1,Methods for differentiating and screening stem cells,The subject matter disclosed herein is generally directed to methods of differentiating pluripotent cells into target cell types and screening platforms for systematically identifying transcription factors (TFs) that drive differentiation of pluripotent cells into target cell types. Also disclosed is a high-throughput multiplex screening platform. Also disclosed are in vitro models for neural progenitor cells and cardiomyocytes.,"['A61K35/30', 'C12N5/0619', 'C12Q1/6809', 'C12Q1/6881', 'C12N2501/65', 'C12N2510/00', 'C12Q2600/158']"
CN118115706A,"Three-dimensional image generation method, three-dimensional character image generation method, and computing device","Embodiments of the present specification provide a three-dimensional image generation method, a three-dimensional character image generation method, and a computing device, wherein the three-dimensional image generation method includes: acquiring two-dimensional attitude images under a plurality of preset view angles, wherein the two-dimensional attitude images are obtained by projecting key point information of a reference object to a two-dimensional plane based on view angle parameters of the preset view angles; generating a two-dimensional object image under a plurality of target view angles based on the two-dimensional gesture images under a plurality of preset view angles by using a first generation network, wherein the target view angles cover the target object; and mapping the two-dimensional object images under the multiple target visual angles to a three-dimensional space, and generating a target three-dimensional image of the target object. The method gets rid of the dependence of training the three-dimensional image generation network by using sample data in advance, solves the problems of insufficient generalization capability, overfitting and the like of the three-dimensional image generation network caused by data scarcity, and improves the flexibility and generalization of the three-dimensional image generation.","['G06T19/20', 'G06T15/04', 'G06T17/10', 'G06T2219/2008']"
US20240296523A1,Method for semantic image synthesis using condition diffusion and apparatus for same,"A semantic image generation method using condition image diffusion according to an embodiment of the present invention includes the steps of: (a) training an image generation model by inputting N-th learning data (N is a random positive integer); (b) inputting input data for generating semantic images into the trained image generation model; and (c) outputting one or more semantic images generated by the image generation model according to the input data, wherein the input data includes a condition image frame (Layout), which is input condition data, and the condition image frame is an image frame, through which classes, which are one or more objects included in a semantic image to be generated, are classified into each category by the object, and a different number is assigned to pixel areas occupied by the classes for each classified category.","['G06T5/60', 'G06V10/82', 'G06T11/60', 'G06N3/08', 'G06T5/73', 'G06T7/11', 'G06V10/774', 'G06T2207/20081', 'G06T2207/20084']"
CN113970532A,Fabric fiber component detection system and prediction method based on near infrared spectrum,"The invention provides a fabric fiber component detection system and a prediction method based on near infrared spectrum, wherein the system collects the waveform of the reflectivity and the absorptivity of the near infrared spectrum of a fabric, performs noise reduction through a filtering method of median filtering, mean filtering, wiener filtering and S-V filtering, enhances data through a generative countermeasure network, a difference value, a sampling algorithm and the like, increases the feature extraction capability by using a convolutional neural network in deep learning, performs model training by using smooth and derivative data through a deep regressor model aiming at the characteristics of the fabric near infrared spectrum data, learns and distinguishes the fabric near infrared spectrum characteristics, realizes the lossless cleaning analysis of the fabric fiber components, and obtains the fiber component type of a target fabric and the mixing proportion of all component materials in the mixed material.","['G01N21/359', 'G01N21/55', 'G01N2201/1296', 'Y02P90/30']"
US20240180672A1,Smart orthodontic appliances with hierarchical structures and materials,"This application is directed to orthodontic devices, systems, and methods for repositioning teeth. An orthodontic device includes an integral piece of orthodontic appliance, and the orthodontic appliance defines a target tooth arrangement and having at least a reinforcement portion and a shell portion. The orthodontic appliance is configured to hug a plurality of teeth and resiliently reposition the plurality of teeth from a current tooth arrangement to the target tooth arrangement gradually within an extended duration of time. The reinforcement portion has a first stiffness level extended from the reinforcement portion and has a second stiffness level, the second stiffness level lower than the first stiffness level.","['A61C7/08', 'A61C7/10', 'A61C7/12']"
CN106469546A,"Semiconductor device, display floater and electronic equipment","The present invention relates to semiconductor device, display floater and electronic equipment, one of purpose of a mode of the present invention is to provide a kind of novel semiconductor device of structure and suppress to result from the deviation of the grayscale voltage of offset voltage.When generating the electric current corresponding to the grayscale voltage of low level in trsanscondutance amplifier, according to the digital signal of the highest significant position in low level, the voltage (V that trsanscondutance amplifier is provided is inputted with replacing switching to two input terminalsHIãVLO).Both maximum to the electric current exporting from trsanscondutance amplifier and minima add the variable quantity corresponding to offset voltage it is possible to suppress to result from the deviation of the grayscale voltage of offset voltage.","['G09G3/20', 'G09G3/3648', 'G09G3/3283', 'G09G3/3275', 'G09G3/3688', 'H03M1/66', 'H10K19/00', 'G09G2300/0426', 'G09G2300/0828', 'G09G2310/027', 'G09G2310/0291', 'G09G2330/028']"
CN102036684A,RGD- (bacterio) chlorophyll conjugates for photodynamic therapy and imaging of necrotic tumors,"The present invention provides RGD-chlorophyll and RGD-bacteriochlorophyll conjugates that home and accumulate much longer in necrotic tumor areas compared to non-necrotic tumor areas, for use in minimally invasive tumor-targeted imaging, tumor-targeted photodynamic therapy and/or online prognosis of necrotic tumors.","['A61K51/0485', 'A61K41/0071', 'A61K49/0036', 'A61K49/0056', 'A61K49/085', 'A61K49/14', 'A61K51/082', 'A61K51/088', 'A61P35/00', 'A61P35/04', 'A61P43/00', 'A61K41/0057', 'A61K51/044', 'A61K51/0446', 'A61K51/0451', 'C07D257/04']"
US20240420443A1,Method and apparatus with quantized image generation,A system includes: an image sensor configured to acquire an image; an image processor configured to generate a quantized image based on the acquired image using a trained quantization filter; and an output interface configured to output the quantized image.,"['H04N1/405', 'G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T3/4046', 'G06V10/28', 'G06V20/10', 'H04N1/40087']"
US20240249395A1,Systems and methods for contrast dose reduction,"A deep learning-based algorithm has been proposed for contrast dose reduction in MRI, using multi-contrast images and an anomaly-aware attention mechanism. The method comprises: obtaining a multi-contrast image of a subject, where the multi-contrast image comprises an image of a first contrast acquired with a reduced dose of contrast agent; generating an anomaly mask using a first deep learning network; and taking the multi-contrast image and the anomaly mask as input to a second deep network model to generate a predicted image with improved quality.","['G01R33/5608', 'A61B5/055', 'A61B5/7267', 'G01R33/50', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06T5/60', 'G06T7/0002', 'G06T7/0012', 'G01R33/4835', 'G01R33/5602', 'G01R33/56341', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096']"
US12380640B2,3D generation of diverse categories and scenes,"A three-dimensional (3D) scene is generated from non-aligned generic camera priors by producing a tri-plane representation for an input scene received in random latent code, obtaining a camera posterior including posterior parameters representing color and density data from the random latent code and from generic camera priors without alignment assumptions, and volumetrically rendering an image of the input scene from the color and density data to provide a scene having pixel colors and depth values from an arbitrary camera viewpoint. A depth adaptor processes depth values to generate an adapted depth map that bridges domains of rendered and estimated depth maps for the image of the input scene. The adapted depth map, color data, and scene geometry information from an external dataset are provided to a discriminator for selection of a 3D representation of the input scene.","['G06T17/00', 'G06T15/08', 'G06T15/20', 'G06T7/50', 'G06T7/90', 'G06V10/82', 'G06T2207/10024']"
US20250285243A1,"Image processing method, electronic device and storage medium","Provided are an image processing method, an electronic device and a storage medium. In the method, a to-be-inpainted image is obtained based on an original image, where an image size of the to-be-inpainted image is a target image size to which the original image is desired to be adjusted, the to-be-inpainted image includes a first image area corresponding to the original image and a second image area other than the first image area, and the second image area is an area for which image inpainting is to be performed. The second image area in the to-be-inpainted image is inpainted with a pre-trained image inpainting model, and an intermediate image is obtained. The second image area in the intermediate image is inpainted with a pre-trained large language model, and a first target image is obtained.","['G06T5/77', 'G06T3/40', 'G06T2207/20081', 'G06T2207/20132', 'G06T2207/30168']"
DE102007049058A1,Material system and method for modifying properties of a plastic component,"The instant invention relates to a method for changing characteristics of a plastic component, wherein a medium is introduced into the plastic component, which encompasses a porosity and wherein the medium forms a homogenous compound with the plastic component by at least partially dissolving the plastic component.","['C08J9/405', 'B05C3/005', 'B05C3/02', 'B05C5/0283', 'B29C71/0009', 'B33Y10/00', 'B33Y70/00', 'C08J7/02', 'C08J7/18', 'B33Y80/00', 'C08J2351/00']"
CN119046840B,Small sample distribution network anomaly detection method and device based on graph contrast learning,"The invention discloses a small sample power distribution network anomaly detection method and device based on graph comparison learning, and relates to the technical field of intelligent detection of power grid data. Constructing a complete power distribution network abnormal pattern according to given feeder line pattern data and equipment measurement data, taking any transformer as a central node to form a sub-graph, carrying out heterogeneous pattern data enhancement on the sub-graph through a data enhancement strategy to generate a plurality of positive example samples, randomly selecting a plurality of negative examples from the power distribution network abnormal pattern, respectively learning graph embedding of an original sample, the positive example sample and the negative example sample through a graph convolution neural network, evaluating consistency of each heterogeneous graph example pair by utilizing a contrast learning discriminator, and outputting whether a target sub-graph is abnormal or not. According to the invention, efficient modeling of the power distribution network is realized, and under the condition of lack of an abnormal sample, particularly under a small sample scene, the low-dimensional characteristic of the abnormal topology can be automatically learned, so that the accuracy and the robustness of the abnormal detection are improved.","['G01R31/00', 'G06F18/2433', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06Q50/06', 'Y04S10/50']"
EP4318395A1,A training method and an image instance segmentation method for an image mask generator,"The present disclosure provides a training method and an image instance segmentation method for an image mask generator, the training method comprising: selecting a sample image from two sets of sample images to input a generative adversarial network comprising a generator and a discriminator, each sample image comprising a target object, a target object of the first set of sample images among the two sets of sample images being unblocked, and a target object of the second set of sample images being partially blocked; the generator is used to generate the masks of the two sample images, the mask of each sample image being used for predicting the target object of the sample image; the masks of the generated two sample images are inputted into the discriminator, and the adversarial loss functions are constructed for the discrimination results of the generated masks of the two sample images according to the discriminator; the parameters of the generator are updated based on the adversarial loss functions to train the generator.","['G06T7/11', 'G06V10/26', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T7/194', 'G06T7/70', 'G06V10/25', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US11145052B2,Intelligent classification of regions of interest of an organism from multispectral video streams using perfusion models,"Embodiments for implementing intelligent classification of region of interest in an organism in a computing environment by a processor. Time series data of a contrast agent in one or more regions of interest captured from multispectral image streams may be collected. The one or more regions of interest may be classified into one of a plurality of classes by applying one or more perfusion models, representing spatio-temporal behavior of the contrast agent reflected by the time series data, and by using a machine learning operation.","['G06T7/0016', 'G06F18/24', 'G06K9/3233', 'G06K9/6267', 'G06N20/00', 'G06T7/0012', 'G06V10/25', 'G06V10/764', 'G06V10/776', 'G06T2207/10024', 'G06T2207/10036', 'G06T2207/10064', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
US12367597B2,Trackerless 2D ultrasound frame to 3D image volume registration,"One embodiment provides an apparatus for registering a two dimensional (2D) ultrasound (US) frame and a three dimensional (3D) magnetic resonance (MR) volume. The apparatus includes a first deep neural network (DNN) and an image fusion management circuitry. The first DNN is configured to determine a 2D US pose vector based, at least in part, on 2D US frame data. The image fusion management circuitry is configured to register the 2D US frame data and a 3D MR volume data. The registering is based, at least in part, on the 2D US pose vector.","['A61B5/7425', 'G06T7/30', 'G06T7/70', 'A61B5/0035', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/10132', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30081']"
CN114742208A,Graph pre-training learning method based on contrast learning and counterlearning,"The invention discloses a graph pre-training learning method based on contrast learning and confrontation learning. And finally, carrying out fine adjustment operation on the pre-trained encoder model, and applying the encoder model to two downstream tasks of node classification and graph classification. Compared with other baseline models trained for a specific data set and a specific task, the unsupervised graph pre-training learning method based on contrast learning and antagonistic learning has better or competitive performance of the graph pre-training model. Experiments such as robustness, ablation, model hyper-parameter verification and the like are carried out, and the effectiveness of the model is proved.","['G06N3/045', 'G06N3/088']"
US12270883B2,Sparse representation of measurements,"A computer system that performs a sparsity technique is described. During operation, the computer system accesses or obtains information associated with non-invasive measurements performed on at least an individual, historical non-invasive measurements, and a dictionary of predetermined features or basis functions associated with the historical non-invasive measurements. Note that the non-invasive measurements and the historical non-invasive measurements may include or correspond to magnetic resonance (MR) measurements. For example, the MR measurements may include magnetic resonance imaging (MRI) scans. Then, the computer system updates the dictionary of predetermined features based at least in part on the non-invasive measurements and the historical non-invasive measurements, where the updating includes performing a minimization technique with a cost function having an L2-norm term and an L0-norm term. Next, the computer system determines weights associated with features in the updated dictionary of predetermined features based at least in part on the non-invasive measurements.","['G01R33/5608', 'A61B5/055', 'G01R33/50', 'G01R33/561', 'G01R33/5611', 'G06T7/0012', 'G06T2207/10088', 'G06T2207/20081']"
WO2025055537A1,"Picture displaying method and system, picture processing method and system, picture uploading method, picture generating method, and electronic device","Embodiments of the present application provide a picture displaying method and system, a picture processing method and system, a picture uploading method, a picture generating method, and an electronic device. The picture displaying method comprises: in response to an operation of a user, obtaining a second picture related to the user, wherein the second picture is generated on the basis of at least one decoration material and a first picture of a target object, and the at least one decoration material is related to the user; and displaying the second picture on a client interface. According to the technical solution provided in the embodiments of the present application, the second picture displayed for the user is a picture decorated and related to the user, such that the user can directly perceive that the target object is closely related to the user, making it more immersive.","['G06T5/50', 'G06Q30/0643', 'G06T2207/20221']"
CN106663446A,User environment aware acoustic noise reduction,"Examples of the present disclosure describe user environment aware single channel acoustic noise reduction. A noisy signal received by a computing device is transformed and a feature vector of the received noisy signal is determined. The computing device accesses classification data corresponding to a plurality of user environments. The classification data for each user environment has a noise model associated with it. A comparison between the determined feature vectors and the accessed classification data is performed to identify a current user environment. A noise level, a speech level, and a speech presence probability from the transformed noisy signal are estimated and the noise signal is reduced based on the estimates. The resulting signal is output as an enhanced signal with reduced or eliminated noise signals.","['G10L21/02', 'G10L21/0216', 'G10L25/24', 'G10L25/84', 'H03G3/32', 'G10L25/51']"
CN119337328A,Intelligent fire command method and system based on multimodal AI big model,"The invention relates to the technical field of multi-source information integration, and discloses an intelligent fire command method and system based on a multi-mode AI large model, which acquires fire scene data in real time through multi-terminal information acquisition, performs scene reconnaissance feedback through image recognition algorithm flame and smoke recognition and dangerous goods recognition, and utilizes a pre-trained multi-mode live restoration model to restore and simulate the fire scene to generate a multi-source live simulation model for analyzing and formulating personalized rescue plans, by collecting positioning and state information of a rescue unit in real time, constructing a rescue unit simulation model, analyzing specific rescue execution steps according to a personalized plan, the steps help commander to realize accurate command and efficient rescue, improve rescue decision accuracy, reduce response time, optimize resource allocation, remarkably improve emergency response capacity and successful rescue rate of a fire scene, and solve the problem of lower efficiency in the prior art when the manual integration of multi-source information is adopted to recover the fire.","['G06F18/25', 'G06F30/20', 'G06N3/042', 'G06N3/08', 'G06Q10/063', 'G06V20/40', 'Y02T10/40']"
KR20230013995A,Method and apparatus for generating process simulation model,"According to the technological idea of the present disclosure, provided is a method for generating a simulation model based on simulation data and measurement data for an object, which includes the steps of: classifying weight parameters included in a pre-learning model learned based on simulation data into a first weight group and a second weight group according to importance; re-learning the first weight group of the pre-learning model based on the simulation data; and learning the second weight group of a transfer learning model including the first weight group re-learned based on the measurement data.","['G05B19/41885', 'G01R31/2834', 'G05B23/02', 'G06F30/27', 'G06F30/367', 'G06N3/0464', 'G06N3/08', 'G06N3/092', 'G06N3/096', 'H01L21/67276', 'G01R31/319', 'G05B2219/2602', 'G05B2219/45031']"
CN112566641A,Methods and compositions for treating and/or preventing the progression and/or onset of age-related neurodegeneration,"The present invention relates to methods for treating and/or preventing the progression and/or onset of age-related neurodegeneration. The present invention also relates to a method of reversibly slowing growth and/or aging, and/or extending the potential lifespan of a subject comprising administering the naturally occurring aminosterol MSI-1436, or a derivative or salt thereof. Also described are methods for treating, preventing, or delaying the onset of an age-related disease or condition comprising administering an aminosterol 1436, or a derivative or salt thereof.","['A61K31/575', 'A61K9/0019', 'A61K9/0031', 'A61K9/0043', 'A61K9/0053', 'A61P19/02', 'A61P25/28', 'A61P35/00', 'A61P9/10', 'Y02A50/30']"
CN107195935A,CIHT dynamical systems,"The present invention relates to CIHT dynamical systems.The present invention provides a kind of electrochemical power system for producing at least one of voltage and current and heat energy, and the electrochemical power system includes container, and the container is includedï¼At least one negative electrode, wherein, the negative electrode includes at least one of capillary system and radial gas passages, porous electrode and the porous layer perforated with surrounding, by H2O and O2At least one of relative to periphery towards the battery central transmissionï¼At least one anodeï¼At least one bipolar plates, and reactant, the reactant include at least two compositions selected from following materialï¼A) at least one H2O originatesï¼B) oxygen is originatedï¼C) at least one catalyst source or catalyst, it, which is included, is selected from nH, O, O2ãOHãOHâWith newborn H2At least one of O group, wherein n are integerï¼And d) at least one atomic hydrogen source or atomic hydrogen, and the system also includes electrolysis system.","['H01M8/186', 'H01M8/143', 'H01M16/003', 'H01M4/86', 'H01M8/00', 'H01M8/06', 'H01M8/0606', 'H01M8/0656', 'H01M8/144', 'H01M8/146', 'Y02E30/10', 'Y02E60/36', 'Y02E60/50']"
CN101840910A,Semiconductor device and manufacture method thereof,"The present invention relates to a kind of semiconductor device and manufacture method thereof.A kind of technology of dependability that allows to reduce size of semiconductor device and do not weaken effectiveness and take precautions against the heating that refluxes wherein is provided.After a plurality of parts are installed on the component mounting surface of module substrate, form resin to cover mounted component.Form screen in addition on the surface of resin (upper surface and side surface), this screen comprises the stacked film of Cu plated film and Ni plated film.In screen, crack, a plurality of microchannel forms at random and does not intercouple in straight line along granule boundary and with net-like configuration, and forms a plurality of paths of extending to the surface of screen from resin by the crack, microchannel.","['H01L23/66', 'H01L23/3121', 'H01L23/3677', 'H01L23/552', 'H01L24/97', 'H05K3/284', 'H05K9/0084', 'H01L2223/6644', 'H01L2224/32225', 'H01L2224/45144', 'H01L2224/45147', 'H01L2224/48091', 'H01L2224/48227', 'H01L2224/73265', 'H01L2224/97', 'H01L23/49838', 'H01L23/50', 'H01L23/5383', 'H01L24/45', 'H01L24/48', 'H01L2924/01005', 'H01L2924/01006', 'H01L2924/01011', 'H01L2924/01012', 'H01L2924/01013', 'H01L2924/01015', 'H01L2924/01019', 'H01L2924/01023', 'H01L2924/01029', 'H01L2924/0103', 'H01L2924/01033', 'H01L2924/01042', 'H01L2924/01046', 'H01L2924/01047', 'H01L2924/01061', 'H01L2924/01074', 'H01L2924/01078', 'H01L2924/01079', 'H01L2924/01082', 'H01L2924/10253', 'H01L2924/12041', 'H01L2924/1305', 'H01L2924/1306', 'H01L2924/14', 'H01L2924/15311', 'H01L2924/181', 'H01L2924/19041', 'H01L2924/19042', 'H01L2924/19043', 'H01L2924/19105', 'H01L2924/30105', 'H01L2924/30107', 'H01L2924/3011', 'H01L2924/3025', 'H05K1/0218', 'H05K2201/09036', 'H05K2201/0909', 'H05K3/0052']"
US20230214461A1,System and process for generating code snippets to license digital content,"A method and system for generating code snippets to license content are disclosed. In some embodiments, the method includes acquiring a digital asset in a software-as-a-service (SaaS) interface. The method further includes generating metadata and an access uniform resource locator (URL) for the digital asset. The method additionally includes generating a primary JavaScript object notation (JSON) file to create one or more code snippets in different formats for the digital asset. The method further includes activating an abstraction process to automatically generate a truncated embeddable code snippet after detection of a licensing of the digital asset.","['G06F21/105', 'G06F16/164', 'G06F21/10', 'G06F21/1065', 'G06F21/16', 'G06Q30/0246', 'G06Q30/0641', 'G06Q2220/18', 'G06Q50/184']"
CN114996866A,A Mathematical Model and Discrete Method for Jet Pulse Engine Interior,"The invention provides a mathematical model and a discrete method for the interior of a jet pulse engine, which comprises the following steps: the method comprises the following steps: establishing a mathematical model by taking an RANS equation as a control equation, and performing the following steps: carrying out grid division on the mathematical model and the fluid calculation domain established in the step one, and establishing the fluid calculation domain on the geometric model of the underwater solid rocket engine jet pipe obtained in the step one; step three: discretizing and solving a control equation; step four: numerical calculation analysis of the flow characteristics of the swinging high-speed jet of the underwater solid rocket engine nozzle is carried out on the basis of the first step to the third step, and the design solves the problem of flow field calculation of complex configuration which cannot be solved or has poor effect by using a single-domain grid generation method; after the generation of the partitioned mesh, the different regions are allowed to be solved using different mesh systems or using different numerical calculation formats.","['G06F30/17', 'G06F30/23', 'G06F30/28', 'G06F2111/10', 'G06F2113/08', 'G06F2119/08', 'G06F2119/14', 'Y02T90/00']"
US20230360547A1,Method and system for on-board localization,"A method and system provide for on-board localization in a unmanned aerial system (UAS). A map image if generated (using previously acquired images) of an area that the UAS is overflying. The map image is then processed by orthorectifying, referencing the map image in a global reference frame, and generating an abstract map by detecting features and locating the features in the global reference frame. The UAS is then localized by acquiring camera images during flight, selecting a subset of the camera images as localization images, detecting on-board image features (in the localization images), mapping features from the detected on-board image features to the abstract map, deleting outliers to determine an estimated 3D pose, and refining the 3D pose. The localized UAS then used to autonomously navigate the UAS.","['G08G5/0069', 'G08G5/55', 'G06V10/82', 'G06V20/17', 'G08G5/57', 'G06V10/462']"
CN119400393B,Infarct change prediction method and system based on brain parenchyma MRI image,"The invention provides an infarct change prediction method and system based on brain parenchyma MRI images, which relate to the technical field of image recognition and comprise the steps of obtaining brain parenchyma MRI images, constructing a multi-mode image set, screening according to screening standards, artifact recognition, calculating quality scores, preprocessing to obtain standard image data, performing feature extraction to obtain brain region division masks, performing feature extraction to obtain multi-mode feature data, constructing topological relations among different brain regions, extracting high-order semantic features to obtain brain region feature data, selecting to obtain high-quality feature data, constructing a time sequence feature matrix, distributing weights, generating residual output, predicting through a fully connected neural network, generating an infarct change prediction result, generating a prediction prognosis result and generating a comprehensive prediction report.","['G16H50/20', 'G06N20/20', 'G06N3/0442', 'G06N3/0464', 'G06N3/0499', 'G06N5/01', 'G06T7/0012', 'G06V10/20', 'G06V10/40', 'G06V10/62', 'G06V10/771', 'G06V10/806', 'G06V10/82', 'G16H15/00', 'G16H50/30', 'G16H50/70', 'G06T2207/10088', 'G06T2207/30016', 'G06T2207/30168', 'G06V2201/03', 'Y02A90/10']"
EA037366B1,"Process for preparing parp inhibitor, crystalline forms, and uses thereof","The invention relates to a process for preparing a PARP1/2 (poly(ADP-ribose)polymerase) inhibitor, i.e., (R)-2-fiuoro-10a-methyl-7,8,9,10,10a,11-hexahydro-5,6,7a,11-tetraazacyclohepta[def]cyclopenta[a]fluoren-4(5H)-one (hereinafter referred to as compound A), crystalline forms (polymorphs) of compound A or a hydrate or solvate thereof, particularly crystalline form C of compound A sesqui-hydrate, methods for preparing the crystalline forms, and the use thereof.","['C07D471/22', 'A61K31/4353', 'A61K31/437', 'A61K31/551', 'A61K31/5517', 'A61P35/00', 'A61P35/04', 'C07D471/04', 'C07D471/14', 'C07B2200/13']"
US20240126959A1,Reservoir modeling,"A method can include receiving sample information for reservoir fluid samples and automatically selecting one or more equations of state from a plurality of different equations of state, which can suitably match the reservoir fluid samples and/or other samples. Such a method can also include automatically generating initial conditions based at least in part on sample information where such initial conditions along with one or more selected equations of state can be utilized in simulating physical phenomena using at least a reservoir model to generate simulation results. Such a method can include outputting at least a portion of the simulation results, which may be utilized in one or more processes.","['G06F30/28', 'E21B43/00', 'G06F30/23', 'G01V20/00', 'G01V9/02', 'E21B2200/20', 'E21B2200/22', 'G01V2210/624', 'G01V2210/645', 'G01V2210/663', 'G05B13/04', 'G05B17/02', 'G05B19/02', 'G06F17/10', 'G06F2113/08', 'G06F30/20']"
US20230222328A1,Solving Aliasing-Induced Problems in Convolutional Nonlinear Networks,"Methods are disclosed for aliasing-free nonlinear signal processing, by implementing non-polynomial operations as implicitly defined functions that are computed iteratively using linear shift-invariant convolutions in conjunction with polynomial operations, where upsampling and/or downsampling of signals are employed to control their spectra and avoid aliasing completely. Techniques of system or image symmetrization are also disclosed to render a convolutional nonlinear network shift-invariant under an arbitrary spacetime shift.","['G06N3/0464', 'G06N3/0455', 'G06N3/048', 'G06N3/08']"
CN102855342A,Optimization design method of anaerobic continuous flow agitator bath type biological hydrogen production reactor,"The invention belongs to the field of environment protection, and in particular relates to an optimization design method of an anaerobic continuous flow agitator bath type biological hydrogen production reactor. The method comprises the following steps: researching reactor internal flow field characteristics of different types of stirring paddles under the conditions of different paddle-bath diameter ratios and different agitating speeds and influence on hydrogen production process, by using a numerical simulation software based on computational fluid mechanics technology; obtaining detailed flow field information, such as velocity field, turbulence energy and dissipation rate thereof, biogas integration rate and shearing rate distribution by adopting a two-phase flow model, and analyzing and comparing different flow field information obtained through simulation according to influence on hydrogen production process by the various flow field information, thereby determining an optimal stirring paddle style and agitating speed combination, and providing an effective method for the optimization design of the agitator bath reactor. The optimization design method of the anaerobic continuous flow agitator bath biological hydrogen production reactor is mature in technology, avoids the blindness of hydraulic design of the reactor using an empirical or semiempirical association method, and has the advantages of being visual in optimization cycle effect and short in optimization cycle, saving cost, and the like.",[]
WO2022223042A1,"Surgical path processing system, method, apparatus and device, and storage medium","Provided in the embodiments of the present description are a surgical path processing system, method, apparatus and device, and a storage medium. The system comprises: an image segmentation module, which is used for performing image segmentation on a first medical image, so as to acquire a first segmented image; an avoidance area determination module, which is used for determining, on the basis of the first segmented image, an area that needs to be avoided; and a path planning module, which is used for determining a surgical path on the basis of the area that needs to be avoided.","['A61B34/30', 'A61B34/10', 'A61B34/25', 'B25J9/1664', 'G05B19/4155', 'G06T7/11', 'G06T7/174', 'G06T7/33', 'G06T7/337', 'A61B2034/101', 'A61B2034/105', 'A61B2034/107', 'G05B2219/50391', 'G06N20/00', 'G06T2207/10081', 'G06T2207/20021', 'G06T2207/20092', 'G06T2207/20101', 'G06T2207/30004']"
CN117252966B,"Dynamic cartoon generation method and device, storage medium and electronic equipment","The invention provides a dynamic cartoon generating method and device, a storage medium and electronic equipment. The whole process does not need an creator to create cartoon images of film and television roles, does not need the creator to draw cartoon images of story scripts frame by frame, effectively shortens the generation period of dynamic cartoon videos, reduces the cost of generating the dynamic cartoon videos, and improves the generation efficiency.","['G06T13/40', 'G06T13/205', 'H04N5/265']"
CN107016143A,The method and its system of parameter extraction,"Embodiments of the invention are related to the method implemented by least one processor, comprise the following stepsï¼Generation includes the topology data of the chip of transistorï¼Position based on the transistor in topology data determines the hot relevant parameter for transistorï¼Generation includes the netlist data of hot relevant parameterï¼Post layout simulation is implemented based on netlist dataï¼And whether checking post layout simulation meets design specification.Embodiments of the invention further relate to the method and its system of parameter extraction.","['G06F30/367', 'G06F30/398', 'G06F30/20']"
CN103234219A,Circumference air quantity adjustment method and system for pulverized coal boiler after fire coal kind changing,"The invention discloses a circumference air quantity adjustment method for a pulverized coal boiler after fire coal kind changing. The method comprises the steps of establishing a gridding structural model of the boiler; establishing a mathematical model of various physical and chemical processes formed by pulverized coal combustion; simulating the pulverized coal combustion process of the boiler after the fire coal kind changing, and obtaining corresponding relations between various circumference air quantity conditions of the boiler and boiler combustion performance indexes; and adjusting circumference air quantity of the boiler to enable the boiler to meet preset combustion performance indexes. In addition, a circumference air quantity adjustment system for the pulverized coal boiler after the fire coal kind changing is further disclosed. According to the circumference air quantity adjustment method and system for the pulverized coal boiler after the fire coal kind changing, circumference air quantity control accuracy and safety of the pulverized coal boiler after the fire coal kind changing can be improved, the problems of instable combustion in the boiler and low combustion efficiency which are easily caused by manual control are solved, and pollutants generated in the combustion process are greatly reduced simultaneously.",[]
KR102303002B1,Method and Apparatus for Deblurring of Human and Scene Motion using Pseudo-blur Synthesizer,"Provided are a method and a device for deblurring an image including a person using a pseudo-blur synthesizer. The method of the present invention comprises the steps of: initializing and learning an input image including a scene blur and a person blur through an initial deblurring unit until a deblurring network is converged to generate a learned deblurring weight; generating a learned re-blurred image through a pseudo-blur synthesizing unit by receiving the learned deblurring weight; generating a meta-transmission deblurring weight after generating the learned reblurred image through the pseudo-blur synthesizing unit; and performing a meta test using the meta-transmission deblurring weight through a final deblurring unit. Therefore, the deblurring performance can be improved.","['G06T5/003', 'G06N20/00', 'G06T2207/20081']"
CN118898555A,Colored three-dimensional point cloud repair method and system,"The present invention relates to a method and system for repairing a colored three-dimensional point cloud, and more particularly, to a computer-implemented method (100) and computer system for coloring a 3D point cloud of an environment, the method comprising: acquiring (110) point cloud data and image data of an environment, wherein the point cloud data comprises coordinates and intensity values of individual points of the point cloud, and the image data provides color information of the environment, wherein the method further comprises: combining (120) the intensity values and the color information in a common alignment space; identifying (130) points in the point cloud and/or pixels in the image data that are affected by content differences or anomalies between the color information and the point cloud data; deriving (140) coloring information from the neural network based on the joint evaluation of the combined intensity values and color information for each of the identified points and/or pixels; and assigning (150) respective shading information to each of the identified points and/or pixels.","['G06T5/77', 'G06T15/50', 'G06T19/20', 'G06T5/60', 'G06T2207/10028', 'G06T2207/20084', 'G06T2210/56', 'G06T2219/2012']"
CN116737150A,Page generation method and device,"The application provides a page generation method and a page generation device, wherein the page generation method comprises the following steps: acquiring an initial page; extracting and constructing an element sequence based on the initial position and the initial size of each page element; performing position association analysis on each information pair in the element sequence by using a natural language model to obtain a target position of each page element; rendering each page element based on the target position of each page element to generate a target page. The initial position and the initial size are extracted, an element sequence which can be processed by a natural language model is constructed, the position correlation analysis capability of the natural language model is utilized to complete the analysis and adjustment of the information in the element sequence to the position of the page element, the target position of each page element with high accuracy is obtained efficiently, on the basis, the target page with high aesthetic degree and high uniformity is rendered and generated, and the efficiency and accuracy of page generation are improved.","['G06F8/38', 'G06F16/958', 'G06F8/34', 'G06N3/0442', 'G06N3/0464', 'G06T15/005', 'Y02D10/00']"
WO2013185856A1,Joint topic model for cross-media news summarization,"A method for providing a complementary summary of news information. The method comprises retrieving a first group of relevant text sentences about an event from a first content source, such as a news media stream, and retrieving a second group of relevant text messages about the same event from a second content source, such as a social media stream or microblogs. The method analyses the retrieved text information and calculates a measure of complementarity between the text information in the first and second groups and ranks the text sentences from the first group against the text messages from the second group according to the measured complementarity between these individual text sentences and messages. Then two types of complementary summaries are generated based on different granularities of complementarity: (1 ) considering summary-level complementarity, the two summaries are generated from two groups of text in such a way that they are complementary as a whole; (2) considering sentence-level complementarity, the two summaries are produced from two groups of text with strict one-on-one complementary correspondence inside the news sentences and text messages that constitute the respective summary.","['G06F16/35', 'G06F16/345']"
WO2019113712A1,Method and system for standardized processing of mr images,Various embodiments are described herein describe a method and system for processing a digital magnetic resonance (MR) image volume in an image data set using intensity standardization to provide standardized MR image slices. The standardized image slices can be used in various MR image processing methodologies such as image segmentation and object detection.,"['G06T7/0014', 'A61B5/055', 'G01R33/4835', 'G01R33/5608', 'G06T3/40', 'G06T5/40', 'G06T5/92', 'G06T7/33', 'G16H30/40', 'G06T2207/10088', 'G06T2207/30016']"
CN102088971A,Use of tocotrienol composition for the prevention of cancer,"The present invention is directed to a method of preventing cancer or preventing the recurrence of cancer after undergoing a cancer treatment by administering a composition comprising at least one of Gamma-tocotrienol or Gamma-tocotrienol, wherein the cancer is selected from the group consisting of melanoma, prostate cancer, prostate intraepithelial neoplasia, colon cancer, liver cancer, bladder cancer, breast cancer and lung cancer. The present invention is further directed to a composition comprising at least one of Gamma-tocotrienol or Delta-tocotrienol and Docetaxel and/or Dacarbazine, and to a method of inhibiting or arresting or reversing of cancer by administering a composition comprising at least one of Gamma-tocotrienol or Gamma-tocotrienol together with Docetaxel and/or Dacarbazine. The present invention is also directed to methods of manufacturing those compositions.","['A61K31/337', 'A61K31/353', 'A61K31/655', 'A61P35/00', 'A61P43/00']"
WO2021064833A1,"Abnormality detection device, abnormality detection method, and recording medium","Provided is an abnormality detection device 10 capable of detecting abnormalities in processing results. The abnormality detection device 10: estimates first processing result information in accordance with a first process using data of a subject; compares the first processing result information with second processing result data of a second process with respect to the data of the subject, said second process being different from the first process; and detects an abnormality in the second process in accordance with the comparison result.","['G05B23/024', 'G06N20/00']"
US11901056B2,Methods and systems for informed selection of prescriptive therapies,A system for informed selection of prescriptive therapies. The system includes a computing device configured to receive compositional training data containing a plurality of unclassified data entries. The system is configured to retrieve a user biological profile and generate an unsupervised machine-learning model that utilizes a biological profile as an input and outputs a therapy response label. The system selects a therapy response model and receives from a remote device a proposed prescriptive therapy. The system creates a therapy response model and identifies a prescriptive therapy label for a proposed prescriptive therapy.,"['G16H20/10', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06N7/01', 'G16H10/60', 'G16H50/20', 'G16H50/70', 'G06N3/088', 'Y02A90/10']"
US12198698B1,Devices for non-audible speech detection,"Provided herein is a device for non-audible speech detection. The device comprises at least one transmitting antenna configured to transmit a plurality of radio frequency (RF) signals. The device further comprises at least one receiving antenna configured to collect RF signal data associated with movement of one or more speech articulators of a user, wherein the device is configured to be coupled to a head of the user, wherein the RF signal data is processed to determine a non-audible speech of the user, and wherein the non-audible speech of the user comprises continuous speech by the user.","['G10L15/16', 'G06F3/012', 'G01S13/02', 'G01S13/426', 'G01S13/50', 'G01S13/89', 'G01S7/412', 'G01S7/417', 'G06F3/013', 'G06F40/58', 'G10L15/1815', 'G10L15/22', 'G10L15/25', 'G10L21/02', 'G10L25/75', 'G01S2013/0245', 'G10L2015/227']"
CN117332745B,"Method, apparatus and medium for generating layout","Methods, devices, and media for generating a layout are provided according to example embodiments of the present disclosure. In the method, a reference layout representation and a reference element representation of a reference layout element are obtained. The reference layout representation characterizes the overall characteristics of the layout, and the reference element representation indicates attributes of the reference layout elements. Further, based on the reference layout representation and the reference element representation, a first machine learning model is utilized to generate respective target element representations of the one or more layout elements to be laid out. The target element representation of each layout element to be placed indicates the position of the layout element to be placed in the target layout, the type of the layout element to be placed, and the arrangement state of the layout element to be placed in the layout element sequence associated with the layout element to be placed. In addition, a target layout is generated based on the respective target element representations of the one or more layout elements to be placed. In this way, a layout can be generated more efficiently, and the diversity of the layout can be improved.","['G06F30/392', 'G06F30/27']"
US11508067B2,Method for quantifying algal for management of water quality,"Disclosed is a method for quantifying algal for management of water quality, performed by a computing device. The method may include: receiving a remote sensing image of an object of interest; and predicting a water quality variable based on the remote sensing image using a pre-trained algal estimation model.","['G01N21/3586', 'G06T7/0012', 'G06N20/00', 'G06N3/045', 'G06N3/082', 'G06N3/084', 'G06T3/40', 'G06T3/4046', 'G06T2207/10036', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
CN118470299A,ISSOD-based infrared ship small target detection method and ISSOD-based infrared ship small target detection equipment,"The invention provides a ISSOD-based infrared ship small target detection method and ISSOD-based infrared ship small target detection equipment, wherein a network in the scheme adopts a model without an anchor frame and optimizes a structure so as to reduce the quantity of network parameters and time delay and promote real-time performance; introducing a global attention mechanism to strengthen the learning ability of a small target, and designing a multi-path aggregation network to improve the extraction ability of target features; the detection head is reinforced, the regression range of the DFL is vectorized, and the detection capability of the network to the small target is further enhanced; the task alignment learning is adopted to replace the original label distribution method, so that the detection precision is improved, and the detection performance of the small target and the shielding target is improved by strengthening the detection head. Through experimental verification of network performance and comparison with other similar algorithms, the result shows that the method has a good detection effect on the small infrared ship targets.","['G06V10/25', 'G06N3/0464', 'G06N3/08', 'G06V10/82', 'G06V20/17']"
CN119940425B,Man-machine cooperative intelligent control system based on AIGC,"The invention discloses a AIGC-based man-machine collaborative intelligent control system, which relates to the technical field of artificial intelligence, and comprises a BI input module, a CI decision module, an AI execution feedback module, a dynamic learning module, an algorithm deviation monitoring module, a user interface module and a user interface module, wherein the BI input module senses a user state through a multi-mode biological signal, combines an antagonism generation network and contrasts with learning to optimize data integrity, the CI decision module adopts a game theory, federal learning and multi-objective optimization algorithm to improve cross-equipment and cross-user decision consistency, the AI execution feedback module realizes accurate execution based on element reinforcement learning and LSTM prediction and provides multi-mode feedback through Stable diffration and CLIP, the dynamic learning module combines knowledge distillation and resource perception optimization model efficiency, the algorithm deviation monitoring module utilizes causality inference and fairness constraint to ensure transparent fairness of decisions, and the user interface module supports an adaptive interaction and causality reinforcement learning optimization man-machine co-adaption mechanism. The invention improves the man-machine interaction capability and decision reliability of the intelligent system.",[]
US20240177832A1,"System and methods for precision tumor delineation in cancer treatment or diagnosis for subjects with carcinoma based on contrast agent-free, virtual contrast-enhanced mri data","The present disclosure provides a system and method for precision tumor delineation in cancer treatment or diagnosis for subjects with carcinoma, in particular, nasopharyngeal carcinoma, based on contrast agent-free, virtual contrast-enhanced MRI data (VCE-MRI) synthesized by a modified multimodality-guided synergistic neural network trained with a more diversified training dataset and having a higher generalizability by minimizing data distribution variation between an external dataset and the training dataset through a data distribution matching mechanism before VCE-MRI synthesis.","['A61B5/055', 'G06T7/0014', 'A61B5/7264', 'A61B5/7267', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
CN117541683A,"Image generation method, device, equipment and computer readable storage medium","The application provides an image generation method, an image generation device, an electronic device, a computer readable storage medium and a computer program product, wherein the method comprises the following steps: acquiring a target scale and an identifier corresponding to the target scale, and generating a text prompt word corresponding to the target scale based on the identifier; acquiring a noise image code; performing text coding processing on the text prompt words to obtain text codes of the text prompt words; denoising the noise image code under the condition of text coding to obtain a denoised image code; and decoding the denoising image code to obtain a target image matched with the target scale. According to the method and the device, scale control in the image generation process can be achieved, and image generation accuracy is improved.",['G06T11/60']
CN119232604B,"Network traffic sequence estimation method, system and storage medium based on diffusion model","The invention belongs to the technical field of network engineering and artificial intelligence, and particularly relates to a network traffic sequence estimation method, a system and a storage medium based on a diffusion model. The invention provides a network flow sequence estimation method based on a diffusion model, which comprises the steps of obtaining a routing matrix A of a network to be estimated and a link load sequence y on a target time point, randomly sampling from standard Gaussian noise to obtain an initial flow sequence x T, carrying out reverse diffusion on the flow sequence x t by combining a diffusion step number t to obtain a flow sequence x tâ1, carrying out gradient update, carrying out loop iteration until obtaining x 1, carrying out noise reduction treatment on the noise-removed network, and outputting a source point flow estimation sequence x' 0. The invention can realize high-precision network flow matrix estimation under the condition of source point flow loss.","['H04L41/16', 'H04L41/142', 'H04L41/145']"
CN114708465B,"Image classification method and device, electronic equipment and storage medium","The invention relates to the technical field of artificial intelligence, and provides an image classification method, an image classification device, electronic equipment and a storage medium, wherein the method comprises the following steps: determining a neural image to be classified; inputting the neural image into a classification model to obtain a classification result of the neural image output by the classification model; the classification model is obtained by training based on the first sample neural image and a sample classification result corresponding to the first sample neural image on the basis of a multi-task learning pre-training model, the multi-task learning pre-training model is obtained by training based on the second sample neural image and a sample label corresponding to the second sample neural image under each task on the basis of an unsupervised pre-training model, and the unsupervised pre-training model is obtained by unsupervised training based on the third sample neural image. The method, the device, the electronic equipment and the storage medium provided by the invention have the advantages that the data labeling cost is saved, the problem of overfitting of the model is avoided, the performance and the generalization of the model on an image classification task are improved, and the accuracy of a classification result is improved.","['G06F18/24', 'G06F18/214']"
CN114018951A,Weld detection method of plastic parts based on DCGAN salient feature sample expansion preprocessing,"The invention discloses a plastic part weld joint detection method based on DCGAN (DCGAN-based significant feature sample expansion pretreatment), which comprises the following steps of: 1) acquiring data, namely acquiring a weld picture of the plastic part by using an industrial camera; 2) based on DCGAN significant feature sample expanding pretreatment; 3) training an SE-Alexnet convolutional neural network; 4) and carrying out identification detection and outputting a detection result. The method improves the characteristic channel which is important for the welding defect and has little inhibition effect based on the fusion of the SE attention module in the Alexnet network, improves the identification rate of the improved welding defect identification model, reduces the training time and ensures that the robustness of the model is stronger.","['G01N21/956', 'G01N21/8851', 'G01N2021/8883', 'G01N2021/8893']"
CN117973445B,"Graph masking self-coding learning method, system and storage medium based on community awareness","The invention belongs to the technical field of neural network models, and discloses a graph masking self-coding learning method, a system and a storage medium based on community consciousness, wherein the graph masking self-coding learning method based on community consciousness introduces community structure information into a GAE framework and keeps influence of communities in the learning process; adopting community-guided edge masking and node feature masking; using GNN for multi-tasking decoding in an automatic encoder, and assisted with dynamic loss functions, extracting additional valuable information from the original data for enhancement map reconstruction; comMGAE retains graph topology and semantic information while learning graph representations across multiple downstream tasks such as node classification, link prediction, and graph classification. The object of the present invention is to identify weaknesses in existing GAE designs and perfect the relevant work in graph representation learning for application to downstream tasks such as link prediction and node or graph classification.","['G06N3/0455', 'G06N3/042', 'G06Q50/01']"
US20220399129A1,Systems and methods for terraforming,"Systems and methods for associating cellular constituents with a cellular process of interest are provided. Constituent vectors comprising abundances for a first plurality of cells representing annotated cell states are formed and used to obtain a latent representation of constituent modules having subsets of constituents. A constituent count data structure comprising abundances of the constituents for a second plurality of cells representing covariates of interest is obtained. An activation data structure is formed by combining the latent representation and the constituent count data structure, using constituents as a common dimension. A model is trained using a difference between the predicted and actual absence or presence of each covariate in each cellular constituent module represented in the activation data structure, thus adjusting covariate weights indicating a correlation between covariates and constituent modules across the activation data structure. The covariate weights are used to identify constituent modules associated with covariates of interest.","['G16H50/50', 'G16B5/00', 'G16B20/00', 'G16B25/10', 'G16B40/20', 'G16H50/20']"
CN109643815A,Systems and methods for electrochemical energy conversion and storage,"The electrochemical energy conversion and storage system includes an electrochemical energy conversion device, such as a fuel cell, in fluid communication with a hydrogen regenerated or electrically regenerated organic liquid fuel and an oxidant for receiving, catalyzing, and electrochemically oxidizing at least a portion of the fuel to produce electricity, a partially oxidized liquid fuel, and water. Liquid fuels include six-membered ring cyclic hydrocarbons having functional group substituents in which the ring hydrogens can undergo electrochemical oxidative dehydrogenation to the corresponding aromatic molecules. It is now also possible to electrochemically oxidize substituent functional groups (including rings) by potentially introducing oxygen, thereby providing additional energy storage capacity. The partially oxidized spent fuel can now be electrically regenerated in situ by inputting power and water to the device, producing oxygen as a byproduct. Alternatively, the recovered spent fuel may be sent to a facility where it is reconstituted by a catalytic hydrogenation or electrochemical hydrogenation process.","['H01M8/1009', 'C01B3/0015', 'C01B3/22', 'H01M4/9083', 'H01M4/926', 'H01M8/1004', 'H01M8/103', 'H01M8/188', 'C01B2203/0277', 'C01B2203/066', 'H01M2008/1095', 'H01M2250/20', 'Y02E60/32', 'Y02E60/50', 'Y02T90/40']"
US20230343414A1,Sequence-to-sequence base calling,"We disclose a computer-implemented method of base calling. The technology disclosed accesses a time series sequence of a read. Respective time series elements in the time series sequence represent respective bases in the read. Then, a composite sequence for the read is generated based on respective aggregate transformations of respective sliding windows of time series elements in the time series sequence. A subject composite element in the composite sequence is generated based on an aggregate transformation of a corresponding window of time series elements in the time series sequence. Then, the composite sequence is processed as an aggregate and generates a base call sequence that has respective base calls for the respective bases in the read.","['G16B30/00', 'G16B40/00', 'G16B5/20', 'C12Q1/6869']"
CN103049474A,Search query and document-related data translation,"The subject disclosure is directed towards developing a translation model for mapping search query terms to document-related data. By processing user logs comprising search histories into word-aligned query-document pairs, the translation model may be trained using data, such as probabilities, corresponding to the word-aligned query-document pairs. After incorporating the translation model into model data for a search engine, the translation model is used may used as features for producing relevance scores for current search queries and ranking documents/advertisements according to relevance.",[]
US20230393122A1,Stem cell compositions for culturing coronaviruses and methods of making and using thereof,"Disclosed are methods for culturing coronavirus particles in early syncytiotrophoblasts (eSTBs). The derived eSTBs are mononucleated or bi-nucleated cells with high ACE2 expression and are not multi-nucleated or mature cells. The methods can also include assessing the eSTBs for coronavirus susceptible markers. Also disclosed are compositions and methods (i) for inducing the differentiation of eSTBs and mature STBs from trophoblast stem cells (TSCs), (ii) for inducing the differentiation of TSCs from EPSCs, primed and naÃ¯ve stem cells, pre-implantation embryos, placental stem cells, and iPSCs, and (ii) for producing TSCs by reprogramming non-trophoblast cells. The disclosed compositions and methods can be used for producing large quantities of coronavirus particles, including human, non-human, and variant coronavirus particles for virus production, the vaccine inductry, disease modeling studies, screening and evaluation of antiviral reagents, compound candidates, testing kits, and evaluation of clinical therapies.","['C12N7/00', 'C12N5/0605', 'C12Q1/025', 'C12Q1/6851', 'C12Q1/6883', 'C12Q1/70', 'C12Q1/701', 'G01N33/5091', 'C12N2770/20021', 'C12N2770/20052', 'G01N2333/165']"
CN101443316A,"1,5-diphenylpyrazoles II as HSP90 inhibitors","Novel 1,5-diphenylpyrazole derivatives of formula (I), where R<1>, R<6> have the meanings given in claim 1 are HSP90 inhibitors and can be used for production of a medicament for treatment of diseases in which the inhibition, regulation and/or modulation of HSP90 plays a role.","['C07D231/12', 'A61K31/415', 'A61P1/00', 'A61P1/04', 'A61P1/16', 'A61P11/00', 'A61P11/06', 'A61P13/12', 'A61P15/00', 'A61P17/00', 'A61P17/02', 'A61P17/06', 'A61P17/10', 'A61P19/02', 'A61P19/04', 'A61P21/00', 'A61P25/00', 'A61P25/14', 'A61P25/16', 'A61P25/28', 'A61P29/00', 'A61P3/10', 'A61P31/00', 'A61P31/04', 'A61P31/12', 'A61P31/14', 'A61P31/18', 'A61P31/20', 'A61P35/00', 'A61P35/04', 'A61P37/00', 'A61P37/06', 'A61P43/00', 'A61P9/00', 'A61P9/10', 'C07D401/12', 'C07D403/12', 'C07D405/12', 'C07D413/12']"
CN101790513A,"1,3-dihydroisoindole derivatives","The invention relates to novel 1,3-dihydroisoindole derivatives of formula (I), in which R1 - R3 are defined as cited in claim 1. Said derivatives are HSP90 inhibitors and can be used to produce a medicament for treating diseases, in which the inhibition, regulation and/or modulation of HSP90 plays a part.","['C07D209/44', 'A61P1/04', 'A61P1/16', 'A61P11/00', 'A61P11/06', 'A61P13/12', 'A61P15/00', 'A61P17/00', 'A61P17/02', 'A61P17/06', 'A61P21/00', 'A61P25/00', 'A61P25/14', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/10', 'A61P31/00', 'A61P31/04', 'A61P31/12', 'A61P31/14', 'A61P31/16', 'A61P31/18', 'A61P31/20', 'A61P31/22', 'A61P35/00', 'A61P35/02', 'A61P35/04', 'A61P37/00', 'A61P37/06', 'A61P9/00', 'A61P9/10', 'C07D403/04', 'C07D403/12', 'C07D413/12', 'C07D417/12']"
CN101443003A,Triazole derivatives II,"Novel triazole derivatives of formula (I), where R<1>, R<6 >and Y have the meanings given in claim 1 are HSP90 inhibitors and can be used for production of a medicament for treatment of diseases in which the inhibition, regulation and/or modulation of HSP90 plays a role.","['C07D249/08', 'A61K31/4196', 'A61P1/16', 'A61P11/06', 'A61P15/00', 'A61P17/00', 'A61P17/06', 'A61P19/02', 'A61P21/00', 'A61P25/00', 'A61P25/14', 'A61P25/28', 'A61P29/00', 'A61P3/10', 'A61P31/04', 'A61P31/12', 'A61P31/14', 'A61P31/18', 'A61P31/20', 'A61P31/22', 'A61P35/00', 'A61P37/06', 'A61P43/00', 'A61P9/00', 'A61P9/10', 'C07D401/12', 'C07D403/12']"
CN101484425A,Indazole derivatives for treating HSP90-induced diseases,"The invention relates to novel indazole derivatives of formula (I), in which R<1>- R<3> are defined as cited in claim (1). Said derivatives are inhibitors of HSP90 and can be used to produce a medicament for treating diseases, in which the inhibition, regulation and/or modulation of HSP90 plays a role.","['C07D403/12', 'A61K31/41', 'A61P1/04', 'A61P1/16', 'A61P11/00', 'A61P11/06', 'A61P13/12', 'A61P15/08', 'A61P17/02', 'A61P19/02', 'A61P21/00', 'A61P21/04', 'A61P25/00', 'A61P25/08', 'A61P25/14', 'A61P25/22', 'A61P25/28', 'A61P27/02', 'A61P29/00', 'A61P3/10', 'A61P31/04', 'A61P31/12', 'A61P31/16', 'A61P31/18', 'A61P31/20', 'A61P31/22', 'A61P35/00', 'A61P35/02', 'A61P35/04', 'A61P37/02', 'A61P37/06', 'A61P43/00', 'A61P9/06', 'A61P9/10', 'C07D231/56', 'C07D405/12']"
US20240346709A1,User-guided visual content generation,A method of generating a visual content item comprises receiving input from a user comprising text. The method computes values of input parameters from the received input and from observed interactions with other visual content items by the user or other users. The visual content item is generated by inputting the computed values of the input parameters to a generative machine learning apparatus.,"['G06F40/40', 'G06F3/0484', 'G06T11/00', 'G06T2200/24']"
