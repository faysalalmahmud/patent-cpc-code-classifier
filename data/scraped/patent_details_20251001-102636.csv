publication_number,title,abstract,cpc_codes
WO2020052169A1,Clothing attribute recognition detection method and apparatus,"A clothing attribute recognition detection method and apparatus. The method comprises: obtaining a picture to be detected, the picture to be detected being a clothing picture; labeling the picture to be detected by using a key point model, and generating the picture to be detected in which a key point is labeled, wherein the key point model is obtained by training a multilayer network structure by using a data set, the multilayer network structure comprises a primary network and a secondary network, and the data set is a set of data obtained by performing data pre-processing after capturing a large number of clothing picture data; according to the picture to be detected in which the key point is labeled, performing clothing attribute recognition of a key point region by using a clothing attribute model, and obtaining clothing attribute information of the picture to be detected, wherein the clothing attribute model is obtained by training a pre-training model on the basis of the idea of transfer learning.","['G06F18/241', 'G06F18/25', 'G06Q30/06', 'G06Q30/0601']"
CN113643269B,"Breast cancer molecular typing method, device and system based on unsupervised learning","The invention relates to a breast cancer molecular typing method, device and system based on unsupervised learning, wherein the method comprises the following steps: obtaining a DCE-MRI image of a breast to be predicted, and extracting regions of interest of sequence images with various specifications in the image; predicting and obtaining corresponding molecular subtype classification probabilities of various sequence images by using a molecular subtype prediction model obtained by adopting unsupervised learning training; adopting ensemble learning fusion to obtain a final corresponding molecular subtype classification result; when the molecular parting prediction model is trained, through the ideas of an unsupervised learning pre-training network and a transfer learning fine tuning network, the breast benign tumor image is fully utilized to construct a label-free source domain data set in the previous stage, and the feature extraction capability of the model is enhanced; in the latter stage, a target domain data set with labels is constructed by adopting breast malignant tumor images to finely tune a model with pre-training weights. Compared with the prior art, the method and the device remarkably improve the prediction precision of breast cancer molecular typing.","['G06T7/0012', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T2207/10096', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30068', 'Y02A90/10']"
CN111638465B,Lithium battery health state estimation method based on convolutional neural network and transfer learning,"The invention discloses a lithium battery health state estimation method based on a convolutional neural network and transfer learning. The method is based on transfer learning, a basic model is pre-trained offline by using complete cycle data of an accelerated aging experiment and the last small part of 7.5% cycle data in the life cycle of a waste battery, and then parameters of the basic model are finely adjusted by using normal speed aging data of only 15% cycle before a new battery, so that the health state of the battery at any time is estimated online. Because the service life of the battery is greatly shortened by the accelerated aging experiment, the last small part of cycle data of the waste battery is easy to obtain, and the previous 15% cycle data of the new battery is also easy to obtain, a large amount of time for collecting training data is saved, the size of model input data is reduced, and the calculation process is quicker.","['G01R31/392', 'G01R31/367', 'G01R31/3842', 'G06N3/045', 'G06N3/08']"
US11620515B2,Multi-task knowledge distillation for language model,"Systems and methods are provided that employ knowledge distillation under a multi-task learning setting. In some embodiments, the systems and methods are implemented with a larger teacher model and a smaller student model, each of which comprise one or more shared layers and a plurality of task layers for performing multiple tasks. During training of the teacher model, its shared layers are initialized, and then the teacher model is multi-task refined. The teacher model predicts teacher logits. During training of the student model, its shared layers are initialized. Knowledge distillation is employed to transfer knowledge from the teacher model to the student model by the student model updating its shared layers and task layers, for example, according to the teacher logits of the teacher model. Other features are also provided.","['G06F40/30', 'G06F40/216', 'G06F40/284', 'G06F40/289', 'G06F40/40', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/047', 'G06N3/048']"
CN115240259B,A face detection method and detection system in classroom environment based on YOLO deep network,"The invention discloses a face detection method and a face detection system in a classroom environment based on a YOLO depth network, which are improved on an original YOLOX algorithm, a smaller pooling core is used in a spatial pyramid pooling structure of the network, the model can be helped to detect small-scale faces in the classroom environment more easily and improve the overall face detection performance, a mixed attention module is added in the network, the model learns to suppress useless background information and improve detection precision, an adaptive spatial feature fusion operation is added in the network, the problem of inconsistency in the PAFPN structure is solved, a EIOU loss function is used for replacing an IOU loss function, the width difference and the height difference of a real frame and a predicted frame are minimized, the convergence speed can be accelerated, the problem of insufficient data is solved by using a transfer learning pre-training operation, the face detection precision of the model in the classroom environment is improved, and a face detection data set collected in the classroom environment is divided into a training set, a verification set and a test set by a division module.","['G06V40/161', 'G06N3/08', 'G06V10/32', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06V40/168']"
CN111291836B,Method for generating student network model,"The application provides a method for generating a student network model. The method comprises the following steps: step 1), obtaining a pre-trained teacher network model; step 2), constructing an auxiliary network model; step 3), initializing the auxiliary network model, and generating a student network by using the initialized auxiliary network model; step 4), training the auxiliary network by using the training image with the image label. The auxiliary network can automatically learn the structure, the neuron number and the convolution kernel number of the student network. The manual trial is avoided, and the model detection precision of the automatic learning result of the method is higher than that of the manual trial method. The amount of computation required decreases exponentially.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/082', 'G06N3/084', 'Y02T10/40']"
US11182602B2,Method and system for person re-identification,"The present application discloses a method and a system for person re-identification, the method including: inputting a training set to a model-to-be-trained, and determining a single-class label and memory features of each image data in the training set; determining multi-class labels through positive label prediction according to the single-class labels and a memory feature set; determining classification scores according to image features of each image data in the training set and the memory feature set; determining a multi-label classification loss according to the multi-class labels and the classification scores; and updating and training the model-to-be-trained to obtain a re-identification model according to the multi-label classification loss. The classification scores are determined according to the image features of each image data in the training set and the memory feature set, which is not affected by the domain gap; the multi-class labels are determined through positive label prediction according to the single-class labels and the memory feature set; then, the multi-label classification loss is determined according to the multi-class labels and the classification scores, and the model-to-be-trained is updated and trained, so that the resulting re-identification model has high performance, strong robustness and low cost.","['G06K9/00362', 'G06V40/10', 'G06F18/214', 'G06F18/2155', 'G06F18/22', 'G06F18/241', 'G06F18/2431', 'G06K9/6215', 'G06K9/6232', 'G06K9/6259', 'G06K9/628', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/096', 'G06V10/761', 'G06V10/764', 'G06V10/774', 'G06N3/088']"
US11531871B2,Stacked neuromorphic devices and neuromorphic computing systems,"A stacked neuromorphic device includes a logic die including a control circuit and configured to communicate with a host, and core dies stacked on the logic die and connected to the logic die via through silicon vias (TSVs) extending through the core dies. The core dies include a neuromorphic core die including a synapse array connected to row lines and column lines. The synapse array includes synapses configured to store weights and perform a calculation based on the weights and input data. The weights are included in layers of a neural network system. And the control circuit provides the weights to the neuromorphic core die through the TSVs and controls data transmission by the neuromorphic core die.","['G06N3/049', 'G06N3/063', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/065', 'G06N3/08', 'G06N3/088', 'H01L2224/16145', 'H01L2224/16227', 'H01L2224/17181', 'H01L2225/06513', 'H01L2225/06517', 'H01L2225/06541', 'H01L25/0652', 'H01L25/0657', 'H01L25/18']"
WO2022108015A1,Knowledge distillation-based neural network architecture search method,"The present invention relates to a knowledge distillation-based neural network architecture search method whereby knowledge acquired from a teacher network can be used to train a student network and search a target neural network, the neural network architecture search method comprising the steps of: (a) extracting an image feature map from a training model of the student network; (b) calculating a loss function by comparing an image feature map extracted from a training model of the teacher network with the image feature map extracted in step (a); (c) selecting a capacity increase block and a capacity decrease block for each of blocks of the training model of the student network on the basis of the loss function; and (d) determining a candidate training model of the student network according to the architecture of the blocks selected in step (c).","['G06N3/04', 'G06N3/088', 'G06N3/08', 'G06N3/045', 'G06N5/022']"
US12340907B2,"Systems, methods, and apparatuses for implementing advancements towards annotation efficient deep learning in computer-aided diagnosis",Embodiments described herein include systems for implementing annotation-efficient deep learning in computer-aided diagnosis. Exemplary embodiments include systems having a processor and a memory specially configured with instructions for learning annotation-efficient deep learning from non-labeled medical images to generate a trained deep-learning model by applying a multi-phase model training process via specially configured instructions for pre-training a model by executing a one-time learning procedure using an initial annotated image dataset; iteratively re-training the model by executing a fine-tuning learning procedure using newly available annotated images without re-using any images from the initial annotated image dataset; selecting a plurality of most representative samples related to images of the initial annotated image dataset and the newly available annotated images by executing an active selection procedure based on the which of a collection of un-annotated images exhibit either a greatest uncertainty or a greatest entropy; extracting generic image features; updating the model using the generic image features extracted; and outputting the model as the trained deep-learning model for use in analyzing a patient medical image. Other related embodiments are disclosed.,"['G16H30/40', 'G06F18/217', 'G06V10/26', 'G06V10/454', 'G06V10/7753', 'G06V10/82', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G06V2201/03']"
CN110647619B,A General Knowledge Question Answering Method Based on Question Generation and Convolutional Neural Networks,"The invention provides a general knowledge question-answering method based on a question generation and convolution neural network, which comprises the steps of coding content-questions into a vector sequence through a BERT language model, transmitting the vector sequence into a question generation module, transmitting the vector sequence into a shared BERT language model, transmitting a triplet formed by the content-questions-answers into an answer selection module through the BERT language model, classifying the output code sequence of the content-questions-answers through the convolution neural network, and finally selecting optimal options as candidate answers selected by the model through scores obtained by the model.","['G06F16/3329', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
US10282661B2,"Multi-modal neural network for universal, online learning","In one embodiment, the present invention provides a neural network comprising multiple modalities. Each modality comprises multiple neurons. The neural network further comprises an interconnection lattice for cross-associating signaling between the neurons in different modalities. The interconnection lattice includes a plurality of perception neuron populations along a number of bottom-up signaling pathways, and a plurality of action neuron populations along a number of top-down signaling pathways. Each perception neuron along a bottom-up signaling pathway has a corresponding action neuron along a reciprocal top-down signaling pathway. An input neuron population configured to receive sensory input drives perception neurons along a number of bottom-up signaling pathways. A first set of perception neurons along bottom-up signaling pathways drive a first set of action neurons along top-down signaling pathways. Action neurons along a number of top-down signaling pathways drive an output neuron population configured to generate motor output.","['G06N3/08', 'G06N3/04', 'G06N3/0499', 'G06N3/09', 'G06N3/092', 'G06N3/02']"
US10343279B2,Navigational control of robotic systems and other computer-implemented processes using developmental network with turing machine learning,The Developmental Network incorporates a Turing Machine that injects teaching instructions directly into the skull-closed network. The Developmental Network can also autonomously learn directly from the natural world without the need for a human to encode its input and output. The neural network so configured can be used as a controller for robotic and other computer control applications where the neural network is organized into plural X-Y-Z areas receiving signals from sensors and providing signals to effectors.,"['B25J9/163', 'B25J9/161', 'G06N3/008', 'G06N3/042', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'Y10S901/01', 'Y10S901/47']"
US20210357210A1,Automatic generation of code documentation,"A code completion tool uses a neural transformer model with attention to generate code documentation for a method in a particular code documentation style. The neural transformer model is trained with source code programs and natural language text. The neural transformer model is pre-trained to learn the meaning of a method name, its corresponding method parameters and types from a large corpus of unsupervised dataset of source code methods. The neural transformer model is then fine-tuned on translation tasks where the model leans to translate a method signature/method body into a docstring of particular code documentation style.","['G06F8/73', 'G06F8/60', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06N3/088', 'G06N3/082', 'G06N7/01']"
WO2023024412A1,"Visual question answering method and apparatus based on deep learning model, and medium and device","A visual question answering method and apparatus based on a deep learning model, and a medium and a device. The method comprises: establishing a visual question answering model by using a pre-trained language model T5 framework, wherein the visual question answering model comprises an encoder sub-model and a decoder sub-model (S101); acquiring image data and question data, inputting same into the visual question answering model, and performing matching in a preset classification category by using the encoder sub-model in the visual question answering model, so as to obtain a classified first answer corresponding to the question data (S102); obtaining a generated second answer by using the decoder sub-model in the visual question answering model in combination with a common word list (S103); and calculating predicted probabilities corresponding to the first answer and the second answer, so as to select the first answer and/or the second answer as a target answer, and outputting the target answer (S104). By means of the method, a final answer of visual question answering can be matched from a common category, and can also be automatically generated; and an output answer is selected according to the magnitude of a predicted probability, thereby improving the accuracy of a result.","['G06F16/3329', 'G06F16/3344', 'G06F16/3346', 'G06F16/35', 'G06F40/279', 'G06N3/04', 'G06N3/08']"
US11487944B1,"System, method, and computer program for obtaining a unified named entity recognition model with the collective predictive capabilities of teacher models with different tag sets using marginal distillation","The present disclosure sets forth a marginal distillation approach to obtaining a unified name-entity recognition (NER) student model from a plurality of pre-trained teacher NER models with different tag sets. Knowledge from the teacher models is distilled into a student model without requiring access to the annotated training data used to train the teacher models. In particular, the system receives a tag hierarchy that combines the different teacher tag sets. The teacher models and the student model are applied to a set of input data sequence to obtain tag predictions for each of the models. A distillation loss is computed between the student and each of the teacher models. If teacher's predictions are less fine-grained than the student's with respect to a node in the tag hierarchy, the student's more fine-grained predictions for the node are marginalized in computing the distillation loss. The overall loss is minimized, resulting in the student model acquiring the collective predictive capabilities of the teacher models.","['G06F40/295', 'G06F40/216', 'G06F40/247', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N20/00', 'G06N7/01']"
US11875126B2,"Method, apparatus, device, and storage medium for training model and generating dialog","A method for training a dialog generation model includes: acquiring a dialog data set, and encoding a post in the dialog data set by using an encoder in the dialog generation model to obtain an encoded representation of the post; fusing, by using a decoder in the dialog generation model, the encoded representation of the post and knowledge information corresponding to the post that is obtained from a knowledge base question answering model through transfer learning to obtain a predicted response corresponding to the post; determining a value of a loss function of the dialog generation model based on the predicted response and the annotated response that correspond to the post; and updating a model parameter of the dialog generation model based on the value of the loss function. A method, an apparatus, a device, and a computer storage medium for generating a dialog are also provided.","['G06F16/3329', 'G06F40/35', 'G06F40/211', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06N5/041']"
CN110032646B,Cross-domain text emotion classification method based on multi-source domain adaptive joint learning,"The invention provides a multi-source field adaptive joint learning method and system aiming at a cross-field text emotion classification task. The framework can simultaneously learn and train neural networks in multiple fields, and richer supervision information can be introduced from different aspects. The tasks of multiple domains can complement each other, making it easier to get a more generalized representation model. In particular, the loss function of the joint training designed by the present invention includes four parts: emotion classification loss, parameter migration loss, domain fusion loss, and regular terms to prevent overfitting. The emotion classification loss comprises emotion classification loss on a source field task and a target field task, the soft parameter migration method can effectively migrate emotion knowledge in the source field to the target field, and the depth field fusion can ensure that marginal distributions in different fields are similar as much as possible in the learning process. Therefore, the adaptive joint learning neural network in the multi-source field can realize better feature representation and generalization capability under the condition of limited data. The multi-source field adaptive joint learning framework is verified on a Chinese and English multi-field data set, and experimental results show that the method provided by the invention is greatly improved in cross-field text emotion classification accuracy.","['G06F16/35', 'G06F18/214', 'G06F18/24', 'G06N3/045']"
US11836632B2,Method and system for image classification,"There is provided a method of image classification. The method includes: providing a set of category mapping discriminators, each corresponding to a respective category, wherein each category mapping discriminator of the set of category mapping discriminators is configured for discriminating features relating to input images that belong to the respective category of the category mapping discriminator; extracting a plurality of features from an input image using a machine learning model; determining, for each of the set of category mapping discriminators, an output value based on the plurality of extracted features using the category mapping discriminator; and determining a classification of the input image based on the output values of the set of category mapping discriminators.","['G06N3/084', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06N3/0985', 'G06V10/765', 'G06V10/7715', 'G06V10/7747', 'G06V10/82', 'G06N3/045', 'G06N3/048', 'G06T7/00']"
US11836611B2,Method for meta-level continual learning,"Classification of an input task data set by meta level continual learning includes analyzing first and second training data sets in a task space to generate first and second meta weights and a slow weight value, and comparing an input task data set to the slow weight to generate a fast weight. The first and second meta weights are parameterized with the fast weight value to update the slow weight value, whereby a value is associated with the input task data set, thereby classifying the input task data set by meta level continual learning.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'H04L67/10', 'G06N3/044', 'G06N3/047']"
US9489623B1,Apparatus and methods for backward propagation of errors in a spiking neuron network,"Apparatus and methods for developing robotic controllers comprising parallel networks. In some implementations, a parallel network may comprise at least first and second neuron layers. The second layer may be configured to determine a measure of discrepancy (error) between a target network output and actual network output. The network output may comprise control signal configured to cause a task execution by the robot. The error may be communicated back to the first neuron layer in order to adjust efficacy of input connections into the first layer. The error may be encoded into spike latency using linear or nonlinear encoding. Error communication and control signal provision may be time multiplexed so as to enable target action execution. Efficacy associated with forward and backward/reverse connections may be stored in individual arrays. A synchronization mechanism may be employed to match forward/reverse efficacy in order to implement plasticity.","['G06N3/084', 'B25J9/163', 'G06N3/008', 'G06N3/044', 'G06N3/049', 'G06N3/0499', 'G06N3/063', 'G06N3/09', 'G06N3/092', 'Y10S901/50']"
US11526424B2,Automated program repair tool,"An automated program repair tool utilizes a neural transformer model with attention to predict the contents of a bug repair in the context of source code having a bug of an identified bug type. The neural transformer model is trained on a large unsupervised corpus of source code using a span-masking denoising optimization objective, and fine-tuned on a large supervised dataset of triplets containing a bug-type annotation, software bug, and repair. The bug-type annotation is derived from an interprocedural static code analyzer. A bug type edit centroid is computed for each bug type and used in the inference decoding phase to generate the bug repair.","['G06F11/362', 'G06N3/088', 'G06F11/3604', 'G06F21/577', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06F2221/033', 'G06N3/042']"
US9875440B1,Intelligent control with hierarchical stacked neural networks,"A method of processing information is provided. The method involves receiving a message; processing the message with a trained artificial neural network based processor, having at least one set of outputs which represent information in a non-arbitrary organization of actions based on an architecture of the artificial neural network based processor and the training; representing as a noise vector at least one data pattern in the message which is incompletely represented in the non-arbitrary organization of actions; analyzing the noise vector distinctly from the trained artificial neural network; searching at least one database; and generating an output in dependence on said analyzing and said searching.","['G06N3/08', 'B60W30/00', 'G01C21/3602', 'G06N3/04', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/096', 'G06N3/0985', 'F02D41/1405', 'F03D7/046', 'G05B2219/25255', 'G05B2219/41054', 'G06N3/00', 'G06N3/02', 'G06N7/046', 'Y10S128/925']"
CN110222188B,Company notice processing method for multi-task learning and server,"The invention discloses a company bulletin processing method and a server for multi-task learning, wherein historical bulletin data are input into a sharing layer of a multi-task learning model, and are pre-trained through Bert; inputting a data set corresponding to a processing task into a task layer of the multi-task learning model to train the multi-task learning model; acquiring current announcement data, and inputting the current announcement data into a trained multi-task learning model to obtain a task processing result; the invention constructs a multi-task learning model by adopting a mode of transfer learning and multi-task learning, and has the advantages of higher learning efficiency, stronger generalization, low manual maintenance cost, higher accuracy of a plurality of tasks, higher recall rate and convenience for engineering deployment and maintenance.","['G06F16/3344', 'G06F16/35', 'G06F40/30', 'Y02D10/00']"
CN109299262B,A textual entailment relation recognition method fused with multi-granularity information,"The invention provides a text inclusion relation recognition method fusing multi-granularity information, and provides a modeling method fusing and interacting multi-granularity information between characters and words, between words and sentences. Firstly, establishing a word vector model based on character level by using a convolutional neural network and a Highway network layer in a character vector layer, and splicing the word vector model with a GloVe pre-trained word vector; then, a sentence modeling layer models word vectors with fused word granularity by using a bidirectional long-time and short-time memory network, interaction and matching of a text pair fusion attention mechanism are performed by a sentence matching layer, and finally, the category is obtained by an integration classification layer; after the model is built, the model is trained and tested, and finally a text inclusion recognition classification result of the test sample is obtained. The hierarchical combined structure method which integrates the multi-granularity information of the characters, the words and the sentences integrates the advantages of shallow feature positioning, deep feature learning and the like in the model, so that the accuracy of identification of the text inclusion relationship is further improved.","['G06F40/30', 'G06F18/2413', 'G06F18/24147', 'G06N3/045', 'G06N3/084']"
US10717191B2,Apparatus and methods for haptic training of robots,"Robotic devices may be trained by a trainer guiding the robot along a target trajectory using physical contact with the robot. The robot may comprise an adaptive controller configured to generate control commands based on one or more of the trainer input, sensory input, and/or performance measure. The trainer may observe task execution by the robot. Responsive to observing a discrepancy between the target behavior and the actual behavior, the trainer may provide a teaching input via a haptic action. The robot may execute the action based on a combination of the internal control signal produced by a learning process of the robot and the training input. The robot may infer the teaching input based on a comparison of a predicted state and actual state of the robot. The robot's learning process may be adjusted in accordance with the teaching input so as to reduce the discrepancy during a subsequent trial.","['B25J9/163', 'B25J9/161', 'G05D1/005', 'G05D1/0088', 'G05D1/0221', 'G06N20/00', 'G05B2219/36418', 'G05B2219/36425', 'G05B2219/40499', 'G05D2201/02', 'G06N3/008', 'G06N3/049']"
CN111652216B,Multi-scale target detection model method based on metric learning,"The invention discloses a multi-scale target detection model method based on metric learning, which is characterized in that a network is initialized by using a pre-trained model by utilizing the idea of transfer learning, and meanwhile, a loss function is added to finely adjust the weight parameters of the network, so that the regression precision of an interest area in an image is improved; after extracting a feature map from an interest region in an image, adding a full-connection layer to vectorize feature information, and then performing distance measurement by using the feature information extracted by the full-connection layer to realize classification and identification of target region information. By adopting the technical scheme of the invention, the loss of the characteristic information can be reduced, and the classification and identification accuracy of the detection target is improved.","['G06V10/25', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06T7/0002', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20104', 'Y02T10/40']"
US20230162481A1,Pre-training of computer vision foundational models,"Examples are provided for pre-training a computer vision foundation model. A representative method comprises curating a pre-training database of image-text pairs from weakly labeled data. Language is encoded of text descriptions from the image-text pairs. The images of the image-text pairs are encoded using a hierarchical vision transformer with shifted windows and convolutional embedding. Based on the encoded images and the encoded language, the computer vision foundation model is pre-trained via unified image-text contrastive learning.","['G06V10/774', 'G06T9/00', 'G06F40/126', 'G06V10/82', 'G06F40/186', 'G06F40/30']"
CN116071292B,A method for identifying blood vessels in fundusscopic retinal images based on generative contrast learning,"The invention discloses a ophthalmoscope retina image blood vessel identification method based on contrast generation learning, and aims to solve the problem that the ophthalmoscope retina image identification precision is not high when no data is marked in the prior art. The technical proposal is as follows: the method comprises the steps of constructing a retinal image blood vessel intelligent recognition system based on generation contrast learning, which consists of an input preprocessing module, an encoder, a decoder, a contrast learning module, a generation learning module and a segmentation prediction module, training the recognition system by adopting a pre-training data set, performing fine tuning optimization by using as few labeling data sets as possible, and finally recognizing the ophthalmoscope retinal image by adopting the recognition system after fine tuning to obtain a blood vessel recognition result. The invention combines the generation learning and the contrast learning, can pretrain the recognition system and fine tune the recognition system after pretraining under the condition of not depending on the labeling data, so that the recognition precision of the image input by the user exceeds the recognition precision of human expert.","['G06T7/0012', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/10088', 'G06T2207/30041', 'G06T2207/30101', 'Y02T10/40']"
CN111984772B,Medical image question-answering method and system based on deep learning,"The invention discloses a medical image question-answering method and system based on deep learning, wherein the method comprises the following steps: training a visual encoder by using non-medical image question-answer data by adopting a multitasking method; leading in a pre-trained model weight to acquire a medical image and a corresponding problem; extracting visual features of the medical image through a visual encoder, and defining spatial features according to the size of the visual feature map; extracting text features by a text encoder; fusing the vision, space and text features through a cross-modal self-attention module to obtain multi-modal features; inputting the multi-modal features into a multi-layer perceptron to infer an estimated answer; calculating loss according to the estimated answer and the actual answer, the estimated medical image type and the actual medical image type, and updating model parameters; the above process is iterated multiple times using different medical images and different questions until stopping conditions are met. The invention can improve the accuracy of medical image questions and answers.","['G06F16/3329', 'G06F16/583', 'G06F18/253', 'G16H50/70']"
CN111738003B,"Named entity recognition model training method, named entity recognition method and medium","The embodiment of the invention provides a named entity recognition model training method, a named entity recognition method and a medium.","['G06F40/295', 'G06N3/045', 'G06N3/08']"
CN110211087B,Shareable semi-automatic diabetic retinopathy labeling method,"A sharable semiautomatic marking method for diabetic fundus lesions is based on deep learning pre-training model, and comprises the steps of recognizing and dividing diabetic fundus image content, performing transfer learning, and adopting different marking methods according to different anatomical structures of fundus. Semantic segmentation is adopted for the blood vessels, and two modes of positioning and semantic segmentation are adopted for the optic nerve discs to output results. And for the diabetic fundus focus, positioning is adopted for hemangioma, and semantic segmentation is adopted for exudation and hemorrhage, so that the result is output. The outline and the positioning of the focus automatically identified through deep learning are covered on the original fundus image in a mode of overlapping image layers, and the segment with the highest confidence score is marked and presented to a marker. And manually auditing the labeling result, and storing the labeling data after manual auditing by adopting a DICOM standard so as to facilitate the interoperation in a standardized medical image system.","['G06N3/048', 'G06T7/0012', 'G06T7/11', 'G16H30/20', 'G06T2207/30041', 'Y02A90/10']"
CN108905209B,"Method and system for detecting plug-in game, electronic equipment and storage medium","The disclosure discloses a plug-in detection method and system in a game, electronic equipment and a storage medium. Wherein, this external detecting system includes: the plug-in model training module is used for training the player behavior sequence to determine a target plug-in detection model, wherein the target plug-in detection model outputs the probability that a target player to be detected is the plug-in player; and the online detection module is connected with the plug-in model training module and used for acquiring the probability that the target player is the plug-in player according to the target plug-in detection model and the newly input player behavior sequence of the target player and determining whether the target player is the plug-in player according to the probability that the target player is the plug-in player. The method and the device solve the technical problems of low efficiency and low accuracy in detecting the plug-in game in the related art.","['A63F13/75', 'A63F2300/5586']"
US20250044412A1,Method for quality detection of tunnel lining through ground-penetrating radar based on self-supervised learning,"A method for a quality detection of tunnel lining through ground-penetrating radar based on self-supervised learning. In the method, a grayscale image of the tunnel to be detected is obtained, the grayscale image is then input into a trained feature recognition model, to obtain a feature atlas is corresponding to the grayscale image, and then a quality recognition result of the tunnel to be detected is determined according to the feature atlas. In the present application, the feature recognition model is obtained by means of the self-supervised learning according to an unlabeled image set and a labeled image set, and the unlabeled image set is directly utilized to train the recognition model, which not only improves the efficiency of training the tunnel recognition model, but also improves the accuracy of tunnel quality detection results.","['G06T7/0004', 'G01S13/885', 'G01S13/89', 'G01S7/417', 'G06N3/045', 'G06N3/088', 'G06T7/0002', 'G06T2207/10044', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/30']"
CN109918510B,Cross-domain keyword extraction method,"The invention discloses a cross-domain keyword extraction method, which comprises the following steps: constructing a topic-based antagonistic neural network, encoding texts in a source field and a target field based on topics by using a topic-based encoder, introducing antagonistic learning to ensure that characteristics learned by the topic-based encoder are independent of the fields and the private characteristics of the target field are reserved by using an antagonistic learning and a bidirectional self-encoder, and finally completing keyword extraction by combining a keyword labeler in the topic-based antagonistic neural network with the output of the topic-based encoder; continuously optimizing each part parameter in the confrontation neural network based on the theme in the training stage; in the testing stage, the text of the target field is input into the trained subject-based confrontation neural network, so that the keywords are extracted. The method can realize keyword extraction of the target field without labels or with a small number of labels, and effectively utilizes the information of the related field compared with the traditional model. The extraction result was improved to some extent by the evaluation index F1.",[]
US12367385B2,Unsupervised learning of memristor crossbar neuromorphic processing systems,An analog neuromorphic circuit is disclosed having a first and a second memristor crossbar configuration implemented into an autoencoder. The first memristor crossbar configuration includes resistive memories that provide resistance values to each corresponding input voltage applied to the first memristor crossbar configuration to generate first output voltages that are compressed from the input voltages. The second memristor crossbar includes resistive memories that provide resistance values to each corresponding first output voltage applied to the second memristor crossbar configuration to generate second output voltages that are decompressed from the first output voltages. A controller compares the second output voltages to the input voltages to determine if the second output voltages are within a threshold of the input voltages. The controller generates an alert when the second output voltages exceed the threshold from the input voltages thereby indicating that input data associated with the input voltages has not been previously identified.,"['G11C11/54', 'G06N3/045', 'G06N3/0455', 'G06N3/048', 'G06N3/0495', 'G06N3/0499', 'G06N3/065', 'G06N3/082', 'G06N3/084', 'G06N3/088', 'G11C13/0002', 'G11C2213/77']"
CN105825511B,A kind of picture background clarity detection method based on deep learning,"The picture background clarity detection method based on deep learning that the invention discloses a kind of, this method are to carry out feature extraction using convolutional neural networks (CNN), and effectively picture is classified according to its clear background degree using the CNN features extracted；Simultaneously using the method for transfer learning, pre-training is carried out with the ImageNet pictures for possessing a large amount of known marks, solves the defect that samples pictures concentrate known background definition values picture less, to obtain preferable CNN parameters；The samples pictures for further utilizing a small amount of known background definition values, are adjusted parameter, make CNN parameter adaptations pictures to be detected；The CNN parameters being adjusted can be carried out the clear background degree detection of picture to be detected.The detection method of the present invention so that clear background degree detects the accuracy that can reach height.","['G06T7/0002', 'G06T2207/20081', 'G06T2207/30168']"
CN110163299B,Visual question-answering method based on bottom-up attention mechanism and memory network,"The invention discloses a visual question-answering method based on a bottom-up attention mechanism and a memory network, which combines the bottom-up image attention mechanism with the memory network, and continuously adjusts parameters through end-to-end training, so that a trained model can carry out visual question-answering, correct answers are predicted, and ideal effects are achieved.","['G06F18/2411', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06V10/25']"
US20230182296A1,Training and/or utilizing machine learning model(s) for use in natural language based robotic control,"Techniques are disclosed that enable training a goal-conditioned policy based on multiple data sets, where each of the data sets describes a robot task in a different way. For example, the multiple data sets can include: a goal image data set, where the task is captured in the goal image; a natural language instruction data set, where the task is described in the natural language instruction; a task ID data set, where the task is described by the task ID, etc. In various implementations, each of the multiple data sets has a corresponding encoder, where the encoders are trained to generate a shared latent space representation of the corresponding task description. Additional or alternative techniques are disclosed that enable control of a robot using a goal-conditioned policy network. For example, the robot can be controlled, using the goal-conditioned policy network, based on free-form natural language input describing robot task(s).","['B25J9/1664', 'B25J9/1656', 'B25J9/163', 'B25J9/1697']"
US11417235B2,"Listen, interact, and talk: learning to speak via interaction","Described herein are systems and methods for grounded natural language learning in an interactive setting. In embodiments, during a learning process, an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. In embodiments, a model is used to incorporate both imitation and reinforcement by leveraging jointly sentence and reward feedback from the teacher. Various experiments are conducted to validate the effectiveness of a model embodiment.","['G06N3/08', 'G06F40/151', 'G06F18/217', 'G06F40/216', 'G06F40/35', 'G06F40/40', 'G06F40/56', 'G06K9/6262', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/091', 'G06N3/092', 'G09B19/04', 'G09B5/06', 'G09B5/12', 'G09B5/125', 'G09B5/14', 'G09B7/04']"
US10778703B2,Method and system for generating an interactive kill chain view for training a machine learning model for identifying threats,"A security platform employs a variety techniques and mechanisms to detect security related anomalies and threats in a computer network environment. The security platform is “big data” driven and employs machine learning to perform security analytics. The security platform performs user/entity behavioral analytics (UEBA) to detect the security related anomalies and threats, regardless of whether such anomalies/threats were previously known. The security platform can include both real-time and batch paths/modes for detecting anomalies and threats. By visually presenting analytical results scored with risk ratings and supporting evidence, the security platform enables network security administrators to respond to a detected anomaly or threat, and to take action promptly.","['G06N20/20', 'G06F16/24578', 'G06F16/254', 'G06F16/285', 'G06F16/444', 'G06F16/9024', 'G06F3/0482', 'G06F3/0484', 'G06F3/04842', 'G06F3/04847', 'G06F40/134', 'G06K9/2063', 'G06N20/00', 'G06N5/022', 'G06N5/04', 'G06N7/005', 'G06N7/01', 'G06V10/225', 'H04L41/0893', 'H04L41/145', 'H04L41/22', 'H04L43/00', 'H04L43/045', 'H04L43/062', 'H04L43/08', 'H04L63/06', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/20', 'H05K999/99', 'H04L2463/121']"
US20200082056A1,Machine-learning model fraud detection system and fraud detection method,"A machine learning model fraud detection system and fraud detection method wherein a license/model management apparatus: generates a test data-trained model by inputting a pre-trained model and test data associated therewith from a licensor apparatus, carrying out learning using the test data on the pre-trained model; stores the test data-trained model in association with the output values obtained when the test data is executed in the test data-trained model; inputs the associated test data into a user model, executes the model when the user model is inputted from a user apparatus using the test data-trained model; compares the output data from the user model with the stored output values from the test data-trained model and detects the fraud if the resulting error is outside tolerance limits.","['G06N20/20', 'G06F18/2185', 'G06F18/2413', 'G06F21/10', 'G06F21/54', 'G06K9/6264', 'G06K9/627', 'G06N20/00', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06F2221/2101', 'G06N20/10', 'G06N3/045', 'G06N3/08', 'G06N5/01']"
US9204796B2,Personal emergency response (PER) system,A system includes one or more sensors to detect activities of a mobile object; and a processor coupled to the sensor and the wireless transceiver to classify sequences of motions into groups of similar postures each represented by a model and to apply the models to identify an activity of the object.,"['A61B5/0022', 'A43B3/42', 'A43B3/46', 'A43B3/48', 'A61B5/0006', 'A61B5/0008', 'A61B5/0013', 'A61B5/002', 'A61B5/0077', 'A61B5/01', 'A61B5/02055', 'A61B5/0402', 'A61B5/0476', 'A61B5/0488', 'A61B5/053', 'A61B5/1112', 'A61B5/1116', 'A61B5/1117', 'A61B5/1118', 'A61B5/318', 'A61B5/369', 'A61B5/384', 'A61B5/389', 'A61B5/395', 'A61B5/6803', 'A61B5/6806', 'A61B5/6807', 'A61B5/681', 'A61B5/6824', 'A61B5/6826', 'A61B5/6891', 'A61B5/7264', 'A61B7/00', 'A61B7/04', 'A61B7/045', 'A61B8/00', 'A61B8/06', 'A61B8/488', 'A61B8/565', 'G06F19/3418', 'G06F19/345', 'G08B21/02', 'G08B21/0423', 'G08B21/0446', 'G08B21/0492', 'G08B25/016', 'G16H15/00', 'G16H40/67', 'G16H50/20', 'G16H80/00', 'G16Z99/00', 'H04M3/5116', 'A61B2562/0219', 'A61B5/0261', 'A61B8/0808', 'G06F19/3462', 'G06F19/3487', 'G08B21/0453', 'G08B21/0461', 'G08B21/0476', 'G08B21/0484', 'G16H20/13', 'G16H20/30', 'H04M2250/12', 'H04W84/18']"
CN114266891B,Railway operation environment abnormality identification method based on image and laser data fusion,"The invention provides a railway operation environment anomaly identification method based on image and laser data fusion, which comprises the steps of firstly carrying out feature analysis and data preprocessing on point cloud data, utilizing a large-scale point cloud semantic segmentation model based on random sampling-feature aggregation-prototype fitting to segment the point cloud data, utilizing an improved Euclidean algorithm to cluster the point cloud, utilizing a deep learning example segmentation method based on transfer learning to identify a target, and finally utilizing a method of fusing the point cloud data with a visible light image identification result serial decision layer to realize intelligent identification of railway operation environment anomalies. The method has the advantages of accurate and comprehensive results, high fault tolerance and the like, and simultaneously proves the significance of multisource data fusion on the abnormal identification of the railway running environment.",['Y02T10/40']
US8768731B2,Syndicating ultrasound echo data in a healthcare environment,"Disclosed herein are systems and methods for syndication and management of structured and unstructured data to assist institutional healthcare delivery, healthcare providers' practices, healthcare providers' group practices, collaborative academic research and decision making in healthcare, including through the utilization of medical devices and healthcare pools.","['G16H10/60', 'G06F19/322', 'G06F16/958', 'G06F21/6254', 'G06F21/6263', 'G06Q10/10', 'G06Q50/24', 'G16H20/40', 'G16H70/20', 'H04L63/20', 'H04L67/00', 'H04L67/02', 'G16H40/20', 'Y02P90/84']"
US11695682B2,Optimizing Border Gateway Protocol (BGP) traffic using reinforcement learning,"Systems, methods, and computer-readable media including software logic are provided for optimizing Border Gateway Protocol (BGP) traffic in a telecommunications network. In one embodiment, systems and methods include, with a current state of one or more inter-Autonomous Systems (AS) links, causing performance of an action in the telecommunication network, determining a metric based on the action to determine an updated current state of the one or more inter-AS links, and utilizing the metric to perform a further action to achieve one or more rewards associated with the one or more inter-AS links.","['H04L43/087', 'H04L45/08', 'G06F30/20', 'H04L41/046', 'H04L41/16', 'H04L41/5067', 'H04L43/0805', 'H04L43/0829', 'H04L43/0852', 'H04L45/04', 'H04L45/70', 'H04L45/124']"
US12046063B2,Table information extraction and mapping to other documents,"The accuracy of existing machine learning models, software technologies, and computers are improved by using one or more machine learning models to map data inside structural elements, such as rows or columns, as found within a document to data objects of other documents, where the data objects are at least partially indicative of candidate categories that the data can belong to.","['G06V30/142', 'G06V30/412', 'G06F18/22', 'G06F40/30', 'G06V30/1448', 'G06V30/413', 'G06V30/414', 'G06V2201/07', 'G06V30/18067']"
US12387040B2,Model for textual and numerical information retrieval in documents,"The accuracy of existing machine learning models, software technologies, and computers are improved by using one or more machine learning models to predict a type of data that one or more numerical characters and/or one or more natural language word characters of a document correspond to. For instance, a Question Answering systems can be used to predict that a particular number value corresponds to a date, a billing amount, a page number, or the like.","['G06F40/295', 'G06F40/279', 'G06F16/93', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/096', 'G06Q10/10', 'G06Q30/04', 'G06Q40/12', 'G06N3/0442']"
US12175188B2,"Sentence paraphrase method and apparatus, and method and apparatus for training sentence paraphrase model","This disclosure relates to a natural language processing technology, and provides a sentence paraphrase method and apparatus. The method includes: paraphrasing an input sentence by using a sentence paraphrase model, to generate a plurality of candidate paraphrased sentences; and determining a similarity between each of the plurality of candidate paraphrased sentences and the input sentence, to obtain an output sentence whose similarity to the input sentence is greater than or equal to a preset threshold, where each of a plurality of paraphrased sentence generators in the sentence paraphrase model includes one neural network, the plurality of paraphrased sentence generators are trained by using source information and similarity information as a first reward, and the paraphrased sentence is obtained by paraphrasing the training sentence by using the plurality of paraphrased sentence generators. In the sentence paraphrase method, diversity of a paraphrased sentence and quality of the paraphrased sentence can be improved.","['G06F40/166', 'G06N3/08', 'G06F17/00', 'G06F40/20', 'G06F40/247', 'G06F40/40', 'G06F40/56', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06F40/30', 'G06N3/044']"
US11573557B2,Methods and systems of industrial processes with self organizing data collectors and neural networks,"Systems and methods for data collection for an industrial heating process are disclosed. The system according to one embodiment can include a plurality of data collectors, including a swarm of self-organized data collector members, wherein the swarm of self-organized data collector members organize to enhance data collection based on at least one of capabilities and conditions of the data collector members of the swarm, and wherein the plurality of data collectors is coupled to a plurality of input channels for acquiring collected data relating to the industrial heating process, and a data acquisition and analysis circuit for receiving the collected data via the plurality of input channels and structured to analyze the received collected data using a neural network to monitor a plurality of conditions relating to the industrial heating process.","['H04B17/29', 'B62D15/0215', 'G01M13/028', 'G01M13/04', 'G01M13/045', 'G05B13/028', 'G05B19/4183', 'G05B19/4184', 'G05B19/41845', 'G05B19/4185', 'G05B19/41865', 'G05B19/41875', 'G05B23/0221', 'G05B23/0229', 'G05B23/024', 'G05B23/0264', 'G05B23/0283', 'G05B23/0286', 'G05B23/0289', 'G05B23/0291', 'G05B23/0294', 'G05B23/0297', 'G06F16/2477', 'G06F18/2178', 'G06F3/0608', 'G06F3/0619', 'G06F3/0635', 'G06F3/067', 'G06K9/6263', 'G06N20/00', 'G06N3/006', 'G06N3/02', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N5/046', 'G06N7/005', 'G06N7/01', 'G06Q10/04', 'G06Q10/0639', 'G06Q30/02', 'G06Q30/0278', 'G06Q30/06', 'G06Q50/00', 'G06V10/7784', 'G06V10/82', 'G16Z99/00', 'H02M1/12', 'H03M1/12', 'H04B17/26', 'H04B17/309', 'H04B17/318', 'H04B17/345', 'H04L1/0002', 'H04L1/0041', 'H04L1/18', 'H04L1/1874', 'H04L67/1097', 'H04L67/12', 'H04W4/38', 'H04W4/70', 'B62D5/0463', 'F01D21/003', 'F01D21/12', 'F01D21/14', 'G05B19/042', 'G05B2219/32287', 'G05B2219/35001', 'G05B2219/37337', 'G05B2219/37351', 'G05B2219/37434', 'G05B2219/37537', 'G05B2219/40115', 'G05B2219/45004', 'G05B2219/45129', 'G05B23/02', 'G05B23/0208', 'G06F17/18', 'G06F18/21', 'G06F18/217', 'G06F18/25', 'G06K9/6288', 'G06N3/126', 'H04B17/23', 'H04B17/40', 'H04L1/0009', 'H04L5/0064', 'H04L67/306', 'Y02P80/10', 'Y02P90/02', 'Y02P90/80', 'Y04S50/00', 'Y04S50/12', 'Y10S707/99939']"
CN107251060B,Pre-training and/or transfer learning for sequence taggers,"Systems and methods are provided for pre-training sequence taggers using unlabeled data, such as hidden layered conditional random field models. Additionally, systems and methods for transfer learning are provided. Thus, the systems and methods construct more accurate, reliable, and/or efficient sequence taggers than previously utilized sequence taggers that were not pre-trained with unlabeled data and/or that were not capable of migration learning/training.","['G10L15/063', 'G06N7/01', 'G06F16/35', 'G06F40/289', 'G06N20/00', 'G10L15/18', 'G10L2015/0631']"
US12002276B2,Document distinguishing based on page sequence learning,"The accuracy of existing machine learning models, software technologies, and computers are improved by estimating whether a particular page belongs to a same document as another page or whether the page belongs to a different document. Such document distinguishing can be based on deriving relationship information between a first feature vector representing the page and a second feature vector representing the other page. This also improves the user experience and model building experience, among other things.","['G06V30/416', 'G06F16/355', 'G06F16/93', 'G06N20/00', 'G06N3/049', 'G06V30/412', 'G06Q30/04']"
US20200160212A1,Method and system for transfer learning to random target dataset and model structure based on meta learning,"Disclosed are a method and system for transfer learning to a random target dataset and model structure based on meta learning. A transfer learning method may include determining the form and amount of information to be transferred, used by a pre-trained model, using a meta model based on similarity between a source dataset and a new target dataset and performing transfer-learning on a target model using the form and amount of information of the pre-trained model determined by the meta model.","['G06N3/096', 'G06N3/088', 'G06N20/00', 'G06N3/045', 'G06N3/0985']"
US10909329B2,Multilingual image question answering,"Embodiments of a multimodal question answering (mQA) system are presented to answer a question about the content of an image. In embodiments, the model comprises four components: a Long Short-Term Memory (LSTM) component to extract the question representation; a Convolutional Neural Network (CNN) component to extract the visual representation; an LSTM component for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. A Freestyle Multilingual Image Question Answering (FM-IQA) dataset was constructed to train and evaluate embodiments of the mQA model. The quality of the generated answers of the mQA model on this dataset is evaluated by human judges through a Turing Test.","['G06F16/538', 'G06N5/04', 'G06F40/56', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/048']"
US11734571B2,Method and apparatus for determining a base model for transfer learning,"Methods and apparatuses for accurately determining a model, which is to be the basis of transfer learning, among a plurality of source models, are provided. According to an embodiment, an apparatus for determining a base model to be used for transfer learning to a target domain is provided. The apparatus comprises a memory which comprises one or more instructions and a processor which executes the instructions to construct a neural network model for measuring suitability of a plurality of pre-trained source models, measure the suitability of each of the source models by inputting data of the target domain to the neural network model, and determine the base model to be used for the transfer learning among the source models based on the suitability.","['G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096']"
US20210089921A1,Transfer learning for neural networks,"Transfer learning can be used to enable a user to obtain a machine learning model that is fully trained for an intended inferencing task without having to train the model from scratch. A pre-trained model can be obtained that is relevant for that inferencing task. Additional training data, as may correspond to at least one additional class of data, can be used to further train this model. This model can then be pruned and retrained in order to obtain a smaller model that retains high accuracy for the intended inferencing task.","['G06N3/082', 'G06N3/045', 'G06N5/04']"
US10268888B2,Method and apparatus for biometric data capture,A method and apparatus for biometric data capture are provided. The apparatus includes in interactive head-mounted eyepiece worn by a user that includes an optical assembly through which a user views a surrounding environment and displayed content. The optical assembly comprises a corrective element that corrects the user's view of the surrounding environment and an integrated processor for handling content to the user. An integrated optical sensor captures biometric data when the eyepiece is positioned so that a nearby individual is proximate to the eyepiece. Biometric data is captured using the eyepiece and is transmitted to a remote processing facility for interpretation. The remote processing facility interprets the captured biometric data and generates display content based on the interpretation. This display content is delivered to the eyepiece and displayed to the user.,"['G02B27/017', 'G06V40/19', 'G06K9/00604', 'G02B27/0172', 'G02C11/10', 'G06F1/1673', 'G06F3/012', 'G06F3/013', 'G06F3/017', 'G06F3/0481', 'G06F3/14', 'G06K9/00617', 'G06Q30/02', 'G06Q30/0261', 'G06V40/197', 'H04N23/55', 'H04N23/635', 'H04N23/661', 'H04N5/2254', 'H04N5/23293', 'H04N5/44', 'G02B2027/0138', 'G02B2027/0178', 'G06F3/011', 'G06F3/014']"
US11900261B2,Transfer learning system for automated software engineering tasks,A transfer learning system is used for the development of neural transformer models pertaining to software engineering tasks. The transfer learning system trains source code domain neural transformer models with attention in various configurations on a large corpus of unsupervised training dataset of source code programs and/or source code-related natural language text. A web service provides the trained models for use in developing a model that may be fine-tuned on a supervised training dataset associated with a software engineering task thereby generating a tool to perform the software engineering task.,"['G06N3/088', 'G06F8/20', 'G06F40/30', 'G06F40/40', 'G06F8/30', 'G06F8/35', 'G06F8/51', 'G06N3/045', 'G06N3/0455', 'G06N3/0495', 'G06N3/0499', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06F8/427', 'G06F8/71', 'G06F8/73', 'G06N20/00', 'G06N3/04', 'G06N3/063', 'G06N3/08']"
US11087883B1,Systems and methods for transfer-to-transfer learning-based training of a machine learning model for detecting medical conditions,"Systems and methods for transfer-to-transfer training using an imbalanced training dataset include reconfiguring an imbalanced training data corpus to a plurality of distinct class-balanced mini-corpora of training data, wherein the reconfiguring includes: (i) partitioning the imbalanced training data corpus into a plurality of mini-corpora of training data samples in which each distinct mini-corpus of the plurality of mini-corpora includes an entirety of the training data samples within the second subset of training data samples; and (ii) allocating an equal number of the training data samples of the first subset into each of the plurality of mini-corpora of training data samples; and transfer-to-transfer learning-based training a subject machine learning algorithm to a trained machine learning model based on implementing the transfer-to-transfer learning-based training using the plurality of distinct class-balanced mini-corpora, wherein in use, the trained machine learning model predicts a presence or a non-presence of COVID-19 based on image data.","['G06T7/0012', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06K9/627', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/11', 'G06V10/26', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/031']"
AU2020369228B2,Private transfer learning,A method for private transfer learning is disclosed. The method includes generating a machine learning model comprising a training application programming interface (API) and an inferencing API. The method further includes encrypting the machine learning model using a predetermined encryption mechanism. The method additionally includes copying the encrypted machine learning model to a trusted execution environment. The method also includes executing the machine learning model in the trusted execution environment using the inferencing API.,"['G06N3/08', 'G06F21/602', 'G06F21/74', 'G06F21/53', 'G06F21/6236', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06F2221/031', 'G06N3/047']"
US20200104710A1,Training machine learning models using adaptive transfer learning,"A method for training a target neural network on a target machine learning task is described. The method includes: obtaining a target dataset for training the target neural network on the target machine learning task, the target dataset comprising a plurality of target training examples; obtaining a source dataset for training a source neural network on a source machine learning task, the source dataset comprising a plurality of source training examples; wherein each of the target neural network and the source neural network has the same feature neural network layers having feature layer parameters, the target neural network further comprises one or more target classification layers having target classification parameters, and the source neural network further comprises one or more source classification layers having source classification parameters; generating, from the source training examples in the source dataset, a pre-training dataset using the source dataset and the target dataset so that the pre-training dataset captures features that are relevant to the target dataset; training the source neural network on the source machine learning task using the pre-training dataset to obtain first values of the feature layer parameters and the source classification parameters; initializing the feature layer parameters of the target neural network using the first values of the feature layer parameters from the training of the source neural network; and training the target neural network on the target machine learning task using the target dataset to obtain trained values of the feature layer parameters and the target classification parameters.","['G06N3/08', 'G06N3/045', 'G06N3/0454']"
US9107586B2,Fitness monitoring,"A mobile system for a user includes a telephone having one or more sensors to capture fitness data or vital sign data, the telephone having a wireless transceiver coupled to the processor to communicate fitness or vital sign data over a personal area network; and a processor coupled to the personal area network to process the fitness or vital sign data.","['A61B5/002', 'A61B5/0022', 'A61B5/0205', 'A61B5/026', 'A61B5/0295', 'A61B5/0476', 'A61B5/0488', 'A61B5/0537', 'A61B5/11', 'A61B5/1112', 'A61B5/1113', 'A61B5/1114', 'A61B5/1116', 'A61B5/1117', 'A61B5/1118', 'A61B5/14532', 'A61B5/33', 'A61B5/369', 'A61B5/389', 'A61B5/4076', 'A61B5/411', 'A61B5/4803', 'A61B5/4806', 'A61B5/681', 'A61B5/6816', 'A61B5/6822', 'A61B5/6826', 'A61B5/6838', 'A61B5/6898', 'A61B5/7203', 'A61B5/7225', 'A61B5/7267', 'A61B5/7271', 'A61B5/7435', 'A61B5/7455', 'A61B5/7465', 'A61B5/7475', 'A61B8/565', 'G06F19/3406', 'G06F19/3418', 'G06F19/345', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'A61B2505/01', 'A61B2560/0214', 'A61B2560/0223', 'A61B2560/0468', 'A61B2562/0219', 'A61B5/0006', 'A61B5/0008', 'A61B5/02055', 'A61B5/02438', 'A61B5/04004', 'A61B5/0402', 'A61B5/1038', 'A61B5/112', 'A61B5/1124', 'A61B5/1128', 'A61B5/1176', 'A61B5/224', 'A61B5/30', 'A61B5/318', 'A61B5/4023', 'A61B5/4519', 'A61B5/4528', 'A61B5/7214', 'A61B5/726', 'A61B5/743', 'A61B8/0808', 'A61B8/56', 'G06F19/321', 'G06F19/322', 'G06F19/3456', 'G16H10/60', 'G16H20/60', 'G16H30/20']"
US20230299872A1,Neural Network-Based Communication Method and Related Apparatus,"Embodiments of this application disclose a neural network-based communication method and a related apparatus. Specifically, joint training optimization is performed on an encoding neural network used by a transmit end and a decoding neural network used by a receive end. A first neural network in the encoding neural network reuses the decoding neural network and a parameter of the decoding neural network.","['H04L25/03165', 'H04L1/0009', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/092', 'G06N3/0985', 'H04L1/0041', 'H04L1/0045', 'G06N3/006', 'G06N3/088', 'G06N3/096', 'H04L1/0054']"
US8230343B2,"Audio and video program recording, editing and playback systems using metadata","A system for utilizing metadata created either at a central location for shared use by connected users, or at each individual user's location, to enhance user's enjoyment of available broadcast programming content. A variety of mechanisms are employed for automatically and manually identifying and designating programming segments, associating descriptive metadata which the identified segments, distributing the metadata for use at client locations, and using the supplied metadata to selectively record and playback desired programming.","['G10H1/0033', 'G06F16/735', 'G06F16/739', 'G06F16/745', 'G06F16/7867', 'G11B27/105', 'G11B27/28', 'G11B27/322', 'G11B27/34', 'H04H20/28', 'H04H60/13', 'H04H60/37', 'H04H60/39', 'H04H60/73', 'H04H60/80', 'H04N21/2543', 'H04N21/25891', 'H04N21/26258', 'H04N21/4147', 'H04N21/426', 'H04N21/4331', 'H04N21/4334', 'H04N21/4335', 'H04N21/439', 'H04N21/44008', 'H04N21/44224', 'H04N21/4532', 'H04N21/458', 'H04N21/4622', 'H04N21/4663', 'H04N21/47', 'H04N21/47202', 'H04N21/47205', 'H04N21/47214', 'H04N21/4756', 'H04N21/4782', 'H04N21/4788', 'H04N21/482', 'H04N21/4825', 'H04N21/6125', 'H04N21/632', 'H04N21/812', 'H04N21/8352', 'H04N21/84', 'H04N21/845', 'H04N21/8456', 'H04N21/8547', 'H04N21/8586', 'H04N5/775', 'H04N7/17318', 'H04N7/17354', 'G10H2240/125', 'G10H2240/131', 'G10H2240/155', 'H04H60/82', 'H04N21/485', 'H04N5/76']"
US11561544B2,Indoor monocular navigation method based on cross-sensor transfer learning and system thereof,"The present disclosure relates to an indoor monocular navigation method based on cross-sensor transfer learning and a system thereof. Determining an preliminary autonomous navigation model according to simulated laser radar data; acquiring actual single-line laser radar data and monocular camera data of the mobile robot simultaneously in an actual environment; determining the heading angle of the mobile robot according to the actual laser radar data; determining a laser radar monocular vision navigation model, according to the generated heading angle of the mobile robot and the monocular camera data at a the same moment and by using a Resnet18 network and a pre-trained YOLO v3 network; determining a heading angle of the mobile robot at the current moment, according to the acquired monocular camera data and by using the laser radar monocular vision navigation model; performing navigation of the mobile robot.","['G05D1/0088', 'G01C21/005', 'G01C21/206', 'G01S17/86', 'G01S17/89', 'G01S17/931', 'G05D1/0221', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/096']"
CN111723738B,Coal rock chitin group microscopic image classification method and system based on transfer learning,"The invention discloses a coal rock shell group microscopic image classification method and system based on transfer learning, which belong to the technical field of image processing and comprise the following steps: s1: collecting and expanding the number of samples; s2: obtaining a pre-training model; s3: constructing a coal rock chitin group micro-component identification model; s4: component identification is performed. In the step S1, the data enhancement process is as follows: s11, performing S11; dividing the acquired sample into a training set and a testing set S12; and carrying out random scaling, random horizontal translation and vertical translation on the images in the training set, and realizing data expansion. According to the invention, the target data set is trained by sharing the parameters of the convolution layer and the pooling layer in the pre-training network based on the transfer learning method, so that a model with good generalization capability can be trained under the condition of limited sample size of the chitin group, the effective classification of the coal rock mantle quality images is realized, and the method is worthy of popularization and use.","['G06V20/695', 'G06N3/045', 'G06N3/08', 'G06V20/698']"
US20230078218A1,Training object detection models using transfer learning,"Apparatuses, systems, and techniques for training an object detection model using transfer learning.","['G06N20/20', 'G06V10/82', 'G06F18/2431', 'G06K9/00624', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/096', 'G06N3/098', 'G06V20/00', 'G06N3/044']"
US12260622B2,"Systems, methods, and apparatuses for the generation of source models for transfer learning to application specific models used in the processing of medical imaging","Described herein are means for generating source models for transfer learning to application specific models used in the processing of medical imaging. In some embodiments, the method comprises: identifying a group of training samples, wherein each training sample in the group of training samples includes an image; for each training sample in the group of training samples: identifying an original patch of the image corresponding to the training sample; identifying one or more transformations to be applied to the original patch; generating a transformed patch by applying the one or more transformations to the identified patch; and training an encoder-decoder network using a group of transformed patches corresponding to the group of training samples, wherein the encoder-decoder network is trained to generate an approximation of the original patch from a corresponding transformed patch, and wherein the encoder-decoder network is trained to minimize a loss function that indicates a difference between the generated approximation of the original patch and the original patch. The source models significantly enhance the transfer learning performance for many medical imaging tasks including, but not limited to, disease/organ detection, classification, and segmentation. Other related embodiments are disclosed.","['G06N3/088', 'G06V10/7747', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/776', 'G06V10/82', 'G06V10/98', 'G06V2201/03']"
US20190354850A1,Identifying transfer models for machine learning tasks,"Techniques regarding autonomously facilitating the selection of one or more transfer models to enhance the performance of one or more machine learning tasks are provided. For example, one or more embodiments described herein can comprise a system, which can comprise a memory that can store computer executable components. The system can also comprise a processor, operably coupled to the memory, and that can execute the computer executable components stored in the memory. The computer executable components can comprise an assessment component that can assess a similarity metric between a source data set and a sample data set from a target machine learning task. The computer executable components can also comprise an identification component that can identify a pre-trained neural network model associated with the source data set based on the similarity metric to perform the target machine learning task.","['G06N3/08', 'G06F18/214', 'G06F18/22', 'G06N20/00', 'G06N3/045', 'G06N5/02', 'G06N5/022', 'G06N99/005', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06N7/01']"
CN110705406B,Face Beauty Prediction Method and Device Based on Adversarial Transfer Learning,"The invention discloses a method and a device for predicting facial beauty based on anti-migration learning, which implement the following steps that the method comprises the steps of screening the auxiliary tasks with highest relevance from a plurality of facial factor recognition tasks through similarity measurement, and constructing a first facial beauty prediction model according to the auxiliary tasks; migrating the general characteristic parameters formed after the confrontation network is pre-trained to a second face beauty prediction model; and inputting the face image to be detected to realize identification. The training cost of pre-training is reduced, and negative migration caused by auxiliary tasks with irrelevant factors is reduced; the amount of calculation of retraining the second face beauty prediction model is reduced through resisting transfer learning, and the effect of obtaining a more accurate model by using fewer training images is achieved.","['G06V40/161', 'G06N3/08', 'G06V40/168', 'G06V40/172']"
US11853877B2,Training transfer-focused models for deep learning,Whether to train a new neural network model can be determined based on similarity estimates between a sample data set and a plurality of source data sets associated with a plurality of prior-trained neural network models. A cluster among the plurality of prior-trained neural network models can be determined. A set of training data based on the cluster can be determined. The new neural network model can be trained based on the set of training data.,"['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096']"
CN112101335B,APP violation monitoring method based on OCR and transfer learning,"The invention discloses an APP violation monitoring method based on OCR and transfer learning, which comprises the following steps: periodically updating the APK, and acquiring data of the corresponding APP according to the updated APK, wherein the data acquisition comprises a data packet capture and a page screenshot; performing character recognition and extraction on the screenshot based on an OCR algorithm; constructing a sample set for the recognized text contents through keywords and a regular expression, and manually marking; inputting the manually marked sample set into a pre-trained deep learning model for model adjustment, and realizing violation judgment of texts in different scenes by dividing service scenes; and according to the discrimination result output by the deep learning model, counting the scores of different APPs to obtain the violation score of the APP. According to the invention, the illegal use condition of the APP is effectively and quickly detected by collecting and analyzing the data of the APP.","['G06V10/22', 'G06F16/951', 'G06F16/955', 'G06F18/241', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06V2201/09', 'G06V30/10']"
US8370362B2,Database access system,"An improved human user computer interface system, wherein a user characteristic or set of characteristics, such as demographic profile or societal “role”, is employed to define a scope or domain of operation. The operation itself may be a database search, to interactively define a taxonomic context for the operation, a business negotiation, or other activity. After retrieval of results, a scoring or ranking may be applied according to user define criteria, which are, for example, commensurate with the relevance to the context, but may be, for example, by date, source, or other secondary criteria. A user profile is preferably stored in a computer accessible form, and may be used to provide a history of use, persistent customization, collaborative filtering and demographic information for the user. Advantageously, user privacy and anonymity is maintained by physical and algorithmic controls over access to the personal profiles, and releasing only aggregate data without personally identifying information or of small groups.","['G06Q30/0275', 'G06F16/2457', 'G06F16/24578', 'G06F16/248', 'G06F16/3323', 'G06F21/6245', 'G06Q30/0212', 'G06Q30/0226', 'G06Q30/0242', 'G06Q30/0247', 'G06Q30/0269', 'G06Q30/0277', 'Y10S707/99932', 'Y10S707/99933']"
CN110929610B,Plant disease identification method and system based on CNN model and transfer learning,"The invention provides a plant disease identification method based on a CNN model and transfer learning, which comprises the following steps: constructing an original image data set, wherein the original image data set comprises various plant disease images; performing data enhancement on the original data set to obtain a new training data set; constructing a model; obtaining pre-training model parameters in the model and setting parameters of a bottleneck layer; extracting and storing parameters of the bottleneck layer to obtain a plant disease identification model; and identifying the plant disease image according to the plant disease identification model, and obtaining and displaying the identification result of the plant disease. According to the invention, the images are directly input into the network, so that the disease spot segmentation and the complex background segmentation processes of the plant leaves are avoided, and the complexity of data modeling in the identification process is reduced. The method is suitable for not only the disease spots, but also the powdery disease and the granular disease of the leaves, and has recognition capability for complex natural environment and objects around the object.","['G06V20/188', 'G06F18/241']"
US20240242487A1,Transfer learning in image recognition systems,Visual Prompt Tuning provides fine-tuning for transformer-based vision models. Prompt Vectors are added as additional inputs to Vision Transformer models. alongside image patches which have been linearly projected and combined with a positional embedding. The transformer architecture allows prompts to be optimized using gradient descent. without modifying or removing any of the Vision Transformer parameters. A Image Recognition System with Visual Prompt Tuning improves a pre-trained vision model by adapting the pre-trained vision model to downstream tasks by tuning the pretrained vision model using a visual prompt.,"['G06V10/7747', 'G06V10/82', 'G06N3/0455', 'G06N3/0464', 'G06N3/096', 'G06V10/469', 'G06V10/764', 'G06V10/774']"
CN109754017B,A method for hyperspectral image classification based on separable 3D residual networks and transfer learning,"The invention relates to a hyperspectral image classification method based on a separable three-dimensional residual error network and transfer learning. Secondly, a migration technology between hyperspectral images acquired by different sensors is designed to be combined with a three-dimensional convolution network model, and high-precision classification of the hyperspectral images under the condition of small samples is achieved. The method realizes the autonomous extraction and high-precision classification of the depth features of the hyperspectral images under the condition of small samples. Compared with the existing hyperspectral image classification method based on deep learning, the hyperspectral image classification method based on deep learning has the advantages of deeper network model, higher precision and less parameter quantity.",[]
US10909407B2,Transfer learning of convolutional neural networks from visible color (RBG) to infrared (IR) domain,Described is a system for converting a convolutional neural network (CNN) designed and trained for color (RGB) images to one that works on infrared (IR) or grayscale images. The converted CNN comprises a series of convolution layers of neurons arranged in a set kernels having corresponding depth slices. The converted CNN is used for performing object detection. A mechanical component of an autonomous device is controlled based on the object detection.,"['G06K9/4628', 'G06N3/082', 'G06F18/214', 'G06F18/24', 'G06K9/6256', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/56', 'H04N1/40012']"
US11809828B2,Systems and methods of data augmentation for pre-trained embeddings,"Systems and methods are provided for generating textual embeddings by tokenizing text data and generating vectors to be provided to a transformer system, where the textual embeddings are vector representations of semantic meanings of text that is part of the text data. The vectors may be averaged for every token of the generated textual embeddings and concatenating average output activations of two layers of the transformer system. Image embeddings may be generated with a convolutional neural network (CNN) from image data, wherein the image embeddings are vector representations of the images that are part of the image data. The textual embeddings and image embeddings may be combined to form combined embeddings to be provided to the transformer system.","['G06F40/30', 'G06F17/18', 'G06F18/214', 'G06F18/2431', 'G06F18/251', 'G06F40/151', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06V10/40', 'G06V10/764', 'G06V10/803', 'G06V10/82', 'G06N20/00']"
US20210110306A1,Meta-transfer learning via contextual invariants for cross-domain recommendation,"Systems, apparatuses, methods, and computer-readable media are provided to alleviate data sparsity in cross-recommendation systems. In particular, some embodiments are directed to a recommendation framework that addresses data sparsity and data scalability challenges seamlessly by meta-transfer learning contextual invariances cross domain, e.g., from dense source domain to sparse target domain. Other embodiments may be described and/or claimed.","['G06N3/08', 'G06N20/00', 'G06N3/045', 'G06N5/04']"
US8666544B2,Cooperative minimally invasive telesurgical system,"Improved robotic surgical systems, devices, and methods include selectably associatable master/slave pairs, often having more manipulator arms than will be moved simultaneously by the two hands of a surgeon. Four manipulator arms can support an image capture device, a left hand tissue manipulation tool, a right hand tissue manipulation tool, and a fourth surgical instrument, particularly for stabilizing, retracting, tool change, or other functions benefiting from intermittent movement. The four or more arms may sequentially be controlled by left and right master input control devices. The fourth arm may be used to support another image capture device, and control of some or all of the arms may be transferred back-and-forth between the operator and an assistant. Two or more robotic systems each having master controls and slave manipulators may be coupled to enable cooperative surgery between two or more operators.","['A61B34/35', 'A61B34/30', 'A61B34/37', 'G09B23/285', 'G16H20/40', 'G16H30/20', 'G16H40/63', 'A61B2017/00199', 'A61B2034/305', 'A61B2034/742', 'A61B2090/506', 'A61B34/76', 'A61B90/361']"
CN113128613B,A semi-supervised anomaly detection method based on transfer learning,"A semi-supervised anomaly detection method based on transfer learning constructs a convolutional neural network for anomaly detection, wherein the convolutional neural network comprises a networkAnd a networkTwo network modules, and a fully-connected layer for feature fusion, respectively pre-training the network with anomaly detection dataset and an uncorrelated tagged reference datasetAnd a networkThen the network obtained by pre-trainingAnd a networkAnd performing joint training, and performing anomaly detection on the convolutional neural network obtained by training. The invention is assisted by a reference data set through a transfer learning method, thereby realizing semi-supervised anomaly detection, the network model can fully utilize the labeling information in the data, the distinguishing capability of normal samples and abnormal samples is improved, and the robustness of the model to polluted data is enhanced. Use of the inventionThe AUC index of the model trained by the method is improved from 72.2% to 75.9%, so that the detection accuracy is effectively improved.","['G06F18/2433', 'G06F18/241', 'G06N3/045', 'G06N3/08']"
CN110472698B,A real-time prediction method for metal additive forming penetration based on deep and transfer learning,"The invention discloses a laser metal additive manufacturing penetration prediction system based on deep learning and transfer learning, which comprises a printing workbench, an image acquisition device, a thermal imager, a human-computer interaction device, a display and a host, wherein the image acquisition device, the thermal imager, the human-computer interaction device and the display are electrically connected with the host. According to the method, the molten pool image and the temperature image are continuously acquired under a certain time sequence, the effective molten pool image and the temperature image are normalized firstly, so that the parameters of the picture size and the pixel size of the molten pool image are kept consistent, other irrelevant features are eliminated in the deep learning convolutional neural network model during training, only the key features are trained, and the method has the advantage of improving the training efficiency of the deep learning convolutional neural network model; and the depth learning convolutional neural network model is adopted to predict the penetration, so that the precision of the parameters can be effectively improved.","['G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08']"
WO2022217849A1,Methods and systems for training neural network model for mixed domain and multi-domain tasks,"Methods and systems for training a neural network model using domain mixing and multi-teacher knowledge distillation are described. Tokens, including a unique token, are inputted to an encoder of the neural network model. A unique embedding vector encoded from the unique token is inputted to an adaptor network to generate domain probabilities. A domain mixing embedding vector, determined from the unique embedding vector, is inputted to a predictor of the neural network model, to generate a predicted output. A final loss is computed using a domain mixing loss computed from the domain probabilities and a ground-truth domain of the data sample, and using an output prediction loss computed from the predicted output and a ground-truth label of the data sample. Parameters of the neural network model and adaptor network are updated using the final loss.","['G06N3/045', 'G06N3/084', 'G06N3/08']"
CN112560665B,A professional dance evaluation method for human pose detection based on deep transfer learning,"The invention relates to a professional dance evaluation method for realizing human posture detection based on deep transfer learning, which comprises the following steps: step S1: establishing a special human body posture detection model by utilizing a deep migration learning principle and combining the posture characteristics of professional dance training; step S2: collecting videos of the exemplary dance movements, inputting the videos into the human body posture detection model, and obtaining a human body key point data stream which changes along with time as a reference standard for evaluation; step S3: and obtaining the human body key point information of the dance motion of the tested person in the same way, and taking the similarity between the human body key point information and the reference standard as the evaluation of the dance gesture standard degree. The invention improves the efficiency and the accuracy of model training by utilizing deep migration learning.","['G06V40/20', 'G06F18/22', 'G06N3/045', 'G06N3/08', 'G06V20/46']"
US20210042916A1,Deep learning-based diagnosis and referral of diseases and disorders,"Disclosed herein are systems, methods, devices, and media for carrying out medical diagnosis of diseases and conditions using artificial intelligence or machine learning approaches. Deep learning algorithms enable the automated analysis of medical images such as X-rays to generate predictions of comparable accuracy to clinical experts for various diseases and conditions including those afflicting the lung such as pneumonia.","['G06T7/0012', 'G16H30/40', 'A61B6/50', 'G06N3/04', 'G06N3/08', 'G16H50/20', 'G16H50/70', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'Y02A90/10']"
US10572828B2,Transfer learning and domain adaptation using distributable data models,"A system for transfer learning and domain adaptation using distributable data models is provided, comprising a network-connected distributable model configured to serve instances of a plurality of distributable models; and a directed computation graph module configured to receive at least an instance of at least one of the distributable models from the network-connected computing system, create a second dataset from machine learning performed by a transfer engine, train the instance of the distributable model with the second dataset, and generate an update report based at least in part by updates to the instance of the distributable model.","['G06N20/00', 'G06F16/215', 'G06F16/27', 'G06F18/214', 'G06F18/295', 'G06K9/00979', 'G06K9/6256', 'G06K9/6297', 'G06N7/005', 'G06N7/01', 'G06V10/95']"
US11620505B2,Neuromorphic package devices and neuromorphic computing systems,"A neuromorphic package device includes a systolic array package and a controller. The systolic array package includes neuromorphic chips arranged in a systolic array along a first direction and a second direction. The controller communicates with a host controls the neuromorphic chips. Each of the neuromorphic chips sequentially transfers weights of a plurality layers of a neural network system in the first direction to store the weights. A first neuromorphic chip performs a calculation based on stored weights therein and an input data received in the second direction, and provides a result of the calculation to at least one of a second neuromorphic chip and a third neuromorphic chip which are adjacent to the first neuromorphic chip. The at least one of the second and third neuromorphic chips performs a calculation based on a provided result of the calculation and stored weights therein.","['G06N3/065', 'G06N3/0635', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G11C11/54', 'G11C13/0007', 'G11C13/003', 'G11C2213/15', 'G11C2213/79']"
CN113806527B,Cross-lingual unsupervised classification with multi-view transfer learning,"Cross-language unsupervised classification with multi-view transfer learning is presented herein. Embodiments of an unsupervised cross-language emotion classification model (which may be referred to as a multi-view encoder classifier (MVEC)) utilizing an Unsupervised Machine Translation (UMT) system and a language discriminator are specifically presented. Unlike previous Language Model (LM) -based fine tuning methods that adjust parameters based only on classification errors of training data, embodiments employ the UMT encoder-decoder framework as a regularized component over shared network parameters. In one or more embodiments, the cross-language encoder of an embodiment learns a shared representation, which is effective for both reconstructing an input sentence in two languages and generating more representative views from the input for classification. Experiments on five language pairs demonstrate that the MVEC embodiment is significantly better than other models for the 8/11 emotion classification task.","['G06F40/30', 'G06F16/35', 'G06F16/353', 'G06F40/126', 'G06F40/151', 'G06F40/197', 'G06F40/58', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F40/216', 'G06F40/284', 'G06N3/044']"
US10722180B2,Deep learning-based diagnosis and referral of ophthalmic diseases and disorders,"Disclosed herein are systems, methods, devices, and media for carrying out medical diagnosis of ophthalmic diseases and conditions. Deep learning algorithms enable the automated analysis of ophthalmic images to generate predictions of comparable accuracy to clinical experts.","['A61B5/7267', 'A61B3/0025', 'A61B3/102', 'A61B3/12', 'A61B3/14', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'A61B2576/02', 'A61B5/0013', 'A61B5/0022', 'A61B5/021', 'A61B5/024', 'A61B5/0531', 'A61B5/486', 'A61B5/4872', 'A61B5/4875', 'A61B5/6898', 'A61B5/7282']"
US11250314B2,Beyond shared hierarchies: deep multitask learning through soft layer ordering,"The technology disclosed identifies parallel ordering of shared layers as a common assumption underlying existing deep multitask learning (MTL) approaches. This assumption restricts the kinds of shared structure that can be learned between tasks. The technology disclosed demonstrates how direct approaches to removing this assumption can ease the integration of information across plentiful and diverse tasks. The technology disclosed introduces soft ordering as a method for learning how to apply layers in different ways at different depths for different tasks, while simultaneously learning the layers themselves. Soft ordering outperforms parallel ordering methods as well as single-task learning across a suite of domains. Results show that deep MTL can be improved while generating a compact set of multipurpose functional primitives, thus aligning more closely with our understanding of complex real-world processes.","['G06N3/084', 'G06N3/0481', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N5/01', 'G06N20/10', 'G06N3/047', 'G06N3/082']"
CN113221639B,A micro-expression recognition method based on multi-task learning for representative AU region extraction,"The invention relates to a micro-expression recognition method for representative AU region extraction based on multitask learning, which comprises the following steps: A. preprocessing the micro-expression video; B. acquiring the position of an AU area to obtain the most representative AU area; C. dividing a training set and a test set; D. training AU mask features to extract a network model; E. sending the trained AU mask feature extraction network to obtain a face image sequence only containing a representative AU; F. training a 3D-ResNet network comprising non-local modules; G. and sending the data to a 3D-ResNet network containing a non-local module to obtain the classification accuracy. The invention considers the contribution of different AUs to the micro expression recognition, solves the problem of insufficient micro expression samples, increases the number of training samples and improves the micro expression recognition performance.","['G06F18/214', 'G06V10/462', 'G06V40/168', 'G06V40/172', 'G06V40/176']"
CN113469356B,Improved VGG16 network pig identity recognition method based on transfer learning,"The invention discloses an improved VGG16 network pig identity recognition method based on transfer learning. Firstly, extracting processed videos frame by frame to obtain a series of pictures, preprocessing the pictures into a data set, and then dividing a training set and a testing set; constructing an improved VGG16 network training model BN-VGG16, and storing a Pre-trained feature extraction model Pre-VGG16; the next is a transfer learning process, wherein the Pre-VGG16 feature extraction network obtained by source domain training is transferred to the Pig-identifying Pic-VGG 16 network; and (3) performing multi-block improved absolute value differential local direction mode (Multi Block ImproveAbsolute Difference Local Direction Pattern, MB-IADLDP for short) feature extraction on the data set with the adjusted size, performing serial fusion, and finally performing pig identification. The improved VGG16 model based on transfer learning is superior to the traditional VGG16 network model in both operation speed and accuracy.","['G06N3/0464', 'G06N3/08', 'G06N3/006', 'G06N3/045', 'G06N3/061', 'G06N3/084', 'G06N3/096', 'G06V10/82', 'G06V40/10', 'G06N3/082']"
US20230267328A1,Matching based intent understanding with transfer learning,Described herein is a mechanism to identify user intent in requests submitted to a system such as a digital assistant or question-answer systems. Embodiments utilize a match methodology instead of a classification methodology. Features derived from a subgraph retrieved from a knowledge base based on the request are concatenated with pretrained word embeddings for both the request and a candidate predicate. The concatenated inputs for both the request and predicate are encoded using two independent LSTM networks and then a matching score is calculated using a match LSTM network. The result is identified based on the matching scores for a plurality of candidate predicates. The pretrained word embeddings allow for knowledge transfer since pretrained word embeddings in one intent domain can apply to another intent domain without retraining.,"['G06F40/30', 'G06N3/08', 'G06N20/00', 'G06N5/04']"
WO2021218517A1,"Method for acquiring neural network model, and image processing method and apparatus","Disclosed are a method for acquiring a neural network model, and an image processing method and apparatus in the field of artificial intelligence. The method for acquiring a neural network model comprises: acquiring a pre-trained super-network model, wherein the pre-trained super-network model is obtained by performing training on the basis of a source data set; acquiring a target data set, wherein a task corresponding to the target data set is the same as a task corresponding to the source data set; performing transfer learning on the pre-trained super-network model on the basis of the target data set, so as to obtain a super-network model after the transfer learning; and searching for a sub-network model in the super-network model after the transfer learning, so as to obtain a target neural network model. By means of the method of the present application, the training cost can be reduced during the process of obtaining the required neural network model, and the performance of the neural network model can be improved.","['G06N3/045', 'G06N3/04', 'G06N3/08', 'G06N3/084']"
US20240161017A1,Connectome Ensemble Transfer Learning,"The present disclosure describes a method of Connectome Ensemble Transfer Learning (CETL), which makes connectome-based predictive models useful for precision mental healthcare. CETL comprises a novel transfer learning process that incrementally trains Connectome Ensemble Predictive Models (CEPMs) by leveraging information from source domains to improve predictive performance in target domains. The disclosed methods broadly comprise selecting target and source domains, obtaining network connectivity data from individual persons, sampling source ensemble representations of connectome “views” from the obtained network connectivity data of said persons in the source domain, reducing the dimensionality of the sampled connectome “views”, and transferring the distilled representations to the target domain to train more robust, generalizable, and clinically deployable CEPMs that predict diverse target mental health phenotypes. Implemented through massively parallel distributed computing, a system of synchronized computer hardware implementing this method is also disclosed.","['G06N20/20', 'G06N3/096', 'G06N3/042', 'G06N3/045', 'G06N3/09', 'G06N5/01', 'G06N5/02', 'G06N7/01', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06N3/0895']"
US20220084679A1,Deep neural network pre-training method for classifying electrocardiogram (ecg) data,"A deep neural network pre-training method for classifying electrocardiogram (ECG) data and a device for the same are disclosed. A method for training an ECG feature extraction model may include receiving a ECG signal, extracting one or more first features related to the ECG signal by inputting the ECG signal to a rule-based feature extractor or a neural network model, extracting at least one second feature corresponding to the at least one first feature by inputting the ECG signal to an encoder, and pre-training the ECG feature extraction model by inputting the at least one second feature into at least one of a regression function and a classification function to calculate at least one output value. The pre-training of the ECG feature extraction model may include training the encoder to minimize a loss function that is determined based on the at least one output value and the at least one first feature.","['G06N3/084', 'G06N5/04', 'A61B5/349', 'A61B5/352', 'A61B5/353', 'A61B5/355', 'A61B5/36', 'A61B5/366', 'A61B5/7225', 'A61B5/7267', 'G06F18/217', 'G06K9/00523', 'G06K9/00536', 'G06N20/00', 'G06N3/042', 'G06N3/045', 'G06N3/088', 'G06N5/02', 'G16H50/20', 'G16H50/70', 'G06F2218/08', 'G06F2218/12', 'G06N3/048']"
CN111832417B,Signal modulation pattern recognition method based on CNN-LSTM model and transfer learning,"The invention discloses a signal modulation pattern recognition method based on a CNN-LSTM model and transfer learning. Firstly, collecting a plurality of different modulation signal sample sets, and preprocessing to obtain a source data set; constructing a CNN-LSTM network model, randomly initializing the weight of the network, and inputting a source data set to pretrain the network model; migrating weight parameters of the pre-trained CNN network and the weight parameters of the LSTM network to the target CNN-LSTM network correspondingly, inputting a training data set to train a random forest classifier in the target CNN-LSTM network, and obtaining a CNN-LSTM network after training is completed; and finally, carrying out modulation pattern recognition on the test data set by using the CNN-LSTM network after training to obtain a signal classification recognition result. The invention combines the feature extraction advantages of the CNN network and the LSTM network, improves the signal recognition performance, and solves the problem of poor recognition performance of deep learning under the condition of lacking a target signal sample.","['G06F2218/08', 'G06F18/214', 'G06F18/241', 'G06F18/24323', 'G06F18/25', 'G06N20/00', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06F18/259', 'G06F2218/12']"
US11436725B2,"Systems, methods, and apparatuses for implementing a self-supervised chest x-ray image analysis machine-learning model utilizing transferable visual words","Not only is annotating medical images tedious and time consuming, but it also demands costly, specialty-oriented expertise, which is not easily accessible. To address this challenge, a new self-supervised framework is introduced: TransVW (transferable visual words), exploiting the prowess of transfer learning with convolutional neural networks and the unsupervised nature of visual word extraction with bags of visual words, resulting in an annotation-efficient solution to medical image analysis. TransVW was evaluated using NIH ChestX-ray14 to demonstrate its annotation efficiency. When compared with training from scratch and ImageNet-based transfer learning, TransVW reduces the annotation efforts by 75% and 12%, respectively, in addition to significantly accelerating the convergence speed. More importantly, TransVW sets new records: achieving the best average AUC on all 14 diseases, the best individual AUC scores on 10 diseases, and the second best individual AUC scores on 3 diseases. This performance is unprecedented, because heretofore no self-supervised learning method has outperformed ImageNet-based transfer learning and no annotation reduction has been reported for self-supervised learning. These achievements are contributable to a simple yet powerful observation: The complex and recurring anatomical structures in medical images are natural visual words, which can be automatically extracted, serving as strong yet free supervision signals for CNNs to learn generalizable and transferable image representation via self-supervision.","['G06T7/0012', 'A61B6/468', 'A61B6/50', 'G06T7/74', 'G06V10/464', 'G06V10/764', 'G06V10/82', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/033']"
US12040094B2,Artificial intelligence-based methods for early drug discovery and related training methods,"An example method for training a graph convolutional neural network (GCNN) configured for virtual screening of molecules for drug discovery is described herein. The method can include receiving a first data set including a plurality of molecules, and training the GCNN to initialize one or more parameters of the GCNN using the first data set. The method can also include receiving a second data set including a plurality of molecules and respective inhibition rates for a disease, and training the GCNN to refine the one or more parameters of the GCNN using the second data set. The molecules in the first and second data sets can be expressed in a computer-readable format. An example method for virtually screening molecules on Plasmodium falciparum (P. falciparum) is also described herein.","['G16H50/70', 'G16H20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G16C20/64', 'G16C20/70', 'G16H10/40', 'G16H50/20', 'G16H70/40', 'G06N3/082', 'Y02A50/30', 'Y02A90/10']"
US11562236B2,Automatically labeling capability for training and validation data for machine learning,"A method for enabling an labeling capability for training and validation data at an edge device to support neural network transfer learning capability is provided. The method includes: inputting candidate data into a first neural network to filter the candidate data by selecting a subset of candidate data based on an output of the first neural network, performing a confidence upgrade check on the subset of candidate data by: (1) performing a data consistency check by generating augmented data from each candidate data from among the subset of candidate data, (2) inputting the subset of candidate data into a second neural network that is trained using data from an environment to determine a second confidence condition, and (3) performing a clustering on the subset of candidate data, and automatically labeling, as training data, the subset of candidate data in accordance with a confidence level label.","['G06N3/08', 'G06T1/20', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06T3/40', 'G06T3/60', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084']"
CN109446898B,A Person Re-identification Method Based on Transfer Learning and Feature Fusion,"The invention discloses a pedestrian re-identification method based on transfer learning and feature fusion, which comprises the following steps of: acquiring pedestrian data, performing primary training through a neural network, modifying the structure, and performing secondary training in a data set by combining an improved loss function; carrying out manual feature extraction and neural network feature extraction; after extracting the features, fusing the two features to obtain high-low level features; classifying and verifying the high-low level features by using an XQDA algorithm to obtain a re-identification result; the invention adopts the cross entropy loss function and the triple loss function to carry out stronger constraint on the whole network, extracts the manual characteristics and the convolution network characteristics to carry out characteristic fusion to form high-low level characteristics, covers different levels of pedestrian characteristic expression, achieves better recognition effect, reduces training time in a fine adjustment mode, and has good generalization and portability on small data sets.","['G06V40/10', 'G06F18/217', 'G06N3/045', 'G06V10/40']"
US10263171B2,Surgical generator for ultrasonic and electrosurgical devices,"A method for determining motional branch current in an ultrasonic transducer of an ultrasonic surgical device over multiple frequencies of a transducer drive signal. The method may comprise, at each of a plurality of frequencies of the transducer drive signal, oversampling a current and voltage of the transducer drive signal, receiving, by a processor, the current and voltage samples, and determining, by the processor, the motional branch current based on the current and voltage samples, a static capacitance of the ultrasonic transducer and the frequency of the transducer drive signal.","['H01L41/042', 'A61B18/1206', 'A61B17/320068', 'A61B17/320092', 'A61B18/1233', 'H10N30/802', 'A61B18/14', 'A61B18/1445', 'A61B2017/00017', 'A61B2017/00477', 'A61B2017/00482', 'A61B2017/00486', 'A61B2017/2934', 'A61B2017/2936', 'A61B2017/320069', 'A61B2017/320071', 'A61B2017/320094', 'A61B2017/320095', 'A61B2018/00178', 'A61B2018/00601', 'A61B2018/0063', 'A61B2018/00666', 'A61B2018/00678', 'A61B2018/00684', 'A61B2018/00702', 'A61B2018/0072', 'A61B2018/00732', 'A61B2018/00767', 'A61B2018/00779', 'A61B2018/00803', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00988', 'A61B2018/00994', 'H01R2201/12']"
US11423255B2,Image processing,"The present disclosure pertains generally to image feature extraction. Both transfer-learning and multi-task training approaches are considered. In one example, a machine learning model is trained to perform a geographic classification task of distinguishing between images captured in different geographic regions based on their visual content. In another example, a machine learning model is trained to perform an order recognition task of determining information about the order of an image sequence based on its visual content, where the order of the image sequence may be different than the order in which its constituent images were captured. A further example combines the two approaches. The knowledge gained by the ML model in learning one or more such tasks can be applied to a desired image recognition task, such as image segmentation, structure detection or image classification, e.g. with a pre-training/fine-tuning framework or a multi-task learning framework.","['G06N3/08', 'G06K9/6256', 'G06F18/214', 'G06F18/24', 'G06F18/2413', 'G06K9/6267', 'G06N3/045', 'G06N3/0464', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/182', 'G06V20/46', 'G06V20/49', 'G06V20/56']"
CN110738605B,"Image denoising method, system, equipment and medium based on transfer learning","The invention discloses an image denoising method, system, equipment and medium based on transfer learning, which acquire an image to be denoised; inputting an image to be denoised into a pre-trained denoising neural network based on transfer learning for processing, wherein the denoising neural network based on transfer learning comprises: a main noise reduction network and a noise distribution information extraction network; the noise distribution information extraction network is used for extracting random noise distribution characteristics; after preprocessing the random noise distribution characteristics, the random noise distribution characteristics are used as dynamic normalization parameters of each residual error module of the main noise reduction network, and are migrated into the data characteristics of the main noise reduction network, so that the convergence speed of the main network is accelerated; carrying out normalization processing on the image features extracted by each residual error module of the main noise reduction network by utilizing dynamic normalization parameters, and outputting a pure noise image by the main noise reduction network; and carrying out difference processing on the pure noise image and the image to be denoised to obtain a denoised image.","['G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
US20190272375A1,Trust model for malware classification,"There is disclosed in one example an apparatus, including: a hardware platform including a processor and a memory; an image classifier to operate on the hardware platform, the image classifier configured to classify an object under analysis as one of malware or benignware based on an image of the object; and a trust component configured to identify portions of the image that contribute to the classification.","['G06F21/562', 'G06F21/563', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N5/045', 'H04L63/14', 'H04L63/1433', 'G06F2221/033']"
CN110674629B,"Punctuation mark labeling model, training method, training equipment and storage medium thereof","Punctuation mark labeling model, training method, training equipment and storage medium thereof, wherein the method comprises the following steps: acquiring a first training corpus containing punctuation marks; inputting the first training corpus into a preset neural network model with a time sequence for pre-training to obtain a pre-trained language sub-model; obtaining second training corpus containing punctuation marks, removing the punctuation marks from the second training corpus, and marking corresponding label combinations at front and rear word segmentation units of the removed punctuation marks to obtain third training corpus; inputting a third training corpus into the initial punctuation mark labeling model for transfer learning training to obtain a trained punctuation mark labeling model, wherein the punctuation mark labeling model comprises a pre-trained language sub-model, and the third training corpus comprises a punctuation-free text set and a label sequence set. According to the scheme, a large amount of training data does not need to be manually marked, the recall rate is improved, and the obtained punctuation mark marking model has good generalization capability and universality.",['G06N3/08']
CN117788957B,Deep learning-based qualification image classification method and system,"The invention relates to the technical field of image classification, in particular to a method and a system for classifying a qualification image based on deep learning. According to the invention, through random clipping, overturning, color conversion and Z-Score standardization, generalization capability and adaptability of the model are enhanced, a transfer learning algorithm and a pre-training model are adopted, the training process is accelerated, data requirements and calculation resources are reduced, the problem of unbalanced classification is processed by an SMOTE algorithm, classification fairness is ensured, the combination of a graph rolling network and a frequency domain analysis technology is ensured, recognition of structural features of the image is enhanced, application of a neural style migration technology is realized, visual performance of the image is optimized, and robustness of the model is further improved.",['Y02T10/40']
CN112232511B,Multitask-oriented automatic compression method and platform of pre-trained language model,"The invention discloses a pre-training language model automatic compression method and platform for multiple tasks. Designing a meta-network of a structure generator, constructing a knowledge distillation coding vector based on a Transformer layer sampling knowledge distillation method, and generating a distillation structure model corresponding to a currently input coding vector by using the structure generator; simultaneously, a Bernoulli distributed sampling method is provided to train a structure generator; in each iteration, each encoder unit is moved by using a Bernoulli distribution sampling mode to form a corresponding encoding vector; by changing the coding vector input into the structure generator and the training data of a small batch, combining the training structure generator and the corresponding distillation structure, the structure generator capable of generating weights for different distillation structures can be learned; and meanwhile, on the basis of the trained meta-learning network, searching for an optimal compression structure through an evolutionary algorithm, thereby obtaining an optimal general compression architecture of the pre-training language model irrelevant to the task.","['G06N3/082', 'G06N5/04']"
CN110008854B,Unmanned aerial vehicle image highway geological disaster identification method based on pre-training DCNN,"The invention relates to the technical field of road geological disaster identification, and discloses an unmanned aerial vehicle image road geological disaster identification method based on pre-trained DCNN, which comprises the following steps: step S1, acquiring unmanned aerial vehicle remote sensing images in a road domain range, and preprocessing the images to obtain orthographic images after absolute orientation; step S2, segmenting the preprocessed unmanned aerial vehicle remote sensing image by adopting a mean shift algorithm considering image texture characteristics; and step S3, taking the segmented unmanned aerial vehicle remote sensing image data as input data, and applying the input data to the trained road geological disaster recognition model to obtain a road geological disaster recognition result. The unmanned aerial vehicle high-resolution image is adopted, the image is segmented based on the mean shift algorithm considering the textural features, and the segmented image unit is used as the input data of the geological disaster identification model, so that the efficiency of visual interpretation of the existing geological disaster can be effectively improved, and data support is provided for highway field investigation and disaster risk evaluation.","['G06N3/045', 'G06V10/267', 'G06V20/182']"
CN111461053B,Multi-growth-period wheat lodging area identification system based on transfer learning,"The invention particularly relates to a system for identifying a plurality of wheat lodging areas in a growth period based on transfer learning, which comprises an image acquisition module, a preprocessing module and an identification module; the unmanned aerial vehicle of the image acquisition module is provided with a camera for shooting the wheat Tian Tuxiang to be identified and outputting the wheat Tian Tuxiang to the preprocessing module, the preprocessing module splices and cuts the images and outputs the images to the identification module, and the marked wheat Tian Tuxiang is obtained through the identification of the trained deep Labv3+ model stored in the identification module. The unmanned aerial vehicle is used for carrying the camera to shoot pictures, so that the unmanned aerial vehicle can be effectively suitable for various environmental conditions, is very portable, and can take pictures along with walking; meanwhile, the shot pictures can be processed and identified in a concentrated mode through the preprocessing module and the identification module, the lodging area of the wheat field to be identified is marked automatically, and the pictures are directly imported into the model for identification because the model in the identification module is trained in advance, so that the processing speed is high, and the cost of the identification module is reduced.","['G06V20/188', 'G06F18/214', 'Y02A40/10']"
US11222330B2,Apparatus and method to perform point of sale transactions using near-field communication (NFC) and biometric authentication,"An apparatus and method to conduct financial and other transactions using a wireless computing device. The wireless device includes an input display part, one or more processors, and at least one memory device. The memory device has stored therein a wallet application for completing transactions based on wireless data communications between the computing device and an external electronic device. The memory device further stores at least one electronic credential. The wireless device permits transmission, via a near-field communication (NFC) module, of at least one electronic credential to an NFC reader of the external electronic device based on comparing a biometric characteristic of a user, detected by a biometric characteristic reader, with stored biometric information.","['G06K7/10297', 'G06Q20/202', 'G06Q20/32', 'G06Q20/322', 'G06Q20/3226', 'G06Q20/325', 'G06Q20/327', 'G06Q20/3278', 'G06Q20/3674', 'G06Q20/3821', 'G06Q20/40', 'G06Q20/401', 'G06Q20/4012', 'G06Q20/42', 'H04B5/77', 'H04L63/08', 'H04L63/083', 'H04L63/18', 'H04W12/02', 'H04W12/033', 'H04W12/06', 'H04W12/068', 'G06K7/10415', 'G06Q20/20', 'G06Q20/3227', 'G06Q20/38215', 'G06Q20/385', 'G06Q20/40145', 'H04B5/0062', 'H04L2463/102', 'H04L63/0428']"
US12035421B2,Procedure for optimization of self-organizing network,"An apparatus for use by a communication network control element or function configured to control a setting of parameters of a self-organizing communication network, the apparatus comprising at least one processing circuitry, and at least one memory for storing instructions to be executed by the processing circuitry, wherein the at least one memory and the instructions are configured to, with the at least one processing circuitry, cause the apparatus at least: to obtain a pre-trained network optimization model indicating a mapping between a communication network environment forming an input of the model, optimization actions or decisions forming an output of the model, and system performance indicators forming a reward, to cause sending, to at least one communication network element or function forming a part of the self-organizing communication network, a request for providing similarity data for a similarity analysis allowing to determine a similarity between a part of the self-organizing communication network for which the pre-trained network optimization model is derived and a part of the self-organizing communication network of the at least one communication network element or function to which the request is sent, to perform the similarity analysis for determining a similarity between the part of the self-organizing communication network for which the pre-trained network optimization model is derived and each part of the self-organizing communication network for which similarity data for the similarity analysis are received, to determine, on the basis of the similarity analysis, at least a part of the pre-trained network optimization model to be provided to the at least one communication network element or function forming a part of the self-organizing communication network from which the similarity data are received, and to cause sending of the determined part of the pre-trained network optimization model to the at least one communication network element or function forming a part of the self-organizing communication network from which the similarity data are received.","['H04W24/02', 'G06N3/045', 'G06N3/0464', 'G06N3/082', 'G06N3/092', 'G06N3/096', 'G06N3/098', 'H04W84/18']"
US20220398462A1,Automated fine-tuning and deployment of pre-trained deep learning models,A cloud platform includes several web services that facilitate the automated tuning and deployment of pre-trained deep learning models configured for software engineering tasks. The automated tuning and deployment allow a developer to fine-tune a pre-existing model without having access to the parameters of the pre-existing and the fine-tuned model in a manner that does not require user management input. The cloud platform provides a set of files for each pre-trained models used to automatically build a fine-tuning infrastructure to fine-tune a model and a deployment infrastructure that deploys the fine-tuned model without requiring user input.,"['G06N3/088', 'G06N3/08', 'G06F8/36', 'G06N3/045', 'G06N3/0454', 'G06F8/35', 'G06F8/60']"
US12086539B2,System and method for natural language processing using neural network with cross-task training,"A method for using a neural network model for natural language processing (NLP) includes receiving training data associated with a source domain and a target domain; and generating one or more query batches. Each query batch includes one or more source tasks associated with the source domain and one or more target tasks associated with the target domain. For each query batch, class representations are generated for each class in the source domain and the target domain. A query batch loss for the query batch is generated based on the corresponding class representations. An optimization is performed on the neural network model by adjusting its network parameters based on the query batch loss. The optimized neural network model is used to perform one or more new NLP tasks.","['G06F40/20', 'G06F16/3329', 'G06F16/3344', 'G06F40/279', 'G06F40/30', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/048']"
US8171032B2,Providing customized electronic information,"This invention relates to customized electronic identification of desirable objects, such as news articles, in an electronic media environment, and in particular to a system that automatically constructs both a “target profile” for each target object in the electronic media based, for example, on the frequency with which each word appears in an article relative to its overall frequency of use in all articles, as well as a “target profile interest summary” for each user, which target profile interest summary describes the user's interest level in various types of target objects. The system then evaluates the target profiles against the users' target profile interest summaries to generate a user-customized rank ordered listing of target objects most likely to be of interest to each user so that the user can select from among these potentially relevant target objects, which were automatically selected by this system from the plethora of target objects that are profiled on the electronic media. Users' target profile interest summaries can be used to efficiently organize the distribution of information in a large scale system consisting of many users interconnected by means of a communication network. Additionally, a cryptographically-based pseudonym proxy server is provided to ensure the privacy of a user's target profile interest summary, by giving the user control over the ability of third parties to access this summary and to identify or contact the user.","['G06Q30/02', 'G06F16/00', 'G06F16/9535', 'G06Q30/0207', 'G06Q30/0269', 'G06Q30/0273', 'G06Q30/0277', 'H04N21/222', 'H04N21/23106', 'H04N21/252', 'H04N21/25891', 'H04N21/262', 'H04N21/26603', 'H04N21/4332', 'H04N21/44224', 'H04N21/4532', 'H04N21/454', 'H04N21/4622', 'H04N21/466', 'H04N21/4665', 'H04N21/4755', 'H04N21/4782', 'H04N21/812', 'H04N7/163', 'H04N7/165', 'H04N7/1675', 'H04N7/173', 'H04N7/17318', 'H04N7/17354', 'Y10S707/922', 'Y10S707/943', 'Y10S707/99932']"
CN110866476B,Dense stacking target detection method based on automatic labeling and transfer learning,"A dense stacking target detection method based on automatic labeling and transfer learning is characterized in that a labeled training image set is established by high-resolution image segmentation; then inputting the marked training image set into a pre-trained target detection model YOLOv3, optimizing the prior frame size and the loss function of the YOLOv3 model, and finely adjusting the model by using the training image set; and finally, inputting the image to be detected into the refined YOLOv3 model, outputting the classification of the target subarea and the subarea position, splicing the output result graph to restore the original image, and counting the total counting result. The method has strong anti-interference performance and robustness, and has lower requirements on image photographers and photographing illumination conditions; by the non-supervision learning method, the quasi-automatic labeling of the images is realized, the workload of manual labeling is greatly reduced, and the model training efficiency is improved; the method can be used for image recognition of dense stacking targets with a large number of mutual shielding, and is suitable for various scenes of automatic counting of the dense stacking targets.","['G06V20/10', 'G06F18/23', 'G06F18/241', 'G06F18/2415', 'Y02T10/40']"
CN107766787B,"Face attribute identification method, device, terminal and storage medium","A face attribute identification method, the method comprising: pre-training a neural network model; carrying out fine adjustment of a face recognition task on the pre-trained neural network model; carrying out fine adjustment on the face attribute recognition task on the neural network model subjected to fine adjustment on the face recognition task; and carrying out face attribute recognition on the given image by using the neural network model after the fine adjustment of the face attribute recognition task. The invention also provides a face attribute recognition device, a terminal and a storage medium. The invention can train out a neural network model suitable for face attribute recognition, and obtain better face attribute recognition effect.","['G06V20/53', 'G06F18/214', 'G06N3/045', 'G06V40/161', 'G06V40/174', 'Y02T10/40']"
US20230162023A1,System and Method for Automated Transfer Learning with Domain Disentanglement,"A system and method for automated construction of an artificial neural network architecture are provided. The system includes a set of interfaces and data links configured to receive and send signals, wherein the signals include datasets of training data, validation data and testing data, wherein the signals include a set of random number factors in multi-dimensional signals, wherein part of the random number factors are associated with task labels to identify, and nuisance variations. The system further includes a set of memory banks to store a set of reconfigurable deep neural network (DNN) blocks, hyperparameters, trainable variables, intermediate neuron signals, and temporary computation values including forward-pass signals and backward-pass gradients. The system further includes at least one processor, in connection with the interface and the memory banks, configured to submit the signals and the datasets into the reconfigurable DNN blocks, wherein the at least one processor is configured to explore hyperparameters of regularization modules, pre-processing and post-processing methods such that the reconfigurable DNN blocks achieve nuisance-robust Bayesian inference to be transferable to new datasets with domain shifts.","['G06N3/096', 'G06N3/08', 'G06N3/04', 'G06N3/0455', 'G06N3/047', 'G06N3/0985', 'G06N7/01', 'G06N3/006', 'G06N3/044', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'G06N3/094']"
US11080918B2,Method and system for predicting garment attributes using deep learning,"There is provided a computer implemented method for predicting garment or accessory attributes using deep learning techniques, comprising the steps of: (i) receiving and storing one or more digital image datasets including images of garments or accessories; (ii) training a deep model for garment or accessory attribute identification, using the stored one or more digital image datasets, by configuring a deep neural network model to predict (a) multiple-class discrete attributes; (b) binary discrete attributes, and (c) continuous attributes, (iii) receiving one or more digital images of a garment or an accessory, and (iv) extracting attributes of the garment or the accessory from the one or more received digital images using the trained deep model for garment or accessory attribute identification. A related system is also provided.","['G06V10/454', 'G06F16/535', 'G06F16/538', 'G06F16/5838', 'G06F16/5862', 'G06F18/214', 'G06F18/24', 'G06F40/20', 'G06K9/6256', 'G06K9/6267', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T15/005', 'G06T15/04', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G06V40/10', 'G06V2201/12']"
US11720994B2,High-resolution portrait stylization frameworks using a hierarchical variational encoder,"Systems and method directed to an inversion-consistent transfer learning framework for generating portrait stylization using only limited exemplars. In examples, an input image is received and encoded using a variational autoencoder to generate a latent vector. The latent vector may be provided to a generative adversarial network (GAN) generator to generate a stylized image. In examples, the variational autoencoder is trained using a plurality of images while keeping the weights of a pre-trained GAN generator fixed, where the pre-trained GAN generator acts as a decoder for the encoder. In other examples, a multi-path attribute aware generator is trained using a plurality of exemplar images and learning transfer using the pre-trained GAN generator.","['G06T3/0012', 'G06N3/088', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06N3/096', 'G06T11/00', 'G06T3/0006', 'G06T3/02', 'G06T3/04', 'G06T5/00', 'G06V10/774', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US12293830B2,Image-based detection of ophthalmic and systemic diseases,"Disclosed herein are systems, methods, devices, and media for carrying out detection of ophthalmic and systemic diseases and disorders. Deep learning algorithms enable the automated analysis of ophthalmic images such as retinal scans to generate accurate detection of various diseases and disorders. Point-of-care implementations allow for rapid and efficient detection outside of the clinical setting.","['G16H50/20', 'G06T7/0012', 'G06V10/7747', 'G16H15/00', 'A61B3/12', 'G06T2207/10024', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041']"
CN113592809B,Pneumonia image detection system and method based on channel attention residual error network,"The invention belongs to the technical field of pneumonia diagnosis, and discloses a pneumonia image detection system and method based on a channel attention residual network, wherein the pneumonia image detection method based on the channel attention residual network comprises the following steps: combining the deep learning technology with a medical image-chest X-ray film, migrating pre-trained ResNet model weights and parameters to a residual network model, introducing an ECA attention module into a residual structure from a channel dimension, and constructing a residual network model ECA-XNet based on the channel attention for detecting pneumonia from the chest X-ray film. The method and the device migrate the pre-trained ResNet model weights and parameters to the model, and improve the training speed of the model. In order to enhance the useful residual features and suppress noise interference, the present invention introduces ECA attention modules into the residual structure from the channel dimension, and the proposed model has been validated on the Chest X-RAY IMAGES dataset.","['G06T7/0012', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061']"
CN110024330B,Service provisioning for IoT devices,"An internet of things (IoT) network includes an orchestrator for issuing service management requests, a service coordinator for identifying components participating in a service, and a component for executing network service elements. The IoT network includes an IoT device having a service enumerator, a contract enumerator, and a join contract function. The IoT network device includes a license guide promoter for the discovered peer, and a license guide action executor. The IoT network device includes a floating service license director for the discovered host, a host hardware selector, a floating service license guide executor, and a service wallet value transferor. The IoT network device includes a license guide drafter, a parameter weight calculator, a license guide clause generator, and a license guide action executor for the first and second discovered peers. The IoT network includes an IoT device having a resource hardware component identifier, a processor for processing a received indication of an external module hardware requirement, an external module comparator, and a deactivation signal transmitter.","['H04L67/104', 'H04W4/70', 'G06F16/1824', 'G06F16/1834', 'H04L41/0806', 'H04L41/12', 'H04L41/5054', 'H04L45/20', 'H04L61/3025', 'H04L61/4505', 'H04L61/5069', 'H04L61/5092', 'H04L63/123', 'H04L67/10', 'H04L67/1046', 'H04L67/1093', 'H04L67/12', 'H04L67/303', 'H04L67/562', 'H04L69/18', 'H04L69/22', 'H04L9/0825', 'H04L9/3239', 'H04L9/50', 'H04W12/106', 'H04W12/69', 'H04W4/08', 'H04W84/18', 'H04W84/22', 'H04L2209/56', 'H04L41/0816', 'H04L41/0886', 'H04L41/16', 'H04W12/76']"
CN110995475B,Power communication network fault detection method based on transfer learning,"The invention relates to a power communication network fault detection method based on transfer learning, which combines a convolutional neural network and transfer learning, integrates the characteristics of a plurality of trained local network models by utilizing the correlation between an actual network topology structure and an experimental network local network topology, and performs transfer parameter learning through a small amount of actual network fault samples to obtain an actual network fault diagnosis model, thereby realizing an available, accurate and comprehensive intelligent power communication network fault detection technology and expanding the applicability of the fault diagnosis technology. The invention innovatively combines the advantages of the convolutional neural network and the transfer learning method, fully utilizes the characteristic correlation between fault alarm data and the similarity of characteristics such as network node correlation degrees of different network topologies and the like, and accurately and comprehensively intelligently detects the fault data in the actual network.","['H04L41/0631', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'H04L41/064', 'H04L41/065', 'H04L41/0677', 'H04L41/12', 'Y04S10/52']"
CN110427875B,Infrared image target detection method based on deep transfer learning and extreme learning machine,"The invention relates to an infrared image target detection method based on deep migration learning and an extreme learning machine, which comprises the following steps of training a visible light image target detection model, training on a visible light sample set D by using a mask rcnn two-stage multi-task detection architecture, inputting a mask into a neural network, and redefining a loss function of an integral network structure; based on a sample migration method, a migration learning data set is obtained by expanding a target domain, namely the distribution of an infrared sample set T; based on a model migration method, a target detection model with high precision based on a visible light image is taken as a pre-training model of the generated migration learning data set, and training is carried out by adopting the same frame as that of visible light target detection; and an extreme learning machine is adopted to replace a network full-connection layer, so that the overfitting phenomenon of the migration training of the small sample model is overcome.","['G06N3/08', 'G06V20/10']"
US20230237649A1,Systems and Methods for Quantification of Liver Fibrosis with MRI and Deep Learning,"Embodiments provide a deep learning framework to accurately segment liver and spleen using a convolutional neural network with both short and long residual connections to extract their radiomic and deep features from multiparametric MRI. Embodiments will provide an “ensemble” deep learning model to quantify biopsy derived liver fibrosis stage and percentage using the integration of multiparametric MRI radiomic and deep features, MRE data, as well as routinely available clinical data. Embodiments will provide a deep learning model to quantify MRE-derived liver stiffness using multiparametric MRI, radiomic and deep features and routinely-available clinical data.","['A61B5/055', 'G06T7/0012', 'A61B5/4244', 'A61B5/7264', 'G06F18/24133', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B2576/02', 'G06T2207/10088', 'G06T2207/20084', 'G06T2207/30056', 'G06V2201/031']"
US12277687B2,"Systems, methods, and apparatuses for the use of transferable visual words for AI models through self-supervised learning in the absence of manual labeling for the processing of medical imaging","Described herein are means for the generation of semantic genesis models through self-supervised learning in the absence of manual labeling, in which the trained semantic genesis models are then utilized for the processing of medical imaging. For instance, an exemplary system is specially configured with means for performing a self-discovery operation which crops 2D patches or crops 3D cubes from similar patient scans received at the system as input; means for transforming each anatomical pattern represented within the cropped 2D patches or the cropped 3D cubes to generate transformed 2D anatomical patterns or transformed 3D anatomical patterns; means for performing a self-classification operation of the transformed anatomical patterns by formulating a C-way multi-class classification task for representation learning; means for performing a self-restoration operation by recovering original anatomical patterns from the transformed 2D patches or transformed 3D cubes having transformed anatomical patterns embedded therein to learn different sets of visual representation; and means for providing a semantics-enriched pre-trained AI model having a trained encoder-decoder structure with skip connections in between based on the performance of the self-discovery operation, the self-classification operation, and the self-restoration operation. Other related embodiments are disclosed.","['G06T5/77', 'G06T3/04', 'G06T5/60', 'G06T7/0014', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/03']"
US11461635B2,Neural network transfer learning for quality of transmission prediction,Systems and methods for predicting performance of a modulation system are provided. A neural network model is trained using performance information of a source system. The neural network model is modified with transferable knowledge about a target system to be evaluated. The neural network model is tuned using specific characteristics of the target system to create a source-based target model. The target system performance is evaluated using the source-based target model to predict system performance of the target system.,"['G06N3/084', 'G06N3/08', 'G06N3/048', 'G06N3/0481', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'H04B10/0775', 'H04B10/541', 'H04B10/5561']"
US11631225B2,Graphical style modification for video games using machine learning,Graphical style modification may be implemented using machine learning. A color accommodation module receives an image frame from a host system and generates a color-adapted version of the image frame. A Graphical Style Modification module generates a style adapted video stream by applying a style adapted from a target image frame to each image frame in a buffered video stream.,"['G06T19/20', 'A63F13/69', 'A63F13/60', 'A63F13/65', 'A63F13/67', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/001', 'G06N3/044', 'G06T2219/2012']"
US20230259553A1,Scene annotation and action description using machine learning,"A system enhances existing audio-visual content with an action a scene annotation module, an action description module, both of which are coupled to a controller. The scene annotation module classifies scene elements from an image frame received from a host system and generates a caption describing the scene elements. The scene annotation module includes a first neural network configured to generate a feature vector from the image frame and a second neural network configured to generate a caption describing elements within the image frame from the feature vector. The action description module recognizes action happening within one or more image frames received from the host system and generates a description of the action happening within one or more image frames.","['G06F16/65', 'A63F13/60', 'G06F16/55', 'G06N3/045', 'G06V10/454', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V20/20', 'G06V20/41', 'G06V20/70', 'G10L13/02', 'G10L15/16', 'G10L15/26', 'G06N3/084', 'G06N3/088', 'G06V20/44', 'G10L13/00']"
US10452899B2,Unsupervised deep representation learning for fine-grained body part recognition,"A method and apparatus for deep learning based fine-grained body part recognition in medical imaging data is disclosed. A paired convolutional neural network (P-CNN) for slice ordering is trained based on unlabeled training medical image volumes. A convolutional neural network (CNN) for fine-grained body part recognition is trained by fine-tuning learned weights of the trained P-CNN for slice ordering. The CNN for fine-grained body part recognition is trained to calculate, for an input transversal slice of a medical imaging volume, a normalized height score indicating a normalized height of the input transversal slice in the human body.","['G06T7/74', 'G06K9/00362', 'G06F18/2148', 'G06F18/2155', 'G06F18/24', 'G06F18/24133', 'G06F18/25', 'G06K9/46', 'G06K9/4628', 'G06K9/6257', 'G06K9/6259', 'G06K9/6267', 'G06K9/6271', 'G06K9/6288', 'G06K9/6298', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V40/10', 'G06K2209/05', 'G06T2200/04', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T7/60', 'G06V2201/03']"
CN112434462B,Method and equipment for obtaining model,"The embodiment of the application discloses a method and equipment for obtaining a model, which can be applied to the field of computer vision in the field of artificial intelligence, and the method comprises the following steps: and rapidly predicting the performance of each model (pre-trained according to the first data set) aiming at the new task under different super-parameters in the model set constructed based on the constraint condition through the constructed first predictor, and selecting the model and the super-parameters meeting preset conditions (such as maximum output precision of the model) from the model and the super-parameters as a target model and a target super-parameter for finally processing the new task (namely the second data set). Aiming at a new task, the method can efficiently select a proper model and super parameters based on constraint conditions given by a user, thereby saving training time and calculation cost. In the actual service delivery process, a proper model can be found for a new task in a limited time to carry out transfer learning, and the model is trained to the precision required by delivery.","['G06F30/27', 'G06F18/214', 'G06N3/045', 'G06Q10/04', 'G06F2111/04', 'Y02T10/40']"
US11501171B2,Method and platform for pre-trained language model automatic compression based on multilevel knowledge distillation,"Disclosed are an automatic compression method and platform for a pre-trained language model based on multilevel knowledge distillation. The method includes the following steps: step 1, constructing multilevel knowledge distillation, and distilling a knowledge structure of a large model at three different levels: a self-attention unit, a hidden layer state and an embedded layer; step 2, training a knowledge distillation network of meta-learning to generate a general compression architecture of a plurality of pre-trained language models; and step 3, searching for an optimal compression structure based on an evolutionary algorithm. Firstly, the knowledge distillation based on meta-learning is studied to generate the general compression architecture of the plurality of pre-trained language models; and secondly, on the basis of a trained meta-learning network, the optimal compression structure is searched for via the evolutionary algorithm, so as to obtain an optimal general compression architecture of the pre-trained language model independent of tasks.","['G06F40/30', 'G06F16/35', 'G06F40/40', 'G06N3/045', 'G06N3/0495', 'G06N3/082', 'G06N3/086', 'G06N3/09', 'G06N3/0985', 'G06N3/047', 'G06N3/084']"
CN110610207B,A small-sample SAR image ship classification method based on transfer learning,"The invention relates to a small sample SAR image ship classification method based on transfer learning, and belongs to the technical field of computer vision. The method comprises the following steps: 1) Preprocessing the SAR image ship slice so that the ship slice meets the requirement of transfer learning on an input picture, performing image enhancement on the ship slice, and synthesizing a similar ship slice image through a DCGAN network so as to meet the requirement of a CNN classification network on the data quantity; 2) Extracting image features from the image through a denoising autoencoder, reducing noise added when the DCGAN network generates the image, and reducing the influence of different sea state backgrounds on classification results; 3) And (4) performing transfer learning by adopting a ResNet network, and further improving the classification accuracy by adopting a fine-tune method. The method ensures that the classification of the small sample SAR image ship can achieve certain accuracy.",['G06F18/241']
US7806891B2,Repositioning and reorientation of master/slave relationship in minimally invasive telesurgery,"The invention provides robotic surgical systems which allow selectable independent repositioning of an input handle of a master controller and/or a surgical end effector without corresponding movement of the other. In some embodiments, independent repositioning is limited to translational degrees of freedom. In other embodiments, the system provides an input device adjacent a manipulator supporting the surgical instrument so that an assistant can reposition the instrument at the patient's side.","['A61B34/30', 'A61B34/35', 'A61B34/37', 'A61B34/70', 'A61B2034/305', 'A61B2034/742', 'A61B90/361']"
CN110852350B,Pulmonary nodule benign and malignant classification method and system based on multi-scale migration learning,"The invention discloses a method for classifying benign and malignant pulmonary nodules based on multi-scale migration learning, which comprises the following steps: s1, carrying out multi-scale sampling on nodules in the lung CT image to obtain a multi-scale region of interest; s2, preprocessing the obtained multi-scale region of interest, and synthesizing a three-channel RGB image; s3, preliminarily constructing a transfer learning network model; and S4, training the preliminarily constructed transfer learning network model by using the synthesized RGB image to obtain a model capable of classifying the lung nodules. According to the lung nodule benign and malignant classification model construction method based on migration learning, the interior and exterior of a lung nodule can be fully utilized for carrying out benign and malignant judgment on the imaging characteristics under different scales, only the approximate position of the nodule needs to be provided, the outline information of the nodule does not need to be used during classification, and the segmentation step of the nodule region is avoided, so that the degree of automation is higher, and the practicability is higher.","['G06F18/241', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T5/40', 'G06T7/0012', 'G06V10/25', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064', 'G06V2201/032']"
CN111046581B,Power transmission line fault type identification method and system,"The invention discloses a method and a system for identifying the fault type of a power transmission line, which utilize a power transmission line fault simulation model to generate fault time sequence data of various types of a target line, process the fault time sequence data and generate a target domain data sample facing a Convolutional Neural Network (CNN); carrying out convolution kernel migration training on the pre-training model by using the target domain data sample to form a target domain model; and identifying the fault type of the target line by adopting the target domain model. The method can realize the migration of the deep model by using a small amount of data, generate the deep learning model suitable for the target line, avoid the condition that the deep learning model is trained independently aiming at each line, and improve the generalization capability of the deep learning model.","['G01R31/081', 'G06N3/045', 'G06N3/08']"
CN111967266B,"Chinese named entity recognition system, model construction method, application and related equipment","The invention provides a Chinese named entity recognition model, a creation method thereof and a method applied to the field of network space security. The application of the Chinese named entity recognition model is based on transfer learning and a deep neural network, firstly, a Bert-BiLSTM-CRF model is trained on four general data sets recognized in the field of Chinese named entity recognition, and general knowledge features are fully learned; and then performing model migration, training a TBBC (Trans-Bert-BiLSTM-CRF) model after migration learning on a self-labeling network space security domain data set, learning to obtain the features of domain knowledge, outputting the model, finally obtaining a TBBC model with practical application value, and then performing Chinese named entity recognition. Through tests, the accuracy, recall rate and F1 value of the TBBC model obtained by the method are obviously improved, the recognition performance of the Chinese named entity is greatly improved, and the reality dilemma that the training data is insufficient and the recognition performance is lower when the named entity recognition task is carried out in a specific field can be effectively relieved.","['G06F40/295', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N7/01']"
CN117453921B,Data information label processing method of large language model,"The invention discloses a data information label processing method of a large language model, relates to the technical field of data information processing, and solves the defects of poor comprehensiveness, low reliability, strong limitation and poor accuracy in the traditional data information label processing method; according to the invention, the model learns the characteristics of the context on the primary task through the migration learning module; enriching semantic information of the text by a word embedding method; the generated labels can be classified according to types or purposes through a label classification algorithm based on machine learning; the irrelevant labels are removed through the keyword extraction model, and the accuracy and the relevance of the labels are improved; the text data, the image, the audio and the video data are fused through the multi-mode data fusion system, so that the context understanding capability of the model is improved; the important characteristics, the focus and the decision basis of the model in the reasoning process are displayed through the explanatory visualization module, so that the explanatory property of the model is enhanced.","['G06F16/353', 'G06F16/358', 'G06F16/367', 'G06F18/15', 'G06F18/2155', 'G06F18/2415', 'G06F18/253', 'G06F40/284', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/094', 'G06N3/096', 'G06N5/01', 'G06N5/022', 'G06N5/045', 'Y02D10/00']"
CN119623766B,Intelligent fusion of multi-source heterogeneous ocean data and marine disaster prediction method and platform,"The application relates to the technical field of data processing and discloses a multi-source heterogeneous ocean data intelligent fusion and ocean disaster prediction method and platform, wherein the method comprises the steps of carrying out hierarchical deployment and network topology construction on ocean environment monitoring equipment, communication relay equipment and data processing equipment to obtain an ocean-air-shore integrated monitoring network; the method comprises the steps of collecting marine environment data with space-time identification, carrying out marine element modeling and dynamic feature extraction to obtain a marine environment digital model, carrying out feature fusion and association analysis on multi-source heterogeneous marine data to obtain space-time feature data, carrying out training and multi-model integration on a typhoon path prediction model, a storm surge prediction model and a red tide prediction model by adopting a migration learning method to obtain a marine disaster prediction model set, further improving prediction precision and timeliness, optimizing distribution and scheduling of computing resources, and meeting real-time requirements of mass data processing.","['G06Q10/04', 'G06F18/10', 'G06F18/213', 'G06F18/2135', 'G06F18/253', 'G06N20/20', 'G06N3/006', 'G06N3/044', 'G06N3/0464', 'G06N3/094', 'G06N3/096', 'Y02A90/10']"
CN109784204B,Method for identifying and extracting main fruit stalks of stacked cluster fruits for parallel robot,"The invention discloses a method for identifying and extracting main fruit stalks of stacked cluster fruits for a parallel robot. A stereoscopic vision detection system of the fruits is constructed based on a Kinect sensor, three-dimensional visual information is obtained, a data set is constructed, and the distribution range of the data set is enlarged through an image processing method. And constructing a convolutional neural network to increase the characteristic quantity. The existing Faster R-CNN is improved based on the constructed CNN framework, the cascade of the Faster R-CNN is realized by designing a strategy of sharing parameters from coarse to fine, and background interference is reduced. A multi-migration learning training strategy is designed to train the network until the precision reaches the standard, the trained fast R-CNN from coarse to fine cascade meeting the requirement of testing precision is used for realizing the on-line main fruit stem identification and extraction of the stacked fruits in the parallel robot fruit sorting system, the identification and extraction precision and efficiency are improved, and a foundation is laid for the parallel robot based on stereoscopic vision to realize the accurate, quick and lossless automatic sorting of the stacked fruits.",['Y02P90/30']
US20230325725A1,Parameter Efficient Prompt Tuning for Efficient Models at Scale,"Systems and methods for natural language processing can leverage trained prompts to condition a large pre-trained machine-learned model to generate an output for a specific task. For example, a subset of parameters may be trained for the particular task to then be input with a set of input data into the pre-trained machine-learned model to generate the task-specific output. During the training of the prompt, the parameters of the pre-trained machine-learned model can be frozen, which can reduce the computational resources used during training while still leveraging the previously learned data from the pre-trained machine-learned model.","['G06N20/20', 'G06V10/764', 'G06V10/7747', 'G06F16/2455', 'G06F16/55', 'G06F40/30', 'G06N3/0455', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06V10/776', 'G06V10/82']"
CN111223553B,Two-stage deep transfer learning traditional Chinese medicine tongue diagnosis model,"A two-stage deep transfer learning tongue diagnosis model of traditional Chinese medicine belongs to the technical field of traditional Chinese medicine auxiliary diagnosis and treatment. Firstly, a depth network is constructed based on a depth convolution characteristic paradigm, a pyramid strategy is utilized to fuse multi-scale characteristics, and a deep abstract representation of an input tongue image is constructed. Then, two-stage deep migration learning is designed, the recognition capability of the tongue image diagnosis on the characteristic of the representative lesion is obtained in a targeted manner, the problem of data deficiency is effectively solved, and the training cost is reduced. On the basis, a focus checking cost function is designed, a depth migration model is trained, detection is carried out from different scales, abnormal tongue image focuses are marked, and detection accuracy is improved. And finally, simulating the process of 'many diagnosis and combined parameters' of traditional Chinese medicine diagnosis and treatment according to the inspection result of the depth migration model, and carrying out real-time judgment on abnormal tongue images so as to improve the diagnosis accuracy. The model designed by the invention can simulate the traditional Chinese medicine diagnosis theory, diagnose abnormal tongue images in real time and provide clinical assistance and diagnosis and treatment suggestions for traditional Chinese medicine.","['G16H20/90', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06V40/10', 'G16H50/20', 'Y02A90/10']"
US11645835B2,"Hypercomplex deep learning methods, architectures, and apparatus for multimodal small, medium, and large-scale data representation, analysis, and applications","A method and system for creating hypercomplex representations of data includes, in one exemplary embodiment, at least one set of training data with associated labels or desired response values, transforming the data and labels into hypercomplex values, methods for defining hypercomplex graphs of functions, training algorithms to minimize the cost of an error function over the parameters in the graph, and methods for reading hierarchical data representations from the resulting graph. Another exemplary embodiment learns hierarchical representations from unlabeled data. The method and system, in another exemplary embodiment, may be employed for biometric identity verification by combining multimodal data collected using many sensors, including, data, for example, such as anatomical characteristics, behavioral characteristics, demographic indicators, artificial characteristics. In other exemplary embodiments, the system and method may learn hypercomplex function approximations in one environment and transfer the learning to other target environments. Other exemplary applications of the hypercomplex deep learning framework include: image segmentation; image quality evaluation; image steganalysis; face recognition; event embedding in natural language processing; machine translation between languages; object recognition; medical applications such as breast cancer mass classification; multispectral imaging; audio processing; color image filtering; and clothing identification.","['G06V10/82', 'G06F18/2148', 'G06F18/2413', 'G06F18/251', 'G06K9/6257', 'G06K9/627', 'G06K9/6289', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/046', 'G06V10/454', 'G06V10/764', 'G06V10/7747', 'G06V10/803', 'G06V10/98', 'G06V20/13', 'G06V20/64', 'G06V20/194']"
US20190341025A1,Integrated understanding of user characteristics by multimodal processing,"A system and method for multimodal classification of user characteristics is described. The method comprises receiving audio and other inputs, extracting fundamental frequency information from the audio input, extracting other feature information from the video input, classifying the fundamental frequency information, textual information and video feature information using the multimodal neural network.","['G10L15/16', 'G10L25/63', 'G10L15/26', 'G10L17/02', 'G10L17/18', 'G10L25/30', 'G10L25/90']"
US11586838B2,End-to-end fuzzy entity matching,Systems and techniques for end-to-end fuzzy entity matching are described herein. A first input and a second input may be received. The first input and the second input may be evaluated to identify common attribute types. A set of attribute entity matching models may be selected that correspond to the attribute types. The first input and the second input may be evaluated using the set of attribute entity matching models to determine a set of weighted scores for attribute pairs in the first input and the second input. The set of weighted scores may be evaluated using a table-level entity matching model to identify a common entity included in the first input and the second input. A linking dataset may be generated that includes a cross-linking facility indicating a relationship between a first entity descriptor in the first input and a second entity descriptor in the second input.,"['G06K9/6201', 'G06F16/215', 'G06F17/18', 'G06F18/22', 'G06F18/24133', 'G06N20/00', 'G06N3/042', 'G06N3/044', 'G06N3/0442', 'G06N3/09', 'G06N3/096', 'G06N5/02', 'G06N5/048', 'G06N7/02', 'G06V10/768', 'G06V10/82']"
CN111724083B,"Training method and device for financial risk identification model, computer equipment and medium","The application discloses a training method, a training device, computer equipment and a medium of a financial risk identification model. According to the method, the classifier corresponding to the target domain financial project is trained by using a meta-learning mode, priori knowledge in the source domain task can be effectively migrated, so that the data size of the labeled sample required by model training is small, the generalization performance of the identification model is improved, and the training process of the model is quicker and more efficient. In addition, the application learns the source domain correlation among the categories of each task set in the training process of the meta learner, can effectively migrate priori knowledge from the task which is closer to the current target domain task in the migration learning process, and can improve the accuracy of model identification. The application can be widely applied to the technical field of machine learning.","['G06Q10/0635', 'G06F18/24133', 'G06N20/00', 'G06Q40/00', 'Y02D10/00']"
CN111461209B,Model training device and method,"The invention discloses a model training device and method, which are used for determining an original training sample set of a neural network model, wherein the original training sample set comprises a sample video, the sample video comprises marked sample graphs, the marked sample graphs comprise bounding boxes with the number of preset numbers, and the bounding boxes are used for representing characteristic information of objects in one frame of image in the sample video; constructing a target recognition model based on the marked sample graph, wherein the target recognition model is used for recognizing characteristic information of objects in a sample video; and constructing a classification model based on the target recognition model, wherein the classification model is used for detecting the validity of the boundary box. The neural network model is applied to the field of image processing, and can further ensure the accuracy of image feature recognition on the basis of reducing the training cost of the neural network model deep learning.","['G06F18/214', 'G06F18/217', 'G06N3/08']"
CN112766596B,"Construction method of building energy consumption prediction model, energy consumption prediction method and device","The application relates to a building energy consumption prediction model construction method, an energy consumption prediction method and an energy consumption prediction device, and relates to the field of computers, comprising the following steps: acquiring actual operation data and basic data of a target building to be predicted; the actual operation data comprise operation environment data and historical energy consumption data of a target building to be predicted; and predicting to obtain the corresponding time-by-time energy consumption of the target building in the predicted day by adopting a pre-constructed energy consumption prediction model. The building energy consumption prediction model is obtained by training by adopting a transfer learning method. The method can solve the problems that the traditional machine learning method only fits the actual running data of the target building, establishes a corresponding prediction model, has inaccurate prediction results due to insufficient data quantity and cannot be popularized to other projects for application.","['G06Q10/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06Q50/06']"
CN113610787B,"Training method, device and computer equipment for image defect detection model","The application relates to a training method, a training device, computer equipment and a storage medium of an image defect detection model. The method comprises the following steps: a plurality of unlabeled generated images belonging to the target domain may be generated by a first generator in the trained feature enhancement model. In this way, a generated image with greatly enhanced characteristics can be obtained, and then clustering processing is carried out on the generated image to obtain the category corresponding to each generated image; constructing each class of countermeasure models, and obtaining each class of countermeasure models after training based on the generated images of the same class; the random variable data and the noise data are acquired and input to a second generator in each class countermeasure model in a superposition mode, class feature images of each class are generated greatly, the condition of insufficient sample size is relieved greatly, the condition of fitting is avoided, a trained defect detection model with improved generalization capability is obtained based on each class feature image, and then accuracy and recall rate of micron-level defect detection are improved greatly.","['G06T7/0004', 'G06F18/214', 'G06F18/23', 'G06F18/23213', 'G06N3/045', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US20190095764A1,Method and system for determining objects depicted in images,"Techniques are disclosed for identifying objects in images. In one embodiment, transfer learning is employed to build new classifiers on top of pre-trained machine learning models, such as pre-trained convolutional neural networks (CNNs), by re-training classification layers of the pre-trained machine learning models using new training data while keeping feature detection layers of the pre-trained machine learning models fixed. Subsequently, the re-trained machine learning models may take as input images depicting regions of interest extracted from larger images using a sliding window, a saliency map, an image disparity map, and/or a region of interest detection technique, and output classifications of objects in the input images. In addition, a meta model may be learned that aggregates outputs of the re-trained machine learning models for robustness.","['G06K9/66', 'G06V10/82', 'G06F16/5838', 'G06F18/214', 'G06F18/2413', 'G06F18/24133', 'G06F18/2433', 'G06K9/00637', 'G06K9/40', 'G06K9/44', 'G06K9/6256', 'G06K9/627', 'G06K9/6284', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V20/00', 'G06V20/176', 'G06V30/19173', 'G06F17/30256']"
US10794609B2,"Methods and systems for personalized heating, ventilation, and air conditioning","Systems and methods for controlling an operation of devices for an occupant. A processor to iteratively train a personalized thermal comfort model (PTCM) during an initialization period. Receive a sequence of unlabeled real-time data. A transmitter requests the occupant to label an instance of unlabeled data, when there is a disagreement between the labels of stored historical labeled data (LD) similar to received unlabeled data and a predicted label on the new unlabeled data that exceeds a threshold. The processor, in response to receiving the labeled data, trains the PTCM using different weights of the personalized LD than to the historical LD. Retrains PTCM using the historical database and the updated personalized database. A controller controls the set of devices based on the retrained PTCM.","['F24F11/63', 'G05B13/048', 'F24F11/80', 'G05B13/0295', 'G05B15/02', 'F24F2120/20', 'G05B2219/2642']"
US7869425B2,System and method for providing requested quality of service in a hybrid network,"Telephone calls, data and other multimedia information is routed through a hybrid network which includes transfer of information across the internet. A media order entry captures complete user profile information for a user. This profile information is utilized by the system throughout the media experience for routing, billing, monitoring, reporting and other media control functions. Users can manage more aspects of a network than previously possible, and control network activities from a central site. The hybrid network also contains logic for responding to requests for quality of service and reserving the resources to provide the requested services.","['H04L41/5054', 'H04L12/14', 'H04L12/1403', 'H04L12/1428', 'H04L12/1439', 'H04L12/1446', 'H04L12/1453', 'H04L12/1482', 'H04L12/1485', 'H04L12/1492', 'H04L12/1822', 'H04L12/6418', 'H04L41/18', 'H04L41/5003', 'H04L41/5029', 'H04L43/50', 'H04L47/10', 'H04L47/2441', 'H04L47/72', 'H04L47/724', 'H04L47/781', 'H04L47/805', 'H04L47/808', 'H04L47/822', 'H04L47/83', 'H04L61/00', 'H04L61/45', 'H04L63/04', 'H04L63/083', 'H04L63/0853', 'H04L63/102', 'H04L65/1043', 'H04L65/1096', 'H04L65/1106', 'H04L65/401', 'H04L65/80', 'H04L67/02', 'H04M15/00', 'H04M15/55', 'H04M15/8016', 'H04M3/42068', 'H04M3/42161', 'H04M7/123', 'H04M7/1275', 'H04L2012/6456', 'H04L41/0659', 'H04L41/5067', 'H04L41/5074', 'H04L41/5087', 'H04M2215/2046', 'H04M2215/7414']"
US8396687B2,Machine logic airtime sensor for board sports,"An airtime sensor for board sports includes a detector for generating signals representative of vibration associated with motion of a board sports vehicle along a surface. State machine logic filters the signals through a first low pass filter, filters the signals through a second low pass filter, and combines filtered signals from the first and second low pass filters to determine airtime.","['A63F13/798', 'A01K29/005', 'A43B3/34', 'A61B5/0002', 'A61B5/0022', 'A61B5/02438', 'A61B5/0816', 'A61B5/1112', 'A61B5/1113', 'A61B5/1117', 'A61B5/1118', 'A61B5/14532', 'A61B5/14542', 'A61B5/22', 'A61B5/4866', 'A61B5/6807', 'A61B5/681', 'A61B5/721', 'A63B24/00', 'B68B1/00', 'B68C1/00', 'G01B21/16', 'G01G19/44', 'G01G23/00', 'G01G23/3728', 'G01L1/04', 'G01L1/16', 'G01L1/22', 'G01P1/127', 'G01P15/00', 'G01P15/0891', 'G01P15/18', 'G01P3/00', 'G01P3/50', 'G01S1/08', 'G01S19/00', 'G06F11/3089', 'G06Q10/08', 'G07C1/10', 'G07C1/24', 'G08B5/36', 'G08G1/20', 'G08G9/00', 'G16Z99/00', 'H04L43/00', 'H04L43/04', 'H04M1/72412', 'H04Q9/00', 'H04W4/02', 'H04W4/027', 'H04W76/14', 'H05K5/0247', 'A42B3/046', 'A61B2503/04', 'A61B2503/10', 'A61B2560/0214', 'A61B2560/0242', 'A61B2560/0285', 'A61B2560/0412', 'A61B2560/0456', 'A61B2562/166', 'A61B5/1114', 'A61B5/112', 'A61B5/1122', 'A61B5/6833', 'A61B5/7242', 'A63B2208/12', 'A63B2220/30', 'A63B2220/40', 'A63B2220/50', 'A63B2225/50', 'A63B69/0028', 'A63B69/16', 'A63B69/26', 'H04Q2209/40', 'H04W4/33']"
US20220122001A1,Imitation training using synthetic data,"Approaches presented herein provide for the generation of synthetic data to fortify a dataset for use in training a network via imitation learning. In at least one embodiment, a system is evaluated to identify failure cases, such as may correspond to false positives and false negative detections. Additional synthetic data imitating these failure cases can then be generated and utilized to provide a more abundant dataset. A network or model can then be trained, or retrained, with the original training data and the additional synthetic data. In one or more embodiments, these steps may be repeated until the evaluation metric converges, with additional synthetic training data being generated corresponding to the failure cases at each training pass.","['G06N20/20', 'G06N3/084', 'A63F13/50', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0454']"
CN115136246B,Machine learning guided polypeptide design,"Systems, devices, software, and methods for engineering amino acid sequences configured to have a particular protein function or property. The method implements machine learning to process an input seed sequence and generate as output an optimized sequence having a desired function or property.","['G06N3/02', 'G16B15/00', 'G16B15/20', 'G16B35/10', 'G16B40/30', 'G16B45/00']"
CN113158850B,Ship driver fatigue detection method and system based on deep learning,"The invention discloses a ship driver fatigue detection method and system based on deep learning. The fatigue detection method comprises the following steps: acquiring a current video frame image; face detection is carried out through an improved Retinaface detection network, and 5 face key points of a left eye, a right eye, a nose tip, a left mouth corner and a right mouth corner are marked at the same time; adaptively cutting out images of eyes and mouths according to positions of 5 face key points, and identifying opening and closing states of the eyes and the mouths through an improved ShuffleNet v2 convolutional neural network; calculating PERCLOS parameters of eyes and mouth; and comprehensively judging whether the driver is tired or not by fusing the eye and mouth PERCLOS parameters through a random forest model. The invention can rapidly realize face detection and key point positioning, does not need to manually extract picture information, can automatically identify the opening and closing states of eyes and mouth, and fuses the characteristic parameters of the eyes and the mouth based on the thought of multi-characteristic fusion, thereby rapidly and accurately detecting the fatigue state of a ship driver.","['G06V20/597', 'G06F18/214', 'G06N3/006', 'G06N3/045', 'G06V40/165', 'G06V40/171']"
US20230111593A1,Method of predicting response to chimeric antigen receptor therapy,"This disclosure provides methods and systems for determining a lesion-level treatment response to a chimeric antigen receptor (CAR) therapy, e.g., a CAR CD19 therapy, and uses of said methods and systems for evaluating the responsiveness of a subject to a CAR CD19 therapy, and for treating a subject with a CAR CD19 therapy.","['G16H50/50', 'G16H50/20', 'A61K35/17', 'A61K38/1774', 'A61K40/11', 'A61K40/31', 'A61K40/4211', 'A61P35/00', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'A61K2239/48', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03', 'Y02A90/10']"
US11893363B2,Unit test case generation with transformers,"A unit test generation system employs a neural transformer model with attention to generate candidate unit test sequences given a focal method of a programming language. The neural transformer model is pre-trained with source code programs and natural language text and fine-tuned with mapped test case pairs. A mapped test case pair includes a focal method and a unit test case for the focal method. In this manner, the neural transformer model is trained to learn the semantics and statistical properties of a natural language, the syntax of a programming language and the relationships between the code elements of the programming language and the syntax of a unit test case.","['G06F8/35', 'G06F11/3684', 'G06F17/18', 'G06F40/30', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/046', 'G06N7/01']"
CN109359557B,SAR remote sensing image ship detection method based on transfer learning,"The invention relates to a method for detecting a ship by using an SAR remote sensing image based on transfer learning, which mainly solves the problems that the existing SAR remote sensing image has no label of the ship and deep learning cannot be directly applied to the ship detection of the SAR remote sensing image. The method comprises the following specific steps: (1) preparing a related data set comprising an optical remote sensing image ship data set and an SAR remote sensing image data set; (2) designing a corresponding network structure and a loss function based on the idea of transfer learning, and simultaneously training a network by utilizing an optical remote sensing image and an SAR remote sensing image data set; (3) and carrying out ship detection on the SAR remote sensing image through the trained model. By utilizing the commonality of the ships in the optical remote sensing image and the SAR remote sensing image, even if no ship label is marked in the SAR remote sensing image during model training, the ships in the SAR remote sensing image can still be detected.","['G06V20/13', 'G06F18/24', 'G06N3/045', 'G06N3/084']"
CN111310934B,"A model generation method, device, electronic device and storage medium","The application discloses a model generation method, a model generation device, electronic equipment and a storage medium, relates to the technical field of artificial intelligence, and particularly relates to the technical field of deep learning. The specific implementation scheme is as follows: determining data used by model training according to the detected first user operation on the current application interface; model training is carried out based on data through a deep learning framework module integrated in the current application; and generating and outputting a code file corresponding to the trained model according to the model deployment environment. According to the embodiment of the application, the client can be visualized through integrating the application of the deep learning framework, so that a developer only needs to operate on an application interface to realize the training of the model, and the developer does not need to know the program development and grasp the details of the relevant interfaces and parameter adjustment modes of the deep learning framework program, so that the model training based on the deep learning framework can be realized, and further, the code file of the trained model is obtained, thereby improving the model training efficiency and reducing the workload.","['G06N20/00', 'G06F8/61']"
CN107316078B,Apparatus and method for performing artificial neural network self-learning operation,"An apparatus and method for performing artificial neural network self-learning operations includes a controller unit, an interconnection module, a master operation module, and a plurality of slave operation modules. The self-learning pre-training of the multi-layer neural network can be completed by the self-learning pre-training of each layer network after the self-learning pre-training of the layer network is completed through multiple operation iterations until the weight updating is smaller than a certain threshold value according to a training mode of layer-by-layer training. The first visible layer intermediate value and the second hidden layer intermediate value are respectively calculated and generated in the first three stages, and the weights are updated in the last stage by using the intermediate values in the first three stages.","['G06N3/045', 'G06N3/063', 'G06N3/08']"
US11064902B2,"Systems, methods, and media for automatically diagnosing intraductal papillary mucinous neosplasms using multi-modal magnetic resonance imaging data","In accordance with some embodiments, systems, methods, and media for automatically diagnosing IPMNs using multi-modal MRI data are provided. In some embodiments, a system comprises: an MRI scanner; and a processor programmed to: prompt a user to select a slice of T1 and T2 MRI data including the subject's pancreas; generate minimum and maximum intensity projections based consecutive slices of the T1 and T2 MRI data; provide the projections to an image recognition CNN, and receive feature vectors for each from a fully connected layer; perform a canonical correlation analysis to determine correlations between the feature vectors; and provide a resultant vector to an SVM that determines whether the subject's pancreas includes IPMNs based on a vector.","['A61B5/055', 'A61B5/7267', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G16H50/70']"
US11989262B2,Unsupervised domain adaptation with neural networks,"Approaches presented herein provide for unsupervised domain transfer learning. In particular, three neural networks can be trained together using at least labeled data from a first domain and unlabeled data from a second domain. Features of the data are extracted using a feature extraction network. A first classifier network uses these features to classify the data, while a second classifier network uses these features to determine the relevant domain. A combined loss function is used to optimize the networks, with a goal of the feature extraction network extracting features that the first classifier network is able to use to accurately classify the data, but prevent the second classifier from determining the domain for the image. Such optimization enables object classification to be performed with high accuracy for either domain, even though there may have been little to no labeled training data for the second domain.","['G06F18/2148', 'G06F18/2155', 'G06F18/217', 'G06F18/22', 'G06F18/2321', 'G06F18/24', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06N3/096', 'G06V10/40', 'G06V10/761', 'G06V10/762', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V10/96', 'G06F18/2415', 'G06N3/048']"
CN111723679B,Face and voiceprint authentication system and method based on deep migration learning,"The invention provides a face and voiceprint authentication system and method based on deep transfer learning, comprising the following steps: and a user terminal module: collecting and constructing a face and voiceprint image data set and returning a verification result; training module: the method comprises a data preprocessing algorithm, a user living body detection algorithm, a deep convolutional neural network model construction, fusion of a transfer learning algorithm, training of the convolutional neural network model and a model integration algorithm of the convolutional neural network; data and model storage module: the method comprises the steps of storing a face data set and a voiceprint data set, and storing a face recognition model and a voiceprint recognition model after training of a network model. The invention applies face recognition and voiceprint recognition to the system verification process, and a user does not need to input user name and password and other operations, so that the system login process is simpler, the user does not need to worry about the problems caused by the fact that the user name and password are stolen and forgotten, and the login experience of the user is improved.","['G06V40/165', 'G06F18/25', 'G06F21/32', 'G06N3/045', 'G06N3/084', 'G06V40/171', 'G06V40/172']"
US10140522B2,Fully convolutional pyramid networks for pedestrian detection,"A fully convolutional pyramid network and method for object (e.g., pedestrian) detection are disclosed. In one embodiment, the object detection system is a pedestrian detection system that comprises: a multi-scale image generator to generate a set of images from an input image, the set of images being versions of the input image at different scales; a human body-specific fully convolutional network (FCN) model operable to generate a set of detection results for each image in the set of images that is indicative of objects that are potentially of human bodies; and a post processor to combine sets of detection results generated by the FCN model for the set of images into an output image with each object location determined as potentially being a human body being marked.","['G06K9/00771', 'G06V10/82', 'G06F18/254', 'G06K9/00791', 'G06K9/4628', 'G06K9/6292', 'G06K9/66', 'G06K9/6857', 'G06V10/454', 'G06V10/809', 'G06V20/52', 'G06V20/56', 'G06V20/58', 'G06V30/2504', 'G06V40/10']"
US12307336B2,Data manufacturing frameworks for synthesizing synthetic training data to facilitate training a natural language to logical form model,"Techniques are disclosed herein for synthesizing synthetic training data to facilitate training a natural language to logical form model. In one aspect, training data can be synthesized from original under a framework based on templates and a synchronous context-free grammar. In one aspect, training data can be synthesized under a framework based on a probabilistic context-free grammar and a translator. In one aspect, training data can be synthesized under a framework based on tree-to-string translation. In one aspect, the synthetic training data can be combined with original training data in order to train a machine learning model to translate an utterance to a logical form.","['G06N20/00', 'G06F16/24522', 'G06F16/3329', 'G06F16/90332', 'G06F40/211', 'G06F40/237', 'G06F40/284', 'G06F40/40', 'G06F40/47', 'G06F40/56', 'G06F40/58', 'G06N3/084', 'G06N5/046', 'H04L51/02', 'G06F40/205', 'G06F40/35', 'G06N3/0442', 'G06N3/0455', 'G06N3/096']"
CN111666836B,High-resolution remote sensing image target detection method of M-F-Y type light convolutional neural network,"A high-resolution remote sensing image target detection method of an M-F-Y type lightweight convolutional neural network belongs to the field of remote sensing. Firstly, constructing a characteristic pyramid network structure FPN on the basis of a lightweight Convolutional Neural Network (CNN) model MobileNet V3-Small, extracting and fusing multi-scale depth characteristics for a high-resolution remote sensing image, and constructing an M-F-Y lightweight convolutional neural network by jointly utilizing a YOLOv3tiny target detection frame; then, by constructing a complementary attention network structure, the complex background is restrained, and meanwhile, the attention to the spatial position information of the target is promoted; and finally, training a model by using a filter grafting strategy based on transfer learning to realize high-resolution remote sensing image target detection. The invention can improve the accuracy of detecting the target of the high-resolution remote sensing image, reduce the constraint on the high-speed computing power of the platform through less parameter quantity and lower delay, and provide technical accumulation for the practical use of the target detection of the high-resolution remote sensing image.","['G06V20/13', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V2201/07', 'Y02D10/00']"
US11631236B2,System and method for deep labeling,"An apparatus for contextual execution comprises a processor, and a memory containing instructions, which when executed by the processor, cause the apparatus to receive, from a user terminal, a control input associated with an intent, obtain location data associated with a location of the user terminal, and determine a scored set of execution options associated with the control input. Further, the instructions, when executed by the processor cause the apparatus to obtain a contextual label associated with the location data, the label determined based on the application of one or more adapted pretrained deep learning models to the location data.","['G06V10/82', 'G06F17/18', 'G06F18/214', 'G06F18/24', 'G06K9/6256', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N7/005', 'G06N7/01', 'G06V10/40', 'G06V10/764', 'G06V20/00', 'G06V20/176', 'G06N3/048', 'G06N3/0481']"
US20200160997A1,Method for detection and diagnosis of lung and pancreatic cancers from imaging scans,"A method of detecting and diagnosing cancers characterized by the presence of at least one nodule/neoplasm from an imaging scan is presented. To detect nodules in an imaging scan, a 3D CNN using a single feed forward pass of a single network is used. After detection, risk stratification is performed using a supervised or an unsupervised deep learning method to assist in characterizing the detected nodule/neoplasm as benign or malignant. The supervised learning method relies on a 3D CNN used with transfer learning and a graph regularized sparse MTL to determine malignancy. The unsupervised learning method uses clustering to generate labels after which label proportions are used with a novel algorithm to classify malignancy. The method assists radiologists in improving detection rates of lung nodules to facilitate early detection and minimizing errors in diagnosis.","['G16H50/20', 'A61B5/055', 'A61B5/7267', 'A61B6/032', 'A61B6/037', 'A61B6/12', 'A61B6/4417', 'A61B6/5217', 'A61B8/481', 'A61B8/5223', 'G06F18/2148', 'G06F18/23', 'G06F18/2411', 'G06K9/6218', 'G06K9/6257', 'G06K9/6269', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N5/04', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H70/60', 'A61B8/085', 'G06K2209/053', 'G06T2207/10081', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064', 'G06T2207/30096', 'G06V2201/03', 'G06V2201/032']"
US20220318621A1,Optimised Machine Learning,"Method for optimising a reinforcement learning model comprising the steps of receiving a labelled data set. Receiving an unlabelled data set. Generating model parameters to form an initial reinforcement learning model using the labelled data set as a training data set. Finding a plurality of matches for one or more target within the unlabelled data set using the initial reinforcement learning model. Ranking the plurality of matches. Presenting a subset of the ranked matches and corresponding one or more target, wherein the subset of ranked matches includes the highest ranked matches. Receiving a signal indicating that one or more presented match of the highest ranked matches is an incorrect match. Adding information describing the indicated incorrect one or more match and corresponding target to the labelled data set to form a new training data set. Updating the model parameters of the initial reinforcement learning model to form an updated reinforcement learning model using the new training data set.","['G06N3/006', 'G06N3/044', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N7/01']"
CN110569878B,Photograph background similarity clustering method based on convolutional neural network and computer,"The invention discloses a method for clustering photo background similarity based on a convolutional neural network, which comprises the following steps: preprocessing the original image based on a convolutional neural network algorithm to correct the direction of the identified target in the original image; carrying out example segmentation on the foreground image characteristics and the background image characteristics of the recognition target in the original image, and carrying out background extraction; carrying out background separation on the image subjected to instance segmentation; extracting the features of the separated background image to obtain a high-dimensional spatial feature map; and carrying out similarity clustering processing on the high-dimensional spatial feature map. The invention also provides a computer program system for implementing the method; the invention is based on the example segmentation algorithm of the pixel level, detect and get and remove the foreground area (portrait and ID card) under the real application scene, carry on the contrast of similarity through the background area, utilize the convolution neural network that the migration trains and gets at the same time can greatly raise the accuracy rate that discerns.","['G06F18/231', 'G06V10/243', 'G06V10/267', 'G06V40/16', 'G06V40/161']"
US10878388B2,Systems and methods for artificial-intelligence-based automated surface inspection,"The disclosed computer-implemented method for artificial-intelligence-based automated surface inspection can include receiving customer data, a request for a targeted model, and compensation for the requested targeted model. The compensation can include an agreement to contribute the customer data and/or targeted model to be available for other third-party entities. The method can also include retrieving the pre-trained model from a pre-trained model pool. The pre-trained model can be related to objects in a second industry. The method can include generating the targeted model from the pre-trained model and the customer data. The targeted model can be related to mapping sensor data to surface anomalies. The method can also include providing the targeted model to the third-party entity. The method can further include updating a distributed blockchain structure to include the at least one of the customer data and the targeted model.","['G06Q20/065', 'G06Q20/123', 'G06F21/55', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06Q20/0655', 'G06F16/35', 'G06F2221/034']"
EP4134865A1,"Language representation model system, pre-training method and apparatus, device and medium","Disclosed in embodiments of the present disclosure are a language representation model system, a language representation model pre-training method and apparatus, a natural language processing method and apparatus, a device, and a medium. The language representation model system includes: a word granularity language representation sub-model based on segmentation in units of words, and a phrase granularity language representation sub-model based on segmentation in units of words, where the word granularity language representation sub-model is configured to output, based on a sentence segmented in units of words, a first semantic vector corresponding to a semantic expressed by each segmented word in the sentence, and the phrase granularity language representation sub-model is configured to output, based on the sentence segmented in units of phrases, a second semantic vector corresponding to a semantic expressed by each segmented phrase in the sentence. According to the technical solutions in the embodiments of the present disclosure, a mixed-granularity language representation model is provided, which provides a model basis for a downstream natural language processing task, and is conductive to improvement of the processing precision of the downstream natural language processing task, and to improvement of the transfer effect of the language representation model.","['G06F40/40', 'G06F40/30', 'G06F16/355', 'G06F40/205', 'G06F40/216', 'G06F40/289']"
CN107679580B,A sentiment polarity analysis method for heterogeneous transfer images based on multimodal deep latent correlation,"The invention provides a heterogeneous migration image emotion polarity analysis method based on multi-mode depth potential correlation, which comprises the following steps of: 1) constructing an initial emotion image data set; taking the emotion polarity corresponding to the emotion vocabulary as an image emotion polarity label; 2) clearing noise data in the initial emotion image data set; removing noise by using an emotion consistency judging method and a probability sampling model based on a multi-mode deep convolutional neural network; 3) constructing a heterogeneous migration model based on multi-modal deep potential correlation; then training a source field text and a target field image; 4) constructing a multi-mode embedding space; embedding semantic information of a source field text into a target field image; 5) and training the image emotion polarity classifier to perform image emotion polarity analysis. The method has the advantages of large available data scale, low labor cost, low data noise, high prediction precision, strong model interpretability and strong classification capability, and can achieve better image emotion polarity analysis effect.","['G06F18/214', 'G06F18/241', 'G06N3/045']"
CN110415215B,Intelligent detection method based on graph neural network,"The invention provides an intelligent detection method based on a graph neural network, which comprises the following steps: collecting data, preprocessing, building a network model, pre-training, transfer learning, predicting and sampling inspection and verifying to perfect the whole prediction system; compared with manual detection, the method improves the accuracy and efficiency of component detection, reduces the intervention of human factors on detection, and reduces the labor cost and the detection cost. Compared with the traditional machine learning method, the graph neural network does not require that the composition form of data has a good spatial relationship, namely, the graph neural network has a matrix form which is arranged orderly, and the expression capability of the model is remarkably improved by the characteristic that the graph neural network can accept unstructured input. Compared with a convolution neural network method, the graph neural network can better learn the logical relationship of each element, so that the generalization capability of the model is improved. In the learning process of the network, each node is responsible for transmitting the information of the node and integrating the information of the neighbor nodes, so that the logical paradigm of learning and mastering data is realized.","['G06T7/0006', 'G06T7/10', 'G06T7/62', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30164', 'Y02B50/00']"
WO2021208490A1,Blood pressure measuring method and device based on deep neural network,"A blood pressure measuring method and device based on a deep neural network. The method comprises: receiving a signal acquisition request, the signal acquisition request at least carrying identification information of an acquisition object; performing a signal acquisition operation on the acquisition object to obtain a pulse wave and an electrocardiosignal; performing a preprocessing operation on the pulse wave and the electrocardiosignal to obtain a preprocessed signal; on the basis of a trained deep neural network blood pressure model, inputting the preprocessed signal into the deep neural network blood pressure model for a measurement operation to obtain systolic pressure and diastolic pressure corresponding to the preprocessed signal; and outputting the identification information, the systolic pressure, and the diastolic pressure.","['A61B5/7264', 'A61B5/021', 'A61B5/7267']"
US7313447B2,Temporary expanding integrated monitoring network,"A system for monitoring an industrial process and taking action based on the results of process monitoring. Actions taken may include process control, paging, voicemail, and input for e-enterprise systems. The system includes an input module for receiving a plurality of parameters from a process for manufacture of a substance or object. The system also includes a library module. The library module includes a plurality of computer aided processes. Any one of the computer aided processes is capable of using each of the plurality of parameters to compare at least two of the plurality of parameters against a training set of parameters. The training set of parameters is generally predetermined. The computer aided process is also capable of determining if the at least two of the plurality of parameters are within a predetermined range of the training set of parameters. Additionally, the system includes an output module for outputting a result based upon the training set and the plurality of parameters.","['G05B15/02', 'G05B19/042', 'G05B19/4093', 'G05B19/41855', 'G05B19/41865', 'G05B19/41875', 'G05B23/0221', 'G05B23/0235', 'G05B23/0243', 'G05B23/0254', 'G05B23/0286', 'G05B23/0294', 'G05B2219/31265', 'G05B2219/31337', 'G05B2219/31435', 'G05B2219/31457', 'G05B2219/32129', 'G05B2219/32194', 'G05B2219/32196', 'G05B2219/32201', 'G05B2219/32404', 'G05B2219/33209', 'G05B2219/35095', 'Y02A90/10', 'Y02P90/02', 'Y02P90/80']"
US20240348663A1,Ai-enhanced simulation and modeling experimentation and control,"An artificial intelligence-driven simulation and decision platform for reducing epistemic uncertainty in complex systems. The system integrates advanced techniques from artificial intelligence, simulation, and uncertainty quantification to generate and run scenarios, monitor progress, and adjust parameters in real-time to achieve user-defined goals. The simulation and decision platform comprises an AI system that employs natural language processing, reinforcement learning, and multi-objective optimization; a continuous and scalable simulation environment; scenario generation and guidance that provides human-readable scenario guides and contextual explanations; and an uncertainty quantification and reduction that employs entropy-based methods and Bayesian inference. The system allows users to define goals and objectives for their simulations, and the AI component generates and optimizes scenarios to achieve these goals while reducing epistemic uncertainty. The simulation and decision platform is designed to be flexible and adaptable to various domains and applications, providing a comprehensive and user-friendly solution for managing complex systems under uncertainty.","['H04L63/104', 'G06F16/2477', 'G06F16/951', 'H04L63/1425', 'H04L63/1441', 'H04L63/20', 'H04L67/10', 'H04L67/535', 'H04L67/55', 'H04L67/566', 'H04L67/02', 'H04L67/125']"
CN111325347B,Automatic danger early warning description generation method based on interpretable visual reasoning model,"A danger early warning description automatic generation method based on an interpretable visual reasoning model comprises the steps of establishing a priori knowledge base and a training database of a specific scene, and finely adjusting the model through transfer learning to obtain a plane target detector and a three-dimensional target detector aiming at the scene; then, aiming at a certain frame of video information, detecting the plane position characteristics of all target types and targets through a plane target detector, obtaining the three-dimensional space characteristics of all targets through a three-dimensional target detector in parallel, constructing a relation task graph under the frame of video by combining a priori knowledge base according to the detected target types, extracting the characteristics through a graph neural network, fusing the plane space characteristics and the three-dimensional space characteristics, sending the characteristics into a modular multilayer sensing machine for reasoning and learning, finally obtaining the danger level existing under the frame of video image and the object with the danger relation, and finally generating the Chinese description corresponding to the frame of video image by combining semantic conversion in the priori knowledge base.","['G06N5/04', 'G06F18/253', 'G06N3/045', 'G06N3/088', 'G06V20/41']"
US11580375B2,Accelerated training of a machine learning based model for semiconductor applications,Methods and systems for accelerated training of a machine learning based model for semiconductor applications are provided. One method for training a machine learning based model includes acquiring information for non-nominal instances of specimen(s) on which a process is performed. The machine learning based model is configured for performing simulation(s) for the specimens. The machine learning based model is trained with only information for nominal instances of additional specimen(s). The method also includes re-training the machine learning based model with the information for the non-nominal instances of the specimen(s) thereby performing transfer learning of the information for the non-nominal instances of the specimen(s) to the machine learning based model.,"['G06N3/08', 'G01Q30/02', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/067', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F30/20', 'G06N3/0454', 'G06T2207/10061']"
CN114022770B,Mountain crack detection method based on improved self-attention mechanism and transfer learning,"The invention provides a mountain crack detection method based on an improved self-attention mechanism and transfer learning, which comprises the steps of preprocessing a data set of a crack detection network to obtain a training set and a verification set; training a crack detection network by using the obtained training set, selecting a model with the best performance obtained by training the crack detection network by using the obtained verification set, testing the performance of the model on different road crack data sets, generalizing, and applying the processed model to mountain crack detection by using a migration learning method. The invention provides a novel crack detection network structure for high-precision mountain crack detection application scenes and research on extraction modes of different scale features of pictures, and the novel network is elaborated from a structural layer and a formula layer. The invention uses different data experiments to explain how the network is applied to a specific detection scene, and shows the advantages of the novel algorithm by comparing the performance with a representative method.","['G06F18/214', 'G06N3/045', 'G06N3/08']"
CN111966914B,Content recommendation method and device based on artificial intelligence and computer equipment,"The application relates to a content recommendation method and device based on artificial intelligence and computer equipment. The method comprises the following steps: acquiring source domain user characteristics corresponding to a new user of a target domain in a source domain; performing feature mapping on the source domain user features through a trained task-oriented mapping model to obtain mapping user features mapped from the source domain to the target domain; through a pre-trained content recommendation model, click prediction of recommended content is carried out according to the mapping user characteristics and the target domain content characteristics of each candidate content in the target domain; screening contents to be recommended from the candidate contents according to a click prediction result; and pushing the content to be recommended to the new user of the target domain. By adopting the method, the accuracy of content recommendation for the new user can be effectively improved.","['G06F16/9535', 'G06F16/958', 'G06N20/00']"
CN117151220B,Entity link and relationship based extraction industry knowledge base system and method,"The application discloses an industry knowledge base system and method based on entity link and relation extraction, relates to the technical field of knowledge base construction, which comprises the following steps: using an entity recognition model based on transfer learning, obtaining an entity contained in the text; the method comprises the steps of performing feature extraction and fusion on multi-modal information containing text features, image features and audio features by adopting a deep learning model, and outputting the fused multi-modal features of an entity; generating candidate entities for each input entity from a knowledge base by adopting a method based on character string matching and word vector matching, and selecting the candidate entity which is most matched with the context information for linking by using a joint inference model based on a knowledge graph; extracting the relation between the linked entities from the input text by adopting a method based on dependency syntactic analysis and semantic role labeling; and constructing an industry field knowledge graph. Aiming at the problem of low entity link accuracy in the prior art, the method and the device improve the entity link accuracy in the knowledge base construction process.","['G06N5/022', 'G06F16/901', 'G06F16/90344', 'G06F18/256', 'G06F40/211', 'G06F40/279', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N5/041', 'Y02D10/00']"
CN110619283B,Automatic extraction method for unmanned aerial vehicle ortho-image road,"The invention provides an automatic extraction method of an orthophoto image road of an unmanned aerial vehicle, which comprises the following steps of S1: performing data enhancement on the original high-resolution satellite image training data to obtain the high-resolution satellite image training data with the quantity expanded; step S2: building a depeplab model in a keras; and step S3: performing data enhancement on original unmanned aerial vehicle orthoimage data to obtain image data with enlarged quantity; and step S4: obtaining a final deep learning model by using the depeplab model established in the step S2; step S5: and performing test enhancement on the test picture to obtain a final prediction result. The method can be used for automatically segmenting pixel points belonging to road targets from a large number of unmanned aerial vehicle ortho images, and greatly improves the speed of extracting map elements such as roads in the surveying and mapping field.","['G06F18/214', 'G06F18/217', 'G06V20/182']"
CN109344884B,"Media information classification method, method and device for training picture classification model","The application discloses a media information classification method, which comprises the steps of obtaining media information to be classified, inputting the media information to be classified into a picture classification model, obtaining a class label of the media information to be classified output by the picture classification model as a first class label, and determining the class of the media information to be classified according to the first class label. According to the method, a neural network model is obtained through training of a machine learning method, the media information to be classified is classified based on the picture classification model, picture feature vectors are generated mainly through learning of picture information in the media information to be classified through the neural network, and the media information is classified according to the picture feature vectors, so that the classification accuracy can be improved for multi-picture and less-text media information to be classified. The application also discloses a method for training the picture classification model, a media information classification device, a device for training the picture classification model, media information classification equipment, equipment for training the picture classification model and a computer storage medium.","['G06F18/2148', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
CN112926324B,Vietnamese Event Entity Recognition Method Fusion Dictionary and Adversarial Transfer,"The invention relates to a Vietnamese event entity recognition method for fusing dictionaries and resisting migration. The method takes Vietnamese as a target language, English and Chinese as source languages respectively, and improves the entity recognition effect of the target language by utilizing the entity marking information and the bilingual dictionary of the source language. The method comprises the steps of firstly utilizing word level anti-migration to realize semantic space sharing of a source language and a target language, then fusing a bilingual dictionary to embed multi-granularity features so as to enrich semantic representation of target language words, then utilizing sentence level anti-migration to extract sequence features irrelevant to languages, and finally marking an entity recognition result through CRF. Experimental results on the vietnamese news data set show that in the case that the source languages are english and chinese, the entity recognition effect of the proposed model is improved compared with that of the monolingual entity recognition model and that of the current mainstream transfer learning model, and the F1 values are respectively increased by 19.61 and 18.73 compared with that of the monolingual entity recognition model.","['G06F40/295', 'G06F16/35', 'G06F40/216', 'G06F40/242', 'G06F40/30', 'G06F40/47', 'G06N3/045', 'G06N3/08']"
US11783227B2,"Method, apparatus, device and readable medium for transfer learning in machine learning","A method, apparatus, device and readable medium for transfer learning in machine learning are provided. The method includes: constructing a target model according to the number of classes to be achieved by a target task and a duly-trained source model; obtaining a value of a regularized loss function of the corresponding target model and a value of a cross-entropy loss function of the target model, based on sets of training data in a training dataset of the target task; according to the value of the regularized loss function and the value of the cross-entropy loss function corresponding to each set of training data, updating parameters in the target model by a gradient descent method to implement the training of the target model. The above technical solution avoids excessive constraints on parameters in the prior art, thereby refraining from damaging the training effect of the source model on the target task.","['G06N20/00', 'G05B13/042', 'G06F11/3452', 'G06F18/214', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096']"
US11557276B2,Ontology integration for document summarization,"A method includes obtaining parameters and a document, determining a domain based on the parameters, where the domain maps to a first ontology, and where ontologies map n-grams onto a set of concepts. The method includes scoring a first set of n-grams of the document using a scoring model based on relations between members of the first set of n-grams, selecting sections of the text based on n-gram scores provided by the scoring model, and determining an initial n-gram set, where each respective n-gram of the initial n-gram set maps to a respective concept of the set of concepts, and where each respective n-gram is identified by an ontology other than the first ontology. The method includes determining related n-grams mapped to the set of concepts associated with the domain and generating a text summary for the document based on the sections and the related n-grams.","['G10L15/063', 'G06F40/30', 'G06F16/2237', 'G06F16/248', 'G06F16/322', 'G06F16/328', 'G06F16/3323', 'G06F16/3329', 'G06F16/3338', 'G06F16/3344', 'G06F16/3347', 'G06F16/345', 'G06F16/367', 'G06F16/90332', 'G06F40/20', 'G06F40/289', 'G06F40/40', 'G06F9/451', 'G06F9/547', 'G06N20/00', 'G06N3/04', 'G06N3/0455', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/022', 'G10L15/16', 'G10L15/197', 'G16H50/70', 'G16H70/60', 'G06F9/453', 'G06N3/044', 'G06N3/045', 'G16B50/10', 'G16H10/60', 'G16H40/20', 'G16H70/20', 'Y02A90/10']"
CA3062891C,Natural language processing using context-specific word vectors,"(57) Abstract: A system is provided for natural language processing. In some embodiments, the system includes an encoder for generating context-specific word vectors for at least one input sequence of words. The encoder is pre-trained using training data for performing a first natural language processing task. A neural network performs a second natural language processing task on the at least one input sequence of words using the context-specific word vectors. The first natural language process task is different from the second natural language processing task and the neural network is separately trained from the encoder. In some embodiments, the first natural processing task can be machine translation, and the second natural processing task can be one of sentiment analysis, question classification, entailment classification, and question answering.","['G06F40/126', 'G06N3/08', 'G06F40/205', 'G06F40/289', 'G06F40/30', 'G06F40/47', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/09', 'G06N3/096', 'G06F40/44', 'G06F40/58']"
CN112869711B,An automatic sleep staging and migration method based on deep neural network,"The invention discloses an automatic sleep staging and migration method based on a deep neural network, which comprises the following steps of S1, collecting sleep electroencephalogram and electro-oculogram signals of a subject as a target data set for migration learning; s2, selecting a data set as a source data set for transfer learning; s3, preprocessing the data in the source data set and the target data set; s4, constructing an automatic sleep staging model based on a deep neural network; the invention provides an improved automatic sleep staging model based on a deep neural network and a migration method thereof.","['A61B5/4812', 'A61B5/4806', 'A61B5/7203', 'A61B5/7225', 'A61B5/7264', 'A61B5/7267']"
US11676008B2,Parameter-efficient multi-task and transfer learning,"The present disclosure provides systems and methods that enable parameter-efficient transfer learning, multi-task learning, and/or other forms of model re-purposing such as model personalization or domain adaptation. In particular, as one example, a computing system can obtain a machine-learned model that has been previously trained on a first training dataset to perform a first task. The machine-learned model can include a first set of learnable parameters. The computing system can modify the machine-learned model to include a model patch, where the model patch includes a second set of learnable parameters. The computing system can train the machine-learned model on a second training dataset to perform a second task that is different from the first task, which may include learning new values for the second set of learnable parameters included in the model patch while keeping at least some (e.g., all) of the first set of parameters fixed.","['G06N3/082', 'G06N20/00', 'G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N3/044', 'G06N3/048', 'G10L15/16']"
US20200089214A1,Methods for data monitoring with changeable routing of input channels,"Methods for data monitoring with changeable routing of input channels are disclosed. An example method includes a data collector communicatively coupled to a plurality of input channels and a data acquisition circuit to interpret the detection values, each corresponding to an input channel. Sensor data is acquired from a first route of input channels and stored together with specifications for the sensors that correspond to the input channels. The sensor data is evaluated with respect to an alarm threshold level and an alarm state set when the alarm threshold level is exceeded. A response circuit changes a routing of the input channels for data collection from a first routing to an alternate routing of input channels, wherein the alternate routing of input channels comprise the first input channel and a group of input channels related to the first input channel.","['G05B19/0425', 'G05B23/0294', 'A01B3/02', 'G05B13/028', 'G05B19/102', 'G05B19/12', 'G05B19/4183', 'G05B19/4184', 'G05B19/41845', 'G05B19/4185', 'G05B19/41865', 'G05B19/41875', 'G05B23/02', 'G05B23/0221', 'G05B23/0229', 'G05B23/024', 'G05B23/0264', 'G05B23/0283', 'G05B23/0286', 'G05B23/0289', 'G05B23/0291', 'G05B23/0297', 'G06F18/20', 'G06F18/217', 'G06F18/2178', 'G06K9/6263', 'G06N20/00', 'G06N3/006', 'G06N3/02', 'G06N3/042', 'G06N3/043', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/049', 'G06N3/088', 'G06N7/005', 'G06T11/206', 'G06V10/70', 'G06V10/776', 'H04B17/309', 'H04B17/318', 'H04L1/0002', 'H04L1/004', 'H04L1/0041', 'H04L1/18', 'H04L12/66', 'H04L43/045', 'H04L47/122', 'H04Q9/00', 'G05B13/0265', 'G05B2219/25428', 'G05B2219/31282', 'G05B2219/32287', 'G05B2219/33331', 'G05B2219/35001', 'G05B2219/37337', 'G05B2219/37351', 'G05B2219/37434', 'G05B2219/40115', 'G05B2219/45004', 'G05B2219/45129', 'G06F2211/005', 'G06N20/10', 'G06N20/20', 'G06N3/084', 'G06N3/086', 'G06N3/126', 'G06N5/01', 'G06N5/046', 'G06N7/01', 'H04L5/0064', 'H04L67/1097', 'H04L67/12', 'H04L69/00', 'Y02P80/00', 'Y02P80/10', 'Y02P80/114', 'Y02P90/02', 'Y04S40/18']"
US10832128B2,"Transfer learning apparatus, transfer learning system, transfer learning method, and recording medium","A transfer learning apparatus includes a transfer target data evaluator and an output layer adjuster. The transfer target data evaluator inputs a plurality of labeled transfer target data items each assigned a label of a corresponding evaluation item from among one or more evaluation items to a neural network apparatus having been trained by using a plurality of labeled transfer source data items and including in an output layer output units, the number of which is larger than or equal to the number of evaluation items, and obtains evaluation values output from the respective output units. The output layer adjuster preferentially assigns, to each of the one or more evaluation items, an output unit from which the evaluation value having the smallest difference from the label of the evaluation item is obtained with a higher frequency, as an output unit that outputs the evaluation value of the evaluation item.","['G06N3/08', 'G06N3/0464', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/096']"
US10915631B2,Deep learning on execution trace data for exploit detection,"Technologies disclosed herein provide for converting a first data of a first control flow packet to a first pixel, where the first data indicates one or more branches taken during a known execution of an application, generating an array of pixels using the first pixel and one or more other pixels associated with one or more other control flow packets generated from the known execution, transforming the array of pixels into a series of images, and using a machine learning algorithm with inputs to train a behavior model to identify a malicious behavior in an unknown execution of the application. The inputs include one or more images of the series of images and respective image labels assigned to the one or more images. More specific embodiments include extracting the first control flow packet from an execution trace representing at least part of the known execution.","['G06F21/552', 'G06F18/214', 'G06F18/217', 'G06F21/54', 'G06F21/56', 'G06F21/566', 'G06K9/325', 'G06K9/4628', 'G06K9/6256', 'G06K9/6262', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V20/62', 'G06F2221/034', 'G06N20/10', 'G06N3/044', 'G06N3/0445', 'G06N3/047', 'G06N3/0472']"
CN110321926B,Migration method and system based on depth residual error correction network,"The invention discloses a migration method and a migration system based on a depth residual error correction network, wherein the migration method comprises the following steps: setting values of parameters in a pre-constructed target network model based on a source domain data set and a target domain data set in the network; based on the target network model with the parameter values set, classifying the image categories of each data in the target domain data set to obtain the category corresponding to each data; labeling the data corresponding to the target domain data set based on the category corresponding to each data, and obtaining the target domain data set with the label; the target network model is constructed based on a residual error correction block and a loss function; the source domain data set comprises a plurality of pictures and labels corresponding to each picture; the target domain dataset includes a plurality of pictures. The residual correction block and the loss function provided by the invention can improve the generalization capability of the original network through deepening the network, thereby improving the accuracy of cross-domain image classification.","['G06F18/217', 'G06F18/24', 'G06N3/08']"
US12231464B2,"Detecting phishing websites via a machine learning-based system using URL feature hashes, HTML encodings and embedded images of content pages","Disclosed is phishing classifier that classifies a URL and content page accessed via the URL as phishing or not is disclosed, with URL feature hasher that parses and hashes the URL to produce feature hashes, and headless browser to access and internally render a content page at the URL, extract HTML tokens, and capture an image of the rendering. Also disclosed are an HTML encoder, trained on HTML tokens extracted from pages at URLs, encoded, then decoded to reproduce images captured from rendering, that produces an HTML encoding of the tokens extracted, and an image embedder, pretrained on images, that produces an image embedding of the image captured. Further, phishing classifier layers, trained on the feature hashes, the HTML encoding, and the image embedding, process the URL feature hashes, HTML encoding and image embeddings to produce a likelihood score that the URL and the page accessed presents a phishing risk.","['H04L63/0281', 'H04L63/1408', 'H04L63/1483', 'H04L63/168', 'H04L67/02']"
CN109409198B,"AU detection method, AU detection device, AU detection equipment and AU detection medium","The application discloses an AU detection model training method, an AU detection method device, equipment and a medium, wherein the method comprises the following steps: acquiring face image sample data; carrying out data augmentation on the face image sample data to obtain a training sample; inputting the training sample into a depth residual error network for training to obtain an AU neural network; acquiring a preset face classification network through a pretrained VGGNet model; based on a preset face classification network, an AU neural network is processed by adopting a transfer learning algorithm, and an AU detection model is obtained. By adopting the AU detection model training method, the AU detection model with higher AU detection accuracy can be obtained.","['G06V40/161', 'G06V40/172', 'Y02T10/40']"
CN112561887B,Binocular vision measurement method for coal flow of belt conveyor based on deep transfer learning,"The invention discloses a belt conveyor coal flow binocular vision measurement method based on deep migration learning, which is characterized in that coal material image preprocessing is carried out according to a Bouguet image correction algorithm, a histogram equalization image enhancement algorithm and a Hough transform image segmentation algorithm; performing migration learning on a pre-training PSM-Net model according to a coal stereo matching data set, establishing a deep learning model aiming at a coal stereo matching task, and calculating coal three-dimensional information by using a binocular vision measurement principle; and calculating the volume of the load adhesive tape by adopting triangular prism gridding differential traversal summation, and obtaining the flow of the carried coal by calculating the difference between the no-load adhesive tape and the load adhesive tape. According to the method, the binocular vision is adopted to collect data to realize non-contact measurement, and the calculation of the flow of the coal carried by the belt conveyor is stably, accurately and quickly realized through the deep migration learning stereo matching model PSM-Net, the GPU accelerated calculation and the differential calculation, and the simplicity and the practicability of the use of the method are improved.","['G06T7/0004', 'G01B11/24', 'G06T5/40', 'G06T7/13', 'G06T7/136', 'G06T7/62', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20228', 'G06T2207/30108']"
US20240256230A1,Neural method completion based on natural language and source code,"A code completion tool uses a neural transformer model with attention to generate candidate sequences to complete a method body of a method signature. The neural transformer model is trained with source code programs and natural language text. The neural transformer model learns the meaning of a method name, its corresponding method parameters and types from a large corpus of unsupervised dataset of source code methods and a supervised dataset of tasks including source code constructs in combination with natural language docstrings to infer a candidate sequence of subtokens that represent a method body for a particular method signature.","['G06F8/33', 'G06F40/274', 'G06F8/35', 'G06F8/36', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N7/01']"
CN108446617B,A fast face detection method against profile interference,"The invention discloses a method for rapidly detecting a human face with anti-side face interference. The invention provides a training method for face detection, which uses a pure data driving mode, uses a common face picture and a face boundary box as input, uses mirror symmetry and Gaussian filtering to amplify data, and uses transfer learning and difficult mining to enhance the training effect. After the face picture is read in, the picture is firstly zoomed, then the picture is put into a deep neural network to extract features, a plurality of face likelihood frames and confidence scores of the face likelihood frames are generated, and finally the most appropriate face likelihood frame is selected by adopting a non-maximum value inhibition mode. The invention has no specific requirements on the angle of the face photo, and the detection effect on the side face is still very obvious. In addition, the detection method is simple, adopts an end-to-end detection mode, and can be applied to a real-time environment.","['G06N3/08', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/7788', 'G06V10/82', 'G06V20/52', 'G06V40/161', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06N20/00', 'G06N7/01']"
CN112235264B,Network traffic identification method and device based on deep migration learning,"The embodiment of the invention provides a network traffic identification method and device based on deep migration learning, relates to the technical field of network security, and can identify novel network traffic. The technical scheme of the embodiment of the invention comprises the following steps: and extracting message information and communication behavior information of a preset number of data packets from the network traffic to be identified. And then calculating the distance between the message information and the communication behavior information of the network flow to be identified and the clustering center of each cluster, wherein each cluster comprises the message information and the communication behavior information of the network flow of one category. And when the shortest distance in the calculated distances is smaller than the preset distance, obtaining the target category of the category cluster corresponding to the shortest distance. And inputting the message two-dimensional data matrix corresponding to the message information and the behavior two-dimensional data matrix corresponding to the behavior information into a network traffic identification model of the target category, and determining whether the network traffic to be identified is malicious traffic.","['H04L63/1425', 'G06N20/00', 'H04L47/2441', 'H04L47/2483', 'H04L63/1416', 'H04L67/141']"
US12042247B2,System and method for determining coronary artery tissue type based on an OCT image and using trained engines,"There is described a system for determining a coronal artery tissue type. The system generally has an optical coherence tomography (OCT) imaging system being configured for acquiring an OCT image of coronal artery tissue; and a controller configured to perform the steps of: using trained feature extraction engines, extracting corresponding feature vectors comprising a plurality of features in at least a region of interest of the OCT image; using trained classification engines, determining corresponding preliminary coronal artery tissue types associated to the region of interest of the OCT image based on corresponding ones of the plurality of feature vectors; and using a majority voting engine, majority voting an output coronal artery tissue type associated to the region of interest of the OCT image based on the previously determined preliminary coronal artery tissue types.","['A61B5/0066', 'A61B5/0044', 'A61B5/7267', 'G06F18/21', 'G06F18/2413', 'G06F18/24323', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/01', 'G06T7/0012', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G16H30/20', 'A61B2576/023', 'A61B5/0084', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30101', 'G06V2201/03']"
CN113486827B,Multi-source remote sensing image migration learning method based on domain countermeasure and self supervision,"The application relates to a multi-source remote sensing image transfer learning method based on domain countermeasure and self-supervision, wherein after a deep learning model performs pre-training in a source domain, training is performed in a transfer learning framework based on domain countermeasure training and self-supervision training, remote sensing image data of a target domain is input into the deep learning model after training is completed, and a prediction result of the target domain is output; the migration learning framework comprises a domain countermeasure training module and a self-supervision training module; the domain countermeasure training module comprises 1 generator and more than 1 discriminant; the self-supervision training module comprises an information entropy calculation module and a pseudo tag selection module, wherein the information entropy calculation module is used for calculating the information entropy of each sample prediction result, and the pseudo tag selection module is used for selecting pseudo tags according to the information entropy ordering of each sample prediction result. The method effectively solves the problems of low accuracy, low degree of automation and unstable model effect of the multi-source remote sensing image model transfer learning in the prior art, and has wide application prospect.","['G06F18/214', 'G06N20/00', 'G06N3/045', 'Y02T10/40']"
CN111931513B,Text intention recognition method and device,"The invention provides a text intention recognition method, a text intention recognition device, computer equipment and a computer readable storage medium, wherein the method comprises the following steps: acquiring a target text and a plurality of preset text intention categories; inputting the target text into a pre-training language model, and determining a semantic vector corresponding to the target text; and determining the probability value of the target text belonging to each text intention category according to the semantic vector, and determining the target text intention category corresponding to the target text. The invention is based on the idea of transfer learning, uses a pre-trained language model which is trained in advance by massive data in the NLP field and has good semantic expression effect, can generate the semantic vector representing the semantic feature of the target text more accurately, and further can further determine the target text intention category corresponding to the target text according to the semantic vector even if a large number of sample texts are not available during the cold start of the system, thereby improving the accuracy of the intention recognition system.","['G06F40/30', 'G06F16/35', 'G06F40/216', 'G06N3/045']"
US11200483B2,Machine learning method and apparatus based on weakly supervised learning,"A machine learning method based on weakly supervised learning according to an embodiment of the present invention includes extracting feature maps about a dataset given a first type of information and not given a second type of information by using a convolutional neural network (CNN), updating the CNN by back-propagating a first error value calculated as a result of performing a task corresponding to the first type of information by using a first model, and updating the CNN by back-propagating a second error value calculated as a result of performing the task corresponding to the first type of information by using a second model different from the first model, wherein the second type of information is extracted when the task corresponding to the first type of information is performed using the second model.","['G06N3/0454', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/084']"
CN112632972B,Method for rapidly extracting fault information in power grid equipment fault report,"The invention relates to a rapid extraction method of fault information in a power grid equipment fault report, which solves the problem that the existing model is insufficient in domain entity identification capability. The model solves the problem of insufficient acquisition of BiLSTM context information by using a bidirectional encoder BERT model based on a transducer, improves the recognition accuracy of the model on the basis of acquiring global context information, and enhances the acquisition capability of field word information by using a pre-training model BERT based on transfer learning. The invention performs local fine tuning training for the power grid field on the basis of the local fine tuning training, performs field-oriented retraining for part of the Transformer layer of the BERT, and enables a general model which is not applicable to the power grid field originally to obtain a better result on a power grid fault report text under the condition of keeping Chinese syntax grammar information contained in an original model.","['G06F40/253', 'G06F40/295', 'G06N3/044', 'G06N3/049']"
EP4083907A1,"Pathological diagnosis assisting method using ai, and assisting device","Diagnosis is assisted by acquiring microscopical observation image data while specifying the position, classifying the image data into histological types with the use of AI, and reconstructing the classification result in a whole lesion. There is provided a pathological diagnosis assisting method that can provide an assistance technology which performs a pathological diagnosis efficiently with satisfactory accuracy by HE staining which is usually used by pathologists. Furthermore, there are provided a pathological diagnosis assisting system, a pathological diagnosis assisting program, and a pre-trained model.","['G06T7/00', 'G06T7/0012', 'G16H50/20', 'G01N33/483', 'G02B21/365', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/096', 'G06N5/02', 'G06N5/04', 'G06V10/267', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V20/693', 'G06V20/698', 'G16H10/40', 'G16H30/40', 'G01N33/574', 'G06N3/0464', 'G06N3/0475', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20084', 'G06T2207/30024']"
US11875479B2,Fusion of deep learning and handcrafted techniques in dermoscopy image analysis,"A system for identifying melanoma and other skin cancer in a dermoscopy image comprises: an image analyzer having at least one processor that instantiates at least one component stored in a memory, the at least one component comprising: a segmenter configured to segment a lesion from the rest of the image, a handcrafted feature component including: a median color splitting model for separating the image into a plurality of color regions, a vessel detection model for detecting elevated vascularity, an atypical pigment network detection model for identifying a pigment network whose structure varies in size and shape, a salient point detection model for detecting salient points based on an intensity plane of the image, a color detection model for detecting at least one of a white area, a pink shade, a pink blush, and a semi-translucency, a hair detection model for characterizing detected hairs and ruler marks, an outside model that finds the above model features on non-dark-corner areas outside the segmented area, and a classifier configured to provide a first analysis result.","['G06T5/002', 'G06T5/70', 'G06T5/005', 'G06T5/30', 'G06T5/77', 'G06T7/0012', 'G06T7/11', 'G06T7/12', 'G06T7/143', 'G06T7/187', 'G06T7/73', 'G06T7/77', 'G06T7/90', 'G06V10/462', 'G06V10/56', 'G06V10/764', 'G06V10/82', 'G06T2207/10024', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20116', 'G06T2207/20152', 'G06T2207/20221', 'G06T2207/30088', 'G06T2207/30096', 'G06T2207/30101', 'G06V2201/03']"
CN112926405B,"Method, system, equipment and storage medium for detecting wearing of safety helmet","The invention discloses a method, a system, equipment and a storage medium for detecting the wearing of a safety helmet, wherein 1, original image data are obtained, and part of the original image data are used as a training set; 2. constructing a safety helmet detection network YOLOv4;3. acquiring the size of an a priori frame of the training set by using a clustering algorithm, and replacing a priori frame data in YOLOv4; 4. uploading the training set to a safety helmet detection network YOLOv4, and training by adopting a transfer learning method to obtain a safety helmet identification model; 5. and detecting whether the safety helmet is worn by the field personnel or not by using the safety helmet identification model. The recognition degree of the network is enhanced, the accuracy of multi-behavior small target detection and the robustness of the model in a complex construction scene are improved, and the accurate detection of the wearing of the safety helmet in the complex scene is realized.","['G06V40/103', 'G06F18/214', 'G06F18/23', 'G06V2201/07']"
CN113807215B,A tea sprout classification method combining improved attention mechanism and knowledge distillation,"The invention discloses a tea tender shoot grading method combining an improved attention mechanism and knowledge distillation, which comprises the following steps: preliminarily screening and preprocessing tea tender shoot images, and establishing a tea tender shoot data set; based on an improved attention mechanism, a multi-size convolution block attention module is constructed, a tea tender shoot grading model is established, a tea tender shoot grading model and a Resnet32 model are pre-trained, and weight parameters of the tea tender shoot grading model and the Resnet32 model are obtained; training a tea tender shoot grading model by utilizing a model training strategy combining double migration learning and knowledge distillation; and (4) importing the tea tender shoot images to be classified in the test set into the trained tea tender shoot classification model, and recording various indexes and model specification parameters of the classification result. The method can extract multi-scale characteristic information in the tea image, enhances the capability of processing a small data set, can relieve the model overfitting phenomenon on a limited number of data sets, and further strengthens the grading performance and the overfitting resistance of the student model while ensuring the light weight and high efficiency of the student model.","['G06F18/214', 'G06N3/045', 'G06N3/084']"
US20240029833A1,Computer implemented engineering materials mechanical property based search method,"The invention pertains to the field of computer implemented or computer aided methods for systematic search (contrary to trial and error) for materials (material science, material informatics) in relation to structural/mechanical properties and preferably a both radiation shielding and structural/mechanical properties.","['G16C60/00', 'G16C20/40', 'G06N3/045', 'G06N3/084', 'G06N5/01', 'G16C20/70', 'G16C20/50']"
US10909446B2,Systems and methods for selecting global climate simulation models for training neural network climate forecasting models,"Methods and systems for generating a multi-model ensemble of global climate simulation data from a plurality of global climate simulation models (GCMs), to be used in training a neural network (NN)-based climate forecasting model, are disclosed. The methods and systems perform steps of computing a GCM validation measure for each GCM; selecting a validated subset of the GCMs, by comparing each computed GCM validation measure to a validation threshold determined based on observational historical climate data; computing a forecast skill score for each validated GCM, based on a first forecast function; selecting a validated and skillful subset of GCMs; generating one or more candidate ensembles by combining simulation data from at least two validated and skillful GCMs; computing an ensemble forecast skill score for each candidate ensemble, based on a second forecast function; and selecting a best-scored candidate ensemble. Embodiments of the present invention enable accurate climate forecasting without the need to run new dynamical global climate simulations on supercomputers.","['G01W1/10', 'G06N3/0445', 'G06F18/214', 'G06F18/217', 'G06F18/25', 'G06F30/27', 'G06K9/6256', 'G06K9/6262', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/80', 'G06V10/82', 'G01W2201/00', 'Y02A90/10']"
US9384443B2,Robotic training apparatus and methods,"Apparatus and methods for training of robotic devices. Robotic devices may be trained by a user guiding the robot along target trajectory using an input signal. A robotic device may comprise an adaptive controller configured to generate control commands based on one or more of the user guidance, sensory input, and/or performance measure. Training may comprise a plurality of trials. During first trial, the user input may be sufficient to cause the robot to complete the trajectory. During subsequent trials, the user and the robot's controller may collaborate so that user input may be reduced while the robot control may be increased. Individual contributions from the user and the robot controller during training may be may be inadequate (when used exclusively) to complete the task. Upon learning, user's knowledge may be transferred to the robot's controller to enable task execution in absence of subsequent inputs from the user.","['B25J9/163', 'B25J9/161', 'G05D1/0221', 'G06N3/008', 'G06N3/049', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/092']"
US11521095B2,Methods and systems for CNN network adaption and object online tracking,"Disclosed are methods, apparatuses and systems for CNN network adaption and object online tracking. The CNN network adaption method comprises: transforming a first feature map into a plurality of sub-feature maps, wherein the first feature map is generated by the pre-trained CNN according to a frame of the target video; convolving each of the sub-feature maps with one of a plurality of adaptive convolution kernels, respectively, to output a plurality of second feature maps with improved adaptability; training, frame by frame, the adaptive convolution kernels.","['G06V10/82', 'G06F18/217', 'G06F18/24143', 'G06K9/6262', 'G06K9/6274', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N5/046', 'G06T7/11', 'G06T7/20', 'G06T7/73', 'G06V10/454', 'G06V10/764', 'G06V10/776', 'G06V20/10', 'G06T2207/20081']"
CN107610709B,Method and system for training voiceprint recognition model,"The application provides a method and a system for training a voiceprint recognition model, wherein the method comprises the steps of training a deep neural network by utilizing first training data to generate a first voiceprint recognition model; performing transfer learning on the first voiceprint recognition model by using second training data to generate a second voiceprint recognition model; and the second fingerprint identification model is used for carrying out voiceprint registration or authentication. The method can solve the problem that in the prior art, in order to develop a voiceprint authentication algorithm and a product of a characteristic scene, the end-to-end voiceprint authentication algorithm usually needs to record a large amount of data to ensure the performance of the algorithm, and a large amount of time cost and economic cost are needed. The full training data can be fully utilized, and the voiceprint recognition and authentication performance aiming at specific data is improved through transfer learning.",[]
US12288360B2,3D human pose estimation system,"Methods and systems for providing a dataset of human in-bed poses include simultaneously gathered images of in-bed poses of humans from imaging modalities including red-green-blue (RGB) and one or more of long wavelength infrared (LWIR), depth imaging, and pressure mapping. The images are obtained under a lighting condition and a cover condition. The dataset can be used to train a model of estimating human in-bed poses and for methods of estimating human in-bed poses. Methods and systems of estimating three-dimensional human poses from two-dimensional input images are provided.","['G06T7/80', 'G06T7/50', 'G06T7/74', 'G06T7/75', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30204', 'G06T2207/30232']"
US11946854B2,Systems and methods for two-dimensional fluorescence wave propagation onto surfaces using deep learning,"A fluorescence microscopy method includes a trained deep neural network. At least one 2D fluorescence microscopy image of a sample is input to the trained deep neural network, wherein the input image(s) is appended with a digital propagation matrix (DPM) that represents, pixel-by-pixel, an axial distance of a user-defined or automatically generated surface within the sample from a plane of the input image. The trained deep neural network outputs fluorescence output image(s) of the sample that is digitally propagated or refocused to the user-defined surface or automatically generated. The method and system cross-connects different imaging modalities, permitting 3D propagation of wide-field fluorescence image(s) to match confocal microscopy images at different sample planes. The method may be used to output a time sequence of images (e.g., time-lapse video) of a 2D or 3D surface within a sample.","['G01N15/1475', 'G01N15/1433', 'G01N21/6458', 'G06F18/214', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T3/4046', 'G06T3/4053', 'G06T5/003', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'G06V10/454', 'G06V10/7715', 'G06V10/82', 'G06V20/69', 'G01N2015/1006', 'G01N2015/1488', 'G06T2207/10016', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
CN112766378B,A cross-domain small-sample image classification model method focusing on fine-grained recognition,"The invention discloses a cross-domain small sample image classification model method focusing on fine granularity recognition, which comprises the steps of constructing a cross-domain small sample classification model FFGR focusing on fine granularity recognition, wherein the FFGR model adopts a two-step recognition method and comprises an image feature extraction module MFFE and an image feature classification recognition module BMF; extracting image features through a front-end concentration feature encoder, and performing image classification and identification by utilizing the image features through a rear-end bilinear metric function. By adopting the method, the characteristic information of the small sample image can be extracted more quickly and efficiently, the integral optimization of the model is more rapid and accurate, and the classification accuracy is high.","['G06F18/243', 'G06F18/214', 'G06F18/253', 'G06N3/048', 'G06N3/08', 'Y02T10/40']"
CN112307351B,"User behavior model training, recommendation methods, devices and equipment","The application discloses a model training and recommending method, device and equipment of user behaviors, wherein the model training method comprises the steps of obtaining a user behavior sequence, inputting the user behavior sequence into a user behavior sequence model under current model parameters to obtain current user expression, obtaining a first training sample according to the current user expression and the user behavior sequence, determining a mutual information loss value according to the first training sample by adopting a mutual information loss function, updating the model parameters of the user behavior sequence model according to the mutual information loss value, taking the updated model parameters as the current model parameters, and returning to execute the step of inputting the user behavior sequence into the user behavior sequence model under the current model parameters to obtain the current user expression until the current model parameters meet preset conditions. The application realizes the modeling of the user behavior sequence by the non-supervision learning method based on mutual information maximization, reduces the training time and cost of the user behavior sequence model, and can be widely applied to the field of artificial intelligence.","['G06F16/9535', 'G06F16/9536', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06Q50/01']"
US12352889B2,"Method, apparatus, and system for wireless sensing based on deep learning","Methods, apparatus and systems for wireless sensing based on deep learning are described. For example, a described method comprises: transmitting a wireless signal through a wireless multipath channel of a venue, wherein the wireless multipath channel is impacted by a motion of an object in the venue; receiving the wireless signal through the wireless multipath channel of the venue, wherein the received wireless signal differs from the transmitted wireless signal due to the wireless multipath channel and the motion of the object; obtaining a time series of channel information (TSCI) of the wireless multipath channel based on the received wireless signal; computing a plurality of autocorrelation functions based on the TSCI, each autocorrelation function (ACF) computed based on CI of the TSCI in a respective sliding time window; constructing at least one ACF vector, wherein each respective ACF vector is a vector associated with a respective ACF comprising multiple vector elements each associated with a respective time lag, each vector element being a value of the respective ACF evaluated at the respective time lag; rearranging the at least one ACF vector into rearranged ACF data, wherein each ACF vector is a one-dimensional (1D) ACF-block; and performing a wireless sensing task based on a task engine to do a processing using the rearranged ACF data as an input.","['G01S7/415', 'G01S13/56', 'G01S13/86', 'G01S13/88', 'H04L27/2647', 'H04L5/0051', 'H04L5/0026', 'H04L5/0048']"
US20220100793A1,Method for retrieving footprint images,"A method for retrieving footprint images is provided, comprising: pre-training models; cleaning footprint data and conducting expansion pre-processing by using the pre-trained models, dividing the footprint data into multiple data sets; adjusting full connection layers and classification layers of the models; training the models again by using the data sets through the parameters of the pre-trained models; saving the models trained twice, removing the classification layer, executing a feature extraction for images in an image library and a retrieval library to form a feature index library; connecting the features extracted by three models to form fused features, establishing a fused feature vector index library; extracting the features of the images in the image library to be retrieved in advance, and establishing a feature vector library; calculating distances in the retrieval library and the image library when a single footprint image is inputted, thereby outputting the image with the highest similarity.","['G06F16/58', 'G06F16/583', 'G06F16/55', 'G06N3/04', 'G06V10/32', 'G06V10/40', 'G06V10/761', 'G06V10/7747', 'G06V10/806', 'G06V10/82', 'G06V40/155', 'G06V40/50', 'Y02D10/00']"
US20230039900A1,Method for realizing a multi-channel convolutional recurrent neural network eeg emotion recognition model using transfer learning,"The invention provides a method for realizing a multi-channel convolutional recurrent neural network EEG emotion recognition model using transfer learning, the method uses a dual-channel one-dimensional convolutional neural network model constructed based on three heartbeats recognition method as the source domain model for transferring, to obtain a multi-channel convolutional recurrent neural network EEG emotion recognition model with EEG signal as the target domain, it solves the problem of scarcity of EEG labeling data, and can improve the accuracy of EEG emotion prediction. The accuracy of data processing is improved by decomposing and normalizing the EEG data set; the transferred multi-channel convolutional neural network extracts the features of multi-channel EEG signals in EEG data set; combined with the recurrent neural network, sequence modeling is carried out to extract multi-channel fused emotional information; the feature redistribution is realized by adaptive attention model and weighted feature fusion, and the complete feature tensor is obtained.","['G06F18/2135', 'G06N3/0464', 'G06F18/253', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/08']"
US12026974B2,Training method and training apparatus for a neural network for object recognition,"The present invention relates to method and apparatus for training a neural network for object recognition. A training method which includes inputting a training image set containing an object to be recognized, dividing the image samples in the training image set into simple samples and hard samples, for each kind of the image sample and the variation image sample, performing, a transitive transfer, calculating a distillation loss of the transferred student feature of the image sample relative to a teacher feature extracted from corresponding image sample of the other kind, classifying, the image sample, and calculating a classification loss of the image sample, calculating a total loss related to the training image set, and updating parameters of the neural network according to the calculated total loss.","['G06V40/16', 'G06F18/214', 'G06F18/241', 'G06F18/25', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/161']"
US11532378B2,Protein database search using learned representations,"A method for efficient search of protein sequence databases for proteins that have sequence, structural, and/or functional homology with respect to information derived from a search query. The method involves transforming the protein sequences into vector representations and searching in a vector space. Given a database of protein sequences and a learned embedding model, the embedding model is applied to each amino acid sequence to transform it into a sequence of vector representations. A query sequence is also transformed into a sequence of vector representations, preferably using the same learned embedding model. Once the query has been embedded in this manner, proteins are retrieved from the database based on distance between the query embedding and the protein embeddings contained within the database. Rapid and accurate search of the vector space is carried out using exact search using metric data structures, or approximate search using locality sensitive hashing.","['G06N3/084', 'G06F16/2255', 'G06F16/24534', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G16B30/10', 'G16B40/20', 'G06N3/045', 'G06N3/047']"
CN110363290B,"Image recognition method, device and equipment based on hybrid neural network model","The invention discloses an image recognition method, device and equipment based on a hybrid neural network model and a computer readable storage medium, comprising the following steps: inputting an image to be identified into a convolution self-encoder for preprocessing; extracting image features of the preprocessed image to be identified by using a characteristic extractor constructed based on transfer learning; extracting internal time sequence characteristics of the preprocessed image to be identified by using a long-term and short-term memory network model; utilizing a feature fusion door and a feature screening door to fusion and screen the image features and the internal time sequence features to obtain target features of the identification image; and classifying the target features by using a softmax classifier to obtain a classification result of the image to be identified. The method, the device, the equipment and the computer readable storage medium provided by the invention can greatly reduce the number of images required by training the neural network model and improve the accuracy of image identification.","['G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V10/40', 'Y02T10/40']"
US11651850B2,Computer vision technologies for rapid detection,"A computer-implemented method includes preprocessing a variable dimension medical image, identifying one or more areas of interest in the medical image; and analyzing the one or more areas of interest using a deep learning model. A computing system includes one or more processors; and one or more memories storing instructions that, when executed by the one or more processors, cause the computing system to preprocess a variable dimension medical image, identify one or more areas of interest in the medical image; and analyze the one or more areas of interest using a deep learning model. A non-transitory computer readable medium contains program instructions that when executed, cause a computer to preprocess a variable dimension medical image, identify one or more areas of interest in the medical image, and analyze the one or more areas of interest using a deep learning model.","['G16H30/40', 'G06F17/18', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T11/20', 'G06T7/0012', 'G06V10/25', 'G06V10/454', 'G06V10/7784', 'G06V10/82', 'G16H10/60', 'G16H50/20', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06T2210/12', 'G06T2211/441', 'G06V10/248', 'G06V10/987']"
CN111209952B,Underwater target detection method based on improved SSD and migration learning,"The invention relates to an underwater target detection method based on improved SSD and transfer learning, which solves the problems of under fitting, low recognition rate and poor robustness of underwater target detection in the prior art, and effectively improves the underwater target detection recognition rate and visual effect. The invention comprises the following steps: step 1, preparation: reading underwater images shot under the condition of deep water by using a computer, and carrying out fusion processing on the underwater background images and the underwater target scene images to obtain more underwater images; step 2, preprocessing an image and removing noise based on a filter; step 3, a feature extraction stage based on a backbone network; step 4, a network model training stage based on transfer learning: training an Underwater-SSD network by using a transfer learning method; step 5, soft-NMS target detection stage based on softening non-maximum suppression algorithm: and adding a softening non-maximum suppression algorithm after the model is subjected to the transfer learning training.","['G06F18/253', 'G06F18/217', 'G06N3/045', 'G06V10/30']"
US11995883B2,Scene graph generation for unlabeled data,"Approaches are presented for training and using scene graph generators for transfer learning. A scene graph generation technique can decompose a domain gap into individual types of discrepancies, such as may relate to appearance, label, and prediction discrepancies. These discrepancies can be reduced, at least in part, by aligning the corresponding latent and output distributions using one or more gradient reversal layers (GRLs). Label discrepancies can be addressed using self-pseudo-statistics collected from target data. Pseudo statistic-based self-learning and adversarial techniques can be used to manage these discrepancies without the need for costly supervision from a real-world dataset.","['G06V10/82', 'G06F18/10', 'G06F18/24', 'G06F18/29', 'G06V10/764', 'G06V10/84', 'G06V20/00', 'G06V20/70', 'G06V20/56']"
CN110046952B,"Recommendation model training method and device, and recommendation method and device","The method for training the recommendation model comprises the steps of determining a first initial parameter value of a training parameter in the recommendation model to be trained, wherein the first initial parameter value is a target parameter value after a pre-trained click rate estimation model iteratively updates the initial parameter value; acquiring user characteristics of at least two sample users and attribute characteristics of at least two sample application programs; generating a positive sample purchased by the sample user for the exposed sample application program and a negative sample not purchased by the sample user for the exposed sample application program based on the user characteristics and the attribute characteristics; training a recommendation model to be trained based on a sample set comprising at least one positive sample and one negative sample and the first initial parameter value to obtain the recommendation model, wherein the recommendation model outputs exposure conversion rate of each sample user to each sample application program.",['G06Q30/0631']
US11983632B2,Generating and utilizing pruned neural networks,"The disclosure describes one or more implementations of a neural network architecture pruning system that automatically and progressively prunes neural networks. For instance, the neural network architecture pruning system can automatically reduce the size of an untrained or previously-trained neural network without reducing the accuracy of the neural network. For example, the neural network architecture pruning system jointly trains portions of a neural network while progressively pruning redundant subsets of the neural network at each training iteration. In many instances, the neural network architecture pruning system increases the accuracy of the neural network by progressively removing excess or redundant portions (e.g., channels or layers) of the neural network. Further, by removing portions of a neural network, the neural network architecture pruning system can increase the efficiency of the neural network.","['G06N3/045', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/044', 'G06N3/047', 'G06N3/084']"
US20240412720A1,Real-time contextually aware artificial intelligence (ai) assistant system and a method for providing a contextualized response to a user using ai,"An artificial intelligence (AI) assistant system and a method for providing a contextualized response to a user using AI are disclosed. The system comprises an audio input device for receiving voice input, an audio output device for providing output, a processor, a wireless communication device, a contextual memory unit for storing conversational context data on a sliding window basis, and a non-volatile system memory unit. The processor executes instructions to receive voice input, determine user identification, update conversational context data with user identification and a tokenized representation of the voice input, process the voice input using a transformer-based language model to generate a response, update the conversational context data with a tokenized representation of the generated response, and output the response via the audio output device. The method comprises receiving voice input, determining user identification, updating conversational context data, processing voice input, and generating and outputting a conversational response.","['G10L13/02', 'G06F40/35', 'G06F16/33295', 'G06F16/90332', 'G06F3/167', 'G10L17/22', 'G10L15/22']"
CN114488140B,Small sample radar one-dimensional image target recognition method based on deep migration learning,"The invention belongs to the technical field of radar target recognition, and particularly relates to a small sample radar one-dimensional image target recognition method based on deep migration learning. According to the method, for radar one-dimensional images under the condition of small samples, firstly, a feature extraction network is pre-trained on a source data set, a mixed attention mechanism and a smooth label are used for improving the recognition accuracy and generalization performance of a model, then, the feature extraction network is fixed, the distribution of the small sample data is calibrated on a target data set by using a distribution calibration strategy, a classifier is trained jointly by data generated from the new distribution and real small sample data, and the recognition accuracy of the model under the condition of small samples is improved. The method effectively solves the problem that the model is difficult to train under the condition of a small sample, reduces the phenomenon of model overfitting, enhances the representation capability of the model and improves the recognition rate.","['G01S13/89', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'Y02A90/10']"
US20230109379A1,Diffusion-based generative modeling for synthetic data generation systems and applications,"Systems and methods described relate to the synthesis of content using generative models. In at least one embodiment, a score-based generative model can use a stochastic differential equation with critically-damped Langevin diffusion to learn to synthesize content. During a forward diffusion process, noise can be introduced into a set of auxiliary (e.g., “velocity”) values for an input image to learn a score function. This score function can be used with the stochastic differential equation during a reverse diffusion denoising process to remove noise from the image to generate a reconstructed version of the input image. A score matching objective for the critically-damped Langevin diffusion process can require only the conditional distribution learned from the velocity data. A stochastic differential equation-based integrator can then allow for efficient sampling from these critically-damped Langevin diffusion-based models.","['G06T5/70', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/09', 'G06N3/096', 'G06T5/60', 'G06T7/277', 'G06V10/772', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06V10/774']"
US20200242471A1,"Devices, Systems, and Methods that Observe and Classify Real-World Activity Relating to an Observed Object, and Track and Disseminate State Relating the Observed Object.","An intelligent monitoring device including a processor and an accelerometer and/or a device that includes at least one processor and at least one image sensor. The intelligent monitoring device is configured to observe at least one machine. The intelligent monitoring device is further configured to utilize its processor, or the processor of a coupled system, to recognize actions carried out on or by the at least one machine and infer the state of the machine. The intelligent monitoring device or the coupled system is further configured to provide alerts or help respond to queries about the status of the at least one machine. For example, the intelligent monitoring camera will infer the state of a washing machine based on its observations and provide an alert (optionally only to the user recognized to have loaded the washer) when the washing machine is ready to be unloaded.","['G06N3/08', 'G06F18/214', 'G06K9/6256', 'G06V10/764', 'G06V20/52', 'G06V40/20', 'H04L67/125', 'G01P15/00', 'G06N3/044', 'G06N3/045']"
US10156900B2,Systems and methods for discerning eye signals and continuous biometric identification,"Apparatus, systems, and methods are provided for substantially continuous biometric identification (CBID) of an individual using eye signals in real time. The apparatus is included within a wearable computing device with identification of the device wearer based on iris recognition within one or more cameras directed at one or both eyes, and/or other physiological, anatomical and/or behavioral measures. Verification of device user identity can be used to enable or disable the display of secure information. Identity verification can also be included within information that is transmitted from the device in order to determine appropriate security measures by remote processing units. The apparatus may be incorporated within wearable computing that performs other functions including vision correction, head-mounted display, viewing the surrounding environment using scene camera(s), recording audio data via a microphone, and/or other sensing equipment.","['G06F3/013', 'G02B27/0093', 'G02B27/017', 'G02B27/0172', 'G06F21/316', 'G06F21/32', 'G06F21/64', 'G06F3/012', 'G06F3/017', 'G06F3/0304', 'G06F3/04817', 'G06F3/0482', 'G06K9/00604', 'G06K9/0061', 'G06K9/00617', 'G06T19/006', 'G06V40/18', 'G06V40/19', 'G06V40/193', 'G06V40/197', 'H04L63/0861', 'H04N23/90', 'H04N5/23229', 'H04N5/247', 'H04N5/44504', 'H04W12/06', 'H04W12/065', 'H04W12/33', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0178', 'G06F2203/011']"
CN107481717B,Acoustic model training method and system,"The application provides an acoustic model training method and system, wherein the method comprises the following steps: training a deep neural network by using the first language training data to generate a first language acoustic model; and carrying out transfer learning on the first language acoustic model by utilizing second language training data to generate a second language acoustic model. The problems that in the prior art, if a data recording method is adopted to obtain the data of the second language, a large amount of data is needed to ensure the performance of the algorithm, and a large amount of time cost and economic cost are needed to be solved; not only the Japanese recognition effect is obviously improved, but also a large amount of recording cost is saved.","['G10L15/063', 'G10L15/16', 'G10L2015/0635']"
US11113323B2,Answer selection using a compare-aggregate model with language model and condensed similarity information from latent clustering,"Embodiments of the present invention provide systems, methods, and computer storage media for techniques for identifying textual similarity and performing answer selection. A textual-similarity computing model can use a pre-trained language model to generate vector representations of a question and a candidate answer from a target corpus. The target corpus can be clustered into latent topics (or other latent groupings), and probabilities of a question or candidate answer being in each of the latent topics can be calculated and condensed (e.g., downsampled) to improve performance and focus on the most relevant topics. The condensed probabilities can be aggregated and combined with a downstream vector representation of the question (or answer) so the model can use focused topical and other categorical information as auxiliary information in a similarity computation. In training, transfer learning may be applied from a large-scale corpus, and the conventional list-wise approach can be replaced with point-wise learning.","['G06F16/3329', 'G06F16/3347', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G06N5/041']"
CN118312922B,Multi-mode network content security intelligent auditing system and method thereof,"The invention provides a multimode network content security intelligent auditing system and a method thereof, belonging to the network content security field, wherein the system comprises: the data access and preprocessing module is used for receiving the multi-mode network content data from different sources and preprocessing the multi-mode network content data; the multi-mode analysis module is used for extracting the characteristics of different modes of content from the multi-mode network content data; the strategy management module is used for configuring and managing auditing strategies of different-mode contents; the auditing engine module is used for comprehensively utilizing the rule engine and the machine learning model and auditing the multi-mode network content data according to the characteristics of different-mode content and auditing strategies; the auditing result disposal module is used for outputting and storing auditing results and triggering corresponding manual auditing or automatic disposal flow according to the auditing results. The invention comprehensively utilizes a plurality of artificial intelligence technologies to comprehensively audit texts, pictures, videos and audios, thereby greatly improving the content security management and control capability.","['G06F18/253', 'G06F18/213', 'G06F18/214', 'G06F18/241', 'G06F18/256', 'G06F18/259', 'G06N3/042', 'G06N3/045', 'G06N3/0495', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G06N5/045']"
US20240095463A1,Natural language processing applications using large language models,"Approaches presented herein can provide for the performance of specific types of tasks using a large model, without a need to retrain the model. Custom endpoints can be trained for specific types of tasks, as may be indicated by the specification of one or more guidance mechanisms. A guidance mechanism can be added to or used along with a request to guide the model in performing a type of task with respect to a string of text. An endpoint receiving such a request can perform any marshalling needed to get the request in a format required by the model, and can add the guidance mechanisms to the request by, for example, prepending one or more text strings (or text prefixes) to a text-formatted request. A model receiving this string can process the text according to the guidance mechanisms. Such an approach can allow for a variety of tasks to be performed by a single model.","['G06F40/30', 'G06F40/40', 'G06F40/20', 'G06F40/284']"
CN111746559B,Method and system for predicting lane changing intention of front vehicle,"The invention belongs to the technical field of automatic driving, and discloses a method and a system for predicting a lane change intention of a preceding vehicle, wherein the method for predicting the lane change intention of the preceding vehicle comprises the following steps: the method comprises the steps of establishing a dynamic grid map with a center point of a head of a vehicle as a zero point, acquiring profile features and lane lines of a front vehicle based on a semantic segmentation method, detecting the relative distance between the center of the head of the front obstacle vehicle and the vehicle, representing the real-time position of the front obstacle vehicle by using grid coordinates, describing position information of the front vehicle, analyzing relevant motion state information of the front obstacle vehicle according to the transverse and longitudinal speeds of the front vehicle, and combining the dynamic grid map with a hybrid Gaussian hidden Markov model to predict lane change behavior of the front vehicle. The method for predicting the lane change intention of the front vehicle based on the dynamic grid map and the mixed Gaussian hidden Markov model can achieve a good prediction effect. The invention can predict the hidden lane changing behavior state of the vehicle by utilizing the observable driving state of the front vehicle, and provides related information for the safe driving of the vehicle.","['B60W60/00272', 'B60W50/0097', 'G06F18/214', 'G06F18/2415', 'G06F18/295', 'G06V10/26', 'G06V20/58', 'G06V20/584', 'G06V20/588', 'B60W2050/0034', 'B60W2554/4042', 'B60W2554/4043', 'G06V2201/08', 'Y02T10/40']"
US10970887B2,Tomographic image reconstruction via machine learning,"Tomographic/tomosynthetic image reconstruction systems and methods in the framework of machine learning, such as deep learning, are provided. A machine learning algorithm can be used to obtain an improved tomographic image from raw data, processed data, or a preliminarily reconstructed intermediate image for biomedical imaging or any other imaging purpose. In certain cases, a single, conventional, non-deep-learning algorithm can be used on raw imaging data to obtain an initial image, and then a deep learning algorithm can be used on the initial image to obtain a final reconstructed image. All machine learning methods and systems for tomographic image reconstruction are covered, except for use of a single shallow network (three layers or less) for image reconstruction.","['G06T11/008', 'A61B5/055', 'A61B5/00', 'A61B6/032', 'A61B6/037', 'A61B6/5205', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/006', 'G06T2210/41', 'G06T2211/421', 'G06T2211/424']"
CN112036547B,Rolling bearing residual life prediction method combining automatic feature extraction with LSTM,"The invention discloses a rolling bearing residual life prediction method combining automatic feature extraction with LSTM, by which the residual service life of a rolling bearing can be predicted according to vibration signals. Firstly, cleaning data of vibration data of a rolling bearing in a full life cycle, and removing abnormal values; performing time-frequency analysis on the vibration signal to obtain a PWVD time-frequency image data set representing the degradation state of the bearing; then, based on transfer learning, automatically extracting features by using a pretrained VGG16 model; and finally, the extracted features are sent to an LSTM network to realize residual life prediction. The residual life prediction value provided by the invention has small mean square error, can monitor the degradation state of the bearing in real time, prevents major accidents, and provides reference opinion for predictive maintenance.","['G06N3/045', 'G06F17/11', 'G06F17/16', 'G06F18/214', 'G06N3/044', 'G06N3/049', 'G06Q10/04', 'G06F2218/08']"
US11379985B2,System and computer-implemented method for segmenting an image,"A computer-implemented method for segmenting an input image, the method comprises: generating a first segmentation of the input image using a first machine learning system, the first segmentation comprising multiple segments; receiving, from a user, at least one indication, wherein each indication corresponds to a particular segment from the multiple segments, and indicates one or more locations of the input image as belonging to that particular segment; constructing, for each segment of the multiple segments having at least one corresponding indication, a respective geodesic distance map, based on the input image and the user indications received for that segment; and generating a second segmentation using a second machine learning system based on the input image and the constructed geodesic distance maps.","['G06T7/0012', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/11', 'G16H30/40', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30016', 'G06T2207/30096']"
US11503998B1,Method and a system for detection of eye gaze-pattern abnormalities and related neurological diseases,"The present disclosure relates to a method and a system for detecting a neurological disease and an eye gaze-pattern abnormality related to the neurological disease of a user. The method comprises displaying stimulus videos on a screen of an electronic device and simultaneously filming with a camera of the electronic device to generate a video of the user's face for each one of the stimulus videos, each one of the stimulus videos corresponding to a task. The method further comprises providing a machine learning model for gaze predictions, generating the gaze predictions for each video frame of the recorded video, and determining features for each task to detect the neurological disease using a pre-trained machine learning model.","['A61B5/163', 'A61B3/113', 'A61B3/0025', 'A61B3/145', 'A61B5/0077', 'A61B5/1114', 'A61B5/165', 'A61B5/4064', 'A61B5/4082', 'A61B5/4842', 'A61B5/4863', 'A61B5/7207', 'A61B5/7267', 'A61B5/742', 'A61B5/7485', 'G06T7/0012', 'G06T7/0016', 'G06T7/269', 'G06T7/277', 'G06T7/70', 'G06T7/73', 'G06T7/90', 'G16H30/40', 'G16H50/20', 'A61B2505/09', 'A61B2560/0223', 'A61B2576/02', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30041', 'G06T2207/30201', 'G16H40/60']"
US11393229B2,Method and system for artificial intelligence based medical image segmentation,"Methods and systems for artificial intelligence based medical image segmentation are disclosed. In a method for autonomous artificial intelligence based medical image segmentation, a medical image of a patient is received. A current segmentation context is automatically determined based on the medical image and at least one segmentation algorithm is automatically selected from a plurality of segmentation algorithms based on the current segmentation context. A target anatomical structure is segmented in the medical image using the selected at least one segmentation algorithm.","['G06T7/11', 'G06F18/285', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06V10/454', 'G06V20/695', 'G06T2207/20084', 'G06V10/7553', 'G06V2201/031', 'G16H30/40']"
CN109255831B,A method for single-view face 3D reconstruction and texture generation based on multi-task learning,"The invention discloses a method for single-view face three-dimensional reconstruction and texture generation based on multi-task learning, and belongs to the field of computer vision. The method comprises the following steps: selecting a special viewpoint rendered by the human face three-dimensional model; generating a depth map and a texture map as truth value data under a special viewpoint; designing an integrated learning coding network shared by depth information and texture information characteristics; designing a branch decoding network for recovering the depth map from the shared characteristics, and recovering the depth map; designing a mutual information maximization generation countermeasure network with shared characteristics as latent variables, and recovering a texture expansion diagram; adjusting the proportion of each task loss function, and training a model; and (4) carrying out interpolation processing on the depth map output by the network, and recovering the human face three-dimensional grid model with texture details by combining the texture map. The method utilizes multi-task learning-based single-view face three-dimensional reconstruction, texture generation and style migration, and has the advantages of high speed, low cost and the like.","['G06T17/00', 'G06T7/50', 'G06T7/80', 'G06T2207/30201']"
CN112101220B,An Unsupervised Model Parameter Migration Method for Rolling Bearing Life Prediction,"A rolling bearing service life prediction method based on unsupervised model parameter migration belongs to the technical field of rolling bearing state identification and residual service life prediction. The method is provided aiming at the problems that in practice, the rolling bearing with the label has difficulty in acquiring vibration data, health indexes are difficult to construct and the service life prediction error is large. Firstly, extracting root mean square characteristics from vibration data of the whole life cycle of a rolling bearing, and introducing a new bottom-up time sequence segmentation algorithm to segment a characteristic sequence into 3 states of a normal period, a degradation period and a decline period; carrying out state information labeling on an amplitude sequence of the vibration signal after fast Fourier transform, taking the amplitude sequence as the input of an improved full convolution neural network, extracting deep features, training and constructing a source domain model and a finely adjusted state recognition model, and realizing multi-state recognition of the rolling bearing; and establishing a rolling bearing service life prediction model by using a state probability estimation method. Experiments prove that the method does not need to construct health indexes, can realize the state identification and the service life prediction of the rolling bearing under different working conditions under the unsupervised condition, and obtains better effect.","['G06F2218/08', 'G06F18/23', 'G06F18/241', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06F2218/12']"
US11568542B2,Body-mounted or object-mounted camera system,"An object or body-mounted camera apparatus for recording surgery is provided that is adapted for tracking a relevant visual field of an on-going operation. To help maintain visibility and/or focus of the visual field, specific machine learning approaches are proposed in combination with control commands to shift a physical positioning or a perspective of the camera apparatus. Additional variations are directed to tracking obstructions based on the visual field of the camera, which can be utilized for determining a primary recording for use when there are multiple cameras being used in concert.","['G06T1/0014', 'G06T7/10', 'A61B34/10', 'A61B90/361', 'F16M11/041', 'F16M11/123', 'F16M11/18', 'F16M11/2021', 'F16M13/04', 'G06T1/20', 'G06T1/60', 'G06T7/11', 'G06T7/73', 'H04N23/60', 'H04N23/685', 'H04N23/695', 'H04N5/765', 'A61B2034/2048', 'A61B2034/2065', 'A61B2090/3612', 'A61B2090/502', 'A61B90/53', 'G06T2207/20081', 'G06T2207/20084']"
CN113705580B,Hyperspectral image classification method based on deep migration learning,"The invention provides a hyperspectral image classification method based on deep migration learning, which mainly solves the problem of low classification precision under the training condition of a small sample in the prior art, and adopts the scheme that: performing super-pixel segmentation on the hyperspectral image by using a spatial preprocessing method based on region clustering to obtain a super-pixel block; extracting super pixel block features using a self-encoding network; spectral clustering is carried out on the super pixel block characteristics to obtain pseudo labels; training the 3DCNN network by using the pseudo tag to obtain a pre-training model; constructing a fusion network, migrating the parameters of the pre-training model into the fusion network, and training the parameters by using a real label; and classifying the hyperspectral images by using the trained fusion model. The invention adopts an improved hyperspectral pixel clustering mode and a migration learning method, thereby not only generating a high-quality pseudo tag, but also improving the effect of a migrated model, improving the classification precision of hyperspectral images, and being applicable to disaster monitoring, geological exploration, urban planning, agriculture and archaeology.","['G01N21/25', 'G06F18/23', 'G06F18/241', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
CN111476219B,Image target detection method in intelligent home environment,"The invention relates to an image target detection method in an intelligent home environment, which comprises the steps of pre-training a model through image Net data, adopting a random seed fusion multiple image enhancement mode to enhance and expand pretreatment operation on home data, utilizing a feature extraction network, introducing cavity convolution, adopting pre-trained model parameters, and carrying out model retraining on a processed home data set; storing the model trained for the second time, packaging the model, and performing k-means cluster analysis on images in an image library and a detection library to form a specific target detection feature library; when a single Zhang Guju image is input, extracting features of the input image by using a feature extraction network to obtain four coordinates of a predicted frame, carrying out regression and classification calculation on the predicted frame, and outputting a detection result through non-maximum suppression. The target detection requirement in the intelligent home environment is met.","['G06V20/36', 'G06F18/214', 'G06F18/23213', 'G06N3/045', 'G06N3/08', 'G06V10/25', 'G06V10/462', 'G06V2201/07']"
US11776092B2,Color restoration method and apparatus,"Disclosed herein is a color restoration method and apparatus. The color restoration method may include pre-processing an input image, determining whether color is distorted, and restoring the color of the input image in an RGB scale or a grayscale according to whether the color is distorted. According to the present disclosure, color of a low light image may be restored using a deep neural network model trained through deep learning of a 5G network and color restoration.","['G06T5/94', 'G06T5/70', 'G06T5/00', 'G06T5/002', 'G06N3/08', 'G06T3/4015', 'G06T5/40', 'G06T5/50', 'G06T5/60', 'G06T5/90', 'G06T7/90', 'G06T2200/24', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US12217033B2,Systems and methods for code understanding and generation,"Embodiments described herein a code generation and understanding model that builds on a Transformer-based encoder-decoder framework. The code generation and understanding model is configured to derive generic representations for programming language (PL) and natural language (NL) in code domain via pre-training on unlabeled code corpus, and then to benefit many code-related downstream tasks with fine-tuning. Apart from the denoising sequence-to-sequence objectives widely adopted for pre-training on natural language, identifier tagging and prediction pre-training objective is adopted to enable the model to better leverage the crucial token type information from PL, which specifically are the identifiers assigned by developers.","['G06F8/30', 'G06F8/427', 'G06F18/214', 'G06F40/20', 'G06N3/0455', 'G06N3/047', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06F40/216', 'G06F40/30']"
CN112529146B,Methods and devices for neural network model training,"The application provides a neural network model training method in the artificial intelligence field, which comprises the following steps: acquiring a neural network model, first training data and categories of the first training data, wherein the neural network model is trained according to second training data, the first training data comprises supporting data and query data, the supporting data comprises all or part of data of each category in the first training data, and the query data comprises all or part of data of each category in the first training data; extracting features of the first training data by using the neural network model to obtain features of the first training data; and adjusting parameters of partial layers of the neural network model according to the feature distance between the class center feature of each class and the query data feature to obtain an adjusted neural network model. And the parameters of part of layers of the neural network model obtained through training are adjusted, so that the neural network model with good precision and generalization capability is obtained.","['G06N3/045', 'G06N3/096', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/0985', 'Y02T10/40']"
US20180307679A1,Multi-lingual semantic parser based on transferred learning,"The disclosure relates to transferred learning from a first language (e.g., a source language for which a semantic parser has been defined) to a second language (e.g., a target language for which a semantic parser has not been defined). A system may use knowledge from a trained model in one language to model another language. For example, the system may transfer knowledge of a semantic parser from a first (e.g., source) language to a second (e.g., target) language. Such transfer of knowledge may occur and be useful when the first language has sufficient training data but the second language has insufficient training data. The foregoing transfer of knowledge may extend the semantic parser for multiple languages (e.g., the first language and the second language).","['G06F17/2785', 'G06N3/082', 'G06F40/30', 'G06F17/2705', 'G06F17/2735', 'G06F17/2836', 'G06F40/205', 'G06F40/242', 'G06F40/284', 'G06F40/45', 'G06F40/47', 'G06N3/044', 'G06N3/045']"
US11875775B2,Voice conversion system and training method therefor,"The present disclosure proposes a speech conversion scheme for non-parallel corpus training, to get rid of dependence on parallel text and resolve a technical problem that it is difficult to achieve speech conversion under conditions that resources and equipment are limited. A voice conversion system and a training method therefor are included. Compared with the prior art, according to the embodiments of the present disclosure: a trained speaker-independent automatic speech recognition model can be used for any source speaker, that is, the speaker is independent; and bottleneck features of audio are more abstract as compared with phonetic posteriorGram features, can reflect decoupling of spoken content and timbre of the speaker, and meanwhile are not closely bound with a phoneme class, and are not in a clear one-to-one correspondence relationship. In this way, a problem of inaccurate pronunciation caused by a recognition error in ASR is relieved to some extent. Pronunciation accuracy of audio obtained by performing voice conversion by the bottleneck feature is obviously higher than that of a phonetic posteriorGram based method, and timbre is not significantly different. By means of a transfer learning mode, dependence on training corpus can be greatly reduced.","['G10L21/003', 'G10L15/063', 'G10L15/02', 'G10L15/16', 'G10L19/173', 'G10L25/24', 'G10L25/30', 'G10L2015/025', 'G10L2021/0135']"
US12265899B2,Method for serving parameter efficient NLP models through adaptive architectures,"A machine learning system executed by a processor may generate predictions for a variety of natural language processing (NLP) tasks. The machine learning system may include a single deployment implementing a parameter efficient transfer learning architecture. The machine learning system may use adapter layers to dynamically modify a base model to generate a plurality of fine-tuned models. Each fine-tuned model may generate predictions for a specific NLP task. By transferring knowledge from the base model to each fine-tuned model, the ML system achieves a significant reduction in the number of tunable parameters required to generate a fine-tuned NLP model and decreases the fine-tuned model artifact size. Additionally, the ML system reduces training times for fine-tuned NLP models, promotes transfer learning across NLP tasks with lower labeled data volumes, and enables easier and more computationally efficient deployments for multi-task NLP.","['G06N20/00', 'G06N20/20', 'G06F40/126', 'G06F40/284', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06F40/279', 'G06F40/30', 'G06N3/08']"
US20220249031A1,Deep end-to-end classification of electrocardiogram data,"There is disclosed a computer-implemented method of classifying electrocardiogram data of a patient, comprising the steps of receiving input data from each of a plurality of electrocardiogram leads, arranging the input data into a single combined image, and applying a machine-learning algorithm to the combined image to classify the electrocardiogram data.","['A61B5/7267', 'A61B5/339', 'A61B5/35', 'A61B5/7246', 'A61B5/7257', 'A61B5/7264', 'G16H50/20']"
US20230377155A1,Method of processing an image of tissue and a system for processing an image of tissue,"A computer implemented method of processing an image of tissue, comprising: obtaining a first set of image portions from an input image of tissue; selecting a second set of one or more image portions from the first set of image portions, the selecting comprising inputting image data of an image portion from the first set into a first trained model comprising a first convolutional neural network, the first trained model generating an indication of whether the image portion is associated with a biomarker; and determining an indication of whether the input image is associated with the biomarker from the second set of one or more image portions.","['G06T7/0012', 'G06T7/0014', 'G06N3/044', 'G06N3/0464', 'G06T7/11', 'G06V10/82', 'G06V20/50', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G06T2207/30204', 'G16H40/20']"
US11551394B2,Audio-speech driven animated talking face generation using a cascaded generative adversarial network,"Conventional state-of-the-art methods are limited in their ability to generate realistic animation from audio on any unknown faces and cannot be easily generalized to different facial characteristics and voice accents. Further, these methods fail to produce realistic facial animation for subjects which are quite different than that of distribution of facial characteristics network has seen during training. Embodiments of the present disclosure provide systems and methods that generate audio-speech driven animated talking face using a cascaded generative adversarial network (CGAN), wherein a first GAN is used to transfer lip motion from canonical face to person-specific face. A second GAN based texture generator network is conditioned on person-specific landmark to generate high-fidelity face corresponding to the motion. Texture generator GAN is made more flexible using meta learning to adapt to unknown subject's traits and orientation of face during inference. Finally, eye-blinks are induced in the final animation face being generated.","['G06T13/40', 'G06T13/205', 'G06F18/214', 'G06K9/6256', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06V40/171', 'G10L15/02', 'G10L21/10', 'G10L25/30']"
CN111126574B,"Method, device and storage medium for training machine learning model based on endoscopic image","The invention provides a method and a device for training a machine learning model. The method comprises the following steps: the first stage: inputting an unlabeled sample set; selecting a sample to be annotated from an unlabeled sample set through active learning based on an initialized or pre-trained machine learning model; labeling the sample to be labeled, and storing the labeled sample in a labeling data set; dividing the annotation data set into a training data set and a verification data set; training the machine learning model by using the training data set to obtain a trained machine learning model; verifying the trained machine learning model by using the verification data set to obtain the performance of the trained machine learning model; and a second stage: repeating the steps in the first stage when the performance of the trained machine learning model is less than a predetermined performance index; until the performance of the trained machine learning model is greater than or equal to a predetermined performance index.","['G06N3/045', 'G06F18/24133', 'G06N3/08']"
US20250140281A1,Robust intrusive perceptual audio quality assessment based on convolutional neural networks,"Described herein is a computer-implemented deep-learning-based system for determining an indication of an audio quality of an input audio frame. The system comprises at least one inception block configured to receive at least one representation of an input audio frame and to map the at least one representation of the input audio frame into a feature map; and at least one fully connected layer configured to receive a feature map corresponding to the at least one representation of the input audio frame from the at least one inception block, wherein the at least one fully connected layer is configured to determine the indication of the audio quality of the input audio frame. Described are further respective methods of operating and training said system.","['G10L25/60', 'G06N3/044', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G10L25/30']"
US11347481B2,"Support system for designing an artificial intelligence application, executable on distributed computing platforms","The present invention relates to a learning engine function and the use thereof in a system using a suite of modular and clearly structured Artificial Intelligence application design tools (SOACAIA), executable on distributed or undistributed computing platforms to browse, develop, make available and manage AI applications, this set of tools implementing four functions:A Studio function;A Forge function;An Orchestrator function;A fast machine learning engine FMLE (FastML Engine) function.","['G06F8/20', 'G06Q10/103', 'G06F3/0486', 'G06F8/60', 'G06F8/77', 'G06F9/45558', 'G06N20/00', 'G06Q10/06395', 'G06Q10/101', 'G06Q10/105', 'G06Q30/0185', 'G06F2009/45562', 'G06F2009/4557', 'G06F2009/45575']"
US10177998B2,Augmenting flow data for improved network monitoring and management,"Flow data can be augmented with features or attributes from other domains, such as attributes from a source host and/or destination host of a flow, a process initiating the flow, and/or a process owner or user. A network can be configured to capture network or packet header attributes of a first flow and determine additional attributes of the first flow using a sensor network. The sensor network can include sensors for networking devices (e.g., routers, switches, network appliances), physical servers, hypervisors or container engines, and virtual partitions (e.g., virtual machines or containers). The network can calculate a feature vector including the packet header attributes and additional attributes to represent the first flow. The network can compare the feature vector of the first flow to respective feature vectors of other flows to determine an applicable policy, and enforce that policy for subsequent flows.","['H04L43/045', 'G06F16/122', 'G06F16/137', 'G06F16/162', 'G06F16/17', 'G06F16/173', 'G06F16/174', 'G06F16/1744', 'G06F16/1748', 'G06F16/2322', 'G06F16/235', 'G06F16/2365', 'G06F16/24578', 'G06F16/248', 'G06F16/285', 'G06F16/288', 'G06F16/29', 'G06F16/9535', 'G06F17/30241', 'G06F17/3053', 'G06F17/30554', 'G06F17/30598', 'G06F17/30604', 'G06F17/30867', 'G06F21/53', 'G06F21/552', 'G06F21/556', 'G06F21/566', 'G06F3/0482', 'G06F3/04842', 'G06F3/04847', 'G06F9/45558', 'G06N20/00', 'G06N99/00', 'G06N99/005', 'G06T11/206', 'H04J3/0661', 'H04J3/14', 'H04L1/242', 'H04L41/046', 'H04L41/0668', 'H04L41/0803', 'H04L41/0806', 'H04L41/0816', 'H04L41/0893', 'H04L41/0894', 'H04L41/12', 'H04L41/16', 'H04L41/22', 'H04L41/40', 'H04L43/02', 'H04L43/026', 'H04L43/04', 'H04L43/062', 'H04L43/08', 'H04L43/0805', 'H04L43/0811', 'H04L43/0829', 'H04L43/0841', 'H04L43/0858', 'H04L43/0864', 'H04L43/0876', 'H04L43/0882', 'H04L43/0888', 'H04L43/10', 'H04L43/106', 'H04L43/12', 'H04L43/16', 'H04L43/20', 'H04L45/306', 'H04L45/38', 'H04L45/46', 'H04L45/507', 'H04L45/66', 'H04L45/74', 'H04L47/11', 'H04L47/20', 'H04L47/2441', 'H04L47/2483', 'H04L47/28', 'H04L47/31', 'H04L47/32', 'H04L61/2007', 'H04L61/5007', 'H04L63/0227', 'H04L63/0263', 'H04L63/06', 'H04L63/0876', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/145', 'H04L63/1458', 'H04L63/1466', 'H04L63/16', 'H04L63/20', 'H04L67/01', 'H04L67/10', 'H04L67/1001', 'H04L67/1002', 'H04L67/12', 'H04L67/16', 'H04L67/36', 'H04L67/42', 'H04L67/51', 'H04L67/75', 'H04L69/16', 'H04L69/22', 'H04L7/10', 'H04L9/0866', 'H04L9/3239', 'H04L9/3242', 'H04W72/08', 'H04W72/54', 'H04W84/18', 'G06F2009/4557', 'G06F2009/45587', 'G06F2009/45591', 'G06F2009/45595', 'G06F2221/033', 'G06F2221/2101', 'G06F2221/2105', 'G06F2221/2111', 'G06F2221/2115', 'G06F2221/2145', 'H04L67/22', 'H04L67/535']"
EP3985684A1,"Virtualized computing platform for inferencing, advanced processing, and machine learning applications","In various examples, a virtualized computing platform for advanced computing operations - including image reconstruction, segmentation, processing, analysis, visualization, and deep learning - may be provided. The platform may allow for inference pipeline customization by selecting, organizing, and adapting constructs of task containers for local, on-premises implementation. Within the task containers, machine learning models generated off-premises may be leveraged and updated for location specific implementation to perform image processing operations. As a result, and using the virtualized computing platform, facilities such as hospitals and clinics may more seamlessly train, deploy, and integrate machine learning models within a production environment for providing informative and actionable medical information to practitioners.","['G16H30/20', 'G06F9/45558', 'G06F9/5005', 'G06F9/5038', 'G06F9/547', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N3/10', 'G06N5/043', 'G06T19/006', 'G06T7/0012', 'G06T7/10', 'G16H30/40', 'G16H50/20', 'G06F2009/4557', 'G06F2009/45595', 'G06T2207/20081', 'G06T2207/20084']"
US20240371184A1,Live-cell label-free prediction of single-cell omics profiles by microscopy,"Computer-implemented methods, computer program products, and systems determine an omics profiles of a cell using microscopy imaging data. In one aspect, a computer-implemented method determines an omics profiles of a cell using microscopy imaging data by a) receiving microscopy imaging data of a cell or a population of cells; b) determining a targeted expression profile of a set of target genes from the microscopy imaging data using a first machine learning model, the target genes identifying a cell type or cell state of interest; and c) determining a single-cell omics profile for the population of cells using a second machine learning algorithm model. The targeted expression profile and a reference single-cell RNA-seq data set are used as inputs for the second machine learning model. Computer-implemented methods, computer program products, and systems described herein also provide for determining single-cell omics profile from microscopy, such as Raman microscopy, or expression profiles, such as H&E stains.","['G06V20/698', 'G06N20/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06N5/01', 'G06V10/774', 'G06V10/82', 'G16B25/10', 'G16B40/20', 'G16H20/10', 'G16H20/60', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70']"
US20220044114A1,Hybrid quantization of neural networks for edge computing applications,"Apparatuses, systems, and techniques to use low precision quantization to train a neural network. In at least one embodiment, one or more weights of a trained model are represented by low bit integer numbers instead of using full floating point precision. Changing precision of the one or more weights is performed by first quantizing all weights and activations of a neural network except for layers that require finer granularity in representation than an 8 bit quantization can provide to generate a first trained model. Subsequently, precision of the one or more weights of the first trained model is changed again to generate a second trained model. For the second trained model, the precision of one or more weights of at least one additional layer is changed in addition to the layers that previously had precision values changed while training the neural network to generate the first trained model.","['G06N3/08', 'G06N3/045', 'G06N3/0454', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N7/01']"
US20200388287A1,Intelligent health monitoring,"Embodiments are disclosed for health assessment and diagnosis implemented in an artificial intelligence (AI) system. In an embodiment, a method comprises: obtaining one or more interpretations from an interpretable artificial intelligence (AI); sorting the AI interpretations based on one or more impact values; selecting one or more augmentations based on the sorted one or more AI interpretations; and applying the selected augmentations to a training dataset for a machine learning model. In another embodiment, a method comprises: obtaining one or more predicted symptoms from a symptom classifier for a plurality of users; feeding the one or more predicted symptoms into a speaker classifier; and predicting an owner of a symptom based on output of the speaker classifier.","['G10L17/26', 'G10L17/18', 'A61B5/002', 'A61B5/0022', 'A61B5/0077', 'A61B5/01', 'A61B5/021', 'A61B5/0507', 'A61B5/0823', 'A61B5/0871', 'A61B5/1116', 'A61B5/14542', 'A61B5/4815', 'A61B5/4839', 'A61B5/4842', 'A61B5/7257', 'A61B5/7264', 'A61B5/747', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06K9/627', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N5/006', 'G06N5/01', 'G06N5/013', 'G06V10/764', 'G06V10/82', 'G10L17/02', 'G10L17/04', 'G10L25/66', 'G16H20/10', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H50/80', 'A61B2560/0247', 'A61B2562/0204', 'A61B2562/0219', 'A61B5/0826', 'A61B5/308', 'A61B5/369', 'A61B5/389', 'A61B5/398', 'G06N3/048', 'G06N3/08', 'G06N3/082']"
US11922681B2,Systems and methods for identifying cell clusters within images of stained biological samples,"The present disclosure relates to automated systems and methods adapted to quickly and accurately train a neural network to detect and/or classify cells and/or nuclei. The present disclosure also relates to automated systems and methods for using a trained cell detection and classification engine, such as one including a neural network, to classify cells within an unlabeled image.","['G06V10/82', 'G06F18/2155', 'G06F18/231', 'G06F18/2413', 'G06F18/243', 'G06V10/25', 'G06V10/454', 'G06V10/764', 'G06V20/695', 'G06V20/698', 'G06V2201/03']"
US12118455B2,"Systems, methods, and/or media, for selecting candidates for annotation for use in training a classifier","Systems for selecting candidates for labelling and use in training a convolutional neural network (CNN) are provided, the systems comprising: a memory device; and at least one hardware processor configured to: receive a plurality of input candidates, wherein each candidate includes a plurality of identically labelled patches; and for each of the plurality of candidates: determine a plurality of probabilities, each of the plurality of probabilities being a probability that a unique patch of the plurality of identically labelled patches of the candidate corresponds to a label using a pre-trained CNN; identify a subset of candidates of the plurality of input candidates, wherein the subset does not include all of the plurality of candidates, based on the determined probabilities; query an external source to label the subset of candidates to produce labelled candidates; and train the pre-trained CNN using the labelled candidates.","['G06N3/08', 'G06F18/2148', 'G06F18/217', 'G06F18/2413', 'G06F18/28', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/772', 'G06V10/7747', 'G06V10/776', 'G06V10/82']"
CN112990262B,An integrated solution system for grassland ecological data monitoring and intelligent decision-making,"The invention discloses a solution system integrating grassland ecological data monitoring and intelligent decision making, which comprises: ecological environment data acquisition module, target area video data acquisition module, sensor module, data processing module and high in the clouds service platform module, the system can be to establishing high in the clouds ecological database to grassland ecological environment on a large scale in the short time, combines big data and artificial intelligence to use, can carry out a series of scientific analysis and decision-making to target area ecological state from a plurality of dimensions, including plant species discernment, ecological disaster early warning and plant diseases and insect pests degree analysis, can take reasonable improvement measure when making the user fully know target area ecological state, also provide valuable scientific research data for scientific research personnel simultaneously, will form powerful technical support to the recovery and the protection of grassland ecological environment.","['G06F18/24', 'G06F18/2415', 'G06F18/253', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
CN108960419B,Apparatus and method for student-teacher transfer learning network using knowledge bridge,"An apparatus, method of manufacturing an apparatus, and method of constructing an integrated circuit are provided. The device comprises: a teacher network; a student network; a plurality of knowledge bridges between the teacher network and the student network, wherein each of the plurality of knowledge bridges provides hints about a function being learned, and the hints include mean square error or probability; and a loss function device connected to the plurality of knowledge bridges and the student network. The method comprises the following steps: training a teacher network; providing cues to the student network through a plurality of knowledge bridges between the teacher network and the student network; and determining a loss function based on the outputs of the plurality of knowledge bridges and the student network.","['G06N3/08', 'G06N3/0675', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N3/096', 'G06N7/01']"
AU2020100705A4,A helmet detection method with lightweight backbone based on yolov3 network,"This helmet detection invention is part of the object detection algorithm for safety production monitoring of construction site. It could detect whether construction personnel are wearing safety helmets or not, and identify the level of construction personnel by the color of the helmet. This detection model is based on YOLOv3 network, aiming to improve the detection speed and distinguish the target and background better. More specifically, our model has been improved its algorithms to maintain the efficiency and accuracy of object detection and enhance the recognition ability of small objects. In essence, YOLOv3 is a deep convolution neural network with regression function. The main purpose of YOLOv3 is to predict six parameters from the Bounding Box through multiple layers of Darknet-53: the center coordinates of (x, y), length, width, confidence and the conditional class probabilities. And then uses the Darknet lightweight framework to process images at a faster speed. In this invention, we use transfer learning skill to put pre-trained weights configuration of the helmet to learn our specific helmet training dataset. Through this method, it shows that it has higher detection quality and less detection error in the detection task of high-quality objects. 1 512 I 512 128 128 DBL RES DBL RES 9L RES DBL Figure 3.1 e Figure 3.2 2","['G06V10/82', 'G06N3/0464', 'G06N3/096', 'G06V20/10', 'G06V20/52']"
US12143775B2,Hearing device comprising a detector and a trained neural network,"A hearing device comprises an input transducer comprising a microphone for providing an electric input signal representative of sound in the environment of the hearing device, a pre-processor for processing electric input signal and providing a multitude of feature vectors, each being representative of a time segment thereof, a neural network processor adapted to implement a neural network for implementing a detector configured to provide an output indicative of a characteristic property of the at least one electric input signal, the neural network being configured to receive said multitude of feature vectors as input vectors and to provide corresponding output vectors representative of said output of said detector in dependence of said input vectors. The hearing device further comprises a transceiver comprising a transmitter and a receiver for establishing a communication link to another part or device or server, at least in a particular adaptation-mode of operation, and a selector for—in said particular adaptation—mode of operation—routing said feature vectors to said transmitter for transmission to said another part or device or server, and—in a normal mode of operation—to route said feature vectors to said neural network processor for use as inputs to said neural network, a neural network controller connected to said neural network processor for—in said particular adaptation-mode of operation—receiving optimized node parameters, and to apply said optimized node parameters to said nodes of said neural network to thereby implement an optimized neural network in said neural network processor, wherein the optimized node parameters have been selected among a multitude of sets of node parameters for respective candidate neural networks according to a predefined criterion in dependence of said feature vectors. A method of selecting optimized parameters for a neural network for use in a portable hearing device is further disclosed. The invention may e.g. be used in hearing aids or headsets, or similar, e.g. wearable, devices.","['H04R25/50', 'G06N3/08', 'G06N3/0464', 'G06N3/063', 'G06N3/09', 'G06N3/096', 'G10L15/08', 'G10L17/00', 'H04R25/554', 'H04R25/70', 'G06N3/045', 'G10L2015/088', 'H04R2225/43', 'H04R2225/67', 'H04R25/453', 'H04R25/507', 'H04R25/558']"
US12032111B2,Method and system for faster seismic imaging using machine learning,"A method may include obtaining seismic data regarding a geological region of interest. The seismic data may include various pre-processed gathers. The method may further include obtaining a machine-learning model that is pre-trained to predict migrated seismic data. The method may further include selecting various training gathers based on a portion of the pre-processed gathers, a migration function, and a velocity model. The method may further include generating a trained model using the training gathers, the machine-learning model, and a machine-learning algorithm. The method may further include generating a seismic image of the geological region of interest using the trained model and a remaining portion of the seismic data.","['G01V1/345', 'G01V1/303', 'G01V1/02', 'G01V1/16', 'G01V1/282', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G01V2210/121', 'G01V2210/1295', 'G01V2210/1425', 'G01V2210/324', 'G01V2210/51', 'G01V2210/74']"
EP4120286A1,Method of evaluating text similarity for diagnosis or monitoring of a health condition,"The invention relates to a computer implemented method of training a machine learning model to evaluate the similarity of a candidate text to a reference text for determining or monitoring a health condition, where the model takes a text comparison pair comprising a reference text and a candidate text, each comprising data encoding a text sequence, the method comprising: pre-training an edit encoder to learn to generate an edit-space representation of an input text comparison pair, where the edit-space representation encodes information for mapping the reference text to the candidate text, the edit encoder comprising a machine learning model; and performing task-specific training by adding a task-specific network layer and training the task-specific network layer to map an edit-space representation generated by the pre-trained edit encoder to an output associated with a health condition. Edit-space representations learned in this way are able to encode a greater range of changes in language use than known metrics used to evaluate machine translations.","['G16H50/70', 'G06F40/166', 'G06F40/284', 'G06F40/30', 'G06N20/00', 'G06N3/0455', 'G06N3/082', 'G06N3/0895', 'G06N3/096', 'G16H10/60', 'G16H50/20']"
US11875125B2,System and method for designing artificial intelligence (AI) based hierarchical multi-conversation system,Method and system for determining a conversation system from a multi-conversation system using Artificial Intelligence (AI) is provided. The method includes receiving a user query associated with a domain and creating a hierarchical tree comprising a root node and a child node using a first pre-trained machine learning model. The method further includes traversing the hierarchical tree for a path between root node and one leaf child node to identify a topic hierarchy. The path is associated with a confidence score corresponding to mapping between user query and match data of nodes in the path. The method further includes determining a conversation system from the multi-conversation system for outputting data to answer the user query corresponding to one leaf child node of one path with a highest confidence score.,"['G06F16/3329', 'G06F40/35', 'G06F16/24522', 'G06F16/24578', 'G06F40/279', 'G06N20/00']"
US12217834B2,Molecular graph generation from structural features using an artificial neural network,"Discovering molecules (which may be known or may never have been cataloged or ever synthesized) that have desired characteristics is addressed using a machine learning approach. As compared to a brute-force search of a database of known molecules, which may not be computationally feasible, the present machine learning approach renders identification of both known and unknown molecules computationally tractable. Furthermore, the computational effort is largely shifted to training of the machine learning system using a database of known molecules, and the generation of molecules to match any particular characteristics requires relatively little computation. The molecules using the present approach may be further studied, for example, with computer-based simulation or after physical synthesis using biological experimentation to ultimately yield useful chemical compounds.","['G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G16C20/50', 'G16C20/70', 'G16C20/80', 'G16C20/30']"
US10474949B2,Knowledge-graph biased classification for data,A method for classifying an object includes applying multiple confidence values to multiple objects. The method also includes determining a metric based on the multiple confidence values. The method further includes determining a classification of a first object from the multiple objects based on a knowledge-graph when the metric is above a threshold.,"['G06N3/08', 'G06N3/04', 'G06N3/042', 'G06N3/0427', 'G06N3/0464', 'G06N3/047', 'G06N3/082', 'G06N3/09', 'G06N7/005', 'G06N7/01', 'G06N3/049']"
JP5188977B2,Companion robot for personal interaction,"A mobile robot guest for interacting with a human resident performs a room-traversing search procedure prior to interacting with the resident, and may verbally query whether the resident being sought is present. Upon finding the resident, the mobile robot may facilitate a teleconferencing session with a remote third party, or interact with the resident in a number of ways. For example, the robot may carry on a dialogue with the resident, reinforce compliance with medication or other schedules, etc. In addition, the robot incorporates safety features for preventing collisions with the resident; and the robot may audibly announce and/or visibly indicate its presence in order to avoid becoming a dangerous obstacle. Furthermore, the mobile robot behaves in accordance with an integral privacy policy, such that any sensor recording or transmission must be approved by the resident.","['B25J9/0003', 'B25J11/008', 'B25J19/0091', 'B25J19/023', 'B25J19/06', 'B25J5/007', 'B25J9/1697', 'G05D1/021', 'G05D1/0246', 'G05D1/0272', 'G05D1/0274', 'G06N3/008', 'G16H20/00', 'G16H20/13', 'G16H40/63', 'G16H40/67', 'G16H70/40', 'H04N7/142', 'G05D1/0225', 'G05D1/0234', 'G05D1/0242', 'G05D1/0251', 'G05D1/0255', 'G05D1/027', 'Y10S901/01', 'Y10S901/46', 'Y10S901/47']"
CN113705769B,Neural network training method and device,"The application provides a neural network training method and device, which are used for measuring the credibility of an initial label by combining the initial label and a pseudo label of a sample, and updating a model based on the initial label and the pseudo label to obtain a model with better robustness. The method comprises the following steps: pre-training the initial model by using a training set to obtain at least two pre-training models; performing iterative training on at least two pre-training models by using a training set to obtain a plurality of trained first models, wherein any one iterative training process comprises the following steps: inputting any sample in the first training set to obtain a first pseudo tag of each sample, obtaining a prediction tag of each sample through a first pre-training model, calculating a first loss value according to the prediction tag, the initial tag and the first pseudo tag of each sample, updating the first pre-training model, and obtaining a trained first pre-training model.","['G06N3/045', 'G06F18/214']"
WO2022116502A1,"Model training method and device, data processing method and device, client and storage medium","The present invention relates to model construction in artificial intelligence, and provides a model training method and device, a data processing method and device, a client and a storage medium. The model training method comprises: obtaining ultrasonic image data containing a target detection object, and pre-training a preset neural network according to the ultrasonic image data to obtain a target neural network (S101); extracting a plurality of pieces of ultrasonic image data from the ultrasonic image data, and training the target neural network according to the plurality of pieces of ultrasonic image data to obtain the training result (S102); determining gradient data of the target neural network on the basis of the training result, encrypting the gradient data, and sending the encrypted gradient data to a federated learning server (S103); receiving target gradient data sent by the federated learning server (S104); and updating model parameters of the target neural network according to the target gradient data until the updated target neural network converges, to obtain an ultrasonic image data processing model (S105). The method can improve the detection effect and accuracy of the ultrasonic image data processing model.","['G06T7/0012', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30056', 'G06T2207/30084', 'Y02T10/40']"
US10891523B2,Optimal and efficient machine learning method for deep semantic segmentation,"Four computerized machine learning methods for deep semantic segmentation are fast machine learning method, active machine learning method, optimal machine learning method, and optimal transfer learning method. The fast machine learning method performs a fast deep semantic segmentation learning on training images to generate a deep model. The active machine learning method performs a fast deep semantic segmentation learning on initial training images to generate a first deep model and then an active deep semantic segmentation learning to generate a second deep model. The optimal machine learning method performs a fast deep semantic segmentation learning on initial training images to generate a first deep model and then an optimal deep semantic segmentation learning to generate a second deep model. The optimal transfer learning method applies a pre-trained first deep model on transfer training images and then an optimal deep semantic segmentation transfer learning to generate a second deep model.","['G06N3/084', 'G06K9/6262', 'G06F18/217', 'G06K9/726', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06V10/7747', 'G06V10/82', 'G06V30/274', 'G06N5/02', 'G06T2207/20081', 'G06T2207/20084']"
US11238593B2,Multi-object image parsing using neural network pipeline,"Techniques are disclosed for parsing a source image, to identify segments of one or more objects within the source image. The parsing is carried out by an image parsing pipeline that includes three distinct stages comprising three respectively neural network models. The source image can include one or more objects. A first neural network model of the pipeline identifies a section of the source image that includes the object comprising a plurality of segments. A second neural network model of the pipeline generates, from the section of the source image, a mask image, where the mask image identifies one or more segments of the object. A third neural network model of the pipeline further refines the identification of the segments in the mask image, to generate a parsed image. The parsed image identifies the segments of the object, by assigning corresponding unique labels to pixels of different segments of the object.","['G06T7/11', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T3/4046', 'G06T7/194', 'G06V10/454', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/10', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20112', 'G06T2207/30196']"
US11449709B2,Domain restriction of neural networks through synthetic data pre-training,"A neural network is trained to focus on a domain of interest. For example, in a pre-training phase, the neural network in trained using synthetic training data, which is configured to omit or limit content less relevant to the domain of interest, by updating parameters of the neural network to improve the accuracy of predictions. In a subsequent training phase, the pre-trained neural network is trained using real-world training data by updating only a first subset of the parameters associated with feature extraction, while a second subset of the parameters more associated with policies remains fixed.","['G06K9/6256', 'G01S7/417', 'G01S13/89', 'G01S13/931', 'G01S17/894', 'G01S17/931', 'G05D1/0088', 'G05D1/0221', 'G05D1/0251', 'G06F18/214', 'G06F18/24', 'G06K9/6232', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/17', 'G06V20/176', 'G06V20/56', 'G08G1/166', 'G08G1/167', 'G01S13/582', 'G05D2201/0213']"
US12314318B2,Enhanced searching using fine-tuned machine learning models,"An advanced search system leverages a pre-trained large language model to enhance user query responses. The system, equipped with hardware processors, a search query via an interface and accesses a pre-trained large language model designed to respond to the search query. The system fine-tunes the model to generate a task-specific generative model. The system employs the task-specific generative model to generate a search result to the search query and analyzes the search result based on a performance metric associated with the task-specific generative model. The system refines the task-specific generative model based on the analyzing of the search result.","['G06F16/24575', 'G06F16/248', 'G06F16/345', 'G06F16/90328', 'G06F16/93', 'G06F16/9538', 'G06F16/9558']"
CN108304873B,Target detection method and system based on high-resolution optical satellite remote sensing image,"The invention relates to a target detection method and a system thereof based on a high-resolution optical satellite remote sensing image, wherein the method comprises the steps of obtaining a marked target positive sample and a marked background negative sample to form a training sample; extracting a plurality of different weak characteristic channels aiming at a training sample, and acquiring a candidate region according to the plurality of different weak characteristic channels; acquiring a context scene of the candidate region, extracting features of the candidate region and the context scene of the candidate region, and fusing the extracted features to form candidate region features; training the training samples to obtain a classifier; classifying the candidate region characteristics by using a classifier to obtain a target region containing a target; and carrying out duplicate removal processing on the target area to obtain a detection target. The invention realizes the target detection on the remote sensing image with the enlarged width, and optimizes the target detection effects of the target with the close distance and the target with the unusual length-width ratio.","['G06F18/214', 'G06F18/2411', 'G06T5/50', 'G06V10/40', 'G06T2207/10044', 'G06T2207/20081']"
US11696714B2,System and method for brain modelling,"Brain modelling includes receiving time-coded bio-signal data associated with a user; receiving time-coded stimulus event data; projecting the time-coded bio-signal data into a lower dimensioned feature space; extracting features from the lower dimensioned feature space that correspond to time codes of the time-coded stimulus event data to identify a brain response; generating a training data set for the brain response using the features; training a brain model using the training set, the brain model unique to the user; generating a brain state prediction for the user output from the trained brain model, and automatically computing similarity metrics of the brain model as compared to other user data; and inputting the brain state prediction to a feedback model to determine a feedback stimulus for the user, wherein the feedback model is associated with a target brain state.","['A61B5/4064', 'A61B5/246', 'A61B5/02055', 'A61B5/375', 'A61B5/377', 'A61B5/7267', 'A61B5/7275', 'G16H20/00', 'G16H40/67', 'G16H50/20', 'G16H50/50', 'G16H50/70']"
US11411979B2,Compliance process risk assessment,"Systems, computer-implemented methods, and computer program products that can facilitate compliance process risk assessment are provided. According to an embodiment, a system can comprise a memory that stores computer executable components and a processor that executes the computer executable components stored in the memory. The computer executable components can comprise a metric assignment component that assigns one or more risk assessment metrics based on vulnerability data of a compliance process. The computer executable components can further comprise a risk assignment component that assigns a risk score of the compliance process based on the one or more risk assessment metrics.","['H04L63/20', 'H04L63/1433', 'G06N20/00', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'H04L63/102']"
US11580410B2,3-D convolutional autoencoder for low-dose CT via transfer learning from a 2-D trained network,"A 3-D convolutional autoencoder for low-dose CT via transfer learning from a 2-D trained network is described, A machine learning method for low dose computed tomography (LDCT) image correction is provided. The method includes training, by a training circuitry, a neural network (NN) based, at least in part, on two-dimensional (2-D) training data. The 2-D training data includes a plurality of 2-D training image pairs. Each 2-D image pair includes one training input image and one corresponding target output image. The training includes adjusting at least one of a plurality of 2-D weights based, at least in part, on an objective function. The method further includes refining, by the training circuitry, the NN based, at least in part, on three-dimensional (3-D) training data. The 3-D training data includes a plurality of 3-D training image pairs. Each 3-D training image pair includes a plurality of adjacent 2-D training input images and at least one corresponding target output image. The refining includes adjusting at least one of a plurality of 3-D weights based, at least in part, on the plurality of 2-D weights and based, at least in part, on the objective function. The plurality of 2-D weights includes the at least one adjusted 2-D weight.","['G06V10/82', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T11/00', 'G06T11/006', 'G06T5/002', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'A61B6/032', 'A61B6/5258', 'A61B6/542', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
AU2020251045B2,Method and system for selecting embryos,"An Artificial Intelligence (AI) computational system for generating an embryo viability score from a single image of an embryo to aid selection of an embryo for implantation in an In-Vitro Fertilisation (IVF) procedure is described. The AI model uses a deep learning method applied to images in which the Zona Pellucida region in the image is identified using segmentation, and ground truth labels such as detection of a heartbeat at a six week ultrasound scan.","['G06N20/20', 'G06F18/24133', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06T7/11', 'G06T7/12', 'G06T7/136', 'G06T7/149', 'G06V10/50', 'G06V10/54', 'G06V10/82', 'G06V20/695', 'A61B17/435', 'G06F17/145', 'G06T2200/28', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30044']"
US20210319559A1,Deep convolutional neural network with self-transfer learning,"Systems and techniques for facilitating a deep convolutional neural network with self-transfer learning are presented. In one example, a system includes a machine learning component, a medical imaging diagnosis component and a visualization component. The machine learning component generates learned medical imaging output regarding an anatomical region based on a convolutional neural network that receives medical imaging data. The machine learning component also performs a plurality of sequential downsampling and upsampling of the medical imaging data associated with convolutional layers of the convolutional neural network. The medical imaging diagnosis component determines a classification and an associated localization for a portion of the anatomical region based on the learned medical imaging output associated with the convolutional neural network. The visualization component generates a multi-dimensional visualization associated with the classification and the localization for the portion of the anatomical region.","['G06T7/0012', 'G06F18/24', 'G06F18/2414', 'G06K9/6267', 'G06K9/6273', 'G06N3/045', 'G06N3/0454', 'G06V10/764', 'G06V10/82', 'G16H50/20', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30008', 'G06T2207/30048', 'G06T2207/30061', 'G06T2207/30096']"
US11620330B2,Classifying image styles of images based on image style embeddings,"Various disclosed embodiments are directed to classify or determining an image style of a target image according to a consumer application based on determining a similarity score between the image style of a target image and one or more other predetermined image styles of the consumer application. Various disclosed embodiments can resolve image style transfer destructiveness functionality by making various layers of predetermined image styles modifiable. Further various embodiments resolve tedious manual user input requirements and reduce computing resource consumption, among other things.","['G06V10/761', 'G06F16/55', 'G06F16/5854', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G06V10/443']"
US12227212B2,Computer vision based real-time pixel-level railroad track components detection system,"Systems, methods and devices for a computer vision-based pixel-level rail components detection system using an improved one-stage instance segmentation model and prior knowledge, aiming to inspect railway components in a rapid, accurate, and convenient fashion.","['B61L23/042', 'B61L23/044', 'B61L23/045', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06T7/0008', 'G06T7/75', 'G06V10/454', 'G06V10/82', 'G06V20/56', 'B61L23/041', 'G06N3/044', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30108']"
US12293288B2,Systems and methods of data preprocessing and augmentation for neural network climate forecasting models,"Methods and systems for training a neural network (NN)-based climate forecasting model on a pre-processed multi-model ensemble of global climate simulation data from a plurality of global climate simulation models (GCMs), are disclosed. The methods and systems perform steps of determining a common spatial scale and a common temporal scale for the multi-model ensemble of global climate simulation data; spatially re-gridding the multi-model ensemble to the common spatial scale; temporally homogenizing the multi-model ensemble to the common temporal scale; augmenting the spatially re-gridded, temporally homogenized multi-model ensemble with synthetic simulation data generated from the spatially re-gridded, temporally homogenized multi-model ensemble; and training the NN-based climate forecasting model using the spatially re-gridded, temporally homogenized, and augmented multi-model ensemble of global climate simulation data. Embodiments of the present invention enable accurate climate forecasting without the need to run new dynamical global climate simulations on supercomputers.","['G06N3/08', 'G01W1/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06N3/044', 'Y02A90/10']"
US11016495B2,Method and system for end-to-end learning of control commands for autonomous vehicle,"Systems and methods are provided for end-to-end learning of commands for controlling an autonomous vehicle. A pre-processor pre-processes image data acquired by sensors at a current time step (CTS) to generate pre-processed image data that is concatenated with additional input(s) (e.g., a segmentation map and/or optical flow map) to generate a dynamic scene output. A convolutional neural network (CNN) processes the dynamic scene output to generate a feature map that includes extracted spatial features that are concatenated with vehicle kinematics to generate a spatial context feature vector. An LSTM network processes, during the (CTS), the spatial context feature vector at the (CTS) and one or more previous LSTM outputs at corresponding previous time steps to generate an encoded temporal context vector at the (CTS). The fully connected layer processes the encoded temporal context vector to learn control command(s) (e.g., steering angle, acceleration rate and/or a brake rate control commands).","['G05D1/0221', 'B60W50/00', 'G06N3/084', 'B60W60/001', 'G05D1/0088', 'G05D1/0246', 'G06F18/24137', 'G06K9/481', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/046', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'B60W2050/0002', 'B60W2050/0088', 'B60W2420/403', 'B60W2520/10', 'B60W2520/105', 'B60W2540/18', 'G05D2201/0213', 'G06N3/048']"
US20240386015A1,Composite symbolic and non-symbolic artificial intelligence system for advanced reasoning and semantic search,"A semantic search system integrates with an AI platform to provide advanced search capabilities by leveraging automatically generated ontologies and knowledge graphs. The system employs natural language processing, machine learning, and large language models to create, update, and align ontologies from diverse data sources. It supports context-aware query interpretation, personalized results, and complex reasoning by incorporating user context, feedback, and domain knowledge. The system optimizes search performance and efficiency through indexing techniques, distributed computing, and continuous learning. With a modular architecture and scalable infrastructure, the semantic search system enables users to retrieve relevant, meaningful, and context-specific information from vast amounts of structured and unstructured data. The integration of the semantic search system with the AI platform's components, such as knowledge graphs and model blending, enhances the platform's overall reasoning, decision-making, and problem-solving capabilities, empowering users with intelligent and intuitive search experiences across various domains and applications.","['G06F40/30', 'G06F16/245', 'G06F16/248', 'G06F16/9024', 'G06N5/022', 'G06N5/04']"
AU2019101142A4,A pedestrian detection method with lightweight backbone based on yolov3 network,"This pedestrian detection invention is part of the autonomous driving algorithms on the vehicles. It could support self-driving vehicles in a safe driving environment for pedestrians and passengers in the car. This detection model is based on the lightweight backbone of YOLOv3, aiming to improve the detection speed and accuracy from current detection models. More specifically, our model has been reduced part of YOLOv3's complex and computationally intensive procedures and improved its algorithms to maintain the efficiency and accuracy of object detection. The main purpose of YOLOv3 is to predict the center coordinates of (x,y) from the Bounding Box and its length, width through multiple layers of VGG Convolutional Neural Network (VGG-CNN) and uses the Darknet lightweight framework to process images at a faster speed. In this invention, we use transfer learning skill to put pre-trained weights configuration of the pedestrian to learn our specific pedestrian training dataset. By this method, it performs a higher quality on mass object detection tasks with fewer detection errors.","['G06V40/103', 'G06N3/02']"
CN117876381B,AI visual detection method and system for identifying and analyzing concrete structure cracks,"The invention discloses an AI visual detection method and system for identifying and analyzing cracks of a concrete structure, comprising the steps of collecting basic data according to a preset period, including reading image data of a multispectral camera, and obtaining monitoring data of a stress-strain sensor; initially segmenting a crack region image from the extracted image data; extracting a crack displacement field based on the crack region image, and screening the crack region image through the crack displacement field to obtain a key crack region image; invoking a constructed random forest classification optimization module to classify the key crack region images to obtain an image dataset composed of at least two types of crack region images; and extracting a crack skeleton according to each type of crack region image and the monitoring data of the corresponding space time of the crack region image, quantitatively analyzing a crack displacement field, and giving out a crack development trend analysis result and outputting the analysis result. The invention solves the problems of environmental adaptation, process reconstruction and three-dimensional reconstruction in the crack identification process.","['G06T7/0004', 'G06N3/0464', 'G06N3/084', 'G06T7/11', 'G06T7/136', 'G06T7/155', 'G06V10/761', 'G06V10/764', 'G06V10/811', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
CN113343821B,Non-contact heart rate measurement method based on space-time attention network and input optimization,"The invention discloses a non-contact heart rate measuring method based on a space-time attention network and input optimization, which comprises the following steps: 1, acquiring a data set containing a face video, a label physiological signal and a label heart rate, and preprocessing; 2, training a super-resolution model ESRGAN for recovering physiological information in the image; 3, constructing a space-time attention network model M; 4, training a space-time attention network model M by adopting a transfer learning strategy to obtain a preliminarily trained space-time attention network model M'; and 5, performing combined training on the generator S 'in the preliminarily trained ESRGAN and the preliminarily trained space-time attention network model M' to realize non-contact heart rate measurement. The invention can effectively and accurately extract the rPPG signal, greatly improve the quality of the extracted signal, and calculate the heart rate information from the rPPG signal, thereby obviously improving the accuracy of non-contact heart rate measurement.","['G06F18/214', 'G06F18/253']"
CN110334814B,Method and system for constructing risk control model,"The present disclosure provides a method for efficiently building a risk control model, comprising: constructing a basic model library to select models in the basic model library when a new service is triggered to construct a default model; constructing a new model suitable for new business through automatic feature generation, automatic feature selection and automatic parameter adjustment; training a default model and a new model via transfer learning; automatically fusing the trained default model and the trained new model to generate a fused model; using the trained default model as an online model and using the trained new model and the fusion model as a backup model; and replacing the on-line model with the backup model when one of the backup models is better than the on-line model.","['G06N20/00', 'G06Q40/04']"
US20200279105A1,Deep learning engine and methods for content and context aware data classification,"Methods, systems and deep learning engines for content and context aware data classification by business category and confidentiality level are provided. The deep learning engine includes a feature extraction module and a classification and labelling module. The feature extraction module extracts both context features and document features from documents and the classification and labelling module is configured for content and context aware data classification of the documents by business category and confidentiality level using neural networks.","['G06K9/00442', 'G06N3/08', 'G06F18/24', 'G06F18/24155', 'G06F18/2431', 'G06K9/6278', 'G06K9/628', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N20/20', 'G06N7/01']"
US20200019864A1,Systems and methods for artificial-intelligence-based automated object identification and manipulation,"The disclosed computer-implemented system and method for artificial-intelligence-based automated object identification and manipulation can include receiving a subsystem request from a third-party entity, the request being related to a subsystem for an object identification and manipulation system. The system and method also includes creating a developer request for a model suitable for the subsystem, the developer request including at least one approval condition. The system and method further includes evaluating a developer proposal received in response to the developer request, the developer proposal including a trained model, the evaluating including determining an accuracy level of the trained model, and the evaluating includes designating the trained model as an approved model if the developer proposal is approved. Also, the system and method includes providing the approved model to the third-party entity in response to the subsystem request.","['G06N5/02', 'G06Q20/3678', 'B25J9/1697', 'G05B19/4183', 'G06Q20/065', 'G05B2219/39271', 'G05B2219/40543', 'G06N3/045', 'G06N3/08', 'G06Q2220/00', 'Y02P90/02']"
CN112836713B,Mesoscale convective system recognition and tracking method based on image anchor-free frame detection,"The invention discloses a Mesoscale convection system (Mesoscale ConvectiveSystem, MCS) identification and tracking method based on image anchor-free frame detection, which comprises the following steps: step 1, preprocessing original static satellite infrared bright temperature data, marking a mesoscale convection system on an infrared cloud picture obtained after processing, and then randomly dividing a training set, a verification set and a test set; step 2, an example segmentation network based on an anchor-free frame is constructed, and the network is used for extracting image characteristics, detecting a mesoscale convection system and segmenting specific examples; step 3, training set image enhancement, and using a transfer learning supervision training example to segment a convolutional neural network, and automatically learning network parameters; step 4, detecting and dividing a mesoscale convection system of the static satellite infrared cloud picture at the adjacent moment by using the trained model; and step 5, tracking the mesoscale convection system according to a related target matching principle.","['G06V10/44', 'G06F18/241', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06T7/11', 'G06T7/136', 'G06T7/62', 'G06V10/25', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/30192', 'Y02A90/10']"
US20240013462A1,Audio-driven facial animation with emotion support using machine learning,"A deep neural network can be trained to output motion or deformation information for a character that is representative of the character uttering speech contained in audio input, which is accurate for an emotional state of the character. The character can have different facial components or regions (e.g., head, skin, eyes, tongue) modeled separately, such that the network can output motion or deformation information for each of these different facial components. During training, the network can be provided with emotion and/or style vectors that indicate information to be used in generating realistic animation for input speech, as may relate to one or more emotions to be exhibited by the character, a relative weighting of those emotions, and any style or adjustments to be made to how the character expresses that emotional state. The network output can be provided to a renderer to generate audio-driven facial animation that is emotion-accurate.","['G10L21/10', 'G06T13/205', 'G06T13/40', 'G06T17/20', 'G10L15/16', 'G10L25/63', 'G10L2021/105']"
US11743150B2,Automated root cause analysis of underperforming video streams by using language transformers on support ticket systems,"A method and system corrects a content delivery infrastructure. The method of the system includes receiving a request to resolve reported issues for the content delivery infrastructure, collecting content delivery metrics for the content delivery infrastructure, executes a language transformer model on the request and the content delivery metrics to generate a set of possible resolutions with confidence ratings, and implementing an automated solution based on a resolution from the set of possible resolutions, in response to the resolution having a confidence rating above a threshold.","['H04L41/0631', 'H04L41/509', 'G06N20/00', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G06N3/096', 'H04L41/0695', 'H04L41/16', 'H04L41/5009', 'H04L41/5048', 'H04L41/5061', 'H04L41/5074', 'H04L43/0829', 'H04L43/0852', 'H04L43/087', 'H04L43/0882', 'H04L43/0894']"
US20230316555A1,System and Method for Image-Based Remote Sensing of Crop Plants,"Methods for image-based remote sensing of crop plants include: acquiring images of the crop plants from a camera flown over the crop by an unmanned/uncrewed aerial vehicle (UAV); forming an artificial neural network (ANN); and using the trained ANN to identify and/or measure one or more phenotypic characteristics of the crop plants in the images by classification and/or regression; and/or obtaining multispectral images of the crop plants from a multispectral camera flown over the crop by the UAV; mosaicking the multispectral images together; determining crop measurement metrics; crop height model (CHM), crop coverage (CC) and crop volume (CV) representing the crop plants in three dimensions from a fusion of a digital surface model and a digital terrain model; determining various vegetation indices (VIs) based on the multispectral orthomosaic reflectance map; and determining a measurement of dry biomass using CV and fresh biomass using CV×VIs.","['G06T7/62', 'G06Q10/06', 'G06V20/188', 'G06T17/00', 'G06T17/05', 'G06T3/4038', 'G06T7/0016', 'G06T7/337', 'G06T7/344', 'G06V10/803', 'G06V10/82', 'G06V20/17', 'G01J2003/2826', 'G01N2021/1797', 'G06N3/02', 'G06Q50/02', 'G06T2207/10036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30188', 'G06T5/80', 'G06V10/16', 'G06V20/194']"
US20190228099A1,Question and answer pair generation using machine learning,"An interactive question and answer (Q&A) service provides pairs of questions and corresponding answers related to the content of a web page. The service includes pre-configured Q&A pairs derived from a deep learning framework that includes a series of neural networks trained through joint and transfer learning to generate questions for a given text passage. In addition, pre-configured Q&A pairs are generated from historical web access patterns and sources related to the content of the web page.","['G06F16/3329', 'G06N5/041', 'G06F17/30654', 'G06F16/3334', 'G06F16/38', 'G06F16/951', 'G06F17/30663', 'G06F17/30722', 'G06F17/30864', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084']"
US10460447B2,Method and system for performing segmentation of image having a sparsely distributed object,"Methods and systems for segmenting images having sparsely distributed objects are disclosed. A method may include: predicting object potential areas in the image using a preliminary fully convolutional neural network; segmenting a plurality of sub-images corresponding to the object potential areas in the image using a refinement fully convolutional neural network, wherein the refinement fully convolutional neural network is trained to segment images on a higher resolution compared to a lower resolution utilized by the preliminary fully convolutional neural network; and combining the segmented sub-images to generate a final segmented image.","['G06T7/11', 'G06T7/143', 'G06F18/21345', 'G06F18/24143', 'G06N3/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/12', 'G06T7/13', 'G06T7/174', 'G06T7/194', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G06T2207/20021', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US20240108286A1,Wearable Appliance,"What is disclosed is a wearable appliance that includes a housing adapted to fit in an ear of a user, an optical transmitter disposed in the housing, an optical receiver disposed in the housing, a wireless network communication device disposed in the housing, an accelerometer disposed in the housing, a microphone disposed in the housing, and a speaker disposed in the housing.","['A61B5/681', 'A61B5/0006', 'A61B5/002', 'A61B5/0022', 'A61B5/02055', 'A61B5/1112', 'A61B5/1117', 'A61B5/296', 'A61B5/332', 'A61B5/384', 'A61B5/411', 'A61B5/4818', 'A61B5/4839', 'A61B5/6803', 'A61B5/6804', 'A61B5/7225', 'A61B7/00', 'A61B8/56', 'A61B8/565', 'G06Q50/22', 'G16H40/20', 'G16H40/67', 'A61B2503/08', 'A61B2560/0214', 'A61B2562/0219', 'A61B5/021', 'A61B5/02416', 'A61B5/02438', 'A61B5/0537', 'A61B5/0816', 'A61B5/11', 'A61B5/1135', 'A61B5/145', 'A61B5/14532', 'A61B5/14551', 'A61B5/165', 'A61B5/25', 'A61B5/369', 'A61B5/398', 'A61B5/4023', 'A61B5/4833', 'A61B5/4866', 'A61B5/4875', 'A61B5/721', 'A61B5/7214', 'A61B5/7232', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B5/7275', 'A61B7/003', 'A61B8/06', 'A61B8/0808', 'A61B8/4472']"
US11457244B2,"Apparatus, a method and a computer program for video coding and decoding","A method comprising: obtaining a block of a picture or a picture in an encoder; determining if the block/picture is used for on-line learning; if affirmative, encoding the block/picture; reconstructing a coarse version of the block/picture or the respective prediction error block/picture; enhancing the coarse version using a neural net; fine-tuning the neural net with a training signal based on the coarse version; determining if the block/picture is enhanced using the neural net; and if affirmative, encoding the block/picture with enhancing using the neural net.","['H04N19/85', 'H04N19/395', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'H04N19/124', 'H04N19/172', 'H04N19/176', 'H04N19/59', 'G06N3/048', 'G06N3/088', 'G06N5/01']"
CN110532397B,"Question-answering method and device based on artificial intelligence, computer equipment and storage medium","An artificial intelligence-based question-answering method, device, computer equipment and storage medium perform language model training based on first training data, NER model training based on second training data and the trained language model, and relationship matching model training; identifying an entity in a sentence to be processed based on the trained NER model, and obtaining a corresponding relation of the sentence to be processed based on the trained relation matching model; and determining and outputting an answer corresponding to the sentence to be processed according to the corresponding relation of the sentence to be processed and the entity in the sentence to be processed. The method is based on the language model transfer learning and the atlas transfer learning technology, improves the common training method of the language model, can achieve higher accuracy through a smaller amount of manual marking data, and is more suitable for constructing a knowledge atlas question-answering system.","['G06F16/3329', 'G06F16/367']"
US11231522B2,Methods and systems for climate forecasting using artificial neural networks,"Methods and systems for generating a neural network (NN)-based climate forecasting model are disclosed. The methods and systems perform steps of generating a multi-model ensemble of global climate simulation data by combining simulation data from at least two global climate simulation models; pre-processing the multi-model ensemble of global climate simulation data; training the NN-based climate forecasting model on the pre-processed multi-model ensemble of global climate simulation data; and validating the NN-based climate forecasting model using observational historical climate data. Embodiments of the present invention enable accurate climate forecasting without the need to run new dynamical global climate simulations on supercomputers. Also disclosed are benefits of the new methods, and alternative embodiments of implementation.","['G01W1/10', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/049', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G01W2201/00', 'Y02A90/10']"
US11816790B2,Unsupervised learning of scene structure for synthetic data generation,"A rule set or scene grammar can be used to generate a scene graph that represents the structure and visual parameters of objects in a scene. A renderer can take this scene graph as input and, with a library of content for assets identified in the scene graph, can generate a synthetic image of a scene that has the desired scene structure without the need for manual placement of any of the objects in the scene. Images or environments synthesized in this way can be used to, for example, generate training data for real world navigational applications, as well as to generate virtual worlds for games or virtual reality experiences.","['G06N3/088', 'G06T17/00', 'A63F13/52', 'G06F16/51', 'G06F16/54', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N5/025', 'G06N7/01', 'G06T15/00', 'G06T15/205', 'G06V10/25', 'G06V10/774', 'G06V20/20', 'A63F13/60', 'A63F13/67', 'G06F18/2148', 'G06F18/2155', 'G06N20/00', 'G06N3/048', 'G06T2210/61', 'G06V20/40']"
CN110188331B,"Model training method, dialogue system evaluation method, device, equipment and storage medium","The embodiment of the application discloses a model training method, device and equipment, wherein the method comprises the following steps: obtaining a pre-trained dialog generation model, the dialog generation model comprising an encoder and a decoder; constructing a dialogue system evaluation model, wherein the dialogue system evaluation model takes questions and replies as input and takes the corresponding scores of the replies as output; initializing parameters of the encoder in the dialogue system evaluation model according to the parameters of the encoder in the dialogue generation model; training the initialized dialogue system evaluation model according to a first training sample set to obtain a dialogue system evaluation model meeting training end conditions, wherein each training sample in the first training sample set comprises a question, a reply and a labeling score corresponding to the reply. The dialogue system evaluation model trained by the method can evaluate the reply quality of the dialogue system from the perspective of semantic relevance, and improves the reliability of dialogue reply evaluation.","['G06F40/12', 'G06F40/30']"
US11361571B1,Term extraction in highly technical domains,"A language model is fine-tuned by extracting terminology terms from a text document. The method comprises identifying a text snippet, identifying candidate multi-word expressions using part of speech tags, and determining a specificity score value for each of the candidate multi-word expressions. Moreover, the method comprises determining a topic similarity score value for each of the candidate multi-word expressions, selecting remaining expressions from the candidate multi-word expressions using a function of a specificity value and a topic similarity value of each of the candidate multi-word expressions, adding a noun comprised in the text snippet to the remaining expressions depending on a correlation function, labeling the remaining multi-word expressions, and fine-tuning an existing pre-trained transformer-based language model using as training data the identified text snippet marked with the labeled remaining expressions.","['G06V30/414', 'G06F40/30', 'G06F40/166', 'G06F40/268', 'G06F40/279', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V30/19093', 'G06V30/19147', 'G06V30/1985', 'G06N3/045', 'G06N5/02']"
US11625557B2,Process to learn new image classes without labels,"Described is a system for learning object labels for control of an autonomous platform. Pseudo-task optimization is performed to identify an optimal pseudo-task for each source model of one or more source models. An initial target network is trained using the optimal pseudo-task. Source image components are extracted from source models, and an attribute dictionary of attributes is generated from the source image components. Using zero-shot attribution distillation, the unlabeled target data is aligned with the source models similar to the unlabeled target data. The unlabeled target data are mapped onto attributes in the attribute dictionary. A new target network is generated from the mapping, and the new target network is used to assign an object label to an object in the unlabeled target data. The autonomous platform is controlled based on the object label.","['G06N3/084', 'G06K9/6259', 'B60W50/06', 'B60W60/00272', 'G06F18/2155', 'G06F18/22', 'G06F18/2413', 'G06F18/28', 'G06K9/6215', 'G06K9/6255', 'G06K9/627', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/091', 'G06N3/096', 'G06N3/0985', 'G06V10/764', 'G06V10/772', 'G06V10/7753', 'G06V10/82', 'B60W2420/403', 'B60W2420/42', 'G06N3/044']"
US20230334834A1,Model training based on synthetic data,"Embodiments of the present disclosure relate to model training based on synthetic data. According to example embodiments of the present disclosure, synthetic images are generated by providing respective text prompts into a text-to-image generation model. Respective training labels associated with the synthetic images are also generated based on the used text prompts. A target model, which is configured to perform an image classification task, is trained based at least in part on the synthetic images and the associated training labels. Through this solution, a large scale of synthetic images can be automatically obtained and applicable for training a model for image classification, to improve the model performance with data-scare setting or in the case of model pre-training where the training data amount matters.","['G06V10/774', 'G06T11/60', 'G06V10/764', 'G06V10/82']"
US10740651B2,Methods of systems of generating virtual multi-dimensional models using image analysis,"The present approach relates to the use of trained artificial neural networks, such as convolutional neural networks, to classify vascular structures, such as using a hierarchical classification scheme. In certain approaches, the artificial neural network is trained using training data that is all or partly derived from synthetic vascular representations.","['G06K9/6256', 'G06T7/11', 'G06F18/214', 'G06F18/24', 'G06F18/24143', 'G06K9/44', 'G06K9/6267', 'G06K9/6274', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06T7/155', 'G06V10/34', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G09B23/30', 'G09B23/303', 'G16H50/20', 'G16H50/50', 'G06K2209/05', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T2200/04', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/30016', 'G06T2207/30101', 'G06T2207/30172', 'G06V2201/03']"
US11176456B2,Pre-training neural networks using data clusters,"Aspects of the present invention disclose a method, computer program product, and system for pre-training a neural network. The method extracting features of data set received from a source, the data set includes labelled data and unlabeled data. Generating a plurality of data clusters from instances of data in the data set, the data clusters are weighted according to a respective number of similar instances of labeled data and unlabeled data within a respective data cluster. Determining a data label indicating a data class that corresponds to labeled data within a data cluster of the generated plurality of data clusters. Applying the determined data label to unlabeled data within the data cluster of the generated plurality of data clusters. In response to applying the determined data label to unlabeled data within the data cluster of the generated plurality of data clusters, deploying the data cluster to a neural network.","['G06V10/82', 'G06F16/355', 'G06F18/2155', 'G06F18/23', 'G06F9/44', 'G06K9/6218', 'G06K9/6259', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/763', 'G06V10/7753', 'G06N7/01']"
CN112732919B,Intelligent classification label method and system for network security threat information,"The invention provides an intelligent label classification method and system for network security threat intelligence. The method comprises the steps of preprocessing text data of social network text data related to network threats, acquiring a vector representation form, and inputting a BERT pre-training model for training; converting the full connection layer and the linear classifier of the feedforward neural network into vectors consistent with the vector dimension of the classification label; calculating and updating model parameters according to a cross entropy loss function until the model is converged to obtain a threat intelligence classification model; and searching, collecting, preprocessing and classifying the labels of the social network text data in sequence according to the threat intelligence classification model to obtain a classification label result. According to the scheme, the pre-training model is adopted to learn the relation between the context semantic information and the sentences of the text data, the semantic representation is obtained, the accuracy of the generated threat information classification model is high, the training efficiency can be improved, and the direct model training time is shortened.","['G06F16/353', 'G06F16/355', 'G06F16/951', 'G06N3/045', 'G06N3/088', 'H04L63/30']"
US11586875B2,Systems and methods for optimization of a data model network architecture for target deployment,"Systems and methods are provided for selecting an optimized data model architecture subject to resource constraints. One or more resource constraints for target deployment are identified, and random model architectures are generated from a set of model architecture production rules subject to the one or more resource constraints. Each random model architecture is defined by randomly chosen values for one or more meta parameters and one or more layer parameters. One or more of the random model architectures are adaptively refined to improve performance relative to a metric, and the refined model architecture with the best performance relative to the metric is selected.","['G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/046']"
CN112116560B,"A welding image defect identification method, device, storage medium and equipment","The invention provides a welding image defect identification method, a device, a storage medium and equipment; the method comprises the following steps: acquiring a welding image to be identified; inputting a welding image to be identified into a defect identification model, and identifying the welding image through the defect identification model to obtain a welding image type, so as to judge whether the welding image has defects and the defect type when the defects exist; training the initial defect recognition model to be: forming a defect identification model by combining a convolution base of the pre-training model with a full-connection classifier; performing migration training on the defect identification model; migration training refers to freezing a convolution basis, training a fully connected classifier, and then fine-tuning a defect identification model. The invention is based on the combination of deep learning and transfer learning technology, can realize the efficient training of the defect recognition model under the condition of limited sample number, and improves the accuracy of the defect recognition of the welding image.","['G06T7/0006', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T2207/10004']"
US20210365342A1,Method and system for power equipment diagnosis based on windowed feature and hilbert visualization,"A method and a system for power equipment diagnosis based on windowed feature and Hilbert visualization are provided, which belong to the field of power equipment fault diagnosis. The method includes: obtaining an original data set of monitoring data containing power equipment fault features; introducing windowed feature calculation considering logarithmic constraints to process data to obtain a feature sequence; using Hilbert visualization method for further processing to obtain a Hilbert image data set used to train and verify a convolutional neural network; and finally directly inputting newly obtained test sample data after windowed feature calculation and Hilbert visualization processing into the trained network for fault diagnosis and location. The disclosure uses windowed feature calculation and Hilbert visualization to process the monitoring data of a power equipment to fully extract fault features and effectively improve diagnostic accuracy, and uses the convolutional neural network for diagnosis to improve the intelligence of diagnosis.","['G01R31/00', 'G06V10/82', 'G06F11/0706', 'G06F11/079', 'G06F11/3058', 'G06F11/321', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
CN112889092B,Textured Neural Avatars,"The present invention relates generally to the field of computer vision and computer graphics that produce whole-body rendering of a person for varying body gestures and camera positions, and in particular to a system and method for synthesizing 2D images of a person. The method for synthesizing a 2D image of a person includes: receiving 3D coordinates of a body joint position of the person defined in a camera coordinate system (S101), wherein the 3D coordinates of the body joint position define a pose of the person and a viewpoint of the 2-D image; predicting a body part assigned map stack and a map stack of body part coordinates using a trained machine learning predictor based on 3D coordinates of body joint positions (S102), wherein the map stack of body part coordinates defines texture coordinates of pixels of a body part of a person, the body part assigned map stack defining weights, wherein each weight indicates a probability that a particular pixel belongs to a particular body part of the person; reading a previously initialized map stack of textures of a human body part from a memory (S103), wherein the map stack of textures comprises values of pixels of the human body part; and reconstructing the 2-D image of the person into a weighted combination of values of the pixels by using the map stack of body part assignments, the map stack of body part coordinates, and the map stack of textures (S104). The system for synthesizing a 2D image of a person implements a method for synthesizing a 2D image of a person.","['G06N3/006', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/001', 'G06T13/40', 'G06T15/04', 'G06T15/205', 'G06T17/10', 'G06V40/103', 'G06N3/047']"
US11816609B2,Intelligent task completion detection at a computing device,"Computerized systems and methods are provided for automatically detecting an indication that a task has been completed and associated user interface functionality. These systems and methods improve existing technologies by automatically detecting indications that tasks have been completed via new logic or rules and improving the functionality and computing resource consumption relative to existing machine learning models. These systems also improve the way computers operate by reducing computing resource consumption, such as memory, network latency, I/O, and the like.","['G06F40/284', 'G06Q10/063114', 'G06F3/0482', 'G06F40/289', 'G06F40/30', 'G06N20/00', 'G06Q10/1097', 'H04L51/046']"
CN110276356B,Fundus image microaneurysm identification method based on R-CNN,"An R-CNN architecture-based fundus microaneurysm target detection model for realizing detection and identification of fundus microaneurysm focuses, the method comprises the following steps: preprocessing the fundus image; performing blood vessel segmentation on the preprocessed image; the method comprises the steps of carrying out local self-adaptive threshold segmentation, blood vessel removal and area screening on a preprocessed image to obtain a real microaneurysm candidate region; adopting data enhancement to expand the number of training samples; performing feature extraction on the sample by using a pre-trained VGG16 network by adopting a transfer learning method, and adding a microaneurysm classifier after the feature extraction network for joint training; the scheme provides a new method for detecting the diabetic retina image fundus microaneurysm target.","['G06F18/214', 'G06T7/0012', 'G06T7/136', 'G06V10/20', 'G06V10/267', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/30096', 'G06T2207/30101']"
US20220343178A1,Method and system for performing non-invasive genetic testing using an artificial intelligence (ai) model,"An Artificial Intelligence (AI) based computational system is used to non-invasively estimate the presence of a range of aneuploidies and mosaicism in an image of embryo prior to implantation. Aneuploidies and mosaicism with similar risks of adverse outcomes are grouped and training images are labelled with their group. Separate AI models are trained for each group using the same training dataset and the separate models are then combined, such as by using an Ensemble or Distillation approach to develop a model that can identify a wide range of aneuploidy and mosaicism risks. The AI model for a group is generated by training multiple models including binary models, hierarchical layered models and a multi-class model. In particular the hierarchical layered models are generated by assigning quality labels to images. At each layer the training set is partitioned in the best quality images and other images. The model at that layer is trained on the best quality images, and the other images are passed down to the next layer and the process repeated (so the remaining images are separated into next best quality images and other images). The final model can then be used to non-invasively identify aneuploidy and mosaicism and associated risk of adverse outcomes from an image of an embryo prior to implantation.","['G06T7/0012', 'G06T7/0014', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/126', 'G06N7/01', 'G06V20/69', 'G16H30/40', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30044']"
US12169875B2,"Model training method and apparatus for image recognition, network device, and storage medium","A model training method and apparatus for image recognition, and a non-transitory storage medium are provided. The model training method includes: obtaining a multi-label image training set including a plurality of training images each annotated with a plurality of sample labels; selecting target training images from the multi-label image training set for training a current model; performing label prediction on each target training image using the current model, to obtain a plurality of predicted labels of the each target training image; obtaining a cross-entropy loss function corresponding to the plurality of sample labels of the each target training image, a positive label loss being greater than a negative label loss and having a weight greater than 1; converging the predicted labels and the sample labels of the each target training image according to the cross-entropy loss function, and updating parameters of the current model, to obtain a trained model.","['G06T1/20', 'G06F18/214', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T3/4046', 'G06V10/764', 'G06V10/7753', 'G06V10/82']"
CN114694002B,Infrared target detection method based on feature fusion and attention mechanism,"The invention belongs to the field of computer vision, and discloses an infrared target detection method based on a feature fusion and attention mechanism, which mainly solves the problem of low precision caused by few infrared image features in infrared image target detection in the prior art. The scheme is as follows: 1) Constructing an infrared target detection network of a feature fusion and attention mechanism; 2) Constructing an infrared image dataset; 3) Training an infrared target detection network of a feature fusion and attention mechanism by using the constructed data set to obtain a trained infrared target detection network; 4) And inputting the infrared image to be detected into a trained network for detection labeling, and outputting a detection result of the infrared target. The invention enhances the recognition and positioning infrared capability of the network, ensures the detection speed, improves the detection precision, and is widely applied to the fields of industry, security, traffic and the like.","['G06F18/253', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'Y02T10/40']"
CN111582068B,Method for detecting the wearing status of personnel masks,"The invention provides a method for detecting the wearing state of a mask for a person. The method comprises the following steps: constructing a mask wearing training data set by using a certain number of face images of the worn mask and the face images of the unworn mask, and training an SSD (solid State disk) target detection algorithm by using the mask wearing training data set to obtain a mask wearing detection model; constructing a mask wearing training data set of a monitoring area scene by utilizing a certain number of images of the monitoring area scene, and training the mask wearing detection model by utilizing the mask wearing training data set to obtain a trained mask wearing detection model suitable for the monitoring area scene; inputting the image of the scene of the monitoring area to be detected into a trained mask wearing detection model, and outputting the detection result of the wearing state of the mask of the person in the image. The invention optimizes the aspect ratio and the learning rate of the detection frame of the SSD network, optimizes the mask detection model by using a migration learning method, and combines a Haar cascade classifier, so that the detection accuracy of the wearing state of the mask of a person can reach 98.2%.","['G06V40/165', 'G06F18/23213', 'G06V40/171', 'G06V40/172', 'G06V2201/07', 'Y02T10/40']"
CN111125365B,"Address data labeling method and device, electronic equipment and storage medium","The disclosure provides an address data labeling method, an address data labeling device, electronic equipment and a computer readable storage medium, and belongs to the technical field of data processing. The method comprises the following steps: acquiring an address labeling model, wherein the address labeling model is obtained by pre-training based on unlabeled first sample data and labeled second sample data; splitting an address to be marked into a plurality of characters so as to convert the address to be marked into a character sequence to be marked, wherein the character sequence to be marked is formed by arranging the characters; processing the character sequence to be marked by adopting the address marking model to obtain a marked data sequence; and determining the labeling result of the address to be labeled according to the labeling data sequence. The method and the device can accurately and efficiently label the address data.","['G06F16/355', 'G06F16/387', 'G06N20/00']"
CN111178981B,"Advertisement putting method and device, computer equipment and storage medium","The invention discloses an advertisement putting method, an advertisement putting device, computer equipment and a storage medium, which belong to the field of internet advertisements, wherein the advertisement putting method comprises the following steps: acquiring click rate predicted values, conversion rate predicted values and marginal cost rate predicted values of the current user for each advertisement in the candidate advertisement set through a pre-trained multitask model; calculating thousands of display benefits of each advertisement based on the click rate predicted value, the conversion rate predicted value and the marginal cost rate predicted value of each advertisement and the bid value of each advertisement of the current user; and according to thousands of display benefits of each advertisement, selecting advertisements from the advertisement set and putting the advertisements to the current user. The embodiment of the invention can realize the accurate delivery of advertisements in industries such as financial insurance and the like, and meets the requirement of accurate operation in the advertisement delivery process in the industries such as financial insurance and the like.","['G06Q30/0244', 'G06Q30/0247']"
US10037601B1,Systems and methods for automatic detection of architectural distortion in two dimensional mammographic images,"There is provided a method, comprising: segmenting fibroglandular tissue of a 2D mammographic image of a breast, extracting regions within the segmented fibroglandular tissue and within a boundary portion between the segmented fibroglandular tissue and non-fibroglandular tissue, computing representations for each RoI by a pre-trained deep neural network, training a classifier on the representations to compute a probability score of architectural distortion for each RoI, clustering RoIs defined as positive for architectural distortion using a mean-shift method and providing an indication of the probability of the presence of architectural distortion around a cluster based on the probability distribution of cluster RoI members, removing small clusters having fewer RoI members than a small number threshold, classifying the image as positive for the indication of architectural distortion when at least one cluster remains, or classifying the image as negative for the indication of architectural distortion when no cluster remains.","['G06V10/82', 'A61B6/502', 'A61B6/5258', 'G06F18/2113', 'G06F18/2321', 'G06F18/2413', 'G06F18/2415', 'G06K9/4604', 'G06K9/6226', 'G06K9/623', 'G06K9/6277', 'G06K9/6298', 'G06K9/66', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T5/004', 'G06T5/75', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06T7/136', 'G06V10/25', 'G06V10/267', 'G06V10/454', 'G06V10/764', 'G06F18/23', 'G06F18/2411', 'G06T2207/10116', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068', 'G06T2207/30096', 'G06V2201/03']"
US11132988B1,"Dialogue system, a dialogue method, and a method of training","A computer implemented method comprising: receiving input data relating to a speech or text signal originating from a user; representing the input data as a first sequence of first representations, each representing a unit of the input data; representing the input data as a second sequence of second representations, each representing one of the units of the input data; using a model to determine a tag sequence from the first sequence of first representations, wherein the model comprises an attention layer using the second sequence of second representations, wherein the tag sequence comprises one or more tags from a set of tags comprising a first tag; if one or more units of the input data correspond to the first tag, determining a system dialogue act based on the part of the input data corresponding to the first tag; and outputting speech or text information specified by the determined dialogue act.","['G06F40/35', 'G06F18/2415', 'G06K9/6277', 'G10L15/063', 'G10L15/083', 'G10L15/22', 'G10L2015/0631', 'G10L2015/223']"
CN111104512B,Game comment processing method and related equipment,"The embodiment of the disclosure provides a game comment processing method and related equipment, and belongs to the technical field of computers. The method comprises the following steps: obtaining annotation data obtained by annotating the game comments, wherein the annotation data comprises the game comments and annotation categories thereof; processing the game comments in the annotation data through a pre-training model to obtain semantic expression vectors of the game comments; the pre-training model is obtained by pre-training the unmarked game comments; processing the semantic expression vector of the game comment through a full connection layer to obtain the probability of the target category of the game comment; determining a predicted category of the game comment according to the probability of the target category of the game comment; and training the pre-training model and the full connection layer according to the labeling category and the prediction category to obtain a game comment classification model.",['G06F16/35']
US10318889B2,Targeted data augmentation using neural style transfer,"A method for training a deep neural network (DNN) to perform a specified task with respect to images captured by a target camera, including: using an image captured by the target camera as a style target image, training a style transformer network to perform a style transformation that transforms any photorealistic input image into a transformed image that has contents of the input image, maintains photorealistic quality of the input image, and has a style that matches a style of the style target image; using the trained style transformer network to transform training image of an original training dataset into transformed training images; labeling the transformed training images with the training labels of the corresponding training image of the original training dataset, to form an augmented training dataset; and using the augmented training dataset to train the DNN to perform the specified task.","['G06N20/00', 'G06F18/214', 'G06K9/00765', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T11/60', 'G06V10/774', 'G06V20/49', 'G06T11/001', 'G06T3/0006', 'G06T3/02']"
US11386302B2,Systems and methods for contrastive learning of visual representations,"Systems, methods, and computer program products for performing semi-supervised contrastive learning of visual representations are provided. For example, the present disclosure provides systems and methods that leverage particular data augmentation schemes and a learnable nonlinear transformation between the representation and the contrastive loss to provide improved visual representations. Further, the present disclosure also provides improvements for semi-supervised contrastive learning. For example, computer-implemented method may include performing semi-supervised contrastive learning based on a set of one or more unlabeled training data, generating an image classification model based on a portion of a plurality of layers in a projection head neural network used in performing the contrastive learning, performing fine-tuning of the image classification model based on a set of one or more labeled training data, and after performing the fine-tuning, distilling the image classification model to a student model comprising a relatively smaller number of parameters than the image classification model.","['G06K9/6263', 'G06N3/084', 'G06F18/2155', 'G06F18/2178', 'G06F18/241', 'G06K9/6259', 'G06K9/6268', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/7753', 'G06V10/7788', 'G06T2207/20081']"
US12272148B2,Scalable semantic image retrieval with deep template matching,"Approaches presented herein provide for semantic data matching, as may be useful for selecting data from a large unlabeled dataset to train a neural network. For an object detection use case, such a process can identify images within an unlabeled set even when an object of interest represents a relatively small portion of an image or there are many other objects in the image. A query image can be processed to extract image features or feature maps from only one or more regions of interest in that image, as may correspond to objects of interest. These features are compared with images in an unlabeled dataset, with similarity scores being calculated between the features of the region(s) of interest and individual images in the unlabeled set. One or more highest scored images can be selected as training images showing objects that are semantically similar to the object in the query image.","['G06F16/583', 'G06V20/56', 'G06N3/088', 'G06F18/2113', 'G06F18/2155', 'G06F18/22', 'G06N3/02', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N5/04', 'G06V10/759', 'G06V10/774', 'G06V10/82', 'G06V30/274', 'G06N20/00', 'G06N3/045']"
US10496898B2,State detection using machine-learning model trained on simulated image data,"A set of virtual images can be generated based on one or more real images and target rendering specifications, such that the set of virtual images correspond to (for example) different rendering specifications (or combinations thereof) than do the real images. An image style can be transferred to the at least some of the virtual images of the set of virtual images to generate a stylized virtual image. A machine-learning model can be trained using a plurality of stylized virtual images. Another real image can then be processed using the trained machine-learning model. The processing can include segmenting the other real image to detect whether and/or which objects are represented (and/or a state of the object). The object data can then be used to identify (for example) a state of a procedure.","['G06K9/6256', 'G06N3/08', 'A61B34/10', 'G06F18/214', 'G06F18/217', 'G06F18/2413', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/20', 'A61B2034/101', 'A61B2034/102', 'A61B2034/104', 'A61B2034/105', 'A61B2090/365', 'A61B2090/502', 'G06K2209/057', 'G06V2201/034']"
US11334764B2,Real-time detection method and apparatus for DGA domain name,"A real-time detection method and apparatus for DGA domain name. An original domain name is translated into a multi-dimensional numeric vector, the multi-dimensional numeric vector is input into a deep learning model pre-trained based on an ImageNet data set, to generate a domain name feature, a domain name classifier is trained based on the generated domain name feature, and a DGA domain name is classified and predicted based on the domain name classifier obtained by training. The method firstly uses a deep learning model pre-trained based on an ImageNet data set, from the field of visual image classification and detection, for real-time detection of a DGA domain name, avoiding the process of high-intensity training and parameter weight adjustment for the deep learning model in DGA domain name detection. The detection rate is higher, and detection speed is faster.","['G06K9/6257', 'G06N20/00', 'G06F18/2148', 'G06F18/2411', 'G06F18/2413', 'G06F18/24323', 'G06K9/6269', 'G06K9/6282', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/75', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'H04L61/00', 'G06N3/045']"
CN110310206B,Method and system for updating risk control model,"The present disclosure provides a method for efficiently updating a risk control model, comprising: monitoring performance changes of the risk control model and changes in the input data; when the risk control model has performance change, re-fitting the risk control model to obtain a re-fitted risk control model; retraining the risk control model to obtain a retrained risk control model when there is a change in input data of the risk control model; updating the re-fitted risk control model or the re-trained risk control model by incremental learning with the streaming data; using the risk control model as an online model, and using the updated re-fitted risk control model and the re-trained risk control model as a backup model; and replacing the on-line model with the backup model when one of the backup models is better than the on-line model.",['G06Q40/04']
US10565433B2,Age invariant face recognition using convolutional neural networks and set distances,"Time lapse, characteristic of aging, is a complex process that affects the reliability and security of biometric face recognition systems. Systems and methods use deep learning, in general, and convolutional neural networks (CNN), in particular, for automatic rather than hand-crafted feature extraction for robust face recognition across time lapse. A CNN architecture using the VGG-Face deep (neural network) learning produces highly discriminative and interoperable features that are robust to aging variations even across a mix of biometric datasets. The features extracted show high inter-class and low intra-class variability leading to low generalization errors on aging datasets using ensembles of subspace discriminant classifiers.","['G06K9/00288', 'G06N3/08', 'G06F18/24133', 'G06F21/32', 'G06K9/00228', 'G06K9/00281', 'G06K9/00926', 'G06K9/4628', 'G06K9/6271', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V40/161', 'G06V40/171', 'G06V40/172', 'G06V40/50']"
US11419499B2,Optical coherence tomography for cancer screening and triage,A device for cancer screening and triage using an optical coherence tomography (OCT) imaging system integrated with optical imaging probe is provided. Endoscopic OCT images are generated using the OCT system having a helical probe. The images are further analyzed to generate a depth resolved intensity OCT signal to classify the region of tissue into variable grades of dysplasia to guide the physician's biopsy or resection.,"['A61B5/0066', 'A61B5/0088', 'A61B5/4552', 'A61B5/7267', 'G01B9/0205', 'G01B9/02091', 'G06K9/00', 'G06T7/0012', 'G06T7/13', 'G06T7/50', 'G06V10/764', 'G06V10/82', 'G06T2207/10068', 'G06T2207/20084', 'G06T2207/30108', 'G06V2201/03', 'G16H50/70']"
CN111460833B,"Text generation method, device and equipment","The invention discloses a text generation method, a text generation device and text generation equipment. The core concept of the invention is to provide a text generation scheme based on attribute generation, attribute matching and attribute adjustment, in particular to obtain a target attribute according to a received attribute description statement and a preset attribute generation strategy; generating a text according to the words by using a language model; after each word is generated, extracting attributes of all generated texts, and matching with the target attributes; and adjusting the historical state information of the language model according to the matching result to generate the next word. The method has the advantages that the representation mode of the target attribute is improved by using the generated strategy, the attribute is expandable, the multi-attribute controllability is supported, the historical state information of the language model is modified through attribute matching and attribute control, the direction of the text attribute is finely controlled, the quality of the generated text is improved, and in addition, the smoothness of the generated text can be improved without excessive modification of the language model.","['G06F18/253', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
US20230274420A1,Method and system for automated generation of text captions from medical images,"Computer implemented method for generating captions for medical images and/or clinical reports are provided. The methods comprise obtaining one or more medical images; using an image processing component to process the one or more images, wherein the image processing component comprises a deep learning model that takes as input the one or more medical images and produces as an output an image feature tensor; and using a natural language processing component to generate a caption for the one or more medical images, wherein the natural language processing component comprises a transformer-based model that takes as input the image feature tensor from the image processing component and produces as output a probability for each word in a vocabulary. Related systems and products are also described.","['G16H50/20', 'G06F40/169', 'G06T7/0012', 'G06F40/30', 'G06F40/56', 'G06N3/045', 'G06N3/08', 'G06V10/469', 'G06V10/761', 'G16H15/00', 'G16H30/40', 'G06N3/0455', 'G06N3/0464', 'G06N3/0499', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
CN113096723B,Construction platform for universal molecular library for screening small molecular drugs,"A small molecule drug screening universal molecular library construction platform comprises a molecular generation module: pre-training on the basis of a compound library, performing directional exploration and optimization on a chemical space through target molecules and an activity prediction model, determining a parent nucleus according to the structure of an active molecule, cutting a side chain, performing migration learning on the cut side chain to generate the side chain, splicing the generated side chain to the parent nucleus to generate a drug-like small molecule with bioactivity, or generating a new small molecule structure based on the structure of the whole reference molecule, performing drug screening, and recommending the drug-like small molecule to the molecular library; commercial library and public molecular library module: invoking a commercial library or a public molecular library, setting conditions for searching and filtering, screening target points and indication types, and recommending the target points and indication types to the molecular library after drug screening; the platform combines a commercial library and a public molecular library through a molecular generation technology and the like, constructs a directional molecular library of small molecular drugs according to target information, and is more in line with the characteristics of a ligand structure of a specific target.","['G16B15/30', 'G16B40/00', 'G16C20/40', 'G16C20/50', 'G16C20/64', 'G16C20/70', 'Y02A90/10']"
CN111640125B,Aerial photography graph building detection and segmentation method and device based on Mask R-CNN,"The invention relates to the technical field of artificial intelligence detection, in particular to a method and a device for detecting and segmenting an aerial photography graph building based on Mask R-CNN, wherein the method comprises the steps of firstly obtaining an aerial photography image of a town building, labeling the outline of a building object in the aerial photography image, establishing a training set and a test set data, and enhancing the training data set by utilizing a non-random covering data enhancement mode; constructing an aerial photo building detection and segmentation network; training the network by using a training data set, and testing and evaluating the performance of the trained segmentation model by using test set data to obtain a final aerial photography graph building segmentation model; and applying the obtained model to the building aerial photography image which needs to be processed by a user to obtain a final building aerial photography image segmentation image. The invention uses the deep learning method to improve the speed and the efficiency, and applies the data enhancement method of the transfer learning and the non-random covering to improve the segmentation accuracy and the robustness of the model.","['G06T7/11', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30181']"
US12412340B2,Synthesizing three-dimensional shapes using latent diffusion models in content generation systems and applications,"Approaches presented herein provide for the unconditional generation of novel three dimensional (3D) object shape representations, such as point clouds or meshes. In at least one embodiment, a first denoising diffusion model (DDM) can be trained to synthesize a 1D shape latent from Gaussian noise, and a second DDM can be trained to generate a set of latent points conditioned on this 1D shape latent. The shape latent and set of latent points can be provided to a decoder to generate a 3D point cloud representative of a random object from among the object classes on which the models were trained. A surface reconstruction process may be used to generate a surface mesh from this generated point cloud. Such an approach can scale to complex and/or multimodal distributions, and can be highly flexible as it can be adapted to various tasks such as multimodal voxel- or text-guided synthesis.","['G06T19/20', 'G06T17/20', 'G06V10/44', 'G06V10/82', 'G06V20/64', 'G06T2210/56', 'G06T2219/2021']"
US11494976B2,Neural rendering for inverse graphics generation,"Approaches are presented for training an inverse graphics network. An image synthesis network can generate training data for an inverse graphics network. In turn, the inverse graphics network can teach the synthesis network about the physical three-dimensional (3D) controls. Such an approach can provide for accurate 3D reconstruction of objects from 2D images using the trained inverse graphics network, while requiring little annotation of the provided training data. Such an approach can extract and disentangle 3D knowledge learned by generative models by utilizing differentiable renderers, enabling a disentangled generative model to function as a controllable 3D “neural renderer,” complementing traditional graphics renderers.","['G06T17/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T15/10']"
US20230377099A1,Synthesizing content using diffusion models in content generation systems and applications,"Approaches presented herein provide for the generation of synthesized data from input noise using a denoising diffusion network. A higher order differential equation solver can be used for the denoising process, with one or more higher-order terms being distilled into one or more separate efficient neural networks. A separate, efficient neural network can be called together with a primary denoising model at inference time without significant loss in sampling efficiency. The separate neural network can provide information about the curvature (or other higher-order term) of the differential equation, representing a denoising trajectory, that can be used by the primary diffusion network to denoise the image using fewer denoising iterations.","['G06T5/002', 'G06T5/70', 'G06N3/042', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/096', 'G06T11/00', 'G06T5/60', 'G06T7/64', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
WO2023071743A1,"Network model training method and apparatus, and computer-readable storage medium","The present application discloses a network model training method and apparatus, and a computer-readable storage medium. Self-supervised pretraining, domain data fine-tuning, and knowledge distillation are sequentially performed on a pretrained model. For example, unsupervised pretraining is performed on a super-large neural network model using massive data, the pretrained model is fine-tuned using limited labeled samples, and the fine-tuned super-large model is compressed by means of knowledge distillation into a target model so as to meet deployment requirements of a target device.","['G06N3/045', 'G06F18/214', 'G06N3/084']"
WO2021109671A1,Fine-granularity sentiment analysis method supporting cross-language transfer,"A fine-granularity sentiment analysis method that supports cross-language transfer, the method comprising the following steps: performing random sampling on e-commerce review text and performing manual annotation on the sampled text to obtain a topic sentiment annotation data set of the text; inputting the annotation data set into a semantic-long and short-term memory network for training to obtain a semantic group of the text; training the obtained semantic group and the sampled text together by means of an aspect-based sentiment model to obtain topic features of the text; training the annotation data set and the topic features by means of a fine-tuning network to obtain an embedding vector of the sampled text; and performing feature fusion on the embedding vector and the topic features to obtain a sentiment classification result of the text. The described method takes into account the asymmetry of polarity distribution, aspect sparsity and uneven distribution of sentiment words in product reviews, improves the accuracy of sentiment analysis, and may be widely used in the field of text data mining.","['G06F18/24', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
US20230244938A1,Using Chains of Thought to Prompt Machine-Learned Models Pre-Trained on Diversified Objectives,"An example method for pretraining a machine-learned model is provided. The example method includes obtaining a plurality of different combinations of configuration parameters of a pretraining objective framework. The example method includes generating, using the pretraining objective framework, a plurality of corrupted training examples from one or more training examples, wherein the plurality of corrupted training examples are respectively generated according to the plurality of different combinations. The example method includes inputting the plurality of corrupted training examples into the machine-learned model, wherein the machine-learned model is configured to generate uncorrupted subportions corresponding to corrupted subportions of the corrupted training examples. The example method includes obtaining, from the machine-learned model, a plurality of outputs respectively generated by the machine-learned model based on the plurality of corrupted training examples. The example method includes updating one or more parameters of the machine-learned model based on an evaluation of the plurality of outputs.","['G06N3/08', 'G06N3/044', 'G06N3/045', 'G06N5/022', 'G06N20/00']"
CN109300530B,Pathological picture recognition method and device,"The invention discloses a pathological picture identification method and a pathological picture identification device, wherein the method comprises the following steps: acquiring a pathological picture to be identified; inputting the pathological picture to be recognized into a plurality of different types of deep neural network models generated by pre-training, recognizing the pathological picture to be recognized, and obtaining a preliminary recognition result by each type of deep neural network model; the method comprises the following steps that a plurality of deep neural network models of different types are generated according to pre-training of a plurality of pathological image samples; and fusing the primary recognition results obtained by the deep neural network models of different types to obtain the final recognition result of the pathological picture to be recognized. According to the technical scheme, the efficiency and the accuracy of pathological picture identification are improved.","['G16H30/20', 'G16H50/20']"
CA3039551C,Training a joint many-task neural network model using successive regularization,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.","['G06N3/04', 'G06N3/084', 'G06F40/205', 'G06F40/216', 'G06F40/253', 'G06F40/284', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06F40/00', 'G10L15/16', 'G10L15/18', 'G10L25/30']"
US20210307673A1,System and method for early and efficient prediction of epilectic seizures,"A seizure prediction algorithm based on deep learning that integrates the feature extraction and classification processes into a single automated architecture is claimed herein. In the method, the computation complexity is reduced because there is no feature engineering. The method uses a novel algorithm for EEG channel selection in which the number of EEG channels is decreased to reduce the required memory for storing the data and parameters. In one or more embodiments, an IoT based framework for accurate epileptic seizure prediction system is disclosed.","['A61B5/4094', 'A61B5/291', 'A61B5/369', 'A61B5/7264', 'A61B5/31']"
US11587551B2,Leveraging unpaired text data for training end-to-end spoken language understanding systems,"An illustrative embodiment includes a method for training an end-to-end (E2E) spoken language understanding (SLU) system. The method includes receiving a training corpus comprising a set of text classified using one or more sets of semantic labels but unpaired with speech and using the set of unpaired text to train the E2E SLU system to classify speech using at least one of the one or more sets of semantic labels. The method may include training a text-to-intent model using the set of unpaired text; and training a speech-to-intent model using the text-to-intent model. Alternatively or additionally, the method may include using a text-to-speech (TTS) system to generate synthetic speech from the unpaired text; and training the E2E SLU system using the synthetic speech.","['G10L15/063', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G10L15/005', 'G10L15/16', 'G10L15/1822', 'G10L15/26', 'G10L13/00']"
US10839606B2,Indoor scene structural estimation system and estimation method thereof based on deep learning network,"An indoor scene structural estimation system and an estimation method based on deep learning network are provided. An indoor scene structural estimation system based on deep learning network includes a 2D encoder, a 2D plane decoder, a 2D edge decoder, a 2D corner decoder, and a 3D encoder. The 2D encoder receives an input image and encodes the input image. The 2D plane decoder is connected to the 2D encoder, decodes the encoded input image, and generates a 2D plane segment layout image. The 2D plane decoder is connected to the 2D encoder, decodes the encoded input image, and generates a 2D plane segment layout image. The 2D corner decoder is connected to 2D encoder, decodes the encoded input image, and generates a 2D corner layout image.","['G06T17/00', 'G06K9/00691', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T19/006', 'G06T7/12', 'G06T7/50', 'G06V10/764', 'G06V10/82', 'G06V20/36', 'G06N3/048', 'G06T2207/20084', 'G06T2210/04']"
US11416716B2,System and method for automatic assessment of cancer,"Cancer can be an aggressive disease. It is critical to determine the most effective patient-specific treatment quickly. Exemplary embodiments use a data-driven approach to extracting tumor information from data obtain from Whole Slide Image that is uploaded through an interface. Exemplary embodiments generate the following information about a tumor from a biopsy slide using neural networks: annotated areas of relevant tissues, molecular subtype, and expression status of an important gene and include three steps: the segmentation of tumor features; prediction of molecular subtype; and prediction of gene methylation status from a WSI.","['G06K9/6267', 'G06V10/82', 'G06F18/24', 'G06F18/2411', 'G06F18/2414', 'G06F18/24147', 'G06F18/24155', 'G06K9/6269', 'G06K9/6273', 'G06K9/6276', 'G06K9/6278', 'G06T7/0012', 'G06V10/454', 'G06V20/698', 'G06V30/19173', 'G06V30/194', 'G16B20/00', 'G16B25/00', 'G16B40/00', 'G16B40/20', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30024', 'G06T2207/30096']"
CN110490802B,Super-resolution-based satellite image airplane target model identification method,"The invention discloses a satellite image airplane target model identification method based on super-resolution, which comprises the following steps: performing super-resolution reconstruction on the acquired satellite image to obtain a super-resolution reconstruction image; performing regional screening network processing on the super-resolution reconstructed image to obtain a candidate frame image; inputting the candidate frame images into a pre-trained super-resolution reconstruction target recognition network for target recognition to obtain a target recognition result; the super-resolution reconstruction target recognition network is obtained by alternately training a super-resolution countermeasure generation network and a classification recognition network and continuously optimizing by using an incremental learning method. The super-resolution countermeasure generation network and the classification recognition network are alternately trained, and the incremental learning thought is utilized to continuously optimize the recognition model, so that the target recognition network with strong generalization capability is obtained, and the application range and the recognition accuracy of the recognition network are improved.","['G06F18/241', 'G06T3/4053', 'G06V20/13']"
CN111652066B,Medical behavior identification method based on multi-self-attention mechanism deep learning,"The invention relates to a medical behavior identification method based on multi-self-attention mechanism deep learning, which comprises the following steps of: the video is sampled frame by frame and decomposed into several video units and stacked in the time dimension as a time sequence of a certain size. Extracting single-frame images in the sequence as input of a convolutional neural network to obtain the characteristics of video units, and stacking the characteristics into the sequence; then inputting the characteristics of the sequence into a recurrent neural network to capture the characteristics of the sequence in a time dimension; inputting the time characteristics into a multi-head attention model, extracting non-local time characteristics, and fully fusing the information of the whole sequence; and finally, obtaining the human body action category prediction through the full connection layer.","['G06V40/10', 'G06F18/241', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06V40/20']"
CN109711557B,"A driving trajectory prediction method, computer equipment and storage medium","The invention relates to the field of driving management, in particular to a driving track prediction method, computer equipment and a storage medium, wherein the method comprises the following steps: acquiring a driver image and vehicle driving data; identifying the driver image through a driver state identification model to obtain the current driving state data of the driver; processing the current driving state data of the driver through a driving strategy prediction model to obtain the driving strategy data of the current state of the driver; and processing the current vehicle state data and the current state driving strategy data of the driver through a driving track prediction model to obtain future driving track information adaptive to the current state of the driver. The invention realizes the training of the driver state recognition model by adopting transfer learning, and has high recognition accuracy and strong generalization capability; the driving tracks of the driver in different states can be predicted through the driving strategy, and the track prediction is more accurate.",[]
US10977551B2,Hybrid reward architecture for reinforcement learning,"Aspects provided herein are relevant to machine learning techniques, including decomposing single-agent reinforcement learning problems into simpler problems addressed by multiple agents. Actions proposed by the multiple agents are then aggregated using an aggregator, which selects an action to take with respect to an environment. Aspects provided herein are also relevant to a hybrid reward model.","['G06N3/08', 'G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/092', 'G06N3/096', 'G06N5/043', 'G06N7/005', 'G06N7/01']"
US12230040B2,Robust state estimation,"State information can be determined for a subject that is robust to different inputs or conditions. For drowsiness, facial landmarks can be determined from captured image data and used to determine a set of blink parameters. These parameters can be used, such as with a temporal network, to estimate a state (e.g., drowsiness) of the subject. To improve robustness, an eye state determination network can determine eye state from the image data, without reliance on intermediate landmarks, that can be used, such as with another temporal network, to estimate the state of the subject. A weighted combination of these values can be used to determine an overall state of the subject. To improve accuracy, individual behavior patterns and context information can be utilized to account for variations in the data due to subject variation or current context rather than changes in state.","['B60W40/08', 'G06F18/21', 'G06N3/045', 'G06V20/597', 'G06V40/16', 'G06V40/161', 'G06V40/171', 'G06V40/172', 'G06V40/18', 'B60W2540/229', 'G06N3/0442', 'G06N3/084', 'G06N3/09']"
CN113569001B,"Text processing method, device, computer equipment and computer readable storage medium","The embodiment of the application provides a text processing method, a device, computer equipment and a computer readable storage medium, wherein the text processing method is based on an artificial intelligence technology and comprises the steps of obtaining a text to be processed, wherein the text to be processed comprises a text title, a text keyword and a text body, inputting the text to be processed into a long text recognition model for processing to obtain a target result, wherein the target result is used for indicating the practicability class of the text to be processed, the long text recognition model is obtained by pre-training an initial text recognition model by using first text data and then fine-tuning the pre-trained text recognition model by using second text data, the first text data comprises an incomplete text body, and the second text data comprises a sample text title, a sample text keyword, a sample text body and a corresponding reference practicability class label. The embodiment of the application can effectively improve the accuracy and the robustness of the practical identification of the chapter-level long text.","['G06F16/3331', 'G06F16/35', 'G06F40/289']"
US20230135659A1,Neural networks trained using event occurrences,"Apparatuses, systems, and techniques to facilitate financial natural language processing (NLP) training and tasks, such as sentiment analysis, machine reading comprehension, question answering, and causal inferencing. In at least one embodiment, training of one or more neural networks comprises a bidirectional encoder representations from transformers (BERT) machine learning model and input data further comprising timestamps of financial news articles.","['G06N3/08', 'G06Q40/06', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N5/04']"
CN113569667B,Inland ship target identification method and system based on lightweight neural network model,"The invention discloses a inland ship target identification method and system based on a lightweight neural network model, wherein the method comprises the following steps: s1, constructing a lightweight neural network model, and compressing a MobileNet 3 Largen network in a feature extraction network part to obtain a feature extraction network; on the algorithm prediction structure, utilizing a feature pyramid structure to perform multi-convolution layer feature fusion; and performing loss calculation by using a loss function fused with the distance measurement index; s2, screening and sorting inland ship images to form inland ship image data sets, and dividing training sets and test sets; s3, training the constructed lightweight neural network model; s4, identifying the inland ship targets by using the trained model. The method effectively improves the image target recognition precision of the inland ship, reduces the dependence of ship recognition on the calculation performance of hardware equipment, and effectively improves the processing capability of the inland environment ship video monitoring information.","['G06F18/214', 'G06F18/24', 'G06F18/253', 'G06N3/045']"
US11775812B2,Multi-task based lifelong learning,"Methods, devices, and computer-readable media for multi-task based lifelong learning. A method for lifelong learning includes identifying a new task for a machine learning model to perform. The machine learning model trained to perform an existing task. The method includes adaptively training a network architecture of the machine learning model to generate an adapted machine learning model based on incorporating inherent correlations between the new task and the existing task. The method further includes using the adapted machine learning model to perform both the existing task and the new task.","['G06N3/08', 'G06N3/044', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N3/0985']"
US11256952B2,Image privacy perception method based on deep learning,"An image privacy perception method based on deep learning, including the following steps: S1, building a privacy classification data set with labeled categories, and training a privacy perception network with a transfer learning method; S2, recognizing a privacy image using a deep convolutional neural network oriented to privacy perception; and S3, extracting an attention profile according to deep convolutional features of the neural network, and locating an attention focusing region to complete the perception of an image privacy region. The method has the following beneficial effects: by completing end-to-end training and testing based on the deep neural network, the privacy image can be accurately distinguished with the privacy region located, facilitating the selective protection of the privacy information in the image.","['G06N3/08', 'G06K9/6228', 'G06F18/24', 'G06F18/211', 'G06F18/214', 'G06F18/2148', 'G06F18/253', 'G06F21/6245', 'G06K9/38', 'G06K9/6232', 'G06K9/6257', 'G06K9/6267', 'G06K9/629', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06N3/045']"
CN114494195B,Small sample attention mechanism parallel twin method for fundus image classification,"The invention provides a small sample attention mechanism parallel twin method for fundus image classification, which classifies fundus lesion images of a patient to obtain classification results, and comprises the following steps: reading a medical fundus image dataset for preprocessing to obtain preprocessed picture data; by means of a few shots learning method based on a twin network Siamese, a dense connection network densenet which is pre-trained by using a dataset ImageNet is migrated by means of a feature-based migration learning method to extract features of two different images, a convolution block attention module CBAM is added on the basis of the network to select more critical image information, and similarity measurement of pictures is carried out through a comparison loss function, so that more accurate classification prediction results are obtained. The invention migrates a dense connection network, can effectively reduce the situation of overfitting in the study of small samples, and simultaneously effectively improves the efficiency and the accuracy of medical fundus image lesion classification data by means of CBAM attention mechanisms and a twin network.","['G06T7/0012', 'G06F18/214', 'G06F18/22', 'G06F18/2414', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06T3/4046', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'Y02T10/40']"
US20230320642A1,"Systems and methods for techniques to process, analyze and model interactive verbal data for multiple individuals","Disclosed are methods, systems, and other implementations for processing, analyzing, and modelling psychotherapy data. The implementations include a method for analyzing psychotherapy data that includes obtaining transcript data representative of spoken dialog in one or more psychotherapy sessions conducted between a patient and a therapist, extracting speech segments from the transcript data related to one or more of the patient or the therapist, applying a trained machine learning topic model process to the extracted speech segments to determine weighted topic labels representative of semantic psychiatric content of the extracted speech segments, and processing the weighted topic labels to derive a psychiatric assessment for the patient.","['A61B5/165', 'A61B5/4803', 'A61B5/7267', 'G06F40/279', 'G06F40/30', 'G10L15/063', 'G10L15/26', 'G10L17/02', 'G10L17/04', 'G10L17/14', 'G10L17/18', 'G10L17/22', 'G10L21/028', 'G10L25/66', 'G16H10/20', 'G16H20/70', 'G16H50/20', 'G10L21/0272']"
US10489918B1,Video object tracking,"A technique is disclosed for automating tracking of annotated objects and improves the throughput and efficiency of existing methods while maintaining a degree of accuracy comparable to a human annotator. In particular, the disclosed technique provides an automated annotated object tracking tool that allows machine-learning teams to annotate an object within a frame and have that annotation persist across frames as the annotated object is tracked within a series of frames, still ensuring that every frame is accurately reviewed by a human where high quality annotation is required. This technique incorporates human feedback via a user adjustment that allows the tool to adapt and improve its accuracy in tracking an annotated object across a sequence of frames.","['G06T7/246', 'G06T7/20', 'G06T7/70', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20104', 'G06T2207/30196', 'G06T2207/30232', 'G06T2207/30236']"
CN111985240B,"Named entity recognition model training method, named entity recognition method and named entity recognition device","The application discloses a training method of a named entity recognition model, a named entity recognition method and a named entity recognition device, relates to natural language processing of artificial intelligence, and is suitable for the medical field. The method comprises the following steps: invoking a first NER model to identify a first unlabeled dataset to obtain a first model identification result set; invoking a second NER model to identify the first unlabeled dataset to obtain a second model identification result set; correcting the first model recognition result set according to the second model recognition result set to obtain a third model recognition result set; training and updating the first NER model according to the third model identification result set; and calling the updated first NER model to identify the second unlabeled data set to obtain a first updated identification result set, and updating a dictionary of the second NER model according to the first updated identification result set. The method can save the labor cost of model training and improve the model training efficiency.","['G06F40/295', 'G06F40/205', 'G06F40/242']"
CN113762322B,"Video classification method, device and equipment based on multi-modal representation and storage medium","The application discloses a video classification method, device and equipment based on multi-mode representation and a storage medium, relates to the technical field of artificial intelligence, and is used for reducing difficulty of model learning and improving model training efficiency. The method comprises the following steps: inputting data information of each mode of the target video into a trained target multi-mode video representation model; obtaining a video service class of a target video output by a target multi-mode video representation model in a target service scene; the target multi-mode video representation model is obtained by performing adaptive pre-training of a video domain based on basic video data sample sets corresponding to each mode, and retraining based on video service data sample sets corresponding to each mode in a target service scene, wherein each basic video data sample set comprises basic video data samples corresponding to the same mode of each video, and each video service data sample set comprises video service data samples corresponding to the same mode of each video.","['G06F18/24', 'G06F18/214']"
US20230245651A1,Enabling user-centered and contextually relevant interaction,An approach is disclosed for enabling contextually relevant conversational interaction. Environment data is received by an AI System which detects a plurality of physical objects in a physical environment and forms a contextual understanding of the plurality of physical objects and the physical environment and identifies a user relevant to the contextual understanding. A most relevant contextual information to the user is predicted by the AI system and transformed into a textual form. A set of intents and objectives is predicted by the AI system for user-centered interaction. The AI system and the user interact iteratively through the user-centered interaction to determine an understanding of a most relevant intent and a most relevant objective which is validated by the AI system with the user until the user agrees. The validated most relevant intent and the most relevant objective is utilized to facilitate the user-centered and contextually relevant conversational interaction.,"['G06N5/022', 'G06F3/011', 'G06F3/167', 'G06F40/30', 'G10L13/027', 'G10L15/1815', 'G10L15/22', 'G06F2203/011', 'G06F40/35', 'G06N10/60', 'G06N20/10', 'G06N3/045', 'G10L2015/223', 'G10L2015/226', 'G10L25/63']"
US20230181121A1,Systems and methods to predict and manage post-surgical recovery,"The present invention relates to systems and methods to manage and predict post-surgical recovery. More specifically, the disclosure generally relates to systems and methods for post-surgical intervention planning, support, follow-up, patient compliance, recovery prediction and tracking, and potential treatment modifications.","['A61B5/7275', 'A61B5/02', 'A61B5/0205', 'A61B5/265', 'A61B5/726', 'A61B5/7267', 'A61B7/00', 'G16H10/20', 'G16H40/20', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H80/00', 'A61B2505/05', 'A61B2562/0285', 'A61B5/086', 'A61B5/1118', 'A61B5/318', 'A61B5/4561', 'G16H10/60']"
US12361215B2,Performing machine learning tasks using instruction-tuned neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing a machine learning task on an input to generate an output. In one aspect, one of the method includes receiving input data that describes an input of a machine learning task; receiving candidate output data that describes a set of candidate classification outputs of the machine learning task for the input; generating an input sequence that includes the input and the set of candidate classification outputs; processing the input sequence using a neural network to generate a network output that specifies a respective score for each candidate classification output in the set of candidate classification outputs; and generating an output of the machine learning task for the input, comprising selecting, as the output, a selected candidate classification output from the set of candidate classification outputs using the respective scores.","['G06F40/284', 'G06F40/30', 'G06N3/096', 'G06N3/0455', 'G06N3/084', 'G06N3/0895']"
CN107316015B,High-precision facial expression recognition method based on deep space-time characteristics,"The invention discloses a high-precision facial expression recognition method based on depth space-time characteristics, which comprises the steps of firstly designing an end-to-end trainable multi-channel depth neural network model, respectively extracting the depth space-time characteristics of a facial expression image by utilizing a plurality of parallel depth neural networks at a lower layer, then fusing multi-channel depth space-time characteristic data by using a full connection layer at a higher layer, and recognizing by adopting a softmax layer at a highest layer to obtain expression classification. The model integrates image feature extraction and feature fusion into a network capable of carrying out global training, thereby deepening the network scale and improving the recognition performance. The second innovation point is that the average face is used for replacing a neutral face, and the method solves the problem that the expression image lacks a corresponding neutral face image during testing, so that the method can meet the application requirements of practical occasions. The invention provides a new idea in the field of expression recognition, and has high practical value and development prospect.","['G06V40/174', 'G06F18/2414', 'G06N3/045', 'G06N3/08', 'G06T7/33']"
US20210104021A1,Method and apparatus for processing image noise,"Disclosed are an image noise processing method and apparatus. The image noise processing method includes inputting a target image including a low light level noise, estimating a noise level, and a selective processing of the target image by a denoising sub-network corresponding to the noise level. According to the present disclosure, it is possible to selectively apply a denoising neural network through a 5G network on the basis of an estimation of a noise level.","['G06T5/002', 'G06T5/70', 'G06N3/045', 'G06N3/08', 'G06T5/20', 'G06T5/60', 'G06T7/11', 'G06N20/10', 'G06N3/006', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084']"
US20220122689A1,Systems and methods for alignment-based pre-training of protein prediction models,"Embodiments described herein provide an alignment-based pre-training mechanism for protein prediction. Specifically, the protein prediction model takes as input features derived from multiple sequence alignments (MSAs), which cluster proteins with related sequences. Features derived from MSAs, such as position specific scoring matrices and hidden Markov model (HMM) profiles, have long known to be useful features for predicting the structure of a protein. Thus, in order to predict profiles derived from MSAs from a single protein in the alignment, the neural network learns information about that protein's structure using HMM profiles derived from MSAs as labels during pre-training (rather than as input features in a downstream task).","['G16B5/20', 'G16B40/20', 'G16B30/10']"
CN114970721B,"Training method, device and electronic device for multi-language multi-modal pre-training model","The disclosure relates to a training method and device for a multi-language multi-mode pre-training model and electronic equipment, and particularly relates to the technical field of machine learning. The method comprises the steps of obtaining a pairing sample set, wherein the pairing sample set comprises image-text pairing data of an image and a target text and parallel pairing data of a first language text and a second language text, and pre-training the pairing sample set based on a unified multi-language multi-mode model frame to obtain a multi-language multi-mode pre-training model, wherein the target text is of any language type, and the language types of the first language text and the second language text are different.","['G06F18/214', 'G06F18/253', 'G06F40/126', 'G06F40/30', 'G06F40/40', 'G06N5/04', 'G06V10/774', 'G06V10/806']"
US11481492B2,Method and system for static behavior-predictive malware detection,"Disclosed are a method and system for static behavior-predictive malware detection. The method and system use a transfer learning model from behavior prediction to malware detection based on static features. In accordance with an embodiment, machine learning is used to capture the relations between static features, behavior features, and other context information. For example, the machine learning may be implemented with a deep learning network model with multiple embedded layers pre-trained with metadata gathered from various resources, including sandbox logs, simulator logs and context information. Synthesized behavior-related static features are generated by projecting the original static features to the behavior features. A final static model may then be trained using the combination of the original static features and the synthesized features as the training data. The detection stage may be performed in real time with static analysis because only static features are needed. Other embodiments and features are disclosed.","['G06F21/563', 'G06F21/566', 'H04L63/1425']"
US11282013B2,Mobile vehicles in manufacturing,"A system comprising at least one mobile vehicle configured to move autonomously. The mobile vehicle comprises a spatial localization system, an autonomous navigation and propulsion unit, a local edge computation unit for a local data analysis at the mobile vehicle by intelligent, dynamically deployable edge analytics software agents, and a communication interface providing a data link to other devices. The system utilizes an automatic deployment of a workflow comprising at least one current task. A mobile measurement vehicle with a spatial measurement sensor unit is configured to establish a temporary instance of a local spatial reference cell for a subset of multiple mobile vehicles and a work piece. The temporary instance of the spatial reference cell is established temporally and is established with an individual level of spatial accuracy and individual limited local range, which individual level is dynamically defined by an accuracy requirement of the current task.","['G06Q10/0633', 'B25J9/1694', 'G05B19/418', 'G05B19/41895', 'G06Q10/06393', 'G06Q10/10', 'G06Q10/103', 'G06Q50/04', 'G05B2219/40298', 'Y02P90/30']"
US12282563B2,System and method for automatically detecting a security vulnerability in a source code using a machine learning model,"There is disclosed a method of automatically detecting a security vulnerability in a source code using a machine learning model, characterized in that the method comprises: obtaining the source code from a client codebase, wherein the client codebase is a complete or an incomplete body of the source code for a given software program or an application; and using a machine learning (ML) model to perform a ML based analysis on an abstract syntax tree (AST) for detecting a first security vulnerability over a static source code, the machine learning based analysis comprise (i) flattening the abstract syntax tree (AST) into a sequence of structured tokens, wherein the sequence of structured tokens comprises a semantic structure and a syntactic structure of the source code, (ii) implementing a natural language processing technique on the sequence of structured tokens for mapping the sequence of structured tokens to one or more integers, (iii) pre-training the machine learning model using an unlabeled source code as an input to predict a subsequent sub-token in the sequence of structured tokens and (iv) training the machine learning model on a labeled source code to predict a presence or an absence of the first security vulnerability.","['G06F21/57', 'G06F16/9024', 'G06F16/9027', 'G06F21/563', 'G06F21/577', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/01']"
US11907955B2,System and method for blockchain automatic tracing of money flow using artificial intelligence,"A method and apparatus that receive blockchain transaction data from a blockchain ledger to a transaction database, receive intelligence labels from a blockchain ecosystem intelligence database, select a blockchain transaction flow comprising blockchain transactions associated with a digital account source address, digital account intermediate addresses, a digital account destination address, and intermediate transactions, receive input trace parameters, where the input trace parameters include at least one of an objective directional setting, a tracing constraint, and a transaction filter, the transaction filter based on the transaction timestamps and the digital assets transferred, apply the intelligence labels to the digital account source address, the digital account intermediate addresses, and the digital account destination address, apply an artificial intelligence graph search algorithm to the blockchain transaction flow based on the input trace parameters, and generate a report including tracing destination summary statistics of the auto-traced path.","['G06Q20/4016', 'G06Q20/0655', 'G06Q20/38215', 'G06Q20/389', 'G06Q20/405', 'G06Q20/407', 'G06Q40/02', 'H04L9/3247', 'H04L9/3297', 'H04L2209/56', 'H04L9/50']"
US11875491B2,Method and system for image processing,"An image processing system comprising: a computer readable medium and at least one processor configured to provide a machine learning architecture for image processing. In particular, keyframes are selected for modification by a visual artist, and the modifications are used for training the machine learning architecture. The modifications are then automatically propagated to remaining frames requiring modification through interpolation or extrapolation through processing remaining frames through the trained machine learning architecture. The generated modified frames or frame portions can then be inserted into an original video to generate a modified video where the modifications have been propagated. Example usages include automatic computational approaches for aging/de-aging and addition/removal of tattoos or other visual effects.","['G06T5/50', 'G06T11/00', 'G06T11/60', 'G06T7/11', 'G06V10/25', 'G06V10/774', 'G06V10/7788', 'G06V10/82', 'G06V20/46', 'G06V40/10', 'G06V40/103', 'G06V40/161', 'G06T2207/20084', 'G06T2207/30196']"
US11869629B2,Systems and methods for artificial intelligence-guided biomolecule design and assessment,"Described herein are systems and methods for designing and testing custom biologic molecules in silico which are useful, for example, for the treatment, prevention, and diagnosis of disease. In particular, in certain embodiments, the biomolecule engineering technologies described herein employ artificial intelligence (AI) software modules to accurately predict performance of candidate biomolecules and/or portions thereof with respect to particular design criteria. In certain embodiments, the AI-powered modules described herein determine performance scores with respect to design criteria such as binding to a particular target. AI-computed performance scores may, for example, be used as objective functions for computer implemented optimization routines that efficiently search a landscape of potential protein backbone orientations and binding interface amino-acid sequences. By virtue of their modular design, AI-powered scoring modules can be used separately, or in combination, such as in a pipeline approach where different structural features of a custom biologic are optimized in succession.","['G16B15/20', 'G16B15/30', 'G16B35/00', 'G16B40/20']"
US20220012874A1,Method and system for augmented imaging using multispectral information,"Disclosed herein is a method of generating augmented images of tissue of a patient, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: obtaining one or more multispectral images of said tissue, and applying a machine learning based regressor or classifier, or an out of distribution (OoD) detection algorithm for determining information about the closeness of the multispectral image or parts of said multispectral image to a given training data set, or a change detection algorithm to at least a part of said one or more multispectral images, or an image derived from said multispectral image, or to a time sequence of multispectral images, parts of multiple images or images derived therefrom, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image.","['G06T7/0012', 'G06F18/241', 'G06K9/6268', 'G06T7/254', 'G06T2207/20081']"
US20240161520A1,Systems and methods for a vision-language pretraining framework,"Embodiments described herein provide a multimodal vision-language model. The multimodal vision-language model contains a Generalist Multimodal Transformer capable of complete multiple tasks using the same set of parameters learning from pre-training. The Generalist Multimodal Transformer allows alignment between frozen, unimodal encoders, such as image encoders and large language models. The Generalist Multimodal Transformer eliminates the need for fine-tuning the image encoders and large language models.","['G06V20/70', 'G06F40/10', 'G06F40/126', 'G06F40/284', 'G06F40/30', 'G06F40/35', 'G06F40/40', 'G06F40/56', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T9/00', 'G06V10/74', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
CN111753190B,Meta-learning-based unsupervised cross-modal hash retrieval method,"The invention provides an unsupervised cross-modal hash retrieval method based on meta-learning, which uses a pre-trained ResNet model and a Bert model to extract high-dimensional real number features of an auxiliary image set, an auxiliary text set and a target cross-modal dataset, inputs the high-dimensional real number features into a hash model, clusters the auxiliary image set and the text set, trains the target cross-modal dataset with the help of the auxiliary dataset by using a meta-learning training method (MAML), and updates the hash model. And due to clustering, weak supervision labels of the auxiliary data set are obtained, and then gradient updating directions of the target cross-modal data set are guided through the weak supervision information, so that the retrieval accuracy is improved.","['G06F16/9535', 'G06F16/313', 'G06F16/325', 'G06F16/338', 'G06F16/355', 'G06F16/435', 'G06F16/438', 'G06F16/45', 'G06F16/538', 'G06F16/55', 'G06F16/9538', 'G06N3/045', 'G06N3/084', 'Y02D10/00']"
US20230207064A1,Inter-model prediction score recalibration during training,"The technology disclosed relates to a system for inter-model prediction score recalibration. The system includes a first model that generates, based on evolutionary conservation summary statistics of amino acids in a reference protein sequence, a first set of pathogenicity scores with rankings for variants that mutate the reference sequence to alternate protein sequences. The system further includes a second model that generates, based on epistasis expressed by amino acid patterns spanning a multiple sequence alignment aligning the reference sequence to non-target sequences, a second set of pathogenicity scores with rankings for the variants. The system further includes a rank loss determination logic that determines a rank loss parameter by comparing the two sets of rankings, a loss function reconfiguration logic that reconfigures a loss function based on the rank loss parameter, and a training logic that uses the reconfigured loss function to train the first model.","['G16B20/20', 'G16B30/00', 'G16B40/00', 'G06F18/2111', 'G06F18/2148', 'G06F18/2155', 'G06N20/00', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/126', 'G16B10/00', 'G16B20/00', 'G16B20/40', 'G16B30/10', 'G16B40/20', 'G16B40/30', 'G16B50/10', 'Y02A90/10']"
CN111738037B,"An automatic driving method, system and vehicle thereof","The invention relates to an automatic driving method, a system thereof and a vehicle, wherein the method comprises the following steps: acquiring a vehicle front image sequence and a vehicle speed sequence; the convolutional neural network trained in advance processes the front image sequence to obtain a multi-frame image feature vector sequence, and links the multi-frame image feature vector sequence with the low-dimensional features of the vehicle speed sequence to obtain and output the coding feature vector of each frame; the pre-trained long-period and short-period memory network sequentially processes the coding feature vector of each frame and the state vector obtained by processing the coding feature vector of the previous frame to obtain a driving instruction corresponding to the coding feature vector of the current frame; and controlling an execution mechanism of the vehicle to execute the driving instruction. The system is a carrier for implementing the method, and the vehicle comprises the system. By implementing the invention, the accuracy and the instantaneity of the anthropomorphic automatic driving of the vehicle can be improved.","['G06V20/56', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
CN106845549B,Scene and target identification method and device based on multi-task learning,"The invention relates to a scene and target identification method and a device based on multi-task learning, wherein the method comprises the following steps: collecting pictures containing different scenes and targets as image sample data; manually labeling image sample data to obtain a target class label and a scene class label; constructing a multilayer convolutional neural network model, and carrying out network initialization; pre-training the constructed model by adopting image sample data and a corresponding target class label until convergence to obtain a target identification model; adding network branches into a specific layer of a target recognition model based on a multi-task learning technology, and randomly initializing to obtain a multi-task network; retraining the multitask network by adopting image sample data and corresponding scene class labels and target class labels until convergence to obtain a multitask learning model; inputting new image data to the multitask learning model to obtain the scene of the image and the classification result of the target recognition. It promotes single task recognition accuracy.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06V30/194']"
AU2024201361B2,Processing images using self-attention based neural networks,"#$%^&*AU2024201361B220250717.pdf##### Abstract Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing images using self-attention based neural networks. One of the methods includes obtaining one or more images comprising a plurality of pixels; determining, for each image of the one or more images, a plurality of image patches of the image, wherein each image patch comprises a different subset of the pixels of the image; processing, for each image of the one or more images, the corresponding plurality of image patches to generate an input sequence comprising a respective input element at each of a plurality of input positions, wherein a plurality of the input elements correspond to respective different image patches; and processing the input sequences using a neural network to generate a network output that characterizes the one or more images, wherein the neural network comprises one or more self-attention neural network layers. Abstract Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing images using self-attention based neural networks. One of the methods includes obtaining one or more images comprising a plurality of pixels; determining, for each image of the one or more images, a plurality of image patches of the image, wherein each image patch comprises a different subset of the pixels of the image; processing, for each image of the one or more images, the corresponding plurality of image patches to generate an input sequence comprising a respective input element at each of a plurality of input positions, wherein a plurality of the input elements correspond to respective different image patches; and processing the input sequences using a neural network to generate a network output that characterizes the one or more images, wherein the neural network comprises one or more self-attention neural network layers.","['G06F18/24', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T7/97', 'G06V10/764', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN112735389B,"Speech training method, device, equipment and storage medium based on deep learning","The invention discloses a voice training method, a device, computer equipment and a storage medium based on deep learning, which are applied to the technical field of artificial intelligence and provide a method for training a voice synthesis model through a teacher-student neural network, wherein the method can be used for training the voice synthesis model efficiently, quickly and with low resource consumption. The method comprises the steps of encoding a first phoneme sequence to obtain a first phoneme encoding value, performing duration prediction processing on the first phoneme encoding value to obtain a first sounding duration prediction value, performing expansion processing on each phoneme in the first phoneme sequence to obtain expansion characteristics of each phoneme in the first phoneme sequence, converting the expansion characteristics of each phoneme in the first phoneme sequence into a first Mel frequency spectrum value, training a student neural network through hidden variables provided by a trained teacher neural network and the first Mel frequency spectrum value, and training the student neural network until a first loss function of the student neural network converges to obtain the trained student neural network.","['G10L15/063', 'G10L15/02', 'G10L15/16', 'G10L15/26', 'G10L19/16', 'G10L25/24', 'G10L2015/025']"
US20230409749A1,Systems and methods for surgical video de-identification,"An improved approach is described herein wherein an automated de-identification system is provided to process the raw captured data. The automated de-identification system utilizes specific machine learning data architectures and transforms the raw captured data into processed captured data by modifying, replacing, or obscuring various identifiable features. The processed captured data can include transformed video or audio data.","['G06F21/6254', 'G06V10/25', 'A61B90/361', 'G06T7/11', 'G06T7/20', 'G06V10/82', 'G06V20/70', 'G06V40/10', 'H04N21/234345', 'H04N21/4318', 'G06N3/045', 'G06N3/08', 'G06T2200/28', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06V2201/07']"
CN111352965B,"Sequence mining model training methods, sequence data processing methods and equipment","The application discloses a training method of a sequence mining model, a processing method and equipment of sequence data, belonging to the technical field of artificial intelligence and machine learning, wherein the method comprises the following steps: acquiring a first sequence sample in a target service scene; determining a tag status of the first sequence sample; selecting a sub-model from the sequence mining frame according to the label state to construct a sequence mining model; and training the sequence mining model by adopting the first sequence sample. The technical scheme provided by the embodiment of the application provides a sequence mining framework, and a sequence mining model can be constructed by selecting corresponding sub-models from the sequence mining framework according to different tag states of historical sequence data under different service scenes. Compared with the prior art that only a single model with a fixed structure can be used for training, the technical scheme provided by the embodiment of the application fully utilizes all historical sequence data in a service scene and improves the resource utilization rate.","['G06N3/044', 'G06N20/20', 'G06F16/2465', 'G06F16/2474', 'G06F18/214', 'G06F18/2148', 'G06F18/2155', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06Q40/03', 'G06N20/00', 'Y02D10/00']"
US20220180975A1,Methods and systems for determining gene expression profiles and cell identities from multi-omic imaging data,The present disclosure relates to systems and method of determining transcriptomic profile from omics imaging data. The systems and methods train machine learning methods with intrinsic and extrinsic features of a cell and/or tissue to define transcriptomic profiles of the cell and/or tissue. Applicants utilize a convolutional autoencoder to define cell subtypes from images of the cells.,"['G16B25/10', 'G16B40/20', 'G16B40/30', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/088', 'G06N5/01', 'G06N7/01']"
CN110852447B,"Meta learning method and apparatus, initializing method, computing device, and storage medium","The invention relates to a meta learning method and device, an initializing method, a computing device and a computer-readable storage medium of a risk prediction model. The meta learning method comprises the following steps: generating a training task set comprising a plurality of training tasks, wherein the plurality of training tasks are provided with respective different class predictors; initializing network weights of a meta learner, a feature extractor and a task discriminator, wherein the category predictor, the meta learner, the feature extractor and the task discriminator are artificial neural networks, and the category predictor has the same network structure as the meta learner; dividing the training tasks in the training task set into a plurality of batches, and updating the network weights of the meta learner, the feature extractor and the task discriminator on a per-batch basis, wherein the updating is performed according to the category prediction loss and the task discrimination loss. The method can improve the generalization capability of the meta learner, thereby quickly obtaining a better risk prediction model in the training of small samples in a financial wind control scene.",['G06N20/00']
CN111738357B,"Method, device and equipment for identifying garbage pictures","The application discloses a method, a device and equipment for identifying junk pictures, and relates to the technical field of image identification. The method comprises the following steps: firstly, selecting a pre-preset number layer parameter as a basic network based on a determined deep learning model, and constructing a shallow classification network behind the basic network; then freezing parameters of a basic network, and training a shallow classification network by utilizing a garbage picture training set; if the network convergence is judged according to the updated parameters of the shallow classification network training, unfreezing the parameters of the basic network, and carrying out full data training with a preset number on all the parameters of the basic network and the shallow classification network by using a learning rate smaller than a preset threshold value so as to adjust the parameters frozen before the basic network and obtain a target deep learning model; and finally, classifying the pictures by using the target deep learning model so as to determine whether the pictures to be identified are garbage pictures. The method and the device can automatically realize the classification and identification of the garbage pictures, and can improve the identification efficiency and accuracy of the garbage pictures.","['G06F18/254', 'G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
US10839514B2,Methods and systems for dynamically training and applying neural network analyses to medical images,"A method of training neural networks using digital images is disclosed. Each of the digital images is associated with an imaging modality, an anatomy of a person, a diagnosis of the person, an age of the person, a gender of the person, data indicative of contouring, an aggregated score, or a property of the anatomy of the person. In the method, a client side viewing application receives the digital images, receives a modification of one of the digital images, and transmits the modified digital image to a server. The server selects a neural network to train based on the digital image, trains the selected neural network, receives a request to apply one of the neural networks to another set of digital images, and selects a neural network to apply. The neural network is applied to the other set of digital images and generates a graphical, audio, alphanumeric text, or video result.","['G16H30/20', 'G06F16/27', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T11/008', 'G06T7/0002', 'G06T7/0012', 'G16H30/40', 'G16H40/20', 'H04L67/1095', 'H04L67/1097', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'G06T2200/16', 'G06T2200/24', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G16H50/20', 'G16H80/00']"
CN114376564B,"Sleep staging method, system, device and medium based on ballistocardiogram signals","The invention discloses a sleep stage method, a sleep stage system, a sleep stage device and a sleep stage medium based on a ballistocardiogram signal, wherein the sleep stage method comprises the following steps: collecting a first heart attack signal of a human body; acquiring a first heartbeat signal and a first respiration signal according to the first ballistocardiogram signal; acquiring a first heart rate variability and a first cardiopulmonary coupled power spectrogram according to the first heartbeat signal and the first respiratory signal; inputting the first heart rate variability and the first heart lung coupling power spectrogram into a sleep stage model for feature extraction, performing sleep stage according to the extracted features, and outputting a stage result; the sleep stage model is obtained by training by adopting electrocardiosignals and then adjusting by adopting ballistocardiogram signals based on transfer learning. According to the invention, sleep stage is realized through the ballistocardiogram signal, and the comfort of sleep monitoring is improved as the ballistocardiogram signal can be acquired in a non-invasive manner. The invention can be widely applied to the field of sleep monitoring.","['A61B5/1102', 'A61B5/0205', 'A61B5/02405', 'A61B5/0816', 'A61B5/4806', 'A61B5/4812', 'A61B5/6887', 'A61B5/7264', 'A61B5/7267']"
CN112818892B,Multi-modal depression detection method and system based on time convolution neural network,"The invention provides a multi-modal depression detection method and system based on a time convolution neural network. The detection method specifically comprises the following steps: constructing a training sample set which comprises audio, 3D facial expressions and corresponding text information of depression and non-depression patients; 3D facial expression feature extraction is carried out on the training sample set, and a 3D facial expression feature vector with context perception is obtained; combining with Mel cepstrum coefficients, and performing acoustic feature extraction on the audio signals of the training sample set to obtain speech vector features with context perception; embedding training sample set words by using a Transformer model, and processing to obtain text characteristics with context perception; fusing the 3D facial expression features, the voice vector features and the text features to obtain information for classifying the depression; and substituting the information for classifying the depression into a time convolution neural network to obtain the classification information of the depression. The method can improve the accuracy of depression detection.","['G06V40/174', 'G06F18/214', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V40/168']"
US20230377748A1,A Neural Graph Model for Automated Clinical Assessment Generation,"Embodiments generate medical support text, e.g., assessments and plans, based on patient medical data. One such embodiment begins by receiving medical data for a given patient. Next, a patient knowledge graph for the given patient is generated based on the received medical data and an expanded graph is generated by expanding the patient knowledge graph based upon supplementary data. In turn, the medical support text for the given patient is generated based upon the expanded graph.","['G16H50/20', 'G06F40/40', 'G06N3/045', 'G06N3/08', 'G06N5/022', 'G16H10/60', 'G16H50/70', 'G16H70/60']"
US11769011B2,Universal language segment representations learning with conditional masked language model,"The present disclosure provides a novel sentence-level representation learning method Conditional Masked Language Modeling (CMLM) for training on large scale unlabeled corpora. CMLM outperforms the previous state-of-the-art English sentence embedding models, including those trained with (semi-)supervised signals. For multilingual representations learning, it is shown that co-training CMLM with bitext retrieval and cross-lingual natural language inference (NL) fine-tuning achieves state-of-the-art performance. It is also shown that multilingual representations have the same language bias and principal component removal (PCR) can eliminate the bias by separating language identity information from semantics.","['G06F40/284', 'G06F40/30', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/096', 'G06F40/216', 'G06F40/289', 'G06F40/42', 'G06N3/044']"
CN109389587B,"Medical image analysis system, device and storage medium","The invention provides a medical image analysis system, a medical image analysis apparatus and a storage medium. The system comprises an acquisition module, a region-of-interest determination module and a deformation type determination module. The acquisition module is used for acquiring a sample image and an image to be detected. The interested region determining module is used for inputting the image to be detected into a first detection model and determining at least one interested region of the image to be detected, wherein the first detection model is a deep learning model. The deformation type determining module is used for inputting the at least one region of interest into a second detection model and determining the deformation type of the image to be detected, wherein the second detection model is a deep learning model. The method applies the deep convolution neural network to the prediction of the image deformation type, and has short time consumption and high accuracy.","['G06T7/0012', 'G06F18/241', 'G06T7/136', 'G16H50/20', 'G06T2207/10088']"
CN111160380B,Method for generating video analysis model and video analysis system,"The embodiment of the application provides a method for generating a video analysis model and a video analysis system, wherein the method comprises the steps that the video analysis system acquires video stream data, analyzes the video stream, extracts unlabeled image data in the video stream, manages the image data by utilizing an automatic labeling strategy, completes labeling and cleaning of the image data, carries out online model training on the labeled image data to generate the video analysis model, then tests the newly generated model, outputs a performance analysis report of the model, and issues the video analysis model to the video analysis system when the performance meets the requirement. The method provided by the embodiment of the application can fully utilize the video stream acquired in the actual scene to perform online training of the video analysis model, and continuously optimize the performance of the video analysis model on the premise of ensuring the data safety so as to alleviate the performance decline of the model in the actual scene.","['G06F18/241', 'H04N23/76', 'G06V2201/08', 'G06V40/10', 'G06V40/172', 'G06V40/20']"
US11125675B2,Fluid suspended particle classifier,"A fluid suspended particle classifier system detects particles of one or more classes from a predetermined recognized set of classes based on multiple images of groups of particles. An artificial intelligence classifier combines subtle clues in the images including particle morphology, size, spectral response, fluorescence, movement, density, or aggregation. Class-specific concentration estimations have a low limit of detection, and a high dynamic range. There is a tolerance for mixtures of classes of particles having widely differing sizes and concentrations. Selected particle images, histories and analysis are communicated and stored. Consumable use and manual procedures are minimized or avoided, allowing remote, unattended, real-time operation. In remote water quality monitoring, the appearance of particles resembling the Escherichia coli bacterium, an occasional human pathogen, causes an alarm.","['G01N15/147', 'G01N15/1434', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G01N15/01', 'G01N2015/0053', 'G01N2015/144', 'G01N2021/177', 'G06T7/0012']"
CN111882579B,"Method, system, medium and equipment for detecting large transfusion foreign matters based on deep learning and target tracking","The invention discloses a large transfusion foreign matter detection method, a system, a medium and equipment based on deep learning and target tracking, wherein the method combines a target detection algorithm and a target tracking algorithm after image preprocessing is carried out on collected continuous multi-frame images, so that the fusion of target detection and target tracking and the accurate positioning tracking of foreign matters are realized; firstly, preprocessing sequence images, then, carrying out target detection on a first frame image by using a Faster R-CNN neural network to obtain an initial position of each suspected target, then, tracking the position of each target in a plurality of frames after the target by using a CSR-DCF target tracking algorithm to obtain a motion track of each suspected target, and finally, classifying by using a self-adaptive classification algorithm based on a semi-naive Bayes principle according to track characteristics to remove noise interference. Experiments show that the method can greatly improve the detection speed and the detection precision, and meets the requirements of industrial production precision and real-time performance.","['G06T7/246', 'G06F18/2415', 'G06T7/0012', 'G06T7/10', 'G06T7/44', 'G06T7/90', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30104', 'Y02P90/30']"
CN107409126B,System and method for securing an enterprise computing environment,"Methods and systems provided herein include a network intelligence system, a unified application firewall, and a cloud security architecture having an enterprise API for connecting to an information technology infrastructure of an enterprise, a developer API 102 for enabling developers to access capabilities of the architecture, and a connector API through which the architecture can discover information of entities related to information security of the enterprise (e.g., events involving users, applications, and data of the enterprise that occur on multiple cloud-capable platforms, including PaaS/IaaS platforms), wherein the cloud security architecture has various modules including services deployed in the cloud security architecture, such as a selective encryption module, a policy creation and automation module, a content classification as a service module, and a user and entity behavior analysis module.","['H04L63/1425', 'H04L67/535', 'G06F21/6218', 'G06F9/46', 'H04L63/0227', 'H04L63/0245', 'H04L63/145', 'G06F2221/2141', 'H04L63/168']"
US20250245973A1,Systems and methods for unified vision-language understanding and generation,"Embodiments described herein provide bootstrapping language-images pre-training for unified vision-language understanding and generation (BLIP), a unified VLP framework which transfers flexibly to both vision-language understanding and generation tasks. BLIP enables a wider range of downstream tasks, improving on both shortcomings of existing models.","['G06V10/774', 'G06F40/126', 'G06F40/284', 'G06F40/30', 'G06T9/00', 'G06V10/764', 'G06V10/803', 'G06F40/216', 'G06F40/279']"
US20200294630A1,Systems and Methods for Determining Molecular Structures with Molecular-Orbital-Based Features,"Systems and methods for determining molecular structures based on molecular-orbital-based (MOB) features are described. MOB features can be utilized in combination with machine-learning methods to predict accurate properties, such as quantum mechanical energy, of molecular systems.","['G16C20/50', 'G06F18/213', 'G06F18/24', 'G06K9/6232', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'G16C10/00', 'G16C20/10', 'G16C20/70', 'G16C20/30', 'G16C20/90']"
US5408588A,Artificial neural network method and architecture,"An architecture and data processing method for a neural network that can approximate any mapping function between the input and output vectors without the use of hidden layers. The data processing is done at the sibling nodes (second row). It is based on the orthogonal expansion of the functions that map the input vector to the output vector. Because the nodes of the second row are simply data processing stations, they remain passive during training. As a result the system is basically a single-layer linear network with a filter at its entrance. Because of this it is free from the problems of local minima. The invention also includes a method that reduces the sum of the square of errors over all the output nodes to zero (0.000000) in fewer than ten cycles. This is done by initialization of the synaptic links with the coefficients of the orthogonal expansion. This feature makes it possible to design a computer chip which can perform the training process in real time. Similarly, the ability to train in real time allows the system to retrain itself and improve its performance while executing its normal testing functions.","['G06N3/063', 'G06F18/2135', 'G06V10/44', 'G06V30/10']"
WO2021142902A1,Danet-based unmanned aerial vehicle coastline floating garbage inspection system,"Disclosed in the present invention is a DANet-based unmanned aerial vehicle coastline floating garbage inspection system, using a panoramic segmentation algorithm to segment background and foreground target objects in an image simultaneously and also providing an independent identity for each foreground target. The course of an unmanned aerial vehicle is adjusted by means of an accurate segmentation result, a flight path is automatically planned, a coastline floating garbage condition is inspected, and pollution is found and a position and a category thereof are fed back; the system assists related departments in solving the pollution inspection problem in a long coastline scene.","['H04N1/00127', 'G05D1/0094', 'G05D1/106', 'G06F18/214', 'G06F18/241', 'G06T7/11', 'G06T7/194', 'G06V10/25', 'G06V10/267', 'G06V10/454', 'G06V10/56', 'G06V10/774', 'G06V10/82', 'G06V20/10', 'G06V20/13', 'G06V20/17', 'H04N1/3876', 'H04N23/60', 'H04N23/698', 'G06T2207/10016', 'G06T2207/10032', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30181', 'Y02A10/40']"
AU2022288746B2,Multimodal few-shot learning with frozen language models,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing multi-modal inputs using language models. In particular, the inputs include an image, and the image is encoded by an image encoder neural network to generate a sequence of image embeddings representing the image. The sequence of image embeddings is provided as at least part of an input sequence to that is processed by a language model neural network.","['G06V10/82', 'G06F40/284', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/80', 'G06V20/70', 'G06V30/268']"
CN108898175B,A computer-aided model construction method based on deep learning for gastric cancer pathological slices,"The invention discloses a computer-aided model construction method based on deep learning gastric cancer pathological section, and belongs to the technical field of artificial intelligence. The method uses a 121-layer dense connection convolution neural network to identify the image. The dense block structure in DenseNet allows the high-level part of the network to acquire shallow features, thereby well reducing the overfitting phenomenon. Meanwhile, the number of layers of the model is large, and a more complex and smoother decision function can be fitted. Although the number of layers is large, the number of parameters of the model is not large, and resource occupation is saved well. In order to further avoid overfitting, a training mechanism of transfer learning is adopted. The model can be pre-trained on the ImageNet data set, so that the model has strong image feature extraction capability, and the main optimization of the model can better concentrate on how to extract the features of the diseased region during formal training, thereby greatly improving the utilization efficiency of data.","['G06F18/214', 'G06V2201/03']"
US10991093B2,"Systems, methods and media for automatically generating a bone age assessment from a radiograph","In accordance with some embodiments, systems, methods and media for generating a bone age assessment. In some embodiments, a method comprises: receiving an x-ray image of a subject's left hand and wrist; converting the image to a predetermined size; identifying, without user intervention, a first portion of the image corresponding to the hand and wrist; processing the first portion of the image to increase contrast between bones and non-bones to generate a processed image; causing a trained convolution neural network to determine a bone age based on the processed image; receiving an indication of the bone age; causing the bone age to be presented to a user as the result of a bone age assessment; and causing the bone age and the image to be stored in an electronic medical record associated with the subject.","['G06T7/0012', 'A61B6/505', 'A61B6/5217', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06K9/627', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06V10/764', 'G06V10/82', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'A61B5/4509', 'G06K2209/055', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06V2201/033']"
CN110781916B,"Fraud detection method, apparatus, computer device and storage medium for video data","The application relates to a fraud detection method, a fraud detection device, a fraud detection computer device and a fraud detection storage medium for video data. The method comprises the following steps: acquiring video data to be detected; extracting image data of each video frame from video data to be detected, dividing the image data into a plurality of image data sets according to the time sequence of each video frame, wherein each image data set comprises image data corresponding to continuous video frames; inputting each image data set into a pre-trained image feature extraction model to obtain an image feature vector; extracting voice data from video data to be detected, and acquiring voice feature vectors of the voice data; cascading and splicing the image feature vectors and the voice feature vectors to obtain multi-mode feature vectors; and inputting the multi-mode feature vector into a pre-trained fraud detection model to obtain fraud detection results corresponding to the video data to be detected output by the fraud detection model. The method can increase the characteristic information quantity, improve the comprehensiveness and diversity of the characteristic information and effectively improve the accuracy of video data fraud detection.","['G06F18/253', 'G06F18/214', 'G06V40/174', 'G06V40/176', 'G10L25/27', 'G10L25/63']"
CN110084794B,A skin cancer image recognition method based on attention convolutional neural network,"The invention discloses a skin cancer picture identification method based on an attention convolution neural network, which comprises the following steps: 1) preprocessing of the image, including image turning, rotation and affine transformation; 2) carrying out unbalanced sampling on the image, and carrying out undersampling on the image; 3) establishing a convolutional neural network framework comprising a convolutional layer, a pooling layer and a full-connection layer; 4) establishing an attention mechanism comprising a channel attention module and a space attention module; 5) and designing an attention convolution neural network to realize the identification of the skin cancer picture. The network with the attention module can be more accurately positioned in a local area, and the mined pictures have distinctive characteristics. 6) And (4) migration learning, namely initializing the parameters of the convolutional neural network by using the parameters of the pre-training network. The method can effectively improve the accuracy of identifying the skin cancer picture and promote the development of artificial intelligence in the medical industry to a certain extent.","['G06T7/0012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088']"
US11308614B2,Deep learning for real-time colon polyp detection,"A set of enhancements to further improve the performance of deep learning artificial intelligence algorithms trained to detect and localize colon polyps. The enhancements spanning training data mining efficiencies and automation, training data augmentation, early detection of polyps enable a more performant colon polyp detection solution for use on colonoscopy procedure recordings or live procedures in endoscopy centers.","['A61B1/000094', 'A61B1/000096', 'G06T5/005', 'G06T5/006', 'G06T5/008', 'G06T5/77', 'G06T5/80', 'G06T5/94', 'G06T7/0012', 'G06T7/593', 'G16H30/40', 'G16H50/20', 'G06T2200/08', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10068', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20152', 'G06T2207/30028']"
CN119576507B,Automatic optimization method and system for big data distributed computing task based on AI,"The invention provides an automatic optimization method and system for big data distributed computing tasks based on AI, and relates to the technical field of AI. The global strategy network adopts a hierarchical deep reinforcement learning architecture, combines Monte Carlo tree searching and priority experience playback to generate decisions, and the local execution network optimizes local deployment based on the graph neural network and multi-agent collaborative learning. In addition, the distributed anomaly detection network is deployed to monitor the performance in real time, self-adaptive tuning is realized through reinforcement transfer learning, and finally, the perception network is updated through knowledge distillation, so that model evolution is realized. The invention can effectively improve the execution efficiency and the resource utilization rate of the big data distributed computing task and reduce the system operation cost.","['G06F9/4881', 'G06F11/3433', 'G06F11/3452', 'G06F18/213', 'G06F18/2433', 'G06F18/253', 'G06F9/5038', 'G06F9/505', 'G06F9/5088', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/092', 'G06N3/096', 'G06N5/01', 'G06F2123/02', 'G06F2209/484', 'G06F2209/5021']"
US10650211B2,Artificial intelligence-based machine readable symbol reader,"Systems and methods for establishing optimal reading conditions for a machine-readable symbol reader. A machine-readable symbol reader may selectively control reading conditions including lighting conditions (e.g., illumination pattern), focus, decoder library parameters (e.g., exposure time, gain), etc. Deep learning and optimization algorithms (e.g., greedy search algorithms) are used to autonomously learn an optimal set of reading parameters to be used for the reader in a particular application. A deep learning network (e.g., a convolutional neural network) may be used to locate machine-readable symbols in images captured by the reader, and greedy search algorithms may be used to determine a reading distance parameter and one or more illumination parameters during an autonomous learning phase of the reader. The machine-readable symbol reader may be configured with the autonomously learned reading parameters, which enables the machine-readable symbol reader to accurately and quickly decode machine-readable symbols (e.g., direct part marking (DPM) symbols).","['G06K7/10821', 'G06K7/1482', 'G06K7/01', 'G06K7/10722', 'G06K7/10732', 'G06K7/10752', 'G06K7/10831', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06K2007/10485']"
US10468142B1,Artificial intelligence-based system and methods for corneal diagnosis,"A method of predicting a disease or condition of a cornea or an anterior segment of an eye includes inputting input data into an AI model, processing the input data, and generating a set of scores and outputting a prediction. The input data may be representative of a cornea or anterior segment of an eye. Processing the input data may include processing the data through the plurality of convolutional layers, the fully connected layer, and the output layer. Each score of the set of scores may be generated by a corresponding node in the output layer. The output prediction may be related to the cornea or anterior segment of the eye represented by the input data processed through the AI model. The prediction may be determined by at least one score of the set of scores.","['G16H50/20', 'A61B3/0025', 'A61B3/1005', 'A61B3/102', 'A61B3/107', 'A61B3/117', 'A61B3/14', 'G06T7/0012', 'G16H30/20', 'G16H50/50', 'G06T2207/10024', 'G06T2207/10101', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041']"
US12067646B2,Cross-modal contrastive learning for text-to-image generation based on machine learning models,"A computer-implemented method includes receiving, by a computing device, a particular textual description of a scene. The method also includes applying a neural network for text-to-image generation to generate an output image rendition of the scene, the neural network having been trained to cause two image renditions associated with a same textual description to attract each other and two image renditions associated with different textual descriptions to repel each other based on mutual information between a plurality of corresponding pairs, wherein the plurality of corresponding pairs comprise an image-to-image pair and a text-to-image pair. The method further includes predicting the output image rendition of the scene.","['G06V10/82', 'G06F18/2148', 'G06F18/22', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T11/00', 'G10L15/26']"
CN109978037B,"Image processing method, model training method, device and storage medium","The application relates to an image processing method, a model training method, a device and a storage medium, wherein the image processing method comprises the following steps: acquiring a three-dimensional medical image to be processed; performing feature extraction on the three-dimensional medical image through a feature extraction network to obtain image features of a target object in the three-dimensional medical image; the feature extraction network is used for jointly training an image segmentation network and carrying out iterative training on three-dimensional medical image samples based on different data fields, so that parameter values of the feature extraction network and the training image segmentation network are updated in an iterative manner; inputting the obtained image characteristics into an image segmentation network for processing to obtain a segmented image; and determining the focus attribute corresponding to the target object according to the pixel characteristics in the segmented image. The scheme provided by the application can effectively improve the processing efficiency of the medical image and can also improve the accuracy of focus detection.","['G06F18/214', 'G06T7/11', 'G06T7/251']"
CN117149989B,"Training method for large language model, text processing method and device","The embodiment of the application provides a large language model training method, a text processing method and a device, and relates to the fields of artificial intelligence, cloud technology, natural language processing, machine learning and the like. The method comprises the following steps: acquiring a training sample set; the training sample set comprises a plurality of training samples; the plurality of training samples includes a plurality of first training samples and a plurality of second training samples; the first training sample is a training sample with prediction accuracy greater than a preset threshold value; the second training sample is a training sample with prediction accuracy smaller than a preset threshold value; training the initial rewarding model based on the training sample set to obtain a trained rewarding model; training the pre-trained large language model based on the reward model to obtain a trained large language model. The embodiment of the application provides a richer data base with better training effect for training to obtain the large language model with better performance, and better meets the actual application demands.","['G06F16/3329', 'G06F16/3344', 'G06F16/35', 'Y02D10/00']"
AU2023282274B2,Variant classifier based on deep neural networks,"We introduce a variant classifier that uses trained deep neural networks to predict whether a given variant is somatic or germline. Our model has two deep neural networks: a convolutional neural network (CNN) and a fully connected neural network (FCNN), and two inputs: a DNA sequence with a variant and a set of metadata features correlated with the variant. The metadata features represent the variant's mutation characteristics, read mapping statistics, and occurrence frequency. The CNN processes the DNA sequence and produces an intermediate convolved feature. A feature sequence is derived by concatenating the metadata features with the intermediate convolved feature. The FCNN processes the feature sequence and produces probabilities for the variant being somatic, germline, or noise. A transfer learning strategy is used to train the model on two mutation datasets. Results establish advantages and superiority of our model over traditional classifiers.","['G16B20/20', 'G06N3/045', 'G06N3/048', 'G16B30/10', 'G16B40/20']"
WO2024108522A1,Multi-modal brain tumor image segmentation method based on self-supervised learning,"Disclosed in the present invention is a multi-modal brain tumor image segmentation method based on self-supervised learning, comprising: acquiring a multi-modal MRI image set, the MRI image set comprising a plurality of case images of brain tumors, and each case image corresponding to a segmentation label and comprising four modal images; establishing a self-supervised-learning multi-modal brain tumor image segmentation network, which comprises a feature extraction unit, a global feature modeling unit and a decoding unit, the global feature modeling unit using a cross-pixel Transformer model; and, during training, first pre-training the global feature modeling unit, then training the overall self-supervised-learning multi-modal brain tumor image segmentation network, and finally segmenting the tumor images by using the trained model. The present invention can fully capture local features and global features in medical images while enabling the amount of computation to be only 1/4 of that for an original structure and having high accuracy.",['G06T7/10']
US11232358B1,Task specific processing of regulatory content,"A neural network system for performing a processing task on regulatory content and a method for training the system are disclosed. The method for training involves configuring a neural network language model capable of generating a language embedding output in response to receiving content. The method further involves fine-tuning the language model using regulatory content training data to generate a regulatory content language embedding output for regulatory content processed by the language model. The method also involves configuring at least one task specific output layer to generate task specific results in response to receiving the regulatory content language embedding output from the language model, and training the neural network system using task specific training data to output the task specific results, at least a portion of the task specific training data having been labeled prior to configuring the task specific neural network.","['G06N3/08', 'G06Q50/26', 'G06F40/216', 'G06F40/279', 'G06F40/284', 'G06F40/30', 'G06N3/045', 'G06N3/0499', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06Q10/10']"
CN112418216B,Text detection method in complex natural scene image,"The invention discloses a text detection method in a complex natural scene image, belongs to the field of computer vision and pattern recognition, relates to the technical field of neural networks and computer vision, and particularly relates to a text detection method based on deep learning under a complex scene. The character detection method based on character labeling and the character detection method based on word labeling are combined, the combination characteristics among characters are learned, the false detection rate of characters can be reduced, the redundancy of a detection frame is reduced, and the capability of flexibly coping with characters of any shape is achieved. A text detection method under complex scene comprises the following steps: preprocessing image data, constructing a network frame, pre-training a model and training the network frame; and the text real tag generation and input module is used for generating and inputting a text image, feature extraction, image judgment and text correction under a natural scene to be detected.","['G06V20/63', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V10/267', 'G06V30/1478', 'G06V30/153', 'G06V30/10']"
US20240266074A1,"Cognitive Communications, Collaboration, Consultation and Instruction with Multimodal Media and Augmented Generative Intelligence","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with networked cognitive collaboration, augmented clinical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal clinical communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms, including augmented generative AI algorithms, models and systems. The invention enables cognitively-enriched, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized clinical intelligence.","['A61B34/30', 'G06F40/169', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16H10/60', 'G16H15/00', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H80/00', 'H04L12/1822', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/152', 'A61B2090/365', 'A61B2090/373', 'A61B2090/376', 'A61B2090/378', 'A61B34/25', 'A61B34/73', 'A61B90/361', 'H04L51/10', 'H04M3/561', 'H04M3/567', 'H04M7/0027']"
US11977976B2,Experience learning in virtual world,"A computer-implemented method of machine-learning is described that includes obtaining a test dataset of scenes. The test dataset belongs to a test domain. The method includes obtaining a domain-adaptive neural network. The domain-adaptive neural network is a machine-learned neural network taught using data obtained from a training domain. The domain-adaptive neural network is configured for inference of spatially reconfigurable objects in a scene of the test domain. The method further includes determining an intermediary domain. The intermediary domain is closer to the training domain than the test domain in terms of data distributions. The method further includes inferring, by applying the domain-adaptive neural network, a spatially reconfigurable object from a scene of the test domain transferred on the intermediary domain. Such a method constitutes an improved method of machine learning with a dataset of scenes comprising spatially reconfigurable objects.","['G06F30/12', 'G06N3/045', 'G06N3/08', 'G06F18/25', 'G06F30/20', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F2111/00', 'G06N3/008']"
US11868862B2,Semisupervised autoencoder for sentiment analysis,"A method of modelling data, comprising: training an objective function of a linear classifier, based on a set of labeled data, to derive a set of classifier weights; defining a posterior probability distribution on the set of classifier weights of the linear classifier; approximating a marginalized loss function for an autoencoder as a Bregman divergence, based on the posterior probability distribution on the set of classifier weights learned from the linear classifier; and classifying unlabeled data using the autoencoder according to the marginalized loss function.","['G06N20/10', 'G06F18/214', 'G06F18/2411', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0499', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N7/01', 'G06V10/764', 'G06V10/774']"
US11195051B2,Method for person re-identification based on deep model with multi-loss fusion training strategy,"The invention relates to a method for person re-identification based on deep model with multi-loss fusion training strategy. The method uses a deep learning technology to perform preprocessing operations such as flipping, clipping, random erasing and style transfer, and then feature extraction is performed through a backbone network model; joint training of a network is performed by fusing a plurality of loss functions. Compared with other deep learning-based person re-identification algorithms, the present invention greatly improves the performance of person re-identification by adopting a plurality of preprocessing modes, the fusion of three loss functions and effective training strategy.","['G06N3/08', 'G06K9/6256', 'G06F18/21322', 'G06F18/214', 'G06K9/00369', 'G06K9/00771', 'G06K9/46', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06T3/60', 'G06T5/002', 'G06T5/70', 'G06V10/20', 'G06V10/454', 'G06V10/7715', 'G06V10/82', 'G06V20/52', 'G06V40/103', 'G06V40/173', 'G06N3/047']"
US11836615B2,Bayesian nonparametric learning of neural networks,"In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. A Bayesian nonparametric framework is presented for federated learning with neural networks. Each data server is assumed to provide local neural network weights, which are modeled through our framework. An inference approach is presented that allows us to synthesize a more expressive global network without additional supervision, data pooling and with as few as a single communication round. The efficacy of the present invention on federated learning problems simulated from two popular image classification datasets is shown.","['G06N3/08', 'G06N3/047', 'G06N3/0495', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/098', 'G06N3/0985', 'G06N3/044', 'G06N3/045']"
US20230019211A1,Pretraining framework for neural networks,"Apparatuses, systems, and techniques to indicate an extent, to which text corresponds to one or more images. In at least one embodiment, an extent to which text corresponds to one or more images is indicated using one or more neural networks and used to train the one or more neural networks.","['G06N3/08', 'G06T7/0012', 'G06F40/30', 'G06N3/09', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/0895', 'G06T3/4046', 'G06V10/811', 'G06V10/82', 'G06N3/084', 'G06V2201/03']"
US20230007965A1,Entity relation mining method based on biomedical literature,"The present disclosure provides an entity relation mining method based on a biomedical literature, including the following steps: querying a disease-associated biomedical literature in a public database, and performing data preprocessing to obtain biomedical text data; performing biomedical named entity recognition on obtained biomedical text data in combination with a regex matching pattern and a deep learning model; and mining an entity relation with transfer learning and reinforcement learning based on an entity recognition result. By acquiring the disease-associated biomedical literature from a network, extracting an abstract and a title and performing entity recognition and relation mining, the present disclosure can effectively recognize biomedical noun entities in the literature and mine potential relations between various entities.","['G16B50/10', 'G16H50/70', 'G06F16/35', 'G06F16/334', 'G06F40/295', 'G16H15/00']"
US10482633B2,Systems and methods for automated detection of an indication of malignancy in a mammographic image,"There is provided a method of computing a likelihood of malignancy in a mammographic image, comprising: receiving a single channel 2D mammographic image including a single pixel intensity value for each pixel thereof, converting the single channel 2D mammographic image into a multi channel 2D mammographic image including multiple pixel intensity value channels for each pixel thereof, computing by a first sub-classifier according to the whole multi channel image, a first score indicative of likelihood of malignancy within the whole multi channel image, computing by a second sub-classifier according to each respective patch extracted from the multi channel image, a respective second score indicative of likelihood of malignancy within each respective patch, and computing by a gating sub-classifier according to the first score and the second scores, an indication of likelihood of malignancy and a location of the malignancy.","['G06V10/82', 'A61B6/461', 'A61B6/502', 'A61B6/5217', 'G06F18/24143', 'G06F18/254', 'G06K9/3233', 'G06K9/4628', 'G06K9/4642', 'G06K9/6274', 'G06K9/6292', 'G06T11/005', 'G06T11/008', 'G06T7/0012', 'G06V10/454', 'G06V10/50', 'G06V10/764', 'G06V10/809', 'G16H50/30', 'G06K2209/05', 'G06T2207/10116', 'G06T2207/30068', 'G06T2211/441', 'G06V2201/03']"
CN118093834B,AIGC large model-based language processing question-answering system and method,"The invention relates to the technical field of language processing, in particular to a AIGC large model-based language processing question-answering system and method, comprising the following steps: receiving natural language questions input by a user, and extracting key information through grammar analysis and semantic understanding technology; inputting the extracted key information into a AIGC-based language model, and generating a series of answer candidates by using a AIGC large model according to the input information and the enhanced domain knowledge through domain adaptability enhancement processing; evaluating answer candidates to select an optimal answer; and outputting the optimal answer to the user in the form of natural language. The invention obviously enhances the adaptability and the processing capacity of AIGC large models to the problems in the specific field. The adaptability reinforcement not only improves the application range of the question-answering system in various professional fields, but also enhances the flexibility and accuracy of the question-answering system in the face of new fields or cold questions.","['G06F16/3329', 'G06F16/3344', 'G06F40/211', 'G06F40/253', 'G06F40/30']"
US12393768B2,Layout-aware multimodal pretraining for multimodal document understanding,"Systems and methods for document processing that can process and understand the layout, text size, text style, and multimedia of a document can generate more accurate and informed document representations. The layout of a document paired with text size and style can indicate what portions of a document are possibly more important, and the understanding of that importance can help with understanding of the document. Systems and methods utilizing a hierarchical framework that processes the block-level and the document-level of a document can capitalize on these indicators to generate a better document representation.","['G06N3/084', 'G06F40/166', 'G06F16/483', 'G06F16/93', 'G06F40/109', 'G06F40/284', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V30/413']"
US11436615B2,System and method for blockchain transaction risk management using machine learning,A method involves receiving digital on blockchain information and digital off blockchain information. The digital data from the digital on blockchain information and the digital off blockchain information is extracted. The entity knowledge base engine contextualizes the relationships based on the digital data and the digital off blockchain information and the digital on blockchain information. The risk classification engine analyzes the digital data and transforms the digital data to an identified behavior category. The risk scoring regression engine analyzes the classified risk data and assigns a risk score to each classified risk data. The risk policy engine analyzes the classified risk data and determines if any deviations from rules or standards have or will occur. The security control system takes an action on the digital on blockchain information and digital off blockchain information based on the assigned risk score and any deviations from rules or standards.,"['G06Q30/0185', 'G06F16/2379', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06Q10/10', 'G06Q20/0655', 'G06Q20/3674', 'G06Q20/4016', 'G06Q20/405', 'G06Q40/04', 'G06Q50/265', 'H04L63/1425', 'H04L63/20', 'H04L9/50', 'G06N3/048', 'G06N3/126', 'G06Q2220/00', 'H04L63/0236', 'H04L63/101']"
US12078752B2,Detection and classification of unmanned aerial vehicles,"A method and system for real-time and automated detection and classification of aerial objects, such as e.g. UAVs, on a radar plot level from digital radar images, wherein the digital radar images are created from radar return signals obtained by a conventional radar such as e.g. a continuous wave radar (e.g. FMCW radar), a phased-array radar, or a pulse radar, as opposed to using specialized micro-Doppler radars for classifying UAVs based on the Doppler effect created by the rotors or propellers of the UAVs. Further, the method and system allow for tracking the UAVs based on the digital radar images.","['G01S7/417', 'B64C39/024', 'G01S13/72', 'G01S7/412', 'G01S7/415', 'G06V10/764', 'G06V10/82', 'G06V20/17', 'G06V20/54', 'G08G5/045', 'G08G5/80', 'B64U10/13', 'B64U2101/30']"
US9535563B2,Internet appliance system and method,"An Internet appliance, comprising, within a single housing, packet data network interfaces, adapted for communicating with the Internet and a local area network, at least one data interface selected from the group consisting of a universal serial bus, an IEEE-1394 interface, a voice telephony interface, an audio program interface, a video program interface, an audiovisual program interface, a camera interface, a physical security system interface, a wireless networking interface; a device control interface, smart home interface, an environmental sensing interface, and an environmental control interface, and a processor, for controlling a data transfer between the local area network and the Internet, and defining a markup language interface communicated through a packet data network interface, to control a data transfer or control a remote device.","['G06F3/048', 'G05B15/02', 'G06N5/025', 'G06Q30/02', 'G06Q30/0248', 'G06Q30/0255', 'G06Q30/0267', 'G06Q30/0269', 'G06Q30/0273', 'H04N21/4131', 'H04N21/42201', 'H04N21/44222', 'H04N21/44224', 'H04N21/4532', 'H04N21/47', 'H04N5/782', 'H04N5/913', 'G06N20/00', 'H04N2005/91328', 'H04N2005/91364']"
US11636288B2,"Platform, device and process for annotation and classification of tissue specimens using convolutional neural network","Embodiments described herein provide a platform, device and process for digital pathology that enable multi-level annotation and visualization of histopathologic slides using a modular arrangement of deep convolutional neural networks (CNNs). The CNNs can be trained using pathology images (e.g., in some cases increasing the base of data by breaking larger fields of view into smaller ones) to learn features consistent with certain pathologies. The platform can use the CNNs to visually annotate pathology slides at an interface tool of a display device. The platform can automate the process of selection, as well as provide an opportunity for the pathologist to see a depiction of predicted results. The platform can use the CNNs to identify regions of interest on pathology slides. The interface tool can enable a predicted region of interest (ROI) type to be visually presented on a surface map showing the basis of the prediction. If the ROI primarily lands in part of the hyperdimensional space not occupied by any training set, then the interface tool is capable of marking it as an ROI of unknown type.","['G06K9/6267', 'G06N3/08', 'G06F18/211', 'G06F18/214', 'G06F18/24', 'G06F18/2413', 'G06K9/6228', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06V10/25', 'G06V10/454', 'G06V10/764', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
US11568109B2,Experience learning in virtual world,A computer-implemented method of machine-learning is described that includes obtaining a dataset of virtual scenes. The dataset of virtual scenes belongs to a first domain. The method further includes obtaining a test dataset of real scenes. The test dataset belongs to a second domain. The method further includes determining a third domain. The third domain is closer to the second domain than the first domain in terms of data distributions. The method further includes learning a domain-adaptive neural network based on the third domain. The domain-adaptive neural network is a neural network configured for inference of spatially reconfigurable objects in a real scene. Such a method constitutes an improved method of machine learning with a dataset of scenes including spatially reconfigurable objects.,"['G06F30/27', 'G06F30/17', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/04', 'G06F2111/00', 'G06F2111/18', 'G06F30/12', 'G06N3/008', 'G06N3/0454', 'G06N3/047', 'G06N3/0472']"
CN113962988B,Power inspection image anomaly detection method and system based on federal learning,"The invention discloses a federal learning-based power inspection image anomaly detection method and a federal learning-based power inspection image anomaly detection system. The method comprises the following steps: the pre-trained abnormality detection model is adopted as a server initial model and distributed to all participants; the participants train based on the local power inspection image data set, and the cut gradient information is uploaded to the server; the server judges the data quality on the auxiliary model by using the verification set according to the gradient uploaded by each participant, and eliminates the participants with poor data quality based on the set threshold; weighting and aggregating the model gradients based on the data volume unbalance and the data quality index to obtain global gradient parameters, updating the anomaly detection global model, and then distributing the new model to each participant; and (5) circulating the steps until the global model converges. According to the method provided by the embodiment of the invention, the accuracy of the local power inspection image anomaly detection model of each participant can be improved.","['G06T7/0004', 'G06F21/602', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20132', 'Y04S10/50']"
US20240061832A1,Techniques for converting a natural language utterance to an intermediate database query representation,"Techniques are disclosed herein for converting a natural language utterance to an intermediate database query representation. An input string is generated by concatenating a natural language utterance with a database schema representation for a database. Based on the input string, a first encoder generates one or more embeddings of the natural language utterance and the database schema representation. A second encoder encodes relations between elements in the database schema representation and words in the natural language utterance based on the one or more embeddings. A grammar-based decoder generates an intermediate database query representation based on the encoded relations and the one or more embeddings. Based on the intermediate database query representation and an interface specification, a database query is generated in a database query language.","['G06F16/24522', 'G06F16/243', 'G06F16/2433', 'G06F16/24561', 'G06F40/186', 'G06F40/247', 'G06F40/253', 'G06F40/284', 'G06F40/30', 'G06F40/58', 'G06F40/40']"
US12175204B2,Aspect prompting framework for language modeling,"Techniques for dynamically developing a contextual set of prompts based on relevant aspects extracted from s set of training data. One technique includes obtaining training data comprising text examples and associated labels, extracting aspects from the training data, generating prompting templates based on the training data and the extracted aspects, concatenating each of the text examples with the respective generated prompting template to create prompting functions, training a machine learning language model on the prompting functions to predict a solution for a task, where the training is formulated as a masked language modeling problem with blanks of the prompting templates being set as text labels and expected output for the task being set as specified solution labels, and the training learns or updates model parameters of the machine learning language model for performing the task. The machine learning language model is provided with the learned or updated model parameters.","['G06F40/169', 'G06F40/186', 'G06F40/284', 'G06F40/40', 'G06N3/0455', 'G06N3/0475', 'G06N3/096', 'G06V30/19147']"
US11308401B2,Interactive reinforcement learning with dynamic reuse of prior knowledge,"Systems, methods, and computer readable media directed to interactive reinforcement learning with dynamic reuse of prior knowledge are described in various embodiments. The interactive reinforcement learning is adapted for providing computer implemented systems for dynamic action selection based on confidence levels associated with demonstrator data or portions thereof.","['G06N5/022', 'G06N3/006', 'G06F17/17', 'G06N20/00', 'G06N3/04', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N7/01', 'G06N3/045']"
US11442992B1,Conversational reasoning with knowledge graph paths for assistant systems,"In one embodiment, a method includes receiving a query from a user from a client system associated with the user, accessing a knowledge graph comprising a plurality of nodes and edges connecting the nodes, wherein each node corresponds to an entity and each edge corresponds to a relationship between the entities corresponding to the connected nodes, determining one or more initial entities associated with the query based on the query, selecting one or more candidate nodes by a conversational reasoning model from the knowledge graph corresponding to one or more candidate entities, respectively, wherein each candidate node is selected based on the nodes corresponding to the initial entities, dialog states associated with the query, and a context associated with the query, generating a response based on the initial entities and the candidate entities, and sending instructions for presenting the response to the client system in response to the query.","['G06Q50/01', 'G06F16/90332', 'G06F16/9024', 'G06N20/00', 'G06N3/0442', 'G06N3/049', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/022', 'G06N5/045', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
CN109190120B,Neural network training method and device and named entity identification method and device,"A neural network training method and device and a named entity recognition method and device are provided. A training method for a neural network for named entity recognition, wherein the neural network comprises a plurality of sub-neural networks, the training method comprising: acquiring labeling information of a first training text set and a plurality of named entity categories of the first training text set; inputting the first training text set into a neural network to obtain named entity identification information output by each sub-neural network, wherein each sub-neural network in the neural network corresponds to a plurality of named entity categories contained in the marking information of the first training text set one by one; for each sub-neural network, calculating the loss of the sub-neural network based on the labeling information of the named recognition category corresponding to the sub-neural network of the first training text set and the named entity recognition information output by the sub-neural network; and calculating the loss of the neural network according to the loss of each sub-neural network, and training the neural network according to the loss of the neural network.","['G06F40/295', 'G06N3/045']"
CN112786030B,A meta-learning-based adversarial sampling training method and device,"The invention discloses a countersampling training method and a device based on meta-learning, wherein the method comprises the following steps: outputting K-dimensional probability vectors from a large task set T consisting of K languages according to a policy network
Wherein the content of the first and second substances,
selecting the language with the maximum previous M probabilities according to the sampling probability for the sampling probability corresponding to the ith language task set, sampling one task according to each language in the language with the maximum previous M probabilities to form a training task set, and dividing the training task set into a support set and a query set; the support set carries out gradient descent on the initialization parameter theta of the voice recognition model to obtain an updated parameter
The query set updates the parameters according to the query
To obtain a query loss vector
The query loss vector
And optimizing the initialization parameter theta to obtain an optimal model parameter. Based on a multilingual meta-learning speech recognition framework, a strategy network is introduced to form confrontation training, so that the problem of unbalanced low-resource language recognition is solved, and the training effect is improved.","['G10L15/16', 'G06N3/045', 'G06N3/049', 'G06N3/08']"
US11586805B2,Machine-learning-based natural language processing techniques for low-latency document summarization,"Various embodiments of the present invention provide methods, apparatuses, systems, computing devices, and/or the like that are configured to effectively and efficiently generate one or more abstractive summaries of one or more multi-section documents. For example, certain embodiments of the present invention provide methods, apparatuses, systems, computing devices, and/or the like that are configured to generate an abstractive summary of a multi-section document comprising one or more sections, by generating one or more section summaries, section input batches for each selected section, model outputs created by one or more text summarization machine learning models through the performance of a batch processing operation sequence, abstractive summaries, and then storing the abstractive summaries.","['G06F40/166', 'G06F16/345', 'G06F40/284', 'G06F40/40', 'G06F40/216', 'G06F40/30', 'G06F40/56']"
US20230308465A1,System and method for dnn-based cyber-security using federated learning-based generative adversarial network,"The system comprises a FL-based generative adversarial network (GAN) for generating adversarial examples, wherein the GAN includes a generator for generating the adversarial examples and a discriminator for distinguishing the adversarial examples from the original data, wherein the FL network includes multiple clients, each having a local dataset and a local DNN model, and a central server for coordinating the training process; a DNN for classifying data, where the DNN is trained using the generated adversarial examples, wherein the training process includes exchanging the model updates between the client’s server and the central server; an evaluation module for measuring the adversarial accuracy and adversarial robustness of the DNN using appropriate metrics, including the adversarial accuracy, the adversarial loss, and the robustness to perturbations; and an adjustment module for adjusting the architecture or parameters of the DNN based on the evaluation results to improve its adversarial robustness.","['H04L63/1425', 'H04L63/205']"
CN110728654B,Automatic pipeline detection and classification method based on deep residual error neural network,"The invention discloses a method for automatically detecting and classifying pipelines based on a deep residual error neural network, which comprises the steps of expanding an image through a generating type countermeasure network to form an image set, building the deep residual error neural network containing N residual error modules through a M-layer model before migration learning based on the image set.","['G06T7/0004', 'G06F18/241', 'G06T2207/20081', 'G06T2207/20084']"
CN113704531B,"Image processing method, device, electronic equipment and computer readable storage medium","The application discloses an image processing method, an image processing device, electronic equipment and a computer readable storage medium, and relates to the technical fields of artificial intelligence, cloud technology and image processing, wherein the method comprises the steps of acquiring a first training data set and a second training data set, and pre-training an initial neural network model based on the first training data set to obtain a pre-trained neural network model; training the pre-trained neural network model based on the second training data set to obtain an image similarity model. According to the method, the first training data set is automatically determined by data augmentation on each initial image, so that a large number of training samples with similarity labeling results can be generated based on the first training data set, and data support is provided for training of the model. Furthermore, the second sample image set with the manual annotation and the similarity annotation result are more accurate, so that the image similarity model obtained based on the training of the second training data set is better in performance.","['G06F16/58', 'G06F18/214', 'G06F18/22', 'G06F18/24', 'G06N3/04', 'G06N3/08']"
US10902302B2,Stacked neural network framework in the internet of things,"A method for dividing, by a training system, a computational training work load of one or more neural network layers; pre-training the one or more neural network layers with a first class of image data sensitive to an original known dataset; generating a first weight file from the first layer of the neural network based on the first class of image data sensitive to the original known dataset; loading the one or more pre-trained neural network layers and the generated first weight file into at least one Internet of Things (IoT) device; stacking the one or more pre-trained neural network layers with the first layer of the neural network to form a new training system for an uploaded new dataset; adjusting the generated first weight file based on an input of one or more new classes of image data comprised in the uploaded new dataset to generate a new second weight file; inferencing an object class of new image data comprised on the uploaded new dataset using the generated new second weight file; and outputting the inferenced object class of the new image data.","['G06N3/063', 'G06K9/66', 'G06F18/24', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06V10/82', 'G06V30/19173', 'H04L67/12', 'H04W4/70', 'Y04S40/18']"
US10390170B1,Methods and apparatuses for implementing a head tracking headset,"Methods, apparatuses, and computer program products are provided in order to provide 3D audio playback using audio head-mounted devices. The apparatuses may be configured to receive at least one of position and orientation of a first head-mounted device in relation to a first user device, wherein the at least one of the position and orientation received is used to train a model using machine learning. At least one signal quality parameter may be determined based on input data and a filter pair may be determined corresponding with a direction to which a spatial audio signal is rendered based at least in part on the at least one signal quality parameter and the model so as to control spatial audio signal reproduction to take effect a change in the at least one of the position and orientation of the first head-mounted device during rendering of the spatial audio signal.","['G06N20/00', 'G06F3/012', 'G06F3/017', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'H04R5/033', 'H04S3/008', 'H04S7/304', 'H04R2420/07', 'H04S2400/11', 'H04S2420/01']"
CN111832513B,Real-time football target detection method based on neural network,"The invention discloses a real-time football target detection method based on a neural network, which mainly solves the problems of low speed and low precision of the existing football target detection. The scheme is as follows: 1) Obtaining a football target detection network YOLOv4; 2) Constructing a football target training data set; 3) The prior frame size of the constructed training data set is obtained, and the prior frame in the target detection network YOLOv4 is replaced by the prior frame size; 4) Performing data augmentation on the training data set; 5) Training a target detection network YOLOv4 by using the amplified data set; 6) And inputting the football target video to be detected into a trained YOLOv4 football target detection network for detection labeling, and outputting a football target detection result. The invention enhances the recognition and positioning capability of the network, improves the detection speed and precision of the football target, ensures the real-time property of football target detection, and can be used for man-machine interaction, sports events, live broadcast and motion analysis.","['G06V20/20', 'G06F18/23213', 'G06N3/045', 'G06N3/08', 'G06V2201/07', 'Y02T10/40']"
EP4451286A2,Managing respiratory conditions based on sounds of the respiratory system,"Among other things, sound records captured from a subject by auscultation at sound capture points on the subject are classified among sound classes. Respiratory conditions can be inferred from the sound records and other information. Information about the respiratory conditions can be presented to the subject or to a healthcare provider for purposes of managing the respiratory conditions.","['A61B5/08', 'A61B5/7207', 'A61B5/7246', 'A61B5/7267', 'A61B5/743', 'A61B5/7475', 'A61B7/003', 'G16H10/20', 'G16H40/67', 'G16H50/20', 'A61B5/742', 'G16H50/70']"
WO2022033048A1,"Video frame interpolation method, model training method, and corresponding device","A video frame interpolation method, a model training method, and a corresponding device. The video frame interpolation method comprises: acquiring a first video frame and a second video frame; utilizing, on the basis of the first video frame and the second video frame, a first neural network to calculate an optical flow between the first video frame and a first intermediate video frame and/or an optical flow between the second video frame and the first intermediate video frame; utilizing the optical flow between the first video frame and the first intermediate video frame to reverse map the first video frame to acquire a first mapped video frame, and/or, utilizing the optical flow between the second video frame and the first intermediate video frame to reverse map the second video frame to acquire a second mapped video frame; and determining the first intermediate video frame on the basis of the first mapped video frame and/or of the second mapped video frame. In the method, the accuracy of calculating the optical flow of an intermediate frame is increased; therefore, the image quality of the first intermediate video frame ultimately acquired is improved, and the efficiency of frame interpolation using the method is increased.","['H04N7/014', 'G06T7/248', 'G06T7/269', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
CN114603564B,"Robotic arm navigation obstacle avoidance method, system, computer equipment and storage medium","The invention belongs to the technical field of artificial intelligence, and discloses a mechanical arm navigation obstacle avoidance method, a system, computer equipment and a storage medium, wherein the method comprises the following steps: acquiring the current state tensor of the mechanical arm; inputting the current state tensor of the mechanical arm into a preset mechanical arm navigation obstacle avoidance depth reinforcement learning model to obtain a decision action track of the mechanical arm; the mechanical arm navigation obstacle avoidance depth reinforcement learning model is constructed based on an initial mechanical arm navigation obstacle avoidance depth reinforcement learning model obtained by pre-training under a simulated learning environment with a navigation planning algorithm as priori guidance; and controlling the mechanical arm to run according to the decision motion track of the mechanical arm. Based on the navigation planning algorithm, the model has certain basic implicit knowledge, can adapt to different types of obstacle environments, can be quickly trained and smoothly moved to the actual environment for use, avoids the construction of a complex rewarding system, greatly improves the training speed and reduces the resource consumption.","['B25J9/1676', 'B25J9/1666']"
US20230325711A1,Methods and systems for updating machine learning models,"Methods (1100) and systems (800) for updating ML models. The method is performed by a client computing device (704(1)). In one aspect, the method comprises obtaining (s1102) a first machine learning (ML) model. The first ML model is configured to receive input data set and to generate first output data set. The method further comprises training (s1104) a second ML model 5 based at least on the input data set and the first output data set, obtaining (s1106), as a result of training the second ML model, a third ML model, and deploying the third ML model.","['H04W52/0216', 'G06N20/00', 'G06N3/084', 'G06N5/02', 'H04W16/22', 'H04W52/0245', 'Y02D30/70']"
US11521487B2,System and method to generate traffic congestion estimation data for calculation of traffic condition in a region,"A system, a method, and a computer program product may be provided for generating traffic congestion estimation data of one or more lanes in a region. A system may include a memory configured to store computer program code and a processor configured to execute the computer program code to obtain image data associated with the region. The processor may be configured to determine a count of one or more first movable objects in one or lanes, based on image data, calculate a lane object static capacity of the one or more lanes, based on one or more map free flow or speed limit attributes associated with the one or more lanes and generate the traffic congestion estimation data based on count of first movable objects in the one or more lanes, the moving speed of movable objects crossing multiple image frames, the lane object static capacity of lanes.","['G08G1/0116', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V20/584', 'G06V20/588', 'G08G1/0112', 'G08G1/012', 'G08G1/0133', 'G08G1/0141', 'G08G1/04', 'G08G1/052', 'G08G1/096775', 'G06V2201/08']"
US11714831B2,Data processing and classification,"The present invention discloses a method, a system and a computer program product for data processing and classification. The invention provides warm start and cold start classification tools for classification of data obtained from known or unknown entities. The system and method are also configured to be employed over blockchain based networks.","['G06F16/285', 'G06F16/212', 'G06F16/2379', 'G06F16/2393', 'G06F16/258', 'G06F16/288', 'G06F16/9024', 'G06F18/217', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G06V10/82', 'G06V30/147', 'G06V30/19147', 'G06V30/1916', 'G06V30/19173', 'G06V30/40', 'G06N3/048', 'G06V2201/09', 'G06V30/10']"
CN109523018B,Image classification method based on deep migration learning,"The invention requests to protect a picture classification method based on deep migration learning, wherein the field is adapted to data at least comprising two fields, namely a source field and a target field, and the source field data is marked sample data; step 4) training phase, carrying out field marking on the source domain and target domain samples, setting a loss function based on sample migration weight, and step 5) predicting phase, predicting the target domain data, and taking the category prediction result as a final result.","['G06N3/045', 'G06F18/00']"
CN111126386B,Adversarial Learning-Based Sequential Domain Adaptation in Scene Text Recognition,"The invention belongs to the technical field of artificial intelligence, and particularly relates to a field adaptation method based on a text recognition task of a machine vision scene. The method comprises the following steps: constructing a CNN-LSTM network and an attention network; combining the two into a scene text recognition network; inputting scene images of a source domain and a target domain into a scene text recognition network, extracting image features from the input scene images by CNN-LSTM, recoding the image features by an attention network, extracting corresponding features of each character, and realizing segmentation of text information in the images into character level information; and finally, constructing a domain classification network by using a transfer learning technology based on countermeasure learning, and forming a countermeasure generation network together with a scene text recognition network, so that the model can be effectively adapted to a target domain. According to the invention, a small amount of target domain calibration samples are fully utilized, the problem of sample scarcity frequently occurring in an actual scene text recognition task is solved, and the recognition effect is improved.","['G06V20/63', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V30/10', 'Y02T10/40']"
US20240153590A1,Natural language processing to predict properties of proteins,"A protein language natural language processing (NLP) system is trained to predict specific biophysiochemical properties. Amino acids of proteins are tokenized and masked. A first neural network is trained on a library of amino acid sequences in an unsupervised or self-supervised manner. The information obtained from the first phase of training is applied in a subsequent training operation via transfer learning, to a second neural network. In aspects, an annotated compact dataset is used to fine-tune the second neural network in a second phase of training, and in a supervised manner, to predict biophysiochemical properties of proteins, including TCR-epitope binding.","['G16B15/30', 'G16B40/20', 'G06F40/284', 'G06F40/30', 'G06F40/40', 'G06N3/044', 'G06N3/045', 'G06N3/088', 'G16B15/20', 'G16B35/10']"
CN111860485B,"Training method of image recognition model, image recognition method, device and equipment","The application discloses a training method of an image recognition model, an image recognition method, an image recognition device and image recognition equipment, wherein the method is applied to an artificial intelligence computer vision technology. The method comprises the following steps: acquiring training data; obtaining a basic model, wherein the basic model comprises an encoder and a decoder, the encoder comprises n convolution modules which are sequentially connected, and n is an integer greater than 1; and training a basic model by using training data according to an attention self-supervision mechanism constructed on the encoder to obtain an image recognition model, wherein the attention self-supervision mechanism is used for supervising and adjusting the ith convolution module according to the ith+1th characteristic image output by the ith+1th convolution module in the n convolution modules, and i is an integer larger than 0 and smaller than n. The method can reduce the computational complexity of identifying the target area in the image by using the convolution network.","['G06V10/22', 'G06N3/045', 'G06N3/08', 'G06V10/26']"
US11645548B1,Automated cloud data and technology solution delivery using machine learning and artificial intelligence modeling,"A method includes receiving first input, analyzing the first input using a first model, receiving second input, analyzing the second input using a second model; and generating infrastructure-as-code. A computing system includes a processor; and a memory comprising instructions, that when executed, cause the computing system to: receive first input, analyze the first input using a first model, receive second input, analyze the second input using a second model; and generate infrastructure-as-code. A non-transitory computer-readable storage medium storing executable instructions that, when executed by a processor, cause a computer to: receive first input, analyze the first input using a first model, receive second input, analyze the second input using a second model; and generate infrastructure-as-code.","['G06N3/08', 'G06N5/022', 'G06N20/00', 'G06N3/0464', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N3/098']"
WO2025042780A1,Systems for controllable summarization of content,A method of generating summaries of content items using one or more large language models (LLMs) is disclosed. A first content item is identified. The first content item includes a set of sub-content items. A level of abstraction is determined for the content item. A prompt is automatically engineered for providing to the one or more LLMs. The prompt includes a reference to the first content item and the level of the abstraction for the first content item. A response to the prompt is received from the LLM. The response includes a second content item. The second content item includes a representation of the first content item that is generated by the LLM. The representation omits or simplifies one or more of the set of sub-content items based on the level of abstraction. The representation is used to control an output that is communicated to a target device.,"['G06F40/56', 'G06F16/345']"
CN110008399B,"Recommendation model training method and device, and recommendation method and device","The method for training the recommendation model comprises the steps of obtaining user characteristics of at least two sample users and attribute characteristics of at least two sample application programs; generating a positive sample clicked and purchased by the sample user on the exposed sample application program and a negative sample clicked but not purchased or clicked by the sample user on the exposed sample application program based on the user characteristics and the attribute characteristics; training a recommendation model based on a sample set comprising at least one positive sample and one negative sample to obtain the recommendation model, wherein the recommendation model outputs exposure conversion rate obtained by each sample user based on click rate and purchase rate of each exposed sample application program.","['G06F16/9535', 'G06F18/214']"
US20220114711A1,Systems and methods for deep learning microscopy,"A microscopy method includes a trained deep neural network that is executed by software using one or more processors of a computing device, the trained deep neural network trained with a training set of images comprising co-registered pairs of high-resolution microscopy images or image patches of a sample and their corresponding low-resolution microscopy images or image patches of the same sample. A microscopy input image of a sample to be imaged is input to the trained deep neural network which rapidly outputs an output image of the sample, the output image having improved one or more of spatial resolution, depth-of-field, signal-to-noise ratio, and/or image contrast.","['G06T3/4046', 'G06T5/50', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T3/4053', 'G06T3/4076', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T5/92', 'G06T7/0014', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
CN112507898B,A Multimodal Dynamic Gesture Recognition Method Based on Lightweight 3D Residual Network and TCN,"The invention provides a multi-modal dynamic gesture recognition method based on a lightweight 3D residual error network and a TCN. Firstly, sampling original videos in a data set, and sequencing and storing the videos according to a time sequence; then, pre-training a lightweight 3D residual error network by using a large public gesture recognition data set, and storing a weight file of the model; then, long-short term spatio-temporal features are extracted using the RGB-D image sequence as input and the lightweight 3D residual network and the time convolution network as base models, and information of the multiple modalities is fused by weighting using an attention mechanism. Wherein, RGB and Depth (Depth) sequences are respectively input into the same network structure; and finally, classifying by using a full connection layer, calculating a loss value by adopting a cross entropy loss function, and using the accuracy and the F1Score as evaluation indexes of the network model. The invention can achieve higher classification accuracy and has the advantage of low parameter quantity.","['G06V40/107', 'G06F18/241', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06V40/28']"
US9990564B2,System and method for optical character recognition,"This disclosure relates to system and method for optical character recognition. In one embodiment, the method comprises providing an image data to a plurality of customized machine learning algorithms or various customized neural networks, configured to recognize a set of pre-defined characters. The method comprises presenting one or more suggestions for the character to the user in response to negative character recognition, and training a customized machine learning algorithm corresponding to the character if one of the suggestions is identified by the user. If the suggestions are rejected by the user, the method comprises prompting the user to identify the character and determining presence of the character in the set of pre-defined characters. The method further comprises training a customized machine learning algorithm corresponding to the character if the character is present, or dynamically creating a customized machine learning algorithm corresponding to the character if the character is not present.","['G06K9/6212', 'G06V30/19167', 'G06F18/2178', 'G06F18/2433', 'G06F18/41', 'G06K9/033', 'G06K9/66', 'G06V30/19133', 'G06K2209/01', 'G06V30/10']"
US11875787B2,Synthetic data generation for training of natural language understanding models,This document relates to machine learning. One example includes a method or technique that can be performed on a computing device. The method or technique can include obtaining a task-semantically-conditioned generative model that has been pretrained based at least on a first training data set having unlabeled training examples and semantically conditioned based at least on a second training data set having dialog act-labeled utterances. The method or technique can also include inputting dialog acts into the semantically-conditioned generative model and obtaining synthetic utterances that are output by the semantically-conditioned generative model. The method or technique can also include outputting the synthetic utterances.,"['G10L15/063', 'G10L15/18', 'G06F40/216', 'G06F40/284', 'G06F40/30', 'G06F40/44', 'G06F40/56', 'G10L15/083', 'G10L15/22', 'G10L15/1822']"
US20230260535A1,A computer-implemented method of providing data for an automated baby cry assessment,"A computer-implemented method of providing data for an automated baby cry assessment is suggested, comprising the steps of acoustically monitoring a baby and providing a corresponding stream of sound data, detecting a cry in the stream of sound data, selecting cry related data from the sound data in response to the detection of a cry, determining personal baby data for a personalized cry assessment, preparing an assessment stage for assessment according to personal baby data, and feeding cry related data into the cry assessment stage prepared according to personal baby data. Furthermore, an automated baby cry assessment arrangement is suggested.","['G10L25/63', 'G10L25/18', 'G10L25/84']"
WO2022141878A1,"End-to-end language model pretraining method and system, and device and storage medium","An end-to-end language model pretraining method and system, and a device and a storage medium. The method comprises: according to a preset knowledge similarity determination rule, retrieving, from an existing knowledge base, existing knowledge segments similar to an inputted knowledge segment in knowledge (101); splicing the inputted knowledge segment and the retrieved existing knowledge segments to obtain a spliced knowledge segment (102); performing mask processing on the spliced knowledge segment (103); and using the masked spliced knowledge segment as an input of language model pretraining to perform prediction training, and completing end-to-end language model pretraining (104). In the method, the preset similarity determination rule is used, retrieval of similar existing knowledge segments is performed in the existing knowledge base by means of retrieval, and the requirement of the model for parameters during training is reduced, such that the language model can enhance utilization of external knowledge on the basis of retrieval, and the efficiency of language model training is improved.","['G06F16/3344', 'G06F18/214', 'G06F18/2411']"
CN111143536B,"Information extraction method based on artificial intelligence, storage medium and related device","The embodiment of the invention discloses an information extraction method based on artificial intelligence, a storage medium and a related device, which are applied to the technical field of information processing of the artificial intelligence. The information extraction device is used for determining relation attributes contained in short texts according to a preset relation classification model aiming at each short text in the to-be-processed document, and then extracting entity pairs corresponding to the relation attributes according to a preset entity extraction model so as to form triple information corresponding to each short text. Practice proves that the triple information of the document to be processed can be accurately obtained by respectively determining the relation attribute and the corresponding entity pair through different machine learning models, and the transfer learning can be performed because the machine learning models are adopted for information extraction.","['G06F16/3329', 'G06F16/35', 'G06N20/00']"
CN109447018B,A road environment visual perception method based on improved Faster R-CNN,"A road environment visual perception method based on improved Faster R-CNN. Aiming at the high-precision requirement of target detection and identification in a complex road scene, the invention provides an improved Faster R-CNN algorithm based on multi-GPU training. The algorithm of the invention uses a multi-GPU parallel training method to improve the training efficiency; a ResNet-101 feature extraction network is adopted to improve the target detection precision; reducing the missing rate by adopting a Soft-NMS algorithm; meanwhile, OHEM is introduced into ROI NetWork to reduce the false alarm rate; in order to perfect the target detection effect of the algorithm in rainy, snowy and haze weather, the model is trained by combining an internationally recognized automatic driving data set KITTI and an Oxford RobotCar. Experimental results prove that compared with the Faster R-CNN, the algorithm provided by the invention has the advantages that the training speed and the detection precision are obviously improved, and the algorithm has good generalization capability and stronger practicability particularly in an automatic driving scene.","['G06V20/58', 'G06F18/214', 'G06V20/584']"
CN113673248B,Named entity identification method for testing and identifying small sample text,"The invention discloses a named entity recognition method for a small sample text for experimental identification, which comprises the following specific steps of carrying out a contrast experiment, and constructing a baseline model for entity recognition according to an experiment result; improving the baseline model to obtain an entity recognition model; the entity recognition model comprises a text pre-training model, a coding model and a decoding model which are connected in sequence; the entity recognition model is used for recognizing the entity, classifying the recognition error conditions, summarizing and carrying out semantic analysis, making a semantic correction rule aiming at the error conditions, and constructing a semantic correction rule module to realize semantic correction of the recognition result of the entity recognition model. Aiming at the problems of complex entity structure, long entity length, entity doping irrelevant noise and the like in specific fields such as test identification and the like, the method carries out classified statistical analysis on the error result of multi-model neural network identification, and works out a plurality of correction rules to correct the fusion result.","['G06F40/295', 'G06F18/214', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
CN110782870B,"Speech synthesis method, device, electronic equipment and storage medium","The application discloses a voice synthesis method, a device, electronic equipment and a storage medium, which relate to an artificial intelligence technology and utilize a machine learning technology in the artificial intelligence to carry out voice synthesis, wherein the method comprises the following steps: obtaining word segmentation sequences corresponding to input texts; determining a vector sequence corresponding to the word segmentation sequence by using a trained language characterization model based on an attention mechanism; performing prosodic structure prediction processing on the vector sequence by utilizing a prosodic structure model to determine prosodic structure information, wherein the prosodic structure information comprises pause time and pronunciation weight corresponding to word segmentation fragments corresponding to each feature vector in the vector sequence in the synthesized voice; and synthesizing the voice corresponding to the input text according to the prosodic structure information and the pronunciation corresponding to each word segmentation segment in the word segmentation sequence. According to the voice synthesis method, the voice synthesis device, the electronic equipment and the storage medium, based on the vector sequence obtained by the language characterization model, accurate and real semantics of an input text can be expressed, so that the synthesized voice can be heard more naturally.","['G10L13/08', 'G10L13/10', 'G10L15/1807', 'G10L15/1822', 'Y02T10/40']"
US12124147B2,Control methods and systems using external 3D modeling and neural networks,A system for controlling tinting of one or more zones of windows in a building based on predictions of future environmental conditions.,"['E06B9/24', 'G02F1/163', 'G05B19/048', 'E06B2009/2464', 'G02B5/20']"
CN105608450B,Heterogeneous face identification method based on depth convolutional neural networks,"The invention discloses a kind of heterogeneous face identification methods based on depth convolutional neural networks.This method is by carrying out identical pretreatment to visible light, near-infrared-visible images；With pretreated visible images to depth convolutional neural networks pre-training, priori knowledge is provided for the depth convolutional neural networks training of heterogeneous image；Near-infrared and visible images are constituted into triple according to certain rule, and the more indistinguishable difficult triple of the heterogeneous picture depth convolutional neural networks for picking out pre-training；Heterogeneous picture depth convolutional neural networks after the difficult triple input pre-training that will be singled out carry out accurate adjustment, difficult ternary group selection, the accurate adjustment process to heterogeneous picture depth convolutional neural networks performance of iterating no longer are promoted, and trained heterogeneous picture depth convolutional neural networks model is utilized to carry out heterogeneous recognition of face later.The present invention has been obviously improved heterogeneous face recognition accuracy rate, can be effectively relieved small-scale data convolutional neural networks training in easy over-fitting the problem of.",['G06V40/16']
US11714397B2,System and method for generating machine learning model with trace data,A method for detecting a fault includes: receiving a plurality of time-series sensor data obtained in one or more manufacturing processes of an electronic device; arranging the plurality of time-series sensor data in a two-dimensional (2D) data array; providing the 2D data array to a convolutional neural network model; identifying a pattern in the 2D data array that correlates to a fault condition using the convolutional neural network model; providing a fault indicator of the fault condition in the one or more manufacturing processes of the electronic device; and determining that the electronic device includes a fault based on the fault indicator. The 2D data array has a dimension of an input data to the convolutional neural network model.,"['G09G3/006', 'G05B23/0221', 'G05B23/024', 'G05B19/4063', 'G01M11/00', 'G05B19/41875', 'G05B23/0243', 'G05B23/0272', 'G05B23/0275', 'G05B23/0281', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G01N2021/8887', 'G05B2219/32222', 'G05B2219/34477', 'Y02P90/02']"
US11798164B2,Artificial intelligence for evaluation of optical coherence tomography images,"A neural network is trained to segment interferogram images. A first plurality of interferograms are obtained, where each interferograms corresponds to data acquired by an OCT system using a first scan pattern, annotating each of the plurality of interferograms to indicate a tissue structure of a retina, training a neural network using the plurality of interferograms and the annotations, inputting a second plurality of interferograms corresponding to data acquired by an OCT system using a second scan pattern and obtaining an output of the trained neural network indicating the tissue structure of the retina that was scanned using the second scan pattern. The system and methods may instead receive a plurality of A-scans and output a segmented image corresponding to a plurality of locations along an OCT scan pattern.","['G16H50/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T3/00', 'G06T7/0012', 'G06T7/11', 'G06V10/26', 'G06V10/7747', 'G16H20/40', 'G16H30/40', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06V10/82', 'G06V2201/03']"
CN118739184B,A method for automatic fault detection and repair of self-healing intelligent power lines,"The invention discloses a fault automatic detection and repair method of a self-healing intelligent power line, which comprises the steps of carrying out cluster analysis on fault sensor data by adopting a K-Means clustering algorithm, determining a fault frequent area, then carrying out feature extraction and matching analysis on line layout images and parameter data by adopting a convolution neural network model fused by heterogeneous data aiming at line equipment parameters and electrical parameters in a local repair section, judging the compatibility of a local repair scheme and an original line plan, carrying out real-time analysis on the data by adopting a least square support vector machine model in the local repair construction process, carrying out live debugging and comprehensive evaluation on the reconstructed local line to judge whether a reconstruction effect meets the construction standard of the self-healing intelligent power line, carrying out prediction reasoning on the health state and fault risk of the equipment by adopting a long-short-period memory network model driven by a knowledge graph, and automatically generating state maintenance and fault emergency repair strategies to realize the self-healing operation of the local line.","['G01R31/088', 'G01R31/085', 'G06F18/23213', 'G06N3/0442', 'G06N3/0464', 'G06N3/096', 'G06Q10/20', 'G06Q50/06', 'H02H3/066', 'H02H7/26', 'Y04S10/50']"
US20180247549A1,Deep academic learning intelligence and deep neural language network system and interfaces,"A knowledge acquisition system and artificial cognitive declarative memory model to store and retrieve massive student learning datasets. A Deep Academic Learning Intelligence system for machine learning-based student services provides monitoring and aggregating performance information and student communications data in an online group learning course. The system uses communication activity, social activity, and the academic achievement data to present a set of recommendations and uses responses and post-recommendation data as feedback to further train the machine learning-based system.","['G09B5/02', 'G06F40/30', 'G06N3/08', 'G06N3/084', 'G06N7/005', 'G06N7/01', 'G09B19/00', 'G09B7/02', 'G09B7/06']"
CN110850983B,Virtual object control method and device in video live broadcast and storage medium,"The application relates to a virtual object control method, a device and a storage medium in video live broadcast, wherein the method comprises the following steps: sending a live video stream generated by a first terminal on a live page to a second terminal; when a triggering condition of the virtual object collaborative live broadcast is met, displaying the virtual object on the live broadcast page, and triggering the second terminal to synchronously display the virtual object on a watching page for playing the live broadcast video stream; acquiring a control instruction for the virtual object, wherein the control instruction is triggered by the interaction of at least one of the first terminal and the second terminal for the virtual object; and triggering the virtual object to execute a corresponding interactive action according to the control instruction, and triggering the second terminal to execute the interactive action. The scheme provided by the application can improve the control flexibility of the virtual object.","['G06F3/011', 'H04N21/8166']"
US11410044B2,Application development platform and software development kits that provide comprehensive machine learning services,"The present disclosure provides an application development platform and associated software development kits (“SDKs”) that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (“API”) that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.","['G06N3/084', 'G06F18/214', 'G06F8/76', 'G06F9/541', 'G06K9/6256', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/098']"
CN113591766B,Multi-source remote sensing tree species identification method for unmanned aerial vehicle,"The invention discloses a tree species identification method for multi-source remote sensing of an unmanned aerial vehicle, which comprises the steps of obtaining a visible light image and a laser radar point cloud, and respectively preprocessing the laser radar point cloud and the visible light image; detecting the crown height model of the laser radar point cloud by a local maximum method, and then segmenting the crown by a watershed method to obtain a segmented crown boundary; taking the boundary of the divided tree crown as an outer boundary, and taking a visible light forward projection image brightness value and a laser radar Canopy Height Model (CHM) as characteristics to obtain a tree crown data set and a sample data set; and performing migration learning and ensemble learning on the crown data set and the sample data set through a convolutional neural network, and outputting a tree species identification result. The method comprehensively applies the visible light remote sensing image and the laser radar point cloud of the unmanned aerial vehicle, adopts the deep CNN model for transfer learning, inputs the deep convolutional neural network for transfer learning and integrated learning to carry out tree species identification, and increases the accuracy of the unmanned aerial vehicle remote sensing tree species identification.","['G01S17/88', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
WO2020215593A1,Artificial intelligence-based automatic evaluation method and system on quality check of gastrointestinal endoscopy,"Disclosed are an artificial intelligence-based automatic evaluation method and system on the quality check of a gastrointestinal endoscopy, aimed at accurately, comprehensively and rapidly evaluating the quality check of the gastrointestinal endoscopy in medical institutions, and providing a feasible supervision basis for improving the quality of the gastrointestinal endoscopy. The quality check of gastrointestinal endoscopy diagnosis and treatment institutions is evaluated and displayed. On one hand, the current operant level of a physician is quantitatively expressed objectively and directly, thereby encouraging endoscopists to learn from each other to continously improve the operant level; on the other hand, a superior medical management platform is allowed to comprehensively and accurately obtain the quality reports of gastrointestinal endoscopy diagnosis and treatment institutions within its jurisdiction and to perform quality control timely.","['G06F18/214', 'G06N3/045', 'G06Q10/04', 'G06Q10/06393', 'G06Q10/06395', 'G16H30/20']"
CN112215004B,Application method of transfer learning-based text entity extraction in military equipment,"The invention provides an application method of transition learning-based text entity extraction of military equipment, which comprises the following steps: step 1, establishing a network model for boundary extraction and text segment classification as a skeleton model for text entity extraction, and effectively overcoming the difference of network structures caused by different types of entity extraction in different fields; step 2, analyzing source field data, constructing a source field problem set, and realizing task adaptation; step 3, realizing field adaptation by using a language model based on a mask; and step 4, applying the model for completing the field adaptation and the task adaptation to the target field, and completing the extraction of the military equipment text information. The invention effectively overcomes the difference of network structures caused by different types of extraction entities in different fields; the invention fully utilizes the existing open source sequence labeling data, trains a named entity recognition model on the basis, applies learned knowledge to the target field, and effectively reduces the data labeling work of the target field.","['G06F40/295', 'G06F18/214', 'G06F18/2415', 'G06F40/289']"
US10726207B2,Exploiting document knowledge for aspect-level sentiment classification,"Methods, systems, and computer-readable storage media for receiving a set of document-level training data including a plurality of documents, each document having a sentiment label associated therewith, receiving a set of aspect-level training data including a plurality of aspects, each aspect having a sentiment label associated therewith, training the aspect-level sentiment classifier including a long short-term memory (LSTM) network, and an output layer using one or more of pretraining, and multi-task learning based on the document-level training data and the aspect-level training data, pretraining including initializing parameters based on pretrained weights that are fine-tuned during training, and multi-task learning including simultaneous training of document-level classification and aspect-level classification, and providing the aspect-level sentiment classifier for classifying one or more aspects in one or more sentences of one or more input documents based on sentiment classes.","['G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/02']"
WO2021159613A1,"Text semantic similarity analysis method and apparatus, and computer device","The present application relates to the technical field of computers. Disclosed in the present application are a text semantic similarity analysis method and apparatus, and a computer device, which can solve the problems that when similarity analysis is carried out on short text in a target domain, short text similarity data is difficult to obtain and label, a short text similarity algorithm effect is easily affected by the data labeling quality, so that a calculation result is unstable. The method comprises: obtaining a universal data set and a target domain data set; training a semantic similarity recognition model by taking the universal data set as a training sample; adjusting the semantic similarity recognition model by using the target domain data set as a transfer learning sample; inputting target short text to be subjected to semantic similarity recognition into the adjusted semantic similarity recognition model to obtain semantic similarity; and determining a semantic similarity recognition result on the basis of the semantic similarity. The present application is suitable for analyzing text semantic similarity in a target domain.","['G06F16/3344', 'G06N3/044', 'G06N3/045']"
CN112735535B,"Prediction model training method, prediction model training device, data prediction method, data prediction device and storage medium","The application relates to a prediction model training method, a prediction model training device, computer equipment and a storage medium. The method comprises the following steps: acquiring a training sample set, wherein the training sample set comprises training samples, training sample weights corresponding to the training samples and target energy characteristics corresponding to the training samples; determining a current training sample from a set of training samples based on training sample weights; inputting current target energy characteristics corresponding to a current training sample into a pre-training prediction model for basic training, and obtaining a basic prediction model when the basic training is completed; and updating the training sample weight corresponding to each training sample based on the basic prediction model and performing iteration until model training is completed to obtain a target prediction model, wherein the target prediction model is used for predicting interaction state information corresponding to the input protein information and the input compound information. By adopting the method, the prediction accuracy of the target prediction model obtained by training can be improved.","['G16B40/00', 'G16B15/00', 'G16B15/30', 'G06N20/00', 'G06N20/20', 'G06N5/01', 'G06N5/022', 'G16B20/50', 'G16B40/20']"
CN114332984B,"Training data processing method, device and storage medium","The application provides a training data processing method, a training data processing device and a training data processing storage medium, relates to the technical field of artificial intelligence, and can be applied to various scenes such as cloud technology, artificial intelligence, intelligent traffic, auxiliary driving and the like, and comprises the following steps: obtaining a pre-training regression model and an initial training set; obtaining clustering results corresponding to each sample data in the candidate data set by using a pre-training regression model; based on the initial training set and the second loss function, updating and constraint training is carried out on the pre-training regression model to obtain an intermediate model, and the intermediate model is utilized to obtain the prediction confidence coefficient of each sample data in the first difference set; based on the prediction confidence and the clustering result, sampling data of sample data in the first difference set; further, the initial training set is updated by using the obtained incremental training set; and performing loop iteration based on the updated initial training set, and taking the initial training set obtained when the iteration ending condition is met as a target training set. The method and the device effectively improve the effectiveness of training data.",[]
US12197486B2,Automatic labeling of text data,"The technology described herein determines whether a candidate text is in a requested class by using a generative model that may not be trained on the requested class. The present technology may use of a model trained primarily in an unsupervised mode, without requiring a large number of manual user-input examples of a label class. The may produce a semantically rich positive example of label text from a candidate text and label. Likewise, the technology may produce from the candidate text and the label a semantically rich negative example of label text. The labeling service makes use of a generative model to produce a generative result, which estimates the likelihood that the label properly applies to the candidate text. In another aspect, the technology is directed toward a method for obtaining a semantically rich example that is similar to a candidate text.","['G06F16/3346', 'G06F16/383', 'G06F16/313', 'G06F16/332', 'G06F16/3344', 'G06F16/35', 'G06F16/953', 'G06F40/30', 'G06N3/045', 'G06N3/0475', 'G06N3/096']"
US11664110B2,"System, method and portable devices for detection and enhancement of sleep spindles",A method for administering stimulations to a sleeping subject is provided. The method includes obtaining brain wave data generated based on brain wave activity of the subject over a predetermined time frame and determining a spectral power ratio of a spindle band to delta and theta bands of the brain wave data at a time within the predetermined time frame. The spectral power ratio and brain wave data are sent to the input of a pretrained deep neural network to generate a probability score that sleep spindles are being detected in the brain wave activity. The method may continue to obtain brain wave data and analyze the data using the pretrained deep neural network. A determination that sleep spindles are detected may be made when the probability score is above a predetermined threshold score for a predetermined threshold period of time.,"['G16H20/70', 'G16H50/30', 'A61B5/4815', 'A61B5/7264', 'G06F3/015', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G16H20/30', 'G16H40/63', 'G16H50/20', 'A61B5/377', 'G06F2203/011']"
US10796134B2,Long-tail large scale face recognition by non-linear feature level domain adaptation,"A computer-implemented method, system, and computer program product are provided for facial recognition. The method includes receiving, by a processor device, a plurality of images. The method also includes extracting, by the processor device with a feature extractor utilizing a convolutional neural network (CNN) with an enlarged intra-class variance of long-tail classes, feature vectors for each of the plurality of images. The method additionally includes generating, by the processor device with a feature generator, discriminative feature vectors for each of the feature vectors. The method further includes classifying, by the processor device utilizing a fully connected classifier, an identity from the discriminative feature vector. The method also includes control an operation of a processor-based machine to react in accordance with the identity.","['G06K9/00288', 'G06V10/82', 'G06F18/2135', 'G06F18/214', 'G06F18/217', 'G06F18/2411', 'G06F18/24133', 'G06K9/00261', 'G06K9/00268', 'G06K9/6247', 'G06K9/6256', 'G06K9/6262', 'G06K9/6269', 'G06K9/6271', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06Q20/40145', 'G06Q30/0281', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V40/167', 'G06V40/168', 'G06V40/172', 'G08B13/196', 'G08B15/007', 'H04N7/183', 'H04N7/185']"
CN111767228B,"Interface testing method, device, equipment and medium based on artificial intelligence","The application relates to artificial intelligence and provides an interface testing method, device, equipment and medium based on the artificial intelligence. The method comprises the following steps: receiving an interface test request for an interface to be tested; acquiring an interface image to be tested corresponding to the interface to be tested according to the interface test request; dividing an interface image to be tested to obtain elements to be tested; identifying element types of elements to be tested, and searching operation actions corresponding to the element types from a preset database; executing operation actions on the corresponding elements to be tested on the interface to be tested to obtain corresponding operation results; and generating a test report corresponding to the interface to be tested according to the operation result. The method can improve the efficiency of interface test. In addition, the present invention relates to blockchain technology, and privacy information such as test reports can be stored in blockchain nodes.","['G06F11/3672', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'Y02D10/00']"
CN111275057B,"Image processing method, device and equipment","The invention provides an image processing method, device and equipment, wherein the method comprises the following steps: acquiring a first input image and a second input image; extracting content features of the first input image; extracting attribute features of the second input image; performing feature mapping on the extracted content features of the first input image and the extracted attribute features of the second input image to obtain target image features; and generating an output image based on the target image features. The invention introduces the feature conversion network and trains the whole image processing system in stages, so that the image processing system trains efficiently and quickly, has wide applicability and generates the output image more similar to the expected attribute while maintaining the content information.","['G06V10/7747', 'G06T11/00', 'G06V10/462', 'G06F18/213', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/761', 'G06V10/7715', 'G06V10/776', 'G06V10/806', 'G06V10/82']"
US11461519B2,Machine learning techniques for estimating mechanical properties of materials,"Methods and apparatus for extracting one or more mechanical properties for a material based on one or more indentation parameters for the material. The method comprises receiving load-displacement data from one or more instrumented indentation tests on the material, determining, by at least one computer processor, the indentation parameters for the material based, at least in part, on the received load-displacement data, providing as input to a trained neural network, the indentation parameters for the material, determining, based on an output of the trained neural network, the one or more mechanical properties of the material, and displaying an indication of the determined one or more mechanical properties of the material to a user of the computer system.","['G06N3/08', 'G06F30/27', 'B29C64/386', 'B33Y50/00', 'G06F30/17', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G01N2203/0218', 'G01N3/42', 'G06N3/048']"
US20230267285A1,Using one or more neural networks to perform text translation,"Apparatuses, systems, and techniques to translate a text string. In at least one embodiment, a text string is translated by at least, for example, using one or more neural networks to determine a length of a translated text string before a text string is to be translated.","['G06F40/58', 'G06F40/44', 'G06F40/166', 'G06F40/211', 'G06F40/263', 'G06F40/289', 'G06F40/30', 'G06N3/04', 'G06N3/0455', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06F40/51', 'G06N3/0464', 'G06N3/088', 'G06N3/09']"
CN110223292B,"Image evaluation method, device and computer readable storage medium","The embodiment of the application provides an image evaluation method, an image evaluation device and a computer-readable storage medium, and relates to the technical field of image processing. The image evaluation method comprises the steps of obtaining an image to be evaluated; calculating the image to be evaluated based on a preset image evaluation model to obtain the grading distribution information of the image to be evaluated; and calculating to obtain an image evaluation value corresponding to the image to be evaluated according to the grading distribution information. The method and the device can effectively improve the accuracy of the image evaluation result.","['G06T7/0002', 'G06T2207/20081', 'G06T2207/20084']"
US11391819B2,Object verification using radar images,"Techniques and systems are provided for performing object verification using radar images. For example, a first radar image and a second radar image are obtained, and features are extracted from the first radar image and the second radar image. A similarity is determined between an object represented by the first radar image and an object represented by the second radar image based on the features extracted from the first radar image and the features extracted from the second radar image. A determined similarity between these two sets of features is used to determine whether the object represented by the first radar image matches the object represented by the second radar image. Distances between the features in the two radar images can optionally also be compared and used to determine object similarity. The objects in the radar images may optionally be faces.","['G01S7/417', 'G01S13/87', 'G01S13/89', 'G01S7/412', 'G01S13/90', 'G01S7/4972']"
CN106203506B,A kind of pedestrian detection method based on depth learning technology,"The invention discloses a kind of pedestrian detection method based on depth learning technology, transfer learning is primarily based on using one two disaggregated model of Strategies Training of "" gradually migrating "" to initialize final mask parameter；Then using current very popular efficient Faster RCNN frame and improved and complete pedestrian detection work, be based on CNN feature, not only can handle the image of any scale, but also detection speed is fast.Compared to disclosing patent of invention, the method disclosed in the present does not need to carry out network special design, take full advantage of existing data available, good experiment effect still can achieve using general network structure, the advantage of depth convolutional network has been given full play to, has had design simple, robustness is preferable, Detection accuracy is high, the low advantage of omission factor.","['G06F18/214', 'G06F18/285']"
WO2022037068A1,Method for diagnosis of fault in machine tool bearing,"The invention relates to the technical field of intelligent manufacturing. Provided is a method for diagnosis of a fault in a machine tool bearing, comprising: establishing a digital twin workshop, and loading a machining task to a machine tool in the digital twin workshop, wherein the digital twin workshop corresponds to a real workshop; acquiring fault data of the machine tool during a process of the machine tool executing the machining task, and generating fault diagnosis models of a first type according to the acquired fault data; performing variable working condition transfer learning training on the generated fault diagnosis models, and obtaining fault diagnosis models of a second type, wherein the fault diagnosis models of the second type include a model for diagnosis of a fault in a machine tool bearing in the real workshop; and using the fault diagnosis models of the second type to detect a fault in the machine tool bearing in the real workshop. The diagnosis method is applicable to monitoring of a machine tool workshop.","['G06F18/241', 'G01M13/04', 'G01M13/045', 'G06F18/214', 'G06F18/25', 'G06N3/047', 'G06N3/08', 'G06F2218/12']"
US11937973B2,Systems and media for automatically diagnosing thyroid nodules,"In accordance with some embodiments, systems, methods, and media for automatically localizing and diagnosing thyroid nodules are provided. In some embodiments, a system for automatically diagnosing thyroid nodules comprises: an ultrasound machine; and a processor programmed to: receive a B-mode ultrasound of a thyroid from the ultrasound machine; provide the B-mode ultrasound to a classification model trained to automatically segment B-mode ultrasound; receive an output indicating which portions of the B-mode ultrasound correspond to a nodule; provide at least a portion of the B-mode ultrasound corresponding to the nodule to a second classification model trained to automatically classify thyroid nodules based B-mode, color Doppler, and shear wave elastography ultrasound; and receive, from the second trained classification model, an output indicative of the likelihood that the nodule is malignant.","['A61B8/085', 'A61B8/485', 'A61B8/488', 'A61B8/5223', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G16H50/30']"
CN113627447B,"Label identification method, label identification device, computer equipment, storage medium and program product","The application provides a tag identification method, a tag identification device, computer equipment, a storage medium and a program product, and relates to the technical fields of artificial intelligence, cloud technology, intelligent traffic, driving assistance and the like. Performing multi-type feature extraction on information to be identified through a feature extraction network to obtain multi-type features; respectively determining the matching degree between the information to be identified and each label based on the global features of each label in the multi-type features and the global label features, so as to determine the label of the information to be identified based on the matching degree; the global characteristics of at least two labels included in the global label characteristics are determined based on the initial characteristics of each label and the incidence relation between the at least two labels, the incidence relation existing between the labels in the range of the plurality of labels can be represented, the label identification is carried out by combining the global correlation among the plurality of labels, the problem of identification errors caused by the independent processing of a single label is avoided, and the accuracy of the label identification can be improved.","['G06F18/22', 'G06N3/045', 'G06N3/08']"
CN111507993B,"Image segmentation method, device and storage medium based on generation countermeasure network","The invention discloses an image segmentation method, a device and a storage medium based on a generated countermeasure network, wherein the method comprises the following steps: acquiring a target image set, a reference image set and a pre-marked reference mark set corresponding to the reference image set; the target image set comprises a target image training set and a target image testing set; constructing a segmentation network and a discrimination network; inputting the target image training set and the reference image set into a segmentation network, correspondingly obtaining a target probability score map and a reference probability score map, and inputting the target probability score map and the reference probability score map into a discrimination network so as to perform joint training of the segmentation network and the discrimination network; when the first target loss function of the segmentation network and the second target loss function of the discrimination network are converged, training is finished; and inputting the target image test set into a trained segmentation network to obtain a target segmentation image. The invention can realize image segmentation without pre-labeling of the original image.","['G06T7/12', 'G06N3/045', 'G06N3/084', 'Y02T10/40']"
CN112329467B,"Address recognition method and device, electronic equipment and storage medium","The embodiment of the application discloses an address identification method and device, electronic equipment and a storage medium, and the method and device can be applied to the fields of artificial intelligence, big data, maps and the like. The method comprises the following steps: acquiring an address text to be identified; acquiring identification guide information of an address text to be identified, wherein the identification guide information comprises at least one item of basic information of words contained in the address text to be identified, identification information of target address words or characteristic information of words, and the identification information of the target address words represents identification results of the target address words; and obtaining an address role recognition result of the address text to be recognized according to the address text to be recognized and the recognition guidance information. By adopting the method and the device, the address character recognition result of the address text to be recognized can be obtained through the recognition guidance information of the address text to be recognized and the recognition guidance information of the address text to be recognized, and the accuracy is high.","['G06F40/295', 'G06N3/045', 'G06N3/08']"
WO2020103676A1,"Image identification method and apparatus, system, and storage medium","An image identification method and apparatus, a system, and a storage medium. The method comprises: acquiring a first image (S202); by means of a target model, segmenting the first image into a plurality of first regions, and querying a target region among candidate regions in a first image frame that use a point within a first region as the center, the target region being a candidate region in the first image in which a target object is located, the target model being a pre-trained neural network model that is used to identify from an image a region in which the target object is located, and the target model being obtained by using positive samples that identify a region in which the target object is located and negative samples that identify a region in which noise is located (S204); and identifying a target region in the first image (S206). The present method effectively increases the accuracy in detecting a target object in an image.","['G06F18/23', 'G06V10/764', 'G06F18/214', 'G06F18/24', 'G06N3/08', 'G06T7/0014', 'G06T7/11', 'G06T7/174', 'G06V10/82', 'G06V40/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30032', 'G06V2201/03']"
US12230369B2,Systems and methods for mental health assessment,"The present disclosure provides systems and methods for assessing a mental state of a subject in a single session or over multiple different sessions, using for example an automated module to present and/or formulate at least one query based in part on one or more target mental states to be assessed. The query may be configured to elicit at least one response from the subject. The query may be transmitted in an audio, visual, and/or textual format to the subject to elicit the response. Data comprising the response from the subject can be received. The data can be processed using one or more individual, joint, or fused models. One or more assessments of the mental state associated with the subject can be generated for the single session, for each of the multiple different sessions, or upon completion of one or more sessions of the multiple different sessions.","['A61B5/164', 'A61B5/165', 'A61B5/4803', 'G09B19/00', 'G10L25/66', 'G16H10/20', 'G16H10/60', 'G16H15/00', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'A61B5/01', 'A61B5/024', 'A61B5/0816', 'A61B5/11', 'A61B5/14551', 'A61B5/4088', 'A61B5/7275', 'G06F16/24', 'G10L15/18', 'G10L15/183']"
US11120895B2,Systems and methods for mental health assessment,"The present disclosure provides systems and methods for assessing a mental state of a subject in a single session or over multiple different sessions, using for example an automated module to present and/or formulate at least one query based in part on one or more target mental states to be assessed. The query may be configured to elicit at least one response from the subject. The query may be transmitted in an audio, visual, and/or textual format to the subject to elicit the response. Data comprising the response from the subject can be received. The data can be processed using one or more individual, joint, or fused models. One or more assessments of the mental state associated with the subject can be generated for the single session, for each of the multiple different sessions, or upon completion of one or more sessions of the multiple different sessions.","['G16H10/20', 'G10L25/66', 'A61B5/164', 'A61B5/165', 'A61B5/4803', 'G06F40/20', 'G09B19/00', 'G16H20/10', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'A61B5/4088', 'A61B5/7275', 'G06F16/24', 'G06F40/30', 'G10L15/18', 'G10L15/26']"
CN110363122B,Cross-domain target detection method based on multi-layer feature alignment,"The invention discloses a cross-domain target detection method based on multilayer feature alignment. First, the detector is trained on the framed labeled source domain dataset by a deep convolutional neural network. Then, the trained detector is used as a pre-training model, and the images of the source domain and the target domain without frame marking are subjected to feature extraction through a deep convolutional neural network VGG-16, so that the source domain, the target and the shared feature parameters. And secondly, designing a domain classifier, taking the extracted feature layers of the multiple layers of source domains and target domains as the input of the domain classifier, and judging whether the feature layers are from the source domains or the target domains. And then, through a training mode of confronting a generated network, the feature distribution of the source domain and the target domain is aligned, and further, the data deviation between the two domains is reduced. And finally, performing joint training on the detector and the discriminator to obtain a final model. The method and the device realize the migration of the source domain knowledge to the target domain, and improve the detection precision of the target domain data without frame marking.","['G06F18/214', 'G06N3/045', 'G06V10/25', 'G06V20/58', 'G06V20/584']"
US11354778B2,Systems and methods for contrastive learning of visual representations,"Provided are systems and methods for contrastive learning of visual representations. In particular, the present disclosure provides systems and methods that leverage particular data augmentation schemes and a learnable nonlinear transformation between the representation and the contrastive loss to provide improved visual representations. In contrast to certain existing techniques, the contrastive self-supervised learning algorithms described herein do not require specialized architectures or a memory bank. Some example implementations of the proposed approaches can be referred to as a simple framework for contrastive learning of representations or “SimCLR.” Further example aspects are described below and provide the following benefits and insights.","['G06T5/002', 'G06T11/60', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/096', 'G06T11/001', 'G06T3/40', 'G06T3/60', 'G06T5/20', 'G06T5/70', 'G06T7/90', 'G06V10/764', 'G06V10/82', 'G06V20/35', 'G06N3/044', 'G06N3/048', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/22']"
US12198809B2,"Machine learning algorithms for detecting medical conditions, related systems, and related methods","Systems for preparing, training, and deploying a machine learning algorithm for making medical condition state determinations include at least one processing unit that includes the machine learning algorithm. The at least one processing unit is programmed to receive image input from an imaging device, receive patient health data, encode the patient health data to convert the patient health data to encoded patient health data, and transmit the encoded patient health data into the machine learning algorithm. Systems are configured to make a medical condition state determination based on the image input and the encoded patient health data, via the machine learning algorithm, and provide visual output for the medical condition state determination via a display device such that the visual output may be augmented with the patient health data. Dynamic state information also may be input to the machine learning algorithm and used to make medical condition state determinations.","['A61B5/0205', 'A61B5/021', 'A61B5/024', 'A61B5/0816', 'A61B5/0836', 'A61B5/14542', 'A61B5/7267', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06Q30/04', 'G06T7/0012', 'G16H10/20', 'G16H10/60', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048']"
US12299579B2,Adversarial pretraining of machine learning models,This document relates to training of machine learning models. One example method involves providing a machine learning model having one or more mapping layers. The one or more mapping layers can include at least a first mapping layer configured to map components of pretraining examples into first representations in a space. The example method also includes performing a pretraining stage on the one or more mapping layers using the pretraining examples. The pretraining stage can include adding noise to the first representations of the components of the pretraining examples to obtain noise-adjusted first representations. The pretraining stage can also include performing a self-supervised learning process to pretrain the one or more mapping layers using at least the first representations of the training data items and the noise-adjusted first representations of the training data items.,"['G06N3/084', 'G06F18/24', 'G06F40/20', 'G06F40/242', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/7784', 'G06V10/82', 'G06F40/284', 'G06N3/082', 'G06T2207/20081']"
US20240071185A1,Mobile device platform for automated visual retail product recognition,"A computer-implemented method for configuring a mobile point-of-sale application to perform automated product-recognition checkout processes. The application includes a convolutional neural network including hidden layer n positioned downstream of remaining hidden layers and downstream of an input segment of the convolutional neural network. The method includes: appending a fine classification arm operating on output from hidden layer n and having a first loss function for generating output; appending a second classification arm operating on the output from one of the remaining n hidden layers upstream from hidden layer n and having a second loss function for generating output; providing a plurality of true labels for image subset(s) and applicable to at least one product class; and training the CNN by passing the image subsets therethrough, observing corresponding output of the first and second loss functions, and iteratively adjusting values of CNN model parameters based on the loss function outputs.","['G07G1/0054', 'G06F16/164', 'G06F18/217', 'G06F18/241', 'G06F18/40', 'G06K7/1413', 'G06N3/08', 'G06Q20/208', 'G06Q20/322', 'G06K2007/10504']"
CN116821308B,"Generation method, training method and device of model and storage medium","The embodiment of the specification provides a dialogue content generation method, a model training method, a prompt text generation method, a device and a storage medium. The dialogue content generation method comprises the following steps: a question of receiving an input; judging whether the questions need to be replied by combining with external knowledge; if yes, acquiring target knowledge from a preset knowledge base according to the problem, and generating a prompt text corresponding to the target knowledge; inputting the questions, the target knowledge and the prompt text corresponding to the target knowledge into a dialogue content generation model, and generating dialogue content by the dialogue content generation model; the prompt text is used for prompting the dialogue content generation model to refer to target knowledge to answer the questions; if not, inputting the problems into a dialogue content generation model, and generating dialogue content by the dialogue content generation model; the dialogue content generation model is obtained by fine tuning a pre-training language model. The method is beneficial to accurately solving the universal intention problem of the user and improving the accuracy of the dialogue content and the satisfaction degree of the user.","['G06F16/3329', 'G06F18/214', 'G06F40/205']"
US20200151519A1,Intelligent Health Monitoring,Embodiments are disclosed for health assessment and diagnosis implemented in an artificial intelligence (AI) system. The AI system takes as input information from a multitude of sensors measuring different biomarkers in a continuous or intermittent fashion. The proposed techniques disclosed herein address the unique challenges encountered in implementing such an AI system.,"['G06K9/6269', 'G16H50/20', 'A61B5/0205', 'A61B5/08', 'A61B5/0823', 'A61B5/11', 'A61B5/14551', 'A61B5/4803', 'A61B5/4815', 'A61B5/4818', 'A61B5/4842', 'A61B5/4848', 'A61B5/6817', 'A61B5/7257', 'A61B5/7264', 'A61B5/7267', 'A61B5/7275', 'G06F17/16', 'G06F17/18', 'G06F18/20', 'G06F18/2148', 'G06F18/2185', 'G06F18/2411', 'G06F18/24137', 'G06F18/253', 'G06F18/27', 'G06F18/30', 'G06K9/726', 'G06N20/00', 'G06N20/10', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/088', 'G06N5/01', 'G06V10/82', 'G06V30/274', 'G06V40/70', 'G10L15/02', 'G10L15/16', 'G10L15/1815', 'G10L15/22', 'G10L25/66', 'G16H10/60', 'G16H20/10', 'G16H40/67', 'G16H50/30', 'G16H50/70', 'G16H70/40', 'G16H70/60', 'G16H80/00', 'A61B2562/0204', 'A61B5/024', 'A61B5/681', 'G06N5/045', 'G06V40/15', 'G10L2015/027', 'G10L25/30', 'G10L25/51', 'G16H40/63']"
CN111062250B,Multi-subject motor imagery electroencephalogram signal identification method based on deep feature learning,"The invention discloses a multi-subject motor imagery electroencephalogram signal identification method based on deep feature learning, which comprises the steps of acquiring electroencephalogram signals of subjects in motor imagery through an electroencephalogram acquisition device; analyzing the electroencephalogram signals by using a multi-body motor imagery electroencephalogram signal identification model to determine motor imagery content; firstly, constructing a motor imagery electroencephalogram signal characteristic learning model based on a convolution self-encoder; selecting invariance characteristics of the multi-body electroencephalogram based on a invariance evaluation method and a discriminant evaluation method of depth characteristics, and adding a full-connection layer and a Softmax classification layer after a network layer where the invariance characteristics are positioned to form a multi-body motor imagery electroencephalogram identification model; the model is trained and then applied. The invention can obtain the universal model with generalization capability among subjects, does not need to collect calibration data when a new subject is added, and can effectively improve the accuracy of identifying the motion imagination content of the new subject.","['G06F2218/00', 'G06F18/214', 'G06N3/045', 'G06N3/084']"
US12020265B1,Systems and methods for discovering online influencers and generating market sentiment index,"Systems, apparatuses, and methods obtain and process data that may be used to identify or discover one or more “influencers” in business, finance, fashion, sports, current events, and other areas, and also to generate an indication of each influencer's expertise and ability to influence others with their posts or comments. A measure of each influencer's accuracy with regards to the contents of their previous comments or posts may also be generated. Based on determining the sentiment associated with each influencer's current posts or comments, an index or measure of the accuracy weighted sentiment expressed by a set of influencers with regards to an event, stock, trend, or other aspect may be generated and presented to a user to assist them in making a decision.","['G06F40/30', 'G06Q30/0201', 'G06Q30/0243', 'G06Q50/01']"
US12373947B2,System and method for detecting lung abnormalities,"A computer-implemented method for detecting lung abnormalities is provided. The method includes the steps of: acquiring a chest image of a subject; labeling one or more regions of interest (ROIs) in the chest image; segmenting a fine-grained boundary of each of the labeled ROIs; generating a plurality of output matrixes for each of the segmented ROIs; sorting a plurality of prediction scores obtained in the output matrixes, and generating a plurality of recommendations of potential abnormalities for each of the ROIs; and outputting the recommendations, A smart imagery framing and truthing (SIFT) system for implementing the method is also provided.","['G16H15/00', 'G06T7/0012', 'G06T7/11', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30061', 'G06T2207/30064', 'G06T2207/30096']"
US11100643B2,Training strategy search using reinforcement learning,"In at least one embodiment, a reinforcement-learning-based searching approach is used to produce a training configuration for a machine-learning model. In at least one embodiment, 3D medical image segmentation is performed using learned image preprocessing parameters.","['G06N3/006', 'G06N3/08', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/09', 'G06N3/092', 'G06N3/0985', 'G06T5/002', 'G06T5/70', 'G06T7/0012', 'G06T7/10']"
US12193414B2,"Animal visual identification, tracking, monitoring and assessment systems and methods thereof","An animal management system has one or more imaging devices, and a computing device coupled to the one or more image devices for receiving one or more images captured by the one or more imaging devices, processing at least one image using an artificial intelligence (AI) pipeline for: (i) detecting and locating in the image one or more animals, (ii) for each detected animal: (a) generating at least one section of the detected animal, (b) determining a plurality of key points in each section, (c) generating an embedding for each section based on the plurality of key points in the section, and (d) combining the embeddings for generating an identification of the detected animal with a confidence score. Key points and bounding boxes may also have associated confidence scores.","['G06Q50/02', 'A01K11/006', 'G06Q10/06', 'G06V10/25', 'G06V10/82', 'G06V20/63', 'G06V30/147', 'G06V40/10', 'A01K29/005']"
US20220185625A1,Camera-based sensing devices for performing offline machine learning inference and computer vision,"A sensor module includes at least a camera module and one or more machine learning (ML) inference application-specific integrated circuits (ASICs), which are configured to detect the presence of people in an elevator. The sensor module includes at least one processor, which executes instructions that enable the sensor module to detect, count, and anonymously track one or more persons in an elevator. The sensor module may also sensors, such as an accelerometer and an altimeter, which are used to estimate the kinematic state of the elevator. The camera, ML ASIC(s), sensors, and embedded application enable the sensor device to anonymously monitor the movement of people through a building via the elevator. The ML ASIC(s) allow the sensor module to count occupants in the elevator in near-real time, enabling the sensor to transmit signals for controlling aspects of the elevator system.","['B66B5/0012', 'B66B1/28', 'B66B1/34', 'B66B1/3461', 'B66B1/3476', 'G06V10/26', 'G06V10/454', 'G06V10/82', 'G06V20/53', 'G06V40/103', 'B66B2201/222', 'G06F17/15', 'G06N3/045', 'G06N3/08']"
US10878569B2,Systems and methods for automatic detection of an indication of abnormality in an anatomical image,"There is provided a method for training a deep convolutional neural network (CNN) for detecting an indication of likelihood of abnormality, comprising: receiving anatomical training images, each including an associated annotation indicative of abnormality for the whole image without an indication of location of the abnormality, executing, for each anatomical training image: decomposing the anatomical training image into patches, computing a feature representation of each patch, computing for each patch, according to the feature representation of the patch, a probability that the patch includes an indication of abnormality, setting a probability indicative of likelihood of abnormality in the anatomical image according to the maximal probability value computed for one patch, and training a deep CNN for detecting an indication of likelihood of abnormality in a target anatomical image according to the patches of the anatomical training images, the one patch, and the probability set for each respective anatomical training image.","['G16H30/40', 'G06F18/2155', 'G06F18/2163', 'G06F18/24143', 'G06F18/2415', 'G06K9/2054', 'G06K9/6259', 'G06K9/6261', 'G06K9/6277', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/096', 'G06N7/005', 'G06N7/01', 'G06T7/0012', 'G06T7/0014', 'G06T7/13', 'G06T7/143', 'G06T7/62', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G16H30/20', 'G16H50/20', 'G16H50/70', 'G06K2209/05', 'G06N3/048', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20021', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068', 'G06V2201/03']"
CN114418030B,"Image classification method, training method and device for image classification model","The embodiment of the application provides an image classification method, an image classification model training method and an image classification model training device, and relates to the field of artificial intelligence. The method comprises the following steps: inputting an image to be classified into a coding layer of a pre-trained image classification model, and extracting vectors to obtain feature vectors, wherein the feature vectors comprise a plurality of local vectors, and each local vector corresponds to one sub-image in the image to be classified; screening the local vectors by using an attention mechanism layer in the coding layer to obtain residual local vectors; and obtaining a classification result of the image to be classified based on the residual local vector. The embodiment of the application firstly does not need an auxiliary network or introduces more parameters in the process of reducing the local vector, and can reduce the calculated amount, is also suitable for images with different resolutions and enhances the adaptability of the scheme because a lightweight image classification model can be trained from the beginning.","['G06F18/241', 'G06F18/214', 'G06N3/045', 'G06N3/084']"
US20190318806A1,Variant Classifier Based on Deep Neural Networks,"We introduce a variant classifier that uses trained deep neural networks to predict whether a given variant is somatic or germline. Our model has two deep neural networks: a convolutional neural network (CNN) and a fully-connected neural network (FCNN), and two inputs: a DNA sequence with a variant and a set of metadata features correlated with the variant. The metadata features represent the variant's mutation characteristics, read mapping statistics, and occurrence frequency. The CNN processes the DNA sequence and produces an intermediate convolved feature. A feature sequence is derived by concatenating the metadata features with the intermediate convolved feature. The FCNN processes the feature sequence and produces probabilities for the variant being somatic, germline, or noise. A transfer learning strategy is used to train the model on two mutation datasets. Results establish advantages and superiority of our model over traditional classifiers.","['G16B20/20', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G16B30/10', 'G16B40/20']"
US10318864B2,Leveraging global data for enterprise data analytics,"A deep learning network is trained to automatically analyze enterprise data. Raw data from one or more global data sources is received, and a specific training dataset that includes data exemplary of the enterprise data is also received. The raw data from the global data sources is used to pre-train the deep learning network to predict the results of a specific enterprise outcome scenario. The specific training dataset is then used to further train the deep learning network to predict the results of a specific enterprise outcome scenario. Alternately, the raw data from the global data sources may be automatically mined to identify semantic relationships there-within, and the identified semantic relationships may be used to pre-train the deep learning network to predict the results of a specific enterprise outcome scenario.","['G06N3/08', 'G06N3/04', 'G06N3/0499', 'G06N3/09', 'G06N3/096', 'G06Q10/067']"
CN111209848B,A real-time fall detection method based on deep learning,"The invention relates to a real-time fall detection method based on deep learning, wherein the detection method comprises the following steps of: sequentially taking out single-frame pictures from a video stream after the analysis of a camera or a local video, inputting the single-frame pictures into an openpore algorithm model human body for detection to obtain key point coordinates of each part of the human body, using an SSD-Mobilene algorithm to exclude key points of non-human body areas, and a falling detection module: the method uses a common camera, has lower requirements on environment and use angle, and simultaneously has low cost, instantaneity, lower false detection rate, higher robustness and adaptability to different complex scenes.","['G06V40/103', 'G06F18/214', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06V10/462', 'G06V2201/07']"
CN109308545B,"Method, device, computer equipment and storage medium for predicting diabetes probability","The application relates to an algorithm model and discloses a method, a device, computer equipment and a storage medium for predicting diabetes mellitus probability, wherein the application provides a method for predicting diabetes mellitus probability, which comprises the following steps: acquiring user information and physical examination index data of a user to be detected, wherein the user information comprises user data corresponding to characteristics of multiple dimensions; inputting the physical examination index data into a disease probability detection model obtained by pre-training, wherein the disease probability detection model is obtained by iterative training of a GBDT model according to the influence degree ordering of the characteristics of multiple dimensions of a user on the diabetes disease probability; and acquiring the diabetes mellitus probability of the user to be detected, which is output by the disease probability detection model based on the physical examination index data. According to the method, a reliable prediction model is formed for predicting diabetes through the big data training model, the test conditions for testing sample data are not required, and the adverse effect of the sample detection conditions on the diabetes detection result is effectively avoided.","['G06Q10/04', 'G06F18/214', 'G16H50/50', 'G16H50/70', 'Y02A90/10']"
US20240403031A1,Application Development Platform and Software Development Kits that Provide Comprehensive Machine Learning Services,"The present disclosure provides an application development platform and associated software development kits (“SDKs”) that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (“API”) that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.","['G06F8/65', 'G06F8/36', 'G06N20/00']"
US11436848B2,Automatic labeling apparatus and method for object recognition,"An automatic labeling apparatus for object recognition and a method therefor are provided. The automatic labeling apparatus for object recognition is configured to apply an object recognition algorithm to each of a plurality of image frames so as to recognize an object, and in response to a determination that an object recognition result in at least one first image frame among the image frames corresponds to a predetermined error condition, automatically generate a data set on an object which is a target of object recognition by using an object recognition result of a second image frame other than the first image frame among the image frames and an object image of the first image frame. The object recognition algorithm, which is a neural network model generated through machine learning, may be stored in a memory or provided through a server in an artificial intelligence environment through a 5G network.","['G06V10/10', 'G06N3/08', 'G06F18/00', 'G06F18/214', 'G06K9/6256', 'G06N3/02', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/20', 'G06V20/20', 'G06V20/46', 'G06V20/64', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06N7/01']"
CN110210542B,Picture character recognition model training method and device and character recognition system,"The invention discloses a picture character recognition model training method, a device and a character recognition system. The training method comprises the following steps: s1, acquiring an original picture, and randomly selecting words from a text library to generate test words; s2, randomly combining the test texts with the original pictures to form a test atlas; s3, training the CTPN model to form a character positioning model, and training the CRNN model to form a character recognition model; and S4, combining the character positioning model and the character recognition model in sequence to form a picture character recognition model. The invention overcomes the problem that the existing character recognition algorithm has low accuracy rate for recognizing characters in specific pictures, and effectively improves the accuracy rate for recognizing characters in specific pictures, thereby providing a recognition basis for the subsequent processing of illegal characters or pictures.","['G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V30/10']"
CN110866140B,"Image feature extraction model training method, image searching method and computer equipment","The application relates to an image feature extraction model training method, an image searching method and computer equipment. The method comprises the following steps: acquiring a plurality of picture groups for training, wherein the picture groups at least comprise reference samples and similar samples of the reference samples; inputting each sample of the picture group into a corresponding sub-neural network in the neural network model, extracting semantic feature vectors of each sample through a deep neural network of each sub-neural network, and extracting visual feature vectors of each sample through a shallow neural network of each sub-neural network; according to the semantic feature vector and the visual feature vector, each sub-neural network of the neural network model outputs an image feature vector of a corresponding sample; and training a neural network model by taking the distance between the image feature vectors of the minimized reference sample and the similar sample as a target to obtain an image feature extraction model. The method considers semantic and visual similarity, and can improve image searching accuracy when applied to image searching.","['G06F16/583', 'G06F18/214', 'G06F18/22']"
US11113479B2,Utilizing a gated self-attention memory network model for predicting a candidate answer match to a query,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that can determine an answer to a query based on matching probabilities for combinations of respective candidate answers. For example, the disclosed systems can utilize a gated-self attention mechanism (GSAM) to interpret inputs that include contextual information, a query, and candidate answers. The disclosed systems can also utilize a memory network in tandem with the GSAM to form a gated self-attention memory network (GSAMN) to refine outputs or predictions over multiple reasoning hops. Further, the disclosed systems can utilize transfer learning of the GSAM/GSAMN from an initial training dataset to a target training dataset.","['G06F16/90332', 'G06F16/3329', 'G06F17/16', 'G06F18/22', 'G06F40/30', 'G06F40/44', 'G06K9/6215', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06F40/284']"
CN114596566B,Text recognition method and related device,"The application relates to the technical field of computers, in particular to the technical field of artificial intelligence, and provides a text recognition method and a related device, which are used for improving the text recognition accuracy rate, and the method comprises the following steps: inputting an image to be recognized into a target classification model, obtaining language distribution information and an original text presenting direction, then, carrying out image correction on the image to be recognized based on the original text presenting direction to obtain a target recognition image, then, determining a plurality of text region image sets corresponding to languages respectively, and finally, respectively adopting target text recognition models associated with the corresponding languages based on the text region image sets to obtain text recognition results. Therefore, the text recognition precision is improved by accurately judging and predicting the distribution information and the text presenting direction.","['G06F18/214', 'G06F18/241', 'G06F40/263', 'G06N3/044', 'G06N3/045', 'G06N3/084']"
US20230044399A1,Data analysis based methods and systems for optimizing insertion of a medical instrument,"Provided are computer-implemented methods and systems for generating and/or utilizing data analysis algorithm(s) for providing operating instructions, enhancements and/or recommendations to optimize insertion of a medical instrument toward a target in a body of a patient based, inter alia, on data related to an automated medical device and/or to operation thereof.","['A61B5/7267', 'A61B34/25', 'A61B34/10', 'A61B34/32', 'A61B5/02042', 'A61B5/08', 'A61B5/1073', 'A61B5/489', 'A61B5/7275', 'A61B5/746', 'G06N20/00', 'G06T7/0012', 'G16H20/40', 'G16H30/20', 'G16H40/63', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'A61B2017/00203', 'A61B2034/104', 'A61B2034/107', 'A61B2034/2048', 'A61B2034/2065', 'A61B2034/301', 'A61B2090/365', 'A61B2090/374', 'A61B2090/3762', 'A61B2090/378', 'G06T2207/10', 'G16H20/17', 'G16H30/40', 'G16H70/20']"
CN113272863B,Depth prediction based on dual pixel images,"Apparatus and methods related to determining a depth map of a dual pixel image of an object using machine learning are provided. The computing device may receive a two-pixel image of at least a foreground object. The dual pixel image may include a plurality of dual pixels. The dual pixels of the plurality of dual pixels may include a left pixel and a right pixel, each representing light incident on a single dual pixel element for capturing a dual pixel image. The computing device may be used to train a machine learning system to determine a depth map associated with the two-pixel image. The computing device may provide a trained machine learning system.","['G06T7/593', 'G06F18/214', 'G06F18/217', 'H04N23/90', 'H04N5/2226', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11674384B2,Controller optimization via reinforcement learning on asset avatar,A method can include receiving sensor data from a system; encoding the sensor data to a latent space representation via a trained encoder; generating a control action using the latent space representation; and issuing an instruction that corresponds to the control action for control of the system.,"['E21B47/12', 'G05B13/027', 'E21B43/2607', 'E21B47/008', 'G05B13/041', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06N3/092', 'G06N3/096', 'G06N3/098', 'E21B2200/20', 'E21B2200/22']"
WO2022160170A1,Method and apparatus for detecting metal surface defects,"The present application relates to a method for detecting metal surface defects, the method comprising: acquiring surface defect images of metal so as to obtain a metal surface defect dataset; building a first detection model by using the metal surface defect dataset; training a ResNet by using an ImageNet dataset; transferring the trained ResNet to the first detection model so as to obtain a second detection model, wherein the second detection model is a metal surface defect detection model based on deep transfer learning; and carrying out detection on a metal surface by using the second detection model. The present application further relates to an apparatus for detecting metal surface defects. In the present application, a ResNet trained on the basis of ImageNet is transferred to a metal surface defect detection model built in the present invention. By means of transfer learning, the metal surface defect detection model has gained a more powerful feature expression ability.",['G06N3/02']
US11966837B2,Compression of deep neural networks,"In an approach for compressing a neural network, a processor receives a neural network, wherein the neural network has been trained on a set of training data. A processor receives a compression ratio. A processor compresses the neural network based on the compression ratio using an optimization model to solve for sparse weights. A processor re-trains the compressed neural network with the sparse weights. A processor outputs the re-trained neural network.","['H03M7/3059', 'G06N3/08', 'G06N3/0442', 'G06N3/0464', 'G06N3/047', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N5/01', 'H03M7/6047', 'H03M7/702', 'G06N3/044', 'G06N3/045', 'G06N3/063']"
US11915415B2,"Image processing method and apparatus, computer-readable medium, and electronic device","Embodiments of this application include an image processing method and apparatus, a non-transitory computer-readable storage medium, and an electronic device. In the image processing method a to-be-predicted medical image is input into a multi-task deep convolutional neural network model. The multi-task deep convolutional neural network model includes an image input layer, a shared layer, and n parallel task output layers. One or more lesion property prediction results of the to-be-predicted medical image is output through one or more of the n task output layers. The multi-task deep convolutional neural network model is trained with n types of medical image training sets, n being a positive integer that is greater than or equal to 2.","['G06T7/0012', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30032', 'G06T2207/30096']"
US11922656B2,Partial deformation maps for reconstructing motion-affected treatment dose using machine learning,"A method comprises inputting a treatment planning image of a target subject into a machine learning system. The method further comprises determining, by the machine learning system, a first target-subject-specific model of the treatment planning image. The method further comprises applying, by a processing device, the first target-subject-specific model to the treatment planning image to generate a transformed treatment planning image corresponding to a first position of a plurality of positions of the target subject. The method further comprises comparing the transformed treatment planning image to a reference image. The method further comprises, based on the comparing, modifying one or more parameters of the first target-subject-specific model to generate a second target-subject-specific model corresponding to a second position of the plurality of positions. The method further comprises controlling a treatment device based on the second target-subject-specific model to deliver a treatment to the target subject.","['G06T7/74', 'A61N5/103', 'A61N5/1031', 'A61N5/1037', 'A61N5/1039', 'A61N5/1049', 'A61N5/1082', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06T7/246', 'G06T7/344', 'G06T7/75', 'A61N2005/1051', 'A61N5/1083', 'G06N3/047', 'G06N5/01', 'G06T2200/04', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/10124', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
CN111060601B,Weld ultrasonic phased array detection data intelligent analysis method based on deep learning,"The invention discloses a weld ultrasonic phased array detection data intelligent analysis method based on deep learning, which comprises the following steps: s1: sampling data, and detecting the welding seams of the steel plates with different thicknesses by using a phased array to obtain a series of S-scan pictures; s2: preprocessing is carried out, the S-scan pictures are divided into a training set and a verification set according to the proportion of 1; s3: carrying out data labeling, and labeling the defects of S-scan pictures of the training set and the verification set by using labeling software labelImg; s4: training a Fast RCNN network, and circularly and alternately training the Fast RCNN and the RPN network in the Fast RCNN network by using a data set marked by S3 and a pre-trained VggNet16 network weight model; s5: and (5) performing result testing, inputting the picture to be detected into the trained network, and outputting a detection result. The method improves the recognition rate of the S-scanning two-dimensional plane defect of the ultrasonic phased array detection weld joint, and has the advantages of high accuracy and low omission ratio.","['G01N29/0654', 'G01N29/4481', 'G01N2291/267', 'Y02P90/30']"
US12340316B2,Techniques for building a knowledge graph in limited knowledge domains,"Techniques disclosed herein relate generally to constructing a customized knowledge graph. In one embodiment, entities and relations among entities are extracted from a user dataset based on certain rules to generate a seed graph. Large-scale knowledge graphs are then traversed using a finite state machine to identify candidate entities and/or relations to add to the seed graph. A priority function is used to select entities and/or relations from the candidate entities and/or relations. The selected entities and/or relations are then added to the seed graph to generate the customized knowledge graph.","['G06N5/022', 'G06N5/025', 'G06N20/00', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/041', 'G06N7/01', 'G06N3/006', 'G06N3/08']"
US10936907B2,Training a deep learning system for maritime applications,"An object detection network can be trained with training images to identify and classify objects in images from a sensor system disposed on a maritime vessel. The objects in the images can be identified, classified, and heat maps can be generated. Instructions can be sent regarding operation of the maritime vessel. For some training images, water conditions, sky conditions, and/or light conditions in the image can be changed to generate a second image.","['G06K9/6256', 'G05D1/0206', 'G06F18/214', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06T11/40', 'G06T7/194', 'G06T7/50', 'G06V10/82', 'G06V20/00', 'G06N3/047', 'G06T2207/10012', 'G06T2207/20081', 'G06T2207/20228', 'G06T2207/30261']"
CN115329779B,A multi-person conversation emotion recognition method,"The invention discloses a multi-user dialogue emotion recognition method. Extracting multi-modal features from a sub-module of context information modeling based on multi-modal feature fusion, carrying out multi-modal feature fusion on the extracted single-modal features through a fusion layer based on an attention mechanism, and modeling a context through a bidirectional LSTM network; the sub-module based on Roberta speaker personality characteristic perception modeling captures sequence position information of historical utterances of a speaker corresponding to target utterances through the GRU tracking layer, outputs vectors and speaker personality characteristic vectors to be spliced and input to the pre-training memory network, and models speaker language preference; and splicing the output vectors of the two sub-modules to obtain the emotion vector of the model. The invention is beneficial to improving the dialogue emotion recognition accuracy, and fully utilizes the multi-mode and individual characteristic information to complete the context modeling and speaker modeling.","['G06F40/35', 'G06N3/08', 'Y02D10/00']"
US20230386646A1,Combined vision and language learning models for automated medical reports generation,"A method of generating a medical report is presented herein. In some embodiments, the method includes receiving a medical image and at least one natural language medical question, extracting at least one image feature from the image; extracting at least one text feature from the question; and fusing the at least one image feature with the at least one text feature to form a combined feature. Some embodiments further include encoding, by an encoder, the combined feature to form a transformed combined feature; computing a set of prior context features based on a similarity between the transformed combined feature and each of a set of transformed text features derived from a set of training natural language answers; and generating, by a decoder, a first natural language answer conditioned on the transformed combined feature and the set of prior context features.","['G06V10/82', 'G16H30/40', 'G06F40/40', 'G06V10/774', 'G06V10/803', 'G06V10/806', 'G16H10/20', 'G16H15/00', 'G16H50/20', 'G06V2201/03']"
US12223264B2,Multi-layer graph-based categorization,"A method may include a obtaining a first data model instance comprising an identifier string and. a set of attributes associated with a set of attribute name strings. The method may include obtaining an ontology graph that includes a first label, a second label, and an association between them. The method may include using a prediction model to select the first label based on the first data model instance and determining the second label based on the relationship. The method may include determining a selected set of labels that includes the first label and the second label to associate with the first data model instance. The method may include associating the selected set of labels with the first data model instance in a dataset that includes a plurality of records, where each record is associated with a different data model instance.","['G06F40/20', 'G06F40/247', 'G06F16/345', 'G06F16/367', 'G06F16/9024', 'G06F40/216', 'G06F40/30', 'G06F40/44', 'G06F40/56', 'G06N20/00', 'G06N3/0442', 'G06N3/0455', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06N5/02', 'G06F16/36', 'G06N3/044', 'G06N3/045']"
CN111339255B,"Target emotion analysis method, model training method, medium, and device","The disclosure relates to the technical field of natural language processing, and provides a target emotion analysis method and device, a target emotion analysis model training method and device, a computer storage medium and electronic equipment. The target emotion analysis method comprises the following steps: for each word in the sentence to be tested, acquiring a word vector of the current word, acquiring a text vector used for representing the global semantic information of the current word, and acquiring a position vector used for representing the position information of the current word in the sentence to be tested; for each word in the sentence to be tested: coding the word vector, the text vector and the position vector to obtain a semantic vector of the sentence to be detected; acquiring a target vector corresponding to a target word in a sentence to be detected; and predicting the emotion polarity category of the target word according to the semantic vector and the target vector. The technical scheme is beneficial to improving the prediction accuracy of the emotion polarity category of the target word.","['G06F16/3344', 'G06F16/35', 'Y02D10/00']"
US12277759B2,Dual deep learning architecture for machine-learning systems,"Certain aspects involve a machine-learning query system that uses a dual deep learning network to service queries and other requests. In one example, a machine-learning query system services a query received from a client computing system. A dual deep learning network included in the machine-learning query system matches an unstructured input data object, received from the client computing system, to an unstructured reference data object. The matching may include generating an input feature vector by an embedding subnetwork, based on the unstructured input data object. The matching may also include generating an output probability by a relationship subnetwork, based on the input feature vector and a relationship feature vector that is based on the unstructured reference data object. The machine-learning query system may transmit a responsive message to the client system.","['G06V10/82', 'G06F16/583', 'G06F16/90335', 'G06F18/21', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V40/16']"
US11430576B2,System and method for monitoring and quality evaluation of perishable food items,"This disclosure relates generally to a system and method for monitoring and quality evaluation of perishable food items in quantitative terms. Current technology provides limited capability for controlling environmental conditions surrounding the food items in real-time or any quantitative measurement for the degree of freshness of the perishable food items. The disclosed systems and methods facilitate in quantitative determination of freshness of food items by utilizing sensor data and visual data obtained by monitoring the food item. In an embodiment, the system utilizes a pre-trained CNN model and a RNN model, where the pertained CNN model is further fine-tined while training the RNN model to provide robust quality monitoring of the food items. In another embodiment, a rate kinetic based model is utilized for determining reaction rate order of the food item at a particular post-harvest stage of the food item so as to determine the remaining shelf life thereof.","['G06N3/084', 'G06F18/211', 'G06F18/2163', 'G06K9/6228', 'G06K9/6261', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/751', 'G06V10/765', 'G06V10/82', 'G06V20/68', 'G16Y10/05', 'G16Y20/20', 'G16Y40/10', 'H04L67/01']"
US11491350B2,Decision support system for individualizing radiotherapy dose,"For decision support in a medical therapy, machine learning provides a machine-learned generator for generating a prediction of outcome for therapy personalized to a patient. The outcome prediction may be used to determine dose. To assist in decision support, a regression analysis of the cohort used for machine training relates the outcome from the machine-learned generator to the dose and an actual control time (e.g., time-to-event). The dose that minimizes side effects while minimizing risk of failure to a time for any given patient is determined from the outcome for that patient and a calibration from the regression analysis.","['A61N5/103', 'A61N5/1075', 'A61B6/032', 'A61B6/5211', 'A61B6/5217', 'G06N20/00', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/065', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06N7/01', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/084']"
US20210142181A1,Adversarial training of machine learning models,This document relates to training of machine learning models such as neural networks. One example method involves providing a machine learning model having one or more layers and associated parameters and performing a pretraining stage on the parameters of the machine learning model to obtain pretrained parameters. The example method also involves performing a tuning stage on the machine learning model by using labeled training samples to tune the pretrained parameters. The tuning stage can include performing noise adjustment of the labeled training examples to obtain noise-adjusted training samples. The tuning stage can also include adjusting the pretrained parameters based at least on the labeled training examples and the noise-adjusted training examples to obtain adapted parameters. The example method can also include outputting a tuned machine learning model having the adapted parameters.,"['G06N3/088', 'G06N3/08', 'G06N3/045', 'G06N3/0454']"
CN111552821B,"Legal intention searching method, legal intention searching device and electronic equipment","A legal intention search method, a legal intention search apparatus, and an electronic device are disclosed. The legal intention searching method comprises the following steps: performing knowledge injection and sentence tree conversion on the query request based on a legal knowledge graph through a knowledge layer of a legal intention classifier; transforming the sentence tree into an embedded representation through an embedding layer of the legal intent classifier; the visualization degree of the words in the query request and the words from the legal knowledge graph is controlled through a visual layer of the legal intention classifier, and the self-attention area in a conversion model is controlled through a mask converter layer of the legal intention classifier according to the visualization degree information to obtain a legal intention search result. Therefore, the legal intention classifier with a specific framework is constructed by fusing the legal knowledge map and the pre-training language model, so that the recognition accuracy of the legal intention is improved to optimize the search result.","['G06F16/367', 'G06F16/322', 'G06F16/334', 'G06F16/3344', 'G06F16/35', 'G06F18/214', 'G06Q50/18']"
CN112703528B,Photo Relighting Using Deep Neural Networks and Confidence Learning,Apparatus and methods relating to applying a lighting model to an image of an object are provided. The neural network may be trained to apply the illumination model to the input image. Training of the neural network may utilize confidence learning based on light predictions and predicted confidence values associated with illumination of the input image. The computing device may receive an input image of an object and data regarding a particular lighting model to be applied to the input image. The computing device may determine an output image of the object by applying a particular lighting model to the input image of the object using a trained neural network.,"['G06T5/94', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06T15/50', 'G06T5/60', 'G06T15/506', 'G06T2207/20081', 'G06T2207/20084']"
US12266442B2,Decision support system for medical therapy planning,"For decision support in a medical therapy, machine learning provides a machine-learned generator for generating a prediction of outcome for therapy personalized to a patient. Deep learning may result in features more predictive of outcome than handcrafted features. More comprehensive learning may be provided by using multi-task learning where one of the tasks (e.g., segmentation, non-image data, and/or feature extraction) is unsupervised and/or draws on a greater number of training samples than available for outcome prediction alone.","['G16H30/20', 'G16H50/70', 'G16H20/40', 'A61B5/7267', 'A61N5/103', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0012', 'G16H50/20', 'G16H50/30', 'A61B6/032', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US20200293828A1,Techniques to train a neural network using transformations,"Apparatuses, systems, and techniques to perform training of neural networks using stacked transformed images. In at least one embodiment, a neural network is trained on stacked transformed images and trained neural network is provided to be used for processing images from an unseen domain distinct from a source domain, wherein stacked transformed images are transformed according to transformation aspects related to domain variations.","['G06T7/11', 'G06K9/6257', 'G06F18/2148', 'G06F18/217', 'G06K9/00208', 'G06K9/00979', 'G06K9/6262', 'G06N20/00', 'G06N3/04', 'G06N3/063', 'G06N3/08', 'G06V10/7715', 'G06V10/774', 'G06V10/95', 'G06V20/647', 'G06V30/19127', 'G06V30/19147', 'G06K2209/05', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30081', 'G06V2201/03']"
CN111144263B,Construction worker high-falling accident early warning method and device,"The invention provides a construction worker high-falling accident early warning method and device. The construction worker high-falling accident early warning method comprises the steps of establishing a data set, and respectively training a target detection network and a behavior detection network by adopting a transfer learning method; acquiring a monitoring video of a preset area, inputting the monitoring video to a target detection network after training is completed, calibrating an operation worker, a safety helmet and a safety belt, and judging whether to output equipment abnormality alarm information according to the existence and wearing positions of the safety helmet and the safety belt; inputting the worker target color image detected by the target detection network into the trained behavior detection network, extracting a worker skeleton key point sequence, connecting joints, evaluating the correlation among skeleton key points, estimating the posture of the worker according to the preset worker action category and the unsafe posture of the corresponding worker, and alarming when the abnormal behavior of the worker is detected.","['G06V40/20', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06Q10/04', 'G06Q10/0635', 'G06Q50/08', 'G06Q50/265', 'G06V40/10']"
CN110996789B,"Systems and methods for performing screening, diagnostic, or other image-based analysis tasks","Computer Tomography (CT) screening, diagnostic, or other image analysis tasks are performed using one or more networks and/or algorithms to integrate complementary tomographic image reconstruction and radiometric histology or to map tomographic raw data directly to diagnostic results in a machine learning framework. One or more reconstruction networks are trained to reconstruct tomographic images from the training set of CT projection data. One or more radiological networks are trained to extract features from tomographic images and associated training diagnostic data. The network/algorithm is integrated into the end-to-end network and trained. A set of tomographic data (e.g., CT projection data) and other relevant information from the individual are input to an end-to-end network and a possible diagnosis for the individual is generated based on features extracted by the end-to-end network. The systems and methods may be applied to CT projection data, MRI data, nuclear imaging data, ultrasound signals, optical data, other types of tomographic data, or combinations thereof.","['A61B6/032', 'A61B6/5217', 'A61B5/7267', 'A61B6/025', 'A61B6/463', 'A61B6/466', 'A61B6/5229', 'A61B6/5294', 'G06F18/24143', 'G06N3/084', 'G06T11/005', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G16H50/30', 'A61B5/055', 'A61B6/02', 'A61B6/03', 'A61B6/5247', 'A61B8/13', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10136', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20182', 'G06T2207/30064']"
CN111339774B,Text entity relation extraction method and model training method,"The application discloses a text entity relation extraction method and a model training method, which can be applied to a natural language processing technology in the field of artificial intelligence, respectively extracts a first vector for representing semantic characteristics of a text and a second vector for representing dependency relationship characteristics of the text from the text through the combination of a graph state recurrent neural network and a BERT model, and classifies the first vector and the second vector after splicing, so that the entity pair relation extraction obtains better accuracy in application scenes of long sentences and cross sentences, the problem of insufficient accuracy in application scenes of the long sentences, the cross sentences and the like in the prior art is solved, and in addition, mass production of data is marked through a remote supervision mode based on preset rules and a pre-training model in a model training stage, and a large amount of accurate training data can be obtained at a lower cost. Therefore, the method and the device can be widely applied to natural language processing technology.",['G06F16/367']
CN110310281B,Mask-RCNN deep learning-based pulmonary nodule detection and segmentation method in virtual medical treatment,"The invention relates to a Mask-RCNN deep learning-based pulmonary nodule detection and segmentation method in virtual medical treatment, and belongs to the field of image processing. The method specifically comprises the following steps: s1, establishing a training sample: firstly, preprocessing a three-dimensional lung CT image sample, then synthesizing a cross section, a sagittal plane and a coronal plane of a lung nodule into a three-channel picture to obtain a training sample set, and finally expanding the sample set by adopting a data enhancement method; s2, establishing a pulmonary nodule segmentation network; the method comprises the steps of establishing a backbone network, a characteristic pyramid network, a region generation network, an ROI generation and alignment network and three functional branches; s3, training a pulmonary nodule segmentation network: training the pulmonary nodule segmentation network by using a training sample to obtain a pulmonary nodule segmentation device; and S4, reconstructing a lung nodule and a lung three-dimensional image in a virtual medical environment to realize the detection of the lung nodule. The invention can improve the accuracy of the model without spending more resources and realize real-time interaction.","['G06T17/00', 'G06T7/0012', 'G06T7/12', 'G06T2207/10081', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064']"
CN113693613B,"Electroencephalogram signal classification method, electroencephalogram signal classification device, computer equipment and storage medium","The application relates to an electroencephalogram signal classification method, an electroencephalogram signal classification device, computer equipment and a storage medium, and relates to the technical field of signal processing. The method comprises the following steps: acquiring a first electroencephalogram signal; acquiring time-frequency characteristic diagrams corresponding to at least two electrode signals respectively based on the at least two electrode signals; performing feature extraction based on time-frequency feature graphs corresponding to at least two electrode signals respectively to obtain a first extracted feature graph; weighting the first extracted feature map based on an attention mechanism to acquire an attention feature map; based on the attention characteristic diagram, the motor imagery type corresponding to the first electroencephalogram signal is obtained. According to the scheme, the attention feature map is obtained after the first extraction feature map which fuses the time domain, the frequency domain and the spatial features of the electroencephalogram is weighted based on the attention mechanism, and the motor imagery type corresponding to the first electroencephalogram is determined through the attention feature map, so that the accuracy of predicting the motor imagery type corresponding to the electroencephalogram is improved.","['A61B5/7267', 'A61B5/374', 'G06F3/015', 'A61B5/372', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'A61B5/1126', 'A61B5/4064', 'A61B5/7207', 'A61B5/7253', 'A61B5/7257', 'G06F3/01']"
CN111259982B,A method and device for retinal image classification of premature infants based on attention mechanism,"The invention discloses a premature infant retina image classification method and device based on an attention mechanism, comprising the following steps: preprocessing a two-dimensional retina fundus image to be identified to obtain a preprocessed two-dimensional retina fundus image; inputting the preprocessed two-dimensional retinal fundus image into a pre-trained deep attention network model, and outputting a classification result of the image to identify a retinopathy ROP image of the premature infant; the deep attention network model is to add a complementary residual attention module and a channel attention SE module after a third residual layer and a fourth residual layer of the original ResNet18 network respectively. The invention can acquire rich and important global and local information, so that the network can learn the correct lesion characteristics, thereby better solving the problem of huge data unbalance between lesions and the background by using the classification network, and further improving the classification performance of the deep attention network model.","['G06F18/241', 'G06F18/214', 'G06N3/045', 'G06V2201/03']"
US20230028916A1,Autonomous vehicle component maintenance and repair,"Methods and systems for autonomous and semi-autonomous vehicle control relating to malfunctions are disclosed. Malfunctioning sensors or software of autonomous vehicles may be identified from operating data of the vehicle, and a component maintenance requirement status associated with such malfunctioning component may be generated. Based upon such status, usage restrictions may be enacted to limit operation of the vehicle while the component is malfunctioning. This may include disabling or restricting use of certain autonomous or semi-autonomous features of the vehicle until the component is repaired or replaced. Repair may be accomplished by automatically scheduling repair of the vehicle or installing an updated or uncorrupted version of a software program, in various embodiments.","['G01C21/3461', 'G05D1/0088', 'B60L53/36', 'B60L58/12', 'B60P3/12', 'B60R16/0234', 'B60R21/0136', 'B60R21/34', 'B60R25/04', 'B60R25/10', 'B60R25/1001', 'B60R25/102', 'B60R25/104', 'B60R25/252', 'B60R25/255', 'B60R25/305', 'B60R25/31', 'B60W10/04', 'B60W10/18', 'B60W10/20', 'B60W30/0956', 'B60W30/12', 'B60W30/16', 'B60W30/18163', 'B60W40/04', 'B60W60/0023', 'B60W60/0053', 'B60W60/0059', 'G01B21/00', 'G01C21/34', 'G01C21/3415', 'G01C21/343', 'G01C21/3438', 'G01C21/3453', 'G01C21/3469', 'G01C21/3617', 'G01C21/362', 'G01C21/3697', 'G01S19/13', 'G05B15/02', 'G05B23/0245', 'G05D1/0011', 'G05D1/0055', 'G05D1/0212', 'G05D1/0231', 'G05D1/0246', 'G05D1/0255', 'G05D1/0285', 'G05D1/0287', 'G05D1/0289', 'G05D1/0293', 'G05D1/0295', 'G05D1/223', 'G05D1/227', 'G05D1/228', 'G05D1/247', 'G05D1/249', 'G05D1/617', 'G05D1/646', 'G05D1/69', 'G05D1/692', 'G05D1/693', 'G05D1/695', 'G05D1/697', 'G06F11/3688', 'G06F11/3692', 'G06F16/2455', 'G06F16/90335', 'G06F17/00', 'G06F21/32', 'G06F21/55', 'G06F30/15', 'G06F30/20', 'G06Q10/1093', 'G06Q10/1095', 'G06Q10/20', 'G06Q30/0284', 'G06Q30/0645', 'G06Q40/08', 'G06Q50/163', 'G06Q50/265', 'G06Q50/40', 'G07C5/006', 'G07C5/008', 'G07C5/0808', 'G07C5/0816', 'G07C5/0841', 'G07C9/00563', 'G08B21/00', 'G08B21/02', 'G08B21/18', 'G08B25/00', 'G08B25/014', 'G08G1/017', 'G08G1/0965', 'G08G1/096725', 'G08G1/096783', 'G08G1/143', 'G08G1/146', 'G08G1/148', 'G08G1/161', 'G08G1/165', 'G08G1/166', 'G08G1/167', 'G08G1/20', 'G08G1/205', 'G16Y10/80', 'G16Y30/00', 'H04L12/2803', 'H04L12/2816', 'H04L12/2825', 'H04L67/306', 'H04N7/183', 'B60R2021/0027', 'B60R2021/01013', 'B60R2025/1013', 'B60W2420/403', 'B60W2420/408', 'B60W2530/209', 'B60W2540/229', 'B60W2552/05', 'B60W2552/35', 'B60W2554/4026', 'B60W2554/4029', 'B60W2554/4041', 'B60W2554/406', 'B60W2556/10', 'G01S19/42', 'G06F2221/034', 'G06N20/00', 'H04L67/12', 'Y02A10/40', 'Y02T10/70', 'Y02T10/7072', 'Y02T90/12']"
US11636337B2,System and method for knowledge distillation between neural networks,"Systems and methods for knowledge distillation provide supervised training of a student network with a teacher network, including inputting a batch to the teacher network, inputting the batch to the student network, generating a teacher activation map at a layer of the teacher network, generating a student activation map at a layer of the student network corresponding to the layer of the teacher network, generating a pairwise teacher similarity matrix based on the teacher activation map, generating a pairwise student similarity matrix based on the student activation map, and minimizing a knowledge distillation loss defined as a difference between the pairwise teacher similarity matrix and the pairwise student similarity matrix.","['G06N3/08', 'G06F17/16', 'G06F17/18', 'G06F18/20', 'G06K9/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06N3/096']"
CN113920370B,"Model training method, target detection method, device, equipment and storage medium","The embodiment of the application discloses a model training method, a target detection method, a device, equipment and a storage medium, wherein the method comprises the steps of obtaining a first sample with an instance-level label and a second sample with an image-level label, obtaining the second sample based on the instance-level label of the first sample, determining a pseudo label of sample data in the second sample through a pre-trained target detection model, determining original detection loss of the target detection model based on the instance-level label of the sample data in the first sample, determining classification enhancement loss of the target detection model based on the pseudo label of the sample data in the second sample, and training the target detection model by using the first sample and the second sample based on the original detection loss and the classification enhancement loss.","['G06F18/24', 'G06N3/045', 'G06N3/08', 'Y02T10/40']"
US20220101113A1,Knowledge discovery using a neural network,"Apparatuses, systems, and techniques to identify one or more relationships among one or more words using one or more transformer-based language neural networks trained using domain-specific data.","['G06N5/04', 'G06F40/284', 'G06F40/30', 'G06F18/214', 'G06F40/263', 'G06F40/40', 'G06K9/6256', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/061', 'G06N3/08', 'G06N3/084', 'G06N5/027', 'G16B40/20', 'G16B40/30', 'G16H50/70', 'G16H70/40', 'G06F40/169', 'G06N3/063', 'G16H10/20']"
CN113392209B,"Text clustering method based on artificial intelligence, related equipment and storage medium","The embodiment of the application provides a text clustering method based on artificial intelligence, related equipment and a storage medium, wherein the method comprises the following steps: acquiring a plurality of texts to be clustered; inputting each text in a plurality of texts to be clustered into a vector extraction model to obtain an output vector corresponding to each text, wherein the vector extraction model is obtained by pre-training and fine-tuning a bi-directional coding representation BERT model based on a transformer by utilizing a training sample and keywords in the training sample; determining a representation vector of each text according to a word frequency-inverse document frequency TF-IDF algorithm and the output vector corresponding to each text; and clustering a plurality of representation vectors corresponding to the texts by using a clustering algorithm to obtain at least one class cluster, so that the vector representation of the text fully learns key information and context information of the text, and clustering is performed based on the vector representation, thereby being beneficial to improving the accuracy and efficiency of text clustering.","['G06F16/35', 'G06F16/951', 'G06F40/289']"
US20210374947A1,Contextual image translation using neural networks,"Apparatuses, systems, and techniques to facilitate generation of one medical image from another medical image using one or more neural networks trained using a generative adversarial network (GAN) that utilizes a bidirectional encoder representations from transformers (BERT) as a discriminator. In at least one embodiment, one or more neural networks trained using a GAN comprising a BERT discriminator generate a positron emission tomography (PET) image from a magnetic resonance imaging (MRI) image.","['G06N3/088', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06T7/0012', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'G06T2207/10088', 'G06V2201/03']"
US20210264195A1,Technologies for enabling analytics of computing events based on augmented canonicalization of classified images,"This disclosure discloses various computing technologies that enable a user to operate a browser to browse a web page that hosts a set of images and an operator of the web page to granularly track how the user is operating the browser with respect to the set of images based on various contextual information depicted in the set of images. Note that this disclosure is not limited to browsers and can be applied to other types of software applications, such as domain dedicated applications, such as e-commerce applications, photo gallery applications, encyclopedia applications, inventory applications, videogame applications, educational applications, social media applications, video streaming applications, or others, or others.","['G06F16/55', 'G06K9/628', 'G06T19/20', 'G06F16/51', 'G06F16/53', 'G06F16/535', 'G06F16/56', 'G06F16/58', 'G06F16/583', 'G06F16/5866', 'G06F16/957', 'G06F18/2431', 'G06K9/00248', 'G06K9/00288', 'G06T19/006', 'G06V10/82', 'G06V40/165', 'G06V40/172', 'G06K2009/00328', 'G06V40/179']"
US12277758B2,Generating videos using sequences of generative neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium. In one aspect, a method includes receiving a text prompt describing a scene; processing the text prompt using a text encoder neural network to generate a contextual embedding of the text prompt; and processing the contextual embedding using a sequence of generative neural networks to generate a final video depicting the scene.","['G06V10/82', 'G06N3/045', 'G06T3/4053']"
CN110647765B,Privacy protection method and system based on knowledge migration under collaborative learning framework,"The disclosure provides a privacy protection method and system based on knowledge migration under a collaborative learning framework, which includes: dividing a local privacy data set into a plurality of mutually disjoint privacy subsets, and training a corresponding privacy model based on each privacy subset; and (3) collaborative learning: submitting the public data to a privacy model, wherein the privacy model uses an aggregation mechanism and utilizes knowledge to migrate to a public data set label; after enough marked data are obtained, the local interaction model is trained, part of parameters are uploaded to the server in each round of training, the server updates and maintains global parameters and provides the latest parameters for all parties to download, and the participants download the latest parameters to optimize the local interaction model. The method can ensure that multiple parameter interactions of simultaneous collaborative learning can still keep higher accuracy after multiple rounds of training even if the interaction model obtains less labeled data.",['G06F21/6245']
US20220129724A1,System and method for facilitating affective-state-based artificial intelligence,"In some embodiments, affective-state-based artificial intelligence may be facilitated. One or more growth or decay factors for a set of affective attributes of an artificial intelligence entity may be determined, and a set of affective values, which are associated with the set of affective attributes, may be continuously updated based on the growth or decay factors. An input may be obtained, and a response related to the input may be generated based on the continuously-updated set of affective values of the artificial intelligence entity. In some embodiments, the growth or decay factors may be updated based on the input and subsequent to the updating of the decay factors, the affective values may be updated based on the updated growth or decay factors.","['G06N3/006', 'G06N5/04', 'G06N20/00', 'G06F40/20', 'G06N3/126', 'G06N5/02', 'G06N7/023', 'G06N3/043', 'G06N3/045', 'G06N3/084', 'G06N5/022', 'G06N7/01']"
CN110929603B,A Weather Image Recognition Method Based on Lightweight Convolutional Neural Network,"The invention discloses a weather phenomenon identification method based on a lightweight convolutional neural network, and belongs to the technical field of image identification. The invention comprises the following steps: constructing a lightweight weather identification network; training a weather identification network model; acquiring a weather picture to be identified and carrying out standardization treatment; the processed data is input into a trained weather recognition network and the category is output. The invention fully utilizes the advantages of the convolutional neural network in the large-scale image recognition field, combines the ideas of depth separable convolution, attention mechanism, residual connection, transfer learning and the like, effectively reduces the computational complexity of the model under the condition of not reducing the recognition precision, and provides possibility for the deployment of the model on small-sized equipment.","['G06V20/13', 'G06N3/045', 'G06N3/08', 'Y02A90/10']"
US20230004760A1,Training object detection systems with generated images,"Apparatuses, systems, and techniques to identify objects within an image using self-supervised machine learning. In at least one embodiment, a machine learning system is trained to recognize objects by training a first network to recognize objects within images that are generated by a second network. In at least one embodiment, the second network is a controllable network.","['G06N3/063', 'G06T7/00', 'G06F18/24', 'G06K9/6267', 'G06N3/08', 'G06N3/0895', 'G06T7/194', 'G06V10/22', 'G06V10/7753', 'G06V10/82', 'G06V20/56', 'G06V20/58', 'G06V30/18057', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/12', 'G06V2201/07']"
US20230153615A1,Neural network distillation method and apparatus,"The technology of this application relates to a neural network distillation method, applied to the field of artificial intelligence, and includes processing to-be-processed data by using a first neural network and a second neural network to obtain a first target output and a second target output, where the first target output is obtained by performing kernel function-based transformation on an output of the first neural network layer, and the second target output is obtained by performing kernel function-based transformation on an output of the second neural network layer. The method further includes performing knowledge distillation on the first neural network based on a target loss constructed by using the first target output and the second target output.","['G06N3/096', 'G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/048']"
CN111813532B,Image management method and device based on multitask machine learning model,"The application discloses an image management method and device based on a multitask machine learning model, and relates to an artificial intelligence machine learning technology. By acquiring image data; then inputting the target image into a shared feature expression network in a multi-task machine learning model to obtain task output features; respectively inputting the task output characteristics into a plurality of subtask networks to obtain an identification result; and then processing the image data based on the recognition result. The image management process based on machine learning is realized, and the features for executing a plurality of tasks are extracted through the shared feature expression network, and corresponding tasks are executed by adopting different subtask networks respectively, so that the execution process of the image management tasks can be realized through the multi-task machine learning model, and the image management efficiency is improved.","['G06F9/4881', 'G06N20/00', 'G06T1/00']"
CN112149722B,An automatic image annotation method based on unsupervised domain adaptation,"The invention provides an image automatic labeling method based on unsupervised domain adaptation, which comprises the following steps: collecting a source domain image and a label, and collecting a target domain image; constructing a detection frame, and constructing a domain classifier to extract global features and local features; training the existing data by using a Pytorch deep learning framework application algorithm to obtain a trained domain adaptation detection model; detecting a test data set (a target domain is not marked with a picture) by using the existing latest model to obtain a preliminary detection result; and carrying out secondary processing extraction by utilizing the primary detection result file to generate an xml annotation file in the PASCAL VOC format. According to the method, based on the domain adaptation method, under the condition that a large amount of target domain data is not marked, the training can be put into the automatic marking of the data only by having the source domain picture and the marking data similar to the target domain data. Compared with the prior art, the method has the advantages of good flexibility, higher classification precision, simple model and high practicability.","['G06F18/24', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30204', 'G06V2201/07']"
CN112966691B,"Multi-scale text detection method, device and electronic device based on semantic segmentation","The invention relates to the field of deep learning and computer vision, in particular to a multi-scale text detection method and device based on semantic segmentation and electronic equipment; the method comprises the steps of collecting character images and preprocessing the character images; the character images comprise training character images and character images to be detected; inputting the preprocessed character image into a semantically segmented character detection network, and outputting a text boundary area label and a text center area label of the character image; performing binarization fusion on a text boundary region corresponding to the character image and a text center region to obtain a character image after segmentation fusion; carrying out post-processing on the character image after segmentation and fusion to determine a character area, namely the coordinate position of the character; the invention performs supervised learning through the double labels, fully utilizes high-level semantic features and reduces potential semantic feature learning.","['G06V30/153', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V30/10']"
US20210118136A1,Artificial intelligence for personalized oncology,"Techniques performed by a data processing system for operating a personalized oncology system herein include accessing a first histopathological image of a histopathological slide of a sample taken from a first patient; analyzing the first histopathological image using a first machine learning model configured to extract first features from the first histopathological image; searching a histological database that includes a plurality of second histopathological images and corresponding clinical data for a plurality of second patients to generate search results; analyzing the plurality of third histopathological images and the corresponding clinical data associated with the plurality of third histopathological images using statistical analysis techniques to generate associated statistics and metrics associated with mortality, morbidity, time-to-event, or a combination thereof for the plurality of third patients associated with the third histopathological images; and presenting an interactive visual representation of the associated statistics and metrics including information for the personalized therapeutic plan for treating the first patient.","['G16H50/70', 'G02B21/365', 'G06F16/535', 'G06T7/0012', 'G06T7/0014', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/698', 'G16B20/20', 'G16B40/00', 'G16B50/00', 'G16H20/40', 'G16H50/20', 'G16H50/30', 'G02B21/34', 'G06F18/214', 'G06K9/00147', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G16H10/60', 'G16H30/20', 'G16H30/40']"
US11868582B2,Apparatus for controlling device based on augmented reality and method thereof,"An augmented reality-based device control method and a control apparatus thereof are disclosed. The augmented reality-based device control method includes obtaining a real image with a device to be controlled as a subject, as an image which configures an augmented reality (AR)-based remote controller and detecting a remote control (RC) protocol of the device to be controlled by recognizing the real image. The detecting of an RC protocol of the device to be controlled includes verifying whether the device to be controlled is controllable through a candidate RC protocol based on whether the device to be controlled operates according to the real image. According to the present disclosure, the device can be controlled based on the augmented reality using artificial intelligence (AI)-based image recognition through a 5G network.","['G06F3/04815', 'H04Q9/00', 'G05B15/02', 'G06F3/011', 'G06T11/00', 'G06T19/006', 'G08C17/00', 'G08C17/02', 'H04L12/281', 'H04L67/08', 'H04L67/131', 'G08C2201/30', 'G08C2201/93', 'H04Q2209/40']"
US20240265309A1,"Item recommendation method and apparatus, and storage medium","This application relates to the artificial intelligence field, and in particular, to an item recommendation method and apparatus, and a storage medium. The method includes: obtaining historical interaction data of a target object, where the historical interaction data indicates a historical interaction event between the target object and at least one item; obtaining a pre-trained target recommendation model, where the target recommendation model includes a graph neural network model with one convolutional layer, and the convolutional layer indicates an association relationship between a sample object and a sample item; and invoking, based on the historical interaction data, the target recommendation model to output a target item corresponding to the target object. In the embodiments of this application, a framework structure of the target recommendation model is simplified, so that model operation time is greatly reduced.","['G06F16/9535', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06Q30/0601', 'G06Q30/0631']"
US20210342669A1,"Method, system, and medium for processing satellite orbital information using a generative adversarial network","Method, electronic device, system, and computer-readable medium embodiments are disclosed. Some embodiments include a signal processing workflow incorporating a graphical user interface for displaying orbital information for satellites and other spacecraft. In some embodiments, a generative adversarial network (GAN) is employed for evaluating satellite orbital positions, for predicting future orbital movements, for detecting orbital maneuvers of a satellite, and for analyzing such maneuvers for potential nefarious intent.","['G06N3/0454', 'G01V3/38', 'G01V3/16', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084']"
US12249346B2,Method for detecting and classifying coughs or other non-semantic sounds using audio feature set learned from speech,"A method of detecting a cough in an audio stream includes a step of performing one or more pre-processing steps on the audio stream to generate an input audio sequence comprising a plurality of time-separated audio segments. An embedding is generated by a self-supervised triplet loss embedding model for each of the segments of the input audio sequence using an audio feature set, the embedding model having been trained to learn the audio feature set in a self-supervised triplet loss manner from a plurality of speech audio clips from a speech dataset. The embedding for each of the segments is provided to a model performing cough detection inference. This model generates a probability that each of the segments of the input audio sequence includes a cough episode. The method includes generating cough metrics for each of the cough episodes detected in the input audio sequence.","['A61B5/0823', 'A61B5/4803', 'A61B5/6898', 'A61B5/7267', 'A61B5/7282', 'G10L15/02', 'G10L15/04', 'G10L15/063', 'G10L25/30', 'G10L25/51', 'G10L25/78', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'A61B5/0022', 'G10L25/66']"
US10283101B2,Systems and methods for capturing and interpreting audio,"A device is provided as part of a system, the device being for capturing vibrations produced by an object such as a musical instrument. Via a fixation element, the device is fixed to a drum. The device has a sensor spaced apart from a surface of the drum, located relative to the drum, and a magnet adjacent the sensor. The fixation element transmits vibrations from its fixation point on the drum to the magnet. Vibrations from the surface of the drum and from the magnet are transmitted to the sensor. A method may further be provided for interpreting an audio input, such as the output of the sensors within the system, the method comprising identifying an audio event or grouping of audio events within audio data, generating a model of the audio event that includes a representation of a timbre characteristic, and comparing that representation to expected representations.","['G10H1/06', 'G10H3/146', 'G01H1/00', 'G01H11/00', 'G01H11/02', 'G01H11/08', 'G10D13/02', 'G10D13/024', 'G10D13/26', 'G10H1/14', 'G10H3/12', 'G10H3/143', 'G10H7/00', 'G10H7/008', 'G10H2210/041', 'G10H2210/051', 'G10H2210/265', 'G10H2210/281', 'G10H2220/091', 'G10H2220/525', 'G10H2230/251', 'G10H2230/281', 'G10H2240/121', 'G10H2250/235', 'G10H2250/311', 'G10H2250/315', 'G10H2250/435', 'G10H2250/641']"
WO2022036867A1,Method for reconstructing three-dimensional model of transformer substation,"A method for reconstructing a three-dimensional model of a transformer substation, the method comprising: acquiring three-dimensional model public database data to compose a basic training set (110); acquiring an original image of a transformer substation device for marking and determining a migration learning training set (120); processing images of the basic training set and the migration learning training set and extracting same to obtain a device feature map (130), and constructing a deep convolutional self-encoding neural network on the basis of the device feature map (140); training the deep convolutional self-encoding neural network by using the basic training set (150), and further training the deep convolutional self-encoding neural network by using the migration learning training set (160); and modeling the transformer substation according to the trained deep convolutional self-encoding neural network to obtain a three-dimensional model of the transformer substation (170).","['G06F30/27', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06Q50/06', 'G06T17/00', 'Y04S10/50']"
US11710070B2,Machine learned model framework for screening question generation,"In an example embodiment, a screening question-based online screening mechanism is provided to assess job applicants automatically. More specifically, job-specific questions are automatically generated and asked to applicants to assess the applicants using the answers they provide. Answers to these questions are more recent than facts contained in a user profile and thus are more reliable measures of an appropriateness of an applicant's skills for a particular job.","['G06N20/00', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06Q10/1053', 'G06N5/022']"
US20210125732A1,System and method with federated learning model for geotemporal data associated medical prediction applications,The technology disclosed relates to a system and method for predicting comorbidity trajectories of disease categories on a census tract-basis. The system include logic to process satellite images for a particular census tract and generate respective latent feature vectors for respective satellite images. The system include logic to determine respective weighted average latent feature vectors for the respective latent feature vectors. The respective weighted average latent feature vectors are regressed against a plurality of disease categories and a plurality of risk factors. The regressor generates prevalence scores for disease categories in the plurality of disease categories and for risk factors in the plurality of risk factors. The system can correlate the disease categories with each other and with risk factors to determine comorbidity trajectories of the disease categories in the particular census tract.,"['G16H50/80', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/084', 'G06N5/003', 'G06N5/01', 'G16H50/20', 'G16H50/50', 'G06N3/048']"
US12211277B2,Interactive video surveillance as an edge service using unsupervised feature queries,"A method for querying data obtained from a distributed sensor network, comprising: receiving sensor data representing an aspect of an environment with a sensor of the distributed sensor network; communicating a representation of the sensor data to a fog node through an automated communication network; determining, by the fog node, a correspondence of a query received through the automated communication network to characteristics of the representation of the sensor data; and selectively communicating, in response to the query, at least one of: the sensor data having the determined characteristics corresponding to the query, an identification of the sensor data having the determined characteristics corresponding to the query, and the data representing the sensor data having the determined characteristics corresponding to the query.","['G06V20/46', 'G06F16/785', 'G06F16/7854', 'G06F16/786', 'G06F16/7867', 'G06V10/95', 'G06V20/41', 'G06V20/52', 'G06V40/103']"
CN114170497B,Multi-scale underwater fish school detection method based on attention module,"The invention discloses a multi-scale underwater fish swarm detection method based on an attention module, belonging to the technical field of marine fish resource detection. Firstly, acquiring an underwater fish swarm image, selecting a fish swarm image from the underwater fish swarm image, performing enhanced pretreatment on the underwater image aiming at the characteristics of dim underwater environment, complex background and tiny and dense fish swarm image, and based on an optimized YOLO V4 detection frame, increasing an ECA attention mechanism to enable a network to concentrate on fish body feature learning, overcoming background interference, improving PANet connection, increasing multi-scale information, enhancing feature extraction and improving detection precision. The method realizes automatic detection of the underwater fish shoal; scientific theory and technical support are provided for automatic detection of fish, scientific fishing is designated, ocean resources can be better protected, and sustainable healthy development of an ocean system is promoted; and can provide a reference scheme for the detection of other marine organisms.","['G06F18/214', 'G06F18/217', 'G06F18/253', 'G06N3/045', 'G06N3/048', 'G06N3/082']"
CN112232293B,"Image processing model training method, image processing method and related equipment","In the image processing model training method and the image processing method and the related equipment, when the image processing task of the target scene is faced and the target image processing model meeting the image processing task needs to be trained, the real image sample under the target scene, the simulated image sample and the labeling information under the simulated scene constructed aiming at the target scene are acquired, the labeling information of the real image sample does not need to be manually determined, the sample data acquisition cost is reduced, the sample data acquisition efficiency and the accuracy are improved, the real image sample, the simulated image sample and the labeling information are utilized to carry out supervision countermeasure training on the deep learning network to obtain the target image processing model, and compared with the method for directly carrying out supervision training on the simulated image sample and the labeling information, the training mode can ensure that the real image processing model is reliable, reliable and capable of improving the image processing efficiency, Accurate and meets the image processing task.","['G06V20/56', 'G06F18/214', 'G06N3/08', 'G06T17/00', 'G06V10/267']"
CN114502061B,Image-based automatic skin diagnosis using deep learning,A deep learning based system and method for skin diagnosis and test metrics are shown and described that shows that such a deep learning based system performs better than a human expert in apparent skin diagnosis tasks. A system and method for monitoring a skin treatment regimen using a deep learning based system and method for skin diagnosis is also shown and described.,"['A61B5/441', 'A61B5/0077', 'A61B5/7267', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06V10/454', 'G06V10/82', 'G06V40/171', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088', 'G06T2207/30201', 'G06V2201/03', 'G06V40/174', 'G06V40/18']"
CN112292691B,Methods and systems for improving cancer detection using deep learning,"A method and system for generating a probabilistic prediction of the presence/absence of cancer and a location of cancer in a longitudinal and current image dataset and/or a multimodal image dataset is described. The method and system use integration of deep learning models. The integration includes globally extracting a global model in the form of a 3D Convolutional Neural Network (CNN) that indicates the presence of a cancer from the dataset based on the global. The integration also includes a two-stage prediction model comprising: a first stage or detection model, identifying cancer detection candidates (different cropped volumes of 3D data in the dataset that contain candidates that are likely to be cancer); and a second stage or probability model that combines the longitudinal dataset (or multimodal image in the multimodal dataset) with the extracted features from the global model and assigns a cancer probability p to each cancer detection candidate. For example, using Noisy-OR method, an overall prediction of cancer probability is obtained from the probabilities assigned by the second stage model.","['G06F18/254', 'G06F18/213', 'G06F18/2415', 'G06N20/20', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06T7/11', 'G06T7/73', 'G16H50/20', 'G06T2207/10081', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30061', 'G06T2207/30096', 'G06V2201/03', 'G06V2201/031']"
CN113469236B,Self-tag learning deep clustering image recognition system and method,"The invention discloses a self-label learning deep clustering image recognition system and a self-label learning deep clustering image recognition method, which belong to the technical fields of computer vision, image clustering and artificial intelligence and comprise the following modules: the device comprises a pre-training depth convolution automatic encoder module, a sample characteristic clustering module and a sample re-selection and re-training module. Compared with the prior art, the self-label learning depth clustering image recognition method designed for the image data extracts the depth characteristics of samples through a convolution automatic encoder, distributes clustered pseudo labels for each sample through an embedded clustering layer, screens out samples with higher confidence in the pseudo labels, and transmits the samples into a convolution neural network for retraining so as to obtain a better clustering model. The method can effectively improve the utilization rate of pseudo tag information after sample clustering and improve the performance of an image clustering algorithm.","['G06F18/23213', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'Y02T10/40']"
US12361221B2,Grammar transfer using one or more neural networks,"Apparatuses, systems, and techniques to transfer grammar between sentences. In at least one embodiment, one or more first sentences are translated into one or more second sentences having different grammar using one or more neural networks.","['G06F40/30', 'G06F18/241', 'G06F40/253', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G10L15/063', 'G10L15/16', 'G10L15/1815', 'G10L15/22', 'G06N20/10', 'G06N3/02', 'G06N3/044', 'G06N3/047', 'G06N3/088']"
US11045271B1,Robotic medical system,"A system includes a camera; an AI visual processor to classify and recognize human anatomical features, and a processor to control robot movement to reach a selected anatomical target.","['G16H40/67', 'A61B34/70', 'A61B18/1492', 'A61B34/30', 'A61B34/32', 'A61B34/37', 'A61B90/361', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G16H20/40', 'G16H40/63', 'G16H50/20', 'G16H50/80', 'A61B2018/00351', 'A61B2018/00482', 'A61B2018/00577', 'A61B2018/126', 'A61B2018/143', 'A61B2034/2065', 'A61B2034/301', 'A61B2034/302', 'A61B2034/303', 'A61B2090/306', 'A61B2090/3612', 'A61B2090/3614', 'A61B2090/365', 'A61B2090/3735', 'A61B2090/378', 'G06N3/008', 'G06N3/047', 'G06N3/08', 'G06N5/022']"
US20200303060A1,Diagnostics using one or more neural networks,"Apparatuses, systems, and techniques are presented to analyze objects in images including digital representations of those objects. In at least one embodiment, one or more diagnostic processes are determined based, at least in part, on one or more neural networks used to identify one or more medical images.","['G06Q10/103', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/063', 'G06N3/082', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20']"
CN108872984B,Human body identification method based on multi-base radar micro Doppler and convolutional neural network,"The invention relates to a human body identification method based on multi-base radar micro Doppler and a convolutional neural network, and belongs to the technical field of radar target identification. The method uses the multi-base mines, relieves the difference of echo signals caused by the change of visual angles, enhances the recognition robustness and improves the recognition accuracy. The convolutional neural network is adopted for data processing, manual design of characteristics is not needed, certain universality is achieved, and the recognition accuracy performance is excellent. The method adopts the transfer learning technology, utilizes the RGB optical image pre-training weight in the convolutional neural network, utilizes the three-channel multi-resolution time-frequency graph with the similar RGB optical image as the input of the convolutional neural network, matches the dimension of the pre-training weight, and provides more information compared with a single-resolution time-frequency graph.","['G01S13/90', 'G01S13/9017', 'G01S7/417', 'G01S13/9047']"
WO2021135509A1,"Image processing method and apparatus, electronic device, and storage medium","Provided are an image processing method and apparatus, an electronic device, and a storage medium. The method comprises: acquiring a facial image to be processed (110); extracting key facial points of the facial image (120); on the basis of the key facial points, positioning a sensitive expression area in the facial image, wherein the sensitive expression area is a localized facial area with intensive expression feature information (130); and on the basis of the sensitive expression area, carrying out expression recognition on the facial image (140).","['G06V40/174', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06V10/44', 'G06V40/161', 'G06V40/171']"
US11804050B1,Processor and system to train machine learning models based on comparing accuracy of model parameters,"Apparatuses, systems, and techniques to collaboratively train one or more machine learning models. Parameter reviewers may be configured to compare sets of machine learning model parameter information in order to generate one or more machine learning models, such as neural networks.","['G06V20/64', 'G06F18/214', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N3/044', 'G06N3/088', 'G06N3/105']"
US12008473B2,Augmenting machine learning language models using search engine results,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for augmenting machine learning language models using search engine results. One of the methods includes obtaining question data representing a question; generating, from the question data, a search engine query for a search engine; obtaining a plurality of documents identified by the search engine in response to processing the search engine query; generating, from the plurality of documents, a plurality of conditioning inputs each representing at least a portion of one or more of the obtained documents; for each of a plurality of the generated conditioning inputs, processing a network input generated from (i) the question data and (ii) the conditioning input using a neural network to generate a network output representing a candidate answer to the question; and generating, from the network outputs representing respective candidate answers, answer data representing a final answer to the question.","['G06N3/08', 'G06F16/3329', 'G06F16/953', 'G06N3/0455', 'G06N3/088', 'G06N3/096', 'G06N20/00', 'G06N3/02', 'G06N5/04']"
CN110033479B,Traffic flow parameter real-time detection method based on traffic monitoring video,"The invention discloses a traffic flow parameter real-time detection method based on traffic monitoring video, which comprises the following steps: video pre-calibration: calibrating the type and the position of the vehicle; and (3) target detection: training a deep learning model based on SSD vehicle target detection by using pre-calibrated data; coordinate mapping: solving the mapping relation between the monitoring video image coordinate system and the world coordinate system; vehicle target tracking: the vehicle running is tracked in real time by adopting a kernel correlation filter tracking algorithm and combining a deep learning model of vehicle target detection; index acquisition and calculation: setting a calibration area timer, acquiring a time index, combining a vehicle target detection result, a tracking result of a vehicle tracking algorithm and a timing result of the timer, and obtaining a real-time detection result of traffic flow parameters through coordinate mapping conversion. The invention solves the problem of directly obtaining the traffic flow parameters from the traffic monitoring video, and can complete real-time accurate detection of a plurality of traffic flow parameters at one time.","['G06T7/13', 'G06T7/246', 'G06T7/80', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/30232', 'Y02T10/40']"
US12017352B2,Transformation of joint space coordinates using machine learning,"Apparatuses, systems, and techniques to map coordinates in task space to a set of joint angles of an articulated robot. In at least one embodiment, a neural network is trained to map task-space coordinates to joint space coordinates of a robot by simulating a plurality of robots at various joint angles, and determining the position of their respective manipulators in task space.","['B25J9/023', 'B25J9/163', 'B25J9/1664', 'B25J9/1676', 'G05B2219/39064']"
CN112766607B,"Travel route recommendation method and device, electronic device and readable storage medium","The embodiment of the application provides a method and a device for recommending a travel route, electronic equipment and a readable storage medium, and relates to the technical fields of artificial intelligence, map navigation, intelligent transportation, internet of vehicles and the like. The method comprises the following steps: obtaining travel position information of a target object, wherein the travel position information comprises a starting point position and an end point position; acquiring the characteristics of a target object and road condition characteristics of each associated road of travel position information; and determining a target travel mode from the candidate travel modes by calling a pre-trained travel mode recommendation model according to the target object characteristics and the road condition characteristics of the associated roads, and recommending the target travel mode to the target object. The problem that the travel mode is manually selected at present is effectively solved, and the finally determined target travel mode is determined according to the characteristics of the target object and the road condition characteristics of all relevant roads of the travel position information of the target object, so that the actual preference and the actual demand are better met.","['G06Q10/047', 'G06F16/29', 'G06N3/045']"
US10818398B2,System and method for AI-based eye condition determinations,"In some embodiments, a set of eye images related to a subject may be provided to a prediction model. A first prediction may be obtained via the prediction model, where the first prediction is derived from a first eye image and indicates whether an eye condition is present in the subject. A second prediction may be obtained via the prediction model, where the second prediction is derived from a second eye image and indicates that the eye condition is present in the subject. An aspect associated with the first prediction may be adjusted via the prediction model based on the second prediction's indication that the eye condition is present in the subject. One or more predictions related to at least one eye condition for the subject may be obtained from the prediction model, where the prediction model generates the predictions based on the adjustment of the first prediction.","['A61B3/1005', 'A61B3/0025', 'A61B3/0058', 'G06N20/10', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06T7/0016', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041']"
US10579875B2,Systems and methods for object identification using a three-dimensional scanning system,"A method for identifying and tracking objects includes: capturing one or more 3-D models of one or more objects in a scene using a three-dimensional (3-D) scanning system, the one or more 3-D models including color and geometry information of the one or more objects; and computing, by an analysis agent, one or more descriptors of the one or more 3-D models, each descriptor corresponding to a fixed-length feature vector; and retrieving metadata identifying the one or more objects based on the one or more descriptors.","['G06K9/00664', 'G06V10/82', 'G06F18/24', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06Q20/208', 'G06T15/10', 'G06T17/00', 'G06T7/0004', 'G06T7/174', 'G06T7/285', 'G06V10/764', 'G06V20/10', 'G06V20/52', 'G06V20/64', 'G07G1/0063', 'G06T2207/10012', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US11232330B2,Adaptive neural network selection to extract particular results,"Method, electronic device, and computer readable medium embodiments are disclosed. In one embodiment, a method includes receiving image data, manipulating the received image data based on a set of transform parameters, and analyzing the manipulated image data to generate metadata. The metadata statistically describes the received image data. The method also includes selecting a neural network from a plurality of neural networks to perform a second analysis, wherein the neural network is selected based on the generated metadata. The method additionally includes performing a second analysis of the received image data by the selected neural network based on the generated metadata to extract information from the received image data.","['G06K9/66', 'G06N3/088', 'G06F18/241', 'G06F18/285', 'G06K9/00637', 'G06K9/6227', 'G06K9/6268', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06V20/176']"
CN113657388B,Image semantic segmentation method for super-resolution reconstruction of fused image,"The invention discloses an image semantic segmentation method for super-resolution reconstruction of a fusion image, which comprises the following steps: initializing parameters of a convolutional neural network based on a pre-trained ResNet-50 network model; preprocessing a data set, inputting the preprocessed data set into a downsampling encoding stage of the initialized network model for image feature extraction; performing super-resolution reconstruction on the image by using the extracted image features to obtain a high-resolution feature map; the extracted image features and the reconstructed high-resolution feature images are subjected to feature fusion, input to a feature decoder of a network model, a guided up-sampling module is built by utilizing the reconstructed high-resolution feature images, offset vectors of all pixel points are manufactured to serve as offset tables, and up-sampling operation is carried out by taking the offset tables as guidance, so that an image semantic segmentation result is obtained; and defining a loss function, and optimizing the network model. The method and the device can improve the precision of the semantic segmentation algorithm.","['G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/084', 'G06T3/4053', 'Y02T10/40']"
US10782691B2,Deep learning and intelligent sensing system integration,"Disclosed herein are systems, methods, and apparatuses for deep learning and intelligent sensing system integrations. A processor may be configured to receive a plurality of images from the sensor system, identify objects in the images in an offline mode, classify the objects in the images in the offline mode, generate heat maps in the offline mode, and send instructions regarding operation of the maritime vessel based on the objects that are identified. The visual sensor may be a stereoscopic camera. The processor may be further configured to perform stereoscopy. The instructions may include a speed or a heading of, for example, a maritime vessel.","['G05D1/0206', 'G06K9/00624', 'G06T7/593', 'G06V10/454', 'G06V10/82', 'G06V10/95', 'G06V10/955', 'G06V20/00', 'G06T2207/10012', 'G06T2207/20084', 'G06T2207/30261', 'G06V2201/07', 'H04N13/239', 'H04N2013/0081']"
CN111325748B,Infrared thermal image nondestructive testing method based on convolutional neural network,"An infrared thermal image nondestructive testing method based on a convolutional neural network belongs to the field of image recognition. The existing nondestructive detection of the convolutional neural network cannot be applied to infrared imaging. An infrared thermal image nondestructive testing method based on a convolutional neural network comprises the following steps: arranging an infrared image data acquisition scene, and acquiring an infrared image with defects of an object to be detected; performing enhancement and noise reduction treatment on the acquired infrared image with the defects of the object to be detected, and completing a pretreatment process; utilizing the pretreated infrared image with defects of the object to be detected to amplify and construct a data set; fusing the models of VGG16 and DenseNet169 networks, and training, testing and identifying the fused models by utilizing a data set; and identifying and detecting the defects in the infrared image with the defects of the object to be detected by utilizing the fused network model. The identification accuracy of the detection method of the invention reaches 98.5 percent.","['G06T7/0002', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084']"
CN112084331B,"Text processing, model training method, device, computer equipment and storage medium","The application relates to a text processing and model training method, a device, computer equipment and a storage medium. The text processing method comprises the following steps: obtaining a target text to be processed, and coding the target text to obtain a target text coding vector; acquiring a target entity in a target text, and determining a first associated entity corresponding to the target entity; determining a target knowledge representation vector corresponding to the target entity according to the entity representation vector of the first associated entity and the corresponding attention weight; carrying out fusion processing on the target text coding vector and a target knowledge representation vector corresponding to the target entity to obtain a target fusion result; and determining a text processing result corresponding to the target text according to the target fusion result. The text processing result of the embodiment of the application can be processed by the text processing model based on artificial intelligence, and the accuracy of the obtained text processing result can be improved by adopting the method.","['G06F16/353', 'G06F16/345', 'G06F18/25', 'G06F40/211', 'G06F40/268', 'G06F40/295', 'G06F40/30', 'G06F40/58', 'G06N3/045', 'G06N3/08']"
CN114556354B,Automatically determine and present personalized action items from events,"A computerized system is provided for automatically determining action items for an event such as a meeting. The determined action item may be personalized for a particular user, such as a meeting attendee, and may include contextual information that enables the user to understand the action item. Specifically, personalized action items may be determined based in part on determining and utilizing specific factors in connection with an event dialog, such as the language style of the event speaker, user roles in the organization, historical patterns of communication, event purpose, name or location, event participants or other contextual information. A particular statement is evaluated to determine if the statement may or may not be an action item. The context information may be determined for the action item and then provided to a particular user during or after the event.","['G06F40/20', 'G06F40/30', 'G06N20/20', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/046', 'G06Q10/109', 'G06Q10/1093', 'G06N3/044', 'G06N3/047', 'G06N7/01']"
US11704791B2,Multivariate and multi-resolution retinal image anomaly detection system,"Machine learning technologies are used to identify and separating abnormal and normal subjects and identifying possible disease types with images (e.g., optical coherence tomography (OCT) images of the eye), where the machine learning technologies are trained with only normative data. In one example, a feature or a physiological structure of an image is extracted, and the image is classified based on the extracted feature. In another example, a region of the image is masked and then reconstructed, and a similarity is determined between the reconstructed region and the original region of the image. A label (indicating an abnormality) and a score (indicating a severity) can be determined based on the classification and/or the similarity.","['G06T7/0012', 'G06V40/193', 'A61B3/102', 'G06N20/20', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/809', 'A61B3/12', 'A61B5/7275', 'G06N3/045', 'G06T2207/30041', 'G06V2201/03']"
US12190072B2,Profile-based natural language message generation and selection,"In some embodiments, text for user consumption may be generated based on an intended user action category and a user profile. In some embodiments, an action category, a plurality of text seeds, and a profile comprising feature values may be obtained. Context values may be generated based on the feature values, and text generation models may be obtained based on the text seeds. In some embodiments, messages may be generated using the text generation models based on the action category and the context values. Weights associated with the messages may be determined, and a first text message of the messages may be sent to an address associated with the profile based on the weights. Based on a reaction value obtained in response to the first message, a first expected allocation value may be updated based on the reaction value.","['G06F40/42', 'H04L51/48', 'H04L67/306']"
CN110427846B,Face recognition method for small unbalanced samples by using convolutional neural network,"The invention relates to a face recognition method for small unbalanced samples by using a convolutional neural network. The method comprises the following steps: aiming at the problem of unbalance of positive and negative samples in a training data set, a DCGAN countermeasure generation network is utilized to generate data samples which are approximately distributed with original training data, and the diversity of a small amount of samples is increased. Aiming at the problems that deep learning needs a large amount of training data and overfitting is easy to occur on a small sample, the problem is solved by using transfer learning, and firstly an Alex-Net network trained on an Image-Net large data set is transferred to a target data set; and then changing the number of the neurons of the output layer into a target data set category, and finally training the reinitialization of the following full-connection layer by using the target data set. The method starts from unbalanced and small data sets, and solves the problem of low confidence coefficient when the small data sets are easy to over-fit and the samples are unbalanced by using a deep learning method.","['G06N3/045', 'G06N3/084', 'G06V40/172']"
CN110826328B,"Keyword extraction method, device, storage medium and computer equipment","The application relates to a keyword extraction method, a keyword extraction device, a computer readable storage medium and computer equipment, wherein the method comprises the steps of respectively sliding a target text to obtain a plurality of word combinations under each co-occurrence window according to at least two co-occurrence windows; the method comprises the steps of determining co-occurrence probability among different words in each word combination based on a word vector model, determining the words with the co-occurrence probability meeting screening conditions as candidate words in each word combination, determining contribution probability of each candidate word to interpretation of a target text in a candidate word set formed by the candidate words of each word combination according to the conditional probability of the candidate words in a corpus, and determining the candidate words with the contribution probability meeting threshold conditions as keywords. The scheme provided by the application can improve the keyword extraction accuracy.","['G06F16/3344', 'G06F16/3346', 'G06F16/35', 'G06F18/2415', 'G06F18/24323']"
US11449989B2,Super-resolution anatomical magnetic resonance imaging using deep learning for cerebral cortex segmentation,"Super-resolution images are generated from standard-resolution images acquired with a magnetic resonance imaging (“MRI”) system. More particularly, super-resolution (e.g., sub-millimeter isotropic resolution) images are generated from standard-resolution images (e.g., images with 1 mm or coarser isotropic resolution) using a deep learning algorithm, from which accurate cortical surface reconstructions can be generated.","['G06T7/0012', 'G01R33/5608', 'G01R33/5602', 'G06T3/4007', 'G06T3/4053', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T7/11']"
CN111144496B,Garbage classification method based on hybrid convolutional neural network,"A garbage classification method based on a hybrid convolutional neural network belongs to the technical field of garbage classification and recycling. The invention solves the problems of low precision of garbage classification and long required training time of the existing method. The mixed convolution neural network model flexibly utilizes convolution layers, batch standardization, a maximum pooling layer and a full-link layer, and further enhances the capability of the model for extracting features after BN batch standardization is used for each convolution layer and the full-link layer, so that each layer can fully play a role, and a better classification result is obtained. By utilizing the regularization effect of the BN layer, the maximum pooling layer is properly added to carry out statistics on the features, the feature dimension is reduced, the characterization capability is improved, the fitting is good, the convergence rate is high, the parameter quantity is small, the calculation complexity is low, and the method has obvious advantages compared with the traditional convolutional neural network. Meanwhile, an SGDM + Nesterov optimizer is adopted in the model, and the classification accuracy of the final model on the image reaches 92.6%. The invention can be applied to the classification of household garbage.","['G06F18/214', 'G06F18/213', 'G06N3/045', 'Y02W30/10']"
WO2021218899A1,"Method for training facial recognition model, and method and apparatus for facial recognition","A method for training a facial recognition model, and a method and an apparatus for facial recognition, relating to the technical field of image processing. The method for training a facial recognition model comprises: acquiring sample facial images; on the basis of the sample facial images, training an initial facial recognition model to obtain a pre-trained facial recognition model for detecting the position of a face in the images; and using a first trained neural network model and a second trained neural network model to perform second training on the pre-trained recognition model on the basis of the sample facial images to obtain a target facial recognition model.","['G06V40/161', 'G06N3/045', 'G06N3/084', 'G06V40/168', 'G06V40/172', 'Y02T10/40']"
US11886989B2,System for measuring information leakage of deep learning models,"Using a deep learning inference system, respective similarities are measured for each of a set of intermediate representations to input information used as an input to the deep learning inference system. The deep learning inference system includes multiple layers, each layer producing one or more associated intermediate representations. Selection is made of a subset of the set of intermediate representations that are most similar to the input information. Using the selected subset of intermediate representations, a partitioning point is determined in the multiple layers used to partition the multiple layers into two partitions defined so that information leakage for the two partitions will meet a privacy parameter when a first of the two partitions is prevented from leaking information. The partitioning point is output for use in partitioning the multiple layers of the deep learning inference system into the two partitions.","['G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/048']"
US11691648B2,Drivable surface identification techniques,"The present disclosure relates generally to identification of drivable surfaces in connection with autonomously performing various tasks at industrial work sites and, more particularly, to techniques for distinguishing drivable surfaces from non-drivable surfaces based on sensor data. A framework for the identification of drivable surfaces is provided for an autonomous machine to facilitate it to autonomously detect the presence of a drivable surface and to estimate, based on sensor data, attributes of the drivable surface such as road condition, road curvature, degree of inclination or declination, and the like. In certain embodiments, at least one camera image is processed to extract a set features from which surfaces and objects in a physical environment are identified, and to generate additional images for further processing. The additional images are combined with a 3D representation, derived from LIDAR or radar data, to generate an output representation indicating a drivable surface.","['G06V20/58', 'B60W60/0025', 'B60W40/06', 'B60W60/001', 'G01C21/3407', 'G01C21/3461', 'G01C21/3635', 'G01C21/3822', 'G01C21/3826', 'G06F18/2148', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N7/01', 'G06V10/454', 'G06V10/462', 'G06V10/77', 'G06V10/82', 'G06V20/20', 'G06V20/582', 'G06V20/588', 'G06V20/647', 'G06V20/70', 'B60W2420/403', 'B60W2420/42', 'B60W2552/00', 'B60W2552/15', 'B60W2552/30', 'B60W2552/35']"
CN112559702B,Transformer-based method for generating natural language questions in the field of civil and architectural information,"The invention discloses a natural language problem generation method in the field of civil construction information based on a Transformer. And then, fine adjustment of downstream tasks is carried out on the Bert by adopting a UniLM idea, and the natural language text generation capability of the model in the field of civil construction information is improved. The model provided by the method has higher feasibility and effectiveness in the problem generation in the field of civil construction information, and reaches a higher natural language problem generation level.","['G06F16/3329', 'G06F16/353', 'G06N3/08']"
US20210390355A1,Image classification method based on reliable weighted optimal transport (rwot),"An image classification method based on reliable weighted optimal transport (RWOT) includes: preprocessing data in a source domain, so that a deep neural network fits a sample image in the source domain to obtain a sample label; performing image labeling to add a pseudo label to a data sample in a target domain; performing node pairing to pair associated images in the source domain and the target domain; and performing automatic analysis by using a feature extractor and an adaptive discriminator, to perform image classification. The present disclosure proposes a subspace reliability method for dynamically measuring a difference between the source domain and the target domain based on spatial prototypical information and an intra-domain structure. This method can be used as a preprocessing step of an existing domain adaptation technology, and greatly improves efficiency.","['G06F18/241', 'G06K9/6269', 'G06V30/18057', 'G06F18/10', 'G06F18/214', 'G06F18/2411', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06K9/6298', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06V10/40', 'G06V10/82']"
US12183066B2,Method of deep learning-based examination of a semiconductor specimen and system thereof,"A computerized system and method of training a deep neural network (DNN) is provided. The DNN is trained in a first training cycle using a first training set including first training samples. Each first training sample includes at least one first training image synthetically generated based on design data. Upon receiving a user feedback with respect to the DNN trained using the first training set, a second training cycle is adjusted based on the user feedback by obtaining a second training set including augmented training samples. The DNN is re-trained using the second training set. The augmented training samples are obtained by augmenting at least part of the first training samples using defect-related synthetic data. The trained DNN is usable for examination of a semiconductor specimen.","['G06F18/24133', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V10/993']"
CN112771581B,"Multi-modal, multi-resolution deep learning neural network for segmentation, outcome prediction and longitudinal response monitoring for immunotherapy and radiation therapy","Systems and methods for a multi-modal, multi-resolution deep learning neural network for segmentation, outcome prediction, and longitudinal response monitoring for immunotherapy and radiation therapy are described in detail herein. The structure-specific generation countermeasure network (SSGAN) is used to synthesize realistic and structure-preserving images that were not generated using prior art GAN, and at the same time incorporate constraints to generate synthesized images. A deeply supervised, multi-modal, multi-resolution residual network (DEEPMMRRN) of tumor and organ-at-risk (OAR) segmentations may be used for tumor and OAR segmentations. DEEPMMRRN can be combined with multiple modalities for tumor and OAR segmentation. By using features of multiple scales and resolutions simultaneously and by feature selection of depth supervision to maximize network capacity, accurate segmentation can be achieved. DEEPMMRRN radiology can be used to predict and longitudinally monitor responses to immunotherapy. Automatic segmentation can be used in combination with radiometric analysis to predict response before treatment begins. Quantification of overall tumor burden can be used for automated response assessment.","['A61B6/5211', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06N7/01', 'G06T3/4053', 'G06T5/50', 'G06T7/0012', 'G06T7/11', 'G06T7/187', 'G16H50/20', 'A61B5/055', 'A61B6/03', 'A61B6/5229', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
US20240129368A1,"Server device, learned model providing program, learned model providing method, and learned model providing system","A server device configured to communicate, via a communication network, with at least one device including a learner configured to perform processing by using a learned model, includes processor, a transmitter, and a storage configured to store a plurality of shared models pre-learned in accordance with environments and conditions of various devices. The processor is configured to acquire device data including information on an environment and conditions from the at least one device, and select an optimum shared model for the at least one device based on the acquired device data. The transmitter is configured to transmit a selected shared model to the at least one device.","['G06N20/00', 'H04L67/12', 'G06N20/10', 'G06N3/02', 'H04L67/08', 'H04L67/303', 'H04L67/34', 'H04W12/06', 'H04W88/06', 'G06N3/088']"
US20240273932A1,"Method for recognizing text, and apparatus","A method for recognizing a text, and an apparatus. A specific embodiment of the method comprises: obtaining feature maps, the feature maps being obtained by means of performing text instance segmentation on an image having a text to be recognized; constructing a relationship graph according to the feature maps, wherein in the relationship graph, each node represents a pixel in a feature map, and each edge represents that a similarity measure of spatial semantic features of two connected nodes is greater than a target threshold, and a spatial semantic feature of a node comprises a type feature and a position feature of a pixel represented by the node; utilizing a pre-trained graph convolutional network to perform processing on the relationship graph, and obtaining a first text feature corresponding to the image; and generating a text recognition result for the image according to the first text feature.","['G06V10/82', 'G06F40/30', 'G06F40/40', 'G06N3/04', 'G06N3/08', 'G06V10/26', 'G06V10/74', 'G06V10/764', 'G06V10/774', 'G06V20/62', 'G06V30/148', 'G06V30/153', 'G06V30/19', 'G06V30/19127', 'G06V30/1918']"
US11170295B1,Systems and methods for training a personalized machine learning model for fall detection,Systems and methods for training a personalized Machine Learning (ML) model used to detect fall events are described herein. The methods may be implemented by one or more computing devices and may include obtaining sensor data associated with one or more activities of a user. A processed or unprocessed version of at least a copy of the sensor data having been fed to a personalized ML model associated with the user and that has been determined not to be associated with a fall event; and using the obtained sensor data training the personalized ML model.,"['G06N3/08', 'A61B5/1117', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G08B21/043', 'G08B29/186', 'G06N20/20', 'G06N5/01']"
CN107610087B,An automatic segmentation method of tongue coating based on deep learning,"The invention discloses a tongue coating automatic segmentation method based on deep learning, which comprises the following steps: s1, collecting and inputting an image containing the tongue coating; s2, detecting the tongue coating of the image containing the tongue coating by adopting a Faster R-CNN deep learning method, and automatically obtaining a preliminary tongue coating area image; s3, calibrating the preliminary tongue fur area image by adopting a VGG deep learning method to obtain a more accurate tongue fur area image; and S4, automatically segmenting the tongue fur image according to the calibrated tongue fur area image. The method realizes more accurate tongue fur segmentation based on the deep learning method of big data, and solves the problem of low tongue fur segmentation accuracy of the existing method.",[]
US11227191B2,Conditional loss function modification in a neural network,"Method, electronic device, and computer readable medium embodiments are disclosed. In one embodiment, a method includes training a neural network using a first image dataset and a first truth dataset, then using the trained neural network to analyze a second image dataset. The training includes modifying a loss function of the neural network to forego penalizing the neural network when a feature is predicted with higher than a first confidence level by the neural network, and the first truth dataset has no feature corresponding to the predicted feature.","['G06K9/6262', 'G06N3/084', 'G06F18/214', 'G06F18/217', 'G06K9/00657', 'G06K9/6202', 'G06K9/6256', 'G06N3/04', 'G06N3/043', 'G06N3/0436', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06V20/188']"
US11868892B2,Partially-frozen neural networks for efficient computer vision systems,"An apparatus to facilitate partially-frozen neural networks for efficient computer vision systems is disclosed. The apparatus includes a frozen core to store fixed weights of a machine learning model, one or more trainable cores coupled to the frozen core, the one or more trainable cores comprising multipliers for trainable weights of the machine learning model, and wherein the alpha blending layer includes a trainable alpha blending parameter, and wherein the trainable alpha blending parameter is a function of a trainable parameter, a sigmoid function, and outputs of frozen and trainable blocks in a preceding layer of the machine learning model.","['G06N3/08', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06V10/70', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82']"
US11340324B2,"Systems, methods and media for automatically segmenting and diagnosing prostate lesions using multi-parametric magnetic resonance imaging data","In accordance with some embodiments, systems, methods, and media for automatically segmenting and diagnosing prostate lesions using multi-parametric magnetic resonance imaging (mp-MRI) data are provided. In some embodiments, the system comprises is programmed to: receive mp-MRI data depicting a prostate, including T2w data and ADC data; provide the T2w data and ADC data as input to first and second input channels of a trained convolutional neural network (CNN); receive, from the trained CNN, output values from output channels indicating which pixels are likely to correspond to a particular class of prostate lesion, the channels corresponding to predicted aggressiveness in order of increasing aggressiveness, identify a prostate lesion in the data based on output values greater than a threshold; predict an aggressiveness based on which channel had values over the threshold; and present an indication that a prostate lesion of the predicted aggressiveness is likely present in the prostate.","['G01R33/5608', 'G01R33/50', 'G06F18/214', 'G06F18/254', 'G06K9/00536', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06V10/764', 'G06V10/809', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G01R33/5602', 'G01R33/56341', 'G06F2218/12', 'G06N3/084', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30081', 'G06T2207/30096', 'G06V2201/03']"
US12387096B2,Image-to-image mapping by iterative de-noising,"A method includes receiving training data comprising a plurality of pairs of images. Each pair comprises a noisy image and a denoised version of the noisy image. The method also includes training a multi-task diffusion model to perform a plurality of image-to-image translation tasks, wherein the training comprises iteratively generating a forward diffusion process by predicting, at each iteration in a sequence of iterations and based on a current noisy estimate of the denoised version of the noisy image, noise data for a next noisy estimate of the denoised version of the noisy image, updating, at each iteration, the current noisy estimate to the next noisy estimate by combining the current noisy estimate with the predicted noise data, and determining a reverse diffusion process by inverting the forward diffusion process to predict the denoised version of the noisy image. The method additionally includes providing the trained diffusion model.","['G06V10/30', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06V10/80', 'G06V10/82']"
US12229741B2,"Methods, systems, articles of manufacture, and apparatus for decoding purchase data using an image","Methods, apparatus, systems, and articles of manufacture are disclosed that decode purchase data using an image. An example apparatus includes a dictionary including associated product descriptions and barcodes, interface circuitry, and processing circuitry to execute machine readable instructions to obtain purchase details and barcodes corresponding to a receipt, the purchase details including receipt product descriptions, generate a search query that includes a first receipt product description of the receipt product descriptions, a list of barcodes corresponding to the barcodes, and a store identifier associated with the receipt, execute a search against the dictionary using the search query to identify a barcode from the list of barcodes that corresponds to the first receipt product description, and in response to identifying the barcode that corresponds to the first receipt product description, associating the barcode and the first receipt product description and adding the association to the dictionary.","['G06Q30/0245', 'G06Q20/201', 'G06K7/1413', 'G06Q30/0201', 'G06V30/147', 'G06V30/18057', 'G06V30/414', 'G06V30/42']"
US12327425B2,"Methods, systems, articles of manufacture, and apparatus for decoding purchase data using an image","Methods, apparatus, systems, and articles of manufacture are disclosed that decode purchase data using an image. An example apparatus includes processor circuitry to execute machine readable instructions to at least crop an image of a receipt based on detected regions of interest, apply a first mask to a first cropped image to generate first bounding boxes corresponding to rows of the receipt, apply a second mask to a second cropped image to generate second bounding boxes corresponding to columns of the receipt, generate a structure of the receipt by mapping words detected by an optical character recognition engine to corresponding first bounding boxes and second bounding boxes based on a mapping criterion, classify the second bounding boxes by identifying an expression of interest in ones of the second bounding boxes, and generate purchase information by extracting text of interest from the structured receipt based on the classifications.","['G06Q30/0283', 'G06V30/147', 'G06V30/15', 'G06V30/413', 'G06V30/414', 'G06V30/416']"
CN111507233B,A road surface type recognition method for intelligent vehicles based on multi-modal information fusion,"The invention discloses an intelligent vehicle road type recognition method based on multi-modal information fusion, which comprises the steps of firstly, respectively extracting characteristics of perception information of different modes by adopting different modeling methods according to the characteristics and data structures of the road perception information collected by each sensor, then carrying out characteristic level data fusion on characteristic vectors extracted by the perception information of each mode, finally converting multi-modal fusion characteristics into a time sequence classification problem by adopting an LSTM deep learning network, and completing the recognition of the road type through supervised learning. The invention improves the information fusion depth and the pavement identification precision of each sensor; in addition, frequent false detection caused by accidental errors can be effectively avoided by adopting the LSTM time sequence classification model, and the robustness and the accuracy of road surface identification are further improved.","['G06V20/56', 'G06F18/24', 'G06N3/044', 'G06N3/045', 'G06V10/40']"
US12154293B2,Projecting images captured using fisheye lenses for feature detection in autonomous machine applications,"In various examples, live perception from wide-view sensors may be leveraged to detect features in an environment of a vehicle. Sensor data generated by the sensors may be adjusted to represent a virtual field of view different from an actual field of view of the sensor, and the sensor data—with or without virtual adjustment—may be applied to a stereographic projection algorithm to generate a projected image. The projected image may then be applied to a machine learning model—such as a deep neural network (DNN)—to detect and/or classify features or objects represented therein. In some examples, the machine learning model may be pre-trained on training sensor data generated by a sensor having a field of view less than the wide-view sensor such that the virtual adjustment and/or projection algorithm may update the sensor data to be suitable for accurate processing by the pre-trained machine learning model.","['G06T7/73', 'G01C21/265', 'G05D1/0221', 'G05D1/0246', 'G05D1/249', 'G06F18/214', 'G06F18/2413', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/147', 'G06V10/24', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G06V10/94', 'G06V20/56', 'H04N23/698', 'H04N5/2628', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'G06T2207/30261', 'G06V10/247']"
CN114429150B,Rolling bearing fault diagnosis method and system based on improved depth subdomain adaptive network under variable working conditions,"A rolling bearing fault diagnosis method and system based on an improved depth subdomain adaptive network under variable working conditions relates to the technical field of rolling bearing fault diagnosis and is used for solving the problem that an existing fault diagnosis model is low in fault diagnosis accuracy of vibration data with large difference in different working condition distribution. The technical key points of the invention include: performing short-time Fourier transform on the vibration data of the source domain and the target domain to obtain a time-frequency spectrogram; introducing a channel attention mechanism and a first layer wide convolution kernel mechanism to improve a residual network, and extracting deep features in a time-frequency spectrogram; and carrying out sub-domain adaptation processing on the source domain characteristics and the target domain characteristics by utilizing the local maximum mean value difference, reducing the distribution difference between all sub-domains of the source domain and the target domain, and realizing the fault diagnosis of the rolling bearing under the complex working condition. The invention can realize the fault diagnosis of the rolling bearing under the conditions of variable working conditions and working condition generalization, and has higher accuracy. The invention can be widely applied to the fault diagnosis of the rolling bearing.","['G06F2218/08', 'G01M13/045', 'G06F18/214', 'G06N3/045', 'G06F2218/12']"
US12353409B2,Methods and systems for improved document processing and information retrieval,"Disclosed are methods, systems, devices, apparatus, media, and other implementations that include a method for document processing (particularly for training of a machine learning question answering platform, and for ingestion of documents). The method includes obtaining a question dataset (e.g., either from public or private repositories of questions) comprising one or more source questions for document processing by a machine learning question-and-answer system that provides answer data in response to question data submitted by a user, modifying a source question from the question dataset to generate one or more augmented questions with equivalent semantic meanings as that of the source question, and processing a document with the one or more augmented questions.","['G06F16/24522', 'G06F16/36', 'G06F16/248', 'G06F16/3329', 'G06F16/338', 'G06F16/9024', 'G06F16/90332', 'G06F16/9038', 'G06F16/93', 'G06F40/30', 'G06F40/35', 'G06N20/00', 'G06N5/022', 'G06N5/04', 'G06V30/414', 'G06N3/0464', 'G06N3/09', 'G06N5/046']"
CN112257637B,Vehicle-mounted laser point cloud multi-target identification method integrating point cloud and multiple views,"The invention relates to a vehicle-mounted laser point cloud multi-target identification method fusing point cloud and multiple views, which is characterized in that based on an independent point cloud object, a depth model PGVNet is constructed to predict surface ground object types: performing point cloud local feature extraction on the independent point cloud object by using a point cloud feature extraction module; generating a multi-view image of the independent object, and extracting optimal view characteristics by using a view characteristic extraction module and adopting view grouping and group characteristic fusion; fusing the optimal view features and the point cloud features by using a point cloud-view feature fusion module based on an attention mechanism to obtain point cloud global features fusing attention; and finally, performing class prediction of the independent ground object target on the vehicle-mounted laser point cloud surface by using a classifier MLP. According to the method, on one hand, the problem of information redundancy among similar views is reduced, on the other hand, the optimal view features are utilized to guide the model to learn the local features of the point cloud, the model classification precision is improved, and a new research method is provided for vehicle-mounted laser point cloud roadside multi-target fine classification.","['G06V20/56', 'G06F18/23', 'G06F18/253', 'G06N3/045', 'G06V20/584', 'G06V2201/08', 'Y02T10/40']"
US12333439B2,De-centralised learning for re-indentification,"A method for generating an optimised domain-generalisable model for re-identification of a target in a set of candidate images. The method optimises a local feature embedding model for domain-specific feature representation at each client of a plurality of clients, then receives, at a central server, information on changes to the local feature embedding model at each respective client resulting from the optimising step, and then updates a global feature embedding model based on the changes to the local feature embedding model. The method further receives, at each client from the central server, information representative of the updates to the global feature embedding model, then maps, at each client, on to the respective local feature embedding model at least a portion of the received updates, and subsequently updates, at each client, the respective local feature embedding model based on the mapped updates. The steps are repeated until convergence criteria are met, wherein the global feature embedding model is the optimised domain-generalisable model for re-identification of a target in a set of candidate images.","['G06N20/20', 'G06N3/082', 'G06F18/217', 'G06F18/24133', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/098', 'G06V10/761', 'G06V10/7715', 'G06V10/774', 'G06V10/778', 'G06V10/82', 'G06V10/95', 'G06V20/52', 'G06V40/173', 'G06N3/045']"
US12165289B2,Image enhancement via iterative refinement based on machine learning models,"A method includes receiving, by a computing device, training data comprising a plurality of pairs of images, wherein each pair comprises an image and at least one corresponding target version of the image. The method also includes training a neural network based on the training data to predict an enhanced version of an input image, wherein the training of the neural network comprises applying a forward Gaussian diffusion process that adds Gaussian noise to the at least one corresponding target version of each of the plurality of pairs of images to enable iterative denoising of the input image, wherein the iterative denoising is based on a reverse Markov chain associated with the forward Gaussian diffusion process. The method additionally includes outputting the trained neural network.","['G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T3/4007', 'G06T5/50', 'G06T5/60', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
US20190166823A1,Selective Action Animal Trap,"A method and a system provide an animal trap that records digital images of animals with a camera, convolves the digital image with a kernel to create convolved feature maps that are used as input to a classifier algorithm, producing classification confidence scores that identify the animals. An algorithm categorizes the classified animal and selects an action based on the categorization. The trap has actions to deter the benign or beneficial animals and actions to detain or kill the pest animals. With this method and system, the trap is able to target pest animals with minimal harm to benign or beneficial animals.","['A01M31/002', 'A01M23/02', 'A01M23/18', 'A01M23/38', 'A01M29/16', 'A01M29/24', 'G06F18/2413', 'G06F18/24133', 'G06F18/2431', 'G06K9/00369', 'G06K9/627', 'G06K9/628', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V40/103', 'H04L67/12']"
US20240395035A1,Determining Regions of Interest for Photographic Functions,Apparatus and methods related to photography are provided. A computing device can receive an input image. An object detector of the computing device can determine an object region of interest of the input image that is associated with an object detected in the input image. A trained machine learning algorithm can determine an output photographic region of interest for the input image based on the object region of interest and the input image. The machine learning algorithm can be trained to identify an output photographic region of interest that is suitable for use by a photographic function for image generation. The computing device can generate an output related to the output photographic region of interest.,"['G06V20/35', 'G06V40/16', 'G06N20/00', 'G06V10/56', 'H04N23/61', 'H04N23/611', 'H04N23/67', 'H04N23/73', 'H04N23/75', 'H04N23/76', 'H04N23/80', 'G06T2207/20081', 'G06T2207/20084']"
US11977851B2,"Information processing method and apparatus, and storage medium","Embodiments of this disclosure disclose an information processing method, apparatus and a non-transitory computer readable medium. The method includes: obtaining a target text sequence corresponding to to-be-processed text information; obtaining a context vector according to the target text sequence; determining a logical similarity corresponding to the target text sequence according to the context vector and the target text sequence; and encoding the target text sequence corresponding to target text information by using the logical similarity to obtain a text encoding result. In this embodiment of this disclosure, a context vector related to a discrete sequence is used to encode the discrete sequence, to strengthen the dependence between elements in the discrete sequence, thereby enhancing the performance of a neural network model and improving the learning capability of the model.","['G06F18/2411', 'G06F40/40', 'G06F40/20', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/044']"
CN118797017B,An intelligent question answering method based on the collaboration of large language model and knowledge graph,"The application provides an intelligent question-answering method based on collaboration of a large language model and a knowledge graph, which relates to the technical field of artificial intelligence and natural language processing and comprises the steps of disassembling a complex problem into a plurality of simple problems, and analyzing the association degree of the simple problems and a basic function to form a multi-hop reasoning path; and constructing a cumulative reasoning learning framework based on a logic reasoning big model, and carrying out iterative verification on a process result formed by the knowledge graph based on the multi-hop reasoning path so as to correct the reasoning path until a correct answer is deduced.","['G06F16/3329', 'G06F16/3344', 'G06F16/367', 'G06N3/006', 'G06N3/042', 'G06N3/08', 'G06N5/022', 'G06N5/04']"
CN110288979B,A kind of speech recognition method and device,"The invention relates to the technical field of computers, mainly relates to voice technology, natural language processing technology and machine learning in artificial intelligence, and particularly relates to a voice recognition method and a voice recognition device.","['G10L21/0272', 'G10L15/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G10L15/063', 'G10L15/16', 'G10L15/20']"
EP3992859A1,Machine learning system for digital assistants,"A machine learning system for a digital assistant is described, together with a method of training such a system. The machine learning system is based on an encoder-decoder sequence-to-sequence neural network architecture that is trained to map input sequence data to output sequence data, where the input sequence data relates to an initial query and the output sequence data represents canonical data representation for the query. The method of training involves generating a training dataset for the machine learning system based on original query data samples. The method involves clustering vector representations of the query data samples to generate canonical-query original-query pairs for use in training the machine learning system.","['G06N3/08', 'G06F16/3329', 'G06F16/2425', 'G06F16/3337', 'G06F16/3343', 'G06F16/3344', 'G06F16/35', 'G06F40/295', 'G06F40/58', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N7/01']"
US12072403B2,System and method of perceptive quantitative mapping of physical properties,"Exemplary methods for quantitative mapping of physical properties, systems and computer-accessible medium can be provided to generate images of tissue magnetic susceptibility, transport parameters and oxygen consumption from magnetic resonance imaging data using the Bayesian inference approach, which minimizes a data fidelity term under a constraint of a structure prior knowledge. The data fidelity term is constructed directly from the magnetic resonance imaging data. The structure prior knowledge can be characterized from known anatomic images using image feature extraction operation or artificial neural network. Thus, according to the exemplary embodiment, system, method and computer-accessible medium can be provided for determining physical properties associated with at least one structure.","['A61B5/0042', 'A61B5/055', 'A61B5/7221', 'A61B5/7267', 'G01R33/5608', 'G01R33/56536', 'G06T7/0012', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
US12373958B2,Real time perspective correction on faces,"Apparatus and methods related to image processing are provided. A computing device can determine a first image area of an image, such as an image captured by a camera. The computing device can determine a warping mesh for the image with a first portion of the warping mesh associated with the first image area. The computing device can determine a cost function for the warping mesh by: determining first costs associated with the first portion of the warping mesh that include costs associated with face-related transformations of the first image area to correct geometric distortions. The computing device can determine an optimized mesh based on optimizing the cost function. The computing device can modify the first image area based on the optimized mesh.","['G06T5/80', 'G06T7/174', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06T17/20', 'G06T5/60', 'G06V40/165', 'G06T2207/20084', 'G06T2207/30201']"
CN110414432B,"Training method of object recognition model, object recognition method and corresponding device","The embodiment of the application provides a training method of an object recognition model, an object recognition method and a corresponding device, wherein the method comprises the following steps: acquiring a training sample set; constructing a model to be trained, which comprises an object recognition model, and a first classification module and a second classification module which are respectively connected with the output of the object recognition model; inputting each sample image into a model to be trained, determining a first training loss value according to the predicted identity information output by the first classification model and the marked identity information of the sample image, and determining a second training loss value according to the predicted identity and the direction information output by the second classification model and the marked identity information and the direction information of the sample image; and adjusting model parameters of the model to be trained according to the total loss value determined by the first training loss value and the second training loss value until the total loss value meets the preset condition, and obtaining the trained object recognition model. Based on the method, the recognition accuracy when the object recognition model is used for object recognition is improved.","['G06F18/214', 'G06V20/40', 'G06V40/10']"
US20230164509A1,System and method for headphone equalization and room adjustment for binaural playback in augmented reality,"A system is provided. The system includes an analyzer for determining a plurality of binaural room impulse responses, and a loudspeaker signal generator for generating at least two loudspeaker signals depending on the plurality of binaural room impulse responses and depending on the audio source signal of at least one audio source. The analyzer is configured to determine the plurality of the binaural room impulse responses such that each of the plurality of the binaural room impulse responses considers an effect that results from a headphone being worn by a user.","['H04S7/306', 'H04S3/008', 'H04R1/1083', 'H04R2225/41', 'H04R2225/43', 'H04R2460/01', 'H04R25/507', 'H04R5/027', 'H04R5/033', 'H04R5/04', 'H04S2400/01', 'H04S2400/11', 'H04S2400/15', 'H04S2420/01', 'H04S7/301', 'H04S7/304']"
CN110489582B,Method and device for generating personalized display image and electronic equipment,"The disclosure provides a method and a device for generating personalized display images, and electronic equipment for realizing the method and a computer storage medium; relates to the technical field of machine learning. The method for generating the personalized presentation image comprises the following steps: encoding user data of a target user, display object data related to at least one display image and document data of at least one display image to obtain a first feature; extracting features of at least one display image to obtain second features; the first feature and the second feature are fused through the trained sequencing model, and fusion features are obtained; and predicting click information of the target user on the fusion features through the ordering model so as to determine personalized display images of the target user. According to the technical scheme, individuation of the display image can be improved, and the click rate corresponding to display in the display image can be improved. Meanwhile, personalized display of the images is beneficial to improving image browsing experience of users.","['G06F16/54', 'G06F16/9535', 'G06N3/08']"
US12069470B2,System and method for assisting selective hearing,"A system and a corresponding method for assisting selective hearing are provided. The system includes a detector for detecting an audio source signal portion of one or more audio sources by using at least two received microphone signals of a hearing environment. In addition, the system includes a position determiner for allocating position information to each of the one or more audio sources. In addition, the system includes an audio type classifier for assigning an audio source signal type to the audio source signal portion of each of the one or more audio sources. In addition, the system includes a signal portion modifier for varying the audio source signal portion of at least one audio source of the one or more audio sources depending on the audio signal type of the audio source signal portion of the at least one audio source so as to obtain a modified audio signal portion of the at least one audio source. In addition, the system includes a signal generator.","['H04S7/302', 'H04S7/304', 'G06T7/70', 'H04R3/005', 'H04R5/033', 'H04R5/04', 'H04S1/005', 'H04R1/32', 'H04R25/507', 'H04S2420/01']"
CN111368565B,"Text translation method, text translation device, storage medium and computer equipment","The application relates to a text translation method, which comprises the following steps: acquiring an initial source text and a reconstructed source text supplemented with the position information of the absent words; encoding an initial source text to obtain a source end vector sequence, and calculating according to a source end attention distribution weight vector and the source end vector sequence to obtain a source end content vector; sequentially decoding the source end vector sequence according to the candidate target words determined at the previous time to obtain target end vectors, and determining the candidate target words and the translation scores at the current time according to the target end vectors at the current time; constructing the target end vector into a target end vector sequence, and calculating according to the target end attention distribution weight vector and the target end vector sequence to obtain a target end content vector; performing reconstruction evaluation processing on the source end content vector and the target end content vector according to the reconstruction source text to obtain a reconstruction score; and generating candidate target texts according to the candidate target words, and screening the target texts from the candidate target texts according to the translation scores and the reconstruction scores. The scheme provided by the application can improve the translation quality.","['G06F40/30', 'G06F40/58', 'G06F40/47', 'G06F16/93']"
US20240211805A1,Machine learning model creation,"Embodiments of the present disclosure present devices, methods, and computer readable medium for techniques for creating machine learning models. Application developers can select a machine learning template from a plurality of templates appropriate for the type of data used in their application. Templates can include multiple templates for classification of images, text, sound, motion, and tabular data. A graphical user interface allows for intuitive selection of training data, validation data, and integration of the trained model into the application. The techniques further display a numerical score for both the training accuracy and validation accuracy using the test data. The application provides a live mode that allows for execution of the machine learning model on a mobile device to allow for testing the model from data from one or more of the sensors (i.e., camera or microphone) on the mobile device.","['G06F18/2148', 'G06F18/217', 'G06F18/2193', 'G06F18/2431', 'G06F3/048', 'G06F3/0482', 'G06F3/0486', 'G06F8/34', 'G06N20/00', 'G06V10/776', 'G06N3/084', 'G06N5/01', 'G06N7/01']"
US11710029B2,Methods and apparatus to improve data training of a machine learning model using a field programmable gate array,"Methods, apparatus, systems, and articles of manufacture are disclosed to improve data training of a machine learning model using a field-programmable gate array (FPGA). An example system includes one or more computation modules, each of the one or more computation modules associated with a corresponding user, the one or more computation modules training first neural networks using data associated with the corresponding users, and FPGA to obtain a first set of parameters from each of the one or more computation modules, the first set of parameters associated with the first neural networks, configure a second neural network based on the first set of parameters, execute the second neural network to generate a second set of parameters, and transmit the second set of parameters to the first neural networks to update the first neural networks.","['G06N3/063', 'G06F1/163', 'G06F15/7892', 'G06F16/00', 'G06F18/214', 'G06F18/217', 'G06F18/24143', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N5/04', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V10/955']"
US20230281400A1,Systems and Methods for Pretraining Image Processing Models,"Example embodiments of the present disclosure relate to systems and methods for pretraining image-processing models on weakly-supervised image-text pairs. The pretraining can include receiving a training sequence for the machine-learned image-processing model. The training sequence can include text tokens and image tokens. A prefix sequence can contain the image tokens. A remainder sequence can include a remainder set of the text tokens. The pretraining can include determining, using the prefix sequence as an input to the machine-learned image-processing model, an objective based on recovery of the remainder sequence. The pretraining can include updating one or more learnable parameters of the machine-learned image-processing model based on the objective.","['G06V10/82', 'G06F40/284', 'G06V10/766', 'G06V30/10', 'G06F40/58']"
US11646032B2,Systems and methods for audio processing,"A method of electronically documenting a conversation is provided. The method includes capturing audio of a conversation between a first speaker and a second speaker; generating conversation audio data from the captured audio; and segmenting the conversation audio data into a plurality of utterances according to a speaker segmentation technique. The method further includes, for each utterance: storing time data indicating the chronological position of the utterance in the conversation; passing the utterance to a neural network model, the neural network model configured to receive the utterance as an input and generate a feature representation of the utterance as an output; assigning the utterance feature representation to a first speaker cluster or a second speaker cluster according to a clustering technique; assigning a speaker identifier to the utterance based on the cluster assignment of the utterance; and generating a text representation of the utterance.","['G16H15/00', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G10L15/02', 'G10L15/16', 'G10L15/26', 'G10L17/18', 'G16H10/60', 'G16H50/20', 'G16H80/00']"
US11562147B2,Unified vision and dialogue transformer with BERT,"A visual dialogue model receives image input and text input that includes a dialogue history between the model and a current utterance by a human user. The model generates a unified contextualized representation using a transformer encoder network, in which the unified contextualized representation includes a token level encoding of the image input and text input. The model generates an encoded visual dialogue input from the unified contextualized representation using visual dialogue encoding layers. The encoded visual dialogue input includes a position level encoding and a segment type encoding. The model generates an answer prediction from the encoded visual dialogue input using a first self-attention mask associated with discriminative settings or a second self-attention mask associated with generative settings. Dense annotation fine tuning may be performed to increase accuracy of the answer prediction. The model provides the answer prediction as a response to the current utterance of the human user.","['G06F40/35', 'G06F18/21', 'G06F40/284', 'G06K9/6217', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/774', 'G06V10/82', 'G06N3/047', 'G06N3/084']"
US20220027569A1,"Method for semantic retrieval, device and storage medium","A method for a semantic retrieval, a device and a storage medium are provided. The method may include: receiving query information, and performing sequence labeling on the query information based on a pre-constructed knowledge graph to obtain a sequence labeling result, where the sequence labeling result includes a predetermined information part of the knowledge graph and a semantic retrieval part; constructing a set of a candidate entity matching the sequence labeling result based on the knowledge graph; and performing sematic matching between an entity in the set of the candidate entity and the semantic retrieval part in the sequence labeling result to obtain a set of an entity having a semantic relevance higher than a preset threshold.","['G06F16/3329', 'G06F16/36', 'G06F16/2468', 'G06F16/3334', 'G06F16/367', 'G06F16/9024', 'G06F40/284', 'G06F40/289', 'G06F40/295', 'G06F40/30', 'G06N5/02']"
CN108416755B,Image denoising method and system based on deep learning,"The invention discloses an image denoising method and system based on deep learning, the method comprises the steps of firstly constructing a main neural network structure and an auxiliary neural network structure, and respectively assigning a trainable parameter initial value of a first convolution layer and a trainable parameter initial value of a fifth convolution layer in the auxiliary neural network structure to the trainable parameter initial value of the first convolution layer and the trainable parameter initial value of the fifteenth convolution layer in the main neural network structure by adopting a transfer learning method; secondly, adding the noise-added images of the training set into the assigned main neural network structure, and performing image feature extraction, training and learning on the input noise-added images of the training set through a forward propagation algorithm to obtain noise feature images; determining a training model according to the noise characteristic image; then inputting the verification set noise-added images into a training model, and outputting a final training noise-removed model; and finally, adding the noise-added images of the test set into the final training denoising model for testing to obtain a denoising image, thereby greatly improving the denoising efficiency and the denoising effect.","['G06T5/70', 'G06T7/11', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
WO2021159774A1,"Object detection model training method and apparatus, object detection method and apparatus, computer device, and storage medium","An object detection model training method, comprising: inputting an unannotated first sample image to an initial detection model of this round, and outputting a first prediction result for a target object; transforming the first sample image and a first prediction position area of the target object in the first prediction result to obtain a second sample image and a prediction transformation result of the target object in the second sample image; inputting the second sample image to the initial detection model, and outputting a second prediction result of the target object; obtaining a loss value of unsupervised learning according to the difference between the second prediction result and the prediction transformation result; and adjusting a model parameter of the initial detection model according to the loss value and using the next round as this round, and returning to the step of inputting the first sample image to the initial detection model of this round to perform iterative training until a training end condition is satisfied to obtain an object detection model.","['G16H50/20', 'G06F18/2155', 'G06F18/241', 'G06N3/088', 'G06T7/0012', 'G06T7/73', 'G06V10/25', 'G06V10/40', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/7784', 'G06V10/82', 'G16H30/40', 'G16H50/70', 'A61B1/000094', 'A61B1/000096', 'A61B1/31', 'G06T2207/20081', 'G06T2207/30032', 'G06V2201/032']"
US10313714B2,Audiovisual content presentation dependent on metadata,"A system for utilizing metadata created either at a central location for shared use by connected users, or at each individual user's location, to enhance user's enjoyment of available broadcast programming content. A variety of mechanisms are employed for automatically and manually identifying and designating programming segments, associating descriptive metadata which the identified segments, distributing the metadata for use at client locations, and using the supplied metadata to selectively record and playback desired programming.","['H04N21/23424', 'A23L2/52', 'A23L33/105', 'A61K36/48', 'A61K36/54', 'A61K47/24', 'A61K8/553', 'A61K8/60', 'A61K8/68', 'A61K8/97', 'A61K9/0014', 'A61Q19/00', 'A61Q5/02', 'H04H20/28', 'H04H20/93', 'H04H60/27', 'H04H60/46', 'H04H60/73', 'H04H60/74', 'H04H60/80', 'H04N21/25891', 'H04N21/4147', 'H04N21/426', 'H04N21/4331', 'H04N21/4334', 'H04N21/4335', 'H04N21/439', 'H04N21/44008', 'H04N21/44213', 'H04N21/44222', 'H04N21/44224', 'H04N21/4532', 'H04N21/458', 'H04N21/4622', 'H04N21/4661', 'H04N21/4663', 'H04N21/4668', 'H04N21/47205', 'H04N21/47214', 'H04N21/4756', 'H04N21/4788', 'H04N21/4825', 'H04N21/4826', 'H04N21/6156', 'H04N21/6543', 'H04N21/812', 'H04N21/8352', 'H04N21/84', 'H04N21/8456', 'H04N21/8547', 'H04N21/8586', 'H04N5/4401', 'H04N5/76', 'H04N7/17318', 'A61K2800/782', 'A61K36/899', 'H04H60/37', 'H04N21/482', 'H04N7/088', 'H04N9/8205']"
CN112131366B,"Method, device and storage medium for training text classification model and text classification","The application provides a method, a device and a storage medium for training a text classification model and text classification, and relates to an artificial intelligence cloud technology for improving the accuracy of text classification. Inputting first sample data into a language model coding layer through an input layer to obtain a first feature vector of the first sample data, wherein the first sample data comprises at least one group of question-answer pairs and text information for determining answers of questions in the question-answer pairs; performing keyword highlighting operation on the feature vector used for representing the text information in the first feature vector through keyword highlighting operation introduced in the embedding layer, and performing keyword highlighting on the feature vector used for representing the question-answer pair in the first feature vector to obtain a second feature vector of the text information; inputting the second feature vector and the feature vector for representing the question-answer pair into the full-connection layer, and determining answer probability corresponding to the question in the question-answer pair; and reversely adjusting model parameters of the language model coding layer according to the answer probability output by the full-connection layer and the answer in the first sample data.","['G06F16/3329', 'G06F16/35', 'G06N3/045', 'Y02D10/00']"
US12299124B2,Deep learning based detection of malicious shell scripts,"In some implementations, a system may receive a shell script associated with a computing device. The system may generate a character frequency feature vector based on the shell script. The system may input text of the shell script to a convolutional neural network (CNN) branch of a trained deep learning model. The system may input the character frequency feature vector to a feedforward neural network (FNN) branch of the trained deep learning model. The system may determine using the trained deep learning model, respective probability scores for each of a plurality of obfuscation types for the shell script based on a combined output of the CNN branch and the FNN branch. The system may detect whether the shell script is obfuscated based on respective probability scores for each of the plurality of obfuscation types determined for the shell script.","['G06F21/562', 'G06F21/554', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06F2221/033', 'G06N3/048']"
US20220076133A1,Global federated training for neural networks,"Apparatuses, systems, and techniques to facilitate global semi-supervised training of neural networks to perform image segmentation related to diagnosis and management of emerging diseases, such as COVID-19. In at least one embodiment, distributed client training frameworks train one or more client neural networks to perform image segmentation according to a local training data set as well as global neural network data aggregated, by one or more central servers, from each of one or more globally distributed client neural networks.","['G06N3/088', 'G06N3/08', 'G06N3/084', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/063', 'G16H50/20']"
US20220222920A1,"Content processing method and apparatus, computer device, and storage medium","A content processing method is disclosed, including: obtaining a description text of to-be-processed content and an image included in the to-be-processed content; performing feature extraction on the description text based on text semantics to obtain a text eigenvector; performing feature extraction on the image based on image semantics to obtain an image eigenvector; combining the text eigenvector with the image eigenvector to obtain an image-text multi-modal vector; and generating an estimated click-through rate of the to-be-processed content according to the image-text multi-modal vector.","['G06V10/76', 'G06F16/9535', 'G06V10/82', 'G06F18/253', 'G06F40/30', 'G06V10/40', 'G06V30/41']"
CN112417953B,"Road condition detection and map data updating method, device, system and equipment","The embodiment of the application provides a method, a device, a system and equipment for detecting road conditions and updating map data, and relates to the field of computer vision. The method comprises the following steps: acquiring a vehicle road scene image around a target vehicle, and inputting the scene image into a vehicle detection model obtained by pre-training to obtain vehicle information of the scene image; determining a driving parameter between the surrounding vehicle and the target vehicle based on the scene image and the corresponding vehicle information thereof; the method and the device determine the congestion condition of the road of the target vehicle according to the vehicle information and the driving parameters, so that the road scene image around the target vehicle is acquired by utilizing the vehicle-mounted equipment of the target vehicle, the congestion condition of the road of the target vehicle is determined according to the recognition processing result of the scene image, and the accuracy of road condition detection and map data updating is improved.","['G06V20/588', 'G01C21/20', 'G01C21/28', 'G01C21/32', 'G06F16/23', 'G06F16/29', 'G06F18/214', 'G06N20/20', 'G06N3/045', 'G06N3/08']"
US10839269B1,System for fast and accurate visual domain adaptation,"In the field of computer vision, without sufficient labeled images, it is challenging to train an accurate model. But through visual adaptation from source to target domains, a relevant labeled dataset can help solve such problem. Many methods apply adversarial learning to diminish cross-domain distribution difference. They are able to greatly enhance the performance on target classification tasks. GAN (Generative Adversarial Networks) loss is widely used in adversarial adaptation learning methods to reduce a across-domain distribution difference. However, it becomes difficult to decline such distribution difference if generator or discriminator in GAN fails to work as expected and degrades its performance. To solve such cross-domain classification problems, an adaptation algorithm and system called as Generative Adversarial Distribution Matching (GADM) is implemented. In GADM, the objective function is improved by taking cross-domain discrepancy distance into consideration, and further minimize the difference through the competition between the generator and discriminator, thereby greatly decreasing the cross-domain distribution difference. Even when the performance of its generator or discriminator degrades, GADM is capable of decreasing the cross-domain distribution difference. The GADM algorithm and system employs a single GAN framework so as to achieve faster domain adaption with less computation resource. Specially, GADM transfers target data distribution to source one to keep accurate label dependence information, which ensures high accuracy and stability of source classifier and thus achieves better classification performance on target data.","['G06V10/82', 'G06K9/6263', 'G06F18/2178', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V20/00', 'G06V30/19167', 'G06V30/19173', 'G06N3/047', 'G06N3/088', 'G06V30/10']"
US20230108916A1,Method and system for forecasting non-stationary time-series,"A method (S1500) and a system (1600) for forecasting in a non-stationary time-series are disclosed. It addresses forecasting in a complex form of non-stationarity in time-series by employing regime-switches. The scope of application of the present invention is wider than that of existing models since it makes automating the process of forecasting easy and practical which in turn aids in generating forecasts at higher frequency than the existing models. It relies on a blend of wavelet transforms and deep learning towards automatic identification of different types of regimes that exist in non-stationary time-series. To overcome the limitations of existing models, it proposes a two-step framework for non-stationary time-series forecasting, where, it employs wavelet theory approach for capturing both high and low frequency components present in the time-series process during different time intervals; and then employs various deep learning models and machine learning algorithms to automatically identify the regime structure present in the time-series.","['G06Q30/0202', 'G06F18/23', 'G06F2123/02', 'G06N3/045']"
CN118193714B,Dynamic adaptation question-answering system and method based on hierarchical structure and retrieval enhancement,"The invention provides a dynamic adaptation question-answering system and method based on hierarchical structure and retrieval enhancement, belonging to the technical field of artificial intelligence, comprising the following steps: the system comprises a knowledge representation module, a retrieval enhancement generation module, a dynamic learning and adaptation module, a cross-domain knowledge integration module, a user interaction module and an evaluation and optimization module; the hierarchical structure is introduced to represent the hierarchical relationship of the entities in the organization, so that the knowledge structure in the organization can be better understood and utilized, the accuracy of questions and answers can be improved by combining with RAG technology and fine-tuned LLM, dynamic learning and adaptation can be realized, and cross-domain knowledge integration can be realized, so that a more efficient and accurate solution is provided in the field of document query answers in the organization, efficient and accurate knowledge management service can be provided for enterprises, staff can be helped to quickly acquire required information, and new query requirements can be continuously optimized and adapted along with the time.","['G06F16/3329', 'G06F40/216', 'G06F40/284', 'G06F40/289', 'G06F40/35', 'G06N3/042', 'G06N3/0442', 'G06N3/08', 'G06N5/01']"
CN111930992B,Neural network training method and device and electronic equipment,"The application belongs to the technical field of artificial intelligence, and particularly relates to a neural network training method, a neural network training device, a computer readable medium and an electronic device. The method comprises the following steps: sampling at least two sample segments from a video sample according to a video time sequence; adjusting the arrangement sequence of the at least two sample fragments, and acquiring the adjusted fragment sequence information; performing feature extraction on the sample fragment through neural networks corresponding to different modality types to obtain at least two modality features of the sample fragment; and training the neural network according to the feature similarity of each modal feature and the fragment sequence information so as to update the network parameters of the neural network. The method does not need to label the video data manually, reduces the data processing cost and improves the data processing efficiency.","['G06F16/683', 'G06N3/045', 'G06N3/08']"
CN113807420B,Domain self-adaptive target detection method and system considering category semantic matching,"The invention discloses a domain self-adaptive target detection method and system considering category semantic matching. The method comprises the following steps: step 1, acquiring a source domain tagged image and a target domain untagged image; step 2, training by using the source domain labeled image to obtain a pre-trained basic target detector; step 3, adding a domain self-adaptive component on the pre-trained basic target detector, and training by using a source domain tagged image and a target domain untagged image to obtain a trained domain self-adaptive target detection model; and 4, removing the added domain self-adaptive component, and performing target detection on the target domain scene by using the trained domain self-adaptive target detection model. The invention considers the problem of semantic matching of two specific categories in cross-domain target detection, and avoids the problem of incorrect alignment of the target categories of the source domain and the target domain in a shared category space, thereby promoting the detection performance of the target detection model on the target domain to be further improved.","['G06F18/214', 'G06F18/2415', 'G06N3/08']"
CN112101083B,Method and system for weakly supervised object detection using neural networks,"The invention discloses weak supervised object detection using one or more neural networks, and in particular, devices, systems, and techniques for detecting objects in images, including digital representations of such objects. In at least one embodiment, one or more objects in the image are detected based at least in part on one or more pseudo tags corresponding to the one or more objects.","['G06N3/084', 'G06V40/10', 'G06F18/2113', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06V10/25', 'G06V10/454', 'G06V10/765', 'G06V10/7753', 'G06V10/82', 'G06V20/10', 'G06N3/049']"
CN110533097B,"Image definition recognition method and device, electronic equipment and storage medium","The invention provides an image definition recognition method, an image definition recognition device, electronic equipment and a storage medium, and relates to a computer vision technology, wherein a neural network model comprises the following steps: the system comprises a scene feature extractor, a definition feature extractor, a full connection layer and a maximum likelihood function layer; the method comprises the following steps: extracting scene characteristics of the image through a scene characteristic extractor to obtain the scene characteristics of the image; performing definition feature extraction on the image through a definition feature extractor to obtain the definition feature of the image; splicing the scene features and the definition features of the images, and fusing the scene features and the definition features of the images through a full-connection layer to obtain fusion features; classifying the fusion features through a maximum likelihood function layer to obtain the probability of the image corresponding to a plurality of definition categories; and determining the definition category with the maximum probability as the definition category of the image. The invention can effectively identify the definition of various images.","['G06F18/253', 'G06F18/254', 'G06N3/045', 'G06N3/08']"
CN110928994B,"Similar case retrieval method, similar case retrieval device and electronic equipment","The application discloses a similar case retrieval method, a similar case retrieval device and electronic equipment. The similar case retrieval method comprises the following steps: receiving a case to be retrieved, which comprises at least one of a text description and a multimedia file related to the case; performing dispute focus analysis, legal element analysis, keyword extraction, multi-model semantic processing and multi-granularity semantic processing on the text description to generate a document analysis result; performing semantic processing on the multimedia file to generate a semantic analysis result; and matching the document analysis result and the semantic analysis result of the case to be retrieved with the document analysis result and the semantic analysis result of the case in the case library to obtain a retrieval result. Therefore, similar case retrieval is carried out based on multiple models, multiple particle sizes and multi-mode semantics and by combining dispute focus analysis, search results are increased, and matching accuracy is improved.","['G06F16/3334', 'G06F16/338', 'G06N3/045', 'G06N3/08', 'G06Q50/18']"
US20230145535A1,Neural network training technique,"Apparatuses, systems, and techniques to train a neural network to infer a condition based on an image. In at least one embodiment, a first portion of a neural network is trained to infer a condition from an image using a first dataset, and a second portion of the neural network is trained using a second dataset.","['G06N3/08', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N5/04', 'G06N5/046', 'G06T7/0012', 'G06T7/11', 'G16H30/40', 'G16H50/20', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084']"
CN110717017B,Method for processing corpus,"The application discloses a corpus processing method, relates to the field of artificial intelligence, and is used for improving the accuracy and effectiveness of semantic recognition. The method comprises the following steps: performing word segmentation processing on a target text needing semantic recognition to obtain a plurality of words included in the target text, and performing word vector processing on each word to obtain a word vector sequence corresponding to the target text; inputting the word vector sequence into a pre-trained semantic recognition model to determine a target semantic feature corresponding to a target text through the semantic recognition model; the semantic recognition model is obtained by training a plurality of text training samples labeled with semantic labels, the plurality of text training samples comprise a first type of text training sample and a second type of text training sample, the first type of text training sample determines corresponding semantic labels according to semantic keywords included in the text, and the second type of text training sample determines corresponding semantic labels according to annotation information associated with the text.","['G06F16/3344', 'G06F16/35', 'G06N3/084']"
US12045666B2,Profiling and performance monitoring of distributed computational pipelines,"Apparatuses, systems, and techniques to collect performance data for one or more computations tasks executed by a plurality of nodes of a computational pipeline and enable optimization of distribution of task execution among the plurality of nodes.","['G06F9/5083', 'G06F11/3006', 'G06F11/323', 'G06F11/3409', 'G06F11/3433', 'G06F16/9024', 'G06F9/5038', 'G06F2209/501']"
US20240296352A1,Artificial intelligence enhanced knowledge framework,"A computer-implemented system, a method, and computer products for development and use of a knowledge framework are provided. The system comprises one or more processors and a memory including computer program code. The computer program code is configured to, when executed, cause the one or more processors to perform various tasks. These tasks include receive session data related to responses received from a participant in a session, receive machine learning data, create or enhance the knowledge framework based on the machine learning data and the session data, and create additional machine learning data using the knowledge framework as a source of information. The method performs these tasks, and the computer readable medium contains similar computer program code. The method can perform these tasks with computer synergistic generative artificial intelligence, machine learning, and knowledge framework subsystems.","['G06N5/02', 'G06N5/022', 'G06N5/046']"
US10580137B2,Systems and methods for detecting an indication of malignancy in a sequence of anatomical images,"A method for detecting an indication of likelihood of malignancy, comprising: receiving a sequence of anatomical images of a breast of a target individual acquired over a time interval during which contrast is administered, analyzing the sequence of anatomical images to identify: a baseline pre-contrast image denoting lack of contrast, a peak contrast image denoting a peak contrast enhancement, an initial uptake image denoting initial contrast enhancement, and a delayed response image denoting final contrast enhancement, creating a multi-channel image representation comprising: intensity channel including the peak contrast enhanced image, contrast-update channel including the computed difference between the peak contrast enhanced image and the pre-contrast image, and contrast-washout channel including the computed difference between the initial uptake image and the delayed response image, and computing by a trained deep convolutional neural network, a classification category indicative of likelihood of malignancy for the sequence according to the multi-channel image representation.","['A61B10/0041', 'A61B5/055', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/0016', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B5/4312', 'A61B5/7264', 'A61B5/7275', 'G06F17/18', 'G06T2207/10096', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20084', 'G06T2207/30068']"
CN111488489B,"Video file classification method, device, medium and electronic equipment","The application provides a video file classification method, a video file classification device, a computer readable storage medium and electronic equipment; relates to the technical field of video processing; comprising the following steps: when the uploaded video file is detected, descriptive information and user information corresponding to the video file are acquired, and the video file is decoded to obtain corresponding audio content and a video frame set; text recognition is carried out on the audio content to obtain text information corresponding to the audio content, and word segmentation is carried out on the text information and the description information to obtain word segmentation sets; generating a first classification result corresponding to the video file according to the video frame set and the word segmentation set, generating a second classification result corresponding to the video file according to the audio content, and generating a third classification result corresponding to the video file according to the user information; and classifying the video files according to the classification result. The method can identify the video file through the multidimensional information of the video file so as to improve the identification accuracy of the video file.","['G06F16/75', 'G06F16/783']"
CN112395858B,Multi-knowledge point labeling method and system integrating test question data and answer data,"The invention discloses a multi-knowledge point labeling method and a system for fusing test question data and answer data. The method comprises the following steps: collecting test question data, wherein the test question data comprises a question text and a solution text, and inputting the question text and the solution text into a pre-trained language model to extract word vectors of the question text and the solution text respectively, so as to obtain a question text word vector and a solution text word vector; carrying out vector fusion processing on the topic text word vector and the answering text word vector to obtain a fusion word vector; and inputting the fusion word vector into a pre-trained multi-knowledge-point classification model to obtain the knowledge-point label of the test question data. According to the method, the accuracy and the dimension of the feature information are improved from the longitudinal direction and the transverse direction by improving the information expression effectiveness and adding and expanding the feature information, so that the accuracy of the final knowledge point labeling is improved.","['G06F40/211', 'G06F18/24', 'G06F40/284', 'G06N3/048', 'G06N3/08']"
US11475210B2,Language model for abstractive summarization,"Methods, systems, and computer programs are presented for abstractive summarization of text by viewing sequence transduction as a language modeling problem. One method comprises an operation for training a machine-learning program to create a machine-learning model that estimates a word to be added to a running summary for the text being summarized. The method further comprises operations for detecting the text to be summarized, initializing the running summary, and performing a plurality of iterations. Each iteration comprises providing, to the machine-learning model, the source text and the running summary, and adding, using the machine-learning model, a new word to the running summary. Further, the method comprises an operation for storing, on a memory, the running summary as the summary of the text.","['G06F40/35', 'G06F40/166', 'G06F16/345', 'G06F40/284', 'G06N3/04', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'H04M2203/2061', 'H04M3/5183']"
US12182694B2,"Training, testing, and verifying autonomous machines using simulated environments","In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment—in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack—to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle.","['G06N3/063', 'G05D1/00', 'G06F18/24133', 'G06F9/455', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/56']"
CN110378224B,Detection method and detection system for ground feature change and terminal,"The application is applicable to the technical field of image processing, and provides a method, a system and a terminal for detecting terrain changes, wherein the method comprises the following steps: acquiring a first image before the ground object changes and a second image after the ground object changes in a target area; inputting the first image and the second image into a feature difference convolution neural network model to obtain an output first change intensity graph; and generating a binary image of the ground feature change based on the first change intensity map, so that the robustness and stability of the remote sensing image change detection are improved, and the change detection precision is improved.","['G06N3/045', 'G06T7/0004', 'G06V20/13', 'G06V20/40', 'G06T2207/10032']"
CN109635872B,"Identity recognition method, electronic device and computer program product","The embodiment of the application provides an identity recognition method, electronic equipment and a computer program product. By adopting the scheme in the application, prediction data are obtained; removing first sensor information from the predicted data to form first identification data; inputting the first identification data into a first classification model trained in advance to obtain a first identification initial result; adding the first identity identification initial result as identification information into the prediction data to form second identification data; and inputting the second identification data into a pre-trained second classification model to obtain an identity identification final result, wherein the identity identification final result is the operation of the user or the operation of the non-user. The method comprises the steps of identifying identification data which do not contain sensor information to obtain an initial result; and then, the prediction data added with the initial result is identified to obtain a final result, so that the accuracy and the safety of identity identification are improved under the condition of ensuring good user experience.","['G06F18/214', 'G06F18/254']"
US12412209B2,Image processing arrangements,"Aspects of the detailed technologies concern training and use of neural networks for fine-grained classification of large numbers of items, e.g., as may be encountered in a supermarket. Mitigating false positive errors is an exemplary area of emphasis. Novel network topologies are also detailed—some employing recognition technologies in addition to neural networks. A great number of other features and arrangements are also detailed.","['G06Q30/0641', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/17', 'G06V10/462', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G06F16/906', 'G06N3/04', 'G06N3/08', 'G06V2201/09']"
US12033621B2,Method for speech recognition based on language adaptivity and related apparatus,"A method for speech recognition based on language adaptivity comprises obtaining voice data of a user. The method also comprises extracting, based on the obtained voice data, a phoneme feature representing pronunciation phoneme information. The phoneme feature is input to a pre-trained language discrimination model that is pre-trained based on a multilingual corpus. A language discrimination result corresponding to the phoneme feature and in accordance with the language discrimination model is obtained. The method also comprises obtaining a speech recognition result of the voice data based on a language acoustic model of a language corresponding to the language discrimination result. The method further comprises determining a speech recognition result of the voice data based on a language acoustic model of a language corresponding to the language discrimination result.","['G10L15/005', 'G10L15/02', 'G10L15/063', 'G10L15/22', 'G10L17/00', 'G10L17/04', 'G10L15/187', 'G10L15/32', 'G10L2015/025']"
CN118093979B,Internet news analysis system and method based on big data,"The invention provides an Internet news analysis system and method based on big data, comprising the following steps: collecting news data from a network platform and performing text processing operation; carrying out semantic representation on the text, and constructing a semantic vector; performing topic cluster analysis based on the semantic vector and classifying news to obtain a news classification model; analyzing news emotion tendencies; analyzing the propagation paths, speeds and ranges of news on different platforms, and identifying key propagation nodes; analyzing event hot evolution, development tracks and propagation rules of hot events, and determining key development nodes, key states and event evolution figures; generating a news event analysis model according to the news classification model, the emotion tendency data, the key nodes, the states and the like; and acquiring a new event in real time, carrying out predictive analysis on the development trend of the new event according to the event analysis model, obtaining an analysis result and taking corresponding measures. According to the scheme, big data analysis and event prediction are combined, and the depth and practical value of intelligent news analysis are improved.","['G06F16/951', 'G06F16/35', 'G06F40/242', 'G06F40/284', 'G06F40/30', 'G06N20/00']"
US10855698B2,Leveraging endpoint and network environment inferences for malware traffic classification,"In one embodiment, a device obtains simulation environment data regarding traffic generated within a simulation environment in which malware is executed. The device trains a malware detector using the simulation environment data. The device obtains deployment environment characteristics of a network to which the malware detector is to be deployed. The device configures the malware detector to ignore data in the simulation environment data that is associated with one or more environment characteristics that are not present in the deployment environment characteristics.","['H04L63/1416', 'G06F21/53', 'G06N20/00', 'H04L41/145', 'H04L63/0428', 'H04L63/1425', 'H04L63/1458', 'G06F21/6245', 'H04L63/166', 'H04L67/02', 'H04L67/28', 'H04L67/56', 'H04L69/325']"
US20230135179A1,Systems and Methods for Implementing Smart Assistant Systems,"In one embodiment, a system includes an automatic speech recognition (ASR) module, a natural-language understanding (NLU) module, a dialog manager, one or more agents, an arbitrator, a delivery system, one or more processors, and a non-transitory memory coupled to the processors comprising instructions executable by the processors, the processors operable when executing the instructions to receive a user input, process the user input using the ASR module, the NLU module, the dialog manager, one or more of the agents, the arbitrator, and the delivery system, and provide a response to the user input.","['G06F16/90332', 'G10L15/22', 'G06F16/3329', 'G06F16/367', 'G06F40/30', 'G06N3/006', 'G06N3/0455', 'G06N3/0464', 'G06N5/022', 'G10L15/063', 'G10L15/16', 'G10L15/1815', 'G10L15/30', 'G06N3/084', 'G10L2015/088']"
CN114707227B,Dam safety early warning and alarm eliminating method and system based on digital twinning,"The invention discloses a dam safety early warning and alarm eliminating method and system based on digital twinning, comprising the following steps: constructing a digital twin dam with the same safety state as an objective physical dam, consistent influence factors, equivalent measurable response and fidelity of a multidimensional scene through a self-adaptive numerical simulation, a comprehensive evaluation model, a dynamic recursion data driving model, an online data assimilation model, an abnormality diagnosis reasoning model, a behavior understanding model, a live-action and XR model and a data and mechanism mixed driving control model; the objective physical dam is subjected to information sensing and optimization, information abnormality diagnosis, structural safety and system working state online evaluation, dam safety state accurate prediction, effective early warning of failure results, reasonable regulation and control of dam safety states and targeted recommendation of follow-up measures through the digital twin dam. The invention has complete system, innovation and outstanding practicability and has good popularization and application values.","['G06F30/13', 'G06F30/23', 'G06F30/27', 'G06F2119/02', 'Y02A10/40']"
CN111160350B,"Portrait segmentation method, model training method, device, medium and electronic equipment","The embodiment of the application discloses a portrait segmentation method, a model training device, a medium and electronic equipment. The portrait segmentation model comprises a feature extraction network and a double-branch network, wherein the double-branch network comprises a portrait branch network and a background branch network which are identical in structure. The image is accurately classified by utilizing the image branch network, the background in the image is accurately classified by utilizing the background branch network, and finally, the classification results of the image and the background are fused to divide the image into an image part and a background part, so that separation of the images is realized on the premise of not using related hardware, and the hardware cost of the electronic equipment for realizing image division can be reduced.","['G06V10/26', 'G06F18/214', 'G06F18/24', 'G06F18/241', 'G06F18/253', 'G06F18/254', 'G06N20/00', 'G06N5/04', 'G06T7/194', 'G06V10/764', 'G06V10/806', 'G06V10/809', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
CN116563707B,Lycium chinense insect pest identification method based on image-text multi-mode feature fusion,"The invention discloses a medlar insect pest identification method based on image-text multi-modal feature fusion, which comprises the following steps of S1, constructing an image and text cross-modal feature fusion model; s2, training, testing and verifying a cross-modal feature fusion model of the image and the text of the Chinese wolfberry insect pest by utilizing a multi-modal data set of the image and the text of the Chinese wolfberry insect pest based on various model evaluation indexes, and identifying and classifying the Chinese wolfberry insect pest by utilizing the trained cross-modal feature fusion model of the image and the text of optimal evaluation in combination with a multi-layer perceptron. The advantages are that: the provided image and text cross-modal feature fusion model solves the problems of identification and classification of medlar insect pests in a complex agricultural environment, promotes research and development of cross-modal in the agricultural field and medlar insect pest control, reduces the pesticide utilization rate and protects the agricultural ecological system.","['G06V20/188', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/806', 'G06V10/82', 'G06V20/62', 'G06V30/1918']"
US11942075B2,System and method for automated digital twin behavior modeling for multimodal conversations,"Methods and systems for a multimodal conversational system are described. A method for interactive multimodal conversation includes parsing multimodal conversation from a physical human for content, recognizing and sensing one or more multimodal content from the parsed content, identifying verbal and non-verbal behavior of the physical human from the one or more multimodal content, generating learned patterns from the identified verbal and non-verbal behavior of the physical human, training a multimodal dialog manager with and using the learned patterns to provide responses to end-user multimodal conversations and queries, and training a virtual human clone of the physical human with interactive verbal and non-verbal behaviors of the physical human, wherein appropriate interactive verbal and non-verbal behaviors are provided by the virtual human clone when providing the responses to the end-user multimodal conversations and queries.","['G10L15/063', 'G10L15/22', 'G06F40/211', 'G06F40/35', 'G06N10/00', 'G06N10/60', 'G06N3/044', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G10L15/1815', 'G10L15/1822', 'G10L15/25', 'G10L15/30', 'G10L13/033', 'G10L2015/227']"
TWI794414B,Systems and methods for real-time object detection using depth sensors,"A depth-based object-detection convolutional neural network is disclosed. The depth-based object-detection convolutional neural network described herein incorporates a base network and additional structure. The base network is configured to receive a depth image formatted as RGB image data as input, and compute output data indicative of at least one feature of an object in the RGB image data. The additional structure is configured to receive the output data of the base network as input, and compute predictions of the location of a region in the received depth image that includes the object and of a class of the object as output. An object detection device incorporating the depth- based object-detection convolutional neural network is operable in real time using an embedded GPU.","['G06V10/454', 'G06F18/214', 'G06F18/24133', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06T7/90', 'G06T7/97', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06T2207/10024', 'G06T2207/10028']"
US11646119B2,Systems and methods for automated analysis of medical images,"This disclosure relates to detecting visual findings in anatomical images. Methods comprise inputting anatomical images into a neural network to output a feature vector and computing an indication of visual findings being present in the images by a dense layer of the neural network that takes as input the feature vector and outputs an indication of whether each of the visual findings is present in the anatomical images. The neural network is trained on a training dataset including anatomical images, and labels associated with the anatomical images and each of the visual findings. The visual findings may be organised as a hierarchical ontology tree. The neural network may be trained by evaluating the performance of neural networks in detecting the visual findings and a negation pair class which comprises anatomical images where a first visual finding is identified in the absence of a second visual finding.","['A61B6/5217', 'G16H50/20', 'A61B6/032', 'A61B6/48', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06T7/0012', 'G06V10/82', 'G16H30/40', 'G16H40/67', 'G06N5/02', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061']"
WO2021159714A1,Data processing method and related device,"The present application relates to the field of artificial intelligence, and discloses a data processing method, comprising: acquiring a first neural network model and an available resource state of a terminal device; and determining a second neural network model according to the available resource state. The present application enables an appropriate model size to be determined according to an available resource state, such that a portion of the first neural network model is selected according to the determined model size to serve as a second neural network model to perform data processing, thereby achieving reduction of the model size.","['G06N3/06', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/10', 'G06N5/022', 'G06N3/0495', 'G06N5/04']"
CN111695209B,Rotary machine small sample health assessment method driven by meta-deep learning,"The invention discloses a rotary machine small sample health assessment method driven by meta-deep learning, which comprises the following specific steps: firstly, extracting time-frequency graph, time-frequency domain and frequency domain characteristics of a vibration signal after pretreatment of a rotating machine as degradation characteristic quantity; then, further extracting migratable degradation indexes among different domains by an unsupervised domain self-adaptive method; on the basis, different subtasks are divided, gradient reverse transfer-based parameter solving is carried out on the convolutional network and the cyclic network, and small sample evaluation of different degradation indexes is realized by constructing a meta-deep learning prediction method of two different basic models; and finally, aggregating different learning subtasks to realize cross-task model parameter solution and optimization, and providing a meta-deep learning evaluation agent model for popularization and generalization to unknown data sets. The method introduces the meta-learning idea into the field of health assessment and management of the rotary machine for the first time, and greatly weakens the impact of working condition difference and sample sparseness on the generalization capability of the traditional machine learning model.","['G06F30/17', 'G01M13/00', 'G01M13/045', 'G06F30/27', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06F2119/04']"
US11657525B2,Extracting information from images,"An image processing component is trained to process 2D images of human body parts, in order to extract depth information about the human body parts captured therein. Image processing parameters are learned during the training from a training set of captured 3D training images, each 3D training image of a human body part and captured using 3D image capture equipment and comprising 2D image data and corresponding depth data, by: processing the 2D image data of each 3D training image according to the image processing parameters, so as to compute an image processing output for comparison with the corresponding depth data of that 3D image, and adapting the image processing parameters in order to match the image processing outputs to the corresponding depth data, thereby training the image processing component to extract depth information from 2D images of human body parts.","['G06T7/55', 'B29C64/393', 'B33Y50/00', 'B33Y50/02', 'G06F18/214', 'G06K9/6256', 'G06T17/00', 'G06T7/20', 'G06V10/141', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/647', 'G06V40/16', 'G06V40/172', 'G06V40/40', 'B29C64/386', 'B29L2031/48', 'B33Y30/00', 'B33Y80/00', 'G06T2200/04', 'G06T2207/10021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11941918B2,Extracting information from images,"An image processing component is trained to process 2D images of human body parts, in order to extract depth information about the human body parts captured therein. Image processing parameters are learned during the training from a training set of captured 3D training images, each 3D training image of a human body part and captured using 3D image capture equipment and comprising 2D image data and corresponding depth data, by: processing the 2D image data of each 3D training image according to the image processing parameters, so as to compute an image processing output for comparison with the corresponding depth data of that 3D image, and adapting the image processing parameters in order to match the image processing outputs to the corresponding depth data, thereby training the image processing component to extract depth information from 2D images of human body parts.","['G06V40/40', 'B29C64/393', 'B33Y50/00', 'B33Y50/02', 'G06F18/214', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T17/00', 'G06T7/20', 'G06T7/50', 'G06T7/55', 'G06V10/141', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/647', 'G06V40/16', 'G06V40/168', 'G06V40/172', 'G06V40/45', 'B29L2031/48', 'B33Y30/00', 'B33Y80/00', 'G06F21/32', 'G06T2200/04', 'G06T2207/10021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
CN110738595B,"Picture processing method, device and equipment and computer storage medium","The application discloses a picture processing method, device and equipment and a computer storage medium, relates to the technical field of image processing, and is used for improving the fit and reality of human face added hair. The method comprises the following steps: obtaining a plurality of mask pictures corresponding to a target hairstyle, wherein the mask pictures respectively correspond to different poses of a human face, and each mask picture comprises a hair region mask; acquiring a face picture, and determining a target mask picture matched with the face gesture in the face picture from the mask pictures; and fusing the face picture and the target hair material picture according to the hair region mask in the target mask picture to obtain a target synthetic picture.","['G06T3/04', 'G06T5/50', 'G06T7/33', 'G06T2200/04', 'G06T2207/10016', 'G06T2207/20221', 'G06T2207/30201']"
CN108985377B,A high-level image semantic recognition method based on deep network multi-feature fusion,"The present invention provides a kind of image high-level semantics recognition methods of multiple features fusion based on deep layer network, by the way that global color histogram to be extracted to the color characteristic of image, LBP algorithm extracts the textural characteristics of image, deep layer object network extract image characteristics of objects and deep layer emotion network extract image deep layer affective characteristics fusion get up identify image compound emotion and comprising main object, finally for the image of input, the descriptive with high-level semantics information can be generated in the network model, and high-level semantics include emotional semantic and Object Semanteme.The present invention is from the deep learning aspect for being directed to small data set, in such a way that a kind of data expand respectively, combine extract in advance have such as color and texture statistics low-level features, and propose that a kind of method by multiple features fusion identifies the model of the high-level semantics information of Image emotional semantic and object, the accuracy for improving experimental result chooses experimental image more scientific.","['G06F18/2413', 'G06F18/24147', 'G06F18/25']"
EP3822865A1,Synthesizing data for training one or more neural networks,"Apparatuses, systems, and techniques are presented to generate data useful for further training of a neural network. In at least one embodiment, one or more neural networks can be retrained based, at least in part, on data generated by the one or more neural networks including data used to previously train the one or more neural networks.","['G06F18/214', 'G06N3/084', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N5/04', 'G06N3/098']"
CN111696028B,"Real scene image cartoonization processing method, device, computer equipment and storage medium","The application relates to a real scene image cartoon processing method and device based on artificial intelligence, computer equipment and storage medium. The method comprises the steps of obtaining a real scene image, carrying out image reconstruction processing and abstract smoothing processing on the real scene image based on semantic information of the real scene image to obtain an abstract cartoon image of the real scene image mapped on a cartoon domain, abstracting the cartoon image, carrying out stylization processing on the abstract cartoon image to generate a style cartoon image with an artistic style, and generating contour edge lines of the style cartoon image to obtain the cartoon image of the real scene image after cartoon. The quality of the generated cartoon image can be improved by adopting the method.","['G06T3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T5/70', 'G06T7/181', 'G06T2207/20028', 'Y02T10/40']"
US12219301B1,Determination of luminance values using image signal processing pipeline,"Apparatuses, systems, and techniques to receive, at one or more processors associated with an image signal processing (ISP) pipeline for a camera, an image generated using an image sensor of the camera, wherein the image comprises a plurality of channels associated with color information of the image; process, by the one or more processors, the plurality of channels of the image to generate a plurality of luminance and/or radiance values; generate, by the one or more processors, an updated version of the image using the plurality of luminance and/or radiance values; and output the updated version of the image.","['H04N23/71', 'H04N9/7973', 'G06T11/001', 'H04N1/6005', 'H04N23/70', 'H04N23/72', 'H04N23/80', 'H04N23/82', 'H04N23/85', 'G06T2207/10152', 'G06T2207/20081', 'G06T2207/20084']"
CN113823262B,"Voice recognition method and device, electronic equipment and storage medium","The application relates to the technical field of voice recognition, in particular to a voice recognition method, a voice recognition device, electronic equipment and a storage medium, which can be applied to various scenes such as cloud technology, artificial intelligence, intelligent traffic, auxiliary driving and the like and are used for efficiently and accurately realizing voice recognition of a multi-dialect target language. The method comprises the following steps: acquiring voice data to be recognized of a target language; extracting voice acoustic characteristics corresponding to each frame of voice data in the voice data to be recognized; performing depth feature extraction on the voice acoustic features to obtain corresponding dialect embedding features; obtaining corresponding acoustic coding features by coding the acoustic features of the voice; and carrying out dialect voice recognition on the voice data to be recognized based on the dialect embedding characteristics and the acoustic coding characteristics to obtain target text information and a target dialect category corresponding to the voice data to be recognized. The method and the device combine dialect embedding characteristics and acoustic coding characteristics to comprehensively learn, and can efficiently and accurately realize the speech recognition of recognizing various dialects.","['G10L15/005', 'G06N3/084', 'G10L15/02', 'G10L15/063', 'G10L15/16']"
CN107591200B,Bone age mark identification and evaluation method and system based on deep learning and image omics,"The invention discloses a bone age mark identification and evaluation method and system based on deep learning and image omics, wherein the bone age mark identification method comprises the following steps: carrying out window adjustment, alignment and standardization preprocessing on the wrist skeleton image; marking out a bone age characteristic region by using a bounding box and recording coordinates, wherein the bone age characteristic region comprises a metacarpophalangeal bone group and a carpal bone group which conform to a TW3 method; amplifying processing according to needs, and simultaneously inputting the signals into a convolutional neural network based on the ResNet-101 region to perform multitask (positioning, classifying and evaluating) training; and further training to improve the bone age evaluation speed and accuracy rate based on the bone age characteristic region and clinical information (demographic characteristics and inspection reports). The method initially trains the bone age model by using a small amount of marked samples, and automatically marks a large amount of samples by using the model with higher positioning detection precision, thereby realizing automatic bone age characteristic region positioning, classification and bone age assessment.",[]
US12059222B2,Robotic surgical methods and apparatuses,"Robotic surgical methods and apparatuses, including systems, for determining positioning information using a combination of AI landmark-identification and visual imaging. Also described herein are methods and apparatuses for determining how to train the AI. Also described herein are end effector devices that may be used with any of the robotic surgical methods and apparatuses. Also described herein designs and techniques incorporating AR into robotic surgical procedures.","['A61B34/30', 'A61B90/361', 'A61B34/20', 'A61B34/32', 'A61B34/76', 'B25J9/1697', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G06T7/50', 'G06T7/70', 'G16H20/40', 'G16H30/40', 'G16H50/50', 'A61B17/16', 'A61B2017/00084', 'A61B2034/105', 'A61B2034/2065', 'A61B2090/365', 'A61B2090/371', 'A61B34/10']"
US11291430B2,Precedent-based ultrasound focusing,"Various approaches for operating an ultrasound transducer having multiple transducer elements include acquiring one or more measurements of anatomical regions through which ultrasound waves emitted from the transducer elements travel; for each of the anatomical regions, determining values of characteristics based at least in part on the measurement(s); computationally predicting aberrations of the ultrasound waves traveling through the anatomical regions by using the first values as input to a predictor that has been computationally trained to predict ultrasound aberrations based on values of the characteristics; and driving the transducer elements to compensate for the predicted aberrations.","['A61B8/5269', 'A61B8/0808', 'A61B8/4416', 'A61B8/4488', 'A61B8/5246', 'A61B8/5253', 'A61B8/5261', 'A61B8/58', 'A61B2090/374', 'A61B6/032', 'A61B6/037', 'A61B6/5217', 'A61B8/0875', 'A61B8/4245', 'A61B8/54', 'G06N20/00', 'G06N3/02', 'G06T2207/20081', 'G06T2207/20084']"
US11574703B2,"Method, apparatus, and computer-readable medium for efficiently optimizing a phenotype with a combination of a generative and a predictive model","A method, apparatus, and computer-readable medium for efficiently optimizing a phenotype with a combination of a generative and a predictive model, training a phenotype prediction model based on experiential genotype vectors, training a genotype generation model based on sample genotype vectors, generating new genotype vectors, applying the phenotype prediction model to the new genotype vectors to generate scores, determining result genotypes based on a ranking of the available genotypes according to the scores, and generating a result based on the result genotypes, the result indicating one or more genetic constructs for testing.","['G16B20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G16B40/00', 'G16B40/20', 'G06N3/044']"
US20210406782A1,System and method for decentralized federated learning,A system for decentralized federated learning is provided. The system comprises agents and aggregators coupled to a communication network. Each agent comprises a data collector collecting raw data; a memory storing the collected raw data and a local machine learning model; and a processor training the local machine learning model. Each aggregator comprises a model collector collecting the local machine learning models; a memory storing the collected local machine learning models; and a processor creating a cluster machine learning model from the local machine learning models. The aggregators communicate with each other and exchange the cluster machine learning models to create a semi-global machine learning model. Each of the aggregators sends the semi-global machine learning model to the associated agents. Each of the agents updates the local machine learning model with the semi-global machine learning model.,"['G06N20/20', 'G06N3/084', 'G06F16/27', 'G06N3/063', 'G06N3/098', 'G06N5/04']"
CN112861616B,Passive field self-adaptive target detection method,"The invention discloses a passive field self-adaptive target detection method, which is applied to the field of target detection and aims at solving the problem of poor cross-domain target detection effect; firstly, loading a pre-trained source domain model to a student model and a teacher model, then inputting an unlabeled target domain image acquired from a target domain scene to the teacher model, and inputting a super target domain image corresponding to the target domain image to the student model; the method utilizes the domain discriminators to align the characteristics of the super target domain and the target domain at the image level and the example level respectively and minimizes the class consistency loss of the student model and the teacher model; finally, the student model is updated through back propagation, and the teacher model is updated according to the student model; the problem of cross-domain target detection is well overcome.","['G06V20/00', 'G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/084', 'G06V10/30', 'G06V2201/07']"
US11568625B2,Targeted object detection in image processing applications,"Apparatuses, systems, and techniques to train and apply a first machine learning model to identify a plurality of regions of interest within an input image, and to train and apply a plurality of second machine learning models to identify one or more objects within each region of interest identified by the first machine learning model.","['G06T7/0002', 'G06V10/25', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T7/0014', 'G06T7/11', 'G06V10/764', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30008', 'G06T2207/30012', 'G06V10/82']"
CN110674869B,Classification processing and graph convolution neural network model training method and device,"The invention discloses a classification processing and graph convolution neural network model training method and device. The classification processing method comprises the following steps: the method comprises the steps of obtaining a target characteristic diagram of sample data of a target object, inputting the target characteristic diagram of the sample data of the target object into a pre-trained target diagram convolutional neural network model to obtain classification information of the target object, wherein the classification information can accurately represent the research field of the target object, classifying the target object according to the classification information, and classifying users by inputting the trained target diagram convolutional neural network model, namely an artificial intelligence mode, so that the accuracy of classification of the target object is improved, and the technical problem that the accuracy of a classification result is low due to the fact that the complex diagram convolutional network model is over-fitted and over-smooth in construction is solved.","['G06F18/241', 'G06N3/045', 'G06N3/08']"
US20240185001A1,Dataset generation using large language models,"Disclosed are systems and techniques that may generate datasets for training task-oriented dialogue systems. The techniques include generating natural language queries by selecting a template query, sampling one or more tokens from a data store of domain-specific tokens, modifying the selected template query using the one or more sampled tokens to generate a query prompt, and using a natural language generative machine-learning model to generate, based on the query prompt, a respective natural language query of the subset of the plurality of natural language queries, and causing the generated plurality of natural language queries to be provided to a machine-learning model training engine configured to train, using the generated plurality of natural language queries, a conversational machine-learning model to perform a domain-specific conversational task.","['G06F40/284', 'G06F40/56']"
US20220055689A1,Machine learning using modular solution datasets,A framework for offline learning from a set of diverse and suboptimal demonstrations operates by selectively imitating local sequences from the dataset. At least one embodiment recovers performant policies from large manipulation datasets by decomposing the problem into a goal-conditioned imitation and a high-level goal selection mechanism.,"['B62D15/025', 'B25J1/02', 'B60W30/06', 'B60W60/0025', 'B62D15/0285', 'G05B13/027', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/084', 'G06N7/01']"
US9330388B2,Facilitating establishing trust for conducting direct secure electronic transactions between a user and airtime service providers,"Methods and systems are provided for supporting electronic transactions, including transactions that are provided with per-user, per-device and per-domain security across domains of multiple service providers.","['G06Q20/3227', 'G16Z99/00', 'G06F21/606', 'G06Q20/02', 'G06Q20/045', 'G06Q20/0453', 'G06Q20/047', 'G06Q20/10', 'G06Q20/12', 'G06Q20/145', 'G06Q20/32', 'G06Q20/322', 'G06Q20/3223', 'G06Q20/3226', 'G06Q20/325', 'G06Q20/327', 'G06Q20/367', 'G06Q20/3674', 'G06Q20/382', 'G06Q20/3821', 'G06Q20/38215', 'G06Q20/3829', 'G06Q20/385', 'G06Q20/40', 'G06Q20/4014', 'G06Q20/42', 'G06Q30/06', 'G16H10/60', 'H04L63/0838', 'G06Q2220/00', 'H04L63/0428', 'H04L63/06', 'H04L63/08']"
US12164551B2,Supervised summarization and structuring of unstructured documents,"Disclosed are methods, systems, devices, apparatus, media, and other implementations, including a method that includes obtaining a query set (e.g., a universal set of questions), performing a question-and-answer (Q-A) search on one or more documents using the query set to produce answer data responsive to one or more questions included in the query set, with the answer data characterizing concepts associated with the one or more documents, and deriving structured output information for the one or more documents based on the answer data produced in response to performing the Q-A search.","['G06F16/345', 'G06F16/3329', 'G06F16/3347', 'G06F16/338', 'G06F16/355', 'G06F16/367', 'G06F16/383']"
CN111738231B,"Target object detection method and device, computer equipment and storage medium","The application relates to a target object detection method, a target object detection device, a computer device and a storage medium. The method comprises the following steps: performing feature extraction on an image to be detected to obtain initial image features; performing feature enhancement processing on the initial image features to obtain first image features; performing first-level prediction processing on a target object according to the first image characteristics to obtain an initial prediction frame for identifying the target object; performing feature splicing on the initial image features and the first image features, and performing feature enhancement processing on the spliced image features to obtain second image features; and performing second-level prediction processing on the target object according to the second image characteristic and the initial prediction frame to adjust the initial prediction frame, and identifying the target object in the image to be detected according to the adjusted prediction frame. By adopting the method, the detection accuracy of the target object can be effectively improved.","['G06V40/161', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V10/40', 'G06V40/10', 'G06V2201/07']"
CN111127389B,Scalable artificial intelligence model generation system and method for healthcare,"The invention provides an extensible artificial intelligence model generation system and method for medical care. Systems and methods for generating artificial intelligence models using synthetic data are disclosed. An example system includes a Deep Neural Network (DNN) generator to generate a first DNN model using first real data. The exemplary system includes a synthetic data generator to generate first synthetic data from the first real data, the first synthetic data to be used by the DNN generator to generate a second DNN model. The exemplary system includes an evaluator to evaluate performance of the first DNN model and the second DNN model to determine whether to generate second composite data. The exemplary system includes a composite data aggregator to aggregate third composite data and fourth composite data from a plurality of sites to form a composite data set. The exemplary system includes an artificial intelligence model deployment processor to deploy an artificial intelligence model trained and tested using the synthetic data set.","['G06N3/084', 'G06T7/0012', 'G06F11/3447', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06T7/0002', 'G16H30/20', 'G16H50/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US20230185799A1,Transforming natural language to structured query language based on multi-task learning and joint training,"Techniques are disclosed for training a model, using multi-task learning, to transform natural language to a logical form. In one particular aspect, a method includes accessing a first set of utterances that have non-follow-up utterances and a second set of utterances that have initial utterances and associated one or more follow-up utterances and training a model for translating an utterance to a logical form. The training is a joint training process that includes calculating a first loss for a first semantic parsing task based on one or more non-follow-up utterances from the first set of utterances, calculating a second loss for a second semantic parsing task based on one or more initial utterances and associated one or more follow-up utterances from the second set of utterances, combining the first and second losses to obtain a final loss, and updating model parameters of the model based on the final loss.","['G06F16/24522', 'G06F40/205', 'G06F40/30', 'G06F40/35', 'G06F40/44', 'G06F40/58', 'G06N20/00', 'G06N3/0455', 'G06N3/096', 'G06F40/253', 'G06F40/263', 'G06F40/284', 'G06N3/0442', 'G06N3/084']"
US12094230B2,Cross-modal weak supervision for media classification,"Methods, systems, and storage media for classifying content across media formats based on weak supervision and cross-modal training are disclosed. The system can maintain a first feature classifier and a second feature classifier that classifies features of content having a first and second media format, respectively. The system can extract a feature space from a content item using the first feature classifier and the second feature classifier. The system can apply a set of content rules to the feature space to determine content metrics. The system can correlate a set of known labelled data to the feature space to construct determinative training data. The system can train a discrimination model using the content item and the determinative training data. The system can classify content using the discrimination model to assign a content policy to the second content item.","['G06V30/19', 'G06F16/45', 'G06F16/55', 'G06F16/75', 'G06F18/213', 'G06F18/2148', 'G06F18/241', 'G06N20/00', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/7715', 'G06V10/7784', 'G06V10/82', 'G06V30/19127', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06V30/10']"
CN118366311B,"Intelligent traffic monitoring method and device based on multi-mode data fusion and graph neural network, and electronic equipment","The embodiment of the invention discloses an intelligent traffic monitoring method, an intelligent traffic monitoring system, an intelligent traffic monitoring electronic device and a storage medium based on multi-mode data fusion and a graph neural network, which relate to the technical field of intelligent traffic, are beneficial to improving the performance and reliability of the whole intelligent traffic monitoring system and are better suitable for monitoring analysis of complex traffic environments, and comprise the following steps: acquiring multi-modal data in a target traffic scene, and synchronizing and calibrating the multi-modal data, wherein the multi-modal data comprises: image, point cloud, sound, and temperature; extracting features from the data of each mode by using a deep learning algorithm, and fusing the extracted features by using a fusion algorithm to enhance the data quality under the conditions of severe weather, illumination change or shielding; inputting the fused data characteristics based on a pre-trained graph neural network prediction model, and outputting attribute characteristics and interrelation characteristics of traffic elements in a traffic scene; and according to the attribute characteristics and the interrelation characteristics of the traffic elements, monitoring and analyzing the flow and the behavior mode of the traffic elements in the target traffic scene. The method is suitable for traffic monitoring analysis and control scenes.","['G08G1/0125', 'G06F18/20', 'G06F18/253', 'G08G1/0137', 'G06F2123/02']"
US20200194117A1,"Systems, methods, and media for remote trauma assessment","In some embodiments, systems and methods for remote trauma assessment are provided, a system comprising, a robot arm; an ultrasound probe and a depth sensor coupled to the robot arm; and a processor programmed to: cause the depth sensor to acquire depth data indicative of a three dimensional shape of at least a portion of a patient; generate a 3D model of the patient; automatically identify scan positions using the 3D model; cause the robot arm to move the ultrasound probe to a first identified scan position; receive movement information indicative of input provided via a remotely operated haptic device; cause the robot arm to move the ultrasound probe from the first scan position to a second position based on the movement information; cause the ultrasound probe to acquire ultrasound data at the second position; and transmit an ultrasound image based on the ultrasound data to the remote computing device.","['G16H40/67', 'A61B34/30', 'A61B34/32', 'A61B34/35', 'A61B5/0035', 'A61B5/0037', 'A61B5/0064', 'A61B5/445', 'A61B8/4218', 'A61B8/429', 'A61B8/463', 'A61B8/565', 'G06N3/008', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06T7/0012', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'A61B2090/064', 'A61B34/74', 'A61B34/76', 'G06T2207/10004', 'G06T2207/20084']"
US20210279576A1,Attention neural networks with talking heads attention,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for performing a machine learning task on a network input to generate a network output. In one aspect, one of the systems includes an attention neural network configured to perform the machine learning task, the attention neural network including one or more attention layers, each attention layer comprising an attention sub-layer and, optionally, a feed-forward sub-layer. At least one of the attention layers includes an attention sub-layer that applies talking heads attention instead of conventional multi-head attention.","['G06N3/08', 'G06N3/045', 'G06N3/04', 'G06N3/084']"
US11971955B1,Example-based image annotation,"Techniques are generally described for machine learning exampled-based annotation of image data. In some examples, a first machine learning model may receive a query image comprising a first depiction of an object-of-interest. In some examples, the first machine learning model may receive a target image representing a scene in which a second depiction of the object-of-interest is visually represented. In various examples, the first machine learning model may generate annotated output image data that identifies a location of the second depiction of the object-of-interest within the target image. In some examples, an object detection model may be trained based at least in part on the annotated output image data.","['G06F18/2148', 'G06F18/2155', 'G06F18/2163', 'G06F18/2178', 'G06F18/22', 'G06F18/2413', 'G06F18/40', 'G06F3/04842', 'G06F3/04845', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T7/73', 'G06V10/25', 'G06V10/751', 'G06V10/7788', 'G06V10/82', 'G06F3/0482', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/09']"
US8345962B2,Transfer learning methods and systems for feed-forward visual recognition systems,"A method and system for training a neural network of a visual recognition computer system, extracts at least one feature of an image or video frame with a feature extractor; approximates the at least one feature of the image or video frame with an auxiliary output provided in the neural network; and measures a feature difference between the extracted at least one feature of the image or video frame and the approximated at least one feature of the image or video frame with an auxiliary error calculator. A joint learner of the method and system adjusts at least one parameter of the neural network to minimize the measured feature difference.","['G06N3/08', 'G06F18/214', 'G06N3/0499', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/774']"
US11443149B2,Cuttings imaging for determining geological properties,"Apparatus and methods for ascribing one of multiple predetermined sub-classes to multiple pixels of an image of an unknown rock sample retrieved from a geological formation. The ascription utilizes a deep learning model trained with an annotated training dataset. The annotated training dataset includes multi-pixel images of known rock samples and, for each known rock sample image, which sub-class corresponds to at least a subset of pixels of that image. For each pixel of the unknown rock sample image having an ascribed sub-class, which one of predetermined meta-classes is associated with that pixel is derived based on the sub-class ascribed to that pixel. The meta-classes represent different predetermined rock types. At least one property of the formation is predicted utilizing the ascription-derived meta-classes, including which rock type(s) are present in the formation.","['G01V11/002', 'G06K9/627', 'E21B21/06', 'G01N15/088', 'G01N15/1433', 'G01N21/255', 'G01N33/24', 'G06F18/214', 'G06F18/2413', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06V10/147', 'G06V10/774', 'E21B2200/22', 'G01V20/00']"
CN113379734B,"Quality detection method, quality detection device, quality detection equipment and computer-readable storage medium","The invention provides a quality detection method, a quality detection device, quality detection equipment and a computer readable storage medium. According to the method, the device and the system, the image to be detected including the object to be detected is obtained, the first detection model obtained through pre-training is utilized, the region of interest of the image to be detected is detected, at least one region of interest is obtained, then the image of each region of interest in the at least one region of interest is cut out from the image to be detected, the second detection model obtained through pre-training is utilized, the image of each region of interest is subjected to target detection, the target detection result corresponding to each region of interest is obtained, and further, the quality detection result of the image to be detected is determined based on the target detection result corresponding to the at least one region of interest, so that the local defect of the appliance and the defect of the appliance mould can be accurately and effectively identified.","['G06T7/0012', 'A61C7/002', 'G06F18/214', 'G06T3/4038', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/20132', 'G06T2207/30036']"
US20230125477A1,Defect detection using one or more neural networks,"Apparatuses, systems, and techniques to facilitate feature detection of a manufactured object such as a PCB using combined images of said manufactured object. In at least one embodiment, an automated optical inspection system (AOI) comprising one or more neural networks can infer based, at least in part, on combined images of a PCB the existence of defects on said PCB.","['G06T7/001', 'G06T7/0004', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T7/586', 'G06T7/97', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30141']"
US12271821B2,Training an autoencoder with a classifier,"Computer systems and methods train a deep neural network through machine learning. In response to detection of a training condition, computer system replaces a target node of the network with a split detector compound node, where, prior to replacement, the target node detected a pattern that activated the target node beyond a specified threshold. The split detector compound node comprises first and second nodes, such that: the first node is activated when significant evidence exists in favor of detection of the pattern in inputs to the first node; and the second node is activated when significant evidence exists against detection of the pattern in inputs to the second node, such that activations of the first and second nodes are computed independently. After replacing the target node with the split detector compound node, training of the network through machine learning is resumed.","['G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0495', 'G06N3/0499', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/096', 'G06N3/098', 'G06N3/0985']"
CN111930942B,"Text classification method, language model training method, device and equipment","The application discloses a text classification method, a language model training method, a device and equipment, and relates to the technical field of artificial intelligence and natural language processing. The method comprises the following steps: acquiring an input text; acquiring relation characterization vectors between words of an input text, between words and between words, wherein the relation characterization vectors are used for representing semantic relations; determining an associated feature vector based on the relationship characterization vector, the associated feature vector being used to characterize semantic relevance between different dimensional features of the relationship characterization vector; based on the associated feature vector, a classification result of the input text is determined. The method and the device realize the acquisition of rich relation characterization vectors used for representing semantic relations, and through the acquisition of semantic relativity among different dimensional characteristics of the relation characterization vectors, so as to mine and enrich deeper semantic information, fully improve semantic understanding capability of input texts, and further improve final classification accuracy.","['G06F16/355', 'G06F40/205', 'G06F40/30', 'G06N20/00']"
CN111538894B,"Query feedback method and device, computer equipment and storage medium","The application relates to a query feedback method, a query feedback device, computer equipment and a storage medium. The method comprises the following steps: performing semantic feature recognition on the query statement to obtain a recognition result of the query statement; the recognition result comprises an original semantic entity and semantic information; acquiring at least two candidate semantic entities based on the recognition result of the query statement; screening a target semantic entity from at least two candidate semantic entities; sending a feedback result corresponding to the target semantic entity to the terminal; the scheme is based on an artificial intelligence technology, and the original semantic entities and the semantic information are combined to jointly query the candidate semantic entities, so that the sources of the subsequently determined target semantic entities are wider, the diversity of the target semantic entities is improved, the diversity of feedback results is improved, and the purpose of improving the feedback effect is achieved.","['G06F16/9532', 'G06F16/3344']"
JP2024109937A,Variational Grasp Generation,"To provide improved methods of grasp determination.SOLUTION: A computer system comprises one or more processors and computer-readable memory, the memory storing executable instructions that cause the computer system to perform at least the following steps. By execution by the one or more processors, the computer system performs the steps of: using a first neural network to generate, from a three-dimensional point cloud, a set of grasp poses that allow a robot to grasp the object; using a second neural network to determine an evaluation of individual grasps in the set of grasp poses; and refining the individual grasps in the set of grasp poses on the basis of at least in part, a gradient of the evaluation determined by the second neural network to produce the set of refined grasp poses.SELECTED DRAWING: Figure 5","['B25J9/1612', 'B25J9/1669', 'B25J9/1697', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/063', 'G06N3/088', 'G06N3/09', 'B25J9/161', 'G05B2219/39543']"
US11462325B2,Multimodal machine learning based clinical predictor,"Methods and systems for performing a clinical prediction are provided. In one example, the method comprises: receiving first molecular data of a patient, the first molecular data including at least gene expressions of the patient; receiving first biopsy image data of the patient; processing, using a machine learning model, the first molecular data and the first biopsy image data to perform a clinical prediction of the patient's response to a treatment, wherein the machine learning model is generated or updated based on second molecular data including at least gene expressions and second biopsy image data of a plurality of patients; and generating an output of the clinical prediction.","['G16H50/20', 'G06T7/0012', 'G06V20/69', 'G16B20/00', 'G16B40/00', 'G16H10/40', 'G16H15/00', 'G16H20/30', 'G16H50/30', 'C12Q1/6886', 'C12Q2600/106', 'C12Q2600/158', 'G16B25/00']"
CN110175434B,A damage detection method for railway fastener system based on convolutional neural network,"The invention discloses a method for detecting damage of a railway fastener system based on a convolutional neural network, which is based on a train-track coupling dynamics calculation analysis model, utilizes spring stiffness reduction to simulate fastener damage, and obtains vibration acceleration response of a steel rail under different irregularity excitation, different damage positions and damage degrees through simulation calculation so as to construct a large data set. And designing a one-dimensional convolutional neural network, training the established network by using the data set, and cross-verifying and adjusting parameters. And performing performance test on the trained network on the test set, wherein the test result shows that the detection method has higher detection precision and robustness. Furthermore, a dynamic experiment of a key section of the target monitoring line is developed, an actually measured big data set of system damage is constructed, and the big data set is used for carrying out transfer learning on the pre-trained one-dimensional convolution neural network model.","['G06F30/15', 'G06F30/20', 'G06N3/045', 'G06N3/08']"
CN111144490B,Fine granularity identification method based on alternative knowledge distillation strategy,"A fine granularity identification method based on a rotation knowledge distillation strategy. The method comprises the following steps of S1, utilizing convolutional neural network training to obtain a convolutional characteristic diagram; s2, clustering the convolution feature maps, acquiring channel indication vectors, training a channel group module through the channel indication vectors, and generating an attention mask; and step S3, obtaining a local image according to the attention mask, and training the local image and the global image through an alternate knowledge distillation strategy to obtain a fine-grained image. The method comprises the steps of training a convolutional neural network to obtain a convolutional characteristic diagram, clustering the convolutional characteristic diagram to obtain a channel indication vector, pre-training a channel group module according to the channel indication vector to generate an attention mask, obtaining a local diagram, and finally training the local diagram and a global diagram through a rotation knowledge distillation strategy. The invention can solve the problems of local information loss in the fine-grained image, poor anti-interference capability of the traditional method and the like, and greatly improves the accuracy of fine-grained image classification.","['G06F18/2411', 'G06F18/214', 'G06F18/232', 'G06F18/25', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
CN112329964B,"Method, device, equipment and storage medium for pushing information","The application discloses a method, a device, equipment and a storage medium for pushing information, relates to the fields of data processing, knowledge maps and intelligent recommendation, and can be applied to cloud services. The specific implementation scheme is as follows: acquiring an uploading document and a historical knowledge graph of a target user; analyzing the uploaded document to obtain text information; constructing a target knowledge graph based on the text information; and determining target recommendation information based on the target knowledge graph and the historical knowledge graph, and pushing the target recommendation information to a target user. According to the implementation mode, the artificial intelligence technology is applied to life, the documents uploaded by the user can be intelligently analyzed to obtain the target knowledge graph, and based on the obtained target knowledge graph and the obtained historical knowledge graph, the user is assisted to quickly find out proper matching resource information and push the matching resource information to the user, so that the time for browsing web pages and inquiring by the user is saved, and the rationality and accuracy of information recommendation can be improved.","['G06Q10/02', 'G06F16/367', 'G06F16/9535', 'H04L67/55']"
CN109724984B,Device and method for defect detection and identification based on deep learning algorithm,"The invention discloses a defect detection and identification device based on a deep learning algorithm, which relates to the field of defect detection and identification and comprises a detection platform, a detection system and a model inference system, wherein the detection system is connected with the detection platform, and the model inference system operates in the detection system. The method trains an effective neural network model to detect and identify the processing defect image to be detected under the condition that the real processing defect data sample is insufficient, reduces the omission ratio by utilizing a deep learning algorithm, realizes the full-automatic detection of the decorative plate to be detected, and reduces the manual workload.",[]
US12333442B2,Intelligent updating and data processing for deployed machine learning models,"Particular embodiments can update a deployed machine learning model with actual entity data depending on anomalies detected in stream data, which can be stored to a computer object, such as a journal. Various embodiments map particular subsets of a larger pool of raw input data to the particular models that need the input data and store the raw input data to computer objects so that the corresponding machine learning models can make predictions according to any suitable policy or triggering event on any of the data located in the computer objects. Such mapping allows each machine learning model to continuously make predictions based on the data it needs.","['G06F16/285', 'G06N3/096', 'G06F16/24568', 'G06F16/9024', 'G06N20/00', 'G06N3/09', 'G06N5/04']"
TWI701680B,Method and system of analyzing medical images,"The present invention seeks to provide a method of analyzing medical image, the method comprises receiving a medical image; applying a model stored in a memory; analyzing the medical image based on the model; determining the medical image including a presence of fracture; and, transmitting an indication indicative of the determination.","['G06T7/0012', 'A61B6/032', 'G06T7/60', 'G16H30/20', 'A61B5/055', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T7/11']"
CN111897964B,"Text classification model training method, device, equipment and storage medium","The application discloses a text classification model training method, device, equipment and storage medium, and belongs to the field of artificial intelligence. According to the embodiment of the application, on one hand, the countermeasure sample is introduced, and the text classification model is trained by using the text sample and the countermeasure sample, so that the text classification model learns a classification method for the disturbed text, the robustness of the text classification model is improved, and the accuracy of text classification is improved. On the other hand, the text classification model can reconstruct the text characteristics of the countermeasure sample extracted during classification, restore the text characteristics into text contents, and improve the interpretability of the countermeasure training method. Model parameters are trained by combining errors between the reconstructed text content and the text content of the text sample, so that the text classification model can extract more accurate text features, namely more accurate feature expression of the text content is obtained, and the robustness and accuracy of feature extraction of the text classification model are improved.","['G06F16/35', 'G06F18/214', 'G06F18/22', 'G06F40/30', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
CN109446514B,News entity identification model construction method and device and computer equipment,"The application relates to a method and a device for constructing a news entity identification model based on transfer learning, computer equipment and a storage medium. The method comprises the following steps: constructing a named entity recognition model; extracting neural network parameters of a second neural network model in the pre-trained part-of-speech tagging model, and initializing a first neural network model of the named entity recognition model according to the neural network parameters; acquiring a news corpus training sample, wherein a first Chinese character in the news corpus training sample is marked with a corresponding label; converting the first Chinese character into a first word vector, and inputting the first word vector into a first neural network model to obtain a first feature vector of the Chinese character; and performing supervised training on the target conditional random field model by using the first feature vector corresponding to the first Chinese character and the corresponding label to obtain a news entity identification model. By adopting the method, the recognition effect of the news entity recognition model can be improved.","['G06F40/295', 'G06N3/08']"
CN112669928B,"Structured information construction method and device, computer equipment and storage medium","The application relates to a method and a device for constructing structured information, computer equipment and a storage medium, and belongs to the technical field of artificial intelligence. The method comprises the following steps: carrying out named entity recognition on the natural language text to obtain position information of at least two named entities in the natural language text; processing the at least two named entities and the position information of the at least two named entities through an entity matching model to obtain the matching relation between the at least one first type entity and the at least one second type entity; and constructing the structured information of the natural language text based on the matching relation between the at least one first type entity and the at least one second type entity. By the scheme, the situation that the corresponding first type entity cannot be determined when the same second type entity appears in the natural language text is avoided, and therefore the accuracy of structuring the natural language text is improved.",[]
US20190096135A1,Systems and methods for visual inspection based on augmented reality,"A system for visual inspection includes: a scanning system configured to capture images of an object and to compute a three-dimensional (3-D) model of the object based on the captured images; an inspection system configured to: compute a descriptor of the object based on the 3-D model of the object; retrieve metadata corresponding to the object based on the descriptor; and compute a plurality of inspection results based on the retrieved metadata and the 3-D model of the object; and a display device system including: a display; a processor; and a memory storing instructions that, when executed by the processor, cause the processor to: generate overlay data from the inspection results; and show the overlay data on the display, the overlay data being aligned with a view of the object through the display.","['G06T19/006', 'G02B27/0172', 'G06F18/2148', 'G06F18/24', 'G06F18/24765', 'G06K9/6257', 'G06K9/626', 'G06K9/6267', 'G06T17/00', 'G06T17/20', 'G06T19/20', 'G06T7/0006', 'G06T7/001', 'G06T7/11', 'G06T7/50', 'G06T7/73', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0141', 'G06K2209/27', 'G06T2200/08', 'G06T2207/10008', 'G06T2207/10028', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2219/2004', 'G06T2219/2012', 'G06T2219/2016', 'G06V10/25', 'G06V2201/10']"
US12406583B2,Methods for spatio-temporal scene-graph embedding for autonomous vehicle applications,"The present invention is directed to a Spatiotemporal scene-graph embedding methodology that models scene-graphs and resolves safety-focused tasks for autonomous vehicles. The present invention features a computing system comprising instructions for accepting the one or more images, extracting one or more objects from each image, computing an inverse-perspective mapping transformation of the image to generate a bird's-eye view (BEV) representation of each image, calculating relations between each object for each image, and generating a scene-graph for each image based on the aforementioned calculations. The system may further comprise instructions for calculating a confidence value for whether or not a collision will occur through the generation of a spatio-temporal graph embedding based on a spatial graph embedding and a temporal model.","['B60W30/0956', 'B60W60/0015', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06V10/82', 'G06V20/56', 'G06V20/70', 'G08G1/166', 'G08G1/167', 'B60W2420/403', 'B60W2552/00', 'B60W2554/402', 'B60W2554/4041', 'G06N3/048', 'G06N3/096']"
US11900940B2,Processing speech signals of a user to generate a visual representation of the user,"A computing system for generating image data representing a speaker's face includes a detection device configured to route data representing a voice signal to one or more processors and a data processing device comprising the one or more processors configured to generate a representation of a speaker that generated the voice signal in response to receiving the voice signal. The data processing device executes a voice embedding function to generate a feature vector from the voice signal representing one or more signal features of the voice signal, maps a signal feature of the feature vector to a visual feature of the speaker by a modality transfer function specifying a relationship between the visual feature of the speaker and the signal feature of the feature vector; and generates a visual representation of at least a portion of the speaker based on the mapping, the visual representation comprising the visual feature.","['G10L21/10', 'G10L15/22', 'G06T11/60', 'G10L13/00', 'G10L15/02', 'G10L15/26', 'G10L2021/105']"
US12386874B2,Database generation from natural language text documents,"Some embodiments may perform operations of a process that includes obtaining a natural language text document and use a machine learning model to generate a set of attributes based on a set of machine-learning-model-generated classifications in the document. The process may include performing hierarchical data extraction operations to populate the attributes, where different machine learning models may be used in sequence. The process may include using a pre-trained Bidirectional Encoder Representations from Transformers (BERT) model augmented with a pooling operation to determine a BERT output via a multi-channel transformer model to generate vectors on a per-sentence level or other per-text-section level. The process may include using a finer-grain model to extract quantitative or categorical values of interest, where the context of the per-sentence level may be retained for the finer-grain model.","['G06F16/3344', 'G06F16/31', 'G06F16/3347', 'G06F16/355', 'G06F40/186', 'G06F40/216', 'G06F40/279', 'G06F40/295', 'G06F40/30', 'G06F40/35', 'G06F40/44', 'G06N20/20', 'G06N3/0442', 'G06N3/0455', 'G06N3/09', 'G06N3/096', 'G06Q50/18', 'G06N5/04']"
US11633256B2,"Systems, methods, and media for selectively presenting images captured by confocal laser endomicroscopy","In accordance with some embodiments of the disclosed subject matter, systems, methods, and media for selectively presenting images captured by confocal laser endomicroscopy (CLE) are provided. In some embodiments, a method comprises: receiving images captured by a CLE device during brain surgery; providing the images to a convolution neural network (CNN) trained using at least a plurality of images of brain tissue captured by a CLE device and labeled diagnostic or non-diagnostic; receiving an indication, from the CNN, likelihoods that the images are diagnostic images; determining, based on the likelihoods, which of the images are diagnostic images; and in response to determining that an image is a diagnostic image, causing the image to be presented during the brain surgery.","['A61B5/0068', 'A61B5/7267', 'A61B90/361', 'A61B90/37', 'G06F18/2413', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/693', 'G06V20/698', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'A61B2090/373', 'A61B2505/05', 'A61B5/0084', 'G06N3/048', 'G06T2207/10064', 'G06T2207/10068', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30168', 'G06V2201/031']"
CN113515988B,"Palm print recognition method, feature extraction model training method, device and medium","The embodiment of the application discloses a palm print recognition method, a feature extraction model training method, equipment and a medium, and belongs to the technical field of computers. The method comprises the following steps: acquiring a target hand image, extracting the palm of the target hand image to obtain a target palm image of the target hand image, calling a feature extraction model, extracting features of the target palm image to obtain target palm print features, and identifying the target palm print features according to a plurality of stored preset palm print features and user identifications corresponding to each preset palm print feature to determine target user identifications of the target palm print features. The palm image is extracted from the hand image, so that the influence factors on palm print characteristics in the hand image are reduced, the accuracy of the palm print characteristics is improved, the sample hand image adopted in training the characteristic extraction model is acquired through different types of equipment, the application range is wide, the accuracy of the obtained palm print characteristics is improved, and the accuracy of user identification is improved.","['G06V40/1365', 'G06V40/1347', 'G06F18/214', 'G06F18/23', 'G06F18/24', 'G06N20/00', 'G06T5/50', 'G06V40/1335', 'G06T2207/20081', 'G06T2207/20221']"
CN112967243B,Deep learning chip packaging crack defect detection method based on YOLO,"A deep learning chip packaging crack defect detection method based on YOLO comprises the following steps: firstly, acquiring a chip unit image; secondly, marking the acquired image with defect type information and defect target coordinates; thirdly, enhancing data and making a data set for training; fourthly, constructing a deep learning network model for defect detection based on a YOLOv4 network; fifthly, training a deep learning network by using the pre-trained parameters as initial weights; sixthly, predicting by using the trained network, wherein the picture to be detected is input into the network after being standardized to obtain the output of a network head, the head output is decoded, and the result after decoding is inhibited by adopting an optimized non-maximum value to filter the decoded result by NMS to obtain a network prediction result; and seventhly, further filtering the network prediction result of the sixth step by adopting a confidence coefficient threshold value and a crack boundary threshold value to obtain a final result. The invention has good detection effect on the crack defects of the chip.","['G06T7/0004', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06T7/13', 'G06T7/136', 'G06T7/62', 'G06T7/73', 'G06T2207/10004', 'G06T2207/30148']"
CN112992308B,Training method of medical image report generation model and image report generation method,"The application discloses a training method of a medical image report generation model and an image report generation method, and relates to the technical field of artificial intelligence. The method comprises the following steps: performing visual feature extraction processing on the sample medical image through a visual feature extraction network to obtain a visual feature sequence; based on the visual characteristic sequence, splicing the image category label and the self-learning label to obtain the input information of the coding network; coding the input information through a coding network to obtain a visual coding feature vector, an output category result and an output task result; decoding the visual coding feature vector through a decoding network to obtain an output image report; based on the output image report, the output category results and the output task results, model losses are calculated and model parameters are adjusted. The technical scheme for automatically generating the medical image report with higher accuracy and reliability based on the AI model is provided.","['G16H15/00', 'G16H10/60', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US11687900B2,"Kiosks for remote collection of electronic devices for value, and associated mobile application for enhanced diagnostics and services","A kiosk for accepting a portable electronic device from a client in exchange for payment includes a display, one or more cameras, a portable device receiving arrangement, a payment dispensing arrangement, and a communication connection to a remote server and/or operator. The kiosk is configured to, in conjunction with the remote server and/or operator, perform one or more of associating a fundraising even with an amount payable for the accepted portable electronic device, change or defer payments in accordance with at least some attributes that are yet to be evaluated, and to perform authentication of the accepted portable electronic device.","['G06Q20/18', 'A63F13/85', 'G06F18/24', 'G06Q30/0208', 'G06Q30/0279', 'G06T7/0002', 'G07F17/3216', 'G07F17/3244', 'G07F19/20', 'G07F7/06', 'H04N23/66', 'H04N23/661', 'G06F3/0482', 'G06F3/0488', 'G07F17/3295']"
CN113657115B,Multi-mode Mongolian emotion analysis method based on ironic recognition and fine granularity feature fusion,"The invention relates to a multimode Mongolian emotion analysis method based on ironic recognition and fine granularity feature fusion, which comprises the steps of firstly combining machine translation and emotion analysis to solve the problem of inaccurate emotion analysis caused by lack of Mongolian emotion data sets; secondly, the image attribute is included in irony recognition, the attribute feature and Bi-GRU are utilized to extract text feature, bi-LSTM is replaced by Bi-GRU, and the problems of complex structure and long training time of the Bi-LSTM memory unit are alleviated; thirdly, combining with image-text correlation detection to solve the problem that in multi-mode emotion analysis, if the situation that the distribution diagram is completely irrelevant to the released text exists, larger deviation is caused to the analysis result; finally, the method of multi-mode fine granularity mixing is combined, and differences of different composition components in each mode are considered according to differences of context environments during multi-mode fine granularity mixing, so that the influence of noise information is avoided.","['G06F40/30', 'G06F16/35', 'G06F18/22', 'G06F18/253', 'G06F40/58', 'G06N3/045', 'Y02D10/00']"
US11080533B2,Surveillance system with human behavior prediction by human action recognition,The present invention concerns surveillance systems that flag the potential threats automatically using intelligent systems. It can then notify or automatically alert the security personnel of impending dangers. Such a system can lower the cognitive load on the security personnel and can assist them to bring to prioritize their attention to potential threats and thereby improve the overall efficiency of the system. There could also be savings in labor cost.,"['G06K9/00771', 'H04N7/18', 'G06F18/217', 'G06F18/2411', 'G06F18/24143', 'G06K9/00335', 'G06K9/00718', 'G06K9/4628', 'G06K9/6262', 'G06K9/6269', 'G06K9/6274', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/52', 'G06V40/20', 'G08B13/19613', 'G08B13/19615', 'G08B13/19641', 'G08B13/19645', 'G08B21/02', 'G08B31/00', 'H04N7/181', 'G06K2009/00738', 'G06V20/44']"
CN114330475B,"Content matching method, apparatus, device, storage medium, and computer program product","The embodiment of the application provides a content matching method, a device, equipment, a computer readable storage medium and a computer program product, relating to the field of artificial intelligence, wherein the method comprises the following steps: determining a first feature vector of a text in the content to be queried and a second feature vector of each image, wherein the first feature vector is vectorized fine granularity representation of the text, and the second feature vector is used for representing visual features of each image; carrying out fusion processing on the second feature vectors of the images to determine the image feature vectors of the content to be queried; carrying out fusion weighting treatment between the image feature vector and the first feature vector to determine a feature embedding vector of the content to be queried; and matching similar content corresponding to the content to be queried from the plurality of contents according to the feature embedding vector of the content to be queried and the feature embedding vectors of the preset plurality of contents. The method realizes comprehensive characterization of the text and the image of the content, and improves the accuracy of content matching.",[]
CN115761908B,A mobile-based children's visual attention abnormality screening method based on multimodal data learning,"The invention relates to a mobile terminal child visual attention abnormality screening method for multi-mode data learning, belonging to the field of computer vision. Setting a calibration video and a test video, respectively recording head-face videos of a child when the child watches the calibration video and the test video at a smart phone end, constructing an eye movement estimation model, predicting a gaze point position frame by frame from the head-face videos corresponding to the test video, extracting eye movement characteristics from a plurality of angles such as gaze point jump amplitude, gaze point jump angle, a region of interest and the like, respectively extracting facial expression characteristics and head posture characteristics from the head-face videos corresponding to the test video, and fusing different modal characteristics by utilizing a long-short-period memory network to realize mapping from multi-modal characteristics to category labels. In the test stage, recording head and face videos of the child to be classified when watching the mobile terminal videos, extracting the characteristics of eye movement, facial expression, head gesture and the like, inputting the characteristics into the trained model, and judging whether the characteristics are abnormal or not.","['G06V40/18', 'A61B5/163', 'A61B5/168', 'G06T7/0012', 'G06T7/74', 'G06T7/80', 'G06V10/26', 'G06V10/7715', 'G06V10/811', 'G06V10/82', 'G06V20/46', 'G06V40/171', 'G06V40/174', 'G06V40/176', 'G06V40/193', 'G06V40/20', 'A61B2503/06', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30196', 'G06T2207/30201']"
US12112521B2,Room acoustics simulation using deep learning image analysis,"A method comprises: receiving an image of a real-world environment; using a machine learning classifier, classifying the image to produce classifications associated with acoustic presets for an acoustic environment simulation, the acoustic presets each including acoustic parameters that represent sound reverberation; and selecting an acoustic preset among the acoustic presets based on the classifications.","['G06V10/764', 'G01H7/00', 'G06F30/13', 'G06F30/27', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/82', 'G06V20/10', 'G06V20/20', 'G06V20/64', 'H04S7/305', 'G06F2119/10', 'H04S2400/11', 'H04S2400/15']"
US11544177B2,Mapping of test cases to test data for computer software testing,"A first test case identifier that indicates a first test case is received. The first test case is indicative of testing one or more features of an application associated with the electronic marketplace. The first test case identifier is compared to a plurality of attributes. The plurality of attributes are associated with one or more listings that describe one or more items for sale in an electronic marketplace. Based at least in part on the comparing, it is determined that a first set of attributes, of the plurality of attributes, are test data candidates to be used as input to the first test case. Based at least in part on the determining, the first test case is caused to be run using at least one of the first set of attributes as test data for input.","['G06F11/3688', 'G06F16/22', 'G06F21/6254', 'G06F40/20', 'G06F40/30', 'G06F40/40', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06Q10/06395', 'G06Q30/0623', 'G06F11/3696']"
US11583239B2,Method and system of building hospital-scale chest X-ray database for entity extraction and weakly-supervised classification and localization of common thorax diseases,"A new chest X-ray database, referred to as “ChestX-ray8”, is disclosed herein, which comprises over 100,000 frontal view X-ray images of over 32,000 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. We demonstrate that these commonly occurring thoracic diseases can be detected and spatially-located via a unified weakly supervised multi-label image classification and disease localization framework, which is validated using our disclosed dataset.","['G16H30/40', 'A61B6/5217', 'G06F18/2155', 'G06K9/6259', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06T7/0012', 'G06T7/0014', 'G06V10/764', 'G06V10/82', 'G16H15/00', 'G16H30/20', 'G16H50/20', 'G16H50/70', 'A61B5/08', 'A61B5/7267', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06T2210/12', 'G06V2201/03']"
KR102155739B1,"Method, server, and system for providing chatbot service with adaptive reuse of question and answer dataset","The present invention relates to a method for providing a chatbot service adaptively reusing a question/answer data set. The method includes: a step of sending a received question to a seller terminal pre-mapped with a chatbot and stored in case the question is received from a customer terminal through a message interface; a step of additionally mapping question and answer data in a pre-established question/answer data set and turning it into a database in case the answer data with respect to the question is received at the seller terminal; and a step of sending the received answer data to the customer terminal through the message interface. The question is divided into a general inquiry and a product inquiry and inputted as re-learning data and stored in the database depending on the selection of a reuse option with respect to whether the answer data with respect to the question will be used with a period set, once, or permanently.","['G06Q30/0281', 'G06F16/3329', 'G06F16/3349', 'G06Q50/30', 'G06Q50/40']"
US11960568B2,Model and method for multi-source domain adaptation by aligning partial features,"A multi-source domain adaptation model by aligning partial features includes a general feature extraction module, a feature selection module for partial feature extraction with the dedicated loss function, three partial feature alignment losses, and two classifiers for adversarial training, where the three partial feature alignment losses include an intra-class partial feature alignment loss, an inter-domain partial feature alignment loss, and an inter-class partial feature alignment loss. With the partial features extracted by the general feature extraction module and the feature selection module following three different partial feature alignment losses, the model is capable of clustering the samples from the identical categories and isolating samples from distinct classes.","['G06F18/214', 'G06F18/2415', 'G06F18/213', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06N3/096', 'G06V10/454', 'G06V10/771', 'G06V10/7715', 'G06V10/774']"
US12182940B2,Self-supervised single-view 3D reconstruction via semantic consistency,"Apparatuses, systems, and techniques to identify a shape or camera pose of a three-dimensional object from a two-dimensional image of the object. In at least one embodiment, objects are identified in an image using one or more neural networks that have been trained on objects of a similar category and a three-dimensional mesh template.","['G06T17/20', 'G06F18/217', 'G06T17/00', 'G06T7/40', 'G06T7/50', 'G06T7/74', 'G06V10/26', 'G06V10/776', 'G06V10/82', 'G06V20/64', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
US12299408B2,Translating texts for videos based on video context,"The present disclosure describes systems, non-transitory computer-readable media, and methods that can generate contextual identifiers indicating context for frames of a video and utilize those contextual identifiers to generate translations of text corresponding to such video frames. By analyzing a digital video file, the disclosed systems can identify video frames corresponding to a scene and a term sequence corresponding to a subset of the video frames. Based on images features of the video frames corresponding to the scene, the disclosed systems can utilize a contextual neural network to generate a contextual identifier (e.g. a contextual tag) indicating context for the video frames. Based on the contextual identifier, the disclosed systems can subsequently apply a translation neural network to generate a translation of the term sequence from a source language to a target language. In some cases, the translation neural network also generates affinity scores for the translation.","['G06F40/58', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/82', 'G06V20/46']"
US20220366220A1,Dynamic weight updates for neural networks,"Apparatuses, systems, and techniques to improve federated learning for neural networks. In at least one embodiment, a federated server dynamically selects neural network weights according to one or more learnable aggregation weights indicating a contribution from each of one or more edge devices or clients during federated training according to various characteristics of each edge device or client model and training data.","['G06N3/0454', 'G06N3/08', 'G06N3/082', 'G06F18/214', 'G06K9/6256', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/0472', 'H04L67/10', 'H04L67/34', 'G06N3/006', 'G06N3/044', 'G06N3/048']"
US20240378196A1,Prompt Tuning Using One or More Machine-Learned Models,"Systems and methods for prompt tuning can leverage semantic searching for determining similar prompts to use for retraining. A prompt can be generated then searched to find the similar prompts. Data related to the similar prompts can then be utilized for prompt tuning. Moreover, systems and methods for prompt tuning can generate and utilize a meta-prompt to reduce the computational cost of generating prompts. The prompt tuning techniques can be implemented as part of a prompt tuning application programming interface (API).","['G06N20/00', 'G06F16/243', 'G06N3/091', 'G06N3/096']"
CN111047548B,"Attitude transformation data processing method and device, computer equipment and storage medium","The application relates to a method and a device for processing attitude transformation data, computer equipment and a storage medium, which relate to an artificial intelligence image processing technology and comprise the following steps: acquiring a source image and a target three-dimensional posture, obtaining a three-dimensional segmentation voxel comprising voxel type information based on semantic segmentation reconstruction, projecting the three-dimensional segmentation voxel to obtain a corresponding target posture two-dimensional segmentation map, and labeling an object in the target posture two-dimensional segmentation map based on the type information to obtain a component type; acquiring a target two-dimensional gesture corresponding to the target three-dimensional gesture, and extracting features of a source image, a target gesture two-dimensional segmentation graph and the target two-dimensional gesture to synthesize a transformation image with an intermediate scale; respectively cutting a source image, a three-dimensional segmentation voxel, a target two-dimensional posture and a transformation image to obtain part layer data of each object part, and respectively carrying out part synthesis on the part layer data of each object part to generate a part image; and fusing the transformation image and the component image to obtain a target attitude image, so that the quality of the attitude transformation image is improved.","['G06T5/50', 'G06N3/045', 'G06T7/10', 'G06T2207/20084', 'G06T2207/20221']"
CN112581106B,Government affair event automatic order dispatching method fusing grid semantics of handling organization,"The invention provides an automatic government affair event order dispatching method fusing grid semantics of a handling mechanism, which comprises the following steps: s10, acquiring a government affair event historical data set: s20, event data preprocessing and semantic feature extraction; s30, constructing an event handling mode prediction model
: taking a historical data set and a geographic position corresponding to the historical data as input, taking treatment mechanism coding as final output, and constructing and training a prediction model in a deep neural network mode
(ii) a S40, constructing a prediction model of an event handling mechanism
(ii) a S50, obtaining a prediction model by using training
And a prediction model
To predict and output the corresponding event mechanism code that needs to process the event. The invention simultaneously predicts the service type and the grid where the treatment mechanism is located through a model based on a deep neural network, and can obtain the final treatment mechanism code through a treatment mechanism prediction model.","['G06Q10/10', 'G06F40/205', 'G06F40/30', 'G06N3/045', 'G06N3/08', 'G06Q50/26']"
US11837354B2,Contrast-agent-free medical diagnostic imaging,Described herein is medical imaging technology for concurrent and simultaneous synthesis of a medical CA-free-AI-enhanced image and medical diagnostic image analysis comprising: receiving a medical image acquired by a medical scanner in absence of contrast agent enhancement; providing the medical image to a computer-implemented machine learning model; concurrently performing a medical CA-free-AI-enhanced image synthesis task and a medical diagnostic image analysis task with the machine learning model; reciprocally communicating between the image synthesis task and the image analysis task for mutually dependent training of both tasks. Methods and systems and non-transitory computer readable media are described for execution of concurrent and simultaneous synthesis of a medical CA-free-AI-enhanced image and medical diagnostic image analysis.,"['G16H30/40', 'G06T7/0012', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/0016', 'G06T7/11', 'G06T7/174', 'G16H30/20', 'G16H50/20', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096']"
CN110134968B,"Poem generation method, device, equipment and storage medium based on deep learning","The embodiment of the invention provides a poetry generating method, device, equipment and storage medium based on deep learning, and the method of the embodiment of the invention trains a transform model based on the deep learning in advance according to training corpus corresponding to each poetry type to obtain a poetry generating model corresponding to each poetry type; when the method is used, the theme information and the poem type of poems to be generated are obtained; the method comprises the steps that theme information is input into a poetry generation model corresponding to a poetry type, the poetry generation model is used for directly generating complete poetry according to the theme information, a candidate set comprising a plurality of poetry is obtained, the theme content of the generated poetry can be grasped on the whole, and the quality of the generated poetry is improved; calculating the quality coefficient of each poem in the candidate set; different screening strategies are set for different poetry types, and at least one poetry with the highest quality and the strongest association with the theme information is screened out from the candidate set according to the quality coefficient, so that the quality of poetry generation is further improved.","['G06F40/211', 'G06F40/279', 'G06N3/045', 'Y04S10/50']"
US10650286B2,Classifying medical images using deep convolution neural network (CNN) architecture,"Embodiments of the present systems and methods may provide the capability to classify medical images, such as mammograms, in an automated manner using existing annotation information. In embodiments, only the global, image level tag may be needed to classify a mammogram into certain types, without fine annotation of the findings in the image. In an embodiment, a computer-implemented method for classifying medical images may comprise receiving a plurality of image tiles, each image tile including a portion of a whole view, processed by a trained or a pre-trained model and outputting a one-dimensional feature vector for each tile to generate a three-dimensional feature volume and classifying the larger image by a trained model based on the generated three-dimensional feature volume to form a classification of the image.","['G06K9/6269', 'G06V10/82', 'A61B5/0091', 'A61B5/055', 'A61B5/7264', 'A61B5/7267', 'A61B5/7282', 'A61B6/502', 'A61B6/5217', 'G06F18/2411', 'G06F18/24133', 'G06K9/4642', 'G06K9/6271', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06F18/2433', 'G06K2209/05', 'G06K9/6284', 'G06N3/048', 'G06V2201/03']"
US12023136B2,Method and system for abnormality detection,"A method, including:receiving observation data from one or more data-capturing devices, the observation data representing a presence of an individual;processing the observation data to generate identity data representing the identity of the individual, and to detect at least one physiological characteristic or behavioural characteristic of the individual;retrieving behavioural profile data of the individual based on the identity data; andcomparing the detected characteristic to at least one expected characteristic represented by the behavioural profile data of the individual to identify an abnormality of the individual.","['A61B5/0002', 'A61B5/015', 'A61B5/02055', 'A61B5/024', 'A61B5/02416', 'A61B5/1118', 'A61B5/1171', 'A61B5/1176', 'A61B5/165', 'A61B5/18', 'A61B5/7267', 'G06V10/82', 'G06V20/52', 'G06V40/172', 'G06V40/174', 'G06V40/20', 'G06V40/28', 'A61B2503/00', 'A61B2576/00']"
US20230281253A1,Predictive system for generating clinical queries,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a predictive system that obtains and processes data describing terms for different medical concepts to generate commands from a user query. An entity module of the system determines whether a term describes a medical entity associated with a healthcare condition affecting an individual. When the term describes the medical entity an encoding module links the medical entity with a specified category based on an encoding scheme. The system receives the user query. A parsing engine of the system uses the received query to generate a machine-readable command by parsing the query against terms that describe the medical entity and based on the encoding scheme for linking the medical entity to the specified category. The system uses the command to query different databases to obtain data for generating a response to the received query.","['G06F16/90335', 'G16H50/70', 'G16H10/20', 'G06F16/2425', 'G06F16/3344', 'G06F16/353', 'G06F16/367', 'G06F16/383', 'G06F40/295', 'G06F40/30', 'G06N5/02', 'G16H10/60', 'G16H70/00', 'G06F16/24']"
CN111476781B,Concrete crack identification method and device based on video semantic segmentation technology,"The invention discloses a concrete crack identification method and a concrete crack identification device based on a video semantic segmentation technology, which belong to the technical field of concrete structure damage detection and comprise the following steps: acquiring a crack video, and manually labeling a label in a video picture frame; predicting future frames and future labels of the marked frames by using a spatial displacement rolling block, simultaneously propagating the future frames and the future labels, obtaining a synthetic sample, and preprocessing the synthetic sample to form a crack database; modifying input and output ports and parameters of data of the Deeplabv3+, enabling the data to receive video input, and establishing a CVN (composite video network) model through video output; migrating the trained convolution layer in the Deeplabv3+ network as the initial weight of the CVN model; and inputting the migrated CVN model into the crack database, and training a concrete crack detection semantic segmentation model CVN aiming at crack data. Compared with a convolutional neural classification network, the method has the advantages that the requirement on data volume is reduced, the target can be quickly and accurately identified through video input and video output, and the method has practical engineering significance.","['G06T7/0004', 'G06T7/0008', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/10', 'G06T7/11', 'G06V10/82', 'G06V20/41', 'G06V20/49', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30132']"
US12147497B2,Systems and methods for cross-lingual cross-modal training for multimodal retrieval,"Current pretrained vision-language models for cross-modal retrieval tasks in English depend upon on the availability of many annotated image-caption datasets for pretraining to have English text. However, the texts are not necessarily in English. Although machine translation (MT) tools may be used to translate text to English, the performance largely relies on MT's quality and may suffer from high latency problems in real-world applications. Embodiments herein address these problems by learning cross-lingual cross-modal representations for matching images and their relevant captions in multiple languages. Embodiments seamlessly combine cross-lingual pretraining objectives and cross-modal pretraining objectives in a unified framework to learn image and text in a joint embedding space from available English image-caption data, monolingual corpus, and parallel corpus. Embodiments are shown to achieve state-of-the-art performance in retrieval tasks on multimodal multilingual image caption datasets.","['G06F18/2148', 'G06F40/30', 'G06F40/58', 'G06F40/20', 'G06F40/44', 'G06F40/51', 'G06N3/045', 'G06N3/084', 'G06N5/022', 'G06V10/774', 'G06V10/82', 'G06F40/216', 'G06F40/284']"
US20190147640A1,Motion biased foveated renderer,"An embodiment of an electronic processing system may include an application processor, persistent storage media communicatively coupled to the application processor, a graphics subsystem communicatively coupled to the application processor, a sense engine communicatively coupled to the graphics subsystem to provide sensed information, a focus engine communicatively coupled to the sense engine and the graphics subsystem to provide focus information, a motion engine communicatively coupled to the sense engine, the focus engine, and the graphics subsystem to provide motion information, and a motion biased foveated renderer communicatively coupled to the motion engine, the focus engine, the sense engine to adjust one or more parameters of the graphics subsystem based on one or more of the sense information, the focus information, and the motion information. Other embodiments are disclosed and claimed.","['G06F3/013', 'G06T15/08', 'G02B27/017', 'G06F3/011', 'G06K9/00765', 'G06T15/005', 'G06T15/10', 'G06T15/60', 'G06V20/49', 'G06V40/19', 'H04N13/239', 'H04N13/344', 'H04N23/67', 'H04N25/702', 'H04N5/23212', 'H04N5/3696', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0187', 'G06T2200/24']"
CN113379627B,Training method of image enhancement model and method for enhancing image,"The disclosure provides a training method of an image enhancement model, a method, a device, equipment and a storage medium for enhancing an image, relates to the technical field of artificial intelligence, in particular to the technical field of computer vision and deep learning, and can be applied to an image processing scene. The training method of the image enhancement model comprises the following steps: aiming at the current training round, respectively taking sample images as input of a teacher network model and a student network model to respectively obtain a first enhanced image and a second enhanced image; training the student network model based on the first enhanced image and the second enhanced image to obtain a trained student network model for the current training round; and determining the value of the image enhancement model parameter in the current training round based on the first value of the trained student network model parameter for the current round and the second value of the image enhancement model parameter determined for the previous training round. Wherein the initial model of the image enhancement model is the same as the initial model of the student network model.","['G06T5/73', 'G06N3/045', 'G06N3/08', 'G06T5/50', 'G06T7/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'Y02T10/40']"
CN110569361B,Text recognition method and equipment,"The embodiment of the invention provides a text recognition method and equipment; the method comprises the following steps: carrying out vector representation on the title to be recognized, the text to be recognized and the source to be recognized to obtain a title vector to be recognized, a text vector to be recognized, a paragraph text vector and a source feature vector; identifying a title vector and a paragraph text vector to be identified through a keyword classification model to obtain a target probability value; the keyword classification model is used for determining the probability value of the text to be recognized belonging to the target category; identifying a text vector to be identified and a source characteristic vector through a universal classification model to obtain a text audience degree; the pervasive classification model is used for determining the audience degree of the text to be recognized; fusing the target probability value and the text audience degree through the recognition classification model to obtain a target recognition result; and the recognition classification model is used for determining the result that the text to be recognized belongs to the target class. By the embodiment of the invention, the accuracy of the target recognition result of the text to be recognized can be high.",['G06F16/35']
CN111950453B,Random shape text recognition method based on selective attention mechanism,"The invention discloses a random shape text recognition method based on a selective attention mechanism, and belongs to the field of computer vision. The method comprises the following steps: inputting an original text image, and preprocessing the original text image to obtain a sample set of the original text image; the characteristics of the preprocessed original image are encoded through a Backbone CNN integrated with a channel Attention module, and a basic characteristic encoding characteristic diagram is output; respectively carrying out text image feature coding and text region Mask feature coding on the basic feature coding feature map, and carrying out bidirectional feature weighted fusion; decoding the fusion feature map through a selective attention mechanism; and outputting the identified text information. According to the technical scheme, a selective attention mechanism is innovatively provided, the tasks of extracting text image features and serializing transcription are integrated in a neural network, and the accuracy of character recognition in any shape is greatly improved.","['G06V30/40', 'G06F18/214', 'G06F18/253', 'G06N3/044', 'G06N3/045', 'G06V30/10']"
CN118503832B,Industrial intelligent detection method and system based on multi-mode large model,"The invention provides an industrial intelligent detection method and system based on a multi-mode large model. Belongs to the technical field of industrial intelligent detection; the method comprises the following steps: the multi-mode data acquisition system captures multi-mode information in real time, and utilizes a time stamp synchronization algorithm to perform time correspondence on the multi-mode data; and processing the acquired multi-mode data, and extracting key features related to industrial detection from the processed data through a deep learning algorithm. By integrating multiple sensors and data sources (e.g., visual, acoustic, temperature), the fusion of multi-modal data greatly improves the ability to identify anomalies in complex industrial environments. The deep learning algorithm and the feature extraction technology can grasp key information from mass data more accurately, reduce false alarm and missing report, and improve detection accuracy and response speed.","['G01D21/02', 'G06F18/214', 'G06F18/24155', 'G06F18/253']"
US12190483B2,Deep generative modeling of smooth image manifolds for multidimensional imaging,A method for visualization of dynamic objects using a generative manifold includes steps of: acquiring a set of measurements associated with the dynamic objects using sensors; estimating parameters of a generator using the set of measurements and estimating latent variables using the set of measurements; modeling using a computing device the dynamic objects as a smooth non-linear function of the latent variables using the generator such that points in a latent subspace are mapped to a manifold in a generative manifold model; and generating a visualization of the dynamic objects using the generative manifold model. The set of measurements may include multi-slice data. The generative manifold model may provide for modeling deformations.,"['G06T5/70', 'G06N3/084', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06T5/50', 'G06T2207/10076', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/30048', 'G06T2207/30061']"
US11880208B2,Method for drivable area detection and autonomous obstacle avoidance of unmanned haulage equipment in deep confined spaces,"A method for drivable area detection and autonomous obstacle avoidance of unmanned haulage equipment in deep confined spaces is disclosed, which includes the following steps: acquiring 3D point cloud data of a roadway; computing a 2D image drivable area of the coal mine roadway; acquiring a 3D point cloud drivable area of the coal mine roadway; establishing a 2D grid map and a risk map, and performing autonomous obstacle avoidance path planning by using a particle swarm path planning method designed for deep confined roadways; and acquiring an optimal end point to be selected of a driving path by using a greedy strategy, and enabling an unmanned auxiliary haulage vehicle to drive according to the optimal end point and an optimal path. Images of a coal mine roadway are acquired actively by use of a single-camera sensor device.","['G05D1/0251', 'G06V20/56', 'G06N3/006', 'G05D1/0214', 'G05D1/2435', 'G05D1/2464', 'G05D1/2465', 'G05D1/617', 'G05D1/622', 'G06T5/10', 'G06T5/20', 'G06T7/0012', 'G06T7/155', 'G06T7/593', 'G06V20/41', 'G06V20/58', 'G06V20/588', 'G06V20/647', 'G06V20/70', 'G05D2105/20', 'G05D2107/73', 'G05D2109/10', 'G05D2111/10', 'G05D2111/64', 'G05D2201/0202', 'G06T2207/10012', 'G06T2207/10028', 'G06T2207/20021', 'G06T2207/20028', 'G06T2207/20036', 'G06T2207/20048', 'G06T2207/20081', 'G06T2207/30256', 'G06T2207/30261']"
US12001965B2,Distributed privacy-preserving computing on protected data,"The present disclosure relates to techniques for developing artificial intelligence algorithms by distributing analytics to multiple sources of privacy protected, harmonized data. Particularly, aspects are directed to a computer implemented method that includes receiving an algorithm and input data requirements associated with the algorithm, identifying data assets as being available from a data host based on the input data requirements, curating the data assets within a data storage structure that is within infrastructure of the data host, and integrating the algorithm into a secure capsule computing framework. The secure capsule computing framework serves the algorithm to the data assets within the data storage structure in a secure manner that preserves privacy of the data assets and the algorithm. The computer implemented method further includes running the data assets through the algorithm to obtain an inference.","['G06F16/256', 'G06F21/53', 'G06F21/602', 'G06F21/6245', 'G06F21/74', 'G06F30/20', 'G06N20/00', 'G06N5/02']"
US11657307B1,Data lake-based text generation and data augmentation for machine learning training,"Techniques for data lake-based text generation and data augmentation for machine learning training are described. A user-provided dataset including documents and corresponding label information can be automatically supplemented by creating additional high-quality document samples, with labels, via a large repository of documents in a data lake. Documents from the data lake may be identified as being semantically similar to the user-provided documents but different enough to allow a resulting model to learn from the variation in these documents. New documents can be generated from user-provided document samples or data lake sample documents by identifying and replacing slots within the samples and rewriting adjunct tokens.","['G06N5/043', 'G06F40/30', 'G06F18/22', 'G06F40/20', 'G06N20/00', 'G06V30/40', 'G06V30/41', 'G06F18/214', 'G06N3/045', 'G06N3/09']"
US11109586B2,"System and methods for automated wildlife detection, monitoring and control","The present disclosure describes a system which is able to detect and recognize wildlife, and in particular birds, using camera images. The present solution is comprised of algorithms, software and integrated hardware devices. Properly equipped, the system can be made to be portable and can be set up at any location for different wildlife detection and repelling purposes.","['A01M29/10', 'A01M29/16', 'A01M31/002', 'G06K9/00362', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T7/194', 'G06V40/10']"
US8032153B2,Multiple location estimators for wireless location,"A wireless location system is disclosed that may be configured as a gateway for receiving a plurality of requests for locating mobile stations for, e.g., E911 requests, vehicle location or tracking. For each mobile station (MS) location request, the system: (a) activates one or more location estimators for locating the MS, (b) receives one or more MS location estimates from the estimators, and (c) transmits a resulting location estimate(s) to an identified destination. MS locations are determined using one or more locating technologies based on, e.g.: computed offsets from terrestrial base stations, satellite transmissions, indoor antennas, low range base stations, and/or signal fingerprinting. The system may: adapt with environmental changes, evaluate MS locations using heuristics/constraints, and/or adjust MS estimates for more reliable and accurate estimates. The system is useful for 911 emergencies, tracking, routing (e.g., to desired products/services), people and animal location including applications for confinement to and exclusion from certain areas.","['H04W4/025', 'G01S1/026', 'G01S1/028', 'G01S5/0009', 'G01S5/0054', 'G01S5/021', 'G01S5/0244', 'G01S5/0257', 'G01S5/0278', 'H04W64/00', 'G01S2205/006', 'G01S2205/008', 'G01S5/0018', 'G01S5/06']"
US11017547B2,Method and system for postural analysis and measuring anatomical dimensions from a digital image using machine learning,"A method for use of machine learning in computer-assisted anatomical prediction. The method includes identifying with a processor parameters in a plurality of training images to generate a training dataset, the training dataset having data linking the parameters to respective training images, training at least one machine learning algorithm based on the parameters in the training dataset and validating the trained machine learning algorithm, identifying with the processor digitized points on a plurality of anatomical landmarks in an image of a person displayed on a digital touch screen by determining linear anatomical dimensions of at least a portion of a body of the person in the displayed image using the validated machine learning algorithm and a scale factor for the displayed image, and making an anatomical circumferential prediction of the person based on the determined linear anatomical dimensions and a known morphological relationship.","['G06N3/084', 'G06F18/214', 'G06F18/217', 'G06K9/00369', 'G06K9/6256', 'G06K9/6262', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06T7/60', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/103', 'G06F3/14', 'G06K2209/27', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20101', 'G06T2207/30196', 'G06V2201/10', 'G09G2354/00', 'G09G2380/08', 'G09G3/003']"
CN110826638B,Zero sample image classification model based on repeated attention network and method thereof,"The invention relates to a zero sample image classification model based on a repeated attention network, which comprises a repeated attention network module, a zero sample image classification module and a zero sample image classification module, wherein the repeated attention network module is used for training and acquiring image region sequence information; the generation countermeasure network module is used for acquiring visual error information; the visual feature extraction network processing module is used for obtaining a one-dimensional visual feature vector of the image; the attribute semantic conversion network module is used for mapping the low-dimensional attribute semantic vector to a high-dimensional feature vector with the same dimension as the visual feature vector by using two linear activation layers; the visual-attribute semantic link network is used for realizing the fusion of the visual feature vector and the attribute semantic feature vector; and the score classification result and reward output module is used for classifying the classes with the labels which are already seen by adopting cross entropy loss, and the reward output is used for punishing the un-seen non-label data and punishing the prediction result with the highest possibility of the seen classes and the un-seen classes in the non-label data. The invention can effectively solve the problem of image category label deletion.",['G06F18/241']
US20210358164A1,Content-aware style encoding using neural networks,"Apparatuses, systems, and techniques to facilitate application of a style, for which one or more neural networks have not been trained by a training framework, from one image to content of another image. In at least one embodiment, a styled output image is generated by one or more neural networks based on a style contained in a style image and content of a content image where said one or more neural networks have not been trained by a training framework on said style.","['G06T11/60', 'G06N3/04', 'G06T3/04', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06N5/04', 'G06T11/40', 'G06T5/50', 'G06T7/174', 'G06T7/73', 'G06T9/002', 'G06V10/764', 'G06T2207/20084']"
US12238271B2,Applications for detection capabilities of cameras,"In one embodiment, a system receives pixel data from a pair of regions of an image generated by an imaging device, the pair of regions includes a first region and a second region, where the first region includes a first plurality of pixels and the second region includes a second plurality of pixels. The system determines a plurality of pixel pairs, where a pixel pair includes a first pixel from the first plurality of pixels and a second pixel from the second plurality of pixels. The system calculates a plurality of contrasts based on the plurality of pixel pairs. The system determines a contrast distribution based on the plurality of contrasts. The system calculates a value representative of a capability of the imaging device to detect contrast based on the contrast distribution. The system determines a reduction in contrast detectability of the imaging device based on the value.","['H04N17/002', 'G05D1/0061', 'G05D1/0223', 'G05D1/227', 'G05D1/65', 'G06T7/0002', 'G06T2207/10024', 'G06T2207/30168']"
US11775804B2,Progressive neural networks,"Methods and systems for performing a sequence of machine learning tasks. One system includes a sequence of deep neural networks (DNNs), including: a first DNN corresponding to a first machine learning task, wherein the first DNN comprises a first plurality of indexed layers, and each layer in the first plurality of indexed layers is configured to receive a respective layer input and process the layer input to generate a respective layer output; and one or more subsequent DNNs corresponding to one or more respective machine learning tasks, wherein each subsequent DNN comprises a respective plurality of indexed layers, and each layer in a respective plurality of indexed layers with index greater than one receives input from a preceding layer of the respective subsequent DNN, and one or more preceding layers of respective preceding DNNs, wherein a preceding layer is a layer whose index is one less than the current index.","['G06N3/045', 'G06F17/16', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985']"
WO2021243706A1,Method and apparatus for cross-language question generation,"A method and apparatus for cross-language question generation. The method comprises: S1, obtaining an annotation data set, and establishing probability distribution used for question generation; S2, extracting an answer and a sentence corresponding to the answer, and after encoding, obtaining an answer vector and a sentence vector; S3, according to the answer vector, generating a context vector by means of an attention mechanism so as to obtain a basic question generation model; S4, calculating a similarity between texts to obtain a cross-language question generation model; and S5, obtaining samples by means of the cross-language question generation model, establishing a pseudo task for each sample, performing basic question generation model-based meta-learning on the cross-language question generation model, and outputting a final cross-language question generation model. The present invention has the advantages of using the annotation resource of a source language to enrich training data for shortage of a target language, thereby effectively training the question generation model of the target language; and further introducing meta learning to solve the diversity problem of a sample in a cross-language generation task.","['G06F16/332', 'G06N20/00']"
US20220066691A1,"Data writing method, device, storage server, and computer readable storage medium","This application discloses a data writing method, device, a storage server and a computer readable storage medium, including: writing, when a write request is received, write data corresponding to the write request to a write buffer; acquiring historical access data of a data block corresponding to to-be-flushed data in the write buffer when a data flushing operation is triggered for the write buffer; determining whether the to-be-flushed data is write-only data based on the historical access data by using a pre-trained classifier; if yes, writing the to-be-flushed data to a hard disk drive; and if no, writing the to-be-flushed data to a cache. The data writing method provided by this application can effectively reduce the traffic of writing dirty data to the cache while reserving more space in the cache for the ordinary data, thereby improving the utilization of the cache space and the read hit rate of the cache.","['G06F3/0656', 'G06F3/0655', 'G06F12/0868', 'G06F12/0888', 'G06F3/0604', 'G06F3/061', 'G06F3/0644', 'G06F3/0676', 'G06F3/0679', 'G06N20/00', 'G06F2212/1016', 'G06F2212/154', 'G06F2212/217', 'G06F2212/314', 'G06F2212/502']"
CN112541355B,A few-shot named entity recognition method and system for entity boundary category decoupling,"The invention relates to a method and a system for identifying named entities with fewer samples and decoupled entity boundary categories, wherein the method comprises the following steps: s1, mapping words in sentences into word embedding vectors through a shared word embedding layer; s2, extracting feature vectors through a two-way long-short-term memory network; s3, acquiring a query set entity boundary label prediction result by utilizing a boundary detection module, and extracting an entity block; s4, obtaining entity block category prototype representation based on a prototype network; s5, performing measurement calculation, and classifying according to the measurement result to obtain probability distribution of the query set entity blocks on each category; s6, joint training of the model; s7, completing the identification of the named entities with few samples. According to the method, the entity block representation is obtained through entity boundary detection, the class prototype is calculated by using a small number of samples of the support set based on the prototype network, so that the prototype network class prototype representation with stronger class distinguishing capability is obtained, and the accuracy of the task of identifying the named entity with few samples is improved.","['G06F40/295', 'G06N3/044', 'G06N3/045', 'Y02D10/00']"
US11902705B2,Video prediction using one or more neural networks,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create, from a first video, a second video having one or more additional video frames.","['H04N7/0135', 'G06F18/214', 'G06F18/217', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T9/002', 'G06N3/047', 'G06N3/049', 'G06N3/063', 'G06N3/088']"
CN112017189B,"Image segmentation method and device, computer equipment and storage medium","The application relates to an image segmentation method, an image segmentation device, computer equipment and a storage medium based on artificial intelligence. The method comprises the following steps: acquiring two-dimensional section images under different sections in the three-dimensional image; performing semantic segmentation on the target object in each tangent plane image; carrying out example segmentation on the target object in each section image; obtaining an initial segmentation result corresponding to the target object in each tangent plane image according to a semantic segmentation result and an example segmentation result corresponding to the target object in the same tangent plane image; and performing fusion processing on the initial segmentation results corresponding to each tangent plane image to obtain the segmentation result of the target object in the three-dimensional image. By adopting the method, the segmentation efficiency and the segmentation accuracy of the target object in the three-dimensional image data can be effectively improved.","['G06T7/10', 'G06F18/22', 'G06F18/241', 'G06F18/25', 'G06T2207/10004']"
WO2021121127A1,"Sample type identification method, apparatus, computer device, and storage medium","The present application relates to the field of artificial intelligence. The present application discloses a sample type identification method, an apparatus, a computer device, and a storage medium. Said method comprises: obtaining a sample to be identified; inputting into a first sample check model to perform sample feature extraction and semantic feature identification so as to obtain the identification result of a sample to be processed; if none of the first sample types matches, inputting the sample feature space result and the sample semantic space result into a second sample check model; performing clustering processing on the sample feature space result so as to obtain a first anomalous result, and performing similarity matching on the sample semantic space result so as to obtain a second anomalous result; outputting the sample type of the sample to be identified. The present application allows for automatic sample type identification, conserves manual labor cost, and enhances identification accuracy. The present application is used in fields such as smart traffic and smart medicine, and further facilitates the building of smart cities. The present application also relates to the blockchain technology, as the first sample check model can be stored in a blockchain.","['G06F18/22', 'G06F18/23213', 'G06F18/24147', 'G06F40/30', 'G06N3/045', 'G06N3/088']"
CN113537008B,Micro-expression recognition method based on adaptive motion amplification and convolutional neural network,"The invention discloses a micro-expression recognition method based on a self-adaptive motion amplification and convolution neural network, which comprises the following steps: step one: converting a certain sample of the micro-expression video into an image sequence, and cutting and aligning faces; step two: reading a starting frame of an image sequence, and calculating to obtain a vertex frame picture by using a vertex frame positioning algorithm; step three: adopting a self-adaptive motion amplification method to determine proper amplification factors, and performing motion amplification on the vertex frame according to the determined amplification factors so as to enhance the characteristics of micro expressions; step four: acquiring optical flow characteristics of the micro-expression video according to the initial frame and the amplified vertex frame to obtain horizontal optical flow, vertical optical flow and optical strain; step five: establishing a convolutional neural network model for micro-expression recognition, and performing transfer learning from macro-expression to micro-expression by using the model; and step six, inputting the optical flow characteristics into a model after transfer learning, outputting the optical flow characteristics as time space characteristics, and training the model to realize micro expression recognition.","['G06F18/214', 'G06F18/22', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06T7/248', 'G06T7/269', 'G06T2207/10016', 'G06T2207/20004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US20210256384A1,Computer-implemented methods and systems for achieving real-time dnn execution on mobile devices with pattern-based weight pruning,"PatDNN is an end-to-end framework to achieve real-time DNN execution on mobile devices. PatDNN includes two stages: a pattern-based pruning stage based on extended ADMM solution framework, and an optimized execution code generation stage including a high-level, fine-grained DNN layerwise representation and a set of architecture-aware optimizations. This design allows PatDNN to benefit from both high accuracy and hardware efficiency.","['G06N3/082', 'G06N3/04', 'G06N3/045', 'G06N3/126']"
CN111325764B,A method of fruit image contour recognition,"The invention provides a fruit image contour identification method, which comprises the following steps: training based on a Mask R-CNN deep convolution neural network, inputting a fruit image training set into the Mask R-CNN deep convolution neural network, and training to obtain a target detection model; extracting an interested region of the fruit image verification set through the target detection model, and generating a target regression box according to the interested region; performing multi-feature fusion analysis on the fruit image in the target regression frame to determine the edge contour position of the fruit; and carrying out contour fitting optimization processing on the fruit edge contour position to obtain an optimized fruit edge contour. The method can effectively reduce and reduce the influence of the complex background interference phenomenon of uneven illumination, partial shielding and similar background characteristics on fruit identification and contour fitting, and improve the robustness.","['G06T7/13', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30188']"
WO2022037256A1,"Text sentence processing method and device, computer device and storage medium","A text sentence processing method, comprising: acquiring sample text sentences containing entity pairs and relationship labels of the entity pairs; extracting positive-example sentence pairs and negative-example sentence pairs from the sample text sentences according to the relationship labels, and performing positive-negative example sampling to obtain a training set; inputting the training set into a relationship extraction model to be trained, and generating loss values comprising a contrastive loss value, the contrastive loss value representing the difference between the similarity between sentences in the positive-example pairs and the difference between the similarity between sentences in the negative-example pairs; and adjusting the parameters in the relationship extraction model according to the loss values, returning the steps for extracting the positive-example sentence pairs and the negative-example sentence pairs from the sample text sentences according to the relationship labels, performing iterative training until a training stop condition is met, and obtaining a relationship extraction model for recognizing the entity relationship of the entity pairs in the text sentences.","['G06F40/279', 'G06F40/166', 'G06F40/194', 'G06F40/30']"
CN110991545B,Multi-agent confrontation oriented reinforcement learning training optimization method and device,"The embodiment of the invention provides a multi-agent confrontation oriented reinforcement learning training optimization method and a device, wherein the method comprises the following steps: the rule coupling algorithm training process comprises the following steps: for each training step, acquiring an initial first state result set of the multi-agent of the red party, if the initial first state result set of the multi-agent of the red party meets a preset action rule, acquiring a decision behavior result set according to the preset action rule, otherwise, acquiring the decision behavior result set according to a preset reinforcement training learning algorithm; and performing reinforcement learning training on the multi-agent of the red party by using a training sample consisting of the decision-making behavior result set and other preset parameters. According to the multi-agent confrontation oriented reinforcement learning training optimization method and device provided by the embodiment of the invention, the preset action rules can guide the multi-agent action in the whole training process, and avoid invalid actions, so that the problems of more invalid explorations and low training speed in the training process in the prior art are solved, and the training efficiency is obviously improved.","['G06F18/214', 'G06N3/008']"
CN113569023B,Knowledge graph-based Chinese medicine question-answering system and method,"A Chinese medicine question-answering system based on a knowledge graph comprises a knowledge graph construction module, a question classification module, a database query module, an answer integration module and a result display module. A Chinese medicine question-answering method based on a knowledge graph comprises the following steps: s1, acquiring a query text of a user; s2, analyzing a question of a user to obtain a subject entity, a question category and a question type; s3, carrying out related query according to the analysis result and a pre-constructed Chinese medicine knowledge graph to obtain a query result; s4, sorting the medicine query results to form dialogue answers and visual data which accord with natural language; s5, displaying the text answers and the visual data. The invention improves the accuracy and the answer precision of the question type division, meets the requirements of medical consultation, food guide and disease auxiliary diagnosis and treatment of users, and provides more convenient and efficient service for the users.","['G06F16/3329', 'G06F16/3344', 'G06F16/35', 'G06F16/367', 'G06F16/951', 'G06F18/22', 'G06F40/295', 'G06F40/30', 'Y02A90/10']"
CN111931929B,Training method and device for multitasking model and storage medium,"The application discloses a training method, a device and a computer storage medium of a multitasking model, wherein a backbone network is trained by utilizing a first training image set to obtain a trained backbone network; integrating branch networks according to the relevance of the preset category tasks to obtain a multi-branch network; processing a second training image set by utilizing the trained backbone network to obtain a feature map corresponding to each sample image in the second training image set; and training the multi-branch network by utilizing the feature images corresponding to each sample image. Therefore, on the basis of extracting the characteristics of each sample image in the training image set through the trained backbone network, the application utilizes the relevance integration of the branch networks to put the branch network of the proper task class into the same branch, so that the perception performance of the multi-task model is effectively improved under the condition of equal calculation power.",['G06N3/08']
US20250261850A1,"Patient tuned ophthalmic imaging system with single exposure multi-type imaging, improved focusing, and improved angiography image sequence display","An ophthalmic imaging system provides an automatic focus mechanism based on the difference of consecutive scan lines. The system also provides of user selection of a focus point within a fundus image. A neural network automatically identifies the optic nerve head in an FA or ICGA image, which may be used to determine fixation angle. The system also provides additional scan tables for multiple imaging modalities to accommodate photophobia patients and multi-spectrum imaging options.","['A61B3/12', 'A61B3/0008', 'A61B3/0025', 'A61B3/14', 'A61B5/14555', 'G06T7/0012', 'G06T7/0014', 'G06T7/571', 'G06T7/73', 'A61B3/102', 'A61B3/1241', 'G06T2200/24', 'G06T2207/10024', 'G06T2207/10048', 'G06T2207/10064', 'G06T2207/10101', 'G06T2207/10152', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20101', 'G06T2207/20224', 'G06T2207/30041', 'G06T2207/30168']"
CN111259758B,Two-stage remote sensing image target detection method for dense area,"The invention discloses a two-stage remote sensing image target detection method for dense areas, which mainly solves the problem of low target identification accuracy of the dense areas of targets in the prior art and comprises the following steps: 1. performing data enhancement operation on an input image, and adding a training sample set; 2. constructing a multi-scale feature extraction module; 3. carrying out target detection on the feature maps with different scales to find out a region with dense targets; 4. performing secondary target detection aiming at the region with dense targets; 5. and classifying and position regressing the detected target, outputting a classification label and a position coordinate corresponding to the target, and finishing the target identification and positioning of the image. The invention utilizes the characteristics of the network multi-scale structure to extract and fuse the characteristic graphs under different scales to detect the targets with different sizes, and carries out secondary detection on the region with high target density, thereby improving the accuracy rate of small target identification. The method can be used for the detection, investigation and monitoring of targets by unmanned planes and satellites.","['G06V20/13', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06V10/464', 'G06V2201/07']"
AU2019201881B2,Systems and methods for classification of multi-dimensional time series of parameters,"James & Wells Ref: 311299AU ABSTRACT Traditional systems and methods have implemented hand-crafted feature extraction from varying length time series that results in complexity and requires 5 domain knowledge. Building classification models requires large labeled data and is computationally expensive. Embodiments of the present disclosure implement learning models for classification tasks in multi-dimensional time series by performing feature extraction from entity's parameters via unsupervised encoder and build a non-temporal linear classifier model. A fixed-dimensional feature 10 vector is outputted using a pre-trained unsupervised encoder, which acts as off-the shelf feature extractor. Extracted features are concatenated to learn a non-temporal linear classification model and weight is assigned to each extracted feature during learning which helps to determine relevant parameters for each class. Mapping from parameters to target class is considered while constraining the linear model 15 to use only subset of large number of features. [To be published with FIG. 2] 28 Obtaining a unique time series data corresponding to a plurality of parameters of one or more entities 202 Automatically extracting, using an unsupervised encoder integrated within a Deep Recurrent Neural Network (RNN), one or more features from the unique time series to obtain a unique features set for each of the plurality of parameters, 204 wherein the unique features set comprises a fixed dimensional feature vector Concatenating the one or more extracted features from the unique features set pertaining each of the plurality of 206 parameters to obtain a concatenated features set comprising a fixed-dimensional concatenated feature vector Learning a non-temporal linear classification model based on the concatenated features set, wherein during the learning of the non-temporal linear classification model a 208 weight is assigned to each feature from the concatenated features set Generating a relevance score for each parameter based on the weight of each feature from the concatenated features 210 set to validate the learned non-temporal linear classification model Receiving an input time series corresponding to the plurality 212 of parameters of the entities Automatically extracting one or more features from the input 214 time series Applying the validated learned classification model on the input time series based on the extracted one or more 216 features to obtain a class forthe input time series corresponding to the plurality of parameters of the entities FIG. 2","['G06N3/08', 'G06N3/088', 'G06F16/285', 'G06N3/0442', 'G06N3/0455', 'G06N3/0495', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G16H50/20', 'G16H50/70', 'G06N20/10']"
US20210103747A1,Audio-visual and cooperative recognition of vehicles,"A vehicle recognition system includes a sound analysis circuit to analyze captured sounds using an audio machine learning technique to identify a sound event. The system includes an image analysis circuit to analyze captured images using an image machine learning technique to identify an image event, and a vehicle identification circuit to identify a type of vehicle based on the image event and the sound event. The vehicle identification circuit may further use V2V or V2I alerts to identify the type of vehicle and communicate a V2X or V2I alert message based on the vehicle type. In some aspects, the type of vehicle is further identified based on a light event associated with light signals detected by the vehicle recognition system.","['B60W40/04', 'G06K9/00825', 'G06F18/23', 'G06F18/25', 'G06K9/00718', 'G06K9/6218', 'G06K9/6288', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/56', 'G06V20/584', 'B60W2420/403', 'B60W2420/42', 'B60W2420/54', 'B60W2556/45', 'B60W2556/65', 'G06N20/10', 'G06N20/20', 'G06N5/01']"
US11875390B2,"Computer search engine ranking for accessory and sub-accessory requests systems, methods, and manufactures",Various embodiments improve search technologies and computer information retrieval by executing a query via ranking a set of search result candidates higher than another set search result candidates based at least in part on the query and determining that a first set of search result candidates are indicative of a sub-accessory to an accessory or an accessory itself.,"['G06F16/953', 'G06Q30/0627', 'G06F16/3334', 'G06F16/9538', 'G06N5/025', 'G06Q30/0277', 'G06Q30/0643']"
US20230177682A1,Systems and methods for characterizing a tumor microenvironment using pathological images,"Implementations discussed and claimed herein provide systems and methods for characterizing patient tissue of a patient. In one implementation, a pathological image of the patient tissue is received. Nuclei of the plurality of cells in the pathological image are simultaneously segmented and classified using a histology-based digital staining system. The nuclei of the plurality of cells are segmented according to spatial location and classified according to cell type, thereby generating one or more groups of nuclei. Each of the one or more groups of nuclei have an identified cell type. A composition and a spatial organization of a tumor microenvironment of the patient tissue is determined based on the one or more groups of nuclei. A prognostic model for the patient is generated based on the composition and the spatial organization of the tumor microenvironment.","['G06F18/214', 'G06F18/2413', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/698', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096']"
CN113298189B,Cross-domain image classification method based on unsupervised domain self-adaption,"The invention discloses a cross-domain image classification method based on unsupervised domain self-adaption, which comprises the following steps of S1: constructing source domain image sample data and target domain image sample data as training data; s2: normalizing the images in the training data; s3: inputting the images in the normalized training data to a domain self-adaptive network for training, wherein the domain self-adaptive network is used for cross-domain image classification; s4: when training the domain self-adaptive network, iteratively updating parameters of the domain self-adaptive network when the total loss value does not reach a preset convergence condition, and recording the domain self-adaptive network after convergence as a domain self-adaptive classification model after training when the total loss value reaches the preset convergence condition; s5: and performing cross-domain image classification by using the trained domain self-adaptive classification model. According to the method, the loss of important information in the feature extraction process is reduced, more common features are acquired, and the accuracy of image cross-domain classification and the generalization of the image classification network model are improved.","['G06F18/241', 'G06N3/045', 'G06N3/084', 'G06V10/44', 'Y02T10/40']"
CN108846418B,Cable equipment temperature abnormity positioning and identifying method,"the invention relates to the technical field of computer image processing and recognition, in particular to a method for positioning and recognizing temperature abnormality of cable equipment. The invention selects training fast R-CNN target detection network parameters, uses the RPN network to extract the preselected region training target detection network, fully utilizes the capability of the convolutional neural network to extract two-dimensional picture characteristics, realizes the positioning and identification of the temperature anomaly of the cable equipment, and has higher accuracy, wide applicability, good identification quality and higher identification speed.","['G06F18/214', 'G01J5/00', 'G06F18/241']"
US11074412B1,Machine learning classification system,"A system trains a classification model. Text windows are defined from tokens based on a window size. A network model including a transformer network is trained with the text windows to define classification information. A first accuracy value is computed. (A) The window size is reduced using a predefined reduction factor value. (B) Second text windows are defined based on the reduced window size. (C) Retrain the network model with the second text windows to define classification information. (D) A second accuracy value is computed. (E) An accuracy reduction value is computed from the second accuracy value relative to the first accuracy value. When the computed accuracy reduction value is ≥an accuracy reduction tolerance value, repeat (A)-(E) until the accuracy reduction value is <the accuracy reduction tolerance value. Otherwise, increase the window size, define final text windows based on the increased window size, and retrain the network model.","['G06F40/284', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096']"
AU2019100886A4,Plant organ image separation method and system,"The present invention discloses a plant organ image separation method and system. The separation method includes: acquiring an image of a to-be-measured plant captured by each camera; acquiring a three-dimensional point cloud under the perspective of each camera; unifying all three-dimensional point clouds into a global coordinate system for splicing, to obtain an initial three-dimensional point cloud of the to-be-measured plant; projecting the initial three-dimensional point cloud of the to-be-measured plant onto an OXY plane of the global coordinate system, to obtain a two-dimensional projection point image of the to-be-measured plant; locating stem and leaf regions of the to-be-measured plant in the two-dimensional projection point image of the to-be-measured plant by a plant image region segmentation model; acquiring a stem point cloud region and a leaf point cloud region of the to-be-measured plant in the initial three-dimensional point cloud of the to-be-measured plant, according to a corresponding relationship between the three-dimensional point cloud and a projection point in the global coordinate system; and performing organ point cloud segmentation of the to-be-measured plant by a K-means clustering algorithm, to obtain a three-dimensional point cloud region corresponding to each organ of the to-be-measured plant. The present invention can avoid a data spot when data is spliced, thus improving the plant organ image separation accuracy. To-be-measured plant image acquisition module Three-dimensional point cloud acquisition module Splicing module Projection module Locating module Plant organ three-dimensional point cloud region initial acquisition module Plant organ three-dimensional point cloud region initial determining module 1-2 -1 1-3",[]
US11978258B2,Techniques for identification of out-of-distribution input data in neural networks,"Apparatuses, systems, and techniques to identify out-of-distribution input data in one or more neural networks. In at least one embodiment, a technique includes training one or more neural networks to infer a plurality of characteristics about input information based, at least in part, on the one or more neural networks being independently trained to infer each of the plurality of characteristics about the input information.","['G06V20/56', 'G06F18/211', 'G06F18/2415', 'G06F18/2431', 'G06F18/2433', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06V10/82', 'G06N3/044']"
CN112115469B,Edge intelligent mobile target defense method based on Bayes-Stackelberg game,"The invention discloses an edge intelligent mobile target defense method based on Bayes-Stackelberg game, and provides a dynamic defense mechanism called edge intelligent mobile target defense (EI-MTD). The method comprises the steps of distilling the differential knowledge from a complex teacher model of a cloud data center to obtain a member model with smaller scale and suitable for being deployed at an edge node. And then, dynamically scheduling the member model by using a Bayes-Stackelberg game strategy, so that an attacker cannot judge the target model for executing the classification task. The defense mechanism can effectively prevent an attacker from selecting the optimal proxy model to make a countermeasure sample, thereby blocking the black box attack. Experiments on an ILSVRC2012 image dataset show that the EI-MTD provided by the invention can effectively protect edge intelligence from being attacked by malicious black boxes.","['G06F21/55', 'G06F18/214', 'G06F9/5072', 'G06N3/045']"
US11756675B2,Systems and methods for analysis and remote interpretation of optical histologic images,"A system is presented for analyzing and interpreting histologic images. The system includes an imaging device and a diagnostic module. The imaging device captures an image of a tissue sample at an optical section of the tissue sample, where the tissue sample has a thickness larger than the optical section. The system may further include an image interpretation subsystem located remotely from the imaging device and configured to receive the images from the imaging device. The diagnostic module is configured to receive the images for the tissue sample from the imaging device and generates a diagnosis for the tissue sample by applying a machine learning algorithm to the images. The diagnostic module may be interface directly with the imaging device or located remotely at the image interpretation subsystem.","['G16H30/40', 'G01N21/65', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/0012', 'G01N2021/655', 'G01N2201/0221', 'G01N2201/1296', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096']"
CN116186317B,Cross-modal cross-guidance-based image-text retrieval method and system,"The invention belongs to the technical field of artificial intelligence, and discloses a cross-modal cross-guidance-based image-text retrieval method and a cross-modal cross-guidance-based image-text retrieval system, wherein the cross-modal cross-guidance-based image-text retrieval method comprises the following steps of: inputting image data and text data; performing feature extraction and shared semantic learning of two different mode data of images and texts by using a cross-mode cross-guidance network model constructed based on a self-distillation algorithm to complete training of the model, wherein the cross-mode cross-guidance network model comprises a teacher network and a student network, the student network comprises two branches of images and texts, the teacher network has the same structure as the student network, and cross-mode cross-guidance is performed between the teacher network and the student network; finally, inputting the images or texts to be searched into a trained cross-modal cross-guidance network model to extract corresponding features, calculating the similarity of the images or texts to be searched, and searching according to the similarity score to obtain an optimal searching result; by the method and the device, cross-modal semantic alignment is realized, and retrieval accuracy is improved.","['G06F16/583', 'G06F16/383', 'G06N3/04', 'G06N3/08', 'Y02D10/00']"
WO2021169115A1,"Risk control method, apparatus, electronic device, and computer-readable storage medium","Provided is a risk control method, relating to the technical field of intelligent decision making. The method comprises: collecting service data of a preset type and similar service data similar to the service data of the preset type, and inputting same into a pre-constructed neural network model; calculating a classification loss value of the similar service data, and an adaptive loss value of the service data of the preset type and the similar service data in each hidden layer of the neural network model; taking the sum of the classification loss value and the adaptive loss values of all the hidden layers as a total loss value, substituting same into the neural network model, and training the neural network model, so as to obtain an optimized neural network model; and inputting service data to be subjected to prediction into the optimized neural network model, outputting a label of the service data to be subjected to prediction, and obtaining, according to the label, a risk prediction value of the service data to be subjected to prediction. In the method, by calculating a multi-layer domain adaptive loss function on a neural network, noise in source domain data can be filtered out, thereby improving the performance of a prediction model.","['G06N3/08', 'G06Q40/03']"
US20220165364A1,Systems and Methods for Determining Molecular Properties with Atomic-Orbital-Based Features,"Systems and methods for determining molecular structures based on atomic-orbital-based features are described. Atomic-orbital-based features can be utilized in combination with machine-learning methods to predict accurate properties, such as quantum mechanical energy, of molecular systems.","['G16C20/30', 'G16C10/00', 'G06N3/044', 'G06N3/08', 'G16C20/50', 'G06N10/20', 'G06N3/045', 'G16B15/00', 'G16B40/20', 'G16C20/70', 'G16C60/00']"
US11468542B2,LAPRAN: a scalable Laplacian pyramid reconstructive adversarial network for flexible compressive sensing reconstruction,"This disclosure addresses the single-image compressive sensing (CS) and reconstruction problem. A scalable Laplacian pyramid reconstructive adversarial network (LAPRAN) facilitates high-fidelity, flexible and fast CS image reconstruction. LAPRAN progressively reconstructs an image following the concept of the Laplacian pyramid through multiple stages of reconstructive adversarial networks (RANs). At each pyramid level, CS measurements are fused with a contextual latent vector to generate a high-frequency image residual. Consequently, LAPRAN can produce hierarchies of reconstructed images and each with an incremental resolution and improved quality. The scalable pyramid structure of LAPRAN enables high-fidelity CS reconstruction with a flexible resolution that is adaptive to a wide range of compression ratios (CRs), which is infeasible with existing methods.","['G06T3/4053', 'G06T3/4046', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T5/50', 'G06T5/60', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
CN110796098B,"Method, device, equipment and storage medium for training and auditing content auditing model","The embodiment of the invention discloses a method, a device, equipment and a storage medium for training and auditing a content auditing model, wherein the method for training the content auditing model comprises the following steps: receiving a sample video file; extracting partial image data in the sample video file as sample image data; if the content of the sample image data is illegal, locating a time point of the sample image data in the sample video file; extracting image area data with significance from image data surrounding the time point; and training a content auditing model according to the image area data and the sample image data. The method has the advantages that sample image data with illegal content is positioned in time, image area data with significance is positioned in space, characteristics representing illegal content can be sampled from a sample video file quickly, quality of the characteristics is improved in time and space dimensions, accordingly, a content audit model is trained, and performance of the content audit model can be guaranteed.","['H04N21/466', 'G06F16/783', 'G06F18/214', 'G06N3/045', 'G06T3/40', 'G06V10/22', 'G06V10/774', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/49', 'H04N21/4542', 'G06N3/084']"
US12265612B2,Method for identifying vulnerabilities in computer program code and a system thereof,"Open-source software is prevalent in the development of new technologies. Monitoring software updates for vulnerabilities is expensive and time consuming. Online discussions surrounding new software updates can often provide vital information regarding emerging risks. It is presented a novel approach for automating surveillance of software through the use of natural language processing methods on open-source issues. Further, the potential of virtual adversarial training, a popular semi-supervised learning technique, is used to leverage the vast amounts of unlabeled data available to achieve improved performance. On industry data, it is found that a hierarchical attention network with virtual adversarial training that utilizes the innate document structure to encapsulate the text can be used with good results.","['G06F21/554', 'G06N3/088', 'G06F18/214', 'G06F18/2178', 'G06F21/552', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/047', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/082']"
US11790413B2,System and method for communication,"A digital communication method, comprising: providing a digital packet radio transceiver which communicates through an antenna array, defining a directional pattern with distinct spatial communication channels using a plurality of frequency channels; detecting channel conditions based on a feedback protocol between the digital packet radio transceiver and a remote digital packet radio system, selectively controlling the digital packet transceiver to transmit information responsive to the channel conditions; detecting another digital packet radio transceiver concurrently using the same frequency channels, and selectively controlling an interference with the other digital packet radio transceiver in dependence on information from the other digital packet radio transceiver, by one of deferring to transmissions by the other digital packet radio transceiver, and competing with transmissions by the other digital packet radio transceiver.","['G06Q30/0282', 'G06Q30/0207', 'G06Q30/08', 'G07F17/32', 'G07F17/323', 'G07F17/3237']"
CN111524557B,"Inverse synthesis prediction method, device, equipment and storage medium based on artificial intelligence","The embodiment of the application discloses an artificial intelligence-based inverse synthesis prediction method, an artificial intelligence-based inverse synthesis prediction device and a storage medium, wherein the method comprises the following steps: obtaining the graph structure of a product molecule and the attribute characteristics of atoms in the product molecule; predicting, by a graph neural network model, a broken chemical bond in the product molecule based at least on a graph structure of the product molecule and a characteristic feature of atoms in the product molecule; performing bond breaking treatment on the product molecules based on the broken chemical bonds to obtain at least one synthon; and predicting the reactant molecules at least according to the character strings corresponding to the reverse synthesis reaction types, the character strings corresponding to the product molecules and the character strings corresponding to at least one synthon through a sequence learning model. The method can effectively improve the prediction precision of the inverse synthetic reaction of the organic compound, so that the prediction process of the inverse synthetic reaction of the organic compound is easier to visualize and has better interpretability.","['G16C20/10', 'G06N3/08', 'G16C20/20']"
US10937416B2,Cross-domain multi-task learning for text classification,"A method includes providing input text to a plurality of multi-task learning (MTL) models corresponding to a plurality of domains. Each MTL model is trained to generate an embedding vector based on the input text. The method further includes providing the input text to a domain identifier that is trained to generate a weight vector based on the input text. The weight vector indicates a classification weight for each domain of the plurality of domains. The method further includes scaling each embedding vector based on a corresponding classification weight of the weight vector to generate a plurality of scaled embedding vectors, generating a feature vector based on the plurality of scaled embedding vectors, and providing the feature vector to an intent classifier that is trained to generate, based on the feature vector, an intent classification result associated with the input text.","['G06F40/284', 'G10L15/1815', 'G06F16/35', 'G06F16/90332', 'G06F40/30', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G10L15/16', 'G10L15/22', 'G06N20/10', 'G06N3/044', 'G10L15/26']"
US20210342730A1,System and method of quantum enhanced accelerated neural network training,"A novel and useful system and method of quantum enhanced accelerated training of a classic neural network (NN). The quantum system implements an optimizer that accelerates training of the classic NN by exploiting the properties of quantum mechanics and manipulating the quantum system into a state that represents the complete state of the classic NN, including the loss function. The quantum system is then allowed to transition to its “optimum state” and the minimum energy state is read out from detectors and weight updates are calculated and fed back to the classic NN. Mapping and detection helper neural networks learn the characteristics of the quantum system structures. By averaging this over a number of images the learning weight or gradient of descent can be controlled to yield optimum neural network parameters. The time and energy required for training the classic NN as well as for inference is drastically reduced.","['G06N10/00', 'G06N10/60', 'G06N10/40', 'G06N10/70', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/06', 'G06N3/08']"
US12406104B2,System and method for artifact reduction of computed tomography reconstruction leveraging artificial intelligence and a priori known model for the object of interest,"Nondestructive evaluation (NDE) of objects can elucidate impacts of various process parameters and qualification of the object. Computed tomography (CT) enables rapid NDE and characterization of objects. However, CT presents challenges because of artifacts produced by standard reconstruction algorithms. Beam-hardening artifacts especially complicate and adversely impact the process of detecting defects. By leveraging computer-aided design (CAD) models, CT simulations, and a deep-neutral network high-quality CT reconstructions that are affected by noise and beam-hardening can be simulated and used to improve reconstructions. The systems and methods of the present disclosure can significantly improve the reconstruction quality, thereby enabling better detection of defects compared with the state of the art.","['G06F30/10', 'G06T11/008', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T19/20', 'G06T7/0002', 'G06N3/048', 'G06T2207/10081', 'G06T2211/441', 'G06T2211/448', 'G06T2211/452']"
US11967097B2,System and method for change analysis,"In variants, the method for change analysis can include detecting a rare change in a geographic region by comparing a first and second representation, extracted from a first and second geographic region measurement sampled at a first and second time, respectively, using a common-change-agnostic model.","['G06T7/20', 'G06T7/60', 'G06V10/761', 'G06V10/764', 'G06V20/17', 'G06T2207/10032', 'G06T2207/20081', 'G06T2207/30184']"
CN110633745B,Image classification training method and device based on artificial intelligence and storage medium,"The embodiment of the invention discloses an image classification training method and device based on artificial intelligence and a storage medium, which are applied to the technical field of machine learning of artificial intelligence. The classification training device firstly selects a training set, determines the class of the sketch in the training set according to the sketch classification model, and can identify the sketch features obtained in the sketch classification model according to the real picture identifier to obtain a second sketch feature identification result; and then fixing the real chart classification model and the sketch identifier, and adjusting the fixed parameter value of the sketch classification model according to the class of the sketch and the second sketch feature identification result. Therefore, when the fixed parameter value of a certain classification model, namely the sketch classification model, is adjusted, the error of classification of the corresponding image by referring to the classification model is also referred to by referring to the useful information of another classification model, namely the fixed real sketch classification model, in the classification process, so that the classification calculation of the adjusted sketch classification model is more accurate.","['G06N3/08', 'G06F18/214', 'G06F18/24', 'G06F18/2411', 'G06F18/254', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06V10/809', 'G06V10/82', 'G06V30/19147', 'G06V30/19167', 'G06V30/19173', 'G06V30/333', 'G06V30/36', 'G06V30/413']"
WO2020233464A1,"Model training method and apparatus, storage medium, and device","The present application relates to the technical field of artificial intelligence. Disclosed are a model training method and apparatus, a storage medium, and a device. The method comprises: obtaining a plurality of training samples, each training sample comprising an interactive screen and an action tag which gives an interactive action taken by a character object in the interactive screen; performing feature extraction on the interactive screen comprised in each training sample, and performing clustering on the basis of the extracted features; determining at least one key sample in the plurality of training samples according to the obtained clustering result; and setting a weight for each training sample, and updating network parameters of a deep network on the basis of the training samples having the weights, the weight of each key sample being greater than the weights of other samples in the plurality of training samples.","['A63F13/67', 'G06N5/025', 'A63F13/56', 'G06F18/214', 'G06F18/22', 'G06F18/23', 'G06F18/23213', 'G06N3/08', 'G06V10/763', 'G06V10/82', 'G06V20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045']"
CN110737783B,Method and device for recommending multimedia content and computing equipment,"The application discloses a method, a device and a computing device for recommending multimedia contents, which are used for improving the accuracy and effectiveness of recommending the multimedia contents and further improving the recommendation performance of a recommendation system. The method comprises the following steps: obtaining a recommendation request; after obtaining a recommendation request, responding to the recommendation request, and determining candidate multimedia contents of which the comprehensive attraction degrees meet a preset attraction degree condition from a multimedia content recommendation pool; the comprehensive attraction degree of the multimedia content to be recommended is determined according to a title attraction degree and a picture attraction degree corresponding to the multimedia content to be recommended, the title attraction degree indicates the attraction degree of a text title of the multimedia content to be recommended to a user, and the picture attraction degree indicates the attraction degree of at least one abstract picture of the multimedia content to be recommended to the user; and recommending the multimedia content according to the candidate multimedia content.",['G06F16/435']
US11087460B2,Methods and systems for training and validating quantitative imaging biomarkers,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06T7/0012', 'G16H50/20', 'A61B6/032', 'G06F18/211', 'G06F18/2148', 'G06F18/24', 'G06K9/00127', 'G06K9/3233', 'G06K9/6228', 'G06K9/6257', 'G06K9/6267', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T3/00', 'G06T5/003', 'G06T5/73', 'G06T7/11', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06V20/69', 'G16H30/40', 'G06T2207/10048', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10101', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06T2207/30104', 'G06V2201/03']"
US10551930B2,System and method for executing a process using accelerometer signals,Apparatus and process for controlling a computer process with gestures and a handheld pointing device. The computer system employing the pointing device to determine what component a user wants to control and what control action is desired.,"['G06F3/017', 'A63F13/211', 'A63F13/213', 'A63F13/22', 'A63F13/42', 'A63F13/428', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06F3/0346', 'G06F3/038', 'G06K9/00355', 'G06T7/20', 'G06T7/285', 'G06T7/593', 'G06V40/28', 'H04N13/128', 'H04N13/239', 'H04N13/366', 'A63F2300/1093', 'G06K9/00335', 'G06V40/20', 'H04N2013/0081']"
EP3480786A1,Medical image object detection with dense feature pyramid network architecture in machine learning,"For object detection (56), deep learning (44) is applied with an architecture designed for low contrast objects, such as lymph nodes. The architecture uses a combination of dense deep learning or features, which employs feed-forward connections between convolutions layers (22), and a pyramidal arrangement of the dense deep learning using different resolutions.","['G06T7/0012', 'G06N3/048', 'G06T7/11', 'G16H30/40', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US11222627B1,Exploring ASR-free end-to-end modeling to improve spoken language understanding in a cloud-based dialog system,"Systems and methods are provided for conducting a simulated conversation with a language learner include determining a first dialog state of the simulated conversation. First audio data corresponding to simulated speech based on the dialog state is transmitted. Second audio data corresponding to a variable length utterance spoken in response to the simulated speech is received. A fixed dimension vector is generated based on the variable length utterance. A semantic label is predicted for the variable-length utterance based on the fixed dimension vector. A second dialog state of the simulated conversation is determined based on the semantic label, and third audio data corresponding to simulated speech is transmitted based on the second dialog state.","['G10L15/1822', 'G10L15/1815', 'G06F40/35', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G09B19/06', 'G10L15/16', 'G10L15/22', 'G10L25/24', 'G06N20/10', 'G06N3/048', 'G06N5/01']"
US20230097859A1,Method and system for determining coarsened grid models using machine-learning models and fracture models,"A method may include obtaining fracture image data regarding a geological region of interest. The method may further include determining various fractures in the fracture image data using a first artificial neural network and a pixel-searching process. The method may further include determining a fracture model using the fractures, a second artificial neural network, and borehole image data. The method may further include determining various fracture permeability values using the fracture model and a third artificial neural network. The method may further include determining various matrix permeability values for the geological region of interest using core sample data. The method may further include generating a coarsened grid model for the geological region of interest using a fourth artificial neural network, the matrix permeability values, and the fracture permeability values.","['G01V99/005', 'G01V20/00', 'G06V10/82', 'E21B43/267', 'G06F30/20', 'G06K9/0063', 'G06K9/4671', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/462', 'G06V10/50', 'G06V10/776', 'G06V20/17', 'E21B2200/20', 'E21B2200/22', 'G01V1/301', 'G01V1/306', 'G01V2210/624', 'G01V2210/6244', 'G01V2210/6246', 'G01V2210/646', 'G01V2210/66', 'G06F30/28']"
US20180322623A1,Systems and methods for inspection and defect detection using 3-d scanning,"A method for detecting defects in objects includes: controlling, by a processor, one or more depth cameras to capture a plurality of depth images of a target object; computing, by the processor, a three-dimensional (3-D) model of the target object using the depth images; rendering, by the processor, one or more views of the 3-D model; computing, by the processor, a descriptor by supplying the one or more views of the 3-D model to a convolutional stage of a convolutional neural network; supplying, by the processor, the descriptor to a defect detector to compute one or more defect classifications of the target object; and outputting the one or more defect classifications of the target object.","['G06T7/0004', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06N5/046', 'G06T15/205', 'G06T17/20', 'G06T7/55', 'G06N20/10', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30124']"
EP3483797A1,"Training, validating, and monitoring artificial intelligence and machine learning models","A device identifies training data and scoring data for a model, and removes bias from the training data to generate unbiased training data. The device trains the model with the unbiased training data to generate trained models, and processes the trained models, with the scoring data, to generate scores for the trained models. The device selects a trained model, from the trained models, based on model metrics and the scores, and processes a training sample, with the trained model, to generate first results, wherein the training sample is created based on the unbiased training data and production data. The device processes a production sample, with the trained model, to generate second results, wherein the production sample is created based on the production data and the training sample. The device provides the trained model for use in a production environment based on the first results and the second results.",['G06N20/20']
US11847113B2,Method and system for supporting inductive reasoning queries over multi-modal data from relational databases,"A system, apparatus, and a method for training with multi-modal data in a relational database, including generating a first database including a multi-view of the multi-modal data, retrieving a second set of data from an external source via a network, and training a first model according the first database and the second set of data. The first model outputs relationships of the first database with the multi-view and the second set of data.","['G06F16/24526', 'G06F16/2433', 'G06F16/24556', 'G06F16/283', 'G06F16/285', 'G06N3/088', 'G06N5/04', 'G06N20/20']"
CN111741330B,"Video content evaluation method and device, storage medium and computer equipment","The embodiment of the application discloses a video content evaluation method, a video content evaluation device, a storage medium and computer equipment; the method and the device are related to the big data field and the artificial intelligence machine learning field, and are used for acquiring text information and image information of the video to be evaluated and acquiring evaluation information of an associated object corresponding to the video to be evaluated; vector conversion is carried out on the text information to obtain a text vector; inputting the image information into a trained first neural network model to obtain an image vector, wherein the network parameters of the trained first neural network model are obtained based on sample image information, sample evaluation information of a corresponding association object and label training; the text vector, the image vector and the evaluation information are input into the trained second neural network model to obtain the content evaluation result of the video to be evaluated, so that the efficiency of video content evaluation can be improved.","['H04N21/23418', 'G06F18/214', 'G06N3/045', 'G06N3/047', 'G06N3/049', 'G06N3/08']"
CN108613802B,A kind of mechanical failure diagnostic method based on depth mixed network structure,"The present invention relates to a kind of mechanical failure diagnostic methods based on depth mixed network structure, belong to mechanical fault diagnosis field.Method includes the following steps: 1) original vibration signal obtains；2) original vibration signal passes through first part's both scatternets of hybrid network, extracts its frequency characteristic of field, inhibits noise jamming；3) each subband of both scatternets output is respectively as corresponding channel in SDnet input；4) the second part SDnet for passing through hybrid network, further extracts feature and failure modes diagnose.The method applied in the present invention compared with prior art, the more lightweight in network structure, while there is higher recognition accuracy, and there is stronger transfer learning ability and noiseproof feature.","['G01M13/00', 'G01H17/00']"
CA3080916C,Deep-learning-based system and process for image recognition,"Disclosed are methods and systems for using artificial intelligence (AI) for image recognition by using predefined coordinates to extract a portion of a received image, the extracted portion comprising a word to be identified having at least a first letter and a second letter; executing an image recognition protocol to identify the first letter; when the server is unable to identify the second letter, the server executes an AI model having a nodal data structure to identify the second letter based upon the identified first letter, the nodal data structure comprising a set of nodes where each node represents a letter, each node connected to at least one other node, wherein connection of a first node to a second node corresponds to a probability that a letter corresponding to the second node is used in a word subsequent to a letter corresponding to the first node.","['G06N3/082', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/82', 'G06V30/1478', 'G06V30/19147', 'G06V30/226', 'G06V30/412', 'G06V30/413', 'G06V40/33']"
US8745755B2,Controlling device access to enterprise resources in an orchestration framework for connected devices,"Aspects described herein allow multiple devices to function as a coherent whole, allowing each device to take on distinct functions that are complementary to one another. Aspects described herein also allow the devices function as a coherent whole when interconnected devices and their respective applications are configured to operate in various operation modes, when management policies are employed to control the operation of the interconnected devices and their respective applications, when transferring content between the interconnected devices and storing the content at those devices, when obtaining access credentials for the interconnected devices that enable the devices to access enterprise resources, when a policy agent applies management policies to control operation of and interaction between the interconnected devices, and when the interconnected devices are used to access an enterprise application store.","['H04L67/63', 'G06F21/41', 'G06F21/53', 'G06F21/6218', 'G06F9/543', 'H04L1/0025', 'H04L63/04', 'H04L63/0815', 'H04L63/10', 'H04L67/04', 'H04L67/10', 'H04L67/104', 'H04L67/34', 'H04L67/567', 'H04L67/60', 'H04L9/14', 'G06F2221/2149', 'H04L12/2856']"
US10990901B2,"Training, validating, and monitoring artificial intelligence and machine learning models","A device identifies training data and scoring data for a model, and removes bias from the training data to generate unbiased training data. The device trains the model with the unbiased training data to generate trained models, and processes the trained models, with the scoring data, to generate scores for the trained models. The device selects a trained model, from the trained models, based on model metrics and the scores, and processes a training sample, with the trained model, to generate first results, wherein the training sample is created based on the unbiased training data and production data. The device processes a production sample, with the trained model, to generate second results, wherein the production sample is created based on the production data and the training sample. The device provides the trained model for use in a production environment based on the first results and the second results.","['G06N20/20', 'G06N20/00', 'G06N3/0464', 'G06N3/09', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N7/01']"
CN113705597B,"Image processing method, device, computer equipment and readable storage medium","The embodiment of the application discloses an image processing method, an image processing device, computer equipment and a readable storage medium, wherein the image processing method is based on an artificial intelligence technology and comprises the following steps: acquiring an image to be identified; processing the image to be identified by using an image identification model to obtain a scene category corresponding to the content in the image to be identified; the image recognition model is obtained by using a memory unit for auxiliary training; in the process of training the image recognition model by using sample data, determining a classification loss value corresponding to the sample data based on scene category judgment information of a plurality of scene categories stored by the memory unit, and adjusting model parameters of an initial image recognition model based on the classification loss value to obtain the trained image recognition model. By the embodiment of the application, the deviation of the processed image data can be effectively reduced, and the scene recognition accuracy of the image can be improved.","['G06F18/241', 'G06F18/214', 'G06N3/045', 'G06N3/084']"
CN114363623B,"Image processing method, device, medium and electronic equipment","The application belongs to the technical field of artificial intelligence, and particularly relates to an image processing method, an image processing device, a computer readable medium and electronic equipment. The image processing method comprises the steps of receiving image coding data of video clips transmitted by a coding end, decoding the image coding data to obtain a first video frame, key points in the first video frame and key points in a second video frame, wherein the key points are used for representing the motion gesture of a target object in the video frame, generating transformation information of the motion gesture of the target object according to the key points in the first video frame and the key points in the second video frame, and generating a reconstructed image of the second video frame according to the first video frame and the transformation information.","['H04N19/137', 'H04N19/54', 'G06N3/04', 'G06T7/248', 'G06T7/73', 'G06V10/761', 'G06V10/776', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'H04N19/132', 'H04N19/17', 'H04N19/182', 'H04N19/46', 'H04N19/60', 'H04N19/90', 'G06T2207/10016', 'G06T2207/20081']"
US12229234B2,Data management systems and methods,"A data management system (1) for securely managing data transactions comprises a computing system which incorporates, a public key distribution system, a trusted storage system which is in communication with the public key distribution system, the trusted storage system being configured to store a record for each respective party using the system, each record comprising a unique identifier and a public key for a respective party using the system. The system (1) comprises a verification system which is configured to check the identity of a party seeking to participate in a transaction involving an exchange of data. If the verification system is not able to verify the identity of the party seeking to participate in the transaction, the verification system prevents the transaction from being carried out. If the verification system is able to verify the identity of the party seeking to participate in the transaction, the verification system permits the transaction to be carried out and the trusted storage system stores a transaction record comprising a record of the transaction and a record of the party participating in the transaction.","['G06F21/604', 'G06F21/32', 'G06F21/602', 'H04L9/083', 'G06F2221/2141']"
US20200272625A1,"Platform and method for evaluating, exploring, monitoring and predicting the status of regions of the planet through time","A Platform and Method for Evaluating, Exploring, and Predicting the Status of Regions of the Planet through Time is provided. The method is a computer-implemented means for evaluating an area. The method includes collecting relevant datasets, transforming datasets into dynamic datasets, selecting a region of interest, selecting factors of interest, producing an evaluation index for the region of interest, specifying targets and thresholds for the evaluation index, generating a visualization of the evaluation index for the region of interest; generating alerts when the evaluation index changes in specified ways, and reporting the status and trend of the region of interest using the evaluation index. The data transformation is optionally achieved with machine learning algorithms and training data to produce time series indices. The method may also produce predictive models and maps from the time series indices.","['G06F16/2474', 'G06F16/29', 'G01W1/10', 'G06F16/2228', 'G06F16/24573', 'G06F16/2465', 'G06F16/248', 'G06F16/26', 'G06N20/00', 'G06N3/08', 'G06N5/04', 'G06Q10/04', 'G06N3/044', 'G06N3/045', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'Y02A90/10']"
US12122053B2,Generating computer simulations of manipulations of materials based on machine learning from measured statistics of observed manipulations,"Apparatuses, systems, and techniques to identify at least one physical characteristic of materials from computer simulations of manipulations of materials. In at least one embodiment, physical characteristics are determined by comparing measured statistics of observed manipulations to simulations of manipulations using a simulator trained with a likelihood-free inference engine.","['B25J9/1671', 'B25J11/008', 'B25J9/163', 'G05B17/02', 'G06F17/18', 'G06F18/214', 'G06F30/27', 'G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/0499', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N7/01', 'G06T7/0004', 'G06T7/77', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06V20/64', 'G01N15/00', 'G06F30/25', 'G06T2207/10028', 'G06T2207/20056', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30128', 'G06V2201/031', 'G06V2201/06']"
CN110717470B,"Scene recognition method and device, computer equipment and storage medium","The embodiment of the invention discloses a scene recognition method, a device, computer equipment and a storage medium, wherein the scene recognition method comprises the following steps: performing shot segmentation on the target video, and extracting audio data and an image sequence in the segmented shot segments; respectively inputting the audio data and the image sequence into corresponding deep learning network models to obtain audio characteristics and image characteristics; fusing the audio features and the image features to obtain fusion features; and inputting the fusion characteristics into a scene classifier, and identifying the scenes of the corresponding lens fragments to obtain scene categories. The technical scheme of the embodiment of the invention can improve the accuracy of video scene recognition.","['G06V20/41', 'G06N3/045', 'G06N3/08']"
CN114332578B,"Image anomaly detection model training method, image anomaly detection method and device","The application relates to an image anomaly detection model training method, an image anomaly detection device, computer equipment and a storage medium. The embodiment of the application can be applied to various scenes such as cloud technology, artificial intelligence, intelligent traffic and the like. The method comprises the steps of inputting a training image into an initial image anomaly detection model to obtain a target prediction label, generating model feedback data based on a current mapping label corresponding to the training label of the training image and the target prediction label, generating label loss based on data change reference information corresponding to the model feedback data, adjusting the current mapping label based on the label loss to obtain an updated mapping label, taking the updated mapping label as the updated current mapping label, adjusting model parameters of the initial image anomaly detection model based on the model feedback data to obtain an updated initial image anomaly detection model, and returning to the step of inputting the training image into the initial image anomaly detection model until training is completed to obtain the target image anomaly detection model with high prediction accuracy.","['G06V10/774', 'G06V10/993', 'G06N3/04', 'G06N3/08', 'G06V10/764', 'G06V10/776', 'G06V10/82']"
US12138805B2,Machine learning of grasp poses in a cluttered environment,"Apparatuses, systems, and techniques to grasp objects with a robot. In at least one embodiment, a neural network is trained to determine a grasp pose of an object within a cluttered scene using a point cloud generated by a depth camera.","['B25J9/1671', 'B25J9/161', 'B25J9/1612', 'B25J9/1669', 'B25J9/1676', 'B25J9/1697', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06T7/55', 'G05B2219/39271', 'G05B2219/39536', 'G05B2219/40317', 'G05B2219/40323', 'G06N3/045', 'G06N3/049', 'G06N3/063', 'G06T2207/10028']"
US11321282B2,Blockchain cellular system,"A system includes a distributed ledger storing one or more smart contracts; one or more 5G small cells, each having one or more antennas mounted on a housing, each small cell sending packets of data trackable with the distributed ledger; and a processor to control a directionality of the antennas in communication with a predetermined target using 5G protocols.","['G06F16/1824', 'H04B7/0617', 'B64C39/024', 'G06N20/00', 'G06N3/02', 'G06Q20/02', 'G06Q20/3829', 'H04B7/0413', 'H04B7/0686', 'H04W16/28', 'H04W64/00', 'B64U10/30', 'B64U2101/10', 'B64U2101/20', 'B64U2201/102', 'G06Q2220/00', 'H04W64/003']"
US10916845B2,Blockchain cellular system,"A system includes a distributed ledger storing one or more smart contracts; one or more 5G small cells, each having one or more antennas mounted on a housing, each small cell sending packets of data trackable with the distributed ledger; and a processor to control a directionality of the antennas in communication with a predetermined target using 5G protocols.","['H01Q3/46', 'H04B17/318', 'F21S8/086', 'F21V23/045', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G10L25/51', 'H01Q1/04', 'H01Q1/246', 'H01Q1/44', 'H01Q19/09', 'H01Q21/28', 'H01Q3/20', 'H01Q3/44', 'H04B7/024', 'H04B7/0617', 'H04W16/02', 'H04W16/28', 'H04W24/02', 'H04W4/027', 'H04W4/40', 'H04W4/44', 'F21W2131/103', 'G06K9/00288', 'G06K9/00348', 'G06V40/172', 'G06V40/25', 'H04B17/309', 'H04L67/10', 'H04L67/12', 'H04W4/38', 'H04W4/70']"
CN112633277B,"Channel ship plate detection, positioning and recognition method based on deep learning","The invention relates to a channel ship plate detection, positioning and recognition method based on deep learning. The ship board detection, positioning and recognition method based on the deep learning semantic segmentation technology utilizes transfer learning so as to obtain reliable recognition accuracy on a small data set. And carrying out pixel-level classification on the ship board image based on an advanced EAST algorithm by utilizing a semantic segmentation method, so as to obtain an accurate and reliable ship board text line bounding box, and outputting accurate ship board text information by combining a CRNN text recognition algorithm. Aiming at the problems of high difficulty in ship plate identification, less research content and high specific application requirement, the invention realizes accurate ship plate detection and positioning, and overcomes the problems of complex image background, unfixed ship plate placement position and the like. The character sequence identification method realizes the character sequence identification of indefinite length, and solves the problems of large number of ship board characters, unfixed specific number and mixed Chinese character numbers.","['G06V20/63', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V10/267', 'G06V30/153', 'G06V30/10']"
US20220094713A1,Malicious message detection,"In a natural language processing model such as a Bidirectional Encoder Representations from Transformers (BERT) model, transformer layers can be replaced with simplified adapters without significant loss of predictive ability. This compressed model may in turn be trained to perform security classification tasks such as detection of new phishing attacks in electronic mail communications.","['H04L63/1483', 'H04L63/1425', 'G06F18/214', 'G06K9/6256', 'H04L63/1416', 'H04L63/145']"
US12194632B2,Robotic control system,"In at least one embodiment, under the control of a robotic control system, a gripper on a robot is positioned to grasp a 3-dimensional object. In at least one embodiment, the relative position of the object and the gripper is determined, at least in part, by using a camera mounted on the gripper.","['G05B13/027', 'B25J19/023', 'B25J9/161', 'B25J9/1612', 'B25J9/1669', 'B25J9/1697', 'G06N3/08', 'G06T7/74', 'G06T2207/30244']"
US11833681B2,Robotic control system,"In at least one embodiment, under the control of a robotic control system, a gripper on a robot is positioned to grasp a 3-dimensional object. In at least one embodiment, the relative position of the object and the gripper is determined, at least in part, by using a camera mounted on the gripper.","['G06T7/73', 'B25J9/161', 'B25J9/1612', 'B25J9/163', 'B25J9/1669', 'G06N3/006', 'G06N3/045', 'G06N3/049', 'G06N3/0499', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'G06T7/74', 'G05B2219/39543', 'G05B2219/40564', 'G06N3/044', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
CN112199608B,A social media rumor detection method based on network information dissemination graph modeling,"The invention discloses a social media rumor detection method based on network information propagation graph modeling, which comprises the following steps: establishing a propagation graph model according to the forwarding hierarchical relationship and the time dimension relationship of the posts by taking the posts of the user as nodes, and establishing post connection relationships of the same user in the propagation graph model according to ID information of the user; taking the text features of all posts extracted by the pre-training model as initial node representation features, and performing information aggregation according to the relation between the posts by using a message transfer graph neural network so as to update the node representation features; and after the updated node representation characteristics are connected with the initial node representation characteristics, predicting the probability of the post being rumor and non-rumor through a classifier. The method can improve the accuracy of rumor detection, realize effective rumor detection, and has the advantages of strong applicability, easy migration and the like.","['G06F16/9536', 'G06N3/045']"
CN111444709B,"Text classification method, device, storage medium and equipment","The application discloses a text classification method, a text classification device, a storage medium and a text classification device, and belongs to the technical field of artificial intelligence. The method comprises the following steps: acquiring a text to be processed; calling a target language model in the emotion analysis model to encode the text to be processed to obtain a feature vector sequence, wherein the target language model is a BERT model, and the feature vector sequence represents the context relationship between words in the text to be processed; vectorizing the determined target words to obtain target feature vectors; performing first feature fusion processing on the feature vector sequence and the target feature vector, and acquiring a second feature vector according to the obtained first feature vector and the feature vector sequence; performing second feature fusion processing on the second feature vector and the target feature vector; and predicting the emotion polarity of the target word in the text to be processed based on the obtained third feature vector. According to the method and the device, the emotion polarity of the target word in the text can be accurately predicted, and the target word can be accurately classified in the text.",[]
US11117262B2,Intelligent robots,"One embodiment can provide an intelligent robotic system. The intelligent robotic system can include at least one multi-axis robotic arm, at least one gripper attached to the multi-axis robotic arm for picking up a component, a machine vision system comprising at least a three-dimensional (3D) surfacing-imaging module for detecting 3D pose information associated with the component, and a control module configured to control movements of the multi-axis robotic arm and the gripper based on the detected 3D pose of the component.","['B25J9/1697', 'B25J13/006', 'B25J13/086', 'B25J17/0283', 'B25J19/023', 'B25J9/16', 'B25J9/161', 'B25J9/163', 'G01B11/2513', 'G06T2207/20084']"
US12223439B2,Visual-semantic representation learning via multi-modal contrastive training,"Systems and methods for multi-modal representation learning are described. One or more embodiments provide a visual representation learning system trained using machine learning techniques. For example, some embodiments of the visual representation learning system are trained using cross-modal training tasks including a combination of intra-modal and inter-modal similarity preservation objectives. In some examples, the training tasks are based on contrastive learning techniques.","['G06N5/04', 'G06F16/58', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T2207/00']"
CN111881958B,"License plate classification recognition method, device, equipment and storage medium","The invention relates to the field of logistics management and discloses a license plate classification and identification method, device and equipment and a storage medium. The method comprises the following steps: acquiring an image of a logistics vehicle device scene and classifying according to license plate colors to obtain a data set; training the built VGG19 model by utilizing the data set, and optimizing and adjusting the VGG19 model according to the cross entropy loss function and a preset gradient descent algorithm; inputting the data set into a VGG19 model for training to obtain a license plate classification recognition model; and inputting the vehicle images captured in real time into a license plate classification recognition model, and recognizing the images according to license plate colors. According to the license plate classification recognition model obtained through training, the license plate color information of the vehicle in the picture can be directly obtained through the picture, and the license plate is classified based on the license plate information, so that the original manual classification is replaced, and the license plate classification recognition efficiency is improved.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06V20/625', 'Y02T10/40']"
US20230282055A1,Low-cost apparatus and method for distributed remote collection of electronic devices for value,"A handheld-device imaging and collection apparatus, associated techniques and systems are described. An example apparatus may include a first container and a second container attached to each other. The first container includes a top panel arranged to enable acquiring a clear view of an inside of the first container, and one or more mirrors arranged facing inside of the first container, such that an image captured by a camera through the top panel captures reflections, in the one or more mirrors, of an handheld-device placed inside the first container. The second container includes a collection chamber configured to store the handheld-device.","['G07F7/06', 'A47G29/141', 'G03B15/00', 'G03B15/06', 'G06Q20/18', 'G06Q20/322', 'G06Q30/0278', 'H04N7/04', 'H04W4/12', 'A47G2029/145', 'A47G2029/149']"
US9158971B2,Self-learning object detectors for unlabeled videos using multi-task learning,A system and method enable generating a specific object detector for a category of interest. The method includes identifying seed objects in frames of a video sequence with a pre-trained generic detector for the category. An appearance model is iteratively learned for each of the seed objects using other frames in which the seed object is identified. The appearance models are learned jointly to optimize a loss function which accounts for the loss of incorrectly labeling sub-images and a regularization term which measures a distance between the appearance models. The loss of incorrectly labeling sub-images is determined using a motion model which predicts the location of the seed object in the subsequent frames so that sub-images outside the location that the current appearance model contribute to the loss. The specific object detector is then generated by aggregating the optimized appearance models.,"['G06K9/00711', 'G06F18/24', 'G06F18/2411', 'G06K9/4604', 'G06K9/6269', 'G06V20/40']"
US20250182217A1,Ai-augmented auditing platform including techniques for automated document processing,"Systems and methods for automated document processing for use in AI-augmented auditing platforms are provided. A system for determining the composition of document bundles extracts substantive content information and metadata information from a document bundle and generates, based on the extracted information regarding a composition of the document bundle. A system for validating signatures in documents extracts data representing a spatial location for respective signatures and generates a confidence level for respective signatures, and determines, based on location and confidence level, whether signature criteria are met. A system for extracting information from documents applies a set of data conversion processing steps to a plurality received documents to generate structured data, and then applies a set of knowledge-based modeling processing steps to the structured data to generating output data extracted from the plurality of electronic documents.","['G06F18/22', 'G06F16/3347', 'G06F16/353', 'G06F16/93', 'G06F18/29', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/096', 'G06N5/022', 'G06N5/041', 'G06N5/045', 'G06N5/048', 'G06N7/01', 'G06Q10/0635', 'G06Q30/018', 'G06Q40/12', 'G06V30/412', 'G06V30/416']"
US12322198B2,Text based image search,"Method and system for building a machine learning model for finding visual targets from text queries, the method comprising the steps of receiving a set of training data comprising text attribute labelled images, wherein each image has more than one text attribute label. Receiving a first vector space comprising a mapping of words, the mapping defining relationships between words. Generating a visual feature vector space by grouping images of the set of training data having similar attribute labels. Mapping each attribute label within the training data set on to the first vector space to form a second vector space. Fusing the visual feature vector space and the second vector space to form a third vector space. Generating a similarity matching model from the third vector space.","['G06N3/08', 'G06V30/413', 'G06N20/00', 'G06V10/454', 'G06V10/76']"
CN110969020B,"CNN and attention mechanism-based Chinese named entity identification method, system and medium","The invention discloses a Chinese named entity recognition method, a system and a medium based on CNN and attention mechanism, the method comprises the steps of introducing a target text sequence into K pre-trained Chinese named entity recognition CNN models to respectively obtain K head probability prediction sequences SP and tail probability prediction sequences EP, fusing the head probability prediction sequences SP and the tail probability prediction sequences EP, calculating a head label sequence S and a tail label sequence E according to a fusion result, and decoding by combining the target text sequence, the head label sequence S and the tail label sequence E by using a slice decoding method to obtain an entity set y corresponding to the target text sequence te . The method adapts to sequence tasks by modifying the traditional convolutional neural network CNN, can realize named entity recognition with stronger performance and higher calculation speed, has good performance on a plurality of data sets, and can realize quick and accurate recognition of named entities in Chinese texts.","['G06N3/045', 'G06N3/084']"
CN108920473B,Data enhancement machine translation method based on same-class word and synonym replacement,"The invention belongs to the technical field of natural language processing or conversion, and discloses a data enhancement machine translation method based on the replacement of similar words and synonyms, which utilizes the characteristic that word vectors can be clustered well finally to obtain a high-quality similar word list and a high-quality synonym list; constructing a similar word list and a synonym list by using word vectors obtained in the large language training process, and then replacing the similar words and the synonyms in the scarce small languages; and expanding parallel linguistic data of the Chinese, and training a neural network machine translation model of the Chinese by adopting a neural network with an encoding-decoding structure and an attention mechanism. Training data are expanded, parameters of the neural network translation model can be well learned in enough data, the problem of unknown words in neural machine translation can be solved, and translation quality of the translation model is improved. Network parameters have been well learned when the translation quality of the entire network on the development set no longer significantly improves.",['G06F40/58']
GB2594138A,Robotic control using deep learning,"A method of controlling one or more robotic devices, such as autonomous vehicles using neural networks, to perform a task. A first neural network determines information about environmental conditions relating to the task. Second neural network 206 and the information about the environmental conditions are used to help control the one or more robotic devices when carrying out the task. The information may include a logical state describing the environmental conditions. The second neural network may determine actions to help control the devices when carried out. The environmental conditions may include unexpected events. The neural networks may generate one or more loss values using which they are trained. The environmental conditions may be determined based on sensor data obtained by environmental sensors 214 such as cameras, navigation sensors, GPS sensors, RADAR sensors, LIDAR sensors, or inertial sensors.","['G06N3/049', 'G05B13/027', 'G05D1/0088', 'B60W60/001', 'G05D1/0221', 'G05D1/0246', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N5/04', 'B25J9/161']"
US20210304736A1,Media engagement through deep learning,"Apparatuses, systems, and techniques to facilitate understanding of media content using neural networks to adjust playback speed and volume based on environmental and other factors. In at least one embodiment, playback of media content is slowed down or sped up if audio associated with said media content is difficult to understand based on background noise, accent, difficulty of material, as well as other factors that decrease understandability of media content.","['G06F3/165', 'G06F40/30', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G10L21/0208', 'G10L25/30', 'G06F40/216', 'G10L15/16', 'G10L15/26', 'G10L21/04', 'H03G3/3005', 'H03G3/3089', 'H03G3/32', 'H04R2430/01', 'H04R2499/13']"
CN112085010B,Mask detection and deployment system and method based on image recognition,"The invention provides a mask detection and deployment system and method based on image recognition, belonging to the technical field of biological recognition and comprising the following steps: the data processing module is used for respectively collecting the face image and the mask image and respectively labeling the face image and the mask image; the model training module is used for training a face and mask detection model by using the labeled face image and mask image; the model reasoning module is used for detecting the positions of the face and the mask by using a non-maximum suppression algorithm according to the face and mask detection model; and the model deployment module is used for deploying the face mask detection model according to the detection result. The invention comprises the complete and unified flow of image data acquisition, data annotation, model training, model deployment and application integration, and the core multi-structure and multi-target detection model and the deployment characteristic of an automatic target platform reasoning engine can meet the requirements of different scenes, hardware configuration, detection precision and human flow.","['G06V40/171', 'G06F18/214', 'G06F18/40', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06V10/94', 'G06V40/161', 'G06V2201/07']"
CN112951000B,Large-scale vehicle blind area bidirectional early warning system,"The invention provides a large-scale vehicle blind area bidirectional early warning system, comprising: the front-end sensing module acquires images, videos and vehicle turning signals in a vehicle blind area setting range by using a sensor; the front-end analysis module identifies the barrier by using the AI model and tracks the movement track of the barrier; measuring the speed and the distance of the barrier, prejudging the movement track of the barrier, and transmitting a danger signal to a bidirectional early warning module to send out bidirectional early warning if the track of the barrier is judged to pass through the range of an inner wheel difference danger area; and the cloud management and control platform is used for storing and analyzing the data and the early warning events collected in the vehicle blind area to obtain an AI model and issuing a front-end analysis module of the edge side. The invention introduces the technical innovation of multi-sensor fusion, machine vision and the like in the field of unmanned driving into a blind area scene of a cart, summarizes and summarizes a universal installation scheme, improves the warning effect from two angles of a driver and an obstacle, prevents accidents and realizes a bidirectional early warning mechanism.","['G08G1/167', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/084', 'G06V10/25', 'G06V20/46', 'G06V20/58', 'H04L67/12', 'G06V2201/07', 'Y02T10/40']"
CN109242865B,"Medical image automatic partitioning system, method, device and storage medium based on multiple maps","The invention provides a method, a system and a device for automatically partitioning a medical image of multiple maps and a storage medium. The method includes at least one of the following operations. A sample image may be acquired, as well as an anatomical atlas of the sample image. An image partition network model may be obtained, which is a deep learning model. The image to be detected can be processed by the image partition network model with complete training, and the image partition result of the image to be detected is determined. The image to be detected can be processed by the image partition network model with complete training, and the image partition result of the image to be detected is determined. The deep convolution neural network is introduced into the automatic partitioning operation of the medical image with multiple maps, and the neural network trained by adopting multiple classes and multiple samples is good in robustness, short in partitioning time consumption and high in accuracy.","['G06T7/11', 'G06T7/136', 'G06T2207/20081', 'G06T2207/20084']"
US12087043B2,Leveraging unsupervised meta-learning to boost few-shot action recognition,"The disclosure herein describes preparing and using a cross-attention model for action recognition using pre-trained encoders and novel class fine-tuning. Training video data is transformed into augmented training video segments, which are used to train an appearance encoder and an action encoder. The appearance encoder is trained to encode video segments based on spatial semantics and the action encoder is trained to encode video segments based on spatio-temporal semantics. A set of hard-mined training episodes are generated using the trained encoders. The cross-attention module is then trained for action-appearance aligned classification using the hard-mined training episodes. Then, support video segments are obtained, wherein each support video segment is associated with video classes. The cross-attention module is fine-tuned using the obtained support video segments and the associated video classes. A query video segment is obtained and classified as a video class using the fine-tuned cross-attention module.","['G06V10/82', 'G06F16/73', 'G06F16/75', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/088', 'G06N3/096', 'G06V10/764', 'G06V10/7747', 'G06V10/7753', 'G06V10/778', 'G06V20/42', 'G06N3/084']"
US11687805B2,Systems and methods for self-learning artificial intelligence of things (AIOT) devices and services,"The invention is generally directed to systems and methods of monitoring or predicting a service event for an industrial asset using an artificial intelligence of things (AIoT) system including an AIoT device, AIoT cloud, and a self-learning AI classification and analytics engine. The device may include one or more sensors and an inference engine for reducing power consumption and detecting anomalies at the edge and sending data associated with anomalies to a signal processor for classification and AI-driven automatic configuration. Classification may be based on narrow-band analysis and/or machine learning models. If an anomaly is detected power may be provided to a communication module to send sensor data to the signal processor for classification and/or further processing. Classifications or determinations made by the signal processor or detected through a work-order system may be used to automatically retrain the inference model on the edge, so that the system is self-learning.","['H04L67/12', 'G06N5/04', 'G06N20/00', 'G16Y10/75', 'G16Y20/20', 'H04L67/10']"
CN110750959B,"Text information processing method, model training method and related device","The embodiment of the application provides a text information processing method, a model training method and a related device. The text sequence corresponding to the text information to be labeled is calculated through the sequence labeling model, if a target element exists in the text sequence, it is stated that a wrong word exists in the text information to be labeled, the wrong word can also be called as a first word, then a second word corresponding to the target element is determined, and finally the first word in the text information to be labeled is replaced by the second word, so that the replacement of the wrong word can be realized. Moreover, the second word needs to be determined according to the associated word bank and the word to be replaced, so that the replacement effect of the second word can be ensured, the first word cannot be replaced by other words which are not associated, and the situation that the sentence is not communicated is avoided.",['G06F18/214']
US10922957B2,Methods and systems for content processing,"Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved, and new functionality can be provided. Some aspects relate to visual search capabilities, and determining appropriate actions responsive to different image inputs. Others relate to processing of image data. Still others concern metadata generation, processing, and representation. Yet others concern user interface improvements. Other aspects relate to imaging architectures, in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions/data, to capture and later process imagery. Still other aspects relate to distribution of processing tasks between the mobile device and remote resources (“the cloud”). Elemental image processing (e.g., simple filtering and edge detection) can be performed on the mobile phone, while other operations can be referred out to remote service providers. The remote service providers can be selected using techniques such as reverse auctions, through which they compete for processing tasks. A great number of other features and arrangements are also detailed.","['G08C17/02', 'G06F16/29', 'G06F16/58', 'G06F16/5838', 'G06F16/5854', 'G06F16/587', 'G06F16/9535', 'G06F16/9537', 'G06F16/9554', 'G06F18/40', 'G06K9/00', 'G06V10/17', 'G06V10/24', 'G06V10/945', 'G06V20/10', 'H04L67/34', 'H04N1/00307', 'H04N23/611', 'G06F3/0482', 'G06T1/20', 'G08C2201/93', 'H04N2013/0074', 'H04N2101/00', 'H04N2201/3278', 'H04W88/02']"
CN111179223B,Defect detection method for industrial automation based on deep learning,"An industrial automation defect detection method based on deep learning. The invention relates to the technical field of product defect detection, which has higher accuracy and better generalization capability for realizing the avoidance of complex feature extraction work, can quickly train an applicable detection model under the conditions of smaller defect occupation and complex detection background, and obtains a detection method with better detection effect than the traditional detection method, and processes a shot photo by using a trained target detection model YOLO-V3 to judge whether an object to be detected exists in the photo; and identifying the shot photos by using a neural network topological structure acceptance-V3 image identification model obtained by small sample data migration learning deployed on the server, and judging whether the target positions contain defects. The invention is mainly applied to the detection occasion of the industrial production line.","['G06T7/0002', 'G06F18/23213', 'G06N3/08', 'G06T2207/20081', 'G06T2207/30108']"
CN112949572B,Mask wearing detection method based on Slim-YOLOv3,"The invention belongs to the technical field of deep learning target detection and computer vision, and particularly relates to a mask wearing condition detection method based on Slim-YOLOv3, which comprises the following steps: acquiring face video data in real time, and preprocessing the face video data; inputting the preprocessed face image into a trained Slim-YOLOv3 model, and judging whether the user wears the mask correctly; according to the method, the Slim-YOLOv 3-based mask wearing condition video detection method is adopted, and an improved unsupervised self-classification method is adopted to perform subclass classification on data which do not normally wear the mask, so that a mask wearing video detection task can be more accurately and rapidly realized. And the proposed network is more concise, so that the application cost is further reduced.","['G06V40/165', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06V40/171', 'G06V40/172']"
US9792397B1,System and method for designing system on chip (SoC) circuits through artificial intelligence and reinforcement learning,"The embodiments herein discloses a system and method for designing SoC using AI and Reinforcement Learning (RL) techniques. Reinforcement Learning is done either hierarchically in several steps or in a single-step comprising environment, tasks, agents and experiments, to have access to SoC (System on a Chip) related information. The AI agent is configured to learn from the interaction and plan the implementation of a SoC circuit design. Q values generated for each domain and sub domain are stored in a hierarchical SMDP structure in a form of SMDP Q table in a big data database. An optimal chip architecture corresponding to a maximum Q value of a top level in the SMDP Q table is acquired and stored in a database for learning and inference. Desired SoC configuration is optimized and generated based on the optimal chip architecture and the generated chip specific graph library.","['G06F17/505', 'G06F30/27', 'G06F30/327', 'G06F17/504', 'G06F30/32', 'G06F30/3323', 'G06F2115/02']"
CN110032648B,Medical record structured analysis method based on medical field entity,"The invention discloses a medical record structured analysis method based on medical field entities, which comprises the following steps: 1) constructing a medical entity and attribute category table and corresponding relation mapping for common medical record texts; 2) identifying the medical entity in the medical record text by adopting a Bert _ BilSTM _ CRF model; 3) segmenting medical record texts according to semantics to form events; 4) recombining the events; 5) constructing an attribute identification model, and extracting attributes in the segmented events; 6) connecting medical entities of events in the same sentence by using a knowledge graph to obtain the relationship between the entities; 7) and customizing different attribute identification models for different types of medical record text segments, and finally stacking the structured analysis results according to the text sequence to form a final medical record structured analysis text.","['G06F16/367', 'G06F40/30', 'G16H10/60']"
CN110110327B,A text annotation method and device based on adversarial learning,"The embodiment of the invention provides a text labeling method and equipment based on counterstudy, belonging to the technical field of natural language processing. The method comprises the following steps: the text labeling equipment performs labeling processing on a text to be labeled by using a character labeling model to generate a character labeling result containing labeling words; the text labeling equipment performs word segmentation processing on a text to be labeled through a preset word segmentation model to generate a word segmentation result containing word segmentation words; if the word segmentation result is determined to be credible according to the character labeling result, the text labeling equipment re-performs character labeling on the character labeling result based on the word segmentation result to obtain a fusion labeling result and outputs the fusion labeling result; and if the word segmentation result is determined to be not credible according to the character labeling result, the text labeling equipment outputs the character labeling result. By adopting the method and the device, the accuracy and the recall rate of the text marking can be improved.","['G06N20/00', 'G06F40/284', 'G06F40/295', 'G06V10/22', 'G06V10/82', 'G06V30/153', 'G06V30/287']"
US12333513B2,Low-cost computerized kiosks for remote collection of electronic devices for value,"An example kiosk for accepting a portable electronic device (PED) associated method and systems are described. The kiosk includes an upper container to evaluate the PED, a lower container to store the PED, a network interface to connect to a portable interaction control device, and a computer. The upper container includes at least one camera, and a plurality of mirrors arranged at one or more angles to enable capturing by the at least one camera, in one image, a top surface of the PED and reflected views of sides of the PED. The computer may, in response to an instruction received from a remote operator via the portable interaction control device control the at least one camera to capture the one image, and transmit, via the portable interaction control device, the captured one image to the remote operator.","['G06Q20/18', 'E05G1/06', 'G06Q20/322', 'G07F7/06', 'E05F2015/767', 'E05Y2400/814', 'E05Y2400/818', 'E05Y2400/8505', 'E05Y2400/8515', 'E05Y2400/852', 'E05Y2999/00', 'G03B15/12']"
US11610139B2,System and method for the latent space optimization of generative machine learning models,"A system and method for optimizing the latent space in generative machine learning models, and applications of the optimizations for use in the de novo generation of molecules for both ligand-based and pocket-based generation. The ligand-based optimizations comprise a tunable reward system based on a multi-property model and further define new measurable metrics: molecular novelty and uniqueness. The pocket-based optimizations comprise an initial multi-property optimization followed up by either a seed-based optimization or a relaxed-based optimization.","['G06N3/088', 'G06F16/951', 'G06F18/22', 'G06K9/6215', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N5/022', 'G06N7/01', 'G06V10/751', 'G06V10/82', 'G16B15/00', 'G16B15/30', 'G16B40/00', 'G16B40/20', 'G16B45/00', 'G16B50/10', 'G16C20/50', 'G16C20/70', 'G06N3/044', 'G06N3/048', 'G06N3/096', 'G16C20/30', 'G16C20/90']"
US11876782B2,Header-based packet filtering and inferencing to identify malicious network traffic using neural networks,"In various examples, a first network interface duplicates received network traffic and forwards a first set of network traffic data to a central processing unit (CPU) and a second set of identical network traffic to one or more parallel processing units (PPUs). In an embodiment, the one or more PPUs analyze the second set of network traffic to identify whether the second set of network traffic is malicious. First, the one or more PPUs filter and classify the second set of network traffic into flows, or logical groupings or subsets of the second set of network traffic. Second, the one or more PPUs sort the network packets within each flow and extract features of interest specific to each flow. Using the extracted features of interest, one or more deep learning techniques infer a status indicating whether each flow is malicious (mal) or good. The one or more PPUs then forward the status for each flow to the CPU for use in determining which network traffic from the first set of network traffic is to be forwarded to a second network interface.","['H04L63/0218', 'H04L63/0245', 'G06F21/567', 'G06N3/02', 'H04L63/1425']"
US12390926B2,Machine learning model for task and motion planning,"Apparatuses, systems, and techniques are described that solve task and motion planning problems. In at least one embodiment, a task and motion planning problem is modeled using a geometric scene graph that records positions and orientations of objects within a playfield, and a symbolic scene graph that represents states of objects within context of a task to be solved. In at least one embodiment, task planning is performed using symbolic scene graph, and motion planning is performed using a geometric scene graph.","['B25J9/1664', 'B25J9/161', 'B25J9/163', 'B25J9/1635', 'B25J9/1697', 'G06N20/00', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G05B2219/39311', 'G06N3/044', 'G06N3/045', 'G06N3/048']"
US20200394459A1,Cell image synthesis using one or more neural networks,"Apparatuses, systems, and techniques to generate synthesized images including digital representations of groups of cells blended realistically with appropriate background images. In at least one embodiment, background image data and gene expression data are fused together to generate such a synthesized image using one or more neural networks.","['G06T11/001', 'G06K9/6256', 'G06T7/11', 'G06F18/214', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06T7/0012', 'G06T7/194', 'G16B25/00', 'G16B40/00', 'G16B45/00', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30061', 'G06T2210/41']"
CN110728209B,"Gesture recognition method and device, electronic equipment and storage medium","The application relates to the technical field of computers, mainly to the technology of computer vision and machine learning in artificial intelligence, in particular to a gesture recognition method, a gesture recognition device, electronic equipment and a storage medium, and a human body image area in an image to be recognized is determined; estimating the human body posture in the human body image area to obtain a posture characteristic thermodynamic diagram corresponding to the human body image area; determining gesture scores of the human body image areas corresponding to preset gesture categories respectively according to the gesture feature thermodynamic diagrams; based on the gesture score, a human gesture recognition result in the human body image area is obtained, so that gesture recognition is performed by using a gesture feature thermodynamic diagram, and the gesture recognition accuracy can be improved.","['G06V40/20', 'G06F18/214', 'G06V10/25']"
US20240144489A1,Deep learning method for multiple object tracking from video,"A method for multi-object tracking from video. The method includes the following steps: (1) Capturing frames from the streaming source and preprocess the data; (2) Extract video features with three choices: a 3D-CNN backbone followed by a Transformer Encoder, a Video Transformer Encoder, a 2D-CNN Encoder with a stack of frames as input followed by a Transformer Encoder; (3) Multi-object tracking using a new end-to-end multi-task deep learning model named JDAT (Joint Detection Association Transformer), then post-processing and updating tracking state with Temporal Aggregation Module (TAM). The deep learning models in step 2 and step 3 are trained simultaneously end-to-end with a loss function that is accumulated over multiple timesteps (Collective Average Loss—CAL). Also, the model can be pretrained with weakly labeled image dataset in a self-supervised learning manner first, then finetuned on supervised video datasets with full tracking labels.","['G06T7/248', 'G06N3/045', 'G06T7/246', 'G06T7/292', 'G06V10/82', 'G06V20/46', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232']"
US11113812B2,Quantitative imaging for detecting vulnerable plaque,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06T7/0014', 'G06T7/0012', 'G16H10/00', 'G06T2207/10072', 'G06T2207/10116', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G06T2207/30101']"
US12026868B2,Quantitative imaging for detecting histopathologically defined plaque erosion non-invasively,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06T7/001', 'A61B6/504', 'A61B6/5217', 'A61B6/5247', 'G06F18/214', 'G06F18/24133', 'G06T11/008', 'G06T7/0014', 'G06V10/255', 'G06V10/56', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H70/60', 'G06T2207/10072', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30101', 'G06V10/95', 'G06V2201/03', 'G06V2201/031', 'G16H50/30', 'G16H50/70']"
US12008751B2,Quantitative imaging for detecting histopathologically defined plaque fissure non-invasively,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06T7/0012', 'G06T7/10', 'G16H30/40', 'G16H50/20', 'G16H70/60', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06T2207/30101']"
US11676359B2,Non-invasive quantitative imaging biomarkers of atherosclerotic plaque biology,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06V10/25', 'G06F18/211', 'G06F18/2148', 'G06F18/24', 'G06K9/6228', 'G06K9/6257', 'G06K9/6267', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N7/01', 'G06T3/00', 'G06T5/003', 'G06T5/73', 'G06T7/0012', 'G06T7/11', 'G06V10/764', 'G06V20/69', 'G06T2207/10048', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10101', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06T2207/30101', 'G06T2207/30104', 'G06V2201/03']"
CN111275518B,Video virtual fitting method and device based on mixed optical flow,"The invention discloses a video virtual try-on method and a device based on mixed optical flow, wherein the method comprises the following steps: step S1, acquiring a posture heat map according to a human body image, processing the human body image to obtain a human body segmentation image which only keeps the head and lower body areas, and generating a target human body semantic segmentation map under a target posture by the posture heat map, the human body segmentation image and a corresponding clothes image; step S2, respectively extracting a human body SMPL model from a human body image and a skeleton diagram representing human body posture, and calculating a 3D light flow diagram between the two SMPL models; step S3, predicting a clothes light flow graph between an example clothes image and a target clothes image by using a progressive correction network according to binary masks of the two images; and S4, synthesizing the current try-on video frame by utilizing the feature fusion network under the guidance of the 3D optical flow diagram and the clothes optical flow diagram according to the human body segmentation image, the clothes image, the target gesture heat diagram, the target human body semantic segmentation diagram and the last synthesized video frame.","['G06Q30/0621', 'G06F18/214', 'G06T7/11', 'G06V40/10', 'G06T2207/10021']"
US11696735B2,Quantitative imaging for instantaneous wave-free ratio,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06V10/82', 'G06T7/0012', 'A61B6/032', 'A61B6/463', 'A61B6/481', 'A61B6/504', 'A61B6/5217', 'A61B6/5294', 'G06F18/211', 'G06F18/24', 'G06F18/24143', 'G06K9/6228', 'G06K9/6267', 'G06K9/6274', 'G06T11/00', 'G06T11/001', 'G06T5/003', 'G06T5/73', 'G06T7/11', 'G06T7/60', 'G06V10/454', 'G06V10/457', 'G06V30/19173', 'G06V30/274', 'G16H50/30', 'A61B6/5258', 'G06F18/2148', 'G06K9/6257', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10101', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10132', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30096', 'G06T2207/30104', 'G06V2201/03']"
US11607179B2,Non-invasive risk stratification for atherosclerosis,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['A61B5/7267', 'A61B5/0022', 'A61B5/02007', 'A61B5/103', 'A61B5/7275', 'A61B5/743', 'A61B5/7485', 'A61B6/504', 'A61B6/5217', 'A61B6/5294', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T11/001', 'G06T11/60', 'G06T5/003', 'G06T5/20', 'G06T5/73', 'G06T7/0012', 'G16H10/60', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'A61B2576/00', 'A61B5/0037', 'A61B5/0066', 'A61B5/0075', 'A61B5/055', 'A61B5/1075', 'A61B5/145', 'A61B5/489', 'A61B6/032', 'A61B6/037', 'A61B6/481', 'A61B8/5223', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06T2207/30101']"
US11120312B2,Quantitative imaging for cancer subtype,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.","['G06K9/6296', 'G06V20/698', 'G06F18/29', 'G06K9/00147', 'G06V10/84', 'A61B6/032', 'A61B6/504']"
US20220068438A1,Deep learning and alignment of spatially-resolved whole transcriptomes of single cells,"The present invention provides for methods, systems and computer products for aligning single cell data with spatial data to generate spatial maps of cell types and gene expression at single cell resolution. The invention further provides for mapping to common coordinate frameworks.","['G16B40/30', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G16B45/00']"
US20250117473A1,Secure execution for multiple processor devices using trusted executing environments,"Apparatuses, systems, and techniques to generate a trusted execution environment including multiple accelerators. In at least one embodiment, a parallel processing unit (PPU), such as a graphics processing unit (GPU), operates in a secure execution mode including a protect memory region. Furthermore, in an embodiment, a cryptographic key is utilized to protect data during transmission between the accelerators.","['G06F21/53', 'G06F21/54', 'G06F21/602', 'G06F21/71', 'G06F21/79', 'G06F9/45558', 'G06F2009/45583', 'G06F2009/45587', 'G06F21/107']"
CN111243576B,"Speech recognition and model training method, apparatus, equipment and storage medium","The application relates to a method, a device, computer equipment and a storage medium for speech recognition and model training, which relate to artificial intelligence, wherein the method for training the speech recognition model comprises the following steps: acquiring first sample voice data corresponding to a target user and a first reference voice recognition result corresponding to the first sample voice data; acquiring a target model before updating; inputting the first sample voice data into a target model before updating so as to perform voice recognition by using a target voice extraction model, a target characteristic extraction model and a target voice recognition model to obtain a first model output result; obtaining a target model loss value corresponding to the target feature extraction model according to the first model output result and the first reference voice recognition result; and updating the model parameters of the target feature extraction model in the target model before updating according to the target model loss value to obtain the updated target model. The method can improve the voice recognition effect.","['G10L15/063', 'G10L15/183', 'G10L15/22', 'G10L15/02', 'G10L15/07', 'G10L15/16', 'G10L2015/025', 'G10L2015/0635']"
US20230148321A1,Method for artificial intelligence (ai) model selection,"Computational methods and systems for training Artificial Intelligence (AI) models with improved translatability or generalisability (robustness) comprises training a plurality of Artificial Intelligence (AI) models using a common validation dataset over a plurality of epochs. During training of each model, at least one confidence metric is calculated at one or more epochs, and, for each model, the best confidence metric value over the plurality of epochs, and the associated epoch number at the best confidence metric is stored. An AI model is then generated by selecting at least one of the plurality of trained AI models based on the stored best confidence metric and calculating a confidence metric for the selected at least one trained AI model applied to a blind test set. The resultant AI model is saved and deployed if the best confidence metric exceeds an acceptance threshold.","['G16H50/70', 'G06F18/217', 'G06F18/259', 'G06F18/285', 'G06N20/20', 'G06T7/0012', 'G16H40/67', 'G16H50/20', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N5/01', 'G06T2207/30044', 'G16H50/50']"
CN114638784B,A copper tube surface defect detection method and device based on FE-YOLO,"The invention discloses an FE-YOLO-based copper pipe surface defect detection algorithm and an FE-YOLO-based copper pipe surface defect detection device. Determining a priori anchor frame of a copper pipe surface defect data set by a K-means++ clustering method based on statistics, establishing a network structure of FE-YOLO, extracting a network part in backbone features, realizing the light weight of a model according to the light weight network characteristics, and enhancing the position correlation of spatial features by utilizing an improved feature pyramid in a neck feature fusion part; the boundary regression box loss function HIoU optimized by design is selected according to the research on the punishment items, so that the convergence of the model is accelerated, and the precision of the model is improved; finally, the FE-YOLO-based copper pipe surface defect detection model is obtained through training according to the copper pipe surface defect data set, so that the copper pipe surface defect can be detected efficiently and accurately, and the industrial surface defect can be detected rapidly and accurately from end to end.","['G06T7/0004', 'G01N21/8851', 'G01N21/952', 'G06F18/23213', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T7/73', 'G01N2021/8887', 'Y02P90/30']"
US11144889B2,Automatic assessment of damage and repair costs in vehicles,"A system and method are provided for automatically estimating a repair cost for a vehicle. A method includes: receiving, at a server computing device over an electronic network, one or more images of a damaged vehicle from a client computing device; performing image processing operations on each of the one or more images to detect external damage to a first set of parts of the vehicle; inferring internal damage to a second set of parts of the vehicle based on the detected external damage; and, calculating an estimated repair cost for the vehicle based on the detected external damage and inferred internal damage based on accessing a parts database that includes repair and labor costs for each part in the first and second sets of parts.","['G06Q10/20', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N5/003', 'G06N5/01', 'G06N7/005', 'G06N7/01', 'G06Q30/0283', 'G06Q40/08', 'G06T19/20', 'G06T7/0004', 'G06T7/001', 'G06T7/33', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/30136', 'G06T2207/30252', 'G06T2219/2008']"
WO2021174757A1,"Method and apparatus for recognizing emotion in voice, electronic device and computer-readable storage medium","The present application relates to the technical field of artificial intelligence and relates to a method and apparatus for recognizing the emotion in a voice, an electronic device and a computer-readable storage medium. The method comprises: when a user voice is received, extracting multiple types of audio features of the user voice; matching the audio features with feature samples in an emotion feature library, and obtaining an emotion tag corresponding to a feature sample that matches each audio feature; constructing a feature tag matrix of the user voice on the basis of the audio features and the emotion tags corresponding to the matched feature samples; inputting the feature tag matrix into a multi-emotion recognition model, and obtaining a plurality of emotion sets and scene tags corresponding to the emotion sets; and acquiring a scene tag that matches the voice scene of the user voice so as to determine the emotion set corresponding to the matched scene tag as a recognized emotion in the user voice. According to the present application, various potential emotions can be efficiently and accurately recognized from a voice.","['G10L25/63', 'G10L25/03']"
EP3745318A1,Training a neural network using selective weight updates,"Training one or more neural networks using selective updates to weight information of the one or more neural networks. In at least one embodiment, one or more neural networks are trained by at least updating one or more portions of weight information of the one or more neural networks based, at least in part, on metadata that indicate how recently the one or more portions of weight information has been updated.","['G06F18/23213', 'G06N3/0495', 'G06N3/0499', 'G06N3/06', 'G06N3/084', 'G06N3/086', 'G06N3/09', 'G06F18/24', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06T2207/20081', 'G06T2207/20084', 'G10L15/16']"
CN110059558B,A Real-time Detection Method of Orchard Obstacles Based on Improved SSD Network,"The invention discloses an improved SSD-based real-time detection method for orchard obstacles, which is characterized in that an improved SSD deep learning target detection method is used for identifying the obstacles in an orchard environment, a lightweight network MobileNet V2 is used as a basic network in an SSD model to reduce time and operand spent in the process of extracting image features, an auxiliary layer is used for carrying out position prediction by combining a reverse residual structure with cavity convolution as a basic structure, so that the multi-scale features can be synthesized, information loss caused by downsampling operation is avoided, a corresponding SSD target detection model after image data set training is used, images acquired by a camera are input into the trained model to detect target positions, and the problems that the traditional obstacle detection algorithm is easy to be affected by background interference, the positioning of the obstacle positions is inaccurate, and the detection of various obstacle categories is difficult to realize simultaneously are solved.","['G06F18/214', 'G06F18/24', 'G06V20/58', 'G06V2201/07']"
US11741365B2,Generalizable and interpretable deep learning framework for predicting MSI from histopathology slide images,"A generalizable and interpretable deep learning model for predicting microsatellite instability from histopathology slide images is provided. Microsatellite instability (MSI) is an important genomic phenotype that can direct clinical treatment decisions, especially in the context of cancer immunotherapies. A deep learning framework is provided to predict MSI from histopathology images, to improve the generalizability of the predictive model using adversarial training to new domains, such as on new data sources or tumor types, and to provide techniques to visually interpret the topological and morphological features that influence the MSI predictions.","['G06N3/084', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/02', 'G06T7/0012', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
CN108364280B,Method and equipment for automatically describing structural crack and accurately measuring width,"The invention discloses a method and equipment for automatically describing a structural crack and accurately measuring the width of the structural crack, wherein the method comprises a crack automatic describing method and a crack width calculating method based on a single-pixel framework and a Zernike orthogonal moment, the crack automatic describing method is used for rapidly and accurately describing the crack on the surface of a structure, and the crack width calculating method based on the crack framework and the Zernike orthogonal moment is used for calculating the crack widths of a wide crack and a fine crack in an image in real time. Its equipment will test and analysis function and combine together, mainly include image calibration module, image acquisition module, image processing module, and this equipment can realize the automatic detection of structure surface crack, contains: (1) high-precision and automatic drawing of cracks on the surface of the structure; (2) the method and the device disclosed by the invention can be widely applied to regular detection of structural appearance cracks and structural laboratory crack observation.","['G06T7/136', 'G01B11/022', 'G01N33/383', 'G06T11/00', 'G06T5/20', 'G06T5/70', 'G06T7/0002', 'G06T7/0004', 'G06T7/12', 'G06T7/13', 'G06T7/155', 'G06T7/181', 'G06T7/60', 'G06T7/62', 'G06T7/70', 'G06T7/80', 'G06T2207/10004', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20032', 'G06T2207/20044', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/30132', 'G06T2207/30204', 'G06T2207/30244']"
CN110588653B,"Control system, control method and controller for autonomous vehicle","A control system and method for an Autonomous Vehicle (AV) is provided. A scene understanding module of the advanced controller selects a particular combination of sensorimotor primitive modules to enable and execute for a particular driving scene from among a plurality of sensorimotor primitive modules. Each of the particular combinations of sensorimotor primitive modules handles one of the subtask sequences that handles a particular driving scenario. The primitive processor modules execute a particular combination of sensorimotor primitive modules such that each primitive processor module generates a vehicle trajectory and speed profile. The arbitration module selects one of the vehicle trajectory and speed profile having the highest execution priority ranking, and the vehicle control module processes the selected one of the vehicle trajectory and speed profile to generate control signals for executing one or more control actions to automatically control the autonomous vehicle.","['B60W50/0097', 'G05D1/0088', 'B60W10/06', 'B60W10/18', 'B60W10/20', 'B60W30/18', 'B60W40/00', 'B60W50/08', 'B60W60/001', 'G05D1/0223', 'G05D1/0274', 'G05D1/0278', 'G06V10/82', 'G06V20/56', 'B60W2556/50', 'B60W2710/0605', 'B60W2710/18', 'B60W2710/20', 'B60W2720/103']"
CN110531753B,"Control system, control method and controller for autonomous vehicle","Systems and methods for controlling an Autonomous Vehicle (AV) are provided. The map generator module processes the sensor data to generate a world representation of a Particular Driving Scenario (PDS). A Scene Understanding Module (SUM) processes the navigation routing data, location information and feature maps to define an Autonomous Driving Task (ADT), and breaks the ADT into a series of subtasks. The SUM selects a particular combination of sensory-motor primitive modules (SPMs) to be enabled and executed for the PDS. Each SPM processes one subtask in the sequence. The primitive processor module executes the particular combination of SPMs such that each of the SPMs generates a vehicle trajectory and Velocity (VTS) curve. The selected one of the VTS curves is then processed to generate a control signal, which is then processed by the low-level controller to generate commands to control one or more actuators of the AV.","['G05D1/021', 'G05D1/0223', 'B60W50/14', 'B60W60/001', 'G01C21/20', 'G05D1/0212', 'G05D1/0221', 'G05D1/0231', 'G05D1/0257', 'B60W2050/146', 'B60W2420/403', 'B60W2554/402', 'B60W2554/4042', 'B60W2554/806', 'B60W2556/40', 'B60W2556/50', 'G01C21/28']"
US11291919B2,Development of virtual character in a learning game,"Technologies for executing a virtual character development application using machine learning are described herein. In typical simulation applications, a user may be enabled to create a virtual character and navigate a virtual world. A typical simulation application may accept inputs from the user, determine actions initiated by the user based on the inputs, determine subsequent outcomes of the user-initiated actions, and mold the simulation according to the outcomes. However, most outcomes may be predetermined and predictable by design. In contrast, some embodiments may include a server configured to execute a virtual character development application in conjunction with one or more client devices. A user may utilize a client device to create and develop a virtual character within the application. The user may be enabled to provide inputs to the virtual character development application, and the artificial component may process the input and extract information associated with the virtual character.","['A63F13/355', 'A63F13/825', 'A63F13/211', 'A63F13/213', 'A63F13/2145', 'A63F13/215', 'A63F13/424', 'A63F13/58', 'A63F13/63', 'A63F13/655', 'A63F13/67', 'A63F13/822', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/04', 'G06T19/003', 'G06T19/006', 'A63F2300/65', 'A63F2300/8082']"
US20210357835A1,Resource Deployment Predictions Using Machine Learning,"Embodiments are generally directed to systems and methods for generating resource deployment predictions using an ensemble machine learning model. An ensemble machine learning model trained or configured by an aggregated data set can be provided, where the aggregated data set includes data about resources deployed in enterprise deployment scenarios aggregated from a plurality of enterprise sources. Data about a first resource can be received including natural language data and numeric score data. A matching score between the first resource and a first enterprise deployment scenario can be determined based on a matching between natural language data descriptive of the first resource and natural language data descriptive of the first enterprise deployment scenario. Resource deployment parameters can be predicted using the ensemble machine learning model based on the determined matching score and the received numeric score data about the first resource.","['G06Q10/06315', 'G06F16/26', 'G06F40/194', 'G06F40/216', 'G06F40/284', 'G06F40/30', 'G06F40/40', 'G06N20/20', 'G06N5/04', 'G06Q10/105', 'G06Q30/018']"
WO2020108358A1,"Image inpainting method and apparatus, computer device, and storage medium","Disclosed in embodiments of the present application are an image inpainting method and apparatus, and a storage medium. According to the embodiments of the present application, after an image to be inpainted is obtained, an area to be inpainted and a non-inpainting area are determined from the image; feature extraction is performed on the non-inpainting area on the basis of different receptive fields and spatial resolutions, then textures of the area to be inpainted are generated according to the extracted feature information of multiple scales, and the area to be inpainted in the image is filled with the generated textures to obtain an inpainted image.","['G06T3/4053', 'G06T5/00', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06T11/40', 'G06T3/4007', 'G06T5/60', 'G06T5/77', 'G06V10/764', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104']"
US20220161815A1,Autonomous vehicle system,"According to one embodiment, an apparatus includes an interface to receive sensor data from a plurality of sensors of an autonomous vehicle. The apparatus also includes processing circuitry to apply a sensor abstraction process to the sensor data to produce abstracted scene data, and to use the abstracted scene data in a perception phase of a control process for the autonomous vehicle. The sensor abstraction process may include one or more of: applying a Sensor data response normalization process to the sensor data, applying a warp process to the sensor data, and applying a filtering process to the sensor data.","['B60W60/001', 'G06N20/00', 'B60W30/182', 'B60W40/02', 'B60W40/04', 'B60W40/08', 'B60W40/09', 'B60W40/10', 'B60W50/00', 'B60W50/0097', 'B60W50/0098', 'B60W50/14', 'B60W50/16', 'B60W60/00', 'B60W60/0011', 'B60W60/0013', 'B60W60/00274', 'B60W60/0053', 'B60W60/0057', 'G05D1/00', 'G05D1/0038', 'G05D1/0061', 'G05D1/02', 'G05D1/0282', 'G06N7/01', 'G06T1/0007', 'G06T9/00', 'G08G1/0112', 'G08G1/0116', 'G08G1/0129', 'G08G1/0141', 'G08G1/09626', 'G08G1/096725', 'G08G1/096741', 'G08G1/09675', 'G08G1/096758', 'G08G1/096775', 'G08G1/096783', 'G08G1/162', 'G08G1/163', 'G08G1/166', 'G08G1/167', 'H04L9/3213', 'H04W4/40', 'H04W4/46', 'B60W2050/0052', 'B60W2050/0064', 'B60W2050/0075', 'B60W2050/0083', 'B60W2050/143', 'B60W2050/146', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2540/043', 'B60W2540/047', 'B60W2540/215', 'B60W2540/22', 'B60W2540/221', 'B60W2540/223', 'B60W2540/30', 'B60W2554/4046', 'B60W2556/35', 'B60W2556/45', 'B60W2556/50', 'B60W2556/65', 'G06N3/006', 'G06N3/045', 'G06N3/049', 'G06N3/08']"
US20240095077A1,Prompt generator for use with one or more machine learning processes,"Apparatuses, systems, and techniques to generate a prompt for one or more machine learning processes. In at least one embodiment, the machine learning process(es) generate(s) a plan to perform a task (identified in the prompt) that is to be performed by an agent (real world or virtual).","['G06N3/006', 'G06F9/5027', 'G06N20/00', 'G06N3/0455', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G06N5/045', 'G06F16/245', 'G06N3/044', 'G06N3/0464', 'G06N3/0895']"
US12333688B2,Denoising diffusion generative adversarial networks,"Apparatuses, systems, and techniques are presented to train and utilize one or more neural networks. A denoising diffusion generative adversarial network (denoising diffusion GAN) reduces a number of denoising steps during a reverse process. The denoising diffusion GAN does not assume a Gaussian distribution for large steps of the denoising process and applies a multi-model model to permit denoising with fewer steps. Systems and methods further minimize a divergence between a diffused real data distribution and a diffused generator distribution over several timesteps. Accordingly, various embodiments may enable faster sample generation, in which the samples are generated from noise using the denoising diffusion GAN.","['G06T5/70', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
US11954761B2,Neural network for generating synthetic medical images,"Systems, computer-implemented methods, and computer readable media for generating a synthetic image of an anatomical portion based on an origin image of the anatomical portion acquired by an imaging device using a first imaging modality are disclosed. These systems may be configured to receive the origin image of the anatomical portion acquired by the imaging device using the first imaging modality, receive a convolutional neural network model trained for predicting the synthetic image based on the origin image, and convert the origin image to the synthetic image through the convolutional neural network model. The synthetic image may resemble an imaging of the anatomical portion using a second imaging modality differing from the first imaging modality.","['A61N5/1039', 'A61B5/0035', 'G06T11/00', 'G06T11/008', 'A61B5/055', 'A61B5/7267', 'G01R33/4812', 'G01R33/5608', 'G06F18/214', 'G06N3/045', 'G06T5/50', 'A61B5/7264', 'A61B6/032', 'A61B6/037', 'A61B8/00', 'G01R33/481', 'G01R33/4814', 'G06T2207/20221', 'Y02A90/10']"
CN110020647B,Contraband target detection method and device and computer equipment,"The embodiment of the invention provides a contraband target detection method, a contraband target detection device and computer equipment, wherein the method comprises the following steps: enhancing designated features in an X-ray image to be detected by a plurality of preset image enhancement methods to obtain a plurality of enhanced images; detecting each enhanced image by using a preset target detection method, judging whether a contraband target to be determined exists in each enhanced image, and determining the position information of the area where the contraband target to be determined is located; if the counted number of the enhanced images with the contraband target to be determined reaches a preset threshold value, extracting an interested area image corresponding to the position information from the X-ray image to be detected; acquiring and determining the substance type of a contraband target to be determined according to the attribute characteristics of the image of the region of interest; and if the substance type accords with the preset substance type, determining the detected contraband object to be determined as the determined contraband object. By the scheme, the missing rate and the false rate of the contraband target detection can be reduced.","['G06F18/214', 'G06T5/90', 'G06V10/25', 'G06T2207/10116']"
US11586930B2,Conditional teacher-student learning for model training,"Embodiments are associated with conditional teacher-student model training. A trained teacher model configured to perform a task may be accessed and an untrained student model may be created. A model training platform may provide training data labeled with ground truths to the teacher model to produce teacher posteriors representing the training data. When it is determined that a teacher posterior matches the associated ground truth label, the platform may conditionally use the teacher posterior to train the student model. When it is determined that a teacher posterior does not match the associated ground truth label, the platform may conditionally use the ground truth label to train the student model. The models might be associated with, for example, automatic speech recognition (e.g., in connection with domain adaptation and/or speaker adaptation).","['G10L15/063', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G10L15/16', 'G10L15/183', 'G06N3/044', 'G10L15/065', 'G10L15/07']"
US11922124B2,"Method, apparatus and computer program product for generating multi-paradigm feature representations","Methods, apparatus, systems, computing devices, computing entities, and/or the like for programmatically generating multi-paradigm feature representations are provided. An example method may include generating a code dataset including a plurality of codes associated with a predictive entity; generating a plurality of semantic feature vectors based at least in part on code description metadata; generating a plurality of structural feature vectors based at least in part on code relation metadata; generating a plurality of multi-paradigm feature vectors based at least in part on the plurality of semantic feature vectors and the plurality of structural feature vectors; generating a prediction for the predictive entity by processing the plurality of multi-paradigm feature vectors using a prediction model; and performing one or more prediction-based actions based on the prediction.","['G06F40/30', 'G06F16/38', 'G06F16/9024', 'G06F17/16', 'G06F40/20', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G16H40/20', 'G06N5/022']"
US20220383102A1,Wildfire ignition prediction with swarm neural network ensemble,"Various embodiments analyze the application of satellite imaging and deep learning in predicting ignition and spread of major wildfires. The training data comes from NASA satellite products and historical records of wildfires in the United States. A state-of-the-art technique in neural network image classification may be utilized and yield impressive results for wildfire ignition prediction. In one embodiment, the model may achieve an accuracy rate of 93.5%, a precision rate of 93.2%, a recall rate of 88.9%, and an F-1 score of 90.8%. Direct applications of the model may include wildfire monitoring and wildfire prevention.","['G06N3/045', 'G06N3/08', 'G06N3/006', 'G06N3/044', 'G06N3/0464', 'G06N3/048']"
US11615879B2,System and method for automated labeling and annotating unstructured medical datasets,"Supervised and unsupervised learning schemes may be used to automatically label medical images for use in deep learning applications. Large labeled datasets may be generated from a small initial training set using an iterative snowball sampling scheme. A machine learning powered automatic organ classifier for imaging datasets, such as CT datasets, with a deep convolutional neural network (CNN) followed by an organ dose calculation is also provided. This technique can be used for patient-specific organ dose estimation since the locations and sizes of organs for each patient can be calculated independently.","['G06V10/454', 'G06F18/2148', 'G06F18/2155', 'G06F18/217', 'G06F18/2415', 'G06F18/2431', 'G06K9/6257', 'G06K9/6259', 'G06K9/6262', 'G06K9/6277', 'G06K9/628', 'G06N3/084', 'G06N7/005', 'G06N7/01', 'G06V10/42', 'G06V10/751', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G16H15/00', 'G16H20/40', 'G16H30/40', 'G06V2201/031']"
CN112083482B,Seismic super-resolution inversion method based on model-driven depth learning,"The invention discloses a seismic super-resolution inversion method based on model-driven depth learning, which comprises the following steps of: 1) mapping each iteration in the model-driven alternative direction multiplier method ADMM to each layer in the depth network, and learning the near-end mapping by using a mathematic driving method to complete the construction of the depth network ADMM-SRINet; 2) acquiring label data for training a deep network ADMM-SRINet; 3) training the deep network ADMM-SRINet by using the acquired label data; 4) and 3) inverting the data to be measured by using the deep network ADMM-SRINet trained in the step 3). The method combines the advantages of an optimization method based on model driving and a deep learning method based on data driving, so that the network structure has interpretability; meanwhile, due to the increase of physical knowledge, the requirement on a training set is reduced by the iterative deep learning method, so that the inversion result is more reliable.","['G01V1/282', 'G01V1/36', 'G01V1/364', 'G01V2210/20', 'G01V2210/32', 'G01V2210/50', 'G01V2210/665']"
US20230329159A1,Internet-of-things management and control system for intelligent orchard,"An Internet-of-Things management and control system for an intelligent orchard includes a server, agricultural machinery equipment, an image acquisition apparatus disposed on the site, and various sensors. The agricultural machinery equipment, the image acquisition apparatus and the various sensors are in communication connection with the server. The server includes an orchard management subsystem and an information monitoring subsystem. The orchard management subsystem includes a fruit tree planting planning module, a task management module and various information management modules, and the information monitoring subsystem includes a meteorological environment monitoring module, a soil moisture monitoring module and a disease and pest monitoring module. According to the Internet-of-Things management and control system, all-round management for an orchard from planning to picking can be achieved.","['G05B19/048', 'A01G17/005', 'A01G17/00', 'G06Q50/02', 'G16Y10/05', 'G16Y40/35', 'Y02A40/10']"
CN110222759B,Automatic identification system for vulnerable plaque of coronary artery,"The invention relates to an automatic identification system of vulnerable plaque of coronary artery, which is realized based on a convolution neural network, namely CCTA data is deeply mined through an artificial intelligent convolution neural network technology, potential quantitative characteristic information of the vulnerable plaque is automatically extracted, and a vulnerable plaque high-precision identification system is established, so that the detection rate of a non-invasive means to the vulnerable plaque can be obviously improved, the dependence of vulnerable plaque characteristic interpretation on doctor experience and the limitation of human eyes on pixel identification are solved, and the workload of imaging doctors on judging a large number of images is reduced.","['G06F18/241', 'G06N3/045', 'G06T7/0012', 'G06T2207/10081', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/30101', 'G06V2201/03']"
WO2020186886A1,Method and device for generating face recognition model,"The present application is applicable in the technical field of image processing, and provided therein are a method and device for generating a face recognition model, comprising: acquiring a corresponding face image of a training object in each preset modality; extracting a first depth feature vector of a first face image by means of a preset first convolutional neural network; extracting a second depth feature vector of a second face image by means of a preset second convolutional neural network and a residual compensation model to be adjusted regarding a sub-modality; and adjusting the residual compensation model on the basis of the first depth feature vector and the second depth feature vector corresponding to a plurality of training objects, and generating a face recognition model according to the adjusted residual compensation model, the first convolutional neural network and the second convolutional neural network. In the present application, a face recognition model is generated by means of inputting face information of a training object, which may improve the accuracy of face recognition under a plurality of modalities and reduce labor costs.","['G06F18/214', 'G06F18/2411', 'G06N3/045', 'G06N3/08', 'G06V40/172']"
CN109886141B,A Pedestrian Re-Identification Method Based on Uncertainty Optimization,"The invention relates to the field of computer vision, and adopts a deep learning framework, in particular to a pedestrian re-identification method based on uncertainty optimization, which comprises the following steps: 1) Using a twin network structure, and taking two original images belonging to the same or different pedestrians as the input of two isomorphic networks respectively; 2) The method comprises the steps of using a Bayesian convolutional neural network with uncertainty optimization as a feature extraction network by using an acceptance network and Dropout layer superposition mode; 3) According to the characteristic output of the twin network, calculating the classification loss and the multi-classification loss of each network, and using the superimposed network for the back propagation and parameter optimization of the network; 4) Inputting the pedestrian image to be identified and all comparison images into a trained model, and extracting image features; 5) Acquiring a final distance between the pedestrian image to be identified and the comparison image by using a Euclidean distance calculation formula; 6) And sorting according to the feature similarity distance, and obtaining the matching sorting of the comparison images corresponding to the pedestrians to be identified. Compared with the prior art, the method has the advantages of high accuracy, high robustness, rapidness, simplicity and convenience and the like under all samples and few samples.",['Y02T10/40']
CN110378909B,Single wood segmentation method for laser point cloud based on Faster R-CNN,"The invention discloses a single-wood segmentation method facing laser point cloud based on fast R-CNN, which comprises the steps of obtaining forest stand point cloud data; calculating the point cloud characteristics of the scanned forest stand to realize branch-leaf separation of the forest stand point cloud data; performing self-adaptive voxelization operation on the main point cloud data of the forest stand, and performing multi-angle projection on the main point cloud data to generate a corresponding depth image; detecting a trunk in the generated depth image by adopting a deep learning method; and obtaining the space three-dimensional point cloud of the corresponding trunk by back projection by utilizing the detected position information of the trunk in the depth image. And taking the obtained point cloud of the trunk part as a seed point, and combining a region growing algorithm to realize single wood separation. The invention adopts a deep learning method, learns by means of big data samples, has higher single tree segmentation accuracy, and provides possibility for accurately solving the single rubber tree segmentation problem of LiDAR data based on the ground by using the deep learning.","['G06N3/045', 'G06T7/11', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/30188', 'Y02A90/10']"
EP3926525A1,"Virtual image behavior control method and device based on text, and medium","Disclosed are a virtual image behavior control method and device based on text, and a medium. The method comprises: inserting a specific symbol into text, and generating a plurality of input vectors corresponding to the specific symbol and all elements in the text; respectively inputting the plurality of input vectors into a first coding network, and determining a behavior trigger position in the text on the basis of an attention vector of a network node corresponding to the specific symbol; determining behavior content on the basis of a first coding vector corresponding to the specific symbol that is output by the first coding network; and playing audio corresponding to the text, and controlling a virtual image to present the behavior content when the playing reaches the behavior trigger position.","['G06F18/241', 'G06V30/19173', 'G06F18/2415', 'G06F3/011', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/09', 'G06V30/40', 'G06F2203/011', 'G06V30/43']"
US20190361454A1,"Control systems, control methods and controllers for an autonomous vehicle","Systems and methods are provided for controlling an autonomous vehicle (AV). A feature map generator module generates a feature map (FM). Based on the FM, a perception map generator module generates a perception map (PM). A scene understanding module selects from a plurality of sensorimotor primitive modules (SPMs), based on the FM, a particular combination of SPMs to be enabled and executed for the particular driving scenario (PDS). Each SPM maps information from either the FM or the PM to a vehicle trajectory and speed profile (VTSP) for automatically controlling the AV to cause the AV to perform a specific driving maneuver. Each one of the particular combination of the SPMs addresses a sub-task in a sequence of sub-tasks that address the PDS. Each of the particular combination of the SPMs are retrieved from memory and executed to generate a corresponding VTSP.","['G05D1/0221', 'B60W50/0098', 'B60W50/14', 'B60W60/001', 'G05D1/0214', 'G05D1/0219', 'G05D1/0223', 'G05D1/0236', 'G05D1/024', 'G05D1/0251', 'G05D1/0255', 'G05D1/0257', 'G05D1/0259', 'G05D1/0274', 'G05D1/0278', 'G05D1/0285', 'B60W2050/0004', 'B60W2050/146', 'B60W2420/403', 'B60W2556/40', 'B60W2556/50']"
CN110111399B,Image text generation method based on visual attention,"The invention relates to an image text generation method based on visual attention, which comprises the following steps of S1: inputting a training sample image, and acquiring a regional feature vector and a regional space feature vector of the training sample image; step S2: preprocessing the labeling text of the training sample image, constructing a vocabulary library, and encoding words in the vocabulary library to obtain word vectors of each word; step S3: inputting the regional feature vector, regional spatial feature vector and word vector of the training sample image into an image semantic understanding model based on a bidirectional LSTM visual attention network to obtain a training image text; step S4: optimizing and training the image semantic understanding model through a back propagation algorithm to obtain an optimal model; step S5: and inputting the test image into the optimal model to obtain a test image text. Compared with the prior art, the invention can combine historical information and future information, and correct the error area concerned before to a certain extent.","['G06F40/30', 'G06N3/045', 'G06N3/049', 'G06T11/60', 'G06V20/20', 'Y02T10/40']"
US11556749B2,Domain adaptation and fusion using weakly supervised target-irrelevant data,Aspects include receiving a request to perform an image classification task in a target domain. The image classification task includes identifying a feature in images in the target domain. Classification information related to the feature is transferred from a source domain to the target domain. The transferring includes receiving a plurality of pairs of task-irrelevant images that each includes a task-irrelevant image in the source domain and in the target domain. The task-irrelevant image in the source domain has a fixed correspondence to the task-irrelevant image in the target domain. A target neural network is trained to perform the image classification task in the target domain. The training is based on the plurality of pairs of task-irrelevant images. The image classification task is performed in the target domain and includes applying the target neural network to an image in the target domain and outputting an identified feature.,"['G06N3/08', 'G06K9/6292', 'G06F18/2148', 'G06F18/2414', 'G06F18/25', 'G06F18/254', 'G06K9/6257', 'G06K9/6273', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/7747', 'G06V10/80', 'G06V10/809', 'G06V10/82']"
US11798183B2,Machine learning techniques for predicting depth information in image data,"Apparatuses, systems, and techniques to estimate or predict depth information for image data. In at least one embodiment, depth information is predicted based at least in part on color information and geometry information associated with an image.","['G06T7/521', 'G06T7/50', 'G05D1/0214', 'G05D1/0221', 'G05D1/0251', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06T15/06', 'G06T5/77', 'G06T7/0012', 'G06T7/55', 'G06T7/593', 'G06T7/90', 'G05D2201/0213', 'G06T2207/10016', 'G06T2207/10021', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30252', 'G06T2207/30256', 'G06T2210/21']"
WO2021222136A1,Model predictive control techniques for autonomous systems,"Apparatuses, systems, and techniques to infer a sequence of actions to perform using one or more neural networks trained, at least in part, by optimizing a probability distribution function using a cost function, wherein the probability distribution represents different sequences of actions that can be performed. In at least one embodiment, a model predictive control problem is formulated as a Bayesian inference task to infer a set of solutions.","['G06N3/084', 'G06N3/006', 'G05D1/0088', 'G06F17/18', 'G06F18/214', 'G06N3/047', 'G06N3/088', 'G06N5/04', 'G06N7/01', 'G06N3/045', 'G06N3/049', 'G06N3/063']"
CN109171712B,"Atrial fibrillation identification method, atrial fibrillation identification device, atrial fibrillation identification equipment and computer readable storage medium","The invention provides an atrial fibrillation identification method, an atrial fibrillation identification device, atrial fibrillation identification equipment and a computer readable storage medium, wherein the peak position of an R wave in an electrocardiosignal to be identified is obtained, and then heart rate variability characteristics and heart beat segments are determined according to the peak position of the R wave; acquiring heart beat characteristics of each heart beat segment to form a heart beat characteristic group; and finally, inputting the heart rate variability characteristics and the heart beat characteristic group into an atrial fibrillation recognition model to obtain an atrial fibrillation recognition result. According to the atrial fibrillation recognition method, the heart rate variability characteristics and the heart beat characteristics of the electrocardiosignals are input into the pre-trained atrial fibrillation recognition model, so that atrial fibrillation can be effectively recognized, and the reliability and the accuracy of atrial fibrillation recognition are improved.","['A61B5/361', 'A61B5/316', 'A61B5/318', 'A61B5/352', 'A61B5/6802', 'A61B5/7203', 'A61B5/7235', 'A61B5/725', 'A61B5/7271']"
CN111339882B,Power transmission line hidden danger detection method based on example segmentation,"The invention discloses a method for detecting hidden dangers of a power transmission line based on example segmentation, which is used for automatically detecting hidden dangers of the power transmission line in the power field by utilizing an improved MASK R-CNN model based on an example segmentation technology, and particularly has obvious effect advantage aiming at the automatic detection of the corrosion of a vibration damper. For the image shot by the unmanned aerial vehicle, the target area is obtained through the model, and accurate target feature extraction and classification detection can be realized. And detecting the potential risk degree of the target fault by adopting an image processing technology based on the target example obtained by segmentation, and combining with the weighted calculation of the target detection result, the potential risk level of the target fault can be accurately quantified. Meanwhile, the self-characteristics of the detection target are also considered. The method utilizes the priori knowledge to carry out image processing, feature extraction network structure adjustment and non-maximum suppression algorithm improvement, introduces a method combining case segmentation and target detection, realizes automatic detection of the target, and improves the accuracy of hidden danger targets in the power transmission line.","['G06V20/13', 'G06F18/214', 'G06N3/045', 'G06T5/40', 'G06T7/11', 'G06V2201/07', 'Y04S10/50']"
US12223435B2,System and method for molecular reconstruction from molecular probability distributions,"A system and method comprising a transmoler that identifies common substructures of a given 3D conformer and predicts its structural information. First, based on contrastive learning, substructure embeddings are learned in an unsupervised manner. Secondly, a novel oriented 3D object regressor predicts the dimensions and directions of each substructure in a conformer as well as its fingerprint embedding which are used to create differentiable junction tree molecular graphs. Lastly, using the junction tree graphs, molecular representations such as DeepSMILES are generated which represent new and novel molecules. The system may also generate conformers directly from a pocket. A pocket may be input to the model and the model learns to generate structures which can fit that pocket by conditioning the generative system. Furthermore, structure-based contrastive embeddings generated for transmoler can be recycled in structure-based generative modelling.","['G06N3/088', 'G06F16/951', 'G06F18/22', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/022', 'G06V10/751', 'G06V10/82', 'G16B15/00', 'G16B40/00', 'G16B45/00', 'G16B50/10', 'G16C20/50', 'G16C20/70', 'G06N3/044', 'G06N3/048', 'G06N3/084', 'G16C20/30', 'G16C20/90']"
US20230085827A1,Single-shot autofocusing of microscopy images using deep learning,"A deep learning-based offline autofocusing method and system is disclosed herein, termed a Deep-R trained neural network, that is trained to rapidly and blindly autofocus a single-shot microscopy image of a sample or specimen that is acquired at an arbitrary out-of-focus plane. The efficacy of Deep-R is illustrated using various tissue sections that were imaged using fluorescence and brightfield microscopy modalities and demonstrate single snapshot autofocusing under different scenarios, such as a uniform axial defocus as well as a sample tilt within the field-of-view. Deep-R is significantly faster when compared with standard online algorithmic autofocusing methods. This deep learning-based blind autofocusing framework opens up new opportunities for rapid microscopic imaging of large sample areas, also reducing the photon dose on the sample.","['H04N5/23212', 'G06V10/25', 'G02B21/367', 'G06N3/08', 'G06T5/003', 'G06T5/60', 'G06T5/73', 'G06V10/40', 'G06V10/751', 'H04N23/67', 'H04N23/80', 'H04N23/951', 'H04N23/959', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06V10/467', 'G06V2201/06']"
CN112348117B,"Scene recognition method, device, computer equipment and storage medium","The application relates to a scene recognition method, a scene recognition device, computer equipment and a storage medium. The method comprises the following steps: acquiring a training sample image; performing background recognition on the training sample image to obtain a background sample image corresponding to the training sample image; inputting the background sample image into a scene recognition model to obtain a first scene recognition result, and inputting the training sample image into the scene recognition model to obtain a second scene recognition result; obtaining a target model loss value based on a recognition result difference between a first scene recognition result and the second scene recognition result; the target model loss value and the recognition result are different to form a positive correlation relation; and adjusting model parameters of the scene recognition model based on the target model loss value to obtain a trained scene recognition model. The scene recognition model in the application can be deployed in a cloud server, and the cloud server provides artificial intelligent cloud service. By adopting the method, the scene recognition accuracy can be improved.","['G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/084']"
CN113392866B,"Image processing method, device and storage medium based on artificial intelligence","The embodiment of the application provides an image processing method, device and storage medium based on artificial intelligence, which comprises the steps of obtaining a training sample set, training an original model and a storage medium, wherein the training sample set comprises a first image sample set with a category label and a second image sample set formed by triplets, training the original model for semantic learning and training for metric learning by utilizing the training sample set, the original model comprises a first branch network and a second branch network, the first branch network and the second branch network comprise common network parameters, determining an image feature extraction model according to the trained original model, and the image feature extraction model is used for extracting feature vectors of images, so that the model can achieve semantic extraction capability while achieving the metric learning, and the accuracy of image retrieval can be improved based on image features extracted by the model.","['G06F18/214', 'G06N3/045', 'G06N3/08']"
CN111326136B,"Voice processing method and device, electronic equipment and storage medium","The application relates to the technical field of computers, discloses a voice processing method, a device, electronic equipment and a storage medium, relates to an artificial intelligence technology, and utilizes a machine learning technology in the artificial intelligence to classify voices, and the method comprises the following steps: converting the speech to be processed into prosody embedding vectors, decomposing the prosody embedding vectors into a preset number of basic embedding GSTs, and obtaining style embedding vectors representing the prosody characteristics of the speech according to the preset number of GSTs; and obtaining a classification result corresponding to the voice to be processed according to the style embedded vector. The voice processing method, the voice processing device, the electronic equipment and the storage medium provided by the embodiment of the application are beneficial to improving the accuracy of voice classification and have better universality.","['G10L13/02', 'G10L13/04', 'G10L13/047', 'G10L13/10', 'G10L25/03']"
US12390929B2,Object rearrangement using learned implicit collision functions,"Apparatuses, systems, and techniques for determining whether collisions will occur in potential paths of an object within a scene. In at least one embodiment, one or more neural networks determine whether collisions will occur in potential paths of an object within a scene based at least in part on point cloud data of the object and the scene.","['B25J9/1666', 'B25J9/1697', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06V10/82', 'G06V20/58', 'G08G1/166', 'G05B2219/40477', 'G06N3/063']"
CN113538480B,"Image segmentation processing method, device, computer equipment and storage medium","The application relates to an image segmentation processing method, an image segmentation processing device, computer equipment and a storage medium, which comprise the steps of obtaining a sample image, respectively carrying out image segmentation processing on a target object in the sample image through at least two trained guide models to obtain a first segmentation result corresponding to each guide model, carrying out image segmentation processing on the target object in the sample image through an image segmentation model to be trained to obtain a second segmentation result, determining a distillation error according to the difference between the second segmentation result and the first segmentation result, determining an edge error according to the difference between an edge prediction result in the second segmentation result and an edge prediction result in the first segmentation result, and adjusting model parameters of the image segmentation model and continuing distillation training according to the distillation error and the edge error until a training stop condition is met to obtain a trained image segmentation model. By adopting the method, the accuracy can be improved while the processing efficiency of image segmentation can be effectively ensured.","['G06T7/13', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30201', 'Y02T10/40']"
CN109947086B,Mechanical fault migration diagnosis method and system based on counterstudy,"The invention discloses a mechanical fault migration diagnosis method and system based on countermeasure learning, wherein the method comprises the following steps: acquiring original signals of mechanical faults under different working conditions, and analyzing to generate a source domain training data set with a label, a source domain training data set without a label and a target domain testing data set under different working conditions; training a deep convolutional neural network model according to a source domain training data set with a label and a back propagation algorithm to generate a fault diagnosis model; training a fault diagnosis model according to the source domain training data set without the label and the target domain testing data set; fine-tuning the trained fault diagnosis model according to the source domain training data set with the label and a back propagation algorithm; inputting the target domain test data set without the label into the fault diagnosis model after fine adjustment, and outputting the fault category of the sample to be tested. The method obtains the domain invariant feature through the counterstudy method, realizes the migration before different domains, and realizes the intelligent diagnosis of the variable working condition mechanical fault.",[]
US20220396289A1,Neural network path planning,"Apparatuses, systems, and techniques to calculate a plurality of paths, through which an autonomous device is to traverse. In at least one embodiment, a plurality of paths are calculated using one or more neural networks based, at least in part, on one or more distance values output by the one or more neural networks.","['G01C21/3407', 'G01C21/3446', 'B60W60/0011', 'G06N3/082', 'G01C21/20', 'G01C21/3602', 'G05D1/0088', 'G05D1/0212', 'G05D1/0231', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06Q10/04', 'B60W2420/403', 'B60W2420/42', 'B60W2556/45']"
US11862339B2,Model optimization and data analysis using machine learning techniques,"Disclosed herein are platforms, systems, devices, methods and media for model optimization and data analysis using machine learning. Input data can be processed and analyzed to identify relevant discriminating features, which can be modeled using a plurality of machine learning models. A computing device can be configured with one or more optimized models for categorizing input data.","['G16H20/70', 'G16H50/20', 'A61B5/16', 'A61B5/168', 'A61B5/4088', 'A61B5/7267', 'A61M21/00', 'G06F18/211', 'G06F18/285', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T19/006', 'G09B19/00', 'G16H10/20', 'G16H50/70', 'A61M2021/005', 'G06F18/217']"
CN112221159B,Virtual item recommendation method and device and computer readable storage medium,"The application discloses a virtual item recommendation method, a virtual item recommendation device and a computer readable storage medium, wherein a heterogeneous network of a target game is obtained; representing a target user node in the heterogeneous network as a user learning vector by using a heterogeneous network representation learning model, and representing each prop node in the heterogeneous network as a prop learning vector; acquiring first preference information of a target game user to each game virtual prop according to the user learning vector and the prop learning vector; acquiring a historical operation sequence of a target game user, and representing the historical operation sequence as a time sequence learning vector through a time sequence model; acquiring second preference information of the target game user to each game virtual prop according to the time sequence learning vector and the prop learning vector; and recommending the game virtual item to the target game user according to the first preference information and the second preference information. The game virtual item can be more accurately recommended to the game user.",['A63F13/79']
US7987003B2,Network media appliance system and method,"A network media appliance, comprising at least one packet data network interface, adapted for communicating data packets with a data network according to an Internet Protocol; a media data interface, and a processor, having an associated memory for storing executable code, said code defining at least a remote virtual interface function, and a data transfer function for controlling transfer of data through said media data interface.","['G05B15/02', 'G05B19/042', 'G06V40/103', 'G05B2219/25323', 'G05B2219/2613', 'G05B2219/2615', 'G05B2219/34038']"
GB2617887A,Object image completion,"A processor is disclosed, comprising one or more circuits to use one or more neural networks to complete 114 an occluded object 106 in an image, wherein a first portion 108 of the one or more neural networks is trained using training data generated based, at least in part, on output of a second portion 112 of the one or more neural networks. A generative model framework may generate a plurality of complete objects in an image, based on an input image. The parameters of the second part may not be adjusted during training of the first portion. The training of the first portion may be refined using multiple image input loops. An associated system is also disclosed.","['G06T9/002', 'G06F18/214', 'G06T5/77', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06T5/60', 'G06T7/11', 'G06V10/26', 'G06V10/82', 'G06V20/58', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
JP2025016513A,3D Object Segmentation of Localized Medical Images Using Object Detection,"To provide techniques for segmenting objects within medical images using a deep learning network that is localized with object detection based on a derived contrast mechanism.SOLUTION: Aspects of the present invention are directed to localizing an object of interest within a first medical image having a first characteristic, projecting a bounding box or segmentation mask of the object of interest onto a second medical image having a second characteristic to define a portion of the second medical image, and inputting the portion of the second medical image into a deep learning model that is constructed as a detector using a weighted loss function capable of segmenting the portion of the second medical image and generating a segmentation boundary around the object of interest. The segmentation boundary may be used to calculate a volume of the object of interest for determining a diagnosis and/or a prognosis of a subject.SELECTED DRAWING: Figure 4","['G06T7/0012', 'G06T7/12', 'G06F18/241', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T7/10', 'G06T7/174', 'G06T7/62', 'G06T7/70', 'G06T7/73', 'G06V10/758', 'G06V10/764', 'G06V20/64', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10101', 'G06T2207/10104', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/031']"
CN111914812B,"Image processing model training method, device, equipment and storage medium","The application discloses an image processing model training method, device, equipment and storage medium, and belongs to the technical field of artificial intelligence. In the embodiment of the application, on one hand, a shielding mode is introduced, the shielding mode of the sample face image is determined and compared with a target shielding mode marked by the sample face image, an image processing model is trained to determine more accurate shielding indication information, the accuracy of face recognition is improved, and the robustness of the image processing model is improved. On the other hand, the image processing model can process the image end to end without independently performing a prediction process of the shielding region and a dictionary query process of the corresponding characteristics of the shielding region by means of an external network, so that the calculated amount is remarkably reduced, the running speed of equipment is increased, the size of the image processing model is also reduced, the influence of external network factors is avoided, and the accuracy is remarkably improved.","['G06V10/273', 'G06V40/161', 'G06V40/171', 'G06F18/214', 'G06V10/82', 'G06V40/162', 'G06V40/168', 'G06V40/172']"
CN111369576B,"Training method of image segmentation model, image segmentation method, device and equipment","The application discloses a training method of an image segmentation model, an image segmentation method, an image segmentation device and image segmentation equipment, and belongs to the field of image segmentation. The method comprises the following steps: acquiring a sample image, wherein the sample image is an image with an annotation area; performing superpixel division on the sample image to obtain at least two superpixel areas; obtaining a hard label of the pixel according to whether the pixel in the sample image belongs to the labeling area; obtaining a soft label of the pixel according to the super-pixel area to which the pixel belongs and the hard label of the pixel, wherein the soft label is used for representing the pseudo probability that the pixel belongs to the labeling area; and training an image segmentation model according to the hard label of the pixel and the soft label of the pixel. The image segmentation model is trained by using the hard labels and the soft labels of the pixels, so that the trained image segmentation model can accurately segment the segmentation region in the input image, and meanwhile, the training efficiency of the image segmentation model is improved.","['G06T7/11', 'G06F18/214', 'G06N3/045', 'G06T2207/30204']"
CN110390950B,An End-to-End Speech Enhancement Method Based on Generative Adversarial Networks,"The invention discloses an end-to-end voice enhancement method based on a generation countermeasure network, which directly inputs a voice signal with noise into a pre-trained deep neural network for signal processing and outputs an enhanced voice signal; the deep neural network is obtained by training through the following steps: step S1: preliminary training generates a confrontation network, wherein the generated confrontation network comprises two deep neural networks: a generator G and a discriminator D; step S2: after knowledge distillation is carried out on the simulated noisy speech through a traditional statistical-based speech enhancement algorithm, training is carried out again to generate a confrontation network; step S3: fine-tuning the generator G obtained by training in the steps by using real voice with noise; step S4: and outputting the generator G trained by the steps as a final deep neural network for speech enhancement processing.","['G06N3/045', 'G06N3/084', 'G10L21/0208', 'G10L21/0264', 'G10L25/30']"
CN116433940B,Remote sensing image change detection method based on twin image network,"The invention provides a remote sensing image change detection method based on a twin mirror network, which relates to the field of change detection and comprises the steps of S1 obtaining a front time phase image and a rear time phase image of a target area, S2 constructing a change detection model and pre-training the change detection model, wherein the change detection model comprises a feature extraction network, a feature refining network and a change comparison network, S3 obtaining a first feature image and a second feature image through the feature extraction network, S4 inputting the first feature image and the second feature image into the feature refining network in sequence to obtain a first refining feature image and a second refining feature image, and S5 inputting the first refining feature image and the second refining feature image into the change comparison network to obtain a change detection result. According to the invention, by opening the information channels of the remote sensing images of the two time phases, the characteristic can enhance the capability of expressing the content information of the remote sensing images, so that the accuracy of change detection is improved.","['G06V10/761', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06T7/33', 'G06V10/26', 'G06V10/462', 'G06V10/52', 'G06V10/762', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V20/10']"
US11227384B2,Methods and systems for determining a diagnostically unacceptable medical image,"Methods and systems for determining a diagnostically unacceptable medical image. One system includes at least one electronic processor configured to receive a new medical image captured via a medical imaging device. The at least one electronic processor is also configured to determine a classification of the new medical image using a model developed with machine learning using training information that includes a plurality of medical images and an associated classification for each medical image, each associated classification identifying whether the associated medical image is diagnostically unacceptable, wherein the classification of the new medical image indicates whether the new medical image is diagnostically unacceptable. The at least one electronic processor is also configured to, when the classification indicates that the new medical image is diagnostically unacceptable, prompt a user of the medical imaging device to adjust a parameter associated with the new medical image and recapture the new medical image.","['G16H30/40', 'G06F18/2413', 'G06K9/627', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0002', 'G06T7/0012', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G16H30/00', 'G16H30/20', 'G16H50/20', 'G06N20/10', 'G06N3/006', 'G06N3/126', 'G06N5/01', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/03']"
US10372859B2,System and method for designing system on chip (SoC) circuits using single instruction multiple agent (SIMA) instructions,"The embodiments herein discloses a system and method for designing SoC by using a reinforcement learning processor. An SoC specification input is received and a plurality of domains and a plurality of subdomains is created using application specific instruction set to generate chip specific graph library. An interaction is initiated between the reinforcement learning agent and the reinforcement learning environment using the application specific instructions. Each of the SoC sub domains from the plurality of SoC sub domains is mapped to a combination of environment, rewards and actions by a second processor. Further, interaction of a plurality of agents is initiated with the reinforcement learning environment for a predefined number of times and further Q value, V value, R value, and A value is updated in the second memory module. Thereby, an optimal chip architecture for designing SoC is acquired using application-domain specific instruction set (ASI).","['G06F17/505', 'G06F30/3323', 'G06F17/504', 'G06F30/327']"
US11222196B2,Simultaneous recognition of facial attributes and identity in organizing photo albums,"A method is provided for simultaneously recognizing facial attributes and identity to organize photo and/or video albums, based on modifying an efficient convolutional neural network (CNN) which extracts facial representations suitable for face identification and attribute (age, gender, ethnicity, emotion, etc.) recognition tasks. The method enables to process all the tasks simultaneously, without a need for additional CNNs. As a result, a very fast facial analytic system is provided, and the system can be installed onto mobile devices.","['G06F16/583', 'G06K9/00288', 'G06F16/45', 'G06K9/00281', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06V10/82', 'G06V40/171', 'G06V40/172']"
CN110909630B,Abnormal game video detection method and device,"The application relates to the technical field of computers, in particular to a method and a device for detecting abnormal game videos, wherein the method comprises the steps of acquiring a game video frame sequence; respectively identifying a game scene in each video frame in the game video frame sequence, and determining a scene category corresponding to each video frame; and determining abnormal game video clips according to the scene category corresponding to each video frame, so that the abnormal detection is carried out on the basis of the game video frame sequence and the scene category without depending on background data, and the accuracy and the efficiency of the detection are improved.","['G06V20/40', 'A63F13/75', 'A63F2300/5586']"
US11042700B1,Conciseness reconstruction of a content presentation via natural language processing,"A method may include obtaining a document and using a first prediction model to generate text block scores for text blocks in the document, where a first text block of the text blocks is associated with a first text block score of the plurality of text block scores. The method also includes updating, in response to the first text block score for the first text block failing to satisfy a criterion, a modified version of the document with an indicator to set the first text block as a hidden text block in a presentation of the modified version. The method also includes generating a summarization of the first text block based on the words in the first text block and updating the modified version of the document to include the summarization. The method also includes providing the modified version of the document to a user device.","['G06F40/169', 'G06F40/197', 'G06F16/345', 'G06F40/117', 'G06F40/30', 'G06F40/40', 'G06N20/00', 'G06N3/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'H04L67/02']"
EP4102351A1,Secure network access device,"Systems and techniques for securing network communications are described. A network device comprises a network interface and at least one accelerator. The network device inspects obtained data using the accelerator. The network device determines, based on the inspection, that the data is indicative of a violation of a security policy, and generates a response to the violation.","['H04L63/0272', 'H04L63/1416', 'H04L63/1408', 'G06F21/554', 'G06F21/64', 'G06F3/0622', 'G06F3/0637', 'G06F3/067', 'H04L63/0245', 'H04L63/0281', 'H04L63/08', 'H04L63/1425', 'H04L63/145', 'H04L63/20', 'H04L67/1097', 'G06F2009/45579']"
US10248664B1,Zero-shot sketch-based image retrieval techniques using neural networks for sketch-image recognition and retrieval,"This disclosure relates to improved sketch-based image retrieval (SBIR) techniques. The SBIR techniques utilize an architecture comprising three interconnected neural networks to enable zero-shot image recognition and retrieval based on free-hand sketches. Zero-shot learning may be implemented to retrieve one or more images corresponding to the sketches without prior training on all categories of the sketches. The neural network architecture may do so, at least in part, by training encoder hashing functions to mitigate heterogeneity of sketches and images, and by applying semantic knowledge that is learned during a limited training phase to unknown categories.","['G06T7/11', 'G06F16/532', 'G06F17/30259', 'G06F16/5854', 'G06F17/30277', 'G06F18/24133', 'G06F18/2433', 'G06K9/00402', 'G06K9/4609', 'G06K9/66', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N5/022', 'G06N5/046', 'G06V10/454', 'G06V10/75', 'G06V10/82', 'G06V20/10', 'G06V30/19173', 'G06V30/32', 'G06V30/413', 'G06V40/16', 'G06T2207/20081', 'G06T2207/20084']"
US10977530B2,ThunderNet: a turbo unified network for real-time semantic segmentation,"System and method for semantic segmentation. The system includes a computing device. The computing device has a processor and a non-volatile memory storing computer executable code. The computer executable code, when executed at the processor, is configured to: receive an image of a scene; process the image by an encoder to form an encoder feature map; process the encoder feature map by a pyramid pooling module (PPM) to form an PPM feature map; and process the PPM feature map by a decoder to form a segmentation feature map.","['G06K9/726', 'G06V20/10', 'G06V10/267', 'G06K9/6232', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06T9/002', 'G06V10/7715', 'G06V10/82', 'G06V20/70', 'G06V30/19173', 'G06V30/274', 'G06F18/241', 'G06K2009/366', 'G06K9/6268', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30236']"
CN110795925B,Image-text typesetting method and device based on artificial intelligence and electronic equipment,"The disclosure provides an artificial intelligence-based image-text typesetting method and device and electronic equipment. The method comprises the following steps: acquiring a background image to be typeset and a target size for cutting the background image, and determining a main body center coordinate of the background image; determining a plurality of candidate clipping frames on the background image according to the target size and the main body center coordinates, and determining a plurality of candidate clipping images based on the candidate clipping frames; typesetting the text information to be typeset and the plurality of candidate clipping images according to the plurality of candidate format templates to obtain a plurality of candidate typesetting schemes; extracting characteristics of the candidate typesetting schemes, and determining typesetting scores of the candidate typesetting schemes according to characteristic extraction results; and determining a target cut image and a target layout template for typesetting the target cut image and the text information according to the typesetting score. The method simplifies the operation flow and has high automation degree; and the layout template is more accurate to select, so that the application scenes of the image-text typesetting are enriched.",[]
WO2021147325A1,"Object detection method and apparatus, and storage medium","Embodiments of the present application relate to the field of artificial intelligence, and specifically relate to the field of computer vision. Disclosed are an object detection method and apparatus. The method may comprise: obtaining an image to be detected; determining, in the image to be detected, the initial image features of an object to be detected; according to cross-domain knowledge graph information, determining the enhanced image features of the object to be detected, wherein the cross-domain knowledge graph information comprises an association relationship between object categories corresponding to the object to be detected in different domains, and the enhanced image features indicate semantic information of the object categories corresponding to other objects associated with the object to be detected in different domains; and according to the initial image features of the object to be detected and the enhanced image features of the object to be detected, determining the candidate box and category of the object to be detected. By means of the technical solution provided by the present application, a cross-domain knowledge graph is constructed, an internal relationship between different objects to be detected can be obtained, and the effect of object detection is improved.","['G06V20/10', 'G06F16/367', 'G06F18/2414', 'G06N3/045', 'G06N3/08', 'G06V10/462', 'G06V20/35']"
US11670001B2,Object pose estimation,"In an embodiment, a system provides object tracking and 6D pose estimations to a robot that performs different tasks such as manipulation and navigation. In an embodiment the 6D object pose is determined using a Rao-Blackwellized particle filtering framework, where the 3-D rotation and the 3-D translation of the object is decoupled. In an embodiment, the system provides the 3-D translation of an object along with a full distribution over the 3-D rotation. In an embodiment, the 3-D rotation is determined by discretizing the rotation space, and training an autoencoder network to construct a codebook of feature embeddings for the discretized rotations. In an embodiment, the system is able to track objects with arbitrary symmetries while also maintaining adequate posterior distributions.","['G06T7/75', 'G06F18/2413', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06T11/20', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V20/58', 'G06N3/063', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/12']"
US11468680B2,"Shuffle, attend, and adapt: video domain adaptation by clip order prediction and clip attention alignment","A method for performing video domain adaptation for human action recognition is presented. The method includes using annotated source data from a source video and unannotated target data from a target video in an unsupervised domain adaptation setting, identifying and aligning discriminative clips in the source and target videos via an attention mechanism, and learning spatial-background invariant human action representations by employing a self-supervised clip order prediction loss for both the annotated source data and the unannotated target data.","['G06N3/088', 'G06F18/2155', 'G06K9/6259', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/48', 'G06V40/20', 'G06V20/44']"
US12175703B2,Single-stage category-level object pose estimation,"Apparatuses, systems, and techniques to determine a pose and relative dimensions of an object from an image. In at least one embodiment, a pose and relative dimensions of an object are determined from an image based at least in part on, for example, features of the image.","['G06T7/73', 'B25J9/161', 'B25J9/1612', 'B25J9/1697', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T7/60', 'G06T7/62', 'G06V10/255', 'G06V10/462', 'G06V10/82', 'G05B2219/39484', 'G05B2219/40543', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
CN113610219B,Multi-source domain self-adaption method based on dynamic residual error,"The invention discloses a multisource domain self-adaption method based on dynamic residual errors, which comprises the following steps: a module neural network connection mode of short circuit connection enables a dynamic residual error network to adapt to and facilitate access to most convolutional neural networks; the switch of the modularized neural network is set, so that whether the module participates in the calculation of the neural network can be dynamically controlled according to the influence degree of the modularized neural network on the result; the dynamic residual neutral network consisting of global average pooling, full connection layers and convolution kernel groups is designed, the distribution alignment can be carried out according to the data characteristics without domain labels, and the conventional multi-source domain self-adaption problem is simplified into Shan Yuanyu self-adaption problem. The method breaks the domain barriers, simplifies the complexity of the multi-source domain self-adaptive model design, and reduces the data preparation workload. The method can be applied to an industrial Internet scene of transfer learning, the access mode is simple, the time and the space of model training are saved, domain label data are not needed, the accuracy is improved, and meanwhile, the data preparation workload is greatly reduced.","['G06N3/045', 'G06F18/241', 'G06N3/084']"
US20210282701A1,Method of early detection of epileptic seizures through scalp eeg monitoring,"A system performs concurrent detection and early detection of epileptic seizure episodes, based on scalp electroencephalogram (EEG) of a patient collected through a data acquisition device in the course of the patient's normal daily activities. An early detection model, which is trained and retrained applying machine learning techniques at predetermined intervals on the collected data, enables issuing of an early warning of an upcoming seizure episode to allow the patient to take necessary preparatory actions (e.g., seeking a safe location for the episode to happen and alerting care-givers).","['A61B5/4094', 'A61B5/291', 'A61B5/369', 'A61B5/37', 'A61B5/7267', 'G16H20/10', 'G16H20/40', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'A61B5/0006', 'A61B5/7225']"
CN110942086B,"Data prediction optimization method, device, equipment and readable storage medium","The invention relates to the technical field of artificial intelligence, and discloses a data prediction optimization method, which comprises the following steps: respectively carrying out predictive training on a plurality of initial models to be trained by using the same training sample to obtain a set of models to be trained; superposing the model to be trained in the model set to be trained according to preset weights by a preset superposition algorithm to obtain a preset candidate model set; judging whether preset candidate models in a preset candidate model set meet preset scoring standards or not; if yes, obtaining the preset candidate model meeting the preset scoring standard and predicting by using the preset candidate model, otherwise, adjusting the preset weight occupied by the model to be trained in the preset candidate model set. The invention also discloses a data prediction optimization device, equipment and a computer readable storage medium. The data prediction optimization method provided by the invention solves the technical problem of low prediction capacity of the existing model.","['G06F18/285', 'G06F18/2135', 'G06F18/214', 'G06F18/2155', 'G06F18/217', 'G06F18/23', 'G06F18/2433', 'G06N3/045', 'G06N3/088']"
US10932890B1,Enhanced techniques for determination of dental margins in intraoral scans,"Systems and methods for enhanced techniques for determination of dental margins in intraoral scans. An example method includes receiving a request including an intraoral scan of a portion of a mouth, the intraoral scan depicting a margin created via adjustment of a tooth. A prepared region depicting the tooth is identified based on the intraoral scan. A representation of the intraoral scan usable as input to a machine learning model is generated, with the representation comprising structured data associated with the point cloud or mesh. Information identifying an estimated margin is determined based on the representation via computing a forward pass of the machine learning model. A response comprising the determined information is generated, with the determined information being usable to fabricate a prosthetic according to the estimated margin.","['G16H30/40', 'A61C13/0004', 'A61C5/30', 'A61C9/0053', 'G06T15/08', 'G06T17/205', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G06T2210/12', 'G06T2210/21', 'G06T2210/41']"
CN118171179B,Subway station fire emergency response rescue decision-making system and method based on multi-mode fusion,"The invention discloses a subway station fire emergency response rescue decision system and a method based on multi-mode fusion, wherein multi-source data are acquired at intervals of preset time based on configured sensors; extracting multi-mode features from the multi-source data and fusing to obtain fused feature data; invoking a pre-constructed fire evolution process model, taking the fused characteristic data as input data, performing space-time fire evolution analysis and key node vulnerability analysis, and outputting fire evolution characteristic data; and inputting the fire evolution characteristic data into a preconfigured PINN model, extracting key nodes and high-risk areas based on the output of the PINN model, and giving a rescue decision scheme. The specificity of the subway environment and the dynamics of the fire disaster event are fully considered, and the perception capability of the subway environment and the fire disaster event is obviously improved.","['G06F18/2411', 'G06F18/25']"
US20210097691A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate or manipulate digital images. In at least one embodiment, a network is trained to generate modified images including user-selected features.","['G06T11/001', 'G06F18/214', 'G06F18/24133', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06T11/60', 'G06T3/4053', 'G06T7/11', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US10559225B1,Computer-implemented systems and methods for automatically generating an assessment of oral recitations of assessment items,"Provide automatic assessment of oral recitations during computer based language assessments using a trained neural network to automate the scoring and feedback processes without human transcription and scoring input by automatically generating a score of a language assessment. Providing an automatic speech recognition (“ASR”) scoring system. Training multiple scoring reference vectors associated with multiple possible scores of an assessment, and receiving an acoustic language assessment response to an assessment item. Based on the acoustic language assessment automatically generating a transcription, and generating an individual word vector from the transcription. Generating an input vector by concatenating an individual word vector with a transcription feature vector, and supplying an input vector as input to a neural network. Generating an output vector based on weights of a neural network; and generating a score by comparing an output vector with scoring vectors.","['G09B19/04', 'G06N3/04', 'G06N3/045', 'G06N3/0499', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G10L15/16', 'G10L15/183']"
US20210397943A1,Techniques for classification with neural networks,"Apparatuses, systems, and techniques to train neural networks to perform classification. In at least one embodiment, one or more neural networks are trained to perform classification based on, for example, using one or more compressed representations of one or more class labels, where the one or more compressed representations have fewer bits than a representation of the one or more class labels.","['G06F18/214', 'G06F18/241', 'G06N3/063', 'G06F18/24137', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
CN111382584B,"Text translation method and device, readable storage medium and computer equipment","The application relates to a text translation method, which comprises the following steps: acquiring a word sequence of a source text; coding the word sequence layer by layer through a multilayer neural network of a coder in a machine translation model to obtain a source end fusion vector sequence fused with the output of each layer of neural network; processing the input of each layer of neural network of the encoder by adopting a self-attention mechanism processing mode so as to obtain the output of each layer of neural network, wherein the input of the current layer of neural network is determined by the output of the pre-order layer of neural network; decoding the source end fusion vector sequence layer by layer through a multilayer neural network of a decoder in the machine translation model according to the target words output by the machine translation model in the previous time to obtain a target end fusion vector sequence which is fused with the output of each layer of neural network in the current time; determining a target word output at the current time according to the fusion vector sequence at the current target end; and generating a target text according to the output target words. The scheme provided by the application can improve the text translation quality.","['G06N20/00', 'G06N3/045', 'G06N3/08']"
CN109800736B,A Road Extraction Method Based on Remote Sensing Image and Deep Learning,"The invention relates to a road extraction method based on remote sensing images and deep learning, which comprises the following steps: in the remote sensing image, determining the resolution of the remote sensing image, intercepting the resolution, and marking the intercepted remote sensing image with data; extracting the edges of the image of the intercepted remote sensing image by using a Canny edge detection algorithm, and superposing the extracted image with the original image to highlight the road characteristics; setting up an image classification model, leaving low-level image characteristic information in training of classification tasks on a basic network, and transmitting the low-level image characteristic information to a next-level semantic segmentation model in a characteristic extraction model construction process; setting up a semantic segmentation model for segmenting road information in the remote sensing image; after training, the network parameters that extract the road information will remain in the segmentation model. The invention highlights the road characteristics by preprocessing the image, is used for accelerating learning and training a semantic segmentation model, and can realize the effect of extracting the road information of the remote sensing image.",[]
CN113761261B,"Image retrieval method, device, computer readable medium and electronic device","The application belongs to the technical field of artificial intelligence, and particularly relates to an image retrieval method, an image retrieval device, a computer readable medium and electronic equipment. The image retrieval method comprises the steps of extracting features of a query image to be retrieved to obtain image features of the query image, carrying out classification prediction on the image features to determine target semantic categories and target cluster groups which have semantic relativity with the image features, wherein the target cluster groups are selected from one or more candidate cluster groups belonging to the target semantic categories, and carrying out feature comparison on the image features and the candidate images in the target cluster groups to determine target images matched with the query image. The embodiment of the application can improve the image retrieval efficiency and the retrieval accuracy.","['G06F16/583', 'G06F16/55', 'G06F18/22', 'G06F18/23213', 'G06N20/00']"
US12236616B2,Method and system for automatic extraction of virtual on-body inertial measurement units,"An exemplary virtual IMU extraction system and method are disclosed for human activity recognition (HAR) or classifier system that can estimate inertial measurement units (IMU) of a person in video data extracted from public repositories of video data having weakly labeled video content. The exemplary virtual IMU extraction system and method of the human activity recognition (HAR) or classifier system employ an automated processing pipeline (also referred to herein as “IMUTube”) that integrates computer vision and signal processing operations to convert video data of human activity into virtual streams of IMU data that represents accelerometer, gyroscope, or other inertial measurement unit estimation that can measure acceleration, inertia, motion, orientation, force, velocity, etc. at a different location on the body. In other embodiments, the automated processing pipeline can be used to generate high-quality virtual accelerometer data from a camera sensor.","['G06T7/251', 'G06T7/20', 'G06V10/80', 'G06V20/41', 'G06V30/194', 'G06V40/23', 'G06T2207/30196']"
US12236351B2,Gaze detection using one or more neural networks,"Apparatuses, systems, and techniques are described to determine locations of objects using images including digital representations of those objects. In at least one embodiment, a gaze of one or more occupants of a vehicle is determined independently of a location of one or more sensors used to detect those occupants.","['G06N3/084', 'B60W40/08', 'B60W50/00', 'G06F18/214', 'G06F18/217', 'G06F3/013', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/59', 'G06V20/597', 'G06V40/19', 'G06V40/193', 'B60W2050/0043', 'B60W2540/00', 'G06N3/045', 'G06N3/049', 'G06N3/063']"
US20240009851A1,Grasp determination for an object in clutter,"Apparatuses, systems, and techniques determine a set of grasp poses that would allow a robot to successfully grasp an object that is proximate to at least one additional object. In at least one embodiment, the set of grasp poses is modified based on a determination that at least one of the grasp poses in the set of grasp poses would interfere with at least one additional object that is proximate to the object.","['B25J9/1697', 'B25J13/08', 'B25J9/161', 'B25J9/1612', 'B25J9/1666', 'G05B19/402', 'G05B19/4155', 'G06N3/08', 'G06T7/10', 'G06T7/50', 'G06T7/70', 'G05B2219/40269', 'G06T2207/10028', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30244']"
CN113819890B,"Distance measuring method, distance measuring device, electronic equipment and storage medium","The embodiment of the application provides a distance measuring method, and relates to the technical field of automatic driving. The method comprises the following steps: acquiring a frame image of a current frame acquired under a field of view in front of the running vehicle; obtaining at least one mapping point set according to the intersection point of each straight line in the frame image, wherein each mapping point set comprises at least two mapping points which are orthogonal pairwise; determining a homography matrix by combining the coordinates of at least one mapping point set in a camera coordinate system based on the parameters of the image acquisition equipment; identifying a target pixel point corresponding to the grounding point of the target object in the frame image, determining the coordinate of the target pixel point in a pixel coordinate system, and combining a homography matrix to obtain the coordinate of the target object in a world coordinate system of the current frame; and determining the distance between the target object and the vehicle in the current frame according to the coordinates of the target object in the world coordinate system of the current frame. Compared with the prior art, the distance measuring efficiency and precision are improved.","['G01C11/02', 'G01C11/30', 'G06T5/70', 'G06T7/73', 'G06T7/80', 'G06T2207/30244', 'G06T2207/30252', 'Y02T10/40']"
US11751359B2,Intelligent movable flow controller and cooling manifold for datacenter cooling systems,"Systems and methods for cooling a datacenter are disclosed. In at least one embodiment, a first flow controller within a cooling manifold is associated with a second flow controller and with a tube there between; and the first flow controller is movable in at least one direction relative to dimensions of the cooling manifold so that it can be positioned for mating with a server tray or box and so that the second flow controller can be mated with a rack manifold.","['G06N3/08', 'H05K7/20781', 'G06N3/09', 'H05K7/1489', 'H05K7/20272', 'H05K7/20281', 'H05K7/20772', 'H05K7/20836', 'G06N3/02', 'G06N3/063']"
US20230144662A1,Techniques for partitioning neural networks,"Apparatuses, systems, and techniques to partition neural networks. In at least one embodiment, one or more circuits are to cause one or more neural networks to be dynamically partitioned based, at least in part, on one or more performance metrics of the one or more neural networks.","['G06F9/5022', 'G06N3/082', 'G06F9/5088', 'G06F9/505', 'G06F9/5066', 'G06F9/5077', 'G06F9/5094', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/049', 'G06N3/0495', 'G06N3/088', 'G06N3/09', 'G06N3/10', 'G06N5/04', 'G06F2209/509']"
US20220237414A1,Confidence generation using a neural network,"Apparatuses, systems, and techniques to generate one or more confidence values associated with one or more objects identified by one or more neural networks. In at least one embodiment, one or more confidence values associated with one or more objects identified by one or more neural networks are generated based on, for example, one or more neural network outputs.","['G06V10/82', 'G06K9/6262', 'G06F18/217', 'A01B69/001', 'A01C21/005', 'A01G25/09', 'A01G25/16', 'A01M21/00', 'B60W10/04', 'B60W10/18', 'B60W30/09', 'B60W30/0956', 'B60W50/14', 'B60W60/0015', 'G06F18/2163', 'G06F18/24', 'G06K9/0063', 'G06K9/00791', 'G06K9/6261', 'G06K9/6267', 'G06N3/04', 'G06N3/08', 'G06V10/26', 'G06V20/13', 'G06V20/188', 'G06V20/56', 'G06V20/58', 'G16H40/67', 'B60W2420/40', 'B60W2556/45', 'G06K2209/05', 'G06V10/95', 'G06V10/955', 'G06V2201/03', 'G06V2201/031']"
US11776680B2,Method and system for real-time and offline de-identification of facial regions from regular and occluded color video streams obtained during diagnostic medical procedures,"Systems and techniques that facilitate real-time and/or offline de-identification of facial regions from regular and/or occluded color video streams obtained during diagnostic medical procedures are provided. A detection component can generate a bounding box substantially around a person in a frame of a video stream, can generate a heatmap showing key points or anatomical masks of the person based on the bounding box, and can localize a face or facial region of the person based on the key points or anatomical masks. An anonymization component can anonymize pixels in the frame that correspond to the face or facial region. A tracking component can track the face or facial region in a subsequent frame based on a structural similarity index between the frame and the subsequent frame being above a threshold. If the structural similarity index between the frame and the subsequent frame is above the threshold, the tracking component can track the face or facial region in the subsequent frame without having the detection component generate a bounding box or a heatmap in the subsequent frame, and the anonymization component can anonymize pixels in the subsequent frame corresponding to the tracked face or facial region.","['G16H30/40', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T5/002', 'G06T5/70', 'G06T7/246', 'G06T7/248', 'G06V10/7715', 'G06V40/164', 'G06V40/165', 'G16H50/20', 'G16H50/70', 'G06T2207/10016', 'G06T2207/20012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G16H30/20']"
US20220269937A1,Generating frames for neural simulation using one or more neural networks,"Apparatuses, systems, and techniques to use one or more neural networks to generate one or more images based, at least in part, on one or more spatially-independent features within the one or more images. In at least one embodiment, the one or more neural networks determine spatially-independent information and spatially-dependent information of the one or more images and process the spatially-independent information and the spatially-dependent information to generate the one or more spatially-independent features and one or more spatially-dependent features within the one or more images.","['G06T11/00', 'G06V10/82', 'G06N3/08', 'G06N3/082', 'G06F30/27', 'G06K9/00711', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/049', 'G06N3/063', 'G06N3/084', 'G06N3/092', 'G06V20/40', 'B60W60/001', 'G06F30/13', 'G06T2207/20081', 'G06T2207/20084', 'G06T7/194']"
US10157462B2,"System and method for image-based quantification of white and brown adipose tissue at the whole-body, organ and body-region levels","A system and method for automatically detecting and quantifying adiposity distribution is presented herein. The system detects, segments and quantifies white and brown fat adipose tissues at the whole-body, body region, and organ levels.","['G06T7/0012', 'A61B6/032', 'A61B6/037', 'A61B6/50', 'A61B6/5217', 'G06F18/2411', 'G06F18/2413', 'G06K9/4604', 'G06K9/4638', 'G06K9/6269', 'G06K9/627', 'G06T7/00', 'G06T7/11', 'G06T7/12', 'G06T7/143', 'G06V10/457', 'G06V10/764', 'G06V10/82', 'G16H50/30', 'G06K2209/051', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10104', 'G06T2207/10132', 'G06T2207/20084', 'G06T2207/20156', 'G06T2207/30024', 'G06V2201/031']"
CN111209384B,Question-answer data processing method and device based on artificial intelligence and electronic equipment,"The invention provides a question-answer data processing method, a device, equipment and a storage medium based on artificial intelligence; the method comprises the following steps: acquiring semantic features of question-answering data; decoupling the semantic features of the question-answer data to obtain the entity features of the question-answer data and the intention features of the question-answer data; determining an entity matching score of the entity dimension matching corresponding to the question-answer data based on the entity characteristics, and determining an intention matching score of the intention dimension matching corresponding to the question-answer data based on the intention characteristics; when at least one of the entity matching score and the intention matching score meets a corresponding question-and-answer condition, determining that the question-and-answer data belongs to the type of the question-and-answer, and identifying the question-and-answer data from different dimensions by the method and the device, so that the quality of the question-and-answer data is improved.",['G06F16/3328']
CN116935169B,Training method for draft graph model and draft graph method,"The application discloses a method for training a text-generated graph model and a text-generated graph method, and belongs to the technical field of artificial intelligence. The method for training the text-to-image model can carry out diversity constraint of the generated images in the training process of the text-to-image model, and the diversity constraint is led, so that the diversity constraint can be ensured to play a role in the parameter adjustment stage of training, and the text-to-image model obtained through training has the capability of generating diversified images. The text-generated graph model obtained by training based on the training method can also ensure the image diversity of the generated images, thereby improving the text-generated graph effect. Moreover, the method and the device can increase the supervision of the text information in the training process of the text-generated graph model, so that the problem that the text information utilization degree is low when the current text-generated graph model generates the picture is solved.","['G06V10/774', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06V10/763', 'G06V10/82']"
US10891540B2,Adaptive neural network management system,"A method and computer system for managing a neural network. Data is sent into an input layer in a portion of layers of nodes in the neural network. The data moves on an encode path through the portion such that an output layer in the portion outputs encoded data. The encoded data is sent into the output layer on a decode path through the portion back to the input layer to obtain a reconstruction of the data by the input layer. A determination is made as to whether an undesired amount of error has occurred in the output layer based on the data sent into the input layer and the reconstruction of the data. A number of new nodes is added to the output layer when a determination is present that the undesired amount of the error occurred, enabling reducing the error using the number of the new nodes.","['G06N3/0454', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/082', 'G06N3/0895', 'G06N3/09']"
US10817318B2,Multitenant hosted virtual machine infrastructure,"A multi-tenant virtual machine infrastructure (MTVMI) allows multiple tenants to independently access and use a plurality of virtual computing resources via the Internet. Within the MTVMI, different tenants may define unique configurations of virtual computing resources and unique rules to govern the use of the virtual computing resources. The MTVMI may be configured to provide valuable services for tenants and users associated with the tenants.","['G06F9/455', 'G06F9/5077', 'G06F21/6218', 'G06F9/45533', 'G06F9/45558', 'G06Q30/02', 'G06Q30/0601', 'G06Q30/0603', 'G06Q40/02', 'H04L63/10', 'G06F2009/45562', 'G06F2009/4557', 'G06F2201/84', 'G06F9/44505']"
CN110543815B,"Training method of face recognition model, face recognition method, device, equipment and storage medium","The application relates to the field of biological recognition, and discloses a face recognition model based on deep learning training. The method comprises the following steps: training a preset convolutional neural network to construct a feature extraction network; establishing connection between the feature extraction network and a preset classification network to obtain a first convolutional neural network model; freezing the weight parameters of the feature extraction network of the first convolutional neural network model; performing iterative training on the classification network in the first convolutional neural network model to obtain a second convolutional neural network model; thawing the characteristic extraction network weight parameters of the second convolutional neural network model; training the unfrozen second convolutional neural network model to obtain a face recognition model. The method can improve the face recognition speed and the stability of the model.","['G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'G06V10/30', 'G06V40/168', 'G06V40/172']"
CN111931664B,"Mixed-pasting bill image processing method and device, computer equipment and storage medium","The invention discloses a processing method, a device, computer equipment and a storage medium for a mixed-pasting bill image, wherein the method comprises the following steps: acquiring a mixed-pasting bill image, wherein the mixed-pasting bill image comprises a plurality of bill objects; dividing the plurality of bill objects from the mixed-pasting bill image to obtain a bill sub-image corresponding to each bill object; determining an image feature vector and a text feature vector corresponding to a bill sub-image, and determining a target bill type according to the image feature vector and the text feature vector corresponding to the bill sub-image; determining a content field area in the bill sub-image and a field type label corresponding to the content field area based on a content field area detection model matched with the target bill type; and identifying the text information in the content field area, and determining the output of the text information according to the field category label corresponding to the content field area. The invention improves the output accuracy and precision of the text information of each bill in the mixed-pasting bill.","['G06V30/40', 'G06F18/214', 'G06F18/22', 'G06F18/24', 'G06N3/045', 'G06V10/44', 'G06V30/153', 'G06V30/10', 'Y02D10/00']"
CN108665481B,Adaptive anti-occlusion infrared target tracking method based on multi-layer deep feature fusion,"The invention discloses a self-adaptive anti-blocking infrared target tracking method with fusion of multilayer depth features, which comprises the following steps of firstly, obtaining a series of multilayer depth feature maps with the same size and different levels; then, converting the multilayer depth feature map from a time domain to a frequency domain according to related filtering, performing filter training and response map calculation according to fast Fourier transform, performing merging and dimension reduction processing on the multilayer depth feature map according to intra-layer feature weighting fusion, constructing feature response maps of different levels, and solving a maximum related response value, namely a target estimation position; finally, extracting dense features of the target, obtaining a maximum feature response value according to the relevant filtering, and obtaining a response confidence coefficient of the central position of the target estimated through the depth convolution features; when the response confidence of the target center position is less than the re-detection threshold T0And then, evaluating the obtained target estimated position through online target re-detection and carrying out self-adaptive updating on the position of the target according to the evaluation result.","['G06T7/246', 'G06N3/045', 'G06V20/42', 'G06T2207/10048']"
US20230281809A1,Connected machine-learning models with joint training for lesion detection,"Embodiments disclosed herein generally relate to connected machine learning models with joint training for lesion detection. Particularly, aspects of the present disclosure are directed to accessing a three-dimensional magnetic resonance imaging (MRI) image, wherein the three-dimensional MRI image depicts a region of a brain of a subject, wherein the region of the brain includes at least a first type of lesions and a second type of lesions; inputting the three-dimensional MRI image into a machine-learning model comprising a first convolutional neural network and a second convolutional neural network; generating a first segmentation mask for the first type of lesions using the first convolutional neural network that takes as input the three-dimensional MRI image; generating a second segmentation mask for the second type of lesions using the second convolutional neural network that takes as input the three-dimensional MRI image; and outputting the first segmentation mask and the second segmentation mask.","['G06T7/0012', 'G06T7/0014', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06T7/0016', 'G06T7/11', 'G06T7/136', 'G06T7/174', 'G06N3/044', 'G06N3/08', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06T2207/30242']"
CN113724695B,"Electronic medical record generation method, device, equipment and medium based on artificial intelligence","The invention relates to the technical field of artificial intelligence, and discloses an electronic medical record generation method, device, equipment and medium based on artificial intelligence, wherein the method comprises the following steps: acquiring inquiry dialogue voice, patient information and doctor identification in a medical record generation request; obtaining dialogue text through voice character segmentation and voice recognition; carrying out key symptom recognition to obtain a concerned text; extracting the main complaint characteristics, identifying a main complaint result according to the extracted main complaint characteristics, and carrying out medical history identification and verification according to patient information to obtain an existing medical history result and a past history result; and generating medical records of the main complaint result, the current medical history result and the past history result through a medical record template generation model to obtain an electronic medical record. Therefore, the invention realizes the automatic generation of the electronic medical record of the patient based on the medical record template customized by the doctor rapidly and accurately, and improves the doctor diagnosis efficiency. The intelligent medical system is suitable for the field of artificial intelligence and can further promote the construction of intelligent medical treatment.","['G10L15/04', 'G10L15/26', 'G10L25/66', 'G16H15/00', 'Y02A90/10']"
CN112221156B,"Data abnormality recognition method, data abnormality recognition device, storage medium, and electronic device","The invention discloses a data anomaly identification method and device, a storage medium and electronic equipment. Wherein, the method comprises the following steps: acquiring a data identification request; responding to the data identification request, and acquiring attribute statistical characteristics and behavior sequence data corresponding to log data, wherein the attribute statistical characteristics comprise characteristics obtained by respectively counting parameter changes of a plurality of attribute parameters associated with the target account in a target time period, and the behavior sequence data comprise time sequence data of behaviors executed by a virtual object controlled by the target account in the target time period; inputting the attribute statistical characteristics into a conversion model to obtain attribute combination characteristics output by the conversion model; and inputting the attribute combination features, the attribute statistical features and the behavior sequence data into the recognition model to obtain a data recognition result output by the recognition model. The invention solves the technical problem of low accuracy of data anomaly identification.","['A63F13/75', 'G06F18/253', 'G06N3/045']"
US20220153262A1,Object detection and collision avoidance using a neural network,"Apparatuses, systems, and techniques to identify objects in view of a camera associated with a vehicle. In at least one embodiment, objects with which a vehicle may collide are identified, based on, for example, a difference between a size of an image of the objects detected at a first point in time and a size of an image of the objects detected at a subsequent point in time.","['G06T7/0002', 'G06V20/58', 'G06T7/70', 'B60W30/09', 'B60W30/0956', 'G01S13/931', 'G01S7/417', 'G06K9/00805', 'G06K9/4671', 'G06N3/045', 'G06N3/084', 'G06T7/11', 'G06T7/20', 'G06T7/60', 'G06V10/462', 'G08G1/165', 'G08G1/166', 'G08G1/167', 'B60W2420/403', 'B60W2420/42', 'B60W2554/40', 'G01S17/931', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241', 'G06T2207/30252', 'G06T2207/30261', 'G06T7/10', 'G06V10/82']"
US20210397793A1,Intelligent Tone Detection and Rewrite,"A method and system for providing tone detection and modification for a content segment may include receiving a request to detect a tone for the content segment, inputting the content segment into a first machine-learning (ML) model to detect the tone for the content segment, obtaining the detected tone as a first output from the first ML model, inputting the content segment into a second ML model for modifying the tone from the detected tone to a modified tone, obtaining at least one rephrased content segment as a second output from the second ML model, the rephrased content segment modifying the tone of the content segment from the detected tone to the modified tone, and providing at least one of the detected tone or the at least one rephrased content segment for display to a user.","['G06F40/253', 'G06F40/30', 'G06F3/0481', 'G06F40/166', 'G06F40/205', 'G06F40/56', 'G06N20/00', 'G06Q10/10', 'G06F40/44']"
US20240347157A1,Method and system for automatically generating a section in a radiology report,A system 100 for automatically generating a field of a radiology report includes a set of one or more models. A method for automatically generating a field of a radiology report includes: receiving a radiologist identifier (radiologist ID); receiving a set of finding inputs; determining a context of each of the set of finding inputs; determining text associated with a portion or all of the radiology report based on the context and the radiologist style; and inserting the text into the report.,"['G16H15/00', 'G16H10/60', 'G16H20/40', 'G16H40/63', 'G16H40/67', 'G16H50/20']"
WO2019223397A1,"Image processing method and apparatus, computer device, and computer storage medium","Provided in the embodiments of the present application are an image recognition method and apparatus, a computer device, and a storage medium, the method comprising: acquiring an image to be recognised; inputting the image to be recognised into a neural network model obtained through training to obtain a recognition result of the image to be recognised, the neural network model being obtained by performing instance normalisation and batch normalisation on a feature map outputted by a convolutional layer in the neural network; and outputting the recognition result of the image to be recognised.","['G06F18/211', 'G06V10/454', 'G06F18/253', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06N3/048', 'G06N3/082']"
CN112767554B,"Point cloud completion method, device, equipment and storage medium","The embodiment of the application discloses a point cloud completion method, a point cloud completion device, point cloud completion equipment and a storage medium in the field of artificial intelligence, wherein the method comprises the following steps: acquiring target original point cloud data to be complemented; generating complete target point cloud data according to the original target point cloud data through a point cloud completion model; the point cloud completion model is a student network model in a teacher student network model, and the teacher student network model is obtained by training original point cloud data and standard point cloud data corresponding to a training scanning target; performing densification processing on the target point cloud data set to obtain target completion point cloud data; the target point cloud data set comprises the target complete point cloud data. The method can recover complete and dense point cloud data based on the original point cloud data.","['G06T17/20', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T5/70']"
US20210158561A1,Image volume for object pose estimation,"Apparatuses, systems, and techniques estimate a pose of an object based on images generated from a combined image volume. In at least one embodiment, the combined image volume is obtained from a plurality of image volumes generated based on a plurality of images of an object.","['G06T7/55', 'G06T7/70', 'B25J9/1612', 'B25J9/1697', 'G06T15/08', 'G06T15/20', 'G06T3/0031', 'G06T3/06', 'G06T7/0004', 'G06T7/0012', 'G06T7/11', 'G06T7/593', 'G06T7/74', 'G05B2219/39057', 'G05B2219/40584', 'G05B2219/40613', 'G06T2207/10021', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
CN111695562B,Autonomous robot grabbing method based on convolutional neural network,"The invention discloses a robot autonomous grabbing method based on a convolutional neural network, which comprises the following steps: firstly, constructing a grabbing detection model, and training through a large amount of data sets to obtain a feature extractor with stronger robustness and better generalization capability; acquiring a scene image containing an object to be grabbed and sending the scene image into a grabbing detection model to obtain a grabbing frame of the object to be grabbed in an image space; and obtaining a final grabbing pose according to the conversion relation among the coordinate systems in the grabbing process of the robot, and controlling the mechanical arm to reach the designated pose to finish the autonomous grabbing operation. The invention brings the idea of cross-scale detection into the recognition of the grabbing frame, and improves the detection effect under different scales. Meanwhile, the prediction of the direction angle of the grabbing frame is converted into the combination of classification and regression, the multi-angle grabbing performance is improved, the accuracy of the algorithm is improved, and the autonomous grabbing performance of the robot in an unstructured environment is effectively improved.","['G06V10/25', 'G06F18/214', 'G06N3/045', 'G06T7/77', 'G06V10/44', 'G06V20/10', 'G06T2207/20081', 'G06T2207/20084']"
US20220067521A1,Robustness enhancement for face recognition,Methods and systems for enhancing a neural network include detecting an occlusion in an input image using a trained occlusion detection neural network. The detected occlusion is replaced in the input image with a neutral occlusion to prevent the detected occlusion from frustrating facial recognition to generate a modified input image. Facial recognition is performed on the modified input image using a trained facial recognition neural network.,"['G06N3/08', 'G06V40/171', 'G06F18/2163', 'G06F18/28', 'G06K9/00281', 'G06K9/00288', 'G06K9/2054', 'G06K9/6261', 'G06N3/045', 'G06N3/084', 'G06V10/22', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/172']"
US20220051094A1,Mesh based convolutional neural network techniques,"Convolutional operators for triangle meshes are determined to construct one or more neural networks. In at least one embodiment, convolutional operators, pooling operators, and unpooling operators are determined to construct the one or more neural networks, in which the same learned weights from the one or more neural networks can further be used for triangle meshes with different topologies.","['G06N3/08', 'G06N3/084', 'G06N3/04', 'G06N3/045', 'G06T17/205']"
US20210278478A1,Deep parallel fault diagnosis method and system for dissolved gas in transformer oil,"The disclosure provides a deep parallel fault diagnosis method and system for dissolved gas in transformer oil, which relate to the field of power transformer fault diagnosis. The deep parallel fault diagnosis method includes: collecting monitoring information of dissolved gas in each transformer substation and performing a normalizing processing on the data; using the dissolved gas in the oil to build feature parameters as the input of the LSTM diagnosis model, and performing image processing on the data as the input of the CNN diagnosis model; building the LSTM diagnosis model and the CNN diagnosis model, respectively, and using the data set to train and verify the diagnosis models according to the proportion; and using the DS evidence theory calculation to perform a deep parallel fusion of the outputs of the softmax layers of the two deep learning models.","['G01R31/00', 'G01N33/0004', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G01R31/62', 'G06N3/044', 'G06N3/0445', 'Y04S10/50']"
US12039456B2,Electronic device and controlling method thereof,"An electronic device and a controlling method thereof are provided. A controlling method of an electronic device according to the disclosure includes: performing first learning for a neural network model for acquiring a video sequence including a talking head of a random user based on a plurality of learning video sequences including talking heads of a plurality of users, performing second learning for fine-tuning the neural network model based on at least one image including a talking head of a first user different from the plurality of users and first landmark information included in the at least one image, and acquiring a first video sequence including the talking head of the first user based on the at least one image and pre-stored second landmark information using the neural network model for which the first learning and the second learning were performed.","['G06N3/088', 'G06F16/70', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V40/00', 'G06V40/168', 'G06V40/169', 'G06V40/172', 'G06V40/179', 'G06V40/20', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
WO2021143018A1,"Intention recognition method, apparatus, and device, and computer readable storage medium","An intention recognition method, apparatus, and device, and a computer readable storage medium, relating to the technical field of artificial intelligence. The method comprises: performing word vector feature extraction on an unlabeled text by means of a first language model to obtain an unlabeled feature, and according to the unlabeled feature, annotating the unlabeled text to obtain an annotated training text (S10); constructing an attention neural network model on the basis of a second language model and the annotated training text (S20); obtaining a text to be recognized, and by means of the attention neural network model, performing feature extraction on the text to be recognized, so as to obtain a candidate feature set (S30); and calculating, according to the candidate feature set, the similarity of the text to be recognized, and according to the similarity, determining whether the text to be recognized corresponds to the same expression intention, so as to obtain an intention recognition result (S40). Feature extraction is performed in a neural network mode, and thus, the present invention can more comprehensively consider text features, and improve the accuracy of intention recognition.",['G06N3/08']
CN113590876B,"Video tag setting method and device, computer equipment and storage medium","The embodiment of the application discloses a method, a device, computer equipment and a storage medium for setting video tags, which can extract audio and video time sequence characteristic information and target text characteristic information of a video to be processed, and fuse the audio and video time sequence characteristic information and the target text characteristic information to obtain first fused characteristic information; acquiring multi-mode aggregation characteristics of the video to be processed according to the first fused characteristic information; extracting audio and video aggregation characteristic information of the video to be processed, and fusing the audio and video aggregation characteristic information and target text characteristic information to obtain second fused characteristic information; determining category information of the video to be processed according to the second fused characteristic information; screening videos matched with the category information from a preset video database to obtain a target candidate video set; the method has the advantages that the labels are set for the videos to be processed based on the similarity between the videos in the target candidate video set and the videos to be processed, which are acquired based on the multi-mode aggregation characteristics, and the accuracy of setting the labels of the videos is improved.","['G06F16/7867', 'G06F16/75', 'G06F16/7834', 'G06F16/7844']"
CN111177374B,Question-answer corpus emotion classification method and system based on active learning,"The invention discloses a question-answer corpus emotion classification method and a system based on active learning, comprising the following steps: word segmentation is carried out on training sentences in a corpus, TF-IDF values are determined, sentence phasor samples are constructed according to the TF-IDF values, and training data are determined; training the training data with the artificial annotation data set, the pseudo tag data set and the similar data set respectively to obtain an artificial annotation classifier, a pseudo tag classifier and a similar classifier; performing unsupervised clustering on unlabeled data in the training data, adding similar data into a similar data set, and retraining a similar classifier; classifying unlabeled data by using a manual labeling classifier, a pseudo-label classifier and a similar classifier respectively, and updating a voting data set, a pseudo-label data set and an unlabeled data set according to a voting strategy; training the comprehensive classifier by utilizing the voting data set and the manual annotation data set; and determining sentence phasors according to the corpus to be classified, and determining emotion classification results by using the trained comprehensive classifier.","['G06F16/35', 'G06F16/3334', 'G06F16/3346']"
US11923068B2,"Systems and methods for surgical and interventional planning, support, post-operative follow-up, and functional recovery tracking","Various systems and methods are provided for surgical and interventional planning, support, post-operative follow-up, and functional recovery tracking. In general, a patient can be tracked throughout medical treatment including through initial onset of symptoms, diagnosis, non-surgical treatment, surgical treatment, and recovery from the surgical treatment. In one embodiment, a patient and one or more medical professionals involved with treating the patient can electronically access a comprehensive treatment planning, support, and review system. The system can provide recommendations regarding diagnosis, non-surgical treatment, surgical treatment, and recovery from the surgical treatment based on data gathered from the patient and the medical professional(s). The system can manage the tracking of multiple patients, thereby allowing for data comparison between similar aspects of medical treatments and for learning over time through continual data gathering, analysis, and assimilation to decision-making algorithms.","['G16H30/20', 'A61B17/02', 'A61B17/025', 'A61B17/50', 'A61B34/10', 'A61B34/20', 'A61B34/25', 'A61B5/0022', 'A61B5/1118', 'A61B5/4509', 'A61B5/4566', 'A61B5/4571', 'A61B5/4824', 'A61B5/4833', 'A61B5/4848', 'A61B5/7282', 'A61B5/742', 'A61B5/746', 'A61B5/7475', 'A61B6/485', 'A61B8/08', 'G01L5/00', 'G06Q10/00', 'G06Q10/10', 'G09B23/28', 'G16H10/20', 'G16H20/40', 'G16H40/20', 'G16H40/40', 'G16H40/63', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G16H70/20', 'G16Z99/00', 'A61B2010/009', 'A61B2010/0093', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/0262', 'A61B2034/101', 'A61B2034/105', 'A61B2034/2051', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/252', 'A61B2034/254', 'A61B2034/256', 'A61B2090/365', 'A61B2090/502', 'A61B6/4494', 'A61B6/506', 'A61B90/98']"
US11847538B2,Differential privacy dataset generation using generative models,"Apparatuses, systems, and techniques to train a generative model based at least in part on a private dataset. In at least one embodiment, the generative model is trained based at least in part on a differentially private Sinkhorn algorithm, for example, using backpropagation with gradient descent to determine a gradient of a set of parameters of the generative models and modifying the set of parameters based at least in part on the gradient.","['G06N20/00', 'G06F21/6245', 'G06F18/214', 'G06F21/6218', 'G06N3/045', 'G06N3/0475', 'G06N3/061', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06V10/774', 'G06V10/82', 'G06N3/044', 'G06N3/063', 'G06V20/56']"
CN114387520B,Method and system for accurately detecting compact Li Zijing for robot picking,"The invention discloses a compact Li Zijing quasi-detection method and a system for robot picking, wherein the method comprises the following steps: an image of fruit in an orchard is acquired through image acquisition equipment; performing inspection treatment to obtain a target detection image meeting the requirements; carrying out data annotation on fruits with different maturity on the target detection image to obtain an annotation image; dividing the labeling image into a training set and a testing set according to a proportion, and obtaining the number of mature proportion fruits in the training set; judging whether data balance processing is needed according to the fruit ripening proportion in the training set; carrying out data enhancement processing on the balance training set data; improving the target detection model; training and predicting the data enhancement training set by improving the target detection model to obtain a detection result; the deep learning model is applied to identifying and picking plums, can be deployed on a robot picking platform, and provides technical support for estimating the yield of an orchard and researching a picking robot.","['G06F18/241', 'G06F18/2415', 'G06F18/253', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/082', 'G06T7/0002', 'G06T7/90']"
CN110852087B,"Chinese error correction method and device, storage medium and electronic device","The invention discloses a Chinese error correction method and device, a storage medium and an electronic device. Wherein, the method comprises the following steps: acquiring candidate words from the candidate word list according to the target words in the statement to be corrected, and replacing the target words in the statement to be corrected with the candidate words; calculating a first confusion index PPL value of a sentence to be corrected before replacement and a second confusion index PPL value of characters in a short sentence to be corrected after replacement; under the condition that the difference value between the first PPL value and the second PPL value is smaller than a first threshold value, acquiring the position of a suspected wrongly-written word in a statement to be corrected; replacing the characters marked with the suspected wrongly written character positions with the predicted characters, and calculating the probability of the predicted characters in the target sentence; and replacing the suspected wrongly-written words with the predicted words when the probability is larger than a second threshold value. The invention solves the technical problems that the error correction mode for the sentences is single, and the error correction cannot be realized quickly and effectively in the prior art.",[]
US12387481B2,Enhanced object identification using one or more neural networks,"Apparatuses, systems, and techniques to identify one or more objects in one or more images. In at least one embodiment, one or more objects are identified in one or more images based, at least in part, on a likelihood that one or more objects is different from other objects in one or more images.","['G06V20/10', 'G06F17/18', 'G06F18/24', 'G06F18/2413', 'G06F18/2415', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06T11/20', 'G06V10/25', 'G06V10/764', 'G06T2210/12']"
US11928764B2,Neural network motion controller,"Apparatuses, systems, and techniques to animate objects in computer-generated graphics. In at least one embodiment, one or more neural networks are trained to identify one or more forces to be applied to one or more objects based, at least in part, on training data corresponding to two or more aspects of motion of the one or more objects.","['G06T13/20', 'G06N3/061', 'G06V10/82', 'G06T13/40', 'G06F18/211', 'G06F18/2148', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N5/046', 'G06T7/20', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30248', 'G06T2210/28']"
AU2022202661B2,Techniques for parallel execution,"OF DISCLOSURE Apparatuses, systems, and techniques to identify instructions for advanced execution. In at least one embodiment, a processor performs one or more instructions that have been identified by a compiler to be speculatively performed in parallel. 213","['G06F9/4881', 'G06F9/3842', 'G06F9/3885', 'G06F8/41', 'G06F8/4441', 'G06F8/445', 'G06F8/452', 'G06F9/28', 'G06F9/30058', 'G06F9/3851', 'G06F9/3888', 'G06F9/5038', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N5/04']"
US20230188612A1,Intelligent reasoning framework for user intent extraction,"Embodiments of the present systems and methods may provide an intelligent systems framework for analysis of user-generated content from various capture points to determine user intent. For example, a method may be implemented in a computer system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor, the method may comprise receiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices, extracting, at the computer system, from the received data, features relevant to events relating to at least one person, extracting, at the computer system, at least one intent of at least one event relating to at least one person, and performing, at the computer system, an action based on the extracted at least one intent.","['G06F16/5854', 'G06F16/9535', 'G06N20/00', 'G06N5/022', 'G06N5/025', 'G06N5/041', 'H04L12/2829', 'H04L67/306', 'H04L67/535', 'G06N3/006', 'G06N3/042', 'G06N5/043', 'G06N7/01', 'G08B19/00']"
US12373484B2,Multimodal semantic analysis and image retrieval,Systems and methods are provided for identifying and retrieving semantically similar images from a database. Semantic analysis is performed on an input query utilizing a vision language model to identify semantic concepts associated with the input query. A preliminary set of images is retrieved from the database for semantic concepts identified. Relevant concepts are extracted for images with a tokenizer by comparing images against a predefined label space to identify relevant concepts. A ranked list of relevant concepts is generated based on occurrence frequency within the set. The preliminary set of images is refined based on selecting specific relevant concepts from the ranked list by the user by combining the input query with the specific relevant concepts. Additional semantic analysis is iteratively performed to retrieve additional sets of images semantically similar to the combined input query and selection of the specific relevant concepts until a threshold condition is met.,"['G06F16/538', 'G06F16/532', 'G06F40/30', 'G06V10/40', 'G06V10/761', 'G06V10/945']"
US20220284327A1,"Resource pushing method and apparatus, device, and storage medium","This application discloses a resource pushing method performed by a computer device. The method includes: obtaining a target recommendation model and a preference feature and a candidate resource set corresponding to a target object, the preference feature including at least a channel preference feature and a content preference feature; obtaining at least one target resource from the candidate resource set based on the target recommendation model and the preference feature; and pushing the at least one target resource to the target object. Such a resource pushing process integrates preferences of the target object in different dimensions, so that the target resource pushed to the target object not only conforms to channel preferences of the target object, but also conforms to content references of the target object, which is beneficial to improving the resource pushing effect, and further increasing the click-through rates (CTRs) of the pushed resources.","['G06N5/04', 'G06N3/08', 'G06F16/9535', 'G06N3/006', 'G06N3/04', 'G06N5/022', 'G06N7/01']"
US12059619B2,"Information processing method and apparatus, computer readable storage medium, and electronic device","Embodiments of this application relate to the field of artificial intelligence technologies, and in particular, to an information processing method, an information processing apparatus, a computer readable storage medium, and an electronic device. The information processing method includes: determining, by a device, a subject in a game scenario, and acquiring an action model used for controlling the subject to execute a game action; performing, by the device, feature extraction on the game scenario to obtain model game state information related to the subject; performing, by the device, mapping processing on the model game state information by using the action model, to obtain model game action selection information corresponding to at least two candidate game actions; and selecting, by the device according to the model game action selection information, a model game action for the subject from the at least two candidate game actions.","['A63F13/60', 'A63F13/35', 'A63F13/45', 'A63F13/56', 'A63F13/67', 'A63F13/69', 'A63F13/79', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/0499', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N5/01', 'A63F2300/5546']"
US12374317B2,System and method for using gestures and expressions for controlling speech applications,"Methods and systems are provided for detecting and processing gestures, expressions (e.g., facial), tone and/or gestures of the user for the purpose of improving the quality and speed of interactions with computer-based systems. Such information may be detected by one or more sensors such as, for example, electromyography (EMG) sensors used to monitor and record electrical activity produced by muscles that are activated. Other sensor types may be used, such as optical, inertial measurement unit (IMU), or other types of bio-sensors. The system may use one or more sensors to detect speech alone or in combination with gestures, expressions (e.g., facial), tone and/or gestures of the user to provide input or control of the system.","['G10L13/027', 'G06F3/011', 'G06F3/012', 'G06F3/015', 'G06F3/017', 'G06N20/00', 'G06N3/092', 'G10L13/033', 'G10L13/047', 'G10L15/06', 'G10L15/18', 'G10L15/22', 'G10L15/24', 'G10L15/25', 'G10L19/012', 'G10L19/04', 'G10L25/18', 'G10L25/78', 'G06F2203/011', 'G10L2015/223']"
CN111625361B,A joint learning framework based on cloud server and IoT device collaboration,"The invention discloses a joint learning framework based on the cooperation of a cloud server and IoT equipment, which is characterized in that the joint learning framework based on the cooperation of the cloud server and the IoT equipment adopts a distributed AI system architecture and specifically comprises the following steps: the method comprises the steps of cloud offline training, ioT device and cloud collaborative online joint training, ioT device and cloud collaborative reasoning and the like. Compared with the prior art, the method and the device have the advantages that the method and the device are suitable for different IoT use environments or use preferences of users, better performance effects of the local device model and the cloud model are achieved, the prediction accuracy and the average inference execution time of the neural network in the IoT device are effectively improved, meanwhile, the data privacy of the local device user is protected, and the method and the device are particularly suitable for being used in distributed application scenes with diversified data distribution.","['G06F9/5072', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'H04L67/12']"
CN110796031B,Table identification method and device based on artificial intelligence and electronic equipment,"The present disclosure provides an artificial intelligence based form recognition method, an artificial intelligence based form recognition device and an electronic device, and mainly relates to techniques such as computer vision, natural language processing, machine learning, etc. The method comprises the following steps: image segmentation is carried out on the image to be identified based on image semantics to obtain a foreground line image; determining a plurality of table cells according to the line relation in the foreground line image, and establishing a spreadsheet according to the plurality of table cells; performing text recognition on the image to be recognized to obtain text information in the image to be recognized; and filling the text information into the electronic table according to the position of the text information in the image to be identified and the position of the table cell in the electronic table. The method can avoid mutual interference of the table structure and the table content in the identification process by dividing, identifying and recombining the table structure and the table content, thereby improving the identification accuracy of the table.","['G06V30/412', 'G06V30/414']"
US8849259B2,Image processing architectures and methods,"Cell phones and other portable devices are equipped with a variety of technologies by which existing functionality is improved, and new functionality is provided. Some aspects relate to imaging architectures, in which a cell phone's image sensor is one in a chain of stages that successively act on instructions/data, to capture and later process imagery. Other aspects relate to distribution of processing tasks between the device and remote resources (“the cloud”). Elemental image processing, such as filtering and edge detection—and even some simpler template matching operations—may be performed on the cell phone. Other operations are referred out to remote service providers. The remote service providers can be identified using techniques such as a reverse auction, though which they compete for processing tasks. Other aspects of the disclosed technologies relate to visual search capabilities, and determining appropriate actions responsive to different image inputs. Still others concern metadata generation, processing, and representation. A great number of other features and arrangements are also detailed.","['H04W4/001', 'G06F16/50', 'G06F17/30244', 'G06F18/40', 'G06K9/00288', 'G06K9/00577', 'G06K9/228', 'G06K9/4604', 'G06K9/4647', 'G06K9/4652', 'G06K9/4671', 'G06K9/6253', 'G06V10/44', 'G06V10/462', 'G06V10/507', 'G06V10/56', 'G06V10/945', 'G06V20/80', 'G06V30/142', 'G06V40/172', 'H04M1/0202', 'H04M1/0264', 'H04N1/2133', 'H04N23/611', 'H04N23/64', 'H04W4/50', 'H04N1/00307', 'H04N1/32101', 'H04N2101/00', 'H04N2201/3225', 'H04N2201/3274', 'H04N2201/3278']"
US11842495B2,Systems and methods for transparent object segmentation using polarization cues,"A computer-implemented method for computing a prediction on images of a scene includes: receiving one or more polarization raw frames of a scene, the polarization raw frames being captured with a polarizing filter at a different linear polarization angle; extracting one or more first tensors in one or more polarization representation spaces from the polarization raw frames; and computing a prediction regarding one or more optically challenging objects in the scene based on the one or more first tensors in the one or more polarization representation spaces.","['G06T7/11', 'B25J9/1697', 'G05B13/027', 'G06F18/214', 'G06F18/23', 'G06F18/253', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06T3/02', 'G06T7/174', 'G06V10/147', 'G06V10/26', 'G06V10/454', 'G06V10/60', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V20/50', 'G06V20/60', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
CN111324774B,Video duplicate removal method and device,"The application discloses a video duplicate removal method and a video duplicate removal device; the method comprises the steps of determining at least one initial similar video from original videos; adjusting the original size of a video frame in the at least one initial similar video to a first preset size to obtain at least one first adjusted video; determining an intermediate similar video from the at least one first adjusted video based on video frame similarity between corresponding video frames in every two first adjusted videos; adjusting the original size of the video frame in the intermediate similar video to a second preset size to obtain at least one second adjusted video; determining a target similar video from the at least one second adjusted video based on the video frame similarity between corresponding video frames in every two second adjusted videos; and carrying out duplicate removal processing on the original video based on the target similar video to obtain a duplicate-removed video. According to the method, the efficiency of video duplicate removal can be improved by improving the method for identifying the repeated video.","['G06F16/783', 'G06F16/7844', 'G06F18/22', 'G06V20/46']"
US20210086089A1,Player analysis using one or more neural networks,"Apparatuses, systems, and techniques are presented to determine feedback for a user. In at least one embodiment, feedback is provided to one or more players of a game to help those players improve their performance playing the game.","['G06N3/02', 'A63F13/67', 'A63F13/79', 'A63F13/422', 'A63F13/50', 'A63F13/58', 'A63F13/85', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'A63F2300/5546', 'G06N20/00', 'G06N20/10', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N7/01']"
US10289909B2,Conditional adaptation network for image classification,"A method and apparatus for classifying an image. In one example, the method may include receiving one or more images associated with a source domain and one or more images associated with a target domain, identifying one or more source domain features based on the one or more images associated with the source domain, identifying one or more target domain features based on the one or more images associated with the target domain, training a conditional maximum mean discrepancy (CMMD) engine based on a difference between the one or more source domain features and the one or more target domain features, applying the CMMD engine to the one or more images associated with the target domain to generate one or more labels for each unlabeled target image of the one or more images associated with the target domain and classifying each one of the one or more images in the target domain using the one or more labels.","['G06K9/00624', 'G06V10/454', 'G06F18/217', 'G06F18/24133', 'G06K9/4628', 'G06K9/6262', 'G06K9/6271', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V20/00']"
CN112163122B,"Method, device, computing equipment and storage medium for determining label of target video","The application discloses a method, a device, a computing device and a computer readable storage medium for determining a label of a target video. The method comprises the following steps: determining a feature vector of the target video; determining similar videos of the target video from at least one existing video based on the feature vector of the target video and the feature vector of the at least one existing video, wherein the similarity of the similar videos and the target video is larger than a preset similarity threshold value, and each at least one existing video is provided with at least one label; and determining the label of the target video based on the labels of the similar videos. The method can improve the accuracy of the label determined for the target video, improve the efficiency of the label determining process and reduce the cost.","['G06F16/784', 'G06F16/7867', 'G06F16/9535']"
US11657263B2,Neural network based determination of gaze direction using spatial models,"Systems and methods for determining the gaze direction of a subject and projecting this gaze direction onto specific regions of an arbitrary three-dimensional geometry. In an exemplary embodiment, gaze direction may be determined by a regression-based machine learning model. The determined gaze direction is then projected onto a three-dimensional map or set of surfaces that may represent any desired object or system. Maps may represent any three-dimensional layout or geometry, whether actual or virtual. Gaze vectors can thus be used to determine the object of gaze within any environment. Systems can also readily and efficiently adapt for use in different environments by retrieving a different set of surfaces or regions for each environment.","['G06N3/08', 'G06F18/214', 'G06F18/2193', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06T17/00', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V10/95', 'G06V20/597', 'G06V20/647', 'G06V40/171', 'G06V40/193', 'G06T2207/30252', 'G06T2207/30268']"
CN113128442B,Chinese character handwriting style identification method and scoring method based on convolutional neural network,"The invention relates to a handwriting style identification method based on a convolutional neural network. The handwriting style identification method based on the convolutional neural network comprises the following steps: acquiring a calligraphy work image; preprocessing the calligraphic work image to identify each single-word image; inputting the single-word images into a handwriting font style recognition model to obtain handwriting font style recognition results of each single word; the handwriting style recognition model is a ResNet neural network and comprises a first convolution layer, a first pooling layer, 4 convolution layers realized based on Bottleneck residual blocks, a global average pooling layer, 2 full-connection layers and a softmax layer. The handwriting style identification method based on the convolutional neural network has the advantages of high identification accuracy and less calculation amount. The invention also provides a Chinese character handwriting scoring method based on the convolutional neural network, which integrates font style identification, handwriting content identification and handwriting Chinese character aesthetic feeling scoring, and has more comprehensive functions.","['G06V30/2264', 'G06F18/214', 'G06F18/22', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06V10/242', 'G06V10/267']"
US20210383533A1,Machine-learning-based object detection system,"In at least one embodiment, an object detection system uses a neural network to identify and/or locate a set of organs in a medical image. In at least one embodiment, when training to identify and/or locate a particular organ, a subset of incompletely-labeled training images is used that excludes training images for which labels associated with particular organ are unavailable.","['G06V20/64', 'G06F18/24133', 'G06F18/2431', 'G06N5/04', 'G06T11/20', 'G06T7/0012', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2210/12', 'G06V2201/03', 'G06V2201/031']"
US12321863B2,Attention filtering for multiple instance learning,"Method(s), apparatus, and system(s) are provided for filtering a set of data, the set of data comprising multiple data instances by: receiving a set of scores for the set of data; determining attention filtering information based on prior knowledge of one or more relationships between the data instances in said set of data and calculating attention relevancy weights corresponding to the data instances and the set of scores; and providing the attention filtering information to a machine learning, ML, technique or ML model.","['G06N5/022', 'G06F16/9024', 'G06F17/16', 'G06N20/00', 'G06N3/04', 'G06N3/08', 'G06N3/0895', 'G06N3/09']"
CN110992329B,"Product surface defect detection method, electronic equipment and readable storage medium","The invention discloses a product surface defect detection method, electronic equipment and a readable storage medium, wherein the detection method comprises the following steps: s1: acquiring an image of a product to be detected; s2: inputting the image of the product to be tested into a first processing module and a second processing module for parallel operation; if the first processing module and the second processing module are both judged to be good, judging that the product to be detected is the good, and if at least one of the first processing module and the second processing module judges that the product to be detected is suspected defective, entering step S3; s3: and rechecking the suspected defect product. The detection method provided by the invention improves the detection efficiency, reduces the probability of misjudging the defective product as a good product, and further solves the problems of classification of the defective product and the good product under a small data set and accurate positioning of defective points.","['G06T7/0004', 'G06N3/045', 'G06N3/08', 'G06T7/187', 'G06T7/62', 'G06T2207/20024', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'Y02P90/30']"
US11829727B2,Cross-lingual regularization for multilingual generalization,"Approaches for cross-lingual regularization for multilingual generalization include a method for training a natural language processing (NLP) deep learning module. The method includes accessing a first dataset having a first training data entry, the first training data entry including one or more natural language input text strings in a first language; translating at least one of the one or more natural language input text strings of the first training data entry from the first language to a second language; creating a second training data entry by starting with the first training data entry and substituting the at least one of the natural language input text strings in the first language with the translation of the at least one of the natural language input text strings in the second language; adding the second training data entry to a second dataset; and training the deep learning module using the second dataset.","['G06F40/58', 'G06F40/51', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/08', 'G06N3/09', 'G06N3/096']"
US20220358627A1,High dynamic range image processing with fixed calibration settings,"In various examples, apparatuses, systems, and techniques to perform offline image signal processing of source image data to generate target image data. In at least one embodiment, data collection using exposure and calibration setting of an image sensor is performed to generate source image data, which is then processed by using offline image signal processing to generate target data.","['H04N5/77', 'G06T5/90', 'G06T5/92', 'G06T5/009', 'G06F9/3887', 'G06N3/08', 'G06N3/084', 'G06T1/20', 'G06T5/50', 'G06T5/60', 'H04N23/741', 'H04N5/2355', 'H04N5/91', 'G06N3/063', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208', 'G06T2207/30252']"
CN110704641B,"Ten-thousand-level intention classification method and device, storage medium and electronic equipment","The application relates to the technical field of artificial intelligence, and provides a ten-thousand-level intention classification method, a ten-thousand-level intention classification device, a storage medium and electronic equipment. The ten-thousand-level intention classification method comprises the following steps: obtaining a conversation sentence of at least one round of conversation with a user; performing context analysis on the conversation sentences to complement the context information of the conversation; performing semantic analysis on the spoken sentence to obtain a plurality of candidate intentions of the user; and determining the real intention of the user by using an intention decision model constructed based on a reinforcement learning algorithm based on the candidate intentions and the complemented conversation context information. The method is realized based on a brand-new three-layer man-machine conversation technical framework, a plurality of candidate intents are obtained through semantic analysis in a semantic understanding layer, the complemented context information is obtained through context analysis in a logic reasoning layer, dynamic decision is carried out according to the candidate intents and the complemented context information by utilizing an intention decision model in a decision judging layer, and the accuracy of intention classification is high.","['G06F16/367', 'G06F16/35']"
CN111680176B,Remote sensing image retrieval method and system based on attention and bidirectional feature fusion,"The invention provides a remote sensing image retrieval method and a remote sensing image retrieval system based on attention and bidirectional feature fusion, wherein the remote sensing image retrieval method comprises the steps of inputting training data, including remote sensing images of different categories; constructing and training a deep hash network integrating an attention mechanism and high-low order bidirectional features; in the deep hash network, randomly sampled paired remote sensing images are input, convolution layer processing is respectively carried out to obtain convolution features, attention mechanism processing is carried out on the convolution features of different layers to obtain attention features, bidirectional feature fusion is carried out on the attention features of a lower layer and a higher layer, the fused features are subjected to full-connection dimension reduction to obtain hash features, and then hash codes of the images are obtained through quantization; when the network is trained, calculating weighted cross entropy loss and classification loss according to the hash characteristics, and updating network parameters; and introducing category information as the weight of Hamming distance measurement, and realizing remote sensing image retrieval based on a training obtained network. The invention can obtain good effect when applied to remote sensing image retrieval.","['G06F16/53', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
CN114972418B,Mobile multi-target tracking method based on kernel adaptive filtering and YOLOX detection,"The invention discloses a maneuvering multi-target tracking method based on combination of kernel adaptive filtering and YOLOX detection. Firstly, initially detecting a current frame target of a video sequence by using a target detection network based on YOLOX to obtain a detection result; further using a core self-adaptive filter as a nonlinear tracker, and predicting the position and size state information of the current frame of the target by taking the history position and size state information of the target as input to obtain a prediction result; then, performing first re-matching on the detection result and the prediction result by utilizing the motion similarity and the appearance similarity; carrying out second matching on the result which is not successfully matched by adopting the color space feature similarity; in order to further enhance the matching accuracy, the result which is not successfully matched is continuously subjected to third re-matching by adopting a complete cross-correlation ratio index CIoU, so that the tracking of all targets of the current frame is completed, and the continuous detection and tracking of multiple targets in the whole video sequence are completed by continuously cycling the above processes.","['G06T7/246', 'G06N3/045', 'G06N3/084', 'G06T7/269', 'G06T7/90', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06V20/46', 'G06T2207/10016', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/07']"
US12318189B2,"Apparatus, systems, and methods for gathering and processing biometric and biomechanical data","Apparatus, systems, and methods are provided for measuring and analyzing movements of a body and for communicating information related to such body movements over a network. In certain embodiments, a system gathers biometric and biomechanical data relating to positions, orientations, and movements of various body parts of a user performed during sports activities, physical rehabilitation, or military or law enforcement activities. The biometric and biomechanical data can be communicated to a local and/or remote interface, which uses digital performance assessment tools to provide a performance evaluation to the user. The performance evaluation may include a graphical representation (e.g., a video), statistical information, and/or a comparison to another user and/or instructor. In some embodiments, the biometric and biomechanical data is communicated wirelessly to one or more devices including a processor, display, and/or data storage medium for further analysis, archiving, and data mining. In some embodiments, the device includes a cellular telephone.","['A61B5/11', 'A61B5/1124', 'A61B5/22', 'A61B5/6802', 'A61B5/6804', 'A63B24/0006', 'A61B2562/0219', 'A61B5/1114', 'A61B5/1127', 'A61B5/4528', 'A61B5/6824', 'A61B5/7405', 'A63B2024/0012', 'A63B2209/08', 'A63B2209/10', 'A63B2220/10', 'A63B2220/13', 'A63B2220/24', 'A63B2220/30', 'A63B2220/40', 'A63B2220/803', 'A63B2220/836', 'A63B2225/20', 'A63B2225/50', 'A63B24/0062', 'A63B5/11', 'A63B69/3608', 'A63B69/3667', 'G06F3/011', 'G06V40/23', 'G16H20/30', 'G16H40/67', 'G16H80/00']"
CN111563502B,"Image text recognition method and device, electronic equipment and computer storage medium","The application provides a text recognition method and device for an image, electronic equipment and a computer readable storage medium, and relates to the field of image processing. The method comprises the following steps: receiving an image to be detected; calling the trained character recognition model to process the image to be detected, or inputting the image to be detected into the character recognition model, so that the character recognition model generates at least two anchor frames with different inclination angles in the image to be detected based on the inclination angles in the preset anchor frame parameters; determining a region to be identified containing at least one keyword character in the image based on each anchor frame with different inclination angles; identifying at least one keyword character in the area to be identified, and performing mask processing on the area to be identified and each keyword character to generate labeling information of the area to be identified and each keyword character; and displaying the recognized keyword characters and the recognized labeling information in the image to be detected. The application effectively improves the character recognition precision.","['G06V10/25', 'G06F18/214', 'G06V10/242', 'G06V30/153', 'G06V30/10']"
US12204578B2,Machine learning based database search and knowledge mining,"Disclosed herein are embodiments of systems, methods, and products comprises a server for database search and knowledge mining. The server may learn different table's semantics, relationships, and usage by parsing historical query logs and analyzing tables' metadata (e.g., table descriptions). The analytic server may generate a graph database based on the table relationships obtained from the parsing. The graph database may be a relationship graph where tables are the nodes and edges represent the relationships among tables. When the server receives a query, the server extract semantics of the query, and return a set of tables that are semantically similar to the query. The set of tables may be a list of tables whose semantic similarities with the query satisfies a threshold. The analytic server may further generate a graph including the list of tables to show the relationships of these tables.","['G06F16/367', 'G06F16/3334', 'G06F16/3347', 'G06F16/9024', 'G06F18/22', 'G06F40/205', 'G06F40/30', 'G06N20/00', 'G06N3/045', 'G06N3/09', 'G06N3/096', 'G06N5/022']"
US11521326B2,Systems and methods for monitoring and evaluating body movement,"The present disclosure relates to systems and methods for analyzing and evaluating movement of a subjects and providing feedback. In some embodiments, a method comprises receiving one or more images of a body of the subject captured during performance of a physical movement by the subject; computing a model descriptive of positions and orientations of body parts of the subject based on the one or more images; generating a comparison of the positions and orientations to target positions and target orientations, respectively, for the physical movement; and generating a recommendation based on the comparison.","['G09B19/0038', 'G06F18/2413', 'G06F21/316', 'G06F21/32', 'G06N3/0464', 'G06N3/096', 'G06N3/0985', 'G06T7/251', 'G06T7/97', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/40', 'G06V40/20', 'G06N3/045', 'G06N3/08', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/30196', 'G06T2207/30221', 'G06T2207/30232', 'G06V40/172']"
CN111052144B,Attribute perception zero sample machine vision system by joint sparse representation,"A system for object recognition is described. The system generates a training image set of object images from a plurality of image classes. Using the training image set and annotated semantic attributes, a model is trained that maps visual features from known images to annotated semantic attributes using joint sparse representations of dictionaries about the visual features and semantic attributes. Visual features of an input image that have not been seen are mapped to semantic attributes of the image using the trained model. Classifying the unseen input image as belonging to an image class, and controlling the device based on the classification of the unseen input image.","['G06V20/56', 'G06F18/21345', 'G06V20/70', 'G06V2201/10']"
CN113383345B,Method and system for defining emotion machines,"A method for training an intelligent agent is disclosed, comprising: forming a personality matrix; combining a cognitive bias matrix with the personality matrix; and generating a behavioral function for the scenario based on the combined cognitive bias matrix and personality matrix.","['G06N3/084', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06V10/82', 'G06N3/006', 'G06N3/047', 'G06N3/048']"
US20210048991A1,Performing matrix operations in neural networks,"Apparatuses, systems, and techniques to detect a manner in which to optimize execution of a matrix operations. In at least one embodiment, a computer system detects a matrix operation and fetches data for the matrix operation before the matrix operation is fetched.","['G06F8/4434', 'G06F8/443', 'G06F17/153', 'G06F17/16', 'G06F7/57', 'G06F8/4441', 'G06F8/4442', 'G06F8/447', 'G06F8/457', 'G06F9/383', 'G06N3/04', 'G06N3/08']"
US20250191579A1,Data-Informed Decision Making Through a Domain-General Artificial Intelligence Platform,"A domain-general artificial intelligence platform or system and methods that enable data-informed decision making for anyone without the need for any coding ability are disclosed. This artificial intelligence platform has domain-generality, interoperability across heterogeneous sources of data, and controllability by tracking provenance. The artificial intelligence platform works by receiving a natural language query, converts the natural language query into executable code grounded in the deep semantic understanding of the underlying data, using a natural language artificial intelligence engine, runs the executable code on a distributed runtime engine to generate data output, and augments the data with a generated natural language report which becomes the ultimate output to the user.","['G10L15/16', 'G06F3/0481', 'G06F40/205', 'G06F40/30', 'G06F40/35', 'G06N3/0455', 'G06N3/084', 'G10L13/08', 'G06N3/091', 'G10L13/00', 'G10L15/26']"
US20220230300A1,Using Deep Learning to Process Images of the Eye to Predict Visual Acuity,"Systems and methods disclosed herein relate to using a machine-learning model to process an input of a subject's eye and to predict a current or future visual acuity of the subject. The subject may have been diagnosed with age-related macular degeneration. The predicted current or future visual acuity may be used to (for example) facilitate diagnosing the subject (e.g., with a particular type of age-related macular degeneration), facilitate identifying a treatment strategy for the subject, and/or facilitate designing a clinical study.","['G06T7/0012', 'G16H30/40', 'G06T7/0004', 'A61B3/102', 'A61B3/103', 'A61B3/12', 'A61B3/14', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T11/003', 'G06T5/70', 'G16H10/20', 'G16H50/20', 'G06T2207/10081', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041']"
US20250157670A1,Ensemble machine learning systems and methods,"Techniques for responding to a healthcare inquiry from a user are disclosed. In one particular embodiment, the techniques may be realized as a method for responding to a healthcare inquiry from a user, according to a set of instructions stored on a memory of a computing device and executed by a processor of the computing device, the method comprising the steps of: classifying an intent of the user based on the healthcare inquiry; instantiating a conversational engine based on the intent; eliciting, by the conversational engine, information from the user; and presenting one or more medical recommendations to the user based at least in part on the information.","['G16H50/30', 'G16H10/20', 'G06N20/00', 'G06N20/20', 'G06N5/022', 'G06N5/027', 'G06N5/04', 'G16H10/60', 'G16H20/00', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/60', 'G16H80/00', 'G06N3/044', 'G06N3/08']"
US20240161281A1,Neural network for image registration and image segmentation trained using a registration simulator,"Apparatuses, systems, and techniques to perform registration among images. In at least one embodiment, one or more neural networks are trained to indicate registration of features in common among at least two images by generating a first correspondence by simulating a registration process of registering an image and applying the at least two images and the first correspondence to a neural network to derive a second correspondence of the features in common among the at least two images.","['G06T7/32', 'G06T7/0012', 'G06F30/20', 'G06N3/08', 'G06T7/11', 'G06T7/344', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US12172310B2,Systems and methods for picking objects using 3-D geometry and segmentation,"A method for controlling a robotic system includes: capturing, by an imaging system, one or more images of a scene; computing, by a processing circuit including a processor and memory, one or more instance segmentation masks based on the one or more images, the one or more instance segmentation masks detecting one or more objects in the scene; computing, by the processing circuit, one or more pickability scores for the one or more objects; selecting, by the processing circuit, an object among the one or more objects based on the one or more pickability scores; computing, by the processing circuit, an object picking plan for the selected object; and outputting, by the processing circuit, the object picking plan to a controller configured to control an end effector of a robotic arm to pick the selected object.","['B25J9/1697', 'B25J9/1612', 'B25J19/023', 'B25J9/161', 'G06N3/08', 'G06T7/10', 'G06T7/50', 'G06T7/75', 'G05B2219/40053', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
CN111292839B,"Image processing method, image processing device, computer equipment and storage medium","The application relates to an image processing method, an image processing device, a computer device and a storage medium. The method comprises the following steps: acquiring a medical image to be processed and an artificial labeling result corresponding to the medical image; calling a pre-labeling model to label the medical image to obtain a machine labeling result corresponding to the medical image; the pre-labeling model is obtained by training a medical image sample and a corresponding training label; the training label is an explicit characteristic labeling result of the medical image sample; when the explicit characteristic labeling result in the manual labeling result is inconsistent with the machine labeling result, judging that the manual labeling result is a wrong labeling result, and updating the labeling level quantization result of the labeler to which the manual labeling result belongs according to the wrong labeling result; and when the quantitative result of the labeling level of the labeler to which the manual labeling result belongs meets the malicious labeling judgment condition, identifying the manual labeling result as a malicious labeling result. According to the scheme, the malicious mark identification accuracy can be improved.","['G16H30/40', 'G06N20/00', 'G06N3/08']"
CN112434643B,"Classification and recognition method of low, slow and small targets","The classification and identification method for the low-speed small targets, disclosed by the invention, is accurate in identification and short in identification time. The method is realized by adopting the following technical scheme that based on PPI images formed by original point tracks, different target track data are used as training samples of a data preprocessing module, the data preprocessing module predicts and preprocesses the obtained track related point track data law to generate a training set, a deep learning network model and a network optimization module which sequentially adopt a deep convolutional network DCNN and a long short term memory network LSTM are constructed, two groups of features are extracted from framing data, and are spliced to obtain joint features, the deep learning and image recognition target track data are input into a weighted calculation module in real time, model compression and acceleration are carried out on a trained network model structure, model compression acceleration is realized through weighted calculation and model pruning, the depth features required by accurate classification are realized, and the accurate recognition of the classification recognition of small flying birds and unmanned aerial vehicles is completed.","['G06V20/10', 'G06F18/241', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/049', 'G06N3/08', 'Y02T10/40']"
WO2020215984A1,"Medical image detection method based on deep learning, and related device","Provided are a medical image detection method and apparatus based on deep learning, a computer-readable medium and an electronic device. The method comprises: acquiring a medical image to be detected, wherein the medical image to be detected comprises a plurality of slice maps; and for each slice map in the medical image to be detected, executing, by means of a deep neural network, the following operations: obtaining, through extraction, N basic feature maps of the slice map, and performing feature fusion on the N basic feature maps of the slice map to obtain M enhanced feature maps of the slice map; executing a hierarchical dilated convolution operation on each enhanced feature map to generate a superimposed feature map of each enhanced feature map of the slice map; and predicting, by means of the deep neural network and according to the superimposed feature map of each slice map in the medical image to be detected, position information of a region of interest in the medical image to be detected and a confidence level thereof, wherein N and M are both integers greater than one. By means of the technical solutions of the embodiments of the present application, the target detection accuracy for a medical image can be improved.","['G06T7/0012', 'G06F18/253', 'G06N3/045', 'G06N3/084', 'G06T3/4053', 'G06V10/25', 'G06V10/806', 'G06V10/82', 'G06T2207/10081', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30096', 'G06V2201/03']"
US12128567B2,Using machine learning to recognize variant objects,"Using machine learning to recognize variant objects is disclosed, including: identifying an object as a variant of an object type by inputting sensed data associated with the object into a modified machine learning model corresponding to the variant of the object type, wherein the modified machine learning model corresponding to the variant of the object type is generated using a machine learning model corresponding to the object type; and generating a control signal to provide to a sorting device that is configured to perform a sorting operation on the object, wherein the sorting operation on the object is determined based at least in part on the variant of the object type associated with the object.","['B25J9/1679', 'B25J9/163', 'B25J9/1697', 'G05B19/4182', 'G05B2219/40078', 'G05B2219/50162']"
EP4006772A1,"Video processing method and apparatus, and electronic device and storage medium","The present application relates to the technical field of computers, and disclosed are a video processing method and apparatus, and an electronic device and a storage medium. The method comprises: obtaining a video frame sequence containing a moving target; inputting the video frame sequence into a trained neural network model to obtain a motion state feature characterizing that the moving target is represented by the timing of the video frame sequence; and obtaining a matching result of the motion state feature of the moving target and a motion state feature of a specified target. According to the technical solution provided by the embodiments of the present application, the recognition accuracy of a moving target in a video is improved.","['G06V40/28', 'G06T7/251', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06V20/40', 'G06V20/41', 'G06V20/42', 'G06V20/46', 'G06V40/20', 'G06N3/04', 'G06N7/01', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US11202604B2,Comprehensive and context-sensitive neonatal pain assessment system and methods using multiple modalities,"A system and method of automatically assessing pediatric and neonatal pain using facial expressions along with crying sounds, body movement, and vital signs change to improve the diagnosis and treatment of pain in the pediatric patient population.","['A61B5/0077', 'A61B5/0013', 'A61B5/0205', 'A61B5/4824', 'A61B5/7282', 'A61B5/746', 'G06T7/0016', 'G06V10/17', 'G06V10/25', 'G06V10/764', 'G06V40/168', 'G06V40/176', 'G06V40/20', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'A61B2503/045', 'A61B2576/00', 'A61B5/01', 'A61B5/02405', 'A61B5/08', 'A61B5/1102', 'A61B5/318', 'G06V40/15']"
CN117743315B,Method for providing high-quality data for multi-mode large model system,"The invention relates to the technical field of data processing, in particular to a method for providing high-quality data for a multi-mode large model system. The method for providing high-quality data for the multi-mode large model system comprises the steps of combing business knowledge to form an industry knowledge base in the technical field, preprocessing and marking data to form a training set, a verification set and a test set, and converting knowledge points in a text block into a vector form; fine tuning model parameters according to personalized requirements to optimize model performance indexes; the prompt word is designed, so that the large language model can accurately understand the semantics and structure of the industry knowledge; and carrying out vectorization processing on the questions presented by the user, submitting the questions to a large language model for inquiring, and obtaining the answers which are most matched with the questions. The method for providing high-quality data for the multi-mode large-model system forms a systematic, associated and easy-to-use knowledge set through row aggregation arrangement, not only provides high-quality data, but also provides support for intelligent service.",[]
CN108280155B,"Short video-based problem retrieval feedback method, device and equipment","The application provides a problem retrieval feedback method, a problem retrieval feedback device and equipment based on a short video, wherein the method comprises the following steps: acquiring problem retrieval information input by a user, analyzing the problem retrieval information and extracting entity information; inquiring a short video database to obtain all candidate short videos related to the entity information; calculating the correlation degree between each candidate short video and the problem retrieval information, calculating the video attraction degree of each candidate short video, and calculating the video quality of each candidate short video; calculating a matching score of each candidate short video according to the correlation degree between each candidate short video and the problem retrieval information, and the video attractiveness and the video quality of each candidate short video; and sequencing the fed back target short videos according to the matching scores of all the candidate short videos and feeding back the sequenced target short videos to the user. Therefore, problem retrieval is fed back visually in a short video mode, the efficiency of obtaining information by a user is greatly improved, and user experience is improved.","['G06F16/738', 'G06F16/735']"
US11514579B2,Deformable capsules for object detection,"An improved method of performing object segmentation and classification that reduces the memory required to perform these tasks, while increasing predictive accuracy. The improved method utilizes a capsule network with dynamic routing. Capsule networks allow for the preservation of information about the input by replacing max-pooling layers with convolutional strides and dynamic routing, allowing for the reconstruction of an input image from output capsule vectors. The present invention expands the use of capsule networks to the task of object segmentation and medical image-based cancer diagnosis for the first time in the literature; extends the idea of convolutional capsules with locally-connected routing and propose the concept of deconvolutional capsules; extends the masked reconstruction to reconstruct the positive input class; and proposes a capsule-based pooling operation for diagnosis. The convolutional-deconvolutional capsule network shows strong results for the tasks of object segmentation and classification with substantial decrease in parameter space.","['G06N3/084', 'G06F18/217', 'G06F18/241', 'G06K9/6232', 'G06K9/6262', 'G06K9/6268', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06T7/11', 'G06V10/26', 'G06V10/764', 'G06V10/82', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064', 'G06V2201/03']"
US10878708B2,Drone terrain surveillance with camera and radar sensor fusion for collision avoidance,A drone is provided with a convolutional neural network that processes a fusion of video and radar data to identify and avoid collision threats. The drone includes a transmitter for transmitting the video data to a remote convolutional neural network for identifying structures and for further identifying threats or faults with the structures.,"['G08G5/55', 'G08G5/0069', 'B64C39/024', 'B64D47/08', 'B64U10/13', 'G01S13/867', 'G01S13/935', 'G05D1/0055', 'G05D1/0202', 'G05D1/102', 'G06K9/0063', 'G06K9/00718', 'G06K9/66', 'G06N3/04', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V20/13', 'G06V20/17', 'G06V20/41', 'G08G5/0052', 'G08G5/0086', 'G08G5/04', 'G08G5/045', 'G08G5/53', 'G08G5/57', 'G08G5/74', 'G08G5/80', 'B64C2201/141', 'B64U2101/30', 'B64U2201/10', 'G06K2009/00738', 'G06K2209/21', 'G06K9/4628', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454', 'G06V20/44', 'G06V2201/07']"
US12100192B2,"Method, apparatus, and electronic device for training place recognition model","A computer device extracts local features of sample images based on a first part of a convolutional neural network (CNN) model. The sample images comprise a plurality of images taken at the same place. The device; aggregates the local features into feature vectors having a first dimensionality based on a second part of the CNN model. The device obtains compressed representation vectors of the feature vectors based on a third part of the CNN model. The compressed representation vectors have a second dimensionality less than the first dimensionality. The device trains the CNN model, and obtains a trained CNN mode satisfying a preset condition in accordance with the training.","['G06V10/454', 'G06F16/583', 'G06F16/5866', 'G06F16/587', 'G06F18/21343', 'G06F18/2135', 'G06F18/2148', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06V10/7715', 'G06V10/7747', 'G06V10/82']"
CN109583425B,Remote sensing image ship integrated recognition method based on deep learning,"The invention discloses a remote sensing image ship integrated recognition method based on deep learning, which comprises image classification, target detection and image segmentation. Compared with the prior art, the method utilizes the modern artificial intelligence deep learning model to combine with the traditional image processing method to realize the detection and segmentation of the ship with the target remote sensing image; the remote sensing image segmentation method based on deep learning can accurately identify the ship in the sea area, is suitable for various processing environments, has good anti-interference capability to complex environments, and can accurately segment the ship after detection and identification.","['G06V20/13', 'G06F18/214', 'G06F18/241', 'G06F18/253', 'G06V10/26']"
CN112149414B,"Text similarity determination method, device, equipment and storage medium","The application discloses a text similarity determining method, device, equipment and storage medium, and belongs to the technical field of artificial intelligence. The method comprises the following steps: acquiring a first text; determining element words contained in the first text; for a target element category in the N element categories, acquiring word similarity between each target element word belonging to the target element category in the first text and each target element word belonging to the target element category in the second text; determining the similarity of the first text and the second text on the category of the target element based on the word similarity; the similarity between the first text and the second text is determined based on the similarity of the first text and the second text over the N categories of elements. According to the technical scheme provided by the embodiment of the application, the similarity of different texts on each element category is determined from the angle of element word similarity, so that the similarity of different texts is determined, the accuracy of similarity determination between different texts is improved, and the application range is enlarged.","['G06F40/284', 'G06F16/35', 'G06F18/22', 'G06F40/216']"
CN113255420B,3D human body pose estimation using unlabeled multiview data trained models,"The invention discloses 3D human body posture estimation using unlabeled multi-view data trained models. For many practical graphics applications, learning from a single 2D image to estimate the pose of a 3D human body as well as the pose of any type of object is very important and typically relies on neural networks that have been trained using annotated (labeled) sample data, each annotated (labeled) sample having a 2D sample image of a known 3D pose. However, the training data requiring this marker has various drawbacks, including for example the lack of diversity of training data sets traditionally used, thus limiting the extent to which neural networks can estimate 3D poses. Expanding these training data sets is also difficult because it requires manual annotation of the 2D images, which is time consuming and error prone. The present disclosure overcomes these and other limitations of the prior art by providing a model that is trained from unlabeled multi-view data for 3D pose estimation.","['G06T7/70', 'G06V40/103', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N5/04', 'G06T17/00', 'G06T7/50', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
CN111767900B,"Face living body detection method, device, computer equipment and storage medium","The embodiment of the application provides a face living body detection method, a device, computer equipment and a storage medium, wherein the method comprises the following steps: acquiring a face image acquired by shooting equipment; inputting the face image into a feature extraction network trained by a measurement learner to be processed, so as to obtain a first feature vector; inputting the first feature vector into a feature classification network which is trained by combining a classification learner to process the first feature vector, so as to obtain a second feature vector and a living body predicted value; and determining a living body detection result of the face image according to the second feature vector, the living body predicted value and the intra-class center position of the living body class feature vector. The accuracy of human face living body detection can be effectively improved through the embodiment of the application.","['G06V40/166', 'G06F18/214', 'G06F18/23', 'G06N3/045', 'G06N3/08', 'G06V40/168', 'G06V40/172', 'G06V40/45']"
CN112560631B,A Person Re-identification Method Based on Knowledge Distillation,"The invention discloses a pedestrian re-identification method based on knowledge distillation, which comprises the following steps: inputting a pedestrian image training set into a teacher network, and inputting the same data set into a student network; distilling is carried out simultaneously at a plurality of stages of the whole backbone network through the synergistic effect of student network transfer, characteristic distilling positions and distance loss functions, so that the characteristic output of the student network is continuously close to the characteristic output of the teacher network; parameters of the student model are updated in a minimized mode through a distillation loss function, and a student network is trained; distance measurement is carried out on the obtained feature vectors, a pedestrian target graph with the highest similarity is searched, and finally the accuracy of the student network resnet18 is greatly improved to be close to that of the teacher network resnet 50. The method realizes the re-recognition of personnel by using a knowledge distillation migration learning method, effectively reduces the computational complexity by replacing a large model with a small model, and ensures the accuracy of a student model.","['G06F18/214', 'G06N3/045', 'G06N3/084', 'G06V20/52', 'G06V40/103']"
US11010902B2,Capsules for image analysis,"An improved method of performing object segmentation and classification that reduces the memory required to perform these tasks, while increasing predictive accuracy. The improved method utilizes a capsule network with dynamic routing. Capsule networks allow for the preservation of information about the input by replacing max-pooling layers with convolutional strides and dynamic routing, allowing for the reconstruction of an input image from output capsule vectors. The present invention expands the use of capsule networks to the task of object segmentation and medical image-based cancer diagnosis for the first time in the literature; extends the idea of convolutional capsules with locally-connected routing and propose the concept of deconvolutional capsules; extends the masked reconstruction to reconstruct the positive input class; and proposes a capsule-based pooling operation for diagnosis. The convolutional-deconvolutional capsule network shows strong results for the tasks of object segmentation and classification with substantial decrease in parameter space.","['G06T7/11', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06T7/0012', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064']"
US11892746B1,Super system on chip,"A Super System on Chip (SSoC) is disclosed. The Super System on Chip (SSoC)'s input/outputs are coupled with a Mach-Zehnder interferometer (MZI), wherein the Mach-Zehnder interferometer (MZI) can generally include a phase transition material or a phase change material. The Mach-Zehnder interferometer (MZI) is coupled with a first optical waveguide in two-dimensions (2-D) or three-dimensions (3-D). The first optical waveguide is coupled with (i) a semiconductor optical amplifier (SOA) or (ii) a second optical waveguide that can include a nonlinear optical material in two-dimensions (2-D) or three-dimensions (3-D). Furthermore, the semiconductor optical amplifier (SOA) may be replaced by an optical resonator.","['G02F3/00', 'G01S17/34', 'G01S17/58', 'G01S17/89', 'G01S17/931', 'G01S7/4917', 'G02F1/212', 'G02F1/225', 'G06F15/7817']"
CN110880036B,"Neural network compression method, device, computer equipment and storage medium","The application relates to a neural network compression method, a device, computer equipment and a storage medium, and relates to the technical field of neural networks. The method comprises the following steps: respectively inputting training samples into a teacher network and a student network; acquiring first network data containing a first model parameter and a first feature map of an ith layer in a teacher network and second network data containing a second model parameter and a second feature map of the ith layer in a student network, performing cross calculation on the first network data and the second network data to obtain a loss function value, and updating the second model parameter of the ith layer in the student network according to the loss function value. According to the scheme, the accuracy of the compressed neural network can be improved under the condition that the trained neural network is compressed through a small amount of training data.","['G06N3/045', 'G06N3/082']"
US10235128B2,Contextual sound filter,"An embodiments of a contextual sound apparatus may include a sound identifier to identify a sound, a context identifier to identify a context, and an action identifier communicatively coupled to the sound identifier and the context identifier to identify an action based on the identified sound and the identified context. Other embodiments are disclosed and claimed.","['G06F3/165', 'G06N20/00', 'G06N99/005', 'G10L25/51', 'H04R1/1083', 'H04R29/00', 'G06F12/0802', 'G06F2212/1024', 'G06F2212/1032', 'G06F2212/45', 'G06N5/025', 'G10L13/00', 'G10L25/78', 'G11B2020/1062', 'H04R2460/01']"
US20250138884A1,Resource sharing by two or more heterogeneous processing cores,"Apparatus, systems, and techniques to share memory. In at least one embodiment, a processor comprises one or more circuits to allocate memory to at least two heterogeneous processing cores in response to performing one or more instructions associated with one or more application programming interfaces based, at least in part, on one or more attributes associated with the at least two heterogeneous processing cores.","['G06F9/5016', 'G06F9/48', 'G06F9/4806', 'G06F9/4843', 'G06F9/4881', 'G06F9/50', 'G06F9/5005', 'G06F9/5027', 'G06F9/5033', 'G06F9/5044', 'G06F9/505', 'G06F9/5088', 'G06F9/52', 'G06F9/522', 'G06F9/526']"
US20250272533A1,Machine-learning-based architecture search method for a neural network,"In at least one embodiment, differentiable neural architecture search and reinforcement learning are combined under one framework to discover network architectures with desired properties such as high accuracy, low latency, or both. In at least one embodiment, an objective function for search based on generalization error prevents the selection of architectures prone to overfitting.","['G06F7/57', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G05B13/027', 'G06N3/047']"
US11080707B2,Methods and arrangements to detect fraudulent transactions,"Logic may detect fraudulent transactions. Logic may determine, by a neural network based on the data about a transaction, a deviation of the transaction from a range of purchases predicted for the customer, wherein the neural network is pretrained to predict purchases by the customer based on a purchase history of the customer. Logic may compare the deviation of the transaction from purchases predicted by the customer against a deviation threshold to determine whether the transaction is within the range of purchases predicted by the neural network. Logic may generate a notification in response to a determination that the deviation of the transaction from the range of purchases predicted exceeds a deviation threshold, the notification to identify the transaction as a potentially fraudulent transaction. Logic may train the neural network based on the transaction in response to a determination that transaction is not a fraudulent transaction.","['G06Q20/4016', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/044']"
CN110599557B,"Image description generation method, model training method, device and storage medium","The invention discloses an image description generation method, a model training method, equipment and a storage medium, and belongs to the technical field of machine learning. The method comprises the following steps: acquiring a target image; generating a first global feature vector and a first annotation vector set of a target image; inputting a target image to a matching model, and generating a first multi-modal feature vector of the target image through the matching model; the matching model is a model obtained by training according to the training image and the reference image description information of the training image; generating target image description information of the target image according to the first multi-modal feature vector, the first global feature vector and the first annotation vector set; the multi-modal feature vectors of the target image are generated through the trained matching model, then the multi-modal feature vectors are input into the calculation model to obtain the description information of the target image, and the effect of improving the accuracy of the generated image description information is achieved under artificial intelligent scenes such as image recognition.","['G06N3/084', 'G06F18/214', 'G06F18/217', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/049', 'G06N3/09', 'G06T9/002', 'G06V10/454', 'G06V10/776', 'G06V10/82']"
CN111431742B,"Network information detection method, device, storage medium and computer equipment","The method comprises the steps of acquiring a propagation tree structure of network information with marks and release content and characteristic information of each propagation node in the propagation tree structure from a training set by initializing parameters of a prediction model; generating a prediction model corresponding to the propagation tree structure according to the time sequence of propagation based on the hierarchical relationship between the propagation nodes in the propagation tree structure; inputting the release content and the characteristic information of each propagation node into a neural network node corresponding to the prediction model for training; if the training end condition is not met, performing back propagation on the prediction model according to the detection result and the marked error; stopping training until a training end condition is reached to obtain parameters of the trained prediction model; and predicting the network information by using the parameters of the trained prediction model. The method is based on machine learning and intelligently carries out rumor detection.","['H04L63/30', 'H04L41/147', 'H04L63/1416']"
US20200082272A1,Enhancing Data Privacy in Remote Deep Learning Services,"Mechanisms are provided for executing a trained deep learning (DL) model. The mechanisms receive, from a trained autoencoder executing on a client computing device, one or more intermediate representation (IR) data structures corresponding to training input data input to the trained autoencoder. The mechanisms train the DL model to generate a correct output based on the IR data structures from the trained autoencoder, to thereby generate a trained DL model. The mechanisms receive, from the trained autoencoder executing on the client computing device, a new IR data structure corresponding to new input data input to the trained autoencoder. The mechanisms input the new IR data structure to the trained DL model executing on the deep learning service computing system, to generate output results for the new IR data structure. The mechanisms generate an output response based on the output results, which is transmitted to the client computing device.","['G06N3/088', 'G06F16/51', 'G06F16/56', 'G06F17/30271', 'G06F17/3028', 'G06F21/6245', 'G06F21/6254', 'G06N3/045', 'G06N3/084']"
US11026634B2,Image-based system and method for predicting physiological parameters,"System and method for determining physiological parameters of a person are disclosed. A physiological parameter may be obtained by analyzing a facial image of a person, and determining, from the facial image, a physiological parameter of the person by processing the facial image with a data processor. A neural network model such as regression deep learning convolutional neural network is used to predict the physiological parameter. An image processor screens out images which can't be recognized as facial images and adjust facial images to frontal facial images for predicting of physiological parameters.","['A61B5/7275', 'A61B5/0077', 'A61B5/1032', 'A61B5/1072', 'A61B5/441', 'A61B5/4872', 'A61B5/7267', 'G06F18/24133', 'G06K9/00275', 'G06K9/00288', 'G06K9/4628', 'G06K9/6271', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N5/046', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V40/169', 'G06V40/172', 'G16H30/40', 'G16H50/30', 'A61B5/024', 'A61B5/02405', 'A61B5/163', 'A61B5/442', 'G06K2009/00322', 'G06N20/10', 'G06N7/005', 'G06N7/01', 'G06V40/178']"
US11176942B2,Multi-modal conversational agent platform,"A method includes receiving data characterizing an utterance of a query associated with a tenant; providing, to an automated speech recognition engine, the received data and a profile selected from a plurality of profiles based on the tenant, the profile configuring the automated speech recognition engine to process the received data; receiving, from the automated speech recognition engine, a text string characterizing the query; and processing, via an ensemble of natural language agents configured based on the tenant, the text string characterizing the query to determine a textual response to the query, the textual response including at least one word from a first lexicon associated with the tenant. Related systems, methods, apparatus, and computer readable mediums are also described.","['G10L15/22', 'G06F16/3329', 'G06F16/36', 'G06F40/30', 'G06N20/00', 'G06Q30/0603', 'G06Q30/0641', 'G10L13/00', 'G10L15/063', 'G10L15/1815', 'G06Q30/016', 'G10L15/26', 'G10L2015/223', 'G10L2015/228', 'H04M2201/405', 'H04M3/493']"
US12388818B2,"Identity verification method and apparatus, storage medium, and computer device","This application relates to an identity verification method performed at a computer device. The method includes: obtaining a biometric feature image of an object; performing living body detection on the biometric feature image in a secure running environment of the computer device; in accordance with a determination that the object is a living body, extracting biometric feature information from the biometric feature image and encrypting the biometric feature information in the secure running environment of the computer device; transmitting the encrypted feature information to an application in a normal running environment of the computer device for performing identity verification of the object; and receiving, from the application, an identity verification result of the object, the identity verification result being obtained after the encrypted feature information is decrypted and verified.","['H04L63/0861', 'G06F21/32', 'G06F21/602', 'G06N3/0464', 'G06N3/08', 'G06V20/64', 'G06V40/171', 'G06V40/172', 'G06V40/45', 'H04L63/0428', 'H04L63/045', 'G06F2218/04', 'G06N3/045', 'G06V2201/12']"
CN108717856B,A speech emotion recognition method based on multi-scale deep convolutional neural network,"The invention discloses a speech emotion recognition method based on a multi-scale deep convolution cyclic neural network. The method comprises the following implementation steps: (1) generating a three-channel voice frequency spectrum segment; (2) extracting voice frequency spectrum segment characteristics under different scales by adopting a deep Convolutional Neural Network (CNN); (3) adopting a long-time memory network (LSTM) to realize time modeling of voice frequency spectrum segment sequences under different scales and outputting emotion recognition results of the whole sentence of voice; (4) and (3) realizing the fusion of the recognition results obtained by CNN + LSTM under different scales by adopting a fractional layer fusion method, and outputting the final speech emotion recognition result. The method can effectively improve the natural speech emotion recognition performance in the actual environment, and can be used in the fields of artificial intelligence, robotics, natural human-computer interaction technology and the like.","['G10L25/63', 'G10L25/30']"
CN112767910B,"Audio information synthesis method, device, computer readable medium and electronic equipment","The application belongs to the technical field of artificial intelligence and relates to a machine learning technology. In particular, the present application relates to an audio information synthesis method, an audio information synthesis apparatus, a computer-readable medium, and an electronic device. The method comprises the following steps: acquiring mixed language text information comprising at least two language types; performing text coding processing on the mixed-language text information based on at least two language types to obtain intermediate semantic coding characteristics of the mixed-language text information; acquiring target tone characteristics corresponding to the target tone main body, and decoding the intermediate semantic coding characteristics based on the target tone characteristics to obtain acoustic characteristics; and carrying out acoustic coding processing on the acoustic features to obtain audio information corresponding to the mixed language text information. The method solves the tone jump problem caused by the language difference in the existing mixed language audio synthesis technology, and can stably output the mixed language audio with natural and smooth tone and unified tone.","['G10L13/02', 'G06F40/126', 'G06F40/30', 'G10L13/033', 'G10L13/08', 'G06F40/263', 'G10L13/086']"
US20250112825A1,"Multi-entity resource, security, and service management in edge computing deployments","Various aspects of methods, systems, and use cases for multi-entity (e.g., multi-tenant) edge computing deployments are disclosed. Among other examples, various configurations and features enable the management of resources (e.g., controlling and orchestrating hardware, acceleration, network, processing resource usage), security (e.g., secure execution and communication, isolation, conflicts), and service management (e.g., orchestration, connectivity, workload coordination), in edge computing deployments, such as by a plurality of edge nodes of an edge computing environment configured for executing workloads from among multiple tenants.","['H04L67/51', 'H04L67/125', 'G06F1/206', 'G06F11/3006', 'G06F9/4881', 'G06F9/505', 'G06F9/5061', 'G06F9/5072', 'G06F9/5088', 'G06F9/5094', 'G06F9/542', 'H04L41/0869', 'H04L41/5003', 'H04L41/5006', 'H04L41/5022', 'H04L41/5054', 'H04L47/781', 'H04L47/83', 'H04L49/70', 'H04L63/0435', 'H04L63/10', 'H04L63/123', 'H04L67/10', 'H04L67/1074', 'H04L67/1097', 'H04L67/12', 'H04L67/289', 'H04L9/0637', 'H04L9/3213', 'H04L9/3247', 'H04W12/04', 'H04W4/08', 'H04W76/15', 'H04W88/18', 'G06F2209/5021', 'H04L41/0843', 'H04L63/00', 'Y02D10/00', 'Y04S40/00', 'Y04S40/20']"
US20220343137A1,Kernel generation for neural networks,"Apparatuses, systems, and techniques to automatically generate a reduced number of compute kernels for performing operations of one or more neural networks. In at least one embodiment, one or more operations of one or more neural network graph nodes of the one or more neural network are automatically adjusted to generate an optimized one or more operations that are compiled to generate the reduced number of compute kernels.","['G06N3/10', 'G06N3/0445', 'G06N3/063', 'G06F17/16', 'G06F8/443', 'G06F8/447', 'G06N3/04', 'G06N3/044', 'G06F8/30', 'G06N3/084']"
CN111241304B,"Answer generation method based on deep learning, electronic device and readable storage medium","The invention relates to the technical field of intelligent decision making, and discloses an answer generation method based on deep learning, which comprises the following steps: the method comprises the steps of inputting a sentence sample into a preset language model to conduct training of mask word prediction so as to determine structural parameters of the preset language model, inputting a positive text sample and a negative text sample into the preset language model with the determined structural parameters to conduct training of sentence position prediction so as to determine sentence position weight parameters of the preset language model, obtaining a target language model, and inputting a target text and target question word segmentation processing and vectorization processing into the target language model to obtain an answer corresponding to the target question. The invention also provides an electronic device and a computer readable storage medium. The invention solves the problem that the accuracy of the answer generated during text reading and understanding application is not high enough.","['G06F16/367', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
CN111951779B,Front-end processing method for speech synthesis and related equipment,"The application relates to the technical field of voice synthesis, and provides a front-end processing method and related equipment for voice synthesis, wherein the method comprises the following steps: acquiring original text information to be processed, and converting the original text information into regularized text information; inputting regularized text information into a multitasking model to obtain a label sequence of corresponding word segmentation, prosody boundary prediction and polyphonic pinyin; integrating the tag sequences of word segmentation and prosody boundary prediction to obtain an integrated tag sequence; and determining the phoneme sequence of the original text information according to the label sequence of the multi-tone word pinyin and the integrated label sequence. The implementation of the method is beneficial to improving the accuracy of the front-end processing result in the voice synthesis.","['G10L13/02', 'G10L13/04', 'G10L13/06', 'G10L13/07', 'Y02D10/00']"
US12029594B2,Systems and methods for enhanced imaging and analysis,"A method to, is provided for collecting an image from a sample. The method includes selecting a radiation level for a first probe to meet a desired radiation dosage, and providing, with the first probe, a radiation at a selected point within a region of the sample. The method includes identifying a second selected point within the region of the sample based on a down sampling scheme, and providing a second radiation amount at the second selected point within the region of the sample. The method also includes interpolating a first datum and a second datum based on an up sampling scheme to obtain a plurality of data, and forming an image of the region of the sample with the plurality of data. A system to perform the above method and including the first probe is also provided.","['G16H30/40', 'A61B6/4258', 'A61B6/4035', 'A61B6/5282', 'A61B6/5288', 'A61B6/542', 'G06T11/00', 'G16H50/20', 'G06T2210/41', 'H01J2237/221', 'H01J2237/26']"
US12221292B2,Object path planning in a sorting facility,"Object path planning in a sorting facility is disclosed, including: obtain data describing a trajectory associated with a target object; generate a control signal for a sorting device to perform a sorting operation on the target object based at least in part on the trajectory associated with the target object; and provide the control signal to the sorting device, wherein the sorting device is configured to execute the control signal with respect to the target object.","['B65G47/46', 'G06T7/277', 'G06T7/20', 'G06V10/62', 'G06V10/764', 'G06V10/772', 'G06V10/774', 'G06V20/50', 'B65G2203/0208', 'G06F18/2433', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241', 'G06V20/64']"
US11893341B2,Domain-specific language interpreter and interactive visual interface for rapid screening,"A domain-specific language interpreter and live updating visual interface for rapid interactive exploration, filtering, and analysis of a dynamic data set. It includes a multi-line editor that allows a user to enter and edit input on any line at any time, and a grid view display. As the user enters an expression in the multi-line editor, it continually parses and executes the expression with respect to the domain-specific language, recognizing data tags and operations. Each data tag is associated with values for identifiers of the data set, and each operation can be applied to the values. The grid view display updates with a live display of identifiers and result values for the input expression according to the current contents of the multi-line editor user input interface.","['G06F40/166', 'G06F40/30', 'G06F16/2428', 'G06F16/248', 'G06F16/335', 'G06F16/38', 'G06F3/0481', 'G06F3/0482', 'G06F40/103', 'G06F40/177', 'G06F40/205', 'G06F40/216', 'G06F40/221', 'G06F40/274', 'G06N20/00']"
CN111709409B,"Face living body detection method, device, equipment and medium","The application discloses a face in-vivo detection method, a face in-vivo detection device, face in-vivo detection equipment and a face in-vivo detection medium, wherein the face in-vivo detection method comprises the following steps: acquiring a training set; inputting training data into a teacher network for first training to obtain a trained teacher network model; inputting training data into a student network for second training to obtain a trained human face living body detection model; and inputting the face image to be detected into the face living body detection model to obtain a detection result of whether the object in the face image is a living body. The knowledge distillation learner is used for guiding the student network to train, the student network model with fewer model parameters is obtained and is used as the trained human face in-vivo detection model, and the calculation speed of the model and the human face in-vivo detection speed are improved; the training process of the human face living body detection model is assisted through the updating and optimizing of the model parameters by the meta-learner, and the universality is better. The application can be widely applied to the field of artificial intelligence.","['G06V40/16', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V40/168', 'G06V40/172', 'G06V40/45']"
US20230419113A1,Attention-based deep reinforcement learning for autonomous agents,"A data source configured to provide a representation of an environment of one or more agents is identified. Using a data set obtained from the data source, a neural network-based reinforcement learning model with one or more attention layers is trained. Importance indicators generated by the attention layers are used to identify actions to be initiated by an agent. A trained version of the model is stored.","['G06N3/08', 'G05D1/0221', 'G06F16/904', 'G06F17/16', 'G06N3/006', 'G06N3/045', 'G06N3/084', 'G05D2201/0213']"
US12088887B2,"Display method and apparatus for item information, device, and computer-readable storage medium","This application relates to a method for displaying item information performed by a computer device. The method includes: displaying a live stream image comprising a live stream host performing in a live stream environment and at least one item located in the live stream environment, and the at least one item comprising a target item; in response to an item recognition operation, displaying an item tag corresponding to the at least one item; and in response to receiving a first selection operation on an item tag, displaying an item link region. Because the item tag includes an item keyword, preliminary information corresponding to the item can be directly provided to a viewer of the live stream. When the viewer account initiates a selection operation on the item tag, an item link region including item information is displayed. In this way, the viewer can further interact with the item information.","['G06Q30/0643', 'G06Q30/0631', 'G06V10/764', 'G06V20/40', 'G06V20/50', 'G06V20/635', 'G06V40/172', 'H04N21/2187', 'H04N21/23418', 'H04N21/26603', 'H04N21/2743', 'H04N21/4316', 'H04N21/4725', 'H04N21/478', 'H04N21/47815', 'H04N21/6547', 'H04N21/8583']"
US12347195B2,"Video text processing method, apparatus, and computer-readable storage medium","A video processing method is provided. The method includes extracting at least two adjacent video frame images from a frame image sequence corresponding to a video, positioning a text region of each video frame image in the at least two adjacent video frame images, determining a degree of similarity between text regions of each video frame image in the at least two adjacent video frame images, determining, based on the degree of similarity, a key video frame segment comprising a same text in the video, and determining a text key frame in the video based on the key video frame segment.","['G06V10/513', 'H04N21/44', 'G06F18/22', 'G06N3/045', 'G06N3/08', 'G06V10/24', 'G06V10/25', 'G06V10/761', 'G06V20/46', 'G06V20/48', 'G06V20/49', 'G06V20/62', 'G06V20/63']"
US20210125036A1,Determining object orientation from an image with machine learning,"Apparatuses, systems, and techniques to determine orientation of an objects in an image. In at least one embodiment, images are processed using a neural network trained to determine orientation of an object.","['G06V10/242', 'G06N3/0454', 'G06T7/70', 'G05D1/0088', 'G06K9/4628', 'G06K9/66', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V20/56', 'G06V30/194', 'G10L15/16', 'G05D2101/10', 'G06T2207/20081', 'G06T2207/20084']"
US9307917B2,Wearable heart rate monitor,"Some embodiments provide a wearable fitness monitoring device including a motion sensor and a photoplethysmographic (PPG) sensor. The PPG sensor includes (i) a periodic light source, (ii) a photo detector, and (iii) circuitry determining a user's heart rate from an output of the photo detector. Some embodiments provide methods for operating a heart rate monitor of a wearable fitness monitoring device to measure one or more characteristics of a heartbeat waveform. Some embodiments provide methods for operating the wearable fitness monitoring device in a low power state when the device determines that the device is not worn by a user. Some embodiments provide methods for operating the wearable fitness monitoring device in a normal power state when the device determines that the device is worn by a user. Some embodiments provide methods for using response characteristics of the user's skin to adjust a gain and/or light emission intensity of the heart rate monitor.","['A61B5/02427', 'A61B5/0002', 'A61B5/0205', 'A61B5/02416', 'A61B5/02433', 'A61B5/02438', 'A61B5/11', 'A61B5/1118', 'A61B5/1123', 'A61B5/4812', 'A61B5/681', 'A61B5/6843', 'A61B5/6844', 'A61B5/6886', 'A61B5/7235', 'H04W4/027', 'A61B2562/0233', 'H04L67/12', 'H04W4/008', 'H04W4/08', 'H04W4/80', 'Y02D30/70']"
CN114359727B,Tea disease identification method and system based on lightweight optimization Yolo v4,"The invention discloses a tea disease identification method and system based on lightweight optimization Yolo v < 4 >, wherein the method comprises the following steps: collecting tea disease pictures, and preprocessing the pictures to obtain a dataset for training Yolo v model; carrying out lightweight optimization on a feature extraction trunk module and a feature extraction fusion module in the Yolo v model to obtain an optimized Yolo v model; training and verifying the optimized Yolo v model by utilizing a dataset of the training Yolo v4 model to obtain an optimal Yolo v model for identifying tea diseases; and identifying the tea disease image by using the obtained optimal Yolo v model. The invention effectively reduces the huge parameter quantity and model volume of the original Yolo v network model, and improves the detection efficiency and the recognition accuracy of the tea disease target.",[]
US20220309336A1,Accessing tensors,"Apparatuses, systems, and techniques to access a multidimensional tensor from memory while minimizing tile quantization is disclosed. In at least one embodiment, a processor includes one or more circuits to cause a first one or more portions of at least one tensor to be accessed from a memory using a first technique and a second one or more portions of the at least one tensor to be accessed from the memory using a second technique based, at least in part, on an input to combine the first and second techniques.","['G06N3/08', 'G06F9/3004', 'G06F17/16', 'G06F9/30036', 'G06F9/30043', 'G06F9/3851', 'G06F9/3888', 'G06F9/3893', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06T1/60']"
CN118741573B,Fault-tolerant method for improving networking robustness of underwater robot,"The invention discloses a fault tolerance method for improving the networking robustness of an underwater robot, which comprises the steps of adopting target characteristic information and utilizing an improved ant colony algorithm to generate an optimal networking scheme of role division and space position distribution of robot nodes, transmitting the target characteristic information to a leader node through an underwater acoustic communication link, broadcasting target information and task requirements to adjacent nodes, triggering a collaborative operation mechanism, in the collaborative operation process, adopting a dynamic partition collaborative strategy based on Thiessen polygons to carry out preliminary fusion and processing on received data by the leader node, introducing a multi-classification fault diagnosis model for judging the fault type and severity, adopting a dynamic path reconstruction algorithm to re-plan the positions and paths of task nodes, estimating and modeling the probability distribution of the targets by each node through a Bayesian reasoning and evidence theory method in the multi-robot collaborative operation process, and transmitting all data to a data processing center on a mother ship after the operation task is completed.","['H04W24/04', 'H04B13/02', 'H04W16/18', 'H04W84/08']"
CN111832605B,Training method and device for unsupervised image classification model and electronic equipment,"The embodiment of the invention discloses a training method, a training device and electronic equipment for an unsupervised image classification model, which are used for inputting an acquired target domain data set and at least one source domain data set into the unsupervised image classification model in batches for processing so as to train a feature generation network, a classification network, a domain discrimination network and a joint label classification network of the unsupervised image classification model, and determining that the unsupervised image classification model is trained in response to loss corresponding to the feature generation network, the classification network, the domain discrimination network and the joint label classification network meeting preset conditions.","['G06F18/22', 'G06F18/24', 'G06N3/045', 'G06N3/088', 'Y02T10/40']"
CN107527068B,Vehicle type identification method based on CNN and domain adaptive learning,"The invention relates to a vehicle type recognition method based on CNN and domain adaptive learning, which is characterized in that a CNN network-based initial model is established by adding a rotation invariant layer, a distinguishing discrimination layer and designing a new objective function in an Alexnet network; respectively extracting feature maps of sample convolutional layers in different fields by using the established initial model, calculating cosine similarity between the sample feature maps, determining a shared convolution kernel or a non-shared convolution kernel of the CNN network, reserving the weight and the offset of the shared convolution kernel, and updating the weight and the offset of the non-shared convolution kernel; calculating cosine similarity between each layer of feature maps and average similarity of the whole target field based on the target field training samples, and clustering each type of similar feature maps according to the average similarity; expanding a source field sample with similar distribution characteristics with a sample in the target field into a new sample in the target field, finely adjusting the whole CNN network model by using the new sample in the target field, and classifying the vehicle type of the test sample in the target field by using a softmax classifier.","['G06F18/2148', 'G06F18/24', 'G06N3/08', 'G06V20/52', 'G06V2201/08']"
US9202144B2,Regionlets with shift invariant neural patterns for object detection,Systems and methods are disclosed for detecting an object in an image by determining convolutional neural network responses on the image; mapping the responses back to their spatial locations in the image; and constructing features densely extract shift invariant activations of a convolutional neural network to produce dense features for the image.,"['G06K9/66', 'G06V10/454', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V30/194']"
CN112364779B,Underwater sound target identification method based on signal processing and deep-shallow network multi-model fusion,"The invention discloses an underwater sound target identification method based on signal processing and deep-shallow network multi-model fusion, and belongs to the technical field of underwater sound target passive reconnaissance. The method comprises the steps of firstly preprocessing target signal data acquired by a passive reconnaissance array by using a signal processing method, filtering interference and extracting target features, then constructing a multi-model identification framework by using a convolutional neural network and a residual error network, and finally introducing a voting decision mechanism to realize classification and identification of maneuvering targets in water. The invention takes sonar signal processing as preprocessing to solve the problem of difficult acquisition of clean samples under complex sea conditions; the characteristics of multiple dimensions are adopted as training samples to improve the adaptability and the recognition accuracy under different sea conditions and working conditions; the method improves the identification accuracy and robustness based on the fusion identification of the multi-neural network model.","['G06F2218/04', 'G06N3/045', 'G06N3/08', 'G06F2218/08', 'G06F2218/12']"
WO2021107342A1,Device and method for monitoring state of vibration of rotating equipment using deep learning-based time series analysis,"Disclosed are a device and method for monitoring the state of vibration of rotating equipment using deep learning-based time series analysis. The device for monitoring the state of vibration of rotating equipment using deep learning-based time series analysis, according to one embodiment of the present application, may comprise: a data receiving unit which receives vibration data of rotating equipment from a vibration sensor installed for the rotating equipment; a data preprocessing unit which removes noise from the vibration data and extracts a characteristic variable from the noise-removed vibration data; a learning unit which generates, for the extracted characteristic variable, a predicted value associated with the vibration data, through deep learning-based time series analysis, and generates error information on the basis of the predicted value and the actual value of the vibration data; a margin setting unit which, on the basis of the error information, sets a margin for determining the presence or not of a defect associated with the vibration data; and a defect detection unit which receives new vibration data of the rotating equipment and determines the presence or not of a defect in the new vibration data on the basis of the margin.","['G05B23/0243', 'G05B19/404', 'G05B23/0221', 'G05B23/027', 'G06N20/00']"
CN112164391B,"Statement processing method, device, electronic equipment and storage medium","The application relates to the technical field of artificial intelligence and semantic recognition, and discloses a sentence processing method, a sentence processing device, electronic equipment and a storage medium, wherein the sentence processing method comprises the following steps: acquiring a statement to be processed; acquiring word vectors of words contained in the sentence to be processed; inputting word vectors of the words into a semantic recognition model, and obtaining semantic features corresponding to the sentences to be processed through the semantic recognition model; and determining the similarity between the semantic features and each candidate semantic recognition result through the semantic recognition model, and determining the semantic recognition result corresponding to the sentence to be processed based on each similarity and each candidate semantic recognition result. The sentence processing method provided by the invention can be used for mining the deep features of the to-be-processed sentences and obtaining the accurate semantic information of the to-be-processed sentences.","['G10L15/063', 'G10L15/10', 'G10L15/16', 'G10L2015/0631']"
US11908240B2,Micro-expression recognition method based on multi-scale spatiotemporal feature neural network,"Disclosed is a micro-expression recognition method based on a multi-scale spatiotemporal feature neural network, in which spatial features and temporal features of micro-expression are obtained from micro-expression video frames, and combined together to form more robust micro-expression features, at the same time, since the micro-expression occurs in local areas of a face, active local areas of the face during occurrence of the micro-expression and an overall area of the face are combined together for micro-expression recognition.","['G06V40/174', 'G06V40/176', 'G06F18/2148', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06V10/454', 'G06V10/774', 'G06V10/82', 'G06V40/161', 'G06V40/168', 'G06V40/172']"
US11816880B2,"Face recognition method and apparatus, computer device, and storage medium","A face recognition method includes: obtaining a first feature image that describes a face feature of a target face image and a first feature vector corresponding to the first feature image; obtaining a first feature value that represents a degree of difference between a face feature in the first feature image and that in the target face image; obtaining a similarity between the target face image and a template face image according to the first feature vector, the first feature value, and a second feature vector and a second feature value corresponding to a second feature image of the template face image, the second feature value describing a degree of difference between a face feature in the second feature image and that in the template face image; and determining, when the similarity is greater than a preset threshold, that the target face image matches the template face image.","['G06V40/16', 'G06V10/751', 'G06F18/214', 'G06F18/22', 'G06N3/045', 'G06V10/761', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V40/168', 'G06V40/172']"
CN110600122B,Digestive tract image processing method and device and medical system,"The application provides a method and a device for processing an alimentary canal image and a medical system, and relates to the technical field of artificial intelligence. The method comprises the following steps: acquiring an image of the digestive tract to be processed; obtaining focus categories of focus pixel points in the digestive tract image; obtaining a digestive tract segmentation image marked with a focus area and focus categories according to the focus categories of the determined focus pixel points; the focus area is formed by focus pixel points with the same focus category, and the focus category of the focus area is the focus category of the pixel points forming the focus area. The method determines the focus category of each focus pixel point by taking the pixel point as a processing unit, and improves the accuracy of the focus category.","['G06T7/0012', 'G06T7/10', 'G06T7/136', 'G16H50/20', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/10']"
US10008209B1,Computer-implemented systems and methods for speaker recognition using a neural network,"Systems and methods are provided for providing voice authentication of a candidate speaker. Training data sets are accessed, where each training data set comprises data associated with a training speech sample of a speaker and a plurality of speaker metrics, where the plurality of speaker metrics include a native language of the speaker. The training data sets are used to train a neural network, where the data associated with each training speech sample is a training input to the neural network, and each of the plurality of speaker metrics is a training output to the neural network. Data associated with a speech sample is provided to the neural network to generate a vector that contains values for the plurality of speaker metrics, and the values contained in the vector are compared to values contained in a reference vector associated with a known person to determine whether the candidate speaker is the known person.","['G10L17/18', 'G10L17/04', 'G10L17/08', 'G10L17/20', 'G10L15/005', 'G10L15/16']"
WO2022228349A1,Colorectal cancer digital pathological image differentiation method and system based on weakly supervised learning,"Disclosed in the present application are a colorectal cancer digital pathological image differentiation method and system based on weakly supervised learning. The colorectal cancer digital pathological image differentiation system based on weakly supervised learning comprises: a collection module, which is used for collecting a colorectal cancer digital pathological image data set; a pre-processing module, which is used for pre-processing data in the collected data set, so as to obtain pre-processed data; a first classification module, which is used for constructing a sampling block differentiation model on the basis of a weakly supervised learning algorithm, and for inputting the pre-processed data into the constructed sampling block differentiation model for processing, so as to obtain a classification result of all pathological image blocks in a full slice sampling package; and a second classification module, which is used for constructing a decision fusion model, and for inputting the obtained classification result of the pathological image blocks into the decision fusion model for fusion processing, so as to obtain a classification result of a full-digital pathological image.","['G06F18/24', 'G06F18/25', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G16H30/20', 'G16H50/20']"
CN109344789B,Face tracking method and device,"The invention relates to the technical field of face tracking, and provides a face tracking method and device. The face tracking method comprises the following steps: performing face detection on a current frame in an image frame sequence to obtain at least one first face frame and the confidence coefficient of each first face frame; updating the confidence coefficient of each first face frame based on the position relation between at least one second face frame and each first face frame obtained after face tracking of the last frame in the image frame sequence; and screening at least one first face frame based on the updated confidence coefficient, and tracking the face by using the screened first face frame. The method effectively utilizes the interframe information to correct the confidence coefficient of the first face frame, can enable the obtained confidence coefficient to more accurately reflect whether the first face frame has the face or not, equivalently improves the face detection precision, and further can improve the subsequent face tracking effect.","['G06V40/161', 'G06T7/246', 'G06V40/168', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11816753B2,Automated evaluation of human embryos,"Systems and methods are provided for provided for automatic evaluation of a human embryo. An image of the embryo is obtained and provided to a neural network to generate a plurality of values representing the morphology of the embryo. The plurality of values representing the morphology of the embryo are evaluated at an expert system to provide an output class representing one of a current quality of the embryo, a future quality of the embryo, a likelihood that implantation of the embryo will be successful, and a likelihood that implantation of the embryo will result in a live birth.","['G06T7/0012', 'G06T2207/10024', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30044']"
US11393191B2,Method and system for obtaining vehicle target views from a video stream,"A system and method for obtaining target views of a vehicle is disclosed. A seller of a vehicle may seek to obtain one or more target views of the vehicle. To obtain the target views, the user may use a smartphone with an app that accesses the video stream while the user walks around or inside the vehicle. When the app identifies a frame in the video stream as one of the target views sought, the app tags the frame as an image of one of the target views. Further, the user may provide additional input, such as voice input (as part of the video stream) or manual taps on the touchscreen of the smartphone. The additional input may be used for damage assessment or sentiment analysis of the vehicle.","['G06T7/0004', 'G06T7/0002', 'G06V10/17', 'G06V20/10', 'G06V20/41', 'G06V20/70', 'G06T2207/10016', 'G06T2207/30156', 'G06T2207/30248']"
US8425415B2,Health monitoring appliance,"A heart monitoring system for a person includes one or more wireless nodes; and a wearable appliance in communication with the one or more wireless nodes, the appliance monitoring vital signs. Other implementations can monitor heart rate, heart rate variability, respiratory rate, fluid status, posture and activity.","['G16Z99/00', 'A61B5/0006', 'A61B5/0024', 'A61B5/0077', 'A61B5/0205', 'A61B5/021', 'A61B5/02108', 'A61B5/1112', 'A61B5/1113', 'A61B5/1117', 'A61B5/242', 'A61B5/318', 'A61B5/411', 'A61B5/4806', 'A61B5/4833', 'A61B5/6808', 'A61B5/681', 'A61B5/7214', 'A61B5/7225', 'A61B5/7264', 'A61B5/7275', 'A61B5/7282', 'A61B5/7405', 'A61B5/746', 'A61B7/04', 'A61B8/00', 'A61B8/565', 'G16H40/63', 'A61B2503/08', 'A61B2560/0412', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B5/7465']"
US11373064B2,Cross-modality automatic target recognition,"Discussed herein are systems, devices, and methods for automatic target recognition based on a non-visible input image. A method can include providing, as input to a first machine learning (ML) model for object classification, pixel data of a non-visible image, the first ML model including an encoder from a second ML model, the second ML model trained to generate a visible image representation of an input non-visible image, and receiving, from the first ML model, data indicating one or more objects present in the non-visible image.","['G06K9/6267', 'G06V10/764', 'G06F18/214', 'G06F18/24', 'G06F18/251', 'G06K9/6256', 'G06K9/6289', 'G06V10/7753', 'G06V10/803', 'G06V10/82', 'G01S13/9027', 'G01S15/89']"
US10847265B2,Systems and methods for responding to healthcare inquiries,"Techniques for responding to a healthcare inquiry from a user are disclosed. In one particular embodiment, the techniques may be realized as a method for responding to a healthcare inquiry from a user, according to a set of instructions stored on a memory of a computing device and executed by a processor of the computing device, the method comprising the steps of: classifying an intent of the user based on the healthcare inquiry; identifying the intent as a need to obtain a dermatological diagnosis or treatment; soliciting, from the user and via the computing device, an image of the user's skin area to be diagnosed or treated; instantiating an image classification system to identify a dermatological disease from the image; and presenting one or more medical recommendations to the user based on the identified dermatological disease.","['G16H10/20', 'G16H10/60', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/50', 'G16H70/20', 'G16H50/30', 'G16H70/60', 'G16H80/00']"
US20210064987A1,Processor and system to convert tensor operations in machine learning,"Apparatuses, systems, and techniques to convert between tensor convolution and tensor contraction operations. In at least one embodiment, one or more convolution operations are performed on image data by at least contracting one or more tensors to generate one or more feature maps.","['G06N3/063', 'G06F17/153', 'G06F17/16', 'G06F7/57', 'G06N3/045', 'G06N3/08', 'G06N3/105']"
US11205101B1,Formula and recipe generation with feedback loop,"Techniques to mimic a target food item using artificial intelligence are disclosed. A formula generator is trained using ingredients and using recipes and, given a target food item, determines a formula that matches the given target food item. A flavor generator is trained using recipes and their associated flavor information and, given a formula, the flavor generator determines a flavor profile for the given formula. The flavor profile may be used to assist the formula generator in generating a subsequent formula. A recipe generator is trained using recipes and, given a formula, determines a cooking process for the given formula. A food item may be cooked according to a recipe, and feedback, including a flavor profile, may be provided for the cooked food item. The recipe and its feedback may be added to a training set for the flavor generator.","['G06K9/6263', 'G06F16/2423', 'G06F16/2457', 'G06F16/248', 'G06F18/214', 'G06F18/2178', 'G06K9/6256', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/774', 'G06V10/7784']"
US12094105B2,System and method for automatic labeling of pathology images,"Methods and systems are provided for automatically classifying cells in a histological stained image. In an example, a method includes automatically classifying a plurality of cells in an image of a biological sample stained with a histological stain using a classification model, the classification model trained with a plurality of automatically-classified pseudo-stained images each generated from a respective immunofluorescent image.","['G06T7/0012', 'G06F18/2413', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06V20/698', 'G06F18/2178', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096']"
WO2021196920A1,"Intelligent question answering method, apparatus and device, and computer-readable storage medium","An intelligent question answering method, apparatus and device, and a computer-readable storage medium. The intelligent question answering method comprises: on the basis of received question information, determining a target object and target attribute corresponding to the question information (S101); on the basis of the target object and the target attribute, acquiring from a pre-established knowledge graph an answer knowledge path and an external knowledge path of the target object other than the answer knowledge path (S102); inputting the answer knowledge path and the external knowledge path into a trained neural network model, and obtaining reply text (S103), the training corpus of the neural network model during training at least comprising comment information of the target object; and outputting the reply text (S104).","['G06Q30/0631', 'G06F16/3329', 'G06F16/367', 'G06F16/953', 'G06F40/30', 'G06F40/35', 'G06F40/56', 'G06N3/045', 'G06N3/084', 'G06N5/022', 'G06N3/042', 'G06N3/044', 'G06N3/047']"
CN111708950B,Content recommendation method and device and electronic equipment,"The application belongs to the technical field of artificial intelligence, and particularly relates to a content recommendation method, a content recommendation device, a computer readable medium and electronic equipment. The method comprises the following steps: acquiring a plurality of candidate contents to be recommended, which are related to a recommended object, and respectively acquiring object relativity between each candidate content and the recommended object; extracting semantic features of the candidate contents to obtain semantic vectors of the candidate contents, and respectively determining the content similarity between any two candidate contents according to the semantic vectors of the candidate contents; establishing a content matrix for representing content diversity of candidate content according to the object relativity and the content similarity; and selecting a plurality of target contents for recommending to the recommended object from the plurality of candidate contents to be recommended according to the content matrix. The method realizes the balance between the diversity and the relativity of the recommended content, and achieves the diversity scattering effect of the recommended content.","['G06F16/9535', 'G06F40/30', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
CN111784002B,"Distributed data processing method, device, computer equipment and storage medium","The application relates to a distributed data processing method, a distributed data processing device, computer equipment and a storage medium, and relates to the technical field of artificial intelligence. The method comprises the following steps: sending global model parameters to at least two edge node devices; the global model parameters are parameters of a first model deployed in the central node device; acquiring sparse gradients respectively sent by the at least two edge node devices in an asynchronous communication mode; updating the global model parameters based on the gradient weight and the sparse gradients respectively sent by the at least two edge node devices; the gradient weight is used to indicate the proportion of the sparse gradient that accounts for updating the global model parameters. In a distributed data processing scene based on the cloud server, the scheme can ensure the accuracy of model training and save the bandwidth resource of the cloud server.","['G06N20/00', 'G06F18/2136', 'H04L67/10']"
CN114295377B,CNN-LSTM bearing fault diagnosis method based on genetic algorithm,"The invention discloses a CNN-LSTM bearing fault diagnosis method based on a genetic algorithm, which comprises the following steps: firstly, collecting fault data by using a bearing fault simulation experiment platform, and expanding a sample by adopting a data enhancement method based on overlapping sampling; labeling the sample, dividing the expanded sample into a training set and a testing set, and finally standardizing. Selecting structural parameters of the CNN-LSTM fault diagnosis model by using a Genetic Algorithm (GA); and training a fault diagnosis model by using a training set, and performing online diagnosis on the bearing fault by using a test set. And finally, dynamically fine-tuning the fault diagnosis model structure by using a parameter migration method to realize the fault diagnosis of the bearing across working conditions. The method solves the problems that the identification precision of a fault bearing is low by manually extracting features, the accuracy is not high due to the fact that a fault diagnosis model structure is manually selected by experience, and time sequence data are difficult to capture by a single convolutional neural network.",[]
EP3855365A1,Distributed neural network model training,"Systems and methods for distributed training of a neural network model are described. Various embodiments include a master device and a slave device. The master device has a first version of the neural network model. The slave device is communicatively coupled to a first data source and the master device, and the first data source is inaccessible by the master device, in accordance with one embodiment. The slave device is remote from the master device. The master device is configured to output first configuration data for the neural network model based on the first version of the neural network model. The slave device is configured to use the first configuration data to instantiate a second version of the neural network model. The slave device is configured to train the second version of the neural network model using data from the first data source and to output second configuration data for the neural network model. The master device is configured to use the second configuration data to update parameters for the first version of the neural network model.","['G10L15/063', 'G06N3/084', 'G06F21/6245', 'G06N3/044', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G10L15/16', 'G10L15/22', 'H04L41/0806', 'H04L67/10', 'G10L15/065']"
US11551083B2,Neural network training from private data,"Training and enhancement of neural network models, such as from private data, are described. A slave device receives a version of a neural network model from a master. The slave accesses a local and/or private data source and uses the data to perform optimization of the neural network model. This can be done such as by computing gradients or performing knowledge distillation to locally train an enhanced second version of the model. The slave sends the gradients or enhanced neural network model to a master. The master may use the gradient or second version of the model to improve a master model.","['H04L41/145', 'G06N3/08', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'H04L41/082', 'H04L41/16', 'H04L67/10']"
US12271787B2,"Robust, scalable and generalizable machine learning paradigm for multi-agent applications","Described is a learning system for multi-agent applications. In operation, the system initializes a plurality of learning agents. The learning agents include both tactical agents and strategic agents. The strategic agents take an observation from an environment and select one or more of the tactical agents to produce an action that is used to control a platform's actuators or simulated movements in the environment to complete a task. Alternatively, the tactical agents produce the action corresponding to a learned low-level behavior to control the platform's actuators or simulated movements in the environment to complete the task.","['G06N20/00', 'G06N3/006', 'A63F13/67', 'G06N3/0442', 'G06N3/045', 'G06N3/082', 'G06N3/088', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'A63F13/837', 'A63F2300/6623', 'G06N3/044', 'G06N7/01']"
CN112818251B,"Video recommendation method and device, electronic equipment and storage medium","The embodiment of the application discloses a video recommendation method, a video recommendation device, electronic equipment and a storage medium, wherein the method comprises the following steps: collecting video data to be recommended and historical browsing video data; acquiring the video type and video description content of the video to be recommended from the video attribute information, wherein the video description content comprises a video description text and video keywords; performing feature extraction on the video type and the video description content to obtain a first vector corresponding to the video type and a second vector corresponding to the video description content; constructing a semantic text vector of the video description text, and fusing the first vector, the second vector and the semantic text vector to obtain a video vector of the video to be recommended; and determining a target video in the plurality of videos to be recommended based on the historical browsing videos and the video vectors of the videos to be recommended, and recommending the target video.","['G06F16/9535', 'G06F16/735', 'G06F16/7867', 'G06F16/958']"
CN111696094B,"Immunohistochemical PD-L1 membrane staining pathological section image processing method, device and equipment","The invention relates to an immunohistochemical PD-L1 membrane staining pathological section image processing method, device and equipment. The image processing method comprises the following steps: acquiring a digital slice full-field image of an immunohistochemical PD-L1(SP263) membrane staining pathological section to be diagnosed; identifying and segmenting a tumor cell region in the digital slice full-field image under the first visual field magnification by adopting a region segmentation network to obtain a tumor cell region probability map of the whole digital slice full-field image; identifying and segmenting cells in each digital slice full-field image, performing region constraint on a cell positioning network by taking a tumor cell region probability image as a weight matrix, identifying cell characteristics on the digital slice full-field image, and positioning and classifying various cells on the digital slice full-field image; cell location, cell type and immunohistochemical PD-L1(SP263) indices on the digital slice whole field image are indicated. According to the method, the tumor proportion score is accurately evaluated by designing a multi-level characteristic collaborative diagnosis strategy and utilizing a mode that regional characteristics constrain cell characteristics.","['G06T7/0012', 'G06N3/045', 'G06N3/08', 'G06T3/4038', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30024', 'G06T2207/30096']"
CN109948796B,"Self-encoder learning method, self-encoder learning device, computer equipment and storage medium","The application relates to a self-encoder learning method, a self-encoder learning device, computer equipment and a storage medium. The method comprises the following steps: carrying out noise superposition on the data in a Laplace domain to obtain superposition noise data; extracting data features of the superimposed noise data by an encoder; carrying out data reconstruction according to the data characteristics of the superimposed noise data to obtain reconstructed data; obtaining a difference value between the reconstructed data and the initial data; and outputting the network parameters of the encoder when the difference value meets the convergence condition. According to the scheme, the Laplace domain noise superposition is firstly carried out on the initial data, and then the feature extraction and reconstruction are carried out according to the obtained noise superposition data, so that the self-encoder can extract more upper layer features of the initial data, the representativeness of the features which can be learned from the data by the self-encoder is improved, and the accuracy of the trained encoder is improved.",[]
US11684241B2,Autonomous and continuously self-improving learning system,"A system and methods are provided in which an artificial intelligence inference module identifies targeted information in large-scale unlabeled data, wherein the artificial intelligence inference module autonomously learns hierarchical representations from large-scale unlabeled data and continually self-improves from self-labeled data points using a teacher model trained to detect known targets from combined inputs of a small hand labeled curated dataset prepared by a domain expert together with self-generated intermediate and global context features derived from the unlabeled dataset by unsupervised and self-supervised processes. The trained teacher model processes further unlabeled data to self-generate new weakly-supervised training samples that are self-refined and self-corrected, without human supervision, and then used as inputs to a noisy student model trained in a semi-supervised learning process on a combination of the teacher model training set and new weakly-supervised training samples. With each iteration, the noisy student model continually self-optimizes its learned parameters against a set of configurable validation criteria such that the learned parameters of the noisy student surpass and replace the learned parameter of the prior iteration teacher model, with these optimized learned parameters periodically used to update the artificial intelligence inference module.","['A61B1/000096', 'G06F18/211', 'G06F18/214', 'G06F18/2163', 'G06F18/217', 'G06F18/241', 'G06N20/00', 'G06N3/08', 'G06V10/7753', 'G06V10/776', 'G16H30/40', 'G16H50/20']"
CN110163640B,Method for implanting advertisement in video and computer equipment,"The embodiment of the application discloses a method for implanting advertisements in videos and computer equipment, wherein the method comprises the following steps: the method comprises the steps that computer equipment determines a target image, wherein the target image is an image containing a first plane advertisement in M frame images of a target video, and M is a positive integer; the computer equipment determines a target area, wherein the target area is an area where the first plane advertisement is located in the target image; the computer device inserts a second planar advertisement to be implanted into the target area in place of the first planar advertisement; the computer equipment carries out style conversion on the target image implanted with the second planar advertisement, and the style of the second planar advertisement in the converted target image is consistent with the style of the image pixel points outside the area where the second planar advertisement is located in the target image. By implementing the embodiment of the application, the advertisement positioning, the advertisement implantation and the style conversion of the implanted advertisement can be realized by the full automation of the computer equipment, and the visual experience of the implanted advertisement is improved.","['H04N21/23424', 'G06N3/045', 'G06F17/15', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06Q30/0241', 'G06Q30/0276', 'G06T7/0002', 'G06T7/277', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'H04N21/23418', 'H04N21/2668', 'H04N21/44008', 'H04N21/44016', 'H04N21/812', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20164', 'G06T2207/20221']"
CN106203624B,Vector quantization system and method based on deep neural network,"The present invention proposes a kind of Vector Quantization and method based on deep neural network, comprising: initial data is normalized normalization preprocessing module by normalization data, the preprocessed data after output normalization；Vector quantization coding module carries out vector quantization coding, outputting encoded data to the preprocessed data to receive preprocessed data and code book, and by code book；Neural network inverse quantization module is decoded inverse quantization to coded data by deep neural network, exports decoding data；Renormalization post-processing module carries out anti-normalization processing to decoding data by normalization data, the reduction initial data after exporting renormalization；And neural metwork training module carries out the training of neural network, exports deep neural network into neural network inverse quantization module by normalizing pretreated pretreatment training data and coding training data.The present invention can effectively solve the larger problem of quantization error of high-dimensional signal phasor quantization.","['G06N3/084', 'G06N3/088']"
WO2020215985A1,"Medical image segmentation method and device, electronic device and storage medium","An embodiment of the present application discloses a medical image segmentation method and device, an electronic device and a storage medium; in the embodiment of the present application, after a slice pair is obtained, different receptive fields can be used to respectively perform feature extraction on each slice in the slice pair to obtain high-level feature information and low-level feature information of each slice, then, on the one hand, for each slice in the slice pair, the target object in the slice is segmented according to the low-level feature information and high-level feature information of the slice, to obtain an initial segmentation result of the slice, and on the other hand, the low-level feature information and high-level feature information of each slice in the slice pair are fused, and the association information between the slices is determined according to the fused feature information, and then, a segmentation result of the slice pair is generated according to the association information between the slices and the initial segmentation result of each slice in the slice pair; and the solution can improve the accuracy of segmentation.","['G06T7/11', 'G06F18/253', 'G06N3/045', 'G06T7/0012', 'G06T7/174', 'G06T7/194', 'G06V10/267', 'G06V10/42', 'G06V10/44', 'G06V10/811', 'G06V10/82', 'G06V20/64', 'G06N3/08', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20112', 'G06T2207/20221', 'G06T2207/30056', 'G06V2201/031']"
CN113486726B,Rail transit obstacle detection method based on improved convolutional neural network,"The invention discloses a rail transit obstacle detection method based on an improved convolutional neural network, which comprises the steps of capturing road information in front of a train running in real time by using a binocular camera, storing the road information, and using all screened pictures for constructing an obstacle image dataset of the rail transit train; performing data enhancement processing on the obtained obstacle image dataset, marking the obstacle image obtained after the strong processing, and constructing a deep convolution neural detection network model based on deep learning, wherein the deep convolution neural detection network model is based on a first-order object detection network FE-YOLO, and the obstacle image obtained after the enhancement processing is input into the first-order object detection network FE-YOLO for preprocessing; setting super parameters of the first-order object detection network FE-YOLO, and comprehensively evaluating the first-order object detection network FE-YOLO by using the obtained optimal weight file. The invention can improve the accuracy of detecting the obstacle in the dangerous area of the train track.","['G06F18/214', 'G06F18/23213', 'G06N3/045', 'Y02T10/40']"
CN114048568B,Rotary machine fault diagnosis method based on multisource migration fusion shrinkage framework,"A rotary machine fault diagnosis method based on a multisource migration fusion shrinkage framework. Preprocessing the high-noise labeling data; pre-training the model by using a source domain labeled sample, processing high-noise data through a depth residual error shrinkage network structure, extracting high-dimensional characteristics and training a classification module of the model; inputting a target domain unlabeled sample for training, performing domain alignment through a mixed loss function strategy to obtain a classification result of the data characteristics of the migrated target domain, performing an aggregation decision on the classification result of all domain classifiers, adding a class label to the unknown state, and weighting and calculating an average value to obtain a final classification result; and performing state diagnosis on the target domain sample to be detected. The model can effectively reduce the influence of noise pollution which is easy to be related to the bottom public distribution on the diagnosis performance of the public features, can use decision information obtained from a plurality of source domains for realizing high-precision cross-domain fault diagnosis of unlabeled target domain data, and can identify an unknown state in the target domain.","['G06F30/17', 'G06F18/214', 'G06F18/24', 'G06F30/27', 'G06N3/048', 'G06N3/08', 'G06F2111/08', 'G06F2119/10']"
US20220084204A1,Labeling images using a neural network,"Apparatuses, systems, and techniques to generate labels for images using generative adversarial networks. In at least one embodiment, one or more objects in an input image are identified using one or more generative adversarial networks (GANs) and a synthetic version of the input image and one or more labels corresponding to the one or more objects within the synthetic version of the input image are generated using the GANs.","['G06N3/088', 'G06F18/214', 'G06T7/0014', 'G06F18/22', 'G06F18/24', 'G06K9/6215', 'G06K9/6256', 'G06K9/6267', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T11/00', 'G06T7/70', 'G06V10/774', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
CN111666921B,"Vehicle control method, apparatus, computer device, and computer-readable storage medium","The application relates to a vehicle control method, a vehicle control device, a computer device and a computer readable storage medium. The method comprises the following steps: acquiring a road scene image of a target vehicle; performing image semantic segmentation on the road scene image to obtain a semantic segmentation image, wherein the semantic segmentation image comprises a known semantic region and an unknown semantic region; determining position information of an abnormal obstacle in the unknown semantic region; and controlling the target vehicle to run away from the abnormal obstacle according to the position information. The method can improve the safety of the automatic driving automobile.","['G06V20/58', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V10/267']"
CN111339977B,Small target intelligent recognition system based on remote video monitoring and recognition method thereof,"The invention discloses a small target intelligent recognition system based on remote video monitoring, which is realized based on a remote video monitoring system, wherein the remote video monitoring system comprises a front end unit and a rear end unit, the front end unit is designed with monitoring acquisition, intelligent analysis and a servo system, the rear end unit is designed with system control, multi-system integration and big data analysis, the small target intelligent recognition system is positioned in the front end unit, and the small target intelligent recognition system comprises a video acquisition module, an image preprocessing module, an intelligent analysis module, a data processing module, a coding analysis module and a data communication module. Compared with the prior art, the invention can effectively solve the problems of intelligent, accurate and real-time detection and identification of the small target under the condition of remote video monitoring, and transmits the image identification information and the derived early warning information to the back-end control center.","['G06V20/52', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'H04N7/18', 'G06V2201/07', 'Y02T10/40']"
CN110598016B,"Method, device, equipment and medium for recommending multimedia information","The method for recommending the multimedia information comprises the steps of screening the acquired multimedia information according to preset screening conditions, acquiring multimedia information labels of screened candidate multimedia information, and predicting a feedback result of a user to be recommended on the candidate multimedia information through a feedback prediction model and a user portrait which are arranged corresponding to the multimedia information labels. And recommending the candidate multimedia information to the user to be recommended only when the feedback result represents non-negative feedback, and otherwise, filtering the candidate multimedia information. Therefore, after the multimedia information is preliminarily screened, the recommended multimedia information is screened again according to the estimated feedback result of the user to the multimedia information, the optimization of the multimedia information recommendation is realized, and the negative feedback of the user is reduced.","['G06F16/48', 'G06F16/9535']"
US11138520B2,Ranking and updating machine learning models based on data inputs at edge nodes,"An input dataset for training a new machine learning model is received by a processor. For each of a plurality of trained machine learning models, a hash function and a sketch of a training dataset used to train the machine learning model is retrieved. A sketch of the input dataset is computed based on the hash function and the input dataset, along with a distance between the sketch of the training dataset and the sketch of the input dataset. The computed distances of the trained machine learning models are ranked from smallest to largest, and a seed machine learning model for the input dataset is selected from the trained machine learning models based at least in part on the ranking. A training process of the new machine learning model using the selected seed machine learning model and the input dataset is initiated.","['G06N20/00', 'H04L67/10', 'H04L67/12']"
CN111310056B,"Information recommendation method, device, equipment and storage medium based on artificial intelligence","The embodiment of the application discloses an information recommendation method, an information recommendation device, information recommendation equipment and a storage medium based on artificial intelligence, wherein the method comprises the following steps: acquiring target information to be recommended and historical browsing information of a target user; determining a target information characteristic vector corresponding to target information through an interest probability prediction model; determining a historical information characteristic vector corresponding to historical browsing information through the interest probability prediction model, and determining a target user characteristic vector corresponding to a target user according to the target information characteristic vector and the historical information characteristic vector; determining the interest probability of the target user for the target information according to the target information feature vector and the target user feature vector through the interest probability prediction model; whether to recommend the target information to the target user is determined based on the interest probability. The method can effectively improve the accuracy of information recommendation.","['G06F16/9535', 'Y02D10/00']"
CN111325851B,"Image processing method and device, electronic equipment and computer readable storage medium","The embodiment of the disclosure provides an image processing method and device, electronic equipment and a computer readable storage medium. The method comprises the following steps: acquiring an image to be processed, wherein the image to be processed comprises an object to be processed; extracting features of the image to be processed to obtain the target key point position of the object to be processed; acquiring a training set, wherein the training set comprises a training sample with a target design style type, and the training sample comprises known key point positions and set slide bar parameters of a rendering engine corresponding to the target design style type; obtaining a weight coefficient of a training sample according to the target key point position of the object to be processed and the known key point position of the training sample; and obtaining target slide bar parameters of the object to be processed according to the weight coefficient of the training sample and the corresponding set slide bar parameters, and generating the virtual image of the object to be processed based on the target slide bar parameters. The scheme provided by the embodiment of the disclosure can adaptively migrate the design style of the training sample to the avatar of the image to be processed.","['G06T19/006', 'G06F18/214', 'G06F18/22', 'G06T19/20', 'G06T3/02', 'G06T7/10', 'G06V40/162', 'G06V40/171', 'G06T2207/30201', 'G06T2219/2024']"
CN111523621B,"Image recognition method and device, computer equipment and storage medium","The application relates to an image recognition method, an image recognition device, a computer device and a storage medium. The image recognition method comprises the following steps: acquiring a training sample image; inputting the training sample image into an image recognition model to be trained to obtain a first class confidence coefficient; obtaining a first model identification entropy corresponding to the training sample image according to the first class confidence; determining a first sample type corresponding to the training sample image, obtaining a target model loss value according to the first sample type and the first model identification entropy, adjusting model parameters in the image identification model according to the target model loss value to obtain a trained image identification model, and performing image identification based on the trained image identification model. The image recognition model provided by the embodiment of the application can be deployed in a cloud server, the cloud server provides artificial intelligence cloud service, and the image recognition accuracy of the image recognition model can be improved by adopting the method.","['G06F18/24137', 'G06F18/214']"
US12394524B2,Systems and methods for analysis of medical images for scoring of inflammatory bowel disease,"This specification describes systems and methods for performing endoscopy, obtaining medical images for inflammatory bowel disease (IBD) and scoring severity of IBD in patients. The methods and systems are configured for using machine learning to determine measurements of various characteristics related to IBD. The methods and systems may also obtain and incorporate electronic health data of patients along with endoscopic data to use for scoring purposes.","['A61B1/2736', 'A61B1/00009', 'A61B1/000094', 'A61B1/000096', 'A61B1/31', 'A61B5/4255', 'A61B5/4848', 'A61B5/7267', 'A61B5/7275', 'G06F18/21', 'G06F18/24', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G06V10/82', 'G16B20/00', 'G16B30/00', 'G16B40/20', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'G16H70/60', 'G06N20/10', 'G06N3/047', 'G06N3/088', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30092', 'G06V2201/03', 'G06V2201/031', 'G16H10/20', 'G16H10/40']"
CN114299033B,A method and system for detecting hot spots in infrared images of photovoltaic panels based on YOLOv5,"The invention relates to a YOLOv-based method and a YOLOv-based system for detecting infrared image hot spots of a photovoltaic panel, wherein the method comprises the following steps: s1: acquiring infrared images of a photovoltaic module in production operation by using an unmanned aerial vehicle to obtain an original data set; s2: extracting an image in an original data set and preprocessing to obtain a hot spot data set of the photovoltaic module; s3: constructing an improved YOLOv model, training the model by using a training set and testing the model by using a testing set, and selecting the model with the highest detection precision as a trained improved YOLOv model; s4: and detecting the photovoltaic module image to be detected by using the trained improved YOLOv model, and outputting the type information of the photovoltaic module after the output detection frame is processed. The method provided by the invention improves the accuracy of detecting the hot spots of the photovoltaic panel, and effectively distinguishes the defects of the long strip-shaped hot spots from the small hot spots.",[]
CN112861604B,Myoelectric action recognition and control method irrelevant to user,"The invention discloses a myoelectric action recognition and control method irrelevant to users, which is characterized in that high-density myoelectric signals collected by arms are converted into myoelectric images, data samples from a plurality of users executing various gesture actions are collected as a training set, and a convolutional neural network embedded with an attention module is designed by training to become a neural network model for cross-user gesture action classification; and then, if a new user accesses the electromyography control system, classifying the electromyography data of the target user by using the pre-trained neural network model and giving a result. Compared with the traditional method, the method utilizes the space-time characteristics of skeletal muscle activities, and obviously improves the accuracy of gesture action myoelectric pattern recognition under the condition of crossing users. On the basis, the practicability of the myoelectricity controlled human-computer interaction equipment is higher, so that the myoelectricity controlled human-computer interaction equipment is suitable for actual use scenes.","['G06F2218/00', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06F2218/08']"
US9108729B2,Autonomous control of unmanned aerial vehicles,"A control module for an unmanned aerial vehicle is provided. In one example, the control module includes a plurality of control modes, wherein each control mode represents a different autonomy setting, a command generator configured to generate a command causing a selection of a first of the plurality of control modes for the unmanned aerial vehicle, and an intelligence synthesizer that automatically switches the unmanned aerial vehicle between the selected first of the plurality of control modes and a second of the plurality of control mode upon detection of a trigger event.","['B64C39/024', 'B64C19/00', 'G05D1/0061', 'G05D1/0088', 'G08G5/04', 'G08G5/80', 'B64U2101/30', 'B64U2201/10', 'B64U2201/20']"
US11687770B2,Recurrent multimodal attention system based on expert gated networks,"Systems and methods for multimodal classification include a plurality of expert modules, each expert module configured to receive data corresponding to one of a plurality of input modalities and extract associated features, a plurality of class prediction modules, each class prediction module configured to receive extracted features from a corresponding one of the expert modules and predict an associated class, a gate expert configured to receive the extracted features from the plurality of expert modules and output a set of weights for the input modalities, and a fusion module configured to generate a weighted prediction based on the class predictions and the set of weights. Various embodiments include one or more of an image expert, a video expert, an audio expert, class prediction modules, a gate expert, and a co-learning framework.","['G06N3/08', 'G06F18/2113', 'G06F18/2413', 'G06F18/254', 'G06F18/256', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06V10/40', 'G06V10/764', 'G06V10/811', 'G06V10/82']"
CN109034208B,High-low resolution combined cervical cell slice image classification system,"The invention discloses a high-low resolution combined cervical cell slice image classification system, which comprises an image classification program module and is characterized in that the module realizes the following steps when being called: extracting a single cell mass image area on the low-resolution slice image; identifying suspicious cell mass image regions from the low-resolution cell mass image regions; mapping the suspicious cell mass image area into a high-resolution slice image; semantically segmenting a target cell image in the high-resolution suspicious cell cluster image region and classifying the type of the target cell image; and establishing a feature set of the slice image according to the type, the number and the confidence coefficient of the target cells in the segmented target cell image, and further classifying the whole slice image. The invention takes the cell clusters as a processing and identifying unit, and divides the target cell image by adopting the combination of high and low resolution ratios and classifies the type of the target cell image, thereby improving the identification precision and the identification efficiency.","['G06F18/24', 'G06V10/25', 'G06V10/267', 'G06V2201/03']"
CN112673381B,A method for identifying an adversarial sample and a related device,"The embodiment of the application provides a method and a related device for defending a countermeasure sample, the method outputs the result of the convolution layer of a target neural network to a feedback reconstruction network for reconstruction to obtain a reconstruction sample, so that the attack of the countermeasure sample on the target neural network can interfere with the reconstruction of a self-encoder, the error of the reconstruction sample is amplified, the countermeasure sample is easier to detect, the detection accuracy of the countermeasure sample is improved, and the false positive rate is reduced. In addition, the embodiment of the application uses the confrontation sample detector to judge whether the input sample is the confrontation sample by learning the reconstruction error of each of the confrontation sample and the non-confrontation sample, and the detection sensitivity is higher because the reconstruction error amplifies the disturbance of the confrontation sample.","['G06N3/0464', 'G06N3/04', 'G06N3/0455', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/82']"
US20200057964A1,Brain operating system,"Embodiments may provide an intelligent adaptive system that combines input data types, processing history and objectives, research knowledge, and situational context to determine the most appropriate mathematical model, choose the computing infrastructure, and propose the best solution for a given problem. For example, a method implemented in a computer may comprise receiving, at the computer system, data relating to a problem to be solved, generating, at the computer system, a description of the problem, wherein the description conforms to defined format, obtaining, at the computer system, at least one machine learning model relevant to the problem, selecting, at the computer system, computing infrastructure upon which to execute the at least one machine learning model relevant to the problem, and executing, at the computer system, the at least one machine learning model relevant to the problem using the selected computing infrastructure to generate at least one recommendation relevant to the problem.","['G06N20/10', 'A61P25/28', 'G06N3/08', 'G06N3/126', 'G06N5/003', 'G06N7/01', 'G06N20/20', 'G06N3/006', 'G06N5/01', 'G06N5/04']"
US20230410301A1,"Machine learning techniques for tumor identification, classification, and grading","The present disclosure relates to techniques for non-invasive tumor identification, classification, and grading using mixed exam-, region-, and voxel-wise supervision. Particularly, aspects are directed to a computer implemented method that includes obtaining medical images of a subject, inputting the medical images into a three-dimensional neural network model constructed to produce a voxelwise cancer risk map of lesion occupancy and cancer grade as two output channels using an objective function having a first loss function that captures strongly supervised loss for regression in lesions and a second loss function that captures weakly supervised loss for regression in regions, generating an estimated segmentation boundary around one or more lesions, predicting a cancer grade for each pixel or voxel within the medical images, and outputting the voxelwise cancer risk map of lesion occupancy determined based on the estimated segmentation boundary and the cancer grade for each pixel or voxel within the medical images.","['G06T7/0012', 'A61B5/055', 'A61B5/7264', 'G06N3/045', 'G06T7/11', 'G06T7/12', 'G16H30/40', 'G16H50/20', 'G06T2207/10088', 'G06T2207/20084', 'G06T2207/30081', 'G06T2207/30096']"
CN111966800B,Emotion dialogue generation method and device and emotion dialogue model training method and device,"The disclosure provides an emotion dialogue generation method and device and an emotion dialogue model training method and device, and relates to the field of artificial intelligence. The method comprises the following steps: acquiring multi-source knowledge related to a conversation participant; constructing a heterogeneous graph according to the multi-source knowledge, encoding the heterogeneous graph to obtain heterogeneous graph characteristic information, and determining a predicted reply emotion corresponding to the current dialogue participant according to the heterogeneous graph characteristic information; coding the characteristic information corresponding to the historical reply information and the heterogeneous graph characteristic information to acquire the characteristic information to be recovered; and determining a target reply sentence according to the emotion characteristics corresponding to the predicted reply emotion and the characteristic information to be recovered. According to the method and the device, the heterogeneous diagram can be constructed according to the multi-source knowledge of the conversation participants, emotion which the replies of the current conversation participants should contain is accurately predicted according to the heterogeneous diagram, the replies are generated, the accuracy of the replies is improved, and the user experience is further improved.","['G06F16/3329', 'G06F18/214', 'G06F40/126', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06V40/168', 'G06V40/174', 'Y02D10/00']"
CN111565316B,"Video processing method, video processing device, computer equipment and storage medium","The application discloses a video processing method, a video processing device, computer equipment and a storage medium, and belongs to the technical field of computers. According to the method and the device, the playing time characteristic of the target video on the time sequence and the playing cross characteristic of the target video and other videos on the video attribute are obtained, the estimated playing amount of the target video is predicted according to the playing time characteristic and the playing cross characteristic, whether transcoding is carried out on the target video is determined based on the estimated playing amount, the time sequence and the relevant characteristics on the video attribute can be considered at the same time, the estimated playing amount with higher accuracy is predicted, namely the video transcoding is carried out with higher accuracy, and therefore the bandwidth consumed in the video transmission process can be greatly saved.",['H04N19/40']
CN111428015B,"Information generation method, device, equipment and storage medium","The embodiment of the invention provides an information generation method, an information generation device, information generation equipment and a storage medium; the method comprises the following steps: obtaining sentences in the conversation process to obtain conversation history; performing information expansion on each dialogue statement of the dialogue history by using external knowledge information to obtain dialogue statement expansion information; carrying out feature construction on the extension information of the conversation sentences to obtain extension features of the conversation sentences, thereby obtaining at least one extension feature of the conversation sentences corresponding to the conversation history; semantic coding is carried out on at least one conversation sentence expansion feature to obtain conversation historical semantic information; performing emotion prediction on at least one conversation sentence expansion characteristic to obtain emotion information to be expressed; utilizing at least one conversation sentence expansion feature to carry out combined decoding on conversation historical semantic information and emotion information to be expressed so as to generate co-emotion reply information; the co-emotion reply information is reply information of the conversation history in the conversation process. According to the embodiment of the invention, the common situation conversation generation effect can be improved.","['G06F16/3329', 'G06F16/3344']"
US11573996B2,System and method for hierarchically organizing documents based on document portions,"Embodiments as disclosed may generate an organizational hierarchy based on embeddings of portions of documents. Embeddings resulting from the embedding of the portions of the documents can be clustered using a hierarchical clustering mechanism to segment the portion space into a set of hierarchical clusters. Documents can be assigned to these clusters based on the presence of a portion of a document within a cluster. In this manner, the documents may themselves be clustered based on the clusters created from portions across the documents of the corpus. The clusters to which a document is assigned may also be ranked with respect to that document. Similarly, documents assigned to cluster can be ranked within the cluster to which they are assigned. Additionally, in certain embodiments, names or snippets for the clusters of the hierarchy may be derived from the portions comprising that cluster.","['G06F16/355', 'G06F16/93', 'G06F16/313', 'G06F40/295', 'G06F40/30', 'G06F40/279']"
EP3989119A1,"Detection model training method and apparatus, computer device, and storage medium","The present application relates to a detection model training method and apparatus, a computer device, and a storage medium, relating to machine learning in artificial intelligence. The method comprises: obtaining a candidate image area set obtained by segmenting a first sample image; obtaining a first relation degree corresponding to each candidate image area, the first relation degree being a relation degree, about the circumstance that the candidate image area comprises a target object, output after the candidate image area is input into a first detection model; obtaining a second relation degree corresponding to each candidate image area, the second relation degree being a relation degree, about the circumstance that the candidate image area comprises the target object, output after the candidate image area is inputted into a second detection model; obtaining a relation degree change value according to the first relation degree and the second relation degree, and screening out a target image area comprising the target object from the candidate image area set according to the relation degree change value; and performing model training according to the target image area to obtain a target detection model.","['G06F18/214', 'G06T7/0012', 'G06N20/20', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06T7/11', 'G06T7/174', 'G06T7/194', 'G06T7/70', 'G06V10/25', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06T2207/10116', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068', 'G06V2201/03']"
CN111507419B,Training method and device of image classification model,"The invention provides a training method and a device of an image classification model; the method comprises the following steps: acquiring class center features of at least two classes corresponding to an image sample set comprising noise image samples and features of each image sample in the image sample set, wherein the image samples are marked with original class labels; determining similarity between class center features of at least two classes and features of each image sample; for each image sample, taking the class to which the class center feature corresponding to the maximum similarity belongs as a new class label of the corresponding image sample for sample labeling to obtain a target image sample labeled with the original class label and the new class label; constructing a loss function of the image classification model based on the original category label, the new category label and the determined similarity; and training an image classification model by adopting the target image sample based on the loss function. According to the invention, the prediction accuracy of the trained image classification model can be improved.","['G06F18/24', 'G06F18/214']"
US11625494B2,Data privacy policy based network resource access controls,"A method for enabling website access is provided. The method includes detecting an attempt to access a particular website by a computing device via a network, the particular website including one or more webpages, and accessing a particular data privacy policy for the particular website. Scores of the particular data privacy policy are determined based on text of the particular data privacy policy, and a particular multidimensional coordinate is determined based on the scores of the particular data privacy policy. A map including the particular multidimensional coordinate is displayed via the computing device. An instruction from a user is received via the computing device to enable accessing of the particular website, and the accessing by the computing device of the particular website is enabled in response to the instruction from the user.","['G06F16/35', 'G06F16/242', 'G06F16/338', 'G06F16/9535', 'G06F16/955', 'G06F16/958', 'G06F18/22', 'G06F18/24137', 'G06F18/24323', 'G06F21/62', 'G06F21/6209', 'G06F9/44526', 'G06K9/6215', 'G06K9/6282', 'G06N3/044', 'G06N3/0442', 'G06N3/08', 'G06N3/09', 'G06N5/01']"
US12266144B2,Training and inferencing using a neural network to predict orientations of objects in images,"Apparatuses, systems, and techniques to identify orientations of objects within images. In at least one embodiment, one or more neural networks are trained to identify an orientations of one or more objects based, at least in part, on one or more characteristics of the object other than the object's orientation.","['G06F18/2178', 'G06F18/214', 'G06F18/217', 'G06F18/24143', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06T7/74', 'G06V10/242', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/778', 'G06V10/7784', 'G06V10/82', 'G06V20/56', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30252']"
CN110674772B,Auxiliary system and method for intelligent safety management and control of electric power work site,"The system comprises an AI intelligent visual terminal, a handheld intelligent mobile terminal and an Internet of things cloud platform, wherein the front-end AI intelligent visual terminal is wearable equipment and is configured to realize target detection and identification, illegal behavior identification, intelligent analysis and automatic alarm and upload video data, identification results and alarm information to the handheld intelligent mobile terminal; the handheld intelligent mobile terminal is configured to perform identity verification, real-time monitoring, operation ticket management and identification result review, data in the intelligent mobile terminal is accessed into a power grid field operation personal safety Internet of things cloud platform, violation behaviors can be identified and an alarm is given, an identification result is recorded as a scoring basis, operation tickets and the like are managed, a field safety supervisor is powerfully assisted, and the problem that portable and intelligent safety supervision assisting products are blank is solved.","['G06V40/20', 'G06F18/241', 'G06F18/24323', 'G06Q50/06', 'G06V40/10', 'H04L67/06', 'H04L67/12', 'H04L9/3231', 'H04N5/76', 'H04N7/18']"
US12207939B2,Assessing treatment response with estimated number of tumor cells,"A method or system for assessing a patient response to a cancer treatment is provided. The method or system includes acquiring at least one base-line radiological image related to a patient immediately before a treatment, acquiring at least one follow-up radiological image during or after the treatment at a predetermined time interval, estimating a first number of specific tumor cells in a region of interest of the patient based on image features of the base-line radiological image using an algorithm or a model, estimating a second number of specific tumor cells in the region of interest of the patient based on image features of the follow-up radiological image using the algorithm or the model, obtaining a difference between the first number of specific tumor cells and the second number of specific tumor cells, and classifying a treatment response to a cancer based on the difference.","['A61B5/4848', 'G06F18/24137', 'G06T7/0016', 'G06T7/40', 'G06T7/45', 'G06T7/62', 'G06V10/454', 'G06V10/82', 'G06V20/695', 'A61B5/055', 'G06T2207/10064', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06T2207/30242']"
CN112418011B,"Video content integrity identification method, device, equipment and storage medium","The application discloses a method, a device, equipment and a storage medium for identifying the integrity of video content, and relates to the field of deep learning. A video integrity recognition model is constructed through an artificial intelligence technology, and a function of recognizing video integrity is realized by using computer equipment. The method comprises the steps of obtaining video files and video release information of the video files, wherein the video release information represents information provided when video contents corresponding to the video files are released, separating audio data from the video files, extracting audio features from the audio data, extracting text features from the video release information, splicing the audio features and the text features to obtain spliced features, and identifying the spliced features to obtain the integrity of the video contents corresponding to the video files. The method comprises the steps of identifying the vector after the audio features and text features corresponding to the video file are spliced, and determining the integrity of video content by integrating the features of multiple dimensions, so that the accuracy of video integrity auditing is improved.","['G06V20/40', 'G06V20/46', 'G10L25/03']"
US20230206700A1,Biometric facial recognition and liveness detector using ai computer vision,"A method, system, and computer readable medium are described to capture, detect, and recognize faces using machine learning and a single-stage face detector. A method to determine live faces from spoof 2D and spoof 3D images using a liveness score as well as a method to classify faces using machine learning deep convolutional neural networks is also described.","['G06V40/45', 'G06V10/774', 'G06V10/82', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06V40/193', 'G06V40/20']"
CN112417967B,"Obstacle detection method, obstacle detection device, computer device, and storage medium","The present application relates to an obstacle detection method, apparatus, computer device, and storage medium. The method comprises the following steps: acquiring a road scene image of a road where a target vehicle is located; carrying out obstacle identification processing on the road scene image to obtain area information and depth of field information which respectively correspond to each obstacle in the road scene image; determining target obstacles with a shielding relation according to the area information corresponding to each obstacle, and determining a relative depth-of-field relation among the target obstacles according to the depth-of-field information of the target obstacles; acquiring a distance measurement result of each obstacle acquired by a distance measurement device corresponding to the target vehicle; and determining an obstacle detection result corresponding to the road where the target vehicle is located according to the relative depth-of-field relationship among the target obstacles and the distance measurement result of each obstacle. The method can improve the accuracy of the obstacle detection.","['G06V10/82', 'G06V20/58', 'G01C11/04', 'G05D1/0246', 'G06F18/23', 'G06F18/25', 'G06N3/045', 'G06T7/11', 'G06T7/149', 'G06T7/50', 'G06V10/25', 'G06V10/26', 'G06V10/44', 'G06V10/52', 'G06V10/764', 'G06V20/56', 'G06N3/0464', 'G06N3/09', 'G06T2207/10028', 'G06T2207/30261']"
CN109035269B,Cervical cell pathological section pathological cell segmentation method and system,"The invention discloses a cervical cell pathological section pathological cell segmentation method and a system, and particularly relates to a method for off-line establishing a training sample set of cervical cell pathological section pathological cells, introducing a semantic segmentation network of a multi-scale cavity convolution structure on the basis of a depth residual error network and training a semantic segmentation model; extracting a unit to be identified on the cervical pathological section image, and applying a trained semantic segmentation model to segment different types of pathological cells in the unit to be identified; establishing a contour deformation model by combining morphological characteristics of pathological cells, and further optimizing semantic segmentation results; and predicting the lesion types of the whole section according to the cell numbers and confidence degrees of different lesion types segmented from the section. According to the invention, different types of pathological cells are accurately segmented on the cytopathology slice image by utilizing the semantic segmentation network model and the deformation variation model, and meanwhile, the identification precision and the identification efficiency are improved.","['G06T7/12', 'G06T7/149', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
CN111723748B,Infrared remote sensing image ship detection method,"The project belongs to the field of target identification in remote sensing image processing, provides an infrared remote sensing image ship detection method, and solves the problems that the existing detection method based on manual design features is complicated in process, low in robustness, narrow in application range and the like, and the problems that a ship target is small, and a large amount of missing detection and false detection exist in a complex marine environment based on deep learning of an infrared remote sensing image. The main scheme includes creating infrared remote sensing ship data set, strengthening offline data, and dividing the data set into training set, verifying set and testing set; inputting the divided training set into an improved RefineDet detection network for training, wherein the core of the detection network is a basic feature extraction network ResNet101 and a feature pyramid feature fusion module FPN combined with a visual saliency module CBAM, the detection process is a two-step cascade regression mode, the class identification and position regression precision of the ship target can be improved, and the class confidence and the regression frame after threshold filtering are output by the network and are inhibited by non-maximum values to obtain the final ship target detection result.","['G06V20/13', 'G06F18/214', 'G06V20/41', 'G06V20/46']"
CN112235384B,"Data transmission method, device, equipment and storage medium in distributed system","The application relates to a data transmission method, a device, equipment and a storage medium in a distributed system, which relate to the technical field of artificial intelligence. The method comprises the following steps: training a gradient training model in edge node equipment to obtain an original gradient; clustering each gradient data in the original gradient to obtain at least two gradient data clusters; updating gradient data in at least two gradient data clusters by taking the mass center value of the at least two gradient data clusters as a target to generate a compression gradient of the original gradient; the compression gradient comprises clustering information and centroid values of the at least two gradient data clusters; the clustering information is used for indicating gradient data clusters to which each gradient data belongs; the compression gradient is sent to the central node device. In a distributed data processing scene based on a cloud server, the scheme can reduce the consumption of bandwidth resources of the cloud server and improve the communication transmission efficiency while ensuring the accuracy of model training.","['H04L67/10', 'G06F18/23213']"
CN112862874B,"Point cloud data matching method and device, electronic equipment and computer storage medium","The application discloses a point cloud data matching method, a point cloud data matching device, electronic equipment and a computer storage medium, and relates to the technical field of artificial intelligence, automatic driving, maps, positioning and cloud, wherein the method comprises the following steps: for any point cloud data in the first point cloud data and the second point cloud data to be matched, acquiring two-dimensional data corresponding to the point cloud data, determining texture features and space structure features corresponding to each three-dimensional key point in the point cloud data based on the two-dimensional data, and obtaining a matching result based on the key point features of each first three-dimensional key point in the first point cloud data and the key point features (texture features and space structure features) of each second three-dimensional key point in the second point cloud data. According to the method, when the first point cloud data and the second point cloud data are matched, the texture features and the space structure features corresponding to the three-dimensional key points are considered, so that the matching result is more accurate.","['G06T7/33', 'G06N3/08', 'G06T2207/10028', 'G06T2207/20081']"
CN109410185B,"A kind of image partition method, device and storage medium","The embodiment of the invention discloses a kind of image partition method, device and storage mediums；The embodiment of the present invention is after getting 3 d medical images to be split, first the target area (target area includes target object) in the 3 d medical images can be intercepted using two-dimentional parted pattern, obtain candidate region, then again using the type of each voxel in three-dimensional pyramid analysis neural network forecast candidate region, and the target object in the candidate region is split based on the type of prediction, to obtain final segmentation result；The program can prevent three-dimensional spatial information from losing, while to ensure that the marginal layer structure of target object can be come out by Accurate Prediction, training is not easy and the generation of the situation of prediction result inaccuracy caused by avoiding the ratio for accounting for entire original medical image due to target object too small, can greatly improve the accuracy of medical image segmentation.","['G06T7/0012', 'G06T7/11', 'G06T2207/10088', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048']"
US10445576B2,Automated vehicle recognition systems,This disclosure describes a device and methods for determining an image. The disclosure further describes devices and methods for detecting a vehicle in the image; extracting at least one first feature from the image; determining a match between each of the at least one first feature and each of at least one second features stored the at least one memory; and determining a ranking of the each of the at least one first feature.,"['G06V10/82', 'G06K9/00664', 'G06F18/214', 'G06F18/2413', 'G06K9/6202', 'G06K9/6256', 'G06K9/627', 'G06V10/764', 'G06V20/10', 'G06K2209/23', 'G06K9/40', 'G06V10/30', 'G06V2201/08', 'G08G1/015', 'G08G1/0175']"
US20250095630A1,Synthesis of speech from text in a voice of a target speaker using neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for speech synthesis. The methods, systems, and apparatus include actions of obtaining an audio representation of speech of a target speaker, obtaining input text for which speech is to be synthesized in a voice of the target speaker, generating a speaker vector by providing the audio representation to a speaker encoder engine that is trained to distinguish speakers from one another, generating an audio representation of the input text spoken in the voice of the target speaker by providing the input text and the speaker vector to a spectrogram generation engine that is trained using voices of reference speakers to generate audio representations, and providing the audio representation of the input text spoken in the voice of the target speaker for output.","['G06N3/0442', 'G06N3/0455', 'G10L13/033', 'G10L13/04', 'G10L17/04', 'G10L19/00', 'G10L25/18', 'G10L25/30', 'G06N3/08', 'G10L2013/021']"
US12087042B2,"Method, apparatus, and electronic device for training neural network model",The present disclosure relates to a method for training a neural network model performed at an electronic device. The method includes: performing initial training by using a first training sample set to obtain an initial neural network model; performing a prediction on a second training sample set by using the initial neural network model to obtain a prediction result of each of training samples in the second training sample set; determining a plurality of preferred samples from the second training sample set based on the prediction results; adding the plurality of preferred samples that are annotated to the first training sample set to obtain an expanded first training sample set; updating training of the initial neural network model by using the expanded first training sample set to obtain an updated neural network model until a training ending condition is satisfied.,"['G06V10/7753', 'G06F18/2113', 'G06F18/214', 'G06F18/22', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'Y02T10/40']"
CN110444263B,"Disease data processing method, device, equipment and medium based on federal learning","The invention discloses a disease data processing method, device, equipment and medium based on federal learning, wherein the method comprises the following steps: acquiring an electronic health record of a patient diagnosed in a local database and disease data; extracting the characteristics of the electronic health record to obtain the disease characteristic vector of each patient; constructing a local training sample set according to the disease feature vector and the disease data of each patient; and participating in federal learning of data ends of all hospitals based on the local training sample set to obtain a disease prediction model. According to the invention, the data of all hospital ends are combined for federal training, and a high-quality disease prediction model can be trained on the basis of not revealing the privacy of patients of the hospital ends, so that a positive auxiliary effect is exerted in the diagnosis process of doctors.","['G06N3/045', 'G16H10/60', 'G16H50/70']"
US12204851B2,"Method for generating pre-trained language model, electronic device and storage medium","A method for generating a pre-trained language model, includes: obtaining sample files; obtaining typography structure information and text information of the sample files by parsing the sample files; obtaining a plurality of task models of a pre-trained language model; obtaining a trained pre-trained language model by jointly training the pre-trained language model and the plurality of task models according to the typography structure information and the text information; and generating a target pre-trained language model by fine-tuning the trained pre-trained language model according to the typography structure information and the text information.","['G06F40/211', 'G06F40/216', 'G06F40/186', 'G06F40/109', 'G06F40/117', 'G06F40/137', 'G06F40/289', 'G06F40/30', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096']"
EP4002161A1,"Image retrieval method and apparatus, storage medium, and device","An image retrieval method and apparatus, a storage medium, and a device, relating to the technical field of artificial intelligence. The method comprises: obtaining an image, and performing feature extraction on the image according to a deep learning-based extraction mode to obtain a first feature; on the basis of the first feature, determining at least one candidate image matched with the image, and performing feature extraction on the image and each candidate image according to a non-deep learning-based extraction mode to obtain a manual feature; performing key point matching processing on the image and each candidate image in sequence on the basis of the manual feature; and determining a first image in the at least one candidate image having the number of key points matched with those of the image greater than a quantity threshold as an image retrieval result, wherein the number of matched key points between the first image and the image is greater than the quantity threshold. The method improves the retrieval efficiency and the retrieval precision.","['G06F16/583', 'G06V10/757', 'G06F16/532', 'G06F16/55', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06V10/462', 'G06V10/761', 'G06V10/762', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82']"
CN112734775B,"Image labeling, image semantic segmentation and model training methods and devices","The application provides an image labeling, image semantic segmentation and model training method and device, relates to the technical field of artificial intelligence, and is used for improving the efficiency of labeling sample images. According to the image labeling method, the edge pixel points in the sample image are detected, the target image blocks in a plurality of image blocks in the sample image are screened according to the edge pixel points, and the target image blocks are labeled, so that a labeling result of the sample image is obtained, the labeling quantity in the labeling process of the sample image can be relatively reduced because all the pixel points in the sample image are not required to be labeled, the efficiency of labeling the sample image is improved, and the image has certain redundant information, so that the accuracy of an image semantic segmentation model is not influenced even if all the pixel points in the sample image are not labeled during training of the image semantic segmentation model.","['G06T7/12', 'G06T7/13']"
CN111625659B,"Knowledge graph processing method, device, server and storage medium","The application provides a knowledge graph processing method, a knowledge graph processing device, a server and a storage medium, and belongs to the technical field of artificial intelligence. The method comprises the following steps: acquiring a plurality of target text corpora corresponding to the knowledge groups based on any knowledge group in the knowledge graph, wherein the knowledge groups comprise any entity pair in a plurality of entities of the knowledge graph and a reference relation between the entities in the entity pair, and the target text corpora comprise entity pairs; performing relation extraction based on the target text corpora, and determining the probability that the relation between the entities expressed by the target text corpora belongs to the relation category of the reference relation as a relation parameter; determining confidence of the knowledge tuple based on the relationship parameters; and determining the knowledge tuple with the confidence coefficient meeting the target processing condition as the knowledge tuple to be processed. According to the method and the device, the confidence coefficient of the knowledge tuple is determined based on the target text corpus comprising the entity pair in the knowledge tuple, and then the knowledge tuple with the confidence coefficient meeting the condition is processed, so that the accuracy of the knowledge map can be improved.","['G06F16/367', 'G06F40/295']"
US11645479B1,Method for AI language self-improvement agent using language modeling and tree search techniques,"A novel method provides an AI language virtual agent having self-improvement features and which uses language modeling and tree search techniques. The AI language virtual agent exchanges textual discussion with users and other simulated agents. The method includes receiving a current situational description depicting natural language user input, temperament qualities and textual tendencies of the virtual agent, and indicia regarding subject matter context of a present conversation. The indicia regarding subject matter context include textual logs from recent conversational exchanges. The current situational description includes audio, visual, and tactile inputs collected proximate to the virtual agent. The method preferably utilizes an MCTS tree search in combination with self-moving modules, one or more language models, tree search techniques outputting textual responses to the current situation description, and the virtual agent responding with textual expression to verbal input in combination with the audio, visual, tactile, and other sensory inputs.","['G06F40/35', 'G06F40/58']"
CN112800891B,Discriminative feature learning method and system for micro-expression recognition,"The invention discloses an identifying characteristic learning method and system for micro-expression recognition. Firstly, extracting an initial frame and a peak frame in a micro-expression video sequence, preprocessing the initial frame and the peak frame, and further calculating optical flow information between the peak frame and the initial frame to obtain an optical flow graph; then selecting an image with an expression category different from that of the peak frame from a common expression image library, cutting the image, and replacing a corresponding area of the peak frame image with the image block obtained by cutting to obtain a composite image; then constructing a double-current convolution neural network model based on a class activation graph attention mechanism, inputting a light-flow graph and a synthetic image into two branches of the double-current convolution neural network respectively, and training the model; and finally, extracting features with strong discriminative power from the input video sequence by using the trained model for micro-expression classification and identification. The method can effectively prevent the model from being over-fitted, enables the model to learn the micro-expression characteristics with strong discriminative power, and improves the accuracy of micro-expression recognition.","['G06V40/174', 'G06F18/214', 'G06F18/241', 'G06N3/04', 'G06N3/08']"
CN112001187B,A sentiment classification system based on Chinese syntax and graph convolutional neural network,"The invention provides an emotion classification system based on Chinese syntax and a graph convolution neural network, which comprises the following steps of: s1, acquiring a social network text, taking the acquired social network text as a text to be processed, and preprocessing the text to be processed; s2, learning the context information of the sentence and the attribute clause to obtain the corresponding feature representation; s3, generating a semantic tree of sentences according to the acquired dependency relationship and grammar information of the given text; s4, generating emotion feature representation of the given text by using a graph convolution network according to the dependency tree embedded with the feature vector; s5, constructing a conditional probability distribution of each emotion mark by using a Softmax classifier, and outputting a final emotion label of the text. The method and the device can classify the acquired social network text emotion and provide more detailed and deeper emotion analysis for the short text in the social network platform.","['G06F40/30', 'G06F16/35', 'G06F40/211', 'G06N3/045', 'G06N3/08']"
CN111897933B,Emotion dialogue generation method and device and emotion dialogue model training method and device,"The disclosure provides an emotion dialogue generation method and device and an emotion dialogue model training method and device, and relates to the field of artificial intelligence. The method comprises the following steps: acquiring multi-source knowledge related to a conversation participant; encoding the multi-source knowledge to obtain multi-source knowledge characteristic information, and determining reply emotion prediction information corresponding to the current conversation participant according to the multi-source knowledge characteristic information; coding the characteristic information corresponding to the historical reply information and the multi-source knowledge characteristic information to acquire the characteristic information to be replied; and determining a target reply sentence according to the emotion characteristics and the characteristic information to be replied corresponding to the reply emotion prediction information. According to the method and the device for generating the feedback information, emotion information corresponding to the current dialogue participant can be accurately predicted according to the multisource knowledge, the emotion information is introduced into the generated feedback, the accuracy of the feedback is improved, and user experience is further improved.","['G06F16/3329', 'G06F18/214', 'G06F40/126', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06V40/168', 'G06V40/174']"
US20230335121A1,Real-time video conference chat filtering using machine learning models,"In various examples, as a user is speaking or presenting content during an online video conference, the data stream may be processed to generate a textual representation (e.g., transcript) of the audio and/or information relating to the video. The textual representation and/or video related information may then be processed to determine a context or one or more topic(s) of discussion. Based on the determined context/topic(s), a corresponding neural network(s) may be selected. Once a neural network has been selected, comments may be retrieved from a chat feature of the application and applied to the neural network. The neural network may then output data to indicate the relevance of the comments to the determined discussion topic. Based on the relevance of the comment, the comment may be allowed, prioritized, deleted, de-emphasized, or otherwise filtered in the chat feature.","['G06F40/30', 'G10L15/1815', 'G06F40/216', 'G06N3/045', 'G06N3/08', 'G10L15/16', 'G10L15/22', 'H04L12/1827', 'H04L51/046', 'H04L51/212', 'G10L15/26', 'G10L2015/088', 'H04N7/15']"
US20200130177A1,Systems and methods for few-shot transfer learning,"A method for training a controller to control a robotic system includes: receiving a neural network of an original controller for the robotic system based on origin data samples from an origin domain and labels in a label space, the neural network including encoder and classifier parameters, the neural network being trained to: map an input data sample from the origin domain to a feature vector in a feature space using the encoder parameters; and assign a label of the label space to the input data sample using the feature vector based on the classifier parameters; updating the encoder parameters to minimize a dissimilarity, in the feature space, between: origin feature vectors computed from the origin data samples; and target feature vectors computed from target data samples from a target domain; and updating the controller with the updated encoder parameters to control the robotic system in the target domain.","['G06N3/084', 'B25J9/163', 'G06F18/24', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/088', 'G06N3/096', 'G06N3/044']"
CN111488931B,"Article quality evaluation method, article recommendation method and corresponding devices","The invention provides an article quality evaluation method, an article recommendation method and a corresponding device thereof, wherein the method comprises the following steps: obtaining an article to be evaluated; extracting multi-mode features of the article to be evaluated, wherein the multi-mode features comprise at least two of typesetting appearance features, writing style features or text semantic features; the article quality of the article to be evaluated is determined based on the multi-modal features. In the scheme, the typesetting appearance characteristics can visually reflect the characteristics of the articles, the writing style characteristics can reflect the characteristics of the articles from the article contents, the text semantic characteristics can reflect the physical signs of the texts from the article semantics and the writing logic, therefore, the quality of the articles to be evaluated can be measured from at least two dimensions based on the multi-mode characteristics, the influence of a plurality of dimensional factors on the quality of the articles is considered for the determined quality of the articles, the quality of the articles is evaluated based on the multi-mode characteristics, the evaluation of the quality of the articles can be well conformed to the reading cognitive process of people, and the determined quality of the articles is more accurate.","['G06F18/217', 'G06F40/30', 'G06V30/414', 'G06V30/416', 'Y02P90/30']"
CN112100063B,"Interface language display test method and device, computer equipment and storage medium","The application relates to a display test method and device of an interface language, computer equipment and a storage medium. The method comprises the following steps: traversing a target interface of the software to be tested, and acquiring an interface image corresponding to the target interface; performing text recognition on the interface image to obtain text recognition information; acquiring first text information corresponding to a first language mode and second text information corresponding to a second language mode according to the text identification information; acquiring third text information of the first text information in a second language mode; comparing the third text information with the second text information, and determining that the interface text corresponding to the second language mode is abnormal according to the text comparison result; and obtaining a display test result of the target interface in the second language mode according to the interface text abnormity corresponding to the second language mode. According to the scheme, the abnormal text translation and the abnormal text display in the target interface can be quickly acquired through the machine learning technology, and then the display test result of the target interface is accurately acquired.","['G06F11/3668', 'G06F40/58', 'G06N3/045', 'G06V10/22', 'G06V30/10']"
US20190095877A1,Image recognition system for rental vehicle damage detection and management,"Techniques are disclosed for rental vehicle damage detection and automatic rental vehicle management. In one embodiment, a rental vehicle management application receives video and/or images of a rental vehicle's exterior and dashboard and processes the video and/or images to determine damage to the vehicle as well as the vehicle's mileage and fuel level. A machine learning model may be trained using image sets, extracted from larger images of vehicles, that depict distinct types of damage to vehicles, as well as image sets depicting undamaged vehicles, and the management application may apply such a machine learning model to identify and classify vehicle damage. The management application further determines sizes of vehicle damage by converting the damage sizes in pixels to real-world units, and the management application then generates a report and receipt indicating the damage to the vehicle if any, mileage, fuel level, and associated costs.","['G06Q10/20', 'G06F18/214', 'G06F18/217', 'G06K9/00671', 'G06K9/00771', 'G06K9/3258', 'G06K9/6256', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N99/005', 'G06Q30/0283', 'G06V20/20', 'G06V20/52', 'G06V20/63', 'G06K2209/01', 'G06K2209/23', 'G06V2201/02', 'G06V2201/08']"
US11270433B2,"Disease diagnosis support method employing endoscopic images of a digestive organ, a diagnosis support system, a diagnosis support program and a computer-readable recording medium having the diagnosis support program stored therein","Provided is a disease diagnosis support method employing endoscopic images of a digestive organ using a neural network, and the like. The disease diagnosis support method employing endoscopic images of a digestive organ using a neural network trains the neural network by using first endoscopic images of the digestive organ, and corresponding to the first endoscopic images, at least one of definitive diagnosis result of being positive or negative for the disease of the digestive organ, a past disease, a severity level, and information corresponding to an imaged region. The trained neural network outputs, based on second endoscopic images of the digestive organ, at least one of a probability of being positive and/or negative for the disease of the digestive organ, a probability of a past disease, a severity level of the disease, and the information corresponding to the imaged region.","['G06T7/0012', 'A61B1/000096', 'A61B1/00016', 'G06T7/11', 'G06T7/143', 'A61B1/273', 'G06T2207/10024', 'G06T2207/10068', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30028', 'G06T2207/30032', 'G06T2207/30092', 'G06T2207/30096']"
CN112766244B,"Target object detection method and device, computer equipment and storage medium","The application relates to a target object detection method, a target object detection device, a computer device and a storage medium, wherein the target object detection method comprises the following steps: inputting a training image comprising a label marking frame into a target object detection model to be trained; performing feature processing on each initial training feature map obtained by performing feature extraction on the training image to obtain initial prediction labeling frames corresponding to each preset labeling frame on the initial training feature map, and determining an updated labeling frame from each initial prediction labeling frame based on the position difference between the preset labeling frame and the label labeling frame; transforming and fusing the initial training characteristic diagram to obtain a target training characteristic diagram; performing feature processing on the target training feature map based on the updating marking frame to obtain a target prediction marking frame corresponding to the updating marking frame; and generating regression loss based on the position difference between the initial prediction labeling frame and the target prediction labeling frame and the position difference between the target prediction labeling frame and the label labeling frame, and training a target object detection model based on the regression loss, so as to train and obtain a target object detection model with more accurate detection.","['G06V40/161', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V40/168']"
CN109506658B,Robot autonomous positioning method and system,"The invention relates to the technical field of artificial intelligence, in particular to an autonomous robot positioning method and system, which comprises the following steps: acquiring indoor video stream data, and constructing a network data set based on the indoor video stream data; collecting a first image group containing a fixed marker; acquiring a second image group matched with the first image group from the network data set by using a trained preset twin network; matching the same fixed markers in the first image group and the second image group, and taking the same fixed markers as feature markers; acquiring a position parameter of the feature identifier; calculating the position of the robot based on the position parameters of the feature identifier; the fixed marker at least comprises a door, a window, a stand column, a cross beam and a wall body. The invention adopts the autonomous positioning method of the robot with multi-mode fusion, has low requirement on hardware, saves cost and improves indoor positioning precision. Meanwhile, the system is insensitive to scene dynamic change and light intensity, and has strong scene adaptability.","['G01C21/206', 'G01S17/89', 'G06T7/11', 'G06T7/60', 'G06T7/73', 'G06T2207/10016']"
CN114390217B,"Video synthesis method, device, computer equipment and storage medium","The application relates to a video synthesis method, a video synthesis device, computer equipment and a storage medium. The method relates to the field of network media and the technical field of artificial intelligence, and comprises the following steps: acquiring content description text information of a target object; the content description text information is text information describing the content expressed by the target object; extracting semantic features of the content description text information to obtain text semantic features; acquiring candidate video content characteristics; the candidate video content features are obtained by extracting semantic features from the picture content of the candidate video clips; determining video clips matched with the content description text information based on the matching degree between the text semantic features and the candidate video content features to obtain target video clips; and synthesizing the object video based on the content description text information and the target video clip. The method can improve the efficiency of processing the multimedia data.","['H04N5/265', 'G06F40/30']"
CN109658455B,Image processing method and processing apparatus,"The embodiment of the specification discloses an image processing method and processing equipment, wherein the method can comprise the following steps: normalizing an original image into an intermediate image, wherein the intermediate image comprises a plurality of local blocks; calculating image characteristic data of the local block; according to the image feature data, calculating weight distribution data corresponding to the local blocks in the intermediate image, wherein the weight distribution data represent the possible degree that the local blocks comprise partial or all objects; and determining the position area of the object in the original image based on the calculated weight distribution data. By utilizing the embodiment of the specification, the object in the image can be quickly and efficiently positioned, the main body area can be determined, and a large amount of manual image labeling workload can be saved.","['G06V10/82', 'G06T7/73', 'G06F16/55', 'G06F16/5838', 'G06F18/214', 'G06F18/217', 'G06V10/245', 'G06V10/44', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/7788']"
CN112765480B,Information pushing method and device and computer readable storage medium,"The embodiment of the application discloses an information pushing method, an information pushing device and a computer readable storage medium, wherein user attribute information in a cold start state is acquired; determining a push information set corresponding to the user attribute information in the historical browsing record, and selecting push information with browsing times larger than a preset browsing threshold value from the push information set as information to be pushed; extracting one-dimensional target association characteristics of user attribute information and information to be pushed in a nonlinear processing dimension and two-dimensional target cross characteristics in a implicit processing dimension; predicting by combining the one-dimensional target correlation characteristic and the two-dimensional target cross characteristic to obtain target browsing time information corresponding to each piece of information to be pushed; and selecting a preset number of target information to be pushed to carry out information pushing based on the sequence of the target browsing time information from high to low. Therefore, the information to be pushed corresponding to the user attribute information under the cold start can be screened out for accurate prediction, and the accuracy of information pushing is greatly improved.","['G06F16/9535', 'G06F16/9537']"
US11914639B2,"Multimedia resource matching method and apparatus, storage medium, and electronic apparatus","This application discloses a multimedia resource matching method performed at a computing device. The method includes: searching a first media resource set among a multimedia resource set, first target image frames of all media resources in the first media resource set meeting a target condition, and features of the first target image frames matching features in image frames of a to-be-matched multimedia resource according to a first matching condition; determining, among the first target image frames, second target image frames whose features match the features in the image frames of the to-be-matched multimedia resource according to a second matching condition; and obtaining matching information of the second target image frames and an identifier of a target media resource among the multimedia resource set, the matching information being used for indicating a total duration and a playback moment of the second target frame image in the target media resource.","['G06F16/583', 'G06F16/43', 'G06F16/45', 'G06F16/783', 'G06F18/214', 'G06V20/46', 'G06V20/48', 'G06V10/462']"
CN111242748B,"Method, apparatus, and storage medium for recommending items to a user","The invention relates to a method, a device and a storage medium for recommending items to a user. The invention provides a recommendation model training method for recommending items to a user. The method comprises the following steps: obtaining a plurality of samples, each of the plurality of samples including a user characteristic, an item group and a tag corresponding to the item group, the item group including two or more items, the tag indicating whether the item group is selected by a user; generating a respective item embedding vector for each item in the set of items; carrying out weighted average on the generated multiple project embedding vectors to obtain a comprehensive embedding vector of the project group; generating a user embedding vector of the user based on the user characteristics; and training a recommendation model for recommending items to the user using the resulting composite embedded vector, the user embedded vector of the user, and the tags corresponding to the set of items. The recommendation model can realize accurate recommendation of the items.","['G06Q30/0631', 'G06F18/2411', 'G06Q30/0251']"
CN112800766B,Active learning-based Chinese medical entity identification labeling method and system,"The invention discloses a Chinese medical entity identification labeling method and a Chinese medical entity identification labeling system based on active learning, wherein the method comprises the following steps: a pre-training step; a first active learning step: constructing a first named entity recognition model, training and learning based on a training set, verifying based on a verification set, and adjusting a learning process according to a first verification result; a second active learning step: screening out data to be marked by combining the text vector and the transfer score, sorting the data set, retraining the first named entity recognition model to obtain a second named entity recognition model, verifying the second named entity recognition model, and adjusting the retraining process according to a second verification result; and (3) identification: and identifying the Chinese medical text to be identified based on the third named entity identification model. The active learning adopted by the invention combines the text vector and the transfer score, the screened text has higher degree of difference, the labeling cost is reduced, and the output errors are corrected in time through expert labeling.","['G06F40/295', 'G06F18/2415', 'G06F40/117', 'G06N20/00', 'G16H10/60', 'Y02A90/10']"
US20230394247A1,Human-machine collaborative conversation interaction system and method,"A system for human-machine collaborative conversation interaction includes one or more processors configured to execute instructions to cause the system to perform operations including: outputting, according to conversation data to be processed, structural information of the conversation data, wherein the conversation data comprises multiple turns of conversation; obtaining, according to the structural information, a semantic representation vector carrying phrase-dimensional semantic information, sentence-dimensional semantic information and topic-dimensional semantic information corresponding to the conversation data; obtaining semantic transfer relationships between each turn of conversation according to the semantic representation vector; and determining, according to the semantic representation vector and the semantic transfer relationships, conversation data matching service requirements so as to perform preset service processing through the determined conversation data.","['G06F40/35', 'G06F40/211', 'G06F40/284', 'G06F40/289', 'G06F40/40', 'G06N20/00']"
WO2020207377A1,"Method, device, and system for image recognition model training and image recognition","The present application relates to the technical field of computers and specifically relates to a method, device, and system for image recognition model training and image recognition. The recognition method: acquiring an image to be recognized; extracting image feature information of said image; acquiring a disease type recognition result of said image on the basis of a preset image recognition model and with the image feature information of said image serving as an input parameter, where the image recognition model is trained by employing a training image sample set at least comprising strong tag training image samples to determine the disease type recognition result; the strong tag training image samples express image samples having strong tag information, the strong tag information at least comprises label information of disease types and lesions. Image feature information of a certain disease type can be accurately positioned on the basis of the lesions, thus reducing noise and increasing reliability and accuracy.","['G06T7/0012', 'G06N3/08', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/045', 'G06N3/048', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30028', 'G06T2207/30092', 'G06T2207/30096']"
US11416987B2,Image based screening system for prediction of individual at risk of late age-related macular degeneration (AMD),An automated screening system using retinal imaging to identify individuals with early-stage Age-related Macular Degeneration (AMD) and identify individuals at risk for developing late AMD.,"['G06T7/0012', 'G16H50/30', 'A61B5/7267', 'A61B5/7275', 'G06T7/11', 'G06T7/12', 'G06T7/38', 'G06T7/73', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'A61B3/12', 'G06T2207/10024', 'G06T2207/20032', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30041', 'G06T2207/30101']"
CN112735418B,"Voice interaction processing method, device, terminal and storage medium","The invention discloses a processing method, a device, a terminal and a storage medium for voice interaction, wherein the method comprises the following steps: acquiring a first voice interaction fragment; determining a voice recognition text corresponding to the first voice interaction fragment; extracting semantic segments from the voice recognition text through a semantic extraction model to obtain a first semantic segment; identifying the intention of the first semantic segment to obtain at least one intention identification result; and determining a target intention recognition result to be executed from the at least one intention recognition result. The invention avoids the adverse effect on natural language understanding recognition caused by excessive noise, namely useless input entering the subsequent natural language understanding process, and improves the accuracy rate of intention recognition and execution of the input voice in the streaming voice interaction scene.","['G10L15/22', 'G06F40/30', 'G10L2015/223']"
CN110782395B,"Image processing method and device, electronic equipment and computer readable storage medium","The embodiment of the disclosure provides an image processing method and device, electronic equipment and a computer readable storage medium, and belongs to the technical field of computers and communication. The method comprises the following steps: acquiring an image to be processed; extracting multi-scale current image characteristic information in the image to be processed; encoding the channel and the plane space of the current image characteristic information respectively to enhance the current image characteristic information and obtain current image encoding information; and obtaining a target image of the target magnification of the image to be processed according to the current image coding information. The technical scheme of the embodiment of the disclosure provides an image processing method, which can avoid the occurrence of information loss as far as possible in the process of information transmission by jointly applying the extracted multi-scale current image characteristic information and the current image coding information for enhancing the current image characteristic information, thereby realizing the rapid image super-resolution reconstruction with low parameter quantity and low calculation complexity.","['G06T3/4053', 'G06N3/045', 'G06N3/08', 'G06T9/002']"
US11783203B2,Building energy system with energy data simulation for pre-training predictive building models,"A system for controlling heating, ventilation, or air conditioning (HVAC) equipment of a building includes one or more processing circuits configured to generate simulated building data using a simulation model of the building, pre-train a reinforcement learning (RL) model using the simulated building data, operate the HVAC equipment of the building using the RL model, and retrain the RL model using actual building data generated responsive to operating the HVAC equipment using the RL model.","['G06N5/02', 'G06N3/006', 'G05B13/048', 'G05B15/02', 'G05B19/042', 'G05B19/0426', 'G06F3/0482', 'G06F30/13', 'G06F9/451', 'G06N20/00', 'G06N3/088', 'G06N3/092', 'G05B2219/23291', 'G05B2219/2614', 'G05B2219/2639', 'G05B2219/2642', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N5/01', 'G06N7/01']"
US12182507B2,"Text processing model training method, and text processing method and apparatus","A text processing model training method, and a text processing method and apparatus in the natural language processing field in the artificial intelligence field are disclosed. The training method includes: obtaining training text; separately inputting the training text into a teacher model and a student model to obtain sample data output by the teacher model and prediction data output by the student model; the sample data includes a sample semantic feature and a sample label; the prediction data includes a prediction semantic feature and a prediction label; and the teacher model is a pre-trained language model used for text classification; and training a model parameter of the student model based on the sample data and the prediction data, to obtain a target student model. The method enables the student model to effectively perform knowledge transfer, thereby improving accuracy of a text processing result of the student model.","['G06F40/216', 'G06F16/35', 'G06F16/355', 'G06F18/214', 'G06F18/241', 'G06F18/24133', 'G06F40/166', 'G06F40/279', 'G06F40/30', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0495', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096']"
CN113010703B,"Information recommendation method and device, electronic equipment and storage medium","The application relates to the technical field of computers, in particular to an information recommendation method, an information recommendation device, electronic equipment and a storage medium, which are used for improving accuracy of information recommendation. The method comprises the following steps: extracting semantic features of the multimedia information to be detected and at least one candidate multimedia information to obtain content embedding features of the multimedia information to be detected and content embedding features of the at least one candidate multimedia information; acquiring target multimedia information with an association relation with the multimedia information to be detected from at least one candidate multimedia information based on the content embedding characteristics of the multimedia information to be detected and the content embedding characteristics of the at least one candidate multimedia information; and recommending information based on the association relation between the multimedia information to be detected and the target multimedia information. Because the information recommendation is carried out based on the association relation between the multimedia information to be detected and the target multimedia information, the association and the accuracy between the recommended information are improved.","['G06F16/435', 'G06F16/438', 'G06F16/9535', 'G06F18/2135', 'G06F18/22', 'G06F18/24', 'G06V10/462', 'G06V20/46', 'G06V40/161']"
US10733452B2,Brand safety in video content,"Disclosed herein are techniques for determining brand safety of a video including image frames and audio content. In some embodiments, frame-level features, scene-level features, and video-level features are extracted by a set of frame-level models, a set of scene-level models, and a set of video-level models, respectively. Outputs from lower level models are used as inputs for higher level models. A brand safety score indicating whether it is safe to associate a brand with the video is determined based on the outputs from the set of video-level models. In some embodiments, commercial content associated with the brand is insert into the video that is determined to be safe for the brand.","['G06K9/00744', 'G06V20/41', 'G06K9/00718', 'G06T7/0002', 'G06V20/46', 'G06V20/70', 'G10L15/1815', 'G10L15/22', 'G06K2209/01', 'G06K2209/25', 'G06K2209/27', 'G06T2207/10016', 'G06T2207/20081', 'G06V2201/09', 'G06V2201/10', 'G06V30/10']"
CN112083422B,End-to-end classification method for single-pass InSAR system based on multi-level deep learning network,"The invention discloses a single navigation InSAR system end-to-end classification method based on a multistage deep learning network, which comprises an input SAR image, an InSAR phase diagram and a coherence coefficient diagram; acquiring multi-scale space statistical features from an input SAR image through a multi-scale space feature extraction network MSF; extracting middle-layer and high-layer features from the multi-scale space statistical features through a multi-layer selective attention network MLSAN; and the middle-layer and high-layer characteristics are spliced and weighted through an improved strategy network IS to obtain a final classification result, so that automatic classification of shadows, water bodies and overlapping and masking areas IS realized. The method and the device can automatically detect shadows, water bodies and overlapping areas in the InSAR image aiming at the single-navigation InSAR system, and further improve the phase unwrapping precision.","['G01S13/953', 'G01S13/90', 'G01S13/9094', 'G01S7/02', 'Y02A90/10']"
US20210256304A1,"Method and apparatus for training machine learning model, apparatus for video style transfer","Schemes for training a machine learning model and schemes for video style transfer are provided. In a method for training a machine learning model, at a stylizing network of the machine learning model, an input image and a noise image are received, the noise image is obtained by adding random noise to the input image; at the stylizing network, a stylized input image of the input image and a stylized noise image of the noise image are received respectively; at a loss network coupled with the stylizing network, a plurality of losses of the input image are obtained according to the stylized input image, the stylized noise image, and a predefined target image; the machine learning model is trained according to analyzing of the plurality of losses.","['G06V10/774', 'G06K9/6232', 'G06T11/001', 'G06F18/2413', 'G06K9/627', 'G06N3/04', 'G06N3/08']"
CN111026671B,Test case set construction method and test method based on test case set,"The application relates to a test case set construction method and a test case set-based test method. The method is suitable for synchronous classification of a large number of SQL sentences, improves classification accuracy, enlarges data coverage of test cases, and can obtain more comprehensive test cases. Based on the test method of the test case set, the test cases required by the test are obtained from the test case set to carry out the test, and a more comprehensive and accurate test result is obtained.","['G06F11/3684', 'G06F11/3688', 'Y02D10/00']"
US11494637B2,Layer-wise distillation for protecting pre-trained neural network models,"Neural network protection mechanisms are provided. The neural network protection engine receives a pre-trained neural network computer model and forward propagates a dataset through layers of the pre-trained neural network computer model to compute, for each layer of the pre-trained neural network computer model, inputs and outputs of the layer. For at least one layer of the pre-trained neural network computer model, a differentially private distillation operation is performed on the inputs and outputs of the at least one layer to generate modified operational parameters of the at least one layer. The modified operational parameters of the at least one layer obfuscate aspects of an original training dataset used to train the pre-trained neural network computer model, present in original operational parameters of the at least one layer. The neural network protection engine generates a privatized trained neural network model based on the modified operational parameters.","['G06N3/08', 'G06F21/6227', 'G06N3/0464', 'G06N3/09', 'G06N3/02']"
CN110825901B,"Image-text matching method, device, equipment and storage medium based on artificial intelligence","The invention provides an artificial intelligence-based image-text matching method, an artificial intelligence-based image-text matching device, electronic equipment and a storage medium, wherein the method comprises the following steps: acquiring word characteristics of semantics of each word in a given text, and synthesizing global characteristics of the given text based on each word characteristic; acquiring region position features of the position relation in the characterization region of each region of the candidate image; acquiring regional visual characteristics of each region in the candidate image; combining the regional visual features and the regional position features to form regional features of each region of the corresponding candidate image, and acquiring global features of the corresponding candidate image; based on the word characteristics, the global characteristics of the given text, the regional characteristics and the global characteristics of the candidate images, determining the similarity scores of the candidate images and the given text, and determining that the candidate images are matched with the given text when the similarity scores are larger than a similarity score threshold.","['G06F16/5866', 'G06N3/045']"
CN112836640B,Single-camera multi-target pedestrian tracking method,"A single-camera multi-target pedestrian tracking method comprises the steps of firstly collecting pedestrian video images by using a camera installed in a monitoring area, then correspondingly adjusting the sizes of the collected images, inputting the adjusted images into a trained and improved YoloV-Tiny pedestrian detection network, removing abnormal pedestrian detection frames in detection results by adopting a box division method, inputting the screened detection results into a DeepSort algorithm to track pedestrians and record tracking information, and finally correcting abnormal disappeared pedestrian targets by adopting a correction algorithm based on unmatched frame numbers and predicted positions of the pedestrians. The invention realizes higher performance required by a practical scene based on the improved YoloV-Tiny, the box division method, the improved DeepSort and the correction method of unmatched frame numbers and predicted positions of pedestrians, and has the advantages of simultaneous positioning of multiple targets, accurate positioning, strong real-time performance and high stability.","['G06V40/23', 'G06F18/241', 'G06N3/048', 'G06N3/08', 'G06T7/246', 'G06V10/32', 'G06V10/751', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30232', 'G06T2207/30241', 'G06T3/4007', 'Y02T10/40']"
US11625576B2,Systems and methods for image style transformation,"A method for image processing may include: obtaining an original image of a first style, the original image being generated by a first imaging device; obtaining a target transformation model; and generating a transferred image of a second style by transferring the first style of the original image using the target transformation model. The second style may be substantially similar to a target style of one or more other images generated by a second imaging device. The second style may be different from the first style.","['G06T11/00', 'G06N3/0454', 'G06T3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06T7/30', 'G06T2207/20081', 'G06T2207/20084']"
WO2022116424A1,"Method and apparatus for training traffic flow prediction model, electronic device, and storage medium","A federated transfer learning-based method and apparatus for training a traffic flow prediction model, a device, and a storage medium, relating to artificial intelligence technology. The method comprises: using a local database to train a traffic flow prediction model, and when a loss function converges, obtaining a local model gradient (S1); transferring, by means of transfer learning, the local model gradient to other participants participating in federated transfer learning, such that each participant respectively trains a model thereof (S2); when loss functions of the models of all the participants converge, sending the local model gradient to a cloud (S3); obtaining a standard traffic flow prediction model according to a model gradient that has undergone federated learning and is returned by the cloud (S4); and using the standard traffic flow prediction model to analyze traffic data, so as to obtain a traffic flow analysis result (S5). The invention improves the accuracy of the model and reduces calculation pressure for the model while protecting user data privacy.","['G06Q10/04', 'G06N20/20', 'G06Q50/26']"
US20230394372A1,Systems and methods for transfer learning of neural networks,"Methods and systems may be used for transfer learning of neural networks. According to one example, a method includes: grouping data objects of a first training set into a plurality of clusters; training a base model using a first cluster of the plurality of clusters, the base model being a neural network having a plurality of nodes; generalizing the base model to obtain a generalized base model, the generalizing the base model including setting a portion of the plurality of nodes to have random or predetermined weights; determining that the first cluster is, out of the plurality clusters, most similar to a second training set; and training the generalized base model using the second training set to obtain a trained model.","['G06N20/00', 'G06F18/22', 'G06F18/2321', 'G06F18/23213', 'G06F18/24', 'G06F18/24133', 'G06N3/082', 'G06N7/01', 'G06Q30/0201', 'G06Q30/0202', 'G06Q40/04']"
US11551668B1,Generating representations of speech signals using self-supervised learning,"In one embodiment, a method includes generating audio segments from a speech signal, generating latent representations that respectively correspond to the audio segments, the latent representations comprising a first subset and a second subset, generating quantized representations that respectively correspond to the latent representations, masking the second subset of the latent representations, using a machine-learning model to process the first subset of the latent representations and the masked second subset of the latent representations to generate contextualized representations that respectively correspond to the latent representations, pre-training the machine-learning model based on comparisons between (1) a subset of the contextualized representations that respectively correspond to the masked second subset of the latent representations and (2) a subset of the quantized representations that respectively correspond to the masked second subset of the latent representations, and training the pre-trained machine-learning model to perform a speech analysis task.","['G10L15/063', 'G06F18/2155', 'G06F18/2413', 'G06K9/6259', 'G10L15/065', 'G10L15/16', 'G10L15/26']"
US10990851B2,Method and device for performing transformation-based learning on medical image,"A method and device for performing based learning on a medical image includes reading raw data of a medical image, performing transformation processing on the data by analyzing a data attribute, and integrating the same into a data format capable of being received by a model to be trained; selecting a transformation method by comparing parameters of the model to be trained and a trained model, so as to perform parameter transformation and apply transformation-based learning to training of the model to be trained for the medical image; and upon finishing model training, applying a parameter of a trained model to image category analysis. The invention further includes a device for performing transformation-based learning on a medical image, including: a data processing module; a transformation-based learning module; and an application module.","['G06K9/6257', 'G16H30/40', 'G06F18/214', 'G06F18/2148', 'G06F18/217', 'G06K9/6262', 'G06N20/00', 'G16H50/20', 'G16Z99/00', 'G06K2209/05', 'G06N7/01', 'G06V2201/03']"
WO2023126914A2,METHOD AND SYSTEM FOR SEMANTIC APPEARANCE TRANSFER USING SPLICING ViT FEATURES,"Using a pre-trained and fixed Vision Transformer (ViT) model as an external semantic prior, a generator is trained given only a single structure/appearance image pair as input. Given two input images, a source structure image and a target appearance image, a new image is generated by the generator in which the structure of the source image is preserved, while the visual appearance of the target image is transferred in a semantically aware manner, so that objects in the structure image are ""painted"" with the visual appearance of semantically related objects in the appearance image. A self- supervised, pre-trained ViT model, such as a DINO-ViT model, is lerveraged as an external semantic prior, allowing for training of the generator only on a single input image pair, without any additional information (e.g., segmentation/correspondences), and without adversarial training. The method may generate high quality results in high resolution (e.g., HD).","['G06V10/82', 'G06F3/14', 'G06F18/2415', 'G06T7/11', 'G06T7/143', 'G06V10/422', 'G06V10/54', 'G06V10/56', 'G06V10/761', 'G06V20/70', 'G06T2207/20084']"
CN114120019B,Light target detection method,"The invention discloses a light target detection method, which comprises the following steps: carrying out data enhancement processing on the sample image; acquiring the prior boundary box size of the network model; step two: constructing a target detection network model: the target detection network model is based on YOLOv4, a MobileNet v3 network reconstruction feature extraction network is introduced, standard convolution is replaced by depth separable convolution in PANet, and model parameter quantity and operation quantity are reduced; after the feature layers with the same channel number are convolved, an improved CBAM attention mechanism is integrated, and network detection performance is further improved; step three: training a target detection network model; step four: and detecting by using a target detection network model to obtain a detection result. The invention has the characteristics of improving the efficiency of target detection and reducing the network prediction time.","['G06F18/23213', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'Y02D10/00']"
US11462054B2,Radar-based indoor localization and tracking system,"Embodiments of the present disclosure describe mechanisms for a radar-based indoor localization and tracking system. One example can include monitoring unit that includes a radar source, a camera unit, and one or more processors coupled to the radar element and the camera unit. The monitoring unit is configured to generate point cloud data associated with an object; execute Point Cloud Library (PCL) preprocessing based, at least, on the point cloud data; execute Density-Based Spatial Clustering of Applications with Noise (DBSCAN) clustering; execute multi-object tracking on the object; and execute an image PCL overlay based on the point cloud data to generate real-time data associated with the object.","['G01S7/415', 'G01S13/42', 'G01S13/58', 'G01S13/726', 'G01S13/867', 'G01S13/886', 'G01S7/417', 'G06T7/13', 'G06T7/246', 'G06T7/74', 'G06V10/25', 'G06V10/7635', 'G06V10/806', 'G06V20/52', 'G06V40/23', 'G01C21/206', 'G06T2207/10028', 'G06T2207/30196', 'G06T2207/30232', 'G08B21/0492']"
US11373750B2,Systems and methods for brain hemorrhage classification in medical images using an artificial intelligence network,"Systems and methods for rapid, accurate, fully-automated, brain hemorrhage deep learning (DL) based assessment tools are provided, to assist clinicians in the detection & characterization of hemorrhages or bleeds. Images may be acquired from a subject using an imaging source, and preprocessed to cleanup, reformat, and perform any needed interpolation prior to being analyzed by an artificial intelligence network, such as a convolutional neural network (CNN). The artificial intelligence network identifies and labels regions of interest in the image, such as identifying any hemorrhages or bleeds. An output for a user may also include a confidence value associated with the identification.","['G06T7/0012', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T5/002', 'G06T5/70', 'G06T7/11', 'G16H15/00', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'A61B2576/026', 'A61B5/02042', 'A61B6/032', 'A61B6/469', 'A61B6/5211', 'A61B6/548', 'G01R33/5608', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/20084', 'G06T2207/30016']"
US11234006B2,Training end-to-end video processes,"Methods and systems for optimising the quality of visual data. Specifically, methods and systems for preserving visual information during compression and decompression. An example method for optimising visual data includes using a pre-processing neural network to optimise visual data prior to encoding the visual data in visual data processing; and using a post-processing neural network to enhance visual data following decoding visual data in visual data processing.","['H04N19/33', 'H04N19/117', 'G06T3/4053', 'H04N19/154', 'H04N19/17', 'H04N19/59', 'H04N19/85', 'H04N19/86']"
WO2020001082A1,Face attribute analysis method based on transfer learning,"A face attribute analysis method based on transfer learning, relating to the technical field of calculation and reckon, in particular to the technical field of computer vision for recognizing face attributes. The method comprises: jointly training sample sets on a multi-attribute prediction network to predict feature attributes, transferring the convergent multi-attribute prediction network to a main attribute prediction network, and continuing to train the main attribute prediction network and fine-tuning parameters until a loss function of the main attribute prediction network converges. The main attributes comprise but are not limited to face attributes based on logistic regression and the main attributes of face attributes based on linear regression, so that not only local minima are prevented, but also the precision decrease caused by excessive complexity of tasks is avoided, and the method is more accurate and flexible in practical application.","['G06V40/168', 'G06F18/214', 'G06N3/045', 'G06V40/172']"
US20230395075A1,Human-machine dialogue system and method,"A human-machine dialogue system includes one or more processors configured to execute instructions to cause the human-machine dialogue system to perform operations. The operations include: performing intention clustering of a dialogue data sample based on a semantic representation of the dialogue data sample; constructing, based on a clustering result, a dialogue procedure corresponding to the dialogue data sample; obtaining a semantic representation corresponding to a voice dialogue of a user; performing intention analysis on the semantic representation to obtain an intention analysis result; determining, according to the intention analysis result and the dialogue procedure constructed in advance, a dialogue response; and performing voice interaction of the dialogue response with the user, wherein the dialogue response is an answer response to the voice dialogue, or a clarification response to clarify a dialogue intention of the voice dialogue.","['G06F16/3329', 'G10L15/22', 'G06F16/3343', 'G06F16/3344', 'G10L13/027', 'G10L15/1815', 'G10L15/1822', 'G10L25/63', 'G10L2015/223']"
WO2023071217A1,Multi-working-condition process industrial fault detection and diagnosis method based on deep transfer learning,"Provided is a multi-working-condition process industrial fault detection and diagnosis method based on deep transfer learning, comprising: obtaining historical data of a process industry under a plurality of working conditions, the historical data comprising normal operation data and fault data, and constructing a fault library; standardizing the historical data and arranging same into a two-dimensional matrix; in combination with a maximum mean difference (MMD) of deep transfer learning, training a fault detection model and a fault diagnosis model which are designed, and calculating a detection threshold of the fault detection model; acquiring real-time data, performing corresponding standardization and arrangement processing, then inputting the data into the trained fault detection model to calculate a loss function value, and comparing the loss function value with the detection threshold to determine whether a production system has an anomaly; and if the anomaly occurs, inputting the real-time data into the fault diagnosis model to determine a fault type of the production system.","['G06F30/27', 'G06F18/214', 'G06F2119/02']"
US11507049B2,Method for detecting abnormity in unsupervised industrial system based on deep transfer learning,"The present invention discloses a method for detecting abnormity in an unsupervised industrial system based on deep transfer learning. Labeled machine sensor sequence data from a source domain and unlabeled sensor sequence data from a target domain are used in the present invention to train an industrial system abnormal detection model with good generalization ability, and the industrial system abnormal detection model is trained and tested to finally generate a trained industrial system abnormity discrimination model. Using the model, received machine sensor sequence data can be analyzed and whether a machine is abnormal is discriminated.","['G05B23/024', 'G05B19/4065', 'G06N3/0442', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G06N3/096', 'G05B23/0221']"
CN111274910B,"Scene interaction method, device and electronic equipment","The invention relates to the technical field of artificial intelligence, in particular to a scene interaction method, a scene interaction device, a computer readable medium and electronic equipment. The method comprises the following steps: determining at least one real scene that interacts with the virtual scene; acquiring real scene information of the real scene in real time; extracting features of the real scene information to obtain scene features of the real scene; and mapping scene characteristics of the real scene into the virtual scene according to the corresponding relation between the virtual scene and the real scene. According to the method, the information such as the image and the audio of the real scene is identified, converted and communicated to the on-line server to be displayed on the terminal screen, and the off-line characters and the scene are combined with the on-line virtual scene to be fused and interacted in real time, so that the interaction efficiency is improved, and more rich and various interaction effects can be obtained.","['G06V20/41', 'G06T11/00', 'G06T17/00', 'G06F3/011', 'G06T13/40', 'G06T19/00', 'G06V10/16', 'G06V10/40', 'G06V10/44', 'G06V20/20', 'G06V20/46', 'G06V40/16', 'G06V40/172', 'G06V40/20', 'G10L25/15', 'G06T2210/61', 'G06T2219/024', 'G10L15/08', 'G10L15/26', 'G10L25/57', 'H04L67/02', 'H04L69/16']"
US10685663B2,Enabling in-ear voice capture using deep learning,"A method includes accessing, by at least one processing device, an audible signal including at least one in-ear microphone audible signal and at least one external microphone audible signal and at least one noise signal; training a generative network to generate an enhanced external microphone signal from an in-ear microphone signal based on the at least one in-ear microphone audible signal and the at least one external microphone audible signal; and outputting the generative network.","['G10L21/0208', 'G10K11/16', 'G10K11/17827', 'H04R3/00', 'G10K2210/1081', 'G10L25/30', 'G10L25/84', 'H04R1/1016', 'H04R2201/107']"
CN111650210B,Burr detection method and detection system for high-speed high-precision lithium ion battery pole piece,"A method and a system for detecting burrs of a high-speed high-precision lithium ion battery pole piece are disclosed, wherein the method comprises the steps of S1, electrifying and initializing the detection system; s2, when the detection starts, the high-frequency sampling is carried out on the pole piece of the high-speed line scanning camera; s31, the detection system reads the images collected by the line scanning camera from the memory at preset time intervals; s32, when the detection system reads and detects the scanned image, the line scanning camera simultaneously and parallelly collects the image of the pole piece and stores the image into the memory to wait for the next reading; s4, calculating the length of a pole piece defect post-processing buffer area according to the pole piece winding linear velocity v and the algorithm detection ta time consumption, and performing winding suspension or marking processing according to requirements after the algorithm detects the burr defect; and S5, repeating the steps from S31 to S4 until all the pole pieces are detected. The invention can meet the production requirement under the conditions of high-speed cutting and small burr size.","['G01N21/8851', 'G01N21/01', 'G01N2021/0112', 'G01N2021/8887']"
US11556772B2,Incremental precision networks using residual inference and fine-grain quantization,One embodiment provides for a computing device comprising a parallel processor compute unit to perform a set of parallel integer compute operations; a ternarization unit including a weight ternarization circuit and an activation quantization circuit; wherein the weight ternarization circuit is to convert a weight tensor from a floating-point representation to a ternary representation including a ternary weight and a scale factor; wherein the activation quantization circuit is to convert an activation tensor from a floating-point representation to an integer representation; and wherein the parallel processor compute unit includes one or more circuits to perform the set of parallel integer compute operations on the ternary representation of the weight tensor and the integer representation of the activation tensor.,"['G06N3/08', 'G06F9/46', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06N5/04', 'G06T15/005', 'G06F9/505', 'G06T15/04', 'G06T15/80', 'G06T17/10', 'G06T17/20', 'G06V10/94']"
CN115879535B,"Training method, device, equipment and medium for automatic driving perception model","The disclosure provides a training method, device, equipment and medium for an automatic driving perception model, relates to the technical field of artificial intelligence, in particular to the technical fields of computer vision, image processing, deep learning and the like, and can be applied to scenes such as automatic driving, smart cities and the like. The training method comprises the following steps: acquiring training samples of one or more modalities; carrying out scene training on the perception model by adopting the marked data of the set scene; semi-supervised training is carried out on the scenerised perception model by adopting the training sample so as to update the perception model and form pseudo-annotation data, and the pseudo-annotation data is updated into the training sample; and adopting a training sample, and performing knowledge migration based on the perception model after semi-supervision training to form a vehicle end model. The scheme provided by the disclosure fully plays the advantages of massive data and a large model of the automatic driving scene.",['Y02T10/40']
CN112017645B,Voice recognition method and device,"The application discloses a voice recognition method and a device, wherein the method comprises the following steps: acquiring text data output after voice recognition of voice signals of all clients in a current call through a voice recognizer, wherein the voice recognizer comprises a target field language model; determining the target topic field of the current call according to the text data of each client; judging whether the target domain language model is matched with the target topic domain, if not, switching the target domain language model into a domain language model matched with the target topic domain, so as to dynamically select the target domain language model matched with the topic domain of the current call content, and selecting the optimal recognition result by utilizing the matched target domain language model, thereby improving the recognition rate of the voice recognizer and being suitable for the scene of the call content which dynamically changes in the terminal.","['G10L15/065', 'G06F16/3346', 'G06F16/35', 'G06F18/295', 'G06F40/30', 'G06N3/045', 'G10L15/26']"
CN112765358B,Taxpayer industry classification method based on noise label learning,"A taxpayer industry classification method based on noise label learning comprises the steps of firstly, extracting text information to be mined from taxpayer industry information for text embedding, and performing feature processing on the embedded information; secondly, extracting non-text information in the taxpayer business information for coding; thirdly, constructing a BERT-CNN deep network structure which accords with the taxpayer industry classification problem, and determining the layer number of the network, the number of neurons on each layer and the input and output dimensions according to the processed feature information and the target category number; then, pre-training the constructed network through contrast learning, nearest neighbor semantic clustering and self-label learning in sequence; finally, a noise modeling layer is added on the basis of the built deep network, noise distribution is modeled through the trust of the network and noise label information, and model training is carried out on the basis of noise label data; and finally, taking a deep network in front of the noise modeling layer as a classification model, and classifying taxpayer businesses based on the classification model.","['G06F16/35', 'G06F18/2415', 'G06F40/117', 'G06F40/129', 'G06F40/289', 'G06N3/045', 'G06N3/084', 'G06Q40/10', 'G06F40/30']"
US11127062B2,Systems and methods for promoting products in product search results using transfer learning with active sampling,"Systems and methods including one or more processing modules and one or more non-transitory storage modules storing computing instructions configured to run on the one or more processing modules and perform acts of training a source classifier with labeled source training data of a first product category from a website of an online retailer, clustering target data for a second product category into a plurality of clusters, inserting into each cluster labeled source training data of the first product category, assigning a domain discriminator score to each cluster, determining whether each cluster comprises an agreement cluster or a disagreement cluster using the domain discriminator score, receiving a product search request for a product of the second category from a user of the web site, and coordinating a display of the product on the web site to promote the product.","['G06Q30/0625', 'G06F16/285', 'G06F16/951', 'G06N20/00']"
CN114283117B,An insulator defect detection method based on improved YOLOv3 convolutional neural network,"The invention discloses an insulator defect detection method based on an improved YOLOv < 3 > convolutional neural network, which comprises the steps of firstly constructing a power transmission line insulator sub-image database through a power grid unmanned aerial vehicle inspection image, a public data set and an image sample expansion method, utilizing a LabelImg image marking tool to label insulators and defects on the insulators, secondly improving a network structure of YOLOv < 3 >, namely reducing missed inspection and improving detection precision, providing an improved YOLOv < 3 > convolutional neural network based on an attention mechanism, a weighted dense connection pyramid structure and a double-branch cross-layer attention module, then obtaining an optimal detection model through model training and training parameter adjustment, and finally detecting the defects of the power transmission line insulators. The invention can solve the problems of too small size, false detection and high omission factor of the insulator defect in the power grid inspection image, and improves the accuracy and the rapidity of the insulator defect detection under the complex environment so as to ensure the safety of a power supply system.",['Y04S10/50']
CN112002308B,Voice recognition method and device,"The present disclosure relates to the field of computer technologies, and in particular, to a method and an apparatus for voice recognition, to obtain an audio frame sequence to be recognized; respectively extracting acoustic characteristics of each audio frame to be identified in the audio frame sequence to be identified; decoding the audio frame sequence to be identified according to the acoustic characteristics of each audio frame to be identified and the generated decoding diagram, and determining the identification result of the words corresponding to the audio frame sequence to be identified, wherein the decoding diagram is generated at least according to an acoustic model and a pronunciation dictionary, the acoustic model is used for identifying phonemes based on the acoustic characteristics, the pronunciation dictionary is used for identifying and outputting word texts corresponding to the known phonemes for the known phonemes and identifying and outputting word texts represented by the phoneme texts of the unknown phonemes for the unknown phonemes, so that new words and different pronunciations can be automatically found, and the speech identification accuracy is improved.","['G10L15/02', 'G10L15/26', 'G10L25/27']"
CN109409896B,"Bank fraud recognition model training method, bank fraud recognition method and device","The application provides a bank fraud recognition model training method, a bank fraud recognition method and a bank fraud recognition device, wherein during model training, a plurality of sample user historical operation information and marking information of whether fraud behaviors occur are obtained, and according to the historical operation information of each sample user, characteristic vectors corresponding to various operation behaviors of the sample user in a service channel used by the sample user are determined; inputting the characteristic vector into a pre-constructed target neural network model for transfer learning, and acquiring a fraud identification result of the sample user; and training the target neural network model according to the fraud recognition result and the labeling information to obtain a bank fraud recognition model. The method and the device can enable the trained bank fraud recognition model to learn the characteristics of the user behaviors of various different service channels based on the idea of transfer learning, and have higher accuracy rate for detecting whether the operation behaviors of the user belong to the fraud behaviors based on the bank fraud recognition model.","['G06Q20/4016', 'G06Q40/02']"
US10838848B2,System and method for test generation,"Computer implemented methods and systems are provided for generating one or more test cases based on received one or more natural language strings. An example system comprises a natural language classification unit that utilizes a trained neural network in conjunction with a reinforcement learning model, the system receiving as inputs various natural language strings and providing as outputs mapped test actions, mapped by the neural network.","['G06F11/3684', 'G06F40/284', 'G06F40/30', 'G06F40/35', 'G06N3/006', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N5/022']"
US20210151289A1,"Method, device and system for remote deep learning for microscopic image reconstruction and segmentation","The present invention relates to a method of training a network for reconstructing and/or segmenting microscopic images comprising the step of training the network in the cloud. Further, for training the network in the cloud training data comprising microscopic images can be uploaded into the cloud and a network is trained by the microscopic images. Moreover, for training the network the network can be benchmarked after the reconstructing and/or segmenting of the microscopic images. Wherein for benchmarking the network the quality of the image(s) having undergone the reconstructing and/or segmenting by the network can be compared with the quality of the image(s) having undergone reconstructing and/or segmenting by already known algorithm and/or a second network.","['G06T7/174', 'H01J37/28', 'G06N3/045', 'G06N3/08', 'G06T17/00', 'G06T7/0002', 'G06T7/10', 'H01J37/222', 'H01J37/261', 'G06N20/00', 'G06N3/02', 'G06T2207/10056', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30168', 'H01J2237/226']"
CN110148120B,Intelligent disease identification method and system based on CNN and transfer learning,"The invention provides a disease intelligent identification method and a system based on CNN and transfer learning, which can reduce the interference of picture background, can realize higher identification accuracy under the condition of limited sample quantity, and support the training samples to have higher multi-classification operation efficiency, and the disease image identification method comprises the following steps: preprocessing an image, normalizing the size of the image, and then quickly positioning a disease region by using fast-RCNN to discharge background interference; extracting image features, namely extracting the image features by adopting a triplet similarity measurement model, and then performing weighted fusion by adopting SIFT features as compensation features; and (3) disease classification and identification, namely learning a first image characteristic of a normal plant image by adopting a deep convolutional neural network, learning a second image characteristic of a disease plant image by using transfer learning, and finally performing classification and identification by combining the first image characteristic and the second image characteristic.","['G06N3/045', 'G06N3/08', 'G06T7/0002', 'G06T7/12', 'G06T7/70', 'G06T2207/30188']"
US11599806B2,Depth-constrained knowledge distillation for inference on encrypted data,"This disclosure provides a method, apparatus and computer program product to create a full homomorphic encryption (FHE)-friendly machine learning model. The approach herein leverages a knowledge distillation framework wherein the FHE-friendly (student) ML model closely mimics the predictions of a more complex (teacher) model, wherein the teacher model is one that, relative to the student model, is more complex and that is pre-trained on large datasets. In the approach herein, the distillation framework uses the more complex teacher model to facilitate training of the FHE-friendly model, but using synthetically-generated training data in lieu of the original datasets used to train the teacher.","['G06N3/084', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/04', 'G06N3/0499', 'G06N3/09', 'G06N3/0985', 'G06N5/04', 'H04L9/008', 'G06N5/01']"
US12277406B2,Automatic dataset creation using software tags,"Traditionally, a software application is developed, tested, and then published for use by end users. Any subsequent update made to the software application is generally in the form of a human programmed modification made to the code in the software application itself, and further only becomes usable once tested, published, and installed by end users having the previous version of the software application. This typical software application lifecycle causes delays in not only generating improvements to software applications, but also to those improvements being made accessible to end users. To help avoid these delays and improve performance of software applications, deep learning models may be made accessible to the software applications for use in providing inferenced data to the software applications, which the software applications may then use as desired. These deep learning models can furthermore be improved independently of the software applications using manual and/or automated processes.","['G06F8/30', 'G06F18/214', 'G06F8/71', 'G06F9/541', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/0985', 'G06N3/10', 'G06T5/70', 'G06V10/774', 'G06V10/82', 'H04L67/34', 'G06F8/65', 'G06F8/70', 'G06N3/088', 'H04L67/01']"
CN112541445B,"Transfer method, device, electronic equipment and storage medium of human facial expression","According to the facial expression migration method, the facial expression migration device, the electronic equipment and the storage medium, a real facial image is obtained; inputting the real face image into a pre-trained facial expression recognition network model, and outputting action unit coefficients corresponding to facial expressions in the real face image; the facial expression recognition network model is obtained through training of a virtual facial data set and a real facial data set, wherein the action unit coefficients are used for representing facial data of a human face when the human face is in different expressions; and driving the face of the virtual object to make a corresponding facial expression according to the action unit coefficient so as to realize facial expression migration, namely, the facial expression recognition network model in the embodiment of the invention is obtained by training the virtual face data set and the real face data set together, the recognition rate is more accurate, and the virtual object can make more realistic facial expression.","['G06V40/174', 'G06T3/04', 'G06V40/161', 'G06V40/172', 'Y02D10/00']"
CN112115893B,"Instrument panel pointer reading identification method and device, computer equipment and storage medium","The invention relates to a method, a device, computer equipment and a storage medium for identifying pointer reading of an instrument panel, wherein the method comprises the steps of obtaining an image of the instrument panel to obtain an initial image; inputting the initial image into a target detection model to perform target detection so as to obtain a target detection result; cutting the initial image according to the target detection result to obtain an instrument image; inputting the instrument image into a key point detection model to detect the key point of the pointer so as to obtain key point information; inputting the instrument image into a scale recognition model to recognize the scale position so as to obtain scale digital information; acquiring a pointer angle by combining key point information and scale digital information; determining a scale value corresponding to the pointer according to the pointer angle to obtain a reading result; and feeding back the reading result to the terminal so as to display the reading result at the terminal. The invention can identify various instrument panels, has high identification accuracy, and adopts OCR recognition scales to realize end-to-end pointer angle identification, thereby having high universality.","['G06V20/10', 'G06F18/214', 'G06F18/241', 'G06V10/26', 'G06V10/44', 'G06V2201/02', 'G06V2201/07', 'G06V30/10']"
US20190009408A1,Apparatus and methods for programming and training of robotic devices,"Apparatus and methods for training and operating of robotic devices. Robotic controller may comprise a plurality of predictor apparatus configured to generate motor control output. One predictor may be operable in accordance with a pre-configured process; another predictor may be operable in accordance with a learning process configured based on a teaching signal. An adaptive combiner component may be configured to determine a combined control output controller block may provide control output that may be combined with the predicted control output. The pre-programmed predictor may be configured to operate a robot to perform a task. Based on detection of a context, the controller may adaptively switch to use control output of the learning process to perform the given or another task. User feedback may be utilized during learning.","['B25J9/163', 'B25J9/0081', 'B25J9/1602', 'B25J9/1607', 'B25J9/161', 'B25J9/1666', 'B25J9/1697', 'G05D1/0088', 'G05D1/0246', 'G06N20/00', 'G06N3/00', 'G06N3/008', 'G06N3/049', 'G06N99/005', 'Y10S901/01', 'Y10S901/03', 'Y10S901/09', 'Y10S901/47']"
CA3132346C,User abnormal behavior recognition method and device and computer readable storage medium,"The present invention discloses to user anomaly behavior identification method, apparatus, and computer readable storage medium from computer technology field. The method comprises: obtaining time series data and spatial series data associated with user behavior; according to a plurality of actual indicators values before pre-set time point in the time series data, predicting confidence interval of the indicator through ARIMA model when user is at the pre-set time point; comparing actual indicator value when user is at the pre-set time point with correspondingly confidence interval of indicator, obtaining first detection result for user behavior; according to spatial series data, performing anomaly detection through pre- trained SOM neural network model, obtaining second detection result for user behavior; according to the first detection result and the second detection result, performing anomaly identification on user behavior. The implementations of present invention can achieve accurate and reliable identification of user anomaly behavior.","['G06N3/088', 'G06F18/23', 'G06N3/02']"
TWI799191B,System and method for knowledge-preserving neural network pruning,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for knowledge-preserving sparse pruning on neural networks are described. An exemplary method includes obtaining a pre-trained machine learning model trained based on a plurality of general-purpose training data; training a task-specific machine learning model by tuning the pre-trained machine learning model based on a plurality of task-specific training data corresponding to a task; constructing a student network based on the task-specific machine learning model; simultaneously performing (1) knowledge distillation from the trained task-specific machine learning model as a teacher network to the student network and (2) network pruning on the student network; and obtaining the trained student network for serving the task.","['G06N3/082', 'G06N3/045', 'G06N3/0495', 'G06N3/0499', 'G06N3/088', 'G06N3/09', 'G06N3/096']"
US11363929B2,Apparatus and methods for programming and training of robotic household appliances,"Apparatus and methods for training and operating of robotic appliances. Robotic appliance may be operable to clean user premises. The user may train the appliance to perform cleaning operations in constrained areas. The appliance may be configured to clean other area of the premises automatically. The appliance may perform premises exploration and/or determine map of the premises. The appliance may be provided priority information associated with areas of the premises. The appliance may perform cleaning operations in order of the priority. Robotic vacuum cleaner appliance may be configured for safe cable operation wherein the controller may determine one or more potential obstructions (e.g., a cable) along operating trajectory. Upon approaching the cable, the controller may temporarily disable brushing mechanism in order to prevent cable damage.","['A47L9/2847', 'A47L9/009', 'A47L9/2805', 'A47L9/2842', 'A47L9/2852', 'G05D1/0221', 'G06N3/008', 'A47L2201/04', 'A47L2201/06', 'G05D2201/0215', 'G06N3/049']"
US11526680B2,Pre-trained projection networks for transferable natural language representations,"Systems and methods are provided to pre-train projection networks for use as transferable natural language representation generators. In particular, example pre-training schemes described herein enable learning of transferable deep neural projection representations over randomized locality sensitive hashing (LSH) projections, thereby surmounting the need to store any embedding matrices because the projections can be dynamically computed at inference time.","['G06N3/082', 'G06F40/216', 'G06F18/213', 'G06F18/214', 'G06F40/268', 'G06F40/284', 'G06F40/289', 'G06F40/295', 'G06F40/30', 'G06F40/44', 'G06F40/56', 'G06K9/6256', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0472', 'G06N3/0495', 'G06N3/0499', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/82', 'H04L67/04']"
WO2022048182A1,"Image style transfer method and apparatus, and image style transfer model training method and apparatus","Disclosed are an image style transfer method and apparatus, and an image style transfer model training method and apparatus. The image style transfer method comprises: respectively inputting first-style images and second-style images into a content encoder and a style encoder in an encoder network, and respectively extracting content encoded feature images and style encoded feature images; and respectively inputting the style encoded feature images and the content encoded feature images into a decoder network, so as to obtain target images that are transferred from a first style to a second style, wherein an image style transfer model composed of the encoder network and the decoder network is obtained by means of performing pre-training on the basis of image training samples that comprise a plurality of first-style images and second-style images, and instance images cropped from the image training samples. By using the present invention, the style transfer adaptability to a plurality of different scenarios can be improved, the problems of image blur, and poor instance effects in an image after style transfer can be ameliorated, and coarse-grained and fine-grained high-quality image style transfer can also be achieved.","['G06T3/04', 'G06T7/11', 'G06T9/002', 'G06T2207/10024', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
US11137462B2,System and method for quantifying cell numbers in magnetic resonance imaging (MRI),"A system and method are provided for tracking magnetically-labeled substances, such as transplanted cells, in subjects using magnetic resonance imaging (MRI). The method includes obtaining a quantity of a substance that comprises an MRI contrast compound or is otherwise magnetically-labeled for purposes of an MRI scan, administering the substance into a region of interest of a subject, performing an imaging scan of a portion of the subject comprising the region of interest, obtaining an imaging data set from the scan, reducing the dataset into pixel groupings based on intensity profiles, where the pixel groupings have a pixel size larger than the expected pixel size of a unit of the MRI contrast compound or magnetically-labeled substance, extracting candidate pixel matrices from the imaging data, training a machine learning (ML) module by using the candidate pixel matrices, quantifying the presence, number and/or location of units of the substance within the subject by using the ML module, and displaying a visual representation of an identification of the substances within the subject as a result of using the ML module.","['G01R33/5601', 'A61B5/055', 'A61B5/7267', 'A61B5/742', 'A61B5/7475', 'A61K49/1896', 'G01R33/5608', 'G06F18/2414', 'G06K9/0014', 'G06K9/00147', 'G06K9/6273', 'G06V10/764', 'G06V10/82', 'G06V20/695', 'G06V20/698', 'A61B2576/00', 'G01R33/546', 'G16H30/40', 'G16H50/70']"
US10565707B2,3D anisotropic hybrid network: transferring convolutional features from 2D images to 3D anisotropic volumes,"A computer-implemented method for identifying features in 3D image volumes includes dividing a 3D volume into a plurality of 2D slices and applying a pre-trained 2D multi-channel global convolutional network (MC-GCN) to the plurality of 2D slices until convergence. Following convergence of the 2D MC-GCN, a plurality of parameters are extracted from a first feature encoder network in the 2D MC-GCN. The plurality of parameters are transferred to a second feature encoder network in a 3D Anisotropic Hybrid Network (AH-Net). The 3D AH-Net is applied to the 3D volume to yield a probability map;. Then, using the probability map, one or more of (a) coordinates of the objects with non-maximum suppression or (b) a label map of objects of interest in the 3D volume are generated.","['G06V10/764', 'G06F18/2414', 'G06F18/2415', 'G06K9/00201', 'G06K9/4628', 'G06K9/6232', 'G06K9/6273', 'G06K9/6277', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06T11/60', 'G06T7/0012', 'G06V10/454', 'G06V10/82', 'G06V20/64', 'G16H30/20', 'G06T2207/10112', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068']"
CN112732934B,Construction method of word segmentation dictionary and fault case database for power grid equipment,"A power grid equipment word segmentation dictionary and a fault case library construction method are provided, wherein a power grid field word segmentation dictionary is constructed, then preprocessing such as format conversion and word segmentation is carried out on fault case data, and then information such as a structured power grid equipment fault case, a feature tag, a keyword cloud, association rules and the like is analyzed and generated from text data by using various technical means. And designing a relational database Schema for the information, taking a report as a main key, and storing the text information and the information such as pictures, authors and the like reserved in the preprocessing together to form a power grid equipment fault case library. The word segmentation accuracy of the text in the power grid field is improved, the structured case database enables the retrieval according to the case content to be more accurate, the feature labels in the fault case database are used as item sets, effective association rules of faults are sorted and mined, the method can be used for fault early warning, and the blank of the application of the text analysis technology in the power grid field is filled. The application value of the corpora in the field of the power grid is improved, and the consulting cost is reduced.","['G06F16/374', 'G06F16/3344', 'G06F16/35', 'G06F40/211', 'G06F40/242', 'G06F40/247', 'G06F40/295', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'Y04S10/50']"
US11288771B2,Texture hallucination for large-scale image super-resolution,"Systems and methods for texture hallucination with a large upscaling factor are described. Embodiments of the systems and methods may receive an input image and a reference image, extract an upscaled feature map from the input image, match the input image to a portion of the reference image, wherein a resolution of the reference image is higher than a resolution of the input image, concatenate the upscaled feature map with a reference feature map corresponding to the portion of the reference image to produce a concatenated feature map, and generate a reconstructed image based on the concatenated feature map using a machine learning model trained with a texture loss and a degradation loss, wherein the texture loss is based on a high frequency band filter, and the degradation loss is based on a downscaled version of the reconstructed image.","['G06T3/4053', 'G06T3/4046', 'G06T3/4084']"
US10423925B2,Kiosk cluster,"A kiosk cluster may include a plurality of kiosks. Each kiosk may include an inventory shelf, image capturing device, sensors, display device, a processor and memory coupled with the processor. The processor identifies relevant inventory items matching with a current context determined via real time data analytics. The processor captures data associated with a user within the premises of the kiosk cluster via the image capturing device and the sensors. The data may include navigation path, facial expressions, features and actions or behaviors pertaining to one or more relevant inventory items. Further, the processor determines interest of the user in a relevant inventory item and future positions of the user on the navigation path. The processor displaces a kiosk holding the relevant inventory item in the direction of the future positions on the navigation path to be available for the purchase by the user.","['G06Q10/087', 'G06Q20/18', 'G06Q30/06', 'G07F17/26', 'G07F9/023']"
US11734493B2,Enhanced data orchestration with pre-trained machine learning models,"A method of enhanced data orchestration (EDO). The method comprises receiving a first message by a mediation application executing on a computer system and analyzing the first message by the mediation application based at least in part on invoking a machine learning (ML) model by the mediation application, wherein the analyzing determines that a feature of the first message is a probable first component of an item of personally identifiable information (PII). The method further comprises receiving a second message by the mediation application, determining by the mediation application that a feature of the second message when combined with the feature of the first message constitutes an item of PII, and treating the first message and the second message in accordance with predefined PII handling protocols by the mediation application.","['G06F40/117', 'G06F40/30', 'G06F16/254', 'G06F16/9577', 'G06F40/106', 'G06F40/295', 'G06N20/00', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06F40/143', 'G06F40/216', 'G06N3/044', 'G06N3/045']"
US12055464B2,Systems and methods for improved pipeline leak detection,"Provided herein are systems and methods to detect pipeline leaks. The systems and method can identify a pipeline pressure surge by applying a trained convolutional neural network (CNN) model for classifying pipeline pressure measurement images on each sensor site of a plurality of sensor sites, transfer pressure surge information obtained from at least a portion of the plurality of sensor sites to a cloud site, and determine whether the identified pressure surge is a pipeline leak at the cloud site using the pressure surge information. The plurality of sensor sites collect pipeline pressure measurement data. The pressure surge information corresponds to the identified pipeline pressure surge.","['F17D5/02', 'G01M3/2815', 'G06N3/043', 'G06N3/0464', 'G06N3/096']"
US12131122B2,Pre-trained contextual embedding models for named entity recognition and confidence prediction,"At least one processor may obtain a document comprising text tokens. The at least one processor may determine, based on a pre-trained language model, word embeddings corresponding to the text tokens. The at least one processor may determine, based on the word embeddings, named entities corresponding to the text tokens; and one or more accuracy predictions corresponding to the named entities. The at least one processor may compare the one or more accuracy predictions with at least one threshold. The at least one processor may associate, based on the comparing, the named entities with one or more confidence levels. The at last one processor may deliver the named entities and the one or more confidence levels.","['G06F40/295', 'G06F40/284', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06V10/40', 'G06V30/10']"
CN111861103B,Fresh tea classification method based on multiple features and multiple classifiers,"The invention provides a fresh tea leaf classification method based on multiple characteristics and multiple classifiers, which comprises the following steps: extracting geometric features and texture features from the tea image training samples, and inputting SVM training to obtain a trained SVM model; predicting a tea image to be predicted by using the trained SVM model to obtain classification probability of each type of tea based on an SVM classifier; performing corner detection and distance matrix similarity calculation on the tea image training sample, and obtaining tea classification probabilities of various types based on special angle quantity and distance matrix according to the corner detection result and the distance matrix similarity; fusing the classification probability of each type of tea based on the SVM classifier and the classification probability of each type of tea based on the special angle quantity and distance matrix by adopting a KNN result to obtain the final classification probability of each type of tea; in the classification probabilities of the various types of the final vegetable leaves, the class label corresponding to the maximum probability value is the final classification result; the beneficial effects provided by the invention are as follows: the accuracy of tea classification is improved.","['G06Q10/06395', 'G06F18/2411', 'G06F18/2415', 'G06V10/44', 'Y02P90/30']"
CN109816589B,Method and apparatus for generating manga style transfer model,"The embodiment of the disclosure discloses a method and a device for generating a cartoon style conversion model. One embodiment of the method comprises: acquiring a training sample set; acquiring a pre-established generation countermeasure network; by using a machine learning method, a sample image included in a training sample set is used as an input of a generation network, a sample cartoon style image corresponding to the input sample image is used as an expected output of the generation network, a cartoon style image actually output by the generation network and a sample cartoon style image corresponding to the input sample image are used as inputs of a discrimination network, the generation network and the discrimination network are trained, and the trained generation network is determined as a cartoon style conversion model. According to the embodiment, the problems of image edge sawtooth, image outline deformation and the like of the generated cartoon style image relative to the original image can be reduced, and the display effect of the generated cartoon style image is improved.","['G06N3/0464', 'G06N3/04', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/00']"
US11164108B2,Transfer learning without local data export in multi-node machine learning,"A trained base model is distributed to a set of nodes. From a first node in the set of nodes, a first set of meta-metrics resulting from a transfer learning operation on the trained base model at the first node is collected. The transfer learning at the first node uses first local data available at the first node. The first node is clustered in a cluster with a second node from the set of nodes, in response to a meta-metric in the first set of meta-metrics being within a tolerance value of a corresponding meta-metric in a second set of meta-metrics collected from the second node. A normalized set of model parameters is constructed after an iteration of transfer learning or local learning at the first and second nodes. The normalized set of model parameters is distributed to the first node and the second node in the cluster.","['G06N20/00', 'G06F16/285', 'G06F18/256', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N3/08', 'G06V10/811']"
US20250187135A1,Machine vision as input to a cmp process control algorithm,"During chemical mechanical polishing of a substrate, a signal value that depends on a thickness of a layer in a measurement spot on a substrate undergoing polishing is determined by a first in-situ monitoring system. An image of at least the measurement spot of the substrate is generated by a second in-situ imaging system. Machine vision processing, e.g., a convolutional neural network, is used to determine a characterizing value for the measurement spot based on the image. Then a measurement value is calculated based on both the characterizing value and the signal value.","['B24B37/013', 'B24B37/005', 'B24B49/04', 'B24B49/12', 'G06N3/084', 'H01L21/304', 'H01L21/67', 'H01L21/67092', 'H01L21/67242', 'G06N3/045', 'G06N3/048']"
US10909416B2,Deep variational method for deformable image registration,"A correspondence between a source image and a reference image is determined. A generative model corresponds to a prior probability distribution of deformation fields, each deformation field corresponding to a respective coordinate transformation. A conditional model generates a style transfer probability distribution of reference images, given a source image and a deformation field. The first image data is the source image, and the second image data is the reference image. An initial first deformation field is determined. An update process is iteratively performed until convergence to update the first deformation field, to generate a converged deformation field representing the correspondence between the source image and the reference image. The update process includes: determining a change in one or more characteristics of the first deformation field to increase a posterior probability density associated with the first deformation field, given the source image and reference image; and changing the one or more characteristics in accordance with the determined change.","['G06K9/6215', 'G06T7/35', 'G06F17/18', 'G06F18/22', 'G06N20/20', 'G06N3/084', 'G06N5/046', 'G06V10/7557', 'G06T2207/10072', 'G06T2207/20084']"
US11361753B2,System and method for cross-speaker style transfer in text-to-speech and training data generation,"Systems are configured for generating spectrogram data characterized by a voice timbre of a target speaker and a prosody style of source speaker by converting a waveform of source speaker data to phonetic posterior gram (PPG) data, extracting additional prosody features from the source speaker data, and generating a spectrogram based on the PPG data and the extracted prosody features. The systems are configured to utilize/train a machine learning model for generating spectrogram data and for training a neural text-to-speech model with the generated spectrogram data.","['G10L13/033', 'G10L15/063', 'G10L13/02', 'G10L13/04', 'G10L13/08', 'G10L13/10', 'G10L15/1807', 'G10L15/187', 'G10L25/18', 'G10L25/30', 'G10L25/63', 'G10L2021/0135']"
CN111651671B,"User object recommendation method, device, computer equipment and storage medium","The application relates to a user object recommendation method, a user object recommendation device, computer equipment and a storage medium based on artificial intelligence. The method comprises the following steps: acquiring user characteristic information of a target user; obtaining local graph network structure information associated with the target user in a user graph network; the user graph network is constructed based on the user information and the user interaction behavior information of all user objects in the user set; performing information transfer processing based on the user characteristic information and the local graph network structure information through a pre-trained matching degree prediction model to obtain user graph representation information corresponding to the target user; determining a matching degree predicted value between the target user and each user object in the user graph network based on the user graph representation information; and determining a user object meeting recommendation conditions according to the matching degree predicted value, and recommending the user object to the target user. By adopting the method, the recommendation efficiency and recommendation accuracy of the user object can be effectively improved.","['G06F16/9535', 'G06F16/9536']"
CN113609859B,A Chinese named entity recognition method for special equipment based on pre-training model,"A Chinese named entity recognition method for special equipment based on a pre-training model comprises the following steps of 1) marking a Chinese named entity data set according to a Chinese named entity marking strategy BIEOS, dividing entity categories into four categories, 2) converting Chinese sentences into word vector representations based on a BERT pre-training model, 3) inputting the word vector representations into a biLSTM model, learning word vector sequences to bidirectionally encode, extracting sentence characteristics, 4) obtaining all possible tag sequences of each Chinese character by adopting the tag probability of a CRF conditional random field learning context, and 5) finally outputting entity categories corresponding to the Chinese character sequences. The invention trains the non-label corpus in an unsupervised mode, can effectively solve the problem of extracting the Chinese named entity under the condition of insufficient characteristic information of a small data set and a sample, and is used for constructing a knowledge graph in the field of special equipment.","['G06F40/295', 'G06F16/35', 'G06F16/367', 'G06F40/216', 'G06N3/044', 'G06N3/088', 'G06N5/02']"
US11704799B2,Systems and methods for medical image style transfer using deep neural networks,"The current disclosure provides for mapping medical images to style transferred medical images using deep neural networks, while maintaining clinical quality of the style transferred medical image, thereby enabling a clinician to evaluate medical images in a preferred style without loss of clinically relevant content. In one embodiment the current disclosure provides for a method comprising, acquiring a medical image of an anatomical region of a subject, wherein the medical image is in a first style, selecting a target style, wherein the target style is distinct from the first style, selecting a clinical quality metric, selecting a trained style transfer network based on the target style and the clinical quality metric, mapping the medical image to a style transferred medical image using the trained style transfer network, wherein the style transferred medical image is in the target style, and displaying the style transferred medical image via a display device.","['G06T7/0014', 'G06T5/60', 'G06T5/92', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068', 'G06T2207/30096', 'G06T2207/30168']"
WO2022050678A2,Method of training a device using machine learning,"An object of the present disclosure is to provide a pluggable camera that is mounted on top of shelf units can be equipped with AI and embedded computer vision algorithms to identify shoppers and monitor their shopping activities. To this end, the camera provides an easy to install and scalable solution that can detect items being picked up or returned to shelves by a shopper for tracking shopper behavior analytics and inventory management systems. The pluggable camera is a highly scalable solution because the camera can be mounted onto any unit shelf for an easy installation in existing store fronts such that it would require minimal to no change in the layout of the stores and no need for external calibration of the cameras.","['G06Q10/087', 'G01G19/4144', 'G01G19/42', 'G01G23/01', 'G06F18/251', 'G06N20/00', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06Q20/203', 'G06Q20/206', 'G06Q20/208', 'G06T7/251', 'G06T7/73', 'G06V10/762', 'G06V10/774', 'G06V10/82', 'G06V20/52', 'G06V40/107', 'G06V40/161', 'G06V40/168', 'G06V40/172', 'G06V40/28', 'G07G1/0063', 'G07G1/0072', 'G07G1/14', 'H04N23/61', 'G06F2218/12', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06T2207/30232']"
US11461650B2,Validation of deep neural network (DNN) prediction based on pre-trained classifier,"According to an aspect of an embodiment, operations may include receiving a first data point associated with a real-time application and predicting a first class for the received first data point, by a Deep Neural Network (DNN) pre-trained for a classification task of the real-time application. The operations may further include extracting, from the DNN, a first set of features and a corresponding first set of weights, for the predicted first class. The extracted first set of features may be associated with a convolution layer of the DNN. The operations may further include determining, by a pre-trained classifier associated with the predicted first class, a confidence score for the predicted first class based on the extracted first set of features and the corresponding first set of weights. The operations may further include generating output information to indicate correctness of the predicted first class based on the determined confidence score.","['G06N3/08', 'G06F16/285', 'G06F16/55', 'G06N20/00', 'G06N3/0464', 'G06N3/09', 'G06N5/02', 'G06N3/045']"
US12299561B2,On-the-fly deep learning in machine learning for autonomous machines,"A mechanism is described for facilitating on-the-fly deep learning in machine learning for autonomous machines. A method of embodiments, as described herein, includes detecting an output associated with a first deep network serving as a user-independent model associated with learning of one or more neural networks at a computing device having a processor coupled to memory. The method may further include automatically generating training data for a second deep network serving as a user-dependent model, where the training data is generated based on the output. The method may further include merging the user-independent model with the user-dependent model into a single joint model.","['G06N3/063', 'G06F18/214', 'G06F18/2148', 'G06F18/2411', 'G06F18/2413', 'G06F9/3887', 'G06F9/46', 'G06F9/5027', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06T1/20', 'G06T1/60', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V10/95', 'G06V10/955', 'G06V20/00', 'G06F9/505', 'G06V2201/06', 'G06V40/174']"
US11640526B2,Methods and apparatus for enhancing a neural network using binary tensor and scale factor pairs,"Methods and apparatus are disclosed for enhancing a neural network using binary tensor and scale factor pairs. For one example, a method of optimizing a trained convolutional neural network (CNN) includes initializing an approximation residue as a trained weight tensor for the trained CNN. A plurality of binary tensors and scale factor pairs are determined. The approximation residue is updated using the binary tensors and scale factor pairs.","['G06N3/08', 'G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N5/003', 'G06N5/01', 'G06N3/044', 'G06N3/082']"
US11763100B2,System and method for controllable machine text generation architecture,"A system is provided comprising a processor and a memory storing instructions which configure the processor to process an original sentence structure through an encoder neural network to decompose the original sentence structure into an original semantics component and an original syntax component, process the original syntax component through a syntax variation autoencoder (VAE) to receive a syntax mean vector and a syntax covariance matrix, obtain a sampled syntax value from a syntax Gaussian posterior parameterized by the syntax mean vector and the syntax covariance matrix, process the original semantics component through a semantics VAE to receive a semantics mean vector and a semantics covariance matrix, obtain a sampled semantics vector from the Gaussian semantics posterior parameterized by the semantics mean vector and the semantics covariance matrix, and process the sampled syntax vector and the sampled semantics vector through a decoder neural network to compose a new sentence.","['G06F40/56', 'G06F40/30', 'G06F40/211', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/08']"
AU2019202063B2,Synthesizing new font glyphs from partial observations,"OF THE DISCLOSURE Techniques are disclosed for the synthesis of a full set of slotted content, based upon only partial observations of the slotted content. With respect to a font, the slots may comprise particular letters or symbols or glyphs in an alphabet. Based upon partial observations of a subset of glyphs from a font, a full set of the glyphs corresponding to the font may be synthesized and may further be ornamented. 1/18 en sGlyphShape Subse 104 JointlySynthesize All G G phhape r Test/Inference 106 Jointly Perform Ornamentation All Glyph Shapes 108 FIG.la","['G06T11/203', 'G06F40/109', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/40', 'G06T11/60']"
US20240160945A1,Autonomous driving methods and systems,"A method of training a deep reinforcement learning model for autonomous control of a machine, such as autonomous vehicles, the model being configured to output, by a policy network, an agent action in response to input of state information and a value function, the agent action representing a control signal for the machine. The method comprises minimizing a loss function of the policy network; wherein the loss function of the policy network comprises an autonomous guidance component and a human guidance component (human intervention); and wherein the autonomous guidance component is zero when the state information is indicative of a human input signal.","['G06N3/084', 'G06N3/092', 'B60W60/00', 'G06N3/006', 'G06N3/045', 'B60W2050/0082', 'B60W2050/0088', 'B60W60/001']"
US9440025B2,Apparatus and method for controlling insulin infusion with state variable feedback,"An infusion system, which may be a closed loop infusion system or “semi-closed-loop” system, uses state variable feedback to control the rate that fluid is infused into the body of a user. The closed loop infusion system includes a sensor system, a controller, and a delivery system. The “semi-closed-loop” system further includes prompts that are displayed or sounded or otherwise provide indications to the user prior to fluid delivery. The sensor system includes a sensor for monitoring a condition of the user. The sensor produces a sensor signal, which is representative of the condition of the user. The delivery system infuses a fluid into the user at a rate dictated by the commands from the controller. The system may use three state variables, subcutaneous insulin concentration, plasma insulin concentration, and insulin effect, and corresponding gains, to calculate an additional amount of fluid to be infused as a bolus and to be removed from the basal delivery of the fluid.","['A61M5/1723', 'A61B5/14532', 'A61B5/14539', 'A61B5/14865', 'A61B5/6849', 'A61M5/14244', 'A61M5/158', 'A61M5/1582', 'A61M2005/14296', 'A61M2005/1581', 'A61M2005/1726', 'A61M2230/201']"
EP4471616A1,Model training method and related device,"This application may be applied to the artificial intelligence field, and specifically discloses a model training method. The method includes: obtaining a second embedding vector input to a decoder in a pre-trained language model, where the second embedding vector corresponds to a second data sequence, the second data sequence includes first sub-data, a masked to-be-predicted data unit, and second sub-data, the first sub-data is located before the to-be-predicted data unit in the second data sequence, and the second sub-data is located after the to-be-predicted data unit in the second data sequence; obtaining a hidden state based on a first embedding vector by using an encoder in the pre-trained language model PLM; and predicting the to-be-predicted data unit based on the first sub-data, the second sub-data, and the hidden state by using the decoder in the PLM and an output layer of the decoder. In this application, a corresponding PLM does not need to be pre-trained for each type of sequence generation task, thereby greatly reducing resources required for training the PLM.","['G06N3/08', 'G06F16/3329', 'G06F16/3344', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0895']"
WO2018196760A1,Ensemble transfer learning,"An apparatus and method are provided for ensemble transfer learning. One or more first (machine learning) projects that are similar to a second (machine learning) project are identified by comparing metadata of the one or more first projects and the second project, where the metadata comprises a plurality of characteristics and the characteristics of the first projects are compared to the characteristic of the second project to identify the one or more first projects. One or more (machine learning) models associated with the one or more first projects are selected as a plurality of models that each share a common feature set with the second project. Each model in the plurality of models is applied to input data for the second project to generate a set of results. Output data corresponding to the input data is produced for the second project based on the set of results.","['G06N20/20', 'G06N20/00']"
US11601105B2,Ambient sound activated device,Environmental sound is recorded using one or more microphones. A source of the recorded environmental sound is classified. The recorded environmental sound is weighted based on the classification of the source and the source media sound using a weighting mode to determine whether to mix the recorded environmental. The recorded environmental sound is mixed with source media sound to produce a mixed sound based on the determination. The mixed sound is played over one or more speakers.,"['H03G3/02', 'H03G3/32', 'H03G5/025', 'H03G5/165', 'H04R1/1091', 'H04R5/033', 'H04S3/004', 'H04R2205/022', 'H04R2420/01', 'H04R2430/03', 'H04R3/005', 'H04R5/04', 'H04S2400/01', 'H04S2400/11', 'H04S2420/07', 'H04S7/304']"
CN116820429B,"Training method and device of code processing model, electronic equipment and storage medium","The application provides a training method, a training device, an electronic device, a computer program product and a computer readable storage medium of a code processing model; the method comprises the following steps: acquiring a general corpus training set, a domain corpus training set and an instruction data set; pre-training a code processing model based on the universal corpus training set to obtain a pre-trained code processing model; invoking the pre-trained code processing model to perform field training processing based on at least part of samples in the general corpus training set and the field corpus training set to obtain a code processing model in a specific field; and calling a code processing model in a specific field based on the instruction data set to train to obtain a trained code processing model, wherein the trained code processing model is used for generating codes serving as answer contents based on the input question instructions. The method and the device can improve the accuracy of the code processing model in generating the code in the specific field.","['G06F8/30', 'G06N20/00', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'Y02D10/00']"
CN115294407B,Model compression method and system based on preview mechanism knowledge distillation,"The invention belongs to the field of computer vision image classification, and provides a model compression method and system based on preview mechanism knowledge distillation to solve the problems of poor accuracy and instability in image classification identification. Acquiring an image sample, marking a label of the image sample, and performing supervision training on a student network; enabling the student network and a pre-trained teacher network to perform output alignment, feature alignment, category center alignment and category center comparison learning; calculating difficulty scores of the image samples, and dynamically distributing weights of different image samples; obtaining a total loss function based on loss functions of supervision training, output alignment, feature alignment, category center alignment and category center comparison learning and weights of different image samples; and guiding the training of the student network according to the total loss function to obtain the trained student network which is used as an image classification model for carrying out class distribution prediction on the input image. Which improves the accuracy of the image recognition classification.","['G06V10/764', 'G06N3/082', 'G06N5/02', 'G06V10/7788', 'G06V10/82']"
CN110222551B,"Method and device for identifying action type, electronic equipment and storage medium","The invention relates to a method and a device for identifying action types, electronic equipment and a storage medium, and belongs to the technical field of computers. The method comprises the following steps: acquiring skeleton data of continuous multi-frame images, wherein the skeleton data of each frame of image comprises a plurality of joint point positions; extracting feature data of the skeleton data of the multi-frame images based on a pre-trained feature extraction model; and determining action attribute information corresponding to the multi-frame images based on the feature data and a pre-trained action recognition model, wherein the action attribute information comprises an action category. By adopting the invention, the efficiency of identifying the action category can be improved.","['G06F18/214', 'G06V40/20']"
CN108256561B,Multi-source domain adaptive migration method and system based on counterstudy,"The invention discloses a multi-source domain adaptive migration method and system based on antagonistic learning, wherein the method comprises the following steps: the method comprises the following steps that firstly, source domain data are used for pre-training, and a representation network and a classifier of a target model are initialized; step two, multi-path countermeasure is carried out by using the multi-source domain data and the target domain data, and the representation network and the multi-path discriminator of the target model are updated; step three, calculating the confrontation score between each source domain and each target domain; classifying the target domain based on the classifier and the confrontation score of each source domain; selecting a high-confidence target domain pseudo sample to finely adjust a representation network and a classifier of the target model; and step six, returning to the step two, performing the step two-five, and stopping training until the model converges or the maximum iteration times is reached.","['G06F18/24', 'G06F18/2148']"
US10572723B2,Activity detection by joint human and object detection and tracking,"A computing device includes a communication interface, a memory, and processing circuitry. The processing circuitry is coupled to the communication interface and to the memory and is configured to execute the operational instructions to perform various functions. The computing device is configured to process a video frame of a video segment on a per-frame basis and based on joint human-object interactive activity (HOIA) to generate a per-frame pairwise human-object interactive (HOI) feature based on a plurality of candidate HOI pairs. The computing device is also configured to process the per-frame pairwise HOI feature to identify a valid HOI pair among the plurality of candidate HOI pairs and to track the valid HOI pair through subsequent frames of the video segment to generate a contextual spatial-temporal feature for the valid HOI pair to be used in activity detection.","['G06K9/00342', 'G06T7/0016', 'A61B5/0002', 'A61B5/1113', 'A61B5/1123', 'A61B5/1128', 'A61B5/7267', 'A63B24/0062', 'G06K9/00771', 'G06K9/4628', 'G06T7/246', 'G06V10/454', 'G06V20/52', 'G06V40/20', 'G06V40/23', 'A61B5/1117', 'G06T2207/10004', 'G06T2207/10016', 'G06T2207/30196', 'G06T2207/30221', 'G16H50/70']"
US10043112B2,Photo management,A method for image processing includes determining features of multiple stored images from a pre-trained deep convolutional network. The method also includes clustering each image of the multiple stored images based on the determined features.,"['G06K9/66', 'G06N20/00', 'G06F16/583', 'G06F17/30247', 'G06F18/214', 'G06F18/2178', 'G06F18/2411', 'G06F18/2413', 'G06K9/4628', 'G06K9/6256', 'G06K9/6269', 'G06N20/10', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06N99/005', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V30/19133', 'G06V30/19167', 'G06V30/19173']"
CN108647996B,Spark-based personalized recommendation method and system,"The invention discloses a Spark-based personalized recommendation method and system, wherein the personalized recommendation method comprises the following steps: acquiring behavior information of a user on a commodity, carrying out preprocessing, and acquiring implicit feedback of the user on the commodity; constructing an interaction matrix of the user to the commodity according to implicit feedback of the user to the commodity, and acquiring the interaction matrix of the user to the commodity; performing commodity similarity matrix calculation processing on the interaction matrix of the commodity according to the user to obtain a commodity similarity matrix; constructing a commodity proximity set according to the commodity similarity matrix to obtain a commodity proximity set; predicting the preference value of the user to the commodity according to the commodity proximity set to obtain the preference value of the user to the commodity; and recommending commodities to the user according to the preference value of the user to the commodities, and displaying the recommendation result. In the embodiment of the invention, multi-source information is fused, the behavior information of the user on the commodity is fully utilized, and the problems of data sparseness and cold start are solved.","['G06Q30/0201', 'G06Q30/0271', 'G06Q30/0631']"
CN111932144B,"Customer service agent distribution method and device, server and storage medium","The application provides a customer service agent distribution method, a customer service agent distribution device, a server and a storage medium, wherein the customer service agent distribution method, the server and the storage medium are used for receiving consultation problems sent by customers and determining text information representing the consultation problems; the text information is classified based on the pre-trained customer service agent allocation model to determine a candidate customer service mode for providing consultation service for customers, so that the problem of inaccurate customer service agent allocation caused by dependence on the corresponding relation between keywords and customer service agents in the prior art is avoided; and under the condition that the candidate customer service agents transfer customers to the target customer service agents, the customer service agent distribution model is automatically optimized based on the target customer service agents and the consultation problem, so that the accuracy of customer service agent distribution based on the customer service agent distribution model in the follow-up process is improved, accurate recommendation of the customer service agents is realized, and the convenience of post maintenance of the customer service agent distribution method is improved.","['G06Q10/063112', 'G06F16/35', 'G06F40/205', 'G06Q30/01']"
CN112215255B,"Training method of target detection model, target detection method and terminal equipment","The application is applicable to the technical field of image processing, and provides a training method of a target detection model, which comprises the following steps: acquiring a plurality of data sets, wherein each data set comprises a source domain image and a target domain image; converting the source domain image and the target domain image in each dataset to obtain a transition domain image; inputting the transition domain image and the target domain image into an countermeasure learning model, and training a target detection model to obtain a trained target detection model; the countermeasure learning model includes a target detection model and the domain classification model; the object detection model and domain classification model are used for countermeasure learning. According to the scheme, the domain classification model and the target detection model are used for performing countermeasure learning, so that the target detection model is suitable for different scenes, and the detection accuracy of images in different scenes is improved.","['G06F18/214', 'G06F18/24', 'G06N3/08', 'G06V2201/07', 'G06V2201/09', 'Y02T10/40']"
US12300006B2,Method and system for digital staining of microscopy images using deep learning,"A deep learning-based digital/virtual staining method and system enables the creation of digitally/virtually-stained microscopic images from label or stain-free samples. In one embodiment, the method of generates digitally/virtually-stained microscope images of label-free or unstained samples using fluorescence lifetime (FLIM) image(s) of the sample(s) using a fluorescence microscope. In another embodiment, a digital/virtual autofocusing method is provided that uses machine learning to generate a microscope image with improved focus using a trained, deep neural network. In another embodiment, a trained deep neural network generates digitally/virtually stained microscopic images of a label-free or unstained sample obtained with a microscope having multiple different stains. The multiple stains in the output image or sub-regions thereof are substantially equivalent to the corresponding microscopic images or image sub-regions of the same sample that has been histochemically stained.","['G06V20/69', 'G06V20/698', 'G06F18/24137', 'G06T11/001', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G06T2207/10056', 'G06T2207/20084']"
CN111785257B,Empty pipe voice recognition method and device for small amount of labeled samples,"The invention relates to the field of civil aviation air traffic control and voice recognition, in particular to an air traffic control voice recognition method and device aiming at a small number of labeled samples. The method and the device train the recognition model backbone network by using the unlabeled data based on the neural network, can obtain the air traffic control voice recognition model with good recognition accuracy and high efficiency under the condition of labeling a small amount of samples, can accurately and quickly output corresponding air traffic control instruction text information based on the air traffic control voice recognition model after inputting the air traffic control voice, and improve the usability of the application of the air traffic control voice recognition technology and the expandability under a new scene.","['G10L15/063', 'G08G5/56', 'G10L15/02', 'G10L15/16', 'G10L15/22', 'G10L15/26', 'Y02T10/40']"
US20200219274A1,Neural style transfer for image varietization and recognition,"Systems and methods for image recognition are provided. A style-transfer neural network is trained for each real image to obtain a trained style-transfer neural network. The texture or style features of the real images are transferred, via the trained style-transfer neural network, to a target image to generate styled images which are used for training an image-recognition machine learning N model (e.g., a neural network). In some cases, the real images are clustered and representative style images are selected from the clusters.","['G06V10/772', 'G06F18/2155', 'G06F18/28', 'G06K9/6255', 'G06K9/6259', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T7/45', 'G06V10/7753', 'G06F18/23', 'G06N20/00']"
WO2023231995A1,Transfer-learning-based life prediction and health assessment method for aero-engine,"The present invention relates to a transfer-learning-based life prediction and health assessment method for an aero-engine. The method comprises the steps of: data collection and data storage; data pre-processing; and health factor construction. The beneficial effects of the present invention involve: in the present invention, firstly, a construction process of a health state division factor is proposed; secondly, key performance parameters are extracted by using an extreme gradient boosting regression model, which is less affected by an extreme deviation value and has higher generalization, and dimension reduction is performed on data; useful features which are associated with the service life and the health state are then mined by using an automatic feature extraction capability of a gated recurrent unit network for multi-dimensional time sequence data, so as to realize residual service life prediction and health assessment; and finally, the model is generalized under different flight states by using a transfer learning strategy, so as to realize multi-working-condition model transfer; and the present invention efficiently utilizes historical operation data resources within the whole life cycle of an aero-engine, so as to provide a reliable basis for life prediction and health assessment of the aero-engine.","['G06F30/27', 'G06F17/18', 'G06F30/17', 'G06N3/08', 'G06F2113/08', 'G06F2119/04', 'G06F2119/14', 'Y02T90/00']"
US20220215266A1,Systems and methods for synthesizing data for training statistical models on different imaging modalities including polarized images,"A method of generating synthetic images of virtual scenes includes: placing, by a synthetic data generator implemented by a processor and memory, three-dimensional (3-D) models of objects in a 3-D virtual scene; adding, by the synthetic data generator, lighting to the 3-D virtual scene, the lighting including one or more illumination sources; applying, by the synthetic data generator, imaging modality-specific materials to the 3-D models of objects in the 3-D virtual scene in accordance with a selected multimodal imaging modality, each of the imaging modality-specific materials including an empirical model; setting a scene background in accordance with the selected multimodal imaging modality; and rendering, by the synthetic data generator, a two-dimensional image of the 3-D virtual scene based on the selected multimodal imaging modality to generate a synthetic image in accordance with the selected multimodal imaging modality.","['G06T17/00', 'G06N3/088', 'G06T15/00', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06T15/04', 'G06T15/20', 'G06T17/20', 'G06T19/20', 'G06T2207/20081', 'G06T2219/2021', 'G06T2219/2024']"
CN112215604B,Method and device for identifying transaction mutual-party relationship information,"The embodiment of the specification provides a method and a device for identifying information of transaction relationships. The method comprises the following steps: acquiring a knowledge graph constructed based on a plurality of relationships among a plurality of users; the knowledge-graph comprises a plurality of nodes corresponding to a plurality of users and a plurality of categories of connecting edges constructed corresponding to a plurality of relations, wherein the plurality of users comprise natural human users and/or enterprise users; then, carrying out graph embedding processing on the knowledge graph by using a pre-trained graph embedding model to obtain node embedding vectors corresponding to each node; embedding two nodes corresponding to two users related to the target transaction into vectors, respectively forming triples with edge embedded vectors of connecting edges of each category, inputting a pre-trained prediction model, and predicting the evaluation score corresponding to each triplet through the prediction model. Relationship category information between the users is further identified based on the evaluation score to assist in determining whether the transaction is secure.","['G06Q20/382', 'G06F16/367', 'G06Q20/4014']"
US12045729B2,"Neural network compression method, apparatus and device, and storage medium","A neural network compression method whereby forward inference is performed on target data by using a target parameter sharing network to obtain an output feature map of the last convolutional module, a channel related feature is extracted from the output feature map, the extracted channel related feature and a target constraint condition are input into a target meta-generative network, and an optimal network architecture under the target constraint condition is predicted by using the target meta-generative network to obtain a compressed neural network model.","['G06N3/082', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/0895', 'G06N3/0985', 'G06N5/046']"
US20210406476A1,"Method, electronic device, and storage medium for extracting event from text","The disclosure provides a method for extracting an event from a text, an electronic device and a storage medium, relate to fields of knowledge graph, deep learning, and natural language processing. The method includes: obtaining an input text; inputting the input text into a model for extracting trigger words to obtain a trigger word extraction result of the input text; inputting the input text and the trigger word extraction result into a model for extracting arguments to obtain an argument extraction result of the input text; and obtaining an event extraction result of the input text according to the trigger word extraction result and the argument extraction result.","['G06F40/279', 'G06F40/117', 'G06F40/237', 'G06F40/284', 'G06F40/289', 'G06F40/30', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'Y02D10/00']"
US11704569B2,Methods and apparatus for enhancing a binary weight neural network using a dependency tree,"Methods and apparatus are disclosed for enhancing a binary weight neural network using a dependency tree. A method of enhancing a convolutional neural network (CNN) having binary weights includes constructing a tree for obtained binary tensors, the tree having a plurality of nodes beginning with a root node in each layer of the CNN. A convolution is calculated of an input feature map with an input binary tensor at the root node of the tree. A next node is searched from the root node of the tree and a convolution is calculated at the next node using a previous convolution result calculated at the root node of the tree. The searching of a next node from root node is repeated for all nodes from the root node of the tree, and a convolution is calculated at each next node using a previous convolution result.","['G06N3/063', 'G06N3/082', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/09', 'G06N5/01', 'G06N3/084']"
US11361225B2,Neural network architecture for attention based efficient model adaptation,"A neural network architecture for attention-based efficient model adaptation is disclosed. A method includes accessing an input vector, the input vector comprising a numeric representation of an input to a neural network. The method includes providing the input vector to the neural network comprising a plurality of ordered layers, wherein each layer in at least a subset of the plurality of ordered layers is coupled with an adaptation module, wherein the adaptation module receives a same input value as a coupled layer for the adaptation module, and wherein an output value of the adaptation module is pointwise multiplied with an output value of the coupled layer to generate a next layer input value. The method includes generating an output of the neural network based on an output of a last one of the plurality of ordered layers in the neural network.","['G06N3/084', 'G06K9/62', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/82']"
US9659233B2,Method and apparatus for detecting salient region of image,"The present invention provides a method and an apparatus for detecting a salient region of an image. Classification processing is obtained by means of pre-training, so as to obtain a classification label, where the classification label is used to indicate a salience detection algorithm for detecting a salient region of the test image. Salience detection is performed on the test image by using the salience detection algorithm indicated by the classification label, so as to obtain the salient region of the test image. Because a salience detection algorithm with the best detection effect is acquired by using the image feature vector of the test image, to detect the salient region of the test image, accuracy of salience detection is improved.","['G06K9/623', 'G06V10/451', 'G06F18/2113', 'G06F18/214', 'G06K9/4623', 'G06K9/4642', 'G06K9/4652', 'G06K9/481', 'G06K9/6256', 'G06K9/66', 'G06K9/80', 'G06V10/20', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20164']"
WO2022195285A1,Image processing using machine learning,"A method of processing image data, comprises receiving one or more target images and at least one reference source. The method processes the at least one reference source and the one or more target images to extract features using a convolutional neural network. In addition the method processes the features of the one or more target images and the at least one reference source using a transformer network to provide an attention output. The attention output is provided as an input to a convolutional neural network decoder. In addition skip connections are provided from the convolutional neural network encoder to provide features of the one or more target images to the convolutional neural network decoder at one or more decoder layers. Finally, the extracted features of the one or more target images and the attention output are processed using the convolutional neural network decoder to produce one or more output images. The output images take the style of the reference source. In one example, this style is by taking colourisation from the reference source. In another example interpolation is provided between two images and the reference source itself comprises two images.","['G06T5/77', 'G06T11/00', 'G06N3/045', 'G06N3/084', 'G06T5/50', 'G06T11/001', 'G06T2207/20084']"
US11657266B2,"Cooperative multi-goal, multi-agent, multi-stage reinforcement learning","According to one aspect, cooperative multi-goal, multi-agent, multi-stage (CM3) reinforcement learning may include training a first agent using a first policy gradient and a first critic using a first loss function to learn goals in a single-agent environment using a Markov decision process, training a number of agents based on the first policy gradient and a second policy gradient and a second critic based on the first loss function and a second loss function to learn cooperation between the agents in a multi-agent environment using a Markov game to instantiate a second agent neural network, each of the agents instantiated with the first agent neural network in a pre-trained fashion, and generating a CM3 network policy based on the first agent neural network and the second agent neural network. The CM3 network policy may be implemented in a CM3 based autonomous vehicle to facilitate autonomous driving.","['G06N3/006', 'G05D1/0088', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/092', 'G06N3/096', 'G06N7/01', 'H04W4/44', 'G06N3/048']"
US11341177B1,Deep reinforcement learning-based captioning with embedding reward,An image captioning system and method is provided for generating a caption for an image. The image captioning system utilizes a policy network and a value network to generate the caption. The policy network serves as a local guidance and the value network serves as a global and lookahead guidance.,"['G06N3/006', 'G06F16/3344', 'G06F16/338', 'G06F18/256', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06V10/44', 'G06V10/768', 'G06V10/811', 'G06V10/82', 'G06V10/94', 'G06V30/194', 'G06N5/02', 'G06N5/022']"
US10904259B1,Graphical user interface and console management system for distributed terminal network,"A graphical user interface (GUI) and operator console management system for a distributed terminal network is described. In some embodiments, the terminals may be hardware terminals, kiosks, or clients. In some embodiments, a security analysis may be performed, and security scores may be determined, for visitors requesting operations at terminals based on an operator configuration. Security scores may be determined by a provider, in communication with the operator terminals, based on aggregation of a plurality of factors, wherein each factor may be weighted. The factors may incorporate operator settings or preferences. In one embodiment, the factors include one or more facial recognition factors. The one or more facial recognition factors may be used for biometric authentication. The provider may use the security scores to determine user privileges or permissions for the operations. The provider may deliver instructions or messages to the terminals based on the determinations.","['H04L63/0428', 'G06F21/31', 'G06F21/45', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/098', 'G06Q20/206', 'G06Q20/40', 'G06Q30/0185', 'H04L12/4641', 'H04L63/0272', 'H04L63/08', 'H04L63/0823', 'H04L63/0861', 'H04L63/102', 'H04L63/1416', 'H04L63/145', 'H04L63/166', 'H04L63/168', 'H04L67/02', 'H04L67/10', 'H04L9/3226', 'H04W12/72']"
CN111382580B,Encoder-decoder framework pre-training method for neural machine translation,"The invention discloses a coder-decoder framework pre-training method for neural machine translation, which comprises the following steps: constructing massive multilingual document-level monolingual corpus, and adding a special identifier in front of each sentence to represent the language type of the sentence; processing the sentence pairs to obtain training data; training the monolingual data of different languages to obtain a pre-training model parameter after convergence; establishing a parallel corpus, and initializing parameters of a neural machine translation model by using parameters of a pre-training model; the initialized neural machine translation model finely adjusts model parameters through parallel corpora to complete the training process; in the decoding stage, the source language sentences are encoded by using the encoder of the trained neural machine translation model, and the decoder decodes the source language sentences to generate target language sentences. The invention enables the model to have language modeling capability and language generation capability, applies the pre-training model to the neural machine translation model, can accelerate the convergence speed of the model and improve the robustness of the model.","['G06N3/08', 'Y02D10/00']"
WO2022037233A1,Small sample visual target identification method based on self-supervised knowledge transfer,"A small sample visual target identification method based on self-supervised knowledge transfer. The method comprises: 1) collecting unlabeled auxiliary data which is weakly related to a task and has a relatively large amount of data, and labeled target data which is strongly related to the task and has a relatively small amount of data; 2) constructing, on the unlabeled auxiliary data with a relatively large amount of data and by means of data conversion, a positive sample pair and a negative sample pair, and performing self-supervised learning by using a contrast loss function, so as to pre-train a deep neural network; 3) extracting a feature of target data by using a pre-trained model, and performing data dimension reduction on the basis of a feature space, so as to learn of a feature sub-space with a relatively strong discriminative ability regarding the target data; and 4) using a feature expression, in the sub-space, of a small amount of labeled data of each category as a feature prototype of the category, and performing classification prediction on test data by using a nearest neighbor method.","['G06V20/41', 'G06F18/2135', 'G06F18/241', 'G06N3/045', 'G06N3/08']"
CN110377911B,Method and device for identifying intention under dialog framework,"The invention provides an intention recognition method and device under a dialogue framework, wherein the method comprises the following steps: obtaining the matching degree of the corpus to be identified and rule monomers in a preset rule template, wherein the preset rule template comprises a plurality of rule monomers, and each rule monomer corresponds to one label; judging whether the matching degree is larger than a preset threshold value or not; if so, taking the label of the rule monomer corresponding to the maximum matching degree as an intention recognition result; if not, inputting the corpus to be recognized into a pre-trained intention recognition model, and taking the output of the pre-trained intention recognition model as an intention recognition result, wherein the intention of the user can be accurately recognized by using a machine learning model to recognize the intention of the user when a rule template cannot effectively recognize the intention of the user, the requirement on the number of training samples is low, and the development of artificial intelligent equipment such as a question-answering system, a dialogue robot and the like is promoted.","['G06F40/30', 'Y02D10/00']"
US12245536B2,"Systems, methods, and apparatuses for implementing automated data modeling and scaling of a soil health data fabric","An example system may implement automated data modeling and scaling of a soil health data fabric. For example, the example system may be configured to compile data measurements from disparate soil health data sources and integrate the data measurements with baseline soil samples, satellite imagery, or both. According to such an example, the system may train a machine learning algorithm using the integrated data measurements to determine most accurate local soil quality estimates and execute the machine learning algorithm to output soil quality estimate data models based on the data measurements. The example system may also train and refine local soil quality estimate data models to generate a regional soil quality estimate data model. In such an example, the system may scale the local and regional soil quality estimate data models and output soil quality estimates for a target region based on extended satellite imagery.","['G06F18/2148', 'G06Q10/06395', 'G06Q10/067', 'G06Q50/02', 'G06V10/82', 'G06V20/188', 'H04L63/12', 'H04L9/3236', 'A01B79/005', 'G01N33/24', 'G06Q2220/00', 'H04L2209/805', 'H04L9/50']"
US11853401B1,Machine learning model creation via user-configured model building blocks,"Techniques for machine learning (ML) model training and deployment using model building blocks via graphical user interfaces (GUIs) are described. Users can use a GUI provided by an electronic device to select and configure ML aspects for one or more ML models to be trained using identified training data. The electronic device can send a request to cause a model construction service to train one or more ML models based on the user configuration, return results of the training to the user within the GUI, and deploy one or more of the ML models.","['G06F18/40', 'G06F18/214', 'G06F18/2163', 'G06F18/217', 'G06F3/04842', 'G06F3/0486', 'G06F8/34', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'H04L67/10']"
US11620582B2,Automated machine learning pipeline generation,"Techniques regarding one or more automated machine learning processes that analyze time series data are provided. For example, one or more embodiments described herein can comprise a system, which can comprise a memory that can store computer executable components. The system can also comprise a processor, operably coupled to the memory, and that can execute the computer executable components stored in the memory. The computer executable components can comprise a time series analysis component that selects a machine learning pipeline for meta transfer learning on time series data by sequentially allocating subsets of training data from the time series data amongst a plurality of machine learning pipeline candidates.","['G06N20/20', 'G06N3/042', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/01', 'G06N5/022', 'G06N20/10', 'G06N3/04', 'G06N3/086', 'G06N7/01']"
US10949702B2,System and a method for semantic level image retrieval,A system and method for retrieval of similar images related to query images is provided. The query images are pre-processed for noise removal by selecting filtering technique based on noise variance estimation in each query image with respect to pre-set noise variance threshold value. The pre-processed query images are pre-classified for determining class one image identifier. Image types are generated from pre-processed query images for determining class two image identifier. Features are extracted from pre-classified query images based on class one image identifier and from generated images based on class two image identifier. The images similar to query images are retrieved which have features similar to extracted features of pre-classified query images and generated images. The retrieved similar images are ranked for determining most similar images with respect to query images. Similarity between query images and retrieved similar images is analyzed for re-ranking retrieved similar images.,"['G06N3/088', 'G06K9/4623', 'G06F16/535', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/002', 'G06T5/20', 'G06T5/70', 'G06V20/00', 'G06N20/00', 'G06N7/01']"
CN113169887B,Radio network self-optimization based on data from radio networks and spatio-temporal sensors,One technique includes receiving sensor data samples from one or more sensors; receiving a radio network information data sample associated with a radio network; determining a first set of one or more associated sensors and radio network information data samples based on an association of the received one or more sensor data samples with one or more of the received radio network information data samples; developing a trained model based on at least a portion of the first set of associated sensors and radio network information data samples related to performance of the radio network; and improving performance of the radio network based at least on the model.,"['H04B17/29', 'H04L41/16', 'H04B17/15', 'H04L43/022', 'H04W24/10']"
US12124933B2,Artificial intelligence system for anomaly detection in transaction data sets,"An artificial intelligence system configured to detect anomalies in transaction data sets. The system includes a processor and a computer readable medium operably coupled thereto, the computer readable medium comprising a plurality of instructions stored in association therewith that are accessible to, and executable by, the processor, to perform modeling operations which include receiving a first data set for training a first machine learning model to detect anomalies in the transaction data sets using a machine learning technique, accessing at least one micro-model trained using at least one second data set separate from the first data set, determining risk scores from the first data set using the at least one micro-model, enriching the first data set with the risk scores, and determining the first machine learning model for the enriched first data set using the machine learning technique.","['G06N20/20', 'G06N20/00', 'G06Q20/4016', 'G06F21/60']"
US11831867B2,"Apparatus, a method and a computer program for video coding and decoding","A method comprising: obtaining a configuration of at least one neural network comprising a plurality of intra-prediction mode agnostic layers and one or more intra-prediction mode specific layers, the one or more intra-prediction mode specific layers corresponding to different intra-prediction modes; obtaining at least one input video frame comprising a plurality of blocks; determining to encode one or more blocks using intra prediction; determining an intra-prediction mode for each of said one or more blocks; grouping blocks having same intra-prediction mode into groups, each group being assigned with a computation path among the plurality of intra-prediction mode agnostic and the one or more intra-prediction mode specific layers; training the plurality of intra-prediction mode agnostic and/or the one or more intra-prediction mode specific layers of the neural networks based on a training loss between an output of the neural networks relating to a group of blocks and ground-truth blocks, wherein the ground-truth blocks are either blocks of the input video frame or reconstructed blocks; and encoding a block using a computation path assigned to an intra-prediction mode for the block.","['H04N19/11', 'H04N19/174', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04N19/159', 'H04N19/176', 'H04N19/192', 'H04N19/593', 'H04N19/85', 'G06N3/044']"
EP4244718A1,Methods and systems for trusted unknown malware detection and classification in linux cloud environments,"A method for detection of unknown malware in Linux cloud environment, the method including: within a hypervisor, acquiring a raw data set comprising one or more volatile memory dumps of a Linux cloud server, wherein the volatile memory dumps are associated with a current state of the virtual machine's volatile memory, extracting one or more features from the raw data set (either by utilizing knowledge based features or by utilizing Deep Learning CNN architectures), and classifying, using at least one classifier, the one or more features, to determine if one or more of the features are associated with a malware, thereby detecting malware in a Linux cloud environment and distinguishing between a benign or malicious state of the server.","['G06F21/566', 'G06F21/56', 'G06F21/53', 'G06F9/45533', 'G06F9/45558', 'G06N3/0464', 'G06F2009/45587', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06N5/01', 'G06N7/01']"
US20210089903A1,Neural network for generating images trained with a generative adversarial network,"A generative adversarial network, a method of training a generator neural network, and a method of generating images using the generator network is provided. The generator neural network is configured to process an input comprising a noise vector and a pair of conditioning variables to generate an image according to the conditioning variables. The generator neural network includes a mixed-conditional batch normalization layer. The mixed-conditional batch normalization layer is configured to normalize a network layer output to generate a normalized network layer output, comprising transforming the network layer output in accordance with mixed-conditional batch normalization layer parameters to generate the normalized network layer output, wherein the mixed-conditional batch normalization layer parameters are computed by applying an affine transformation to the conditioning variables.","['G06N3/084', 'G06F18/2132', 'G06K9/6234', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06T3/4046', 'G06T3/4053', 'G06N20/20']"
US11836650B2,Artificial intelligence engine for mixing and enhancing features from one or more trained pre-existing machine-learning models,"An AI engine having an architect module to create a number of nodes and how the nodes are connected in a graph of concept nodes that make up a resulting AI model. The architect module also creates a first concept node by wrapping an external entity of code into a software container with an interface configured to exchange information in a protocol of a software language used by the external entity of code. The architect module also creates a second concept node derived from its description in a scripted file coded in a pedagogical programming language, and connects the second concept node into the graph of nodes in the resulting AI model.","['G06Q10/00', 'G06F15/80', 'G06F16/2228', 'G06F16/951', 'G06F18/2148', 'G06F3/0482', 'G06F30/20', 'G06F30/27', 'G06F8/31', 'G06F8/311', 'G06F8/35', 'G06F8/36', 'G06F8/38', 'G06F9/451', 'G06F9/4881', 'G06N20/00', 'G06N3/006', 'G06N3/008', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/0985', 'G06N3/10', 'G06N3/105', 'G06N5/04', 'G06N7/01', 'G06V10/945', 'G06V10/96', 'H04L67/01', 'G06F3/03543', 'G06F30/333', 'G06F40/166', 'H04L67/02']"
US11475590B2,Keypoint based pose-tracking using entailment,"Aspects of the present disclosure describe systems, methods and structures for an efficient multi-person posetracking method that advantageously achieves state-of-the-art performance on PoseTrack datasets by only using keypoint information in a tracking step without optical flow or convolution routines. As a consequence, our method has fewer parameters and FLOPs and achieves faster FPS. Our method benefits from our parameter-free tracking method that outperforms commonly used bounding box propagation in top-down methods. Finally, we disclose tokenization and embedding multi-person pose keypoint information in the transformer architecture that can be re-used for other pose tasks such as pose-based action recognition.","['G06T7/73', 'G06T7/74', 'G06T7/246', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30196']"
WO2020134556A1,"Image style transfer method, device, electronic apparatus, and storage medium","The present application discloses an image style transfer method, a device, an electronic apparatus, and a storage medium. The image style transfer method comprises: acquiring an image to be processed; using a style transfer model to process the image, and obtaining a first styled image, wherein the style transfer model is obtained in advance by performing model training according to content images, second styled images, and third styled images, the second styled images are obtained by performing styling processing on the content images, and the third styled images are obtained by processing the content images using a neural network model. In the present application, style transfer processing is performed on an image to be processed by using a pre-trained style transfer model, and procedures related to a loss function, such as solution finding and optimization, are eliminated from a style transfer process, thereby achieving fast style transfer. In addition, the style transfer model is obtained by performing supervised learning of a neural network model using paired input and output samples, thereby improving styling performance of the model.","['G06T11/00', 'G06T3/00']"
US12307815B2,Face recognition method and face recognition apparatus,"A face recognition method. The method includes: obtaining a face image to be recognized; extracting a face image feature based on the face image by using a pre-trained feature extraction network; extracting a plurality of facial geometric feature points from the face image to determine a plurality of feature point sets, where each of the plurality of feature point sets corresponds to one face part, and the feature point set includes at least one facial geometric feature point; obtaining a face topology structure feature based on the plurality of feature point sets, where the face topology structure feature is used to determine a relative location relationship between the plurality of feature point sets; and performing matching in a preset face database based on the face topology structure feature and the face image feature, to obtain a face recognition result.","['G06V40/161', 'G06N3/045', 'G06N3/084', 'G06V10/82', 'G06V40/165', 'G06V40/168', 'G06V40/171', 'G06V40/172']"
US11645462B2,Continuous machine learning method and system for information extraction,"Methods and systems for artificial intelligence (AI)-assisted document annotation and training of machine learning-based models for document data extraction are described. The methods and systems described herein take advantage of a continuous machine learning approach to create document processing pipelines that provide accurate and efficient data extraction from documents that include structured text, semi-structured text, unstructured text, or any combination thereof.","['G06F40/279', 'G06N20/00', 'G06N3/0464', 'G06N3/084', 'G06V10/40', 'G06V30/18', 'G06V30/18057', 'G06V30/19013', 'G06V30/19107', 'G06V30/19147', 'G06V30/19167', 'G06V30/414', 'G06V30/42', 'G06N3/048', 'G06V30/10']"
US10834128B1,System and method for identifying phishing cyber-attacks through deep machine learning via a convolutional neural network (CNN) engine,"The presently disclosed subject matter includes a system for the detection of phishing cyber-attacks based on an application of deep machine learning techniques including the implementation of a deep convolutional neural network to determine whether a web element associated with a uniform resource locator is part of a phishing cyber-attack. The system produces a notification indicative of the phishing cyber-attack when a positive match between the uniform resource locator and the phishing cyber-attack is determined. The convolutional neural network is retrained at periodic time intervals with new datasets retrieved by an automated dataset collector and thus, improves the detection of zero-days cyber-attacks.","['H04L51/18', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'H04L51/212', 'H04L63/1483', 'H04L67/02', 'G06N20/00', 'H04L63/145']"
CN112733550B,"Knowledge distillation-based language model training method, text classification method and device","The application discloses a language model training method based on knowledge distillation, a text classification method and a text classification device. The language model training method comprises the following steps: inputting the training corpus into the first model and the second model for processing so as to acquire corresponding middle layer data and output results; and calculating to obtain first hidden layer sentence content and second hidden layer sentence content by using corresponding middle layer data, constructing a comparison learning positive and negative example based on the first hidden layer sentence content and the second hidden layer sentence content, training a second model by using the comparison learning positive and negative example, the corresponding middle layer data and an output result, and determining the trained second model as a language model. Through the classification model, the sentence grammar and the semantic representation rich in the first model can be migrated to the second model, so that the second model obtained by distillation has better migration capability, and the application requirements of the cross-field are met.","['G06F40/30', 'G06F18/214', 'G06F40/211', 'Y02D10/00']"
CN110738057B,Text style migration method based on grammar constraint and language model,"The invention provides a text style migration method based on grammar constraint and language model, which comprises extracting grammar relation graph G of input sentence x by Stanford dependency syntax tool package x Then the grammar relation graph G is mapped by a self-grammar-transducer structure x Adding style information S of original input sentence x Style information S of sentence after expected conversion y Obtaining grammar relation graph G' x And G' y Then combining grammar relation graph G of original input sentence x The input sentence x 'is reconstructed by a cross-graph-transformer structure to obtain the sentence y' after style migration. In order to better learn self-graph-transducer structures blended with style information and to learn cross-graph-transducer structures of reconstructed style migration sentences, the method also utilizes a language model to replace a traditional CNN classifier to guide the learning of the latter. Experiments on corresponding data sets in such a way show that the semantic invariance can be better kept under the condition of changing sentence styles compared with the previous text style migration method.","['G06N3/045', 'Y02D10/00']"
CN110515760B,LDPC flash error correction method based on machine learning,"The invention relates to a machine learning-based flash LDPC error correction method, which comprises the following steps: hard decision is carried out on the scrambled coded data according to the reference voltage set between the storage states, and the maximum turnover number marked in the check equation corresponding to each information node is counted; transmitting the codeword which reaches the hard decoding failure of the iteration times to an AI engine, selecting an optimal reference voltage according to an input data set through a pre-trained neural network model, and inquiring a calibration table of read compensation to obtain a read voltage; each reading of the read voltage retrieves metadata related to the data waiting for error correction, inputs the read sequence Y of 0 or 1 to a pre-trained AI engine, loads a log likelihood ratio table to the AI engine, trains and learns the update iteration of the confidence probability between the information node and the check node by setting a neural network transfer function, and makes a decision on the received sequence Y according to a maximum posterior probability decoding criterion.","['G06F11/1068', 'G06N3/084', 'G11C29/42']"
US10902270B2,Machine learning platform for performing large scale data analytics,"To address problems that video imaging systems and platforms face when analyzing image and video content for detection and feature extraction, a solution is provided in which accumulating significant amounts of data suitable for training and learning analytics is leveraged to improve over time, the classifiers used to perform the detection and feature extraction, by employing a larger search space and generate additional and more complex classifiers through distributed processing. A distributed learning platform is therefore provided, which is configured for operating on large scale data, in a true big data paradigm. The learning platform is operable to empirically estimate a set of optimal feature vectors and a set of discriminant functions using a parallelizable learning algorithm. A method of adding new data into a database utilized by such a learning platform is also provided. The method comprises identifying an unrepresented sample space; determining new data samples associated with the unrepresented sample space; and adding the new data samples to the database.","['G06K9/00785', 'G06N20/00', 'G06F18/214', 'G06F18/41', 'G06K9/00973', 'G06K9/6254', 'G06K9/6256', 'G06V10/774', 'G06V10/7788', 'G06V10/94', 'G06V20/54']"
US10867595B2,Cold fusing sequence-to-sequence models with language models,"Described herein are systems and methods for generating natural language sentences with Sequence-to-sequence (Seq2Seq) models with attention. The Seq2Seq models may be implemented in applications, such as machine translation, image captioning, and speech recognition. Performance has further been improved by leveraging unlabeled data, often in the form of a language models. Disclosed herein are “Cold Fusion” architecture embodiments that leverage a pre-trained language model during training. The Seq2Seq models with Cold Fusion embodiments are able to better utilize language information enjoying faster convergence, better generalization, and almost complete transfer to a new domain while using less labeled training data.","['G10L15/063', 'G10L15/183', 'G06F18/2155', 'G06F40/279', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/048', 'G06N3/0481', 'G10L15/16']"
WO2023082697A1,"Coordination and optimization method and system for comprehensive electric-thermal energy system, and device, medium and program","Disclosed in the present application are a coordination and optimization method and system for a comprehensive electric-thermal energy system, and a device, a medium and a program, wherein the method is executed by an electronic device. The method comprises: acquiring real-time parameters of a comprehensive electric-thermal energy system; on the basis of the real-time parameters of the comprehensive electric-thermal energy system, respectively calculating the real-time power-generation power of an electric power system, a thermodynamic system and a coupling apparatus of the comprehensive electric-thermal energy system; and inputting the real-time power-generation power into a pre-trained SAC framework-based optimization scheduling model, and outputting a scheduling action, to form a coordination strategy for the comprehensive electric-thermal energy system.","['G06F18/214', 'G06F30/20', 'G06Q10/04', 'G06Q50/06']"
WO2021017372A1,"Medical image segmentation method and system based on generative adversarial network, and electronic equipment","Disclosed are a medical image segmentation method and system based on generative adversarial network, and an electronic equipment. First, studying the way a generator extracts the pixel-level features of different types of high-quality images, and using a capsule model to perform structured feature representation for generating pixel-level annotation samples; secondly, building an appropriate discriminator for discriminating the authenticity of the generated pixel-level annotation samples, designing an appropriate error optimization function, and feeding the discrimination result back to the generator model and the discriminator model respectively so as to improve the sample generation ability and the discrimination ability of the generator and the discriminator respectively after continuous adversarial training; and finally, using the trained generator to generate pixel-level annotation samples for achieving pixel-level segmentation of a medical image with image-level annotation. The method effectively reduces the dependence of a segmentation model on pixel-level annotation data, thereby not only improving the efficiency of adversarial training of generated samples against real samples, but also effectively achieving high-precision pixel-level image segmentation.","['G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30012', 'G06T2207/30204']"
US20220358451A1,Automated inventory management method and system thereof,"An automated inventory management method is provided. A historical sale record is received, and a future sale of an item is predicted based on the historical sale record to obtain a simulation result of an expected sale state of the item in the next sale cycle. According to the historical sale record of full categories of items and the simulation result of the item in the next sale cycle, an initial weight of the pre-training model is trained and used as a weight of an inventory decision module, and a purchase order that meets the expected sale record of the item in the next sale cycle is automatically generated. A reward feedback is calculated according to a current sale record and an inventory volume of the item and a purchase order of the previous sale cycle and input into the inventory decision module to order the item.","['G06Q10/087', 'G06N20/00', 'G06N3/08', 'G06N3/092', 'G06Q30/0202', 'G06N3/0464']"
TWI872062B,"Systems, devices, and methods for automated and interactive analysis of bone scan images for detection of metastases","Presented herein are systems and methods that provide for improved computer aided display and analysis of nuclear medicine images. In particular, in certain embodiments, the systems and methods described herein provide improvements to several image processing steps used for automated analysis of bone scan images for assessing cancer status of a patient. For example, improved approaches for image segmentation, hotspot detection, automated classification of hotspots as representing metastases, and computation of risk indices such as bone scan index (BSI) values are provided.","['A61B6/469', 'A61B6/037', 'A61B6/465', 'A61B6/505', 'A61B6/5217', 'A61B6/5258', 'A61B6/563', 'A61K51/0489', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06T7/73', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H70/60', 'G06T2200/24', 'G06T2207/10081', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10128', 'G06T2207/20012', 'G06T2207/20128', 'G06T2207/30008', 'G06T2207/30096']"
CN111626218B,"Image generation method, device, equipment and storage medium based on artificial intelligence","The embodiment of the application discloses an image generation method, device and equipment based on artificial intelligence and a storage medium, wherein the method comprises the following steps: acquiring a source image of a target object comprising a gesture to be converted and a target image of a reference object presenting the target gesture; determining an attitude transfer matrix according to the model attitudes corresponding to the target object and the reference object respectively; determining, by the generator, a base appearance feature of the target object from the source image; converting the basic appearance characteristic based on the gesture transfer matrix to obtain a target appearance characteristic; a target composite image is generated by the generator based on the target appearance features. The method can effectively improve the character gesture migration effect, so that the character gesture after migration is more consistent with the character gesture in the target image.","['G06V40/20', 'G06T11/00', 'G06T7/73', 'G06F18/22', 'G06N3/045', 'G06N3/08', 'G06V10/40', 'G06V10/82', 'G06V40/103', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11093733B2,"Image processing method and apparatus, storage medium and electronic device","An image processing method and apparatus, a storage medium and an electronic device are disclosed. The method comprises: acquiring a first face image in a real scene and a second face image in a virtual scene, wherein the second face image is generated at least according to a first value of at least one target parameter, and the at least one target parameter is used for determining at least one attribute of a face image in the virtual scene; extracting at least one first image feature from the first face image, and extracting at least one second image feature from the second face image; acquiring a similarity between the at least one first image feature and the at least one second image feature; adjusting the first value of the at least one target parameter based on the similarity to obtain a target value of the at least one target parameter; and rendering the at least one target parameter according to the target value to obtain the target face image in the virtual scene.","['G06V10/82', 'G06K9/00281', 'G06T13/40', 'G06K9/00248', 'G06K9/00261', 'G06K9/00315', 'G06V10/764', 'G06V20/20', 'G06V40/165', 'G06V40/167', 'G06V40/171', 'G06V40/172', 'G06V40/176']"
CN111159416B,"Language task model training method and device, electronic equipment and storage medium","The invention provides a language task model training method, a language task model training device, electronic equipment and a storage medium; the method comprises the following steps: performing layered pre-training in the language model based on corpus samples of corresponding language tasks in a pre-training sample set; carrying out forward propagation on the corpus samples of the corresponding language tasks in the training sample set in the language task model; fixing the parameters of the language model, and performing back propagation in the language task model to update the parameters of the task model; and carrying out forward propagation and backward propagation on the corpus samples corresponding to the language tasks in the training sample set in the language task model so as to update the parameters of the language model and the task model. The invention can prevent the catastrophic forgetting phenomenon of the language model and simultaneously ensure that the language model and the task model can achieve the training effect according with the corresponding learning rate.","['G06F16/355', 'G06F16/3329', 'G06F16/353', 'G06F16/36', 'G06N3/084']"
US12205029B2,Increasing accuracy and resolution of weather forecasts using deep generative models,"Embodiments of the present invention provide the use of a conditional Generative Adversarial Network (GAN) to simultaneously correct and downscale (super-resolve) global ensemble weather or climate forecasts. Specifically, a generator deep neural network (G-DNN) in the cGAN comprises a corrector DNN (C-DNN) followed by a super-resolver DNN (SR-DNN). The C-DNN bias-corrects coarse, global meteorological forecasts, taking into account other relevant contextual meteorological fields. The SR-DNN downscales bias-corrected C-DNN output into G-DNN output at a higher target spatial resolution. The GAN is trained in three stages: C-DNN training, SR-DNN training, and overall GAN training, each using separate loss functions. Embodiments of the present invention significantly outperform an interpolation baseline, and approach the performance of operational regional high-resolution forecast models across an array of established probabilistic metrics. Crucially, embodiments of the present invention, once trained, produce high-resolution predictions in seconds on a single machine.","['G01W1/10', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088']"
US10759446B2,"Information processing system, information processing method, and program","An information processing system that appropriately estimates a driving conduct includes: a detector that detects a vehicle environment state, which is at least one of surroundings of a vehicle and a driving state of the vehicle; a behavior learning unit configured to cause a neural network to learn a relationship between the vehicle environment state detected by the detector and a behavior of the vehicle implemented after the vehicle environment state; and a behavior estimation unit configured to estimate a behavior of the vehicle by inputting, into the neural network that learned, the vehicle environment state detected at a current point in time by the detector.","['B60W50/14', 'B60K35/00', 'B60K35/10', 'B60K35/22', 'B60K35/28', 'B60R16/02', 'B60W40/09', 'B60W50/00', 'B60W50/0097', 'B60W50/082', 'B60W50/085', 'B60W60/001', 'G05D1/0088', 'G06F18/24143', 'G06K9/00791', 'G06K9/00845', 'G06K9/6274', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/82', 'G06V20/56', 'G06V20/597', 'G08G1/0112', 'G08G1/0129', 'G08G1/0141', 'G08G1/0962', 'G08G1/09626', 'G08G1/096716', 'G08G1/096725', 'G08G1/096741', 'G08G1/096775', 'G08G1/167', 'B60W2050/0002', 'B60W2050/0075', 'B60W2050/146', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2520/10', 'B60W2530/14', 'B60W2540/10', 'B60W2540/12', 'B60W2540/20', 'B60W2540/30', 'B60W2552/10', 'B60W2554/00', 'B60W2554/4041', 'B60W2554/80', 'B60W2554/802', 'B60W2554/804', 'B60W2556/10', 'B60W2556/50', 'G05D2201/0213']"
CN113378965B,Multi-label image identification method and system based on DCGAN and GCN,"The present disclosure provides a multi-label recognition algorithm based on DCGAN and GCN, including: constructing a DCGAN model based on the GAN model, and generating a similar image based on the DCGAN model; extracting features based on a transferred CNN algorithm, transferring parameters of a neural network of a DCGAN model to the CNN algorithm to extract features of a multi-label image, and generating a class label classifier by using a GCN algorithm through a relation graph among training labels; and generating a countermeasure network generation data pre-training model through deep convolution, and transferring parameters of a convolution neural network of the pre-training model to a target task to fine tune the network so as to obtain a more accurate image recognition effect. Meanwhile, random noise is added when the image is generated, and therefore robustness of the pre-training model can be improved.","['G06F18/241', 'G06F18/214', 'G06F18/22', 'G06N3/045', 'G06N3/084']"
US11335062B2,Automated apparel design using machine learning,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media facilitating automated apparel design using deep learning techniques. For example, user instructions may be received as text data (or converted to text data from audio data representing user speech), and natural language processing (NLP) may be performed on the text data to interpret the user instructions. An apparel design may be generated in real-time/substantially real-time based on the user instructions. For example, the interpreted user instructions may be provided as input to at least one machine learning (ML) model that is configured to determine one or more visual apparel elements based on the user instructions and to generate the apparel design based on the visual apparel elements. One or more operations may be initiated based on the apparel design.","['G06T17/20', 'G06T19/20', 'A41D1/00', 'G06F3/167', 'G06F40/30', 'G06F40/35', 'G06N20/00', 'G06N3/006', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G10L15/1822', 'G10L15/22', 'G10L15/26', 'G06F40/216', 'G06F40/289', 'G06F40/295', 'G06T2210/16', 'G06T2219/2004', 'G10L2015/223']"
US11704907B2,Depth-based object re-identification,"An object re-identifier. For each of a plurality of frames of a video, a quality of the frame is assessed and a confidence that a previously-recognized object is present in the frame is determined. The determined confidence for the frame is weighted based on the assessed quality of the frame such that frames with higher relative quality are weighted more heavily than frames with lower relative quality. An overall confidence that the previously-recognized object is present in the video is assessed based on the weighted determined confidences.","['G06V20/41', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06N7/01', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V40/103']"
CN111177393B,"Knowledge graph construction method and device, electronic equipment and storage medium","The embodiment of the disclosure discloses a method and a device for constructing a knowledge graph, electronic equipment and a storage medium, wherein the method comprises the following steps: inputting the language material of the file into a pre-designed sequence marking model, and identifying each entity in the language material of the file and the type of each entity through the sequence marking model; pairing every two entities in the literature corpus to generate at least one piece of entity relationship characteristic information, wherein the entity relationship characteristic information comprises the type of each entity; inputting the entity relation characteristic information into a pre-trained text classification model so as to determine the relation between a target entity and other entities through the text classification model; and constructing a knowledge graph based on the relationship between the target entity and other entities and the type of each entity. The technical scheme of the embodiment of the disclosure realizes the construction purpose of the knowledge graph.","['G06F16/35', 'G06F16/367']"
US12310586B2,Method for adaptive control schemes for surgical network control and interaction,"A method for adaptive control of surgical network control and interaction is disclosed. The surgical network includes a surgical feedback system. The surgical feedback system includes a surgical instrument, a data source, and a surgical hub configured to communicably couple to the data source and the surgical instrument. The surgical hub includes a control circuit. The method includes receiving, by the control circuit, information related to devices communicatively coupled to the surgical network; and adaptively controlling, by the control circuit, the surgical network based on the received information.","['A61B17/07207', 'A61B1/00009', 'A61B1/000096', 'A61B1/00045', 'A61B1/051', 'A61B1/0661', 'A61B17/0682', 'A61B17/072', 'A61B17/1114', 'A61B17/1155', 'A61B17/1285', 'A61B17/320092', 'A61B18/1442', 'A61B18/1445', 'A61B34/20', 'A61B34/25', 'A61B34/32', 'A61B34/71', 'A61B5/0066', 'A61B5/0075', 'A61B5/0261', 'A61B6/5247', 'A61B90/35', 'A61B90/361', 'A61M1/73', 'A61M1/77', 'A61M1/79', 'B25J13/006', 'B25J9/1689', 'B25J9/1697', 'G06K19/07749', 'G06K7/10316', 'G16H10/60', 'G16H20/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/20', 'H01Q1/22', 'H04L63/0428', 'H04L63/08', 'H04L63/1416', 'H04L67/10', 'H04L67/12', 'H04N23/555', 'H04N5/272', 'H04N7/183', 'H04W12/06', 'H04W12/108', 'H05K1/028', 'H05K1/189', 'A61B17/0469', 'A61B17/07292', 'A61B18/14', 'A61B18/16', 'A61B2017/00017', 'A61B2017/00022', 'A61B2017/00026', 'A61B2017/0003', 'A61B2017/00039', 'A61B2017/00044', 'A61B2017/00057', 'A61B2017/00061', 'A61B2017/00075', 'A61B2017/00084', 'A61B2017/00097', 'A61B2017/00106', 'A61B2017/0011', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/00123', 'A61B2017/00128', 'A61B2017/00199', 'A61B2017/00203', 'A61B2017/00221', 'A61B2017/00225', 'A61B2017/00398', 'A61B2017/00402', 'A61B2017/00734', 'A61B2017/00809', 'A61B2017/00818', 'A61B2017/07257', 'A61B2017/07271', 'A61B2017/07278', 'A61B2017/07285', 'A61B2017/1132', 'A61B2017/32007', 'A61B2017/320074', 'A61B2017/320084', 'A61B2017/320095', 'A61B2017/320097', 'A61B2018/00541', 'A61B2018/00589', 'A61B2018/00595', 'A61B2018/00601', 'A61B2018/00607', 'A61B2018/0063', 'A61B2018/00642', 'A61B2018/00684', 'A61B2018/00791', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00898', 'A61B2018/00988', 'A61B2018/00994', 'A61B2018/1253', 'A61B2018/126', 'A61B2018/1273', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/256', 'A61B2034/258', 'A61B2034/301', 'A61B2034/305', 'A61B2090/064', 'A61B2090/0807', 'A61B2090/0809', 'A61B2090/309', 'A61B2217/005', 'A61B2217/007', 'A61B2218/002', 'A61B2218/007', 'A61B2218/008', 'A61B34/30', 'A61B34/37', 'A61B5/021', 'A61B90/30', 'A61B90/98', 'A61M1/80', 'A61M13/003', 'A61M2205/3306', 'A61M2205/3327', 'A61M2205/3331', 'A61M2205/3365', 'A61M2205/3368', 'A61M2205/3553', 'A61M2205/3561', 'A61M2205/3576', 'A61M2205/50', 'G05B2219/40174', 'G05B2219/45119', 'H04W12/63']"
CN115222019B,Reservoir parameter prediction method based on deep Transformer transfer learning based on well logging data,"The invention discloses a depth transducer transfer learning reservoir parameter prediction method based on logging data, which comprises the following steps: and carrying out outlier processing on the source domain logging data, and screening out abnormal logging data. And the logging data is subjected to standardized preprocessing, so that the magnitude order and dimension influence among parameters is effectively eliminated, the network error is reduced, the convergence is accelerated, and the model prediction precision is improved. The standardized data is input to a transform migration learning network, and the correlation between the source domain and the target domain is found in the feature space. And finally, designing a loss function of the whole network. And outputting the error of the pre-position value and the core data to the source domain logging data by calculating the distribution difference of the logging characteristic data of the source domain and the target domain and the model. Based on the back propagation of the loss values, the network parameters are derived through a chain rule, and the network parameters are updated by using a random gradient descent algorithm. The method can find the similarity of the source domain and the target domain, and transmit the knowledge of the source domain to the target domain, thereby effectively solving the problem of large reservoir parameter prediction error.","['G01V11/00', 'G06N20/00', 'G06N3/084', 'Y04S10/50']"
US20230113072A1,"Method, system, and medium for affective music recommendation and composition","A method, system, and medium for affective music recommendation and composition. A listener's current affective state and target affective state are identified, and an audio stream, such as a music playlist, is generated with the intent of effecting a controlled trajectory of the listener's affective state from the current state to the target state. The audio stream is generated by a machine learning system trained using data from the listener and/or other users indicating the effectiveness of specific audio segments, or audio segments having specific features, in effecting the desired affective trajectory. The audio stream is presented to the user as an auditory stimulus. The machine learning system may be updated based on the affective state changes induced in the listener after exposure to the auditory stimulus. Over time, the machine learning system gains a robust understanding of the relationship between music and human affect, and thus the machine learning system may also be used to compose, master, and/or adapt music configured to induce specific affective responses in listeners.","['G10H1/0025', 'A61B5/16', 'A61M21/02', 'G06F16/635', 'G10G1/00', 'G10H1/0008', 'G16H20/70', 'A61M2021/0027', 'A61M21/00', 'A61M2205/3303', 'A61M2205/505', 'G10H2210/111', 'G10H2210/125', 'G10H2220/116', 'G10H2220/371', 'G10H2240/085', 'G10H2240/131', 'G10H2250/311']"
US11986916B2,High-precision kickback detection for power tools,"A high-precision, low false alarm rate detection apparatus, system, and method for rapid reaction to sudden kinetic impulses caused by abnormal motion, such as kickback, of a power tool. The apparatus, system and method includes local measurement of sensing modalities with local real-time processing and advanced digital signal processing to measure the total kinematic motion of any power tool. A machine learning model pre-trained for the power tool to predict an occurrence of an abnormal motion such as a kickback event of the power tool, the machine learning model using data received from sensing modalities to predict an occurrence of the kickback event, and a reactive device of the power tool is activated upon prediction of the kickback event.","['B23Q11/0092', 'B23Q11/00', 'B25F5/00', 'G05B23/02', 'G05B23/024', 'G06N20/00', 'H02K11/21', 'H02K7/14', 'B23D59/001', 'G01P15/18', 'G01P3/36', 'G01P3/44', 'G05B19/406']"
CN107735804B,System and method for transfer learning techniques for different sets of labels,"Examples of the present disclosure describe systems and methods for transition learning techniques for different sets of labels. In aspects, a data set on a server device may be accessed. The data set may include a tag and a set of words associated with the tag. The server device may cause the embedding of the marker within the data set. The embedded token may be represented by a multi-dimensional vector corresponding to the particular token. The vectors may be used to construct a label mapping for the data set. The label mapping may be used to train the model to perform domain adaptation or transfer learning techniques. The model may be used to provide results to a statement/query or training model.",['G06N20/00']
US12045343B2,System and method for heterogeneous transferred learning for enhanced cybersecurity threat detection,"A method includes training a first machine learning model with a first dataset, to produce a first trained machine learning model to infer cybersecurity-oriented file properties and/or detect cybersecurity threats within a first domain. The first dataset includes labeled files associated with the first domain. The first trained machine learning model includes multiple layers, some of which are trainable. A second trained machine learning model is generated, via a transfer learning process, using (1) at least one trainable layer from the multiple trainable layers of the first trained machine learning model, and (2) a second dataset different from the first dataset. The second dataset includes labeled files associated with a second domain. The first domain has a different syntax, different semantics, and/or a different structure than that of the second domain. The second trained machine learning model (e.g., a deep neural network model) is then available for use in inferring cybersecurity-oriented properties of the file in the second domain and/or detecting cybersecurity threats in the second domain.","['G06F21/554', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06F2221/034']"
CN110569359B,"Training and application method and device of recognition model, computing equipment and storage medium","The application discloses a training and application method and device of an identification model, computing equipment and a storage medium. The model training method comprises the following steps: obtaining text data of different sources, wherein the text data of different sources comprises first-type text data and second-type text data, the first-type text data is provided with a source tag, the second-type text data is provided with a preset attribute tag, and the preset attribute does not comprise a text source; extracting feature data of the text data based on the same feature extraction network; a first classifier is trained based on the feature data of the first type of text data and a second classifier is trained based on the feature data of the second type of text data, wherein the first classifier is used to determine a source of the text data and the second classifier is used to determine a predetermined attribute of the text data. Thus, the trained recognition model (machine learning model) can be quickly migrated and applied to data from different sources, so that the cost and the manpower are saved.","['G06F16/353', 'G06F16/355']"
US10896352B2,Deep learning medical systems and methods for image reconstruction and quality evaluation,"Methods and apparatus to automatically generate an image quality metric for an image are provided. An example method includes automatically processing a first medical image using a deployed learning network model to generate an image quality metric for the first medical image, the deployed learning network model generated from a digital learning and improvement factory including a training network, wherein the training network is tuned using a set of labeled reference medical images of a plurality of image types, and wherein a label associated with each of the labeled reference medical images indicates a central tendency metric associated with image quality of the image. The example method includes computing the image quality metric associated with the first medical image using the deployed learning network model by leveraging labels and associated central tendency metrics to determine the associated image quality metric for the first medical image.","['G06N3/084', 'G06K9/6265', 'G06F18/2193', 'G06K9/036', 'G06K9/4604', 'G06K9/4628', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06T7/0002', 'G06T7/0012', 'G06V10/454', 'G06V10/993', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/30168']"
US11876858B1,Cloud-based fleet and asset management for edge computing of machine learning and artificial intelligence workloads,"A process can include receiving monitoring information associated with a machine learning (ML) or artificial intelligence (AI) workload implemented by an edge compute unit of a plurality of edge compute units. Status information corresponding to a plurality of connected edge assets can be received, the plurality of edge compute units and connected edge assets included in a fleet of edge devices. A remote fleet management graphical user interface (GUI) can display a portion of the monitoring or status information for a subset of the fleet of edge devices, based on a user selection input, and can receive a user configuration input indicative of an updated configuration for at least one workload corresponding to a pre-trained ML or AI model deployed on the at least one edge compute unit. A cloud computing environment can transmit control information corresponding to the updated configuration to the at least one edge compute unit.","['H04B7/18513', 'H04L67/1008', 'G06F8/65', 'G06F9/5072', 'H04L41/0816', 'H04L41/16', 'H04L41/22', 'H04L43/0817', 'H04L67/101', 'G06F2209/508', 'H04L41/40']"
US11250323B2,System and method for training neural networks,"A computer-implemented method comprising: training a pre-trained neural network that comprises: an input layer; a plurality of hidden layers, wherein each of the plurality of hidden layers has one or more nodes, wherein each of said one or more nodes has an associated weight trained based on data from a source domain; and an output layer. Training the pre-trained neural network comprises: introducing at least one additional layer to the plurality of hidden layers, wherein said additional layer has one or more nodes having associated weights; keeping weights of the nodes in the plurality of hidden layers of the pre-trained neural network unchanged; inputting data from a target domain to the input layer; and adjusting weights of the one or more nodes in the at least one additional layer based on features obtained at the output layer.","['G06N3/08', 'G06F18/211', 'G06F18/214', 'G06K9/00268', 'G06K9/00295', 'G06K9/6228', 'G06K9/6256', 'G06N3/04', 'G06N3/0499', 'G06N3/063', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/168', 'G06V40/173', 'G06N3/045']"
US11003988B2,Hardware system design improvement using deep learning algorithms,"Methods and apparatus for deep learning-based system design improvement are provided. An example system design engine apparatus includes a deep learning network (DLN) model associated with each component of a target system to be emulated, each DLN model to be trained using known input and known output, wherein the known input and known output simulate input and output of the associated component of the target system, and wherein each DLN model is connected as each associated component to be emulated is connected in the target system to form a digital model of the target system. The example apparatus also includes a model processor to simulate behavior of the target system and/or each component of the target system to be emulated using the digital model to generate a recommendation regarding a configuration of a component of the target system and/or a structure of the component of the target system.","['G06N3/08', 'G06F11/30', 'G06F30/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06F2111/10']"
US10438354B2,Deep learning medical systems and methods for medical procedures,"Methods and apparatus for monitoring and improving imaging system operation are provided. An example apparatus includes a first deployed deep learning network (DLN) which operates with an acquisition engine to generate an imaging device configuration. The example apparatus includes a second deployed DLN which operates with a reconstruction engine based on acquired image data. The example apparatus includes a first assessment engine with a third deployed DLN. The assessment engine receives output from at least one of the acquisition engine or the reconstruction engine to assess operation of the respective at least one of the acquisition engine or the reconstruction engine and to provide feedback to the respective at least one of the acquisition engine or the reconstruction engine. The first deployed DLN and the second deployed DLN are generated and deployed from first and second training DLNS, respectively.","['G06T7/0012', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06N3/0985', 'G16H30/40', 'G16H40/40', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084']"
US10866588B2,System and method for leveraging end-to-end driving models for improving driving task modules,"System, methods, and other embodiments described herein relate to improving training of sub-modules for autonomously controlling a vehicle. In one embodiment, a method includes generating projected controls for autonomously controlling the vehicle through a driving scene by analyzing sensor data about the driving scene using an end-to-end (E2E) model. The E2E model is based, at least in part, on at least one of the sub-modules. The method includes training the E2E model according to the projected controls and labels for the sensor data that indicate expected controls for driving the vehicle through the driving scene. The method includes transferring electronic data of the E2E model into the at least one of the sub-modules associated with the E2E model to initialize the at least one of the sub-modules to improve operation of the at least one sub-modules at sub-tasks for autonomously controlling the vehicle.","['G05D1/0088', 'B60W30/00', 'B60W60/0011', 'G05B13/028', 'G05D1/0221', 'G05D1/0285', 'G06N3/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G05D2201/0213', 'G06N3/048']"
US11907650B2,Methods and systems for artificial intelligence- assisted document annotation,"Methods and systems for artificial intelligence (AI)-assisted document annotation and training of machine learning-based models for document data extraction are described. The methods and systems described herein take advantage of a continuous machine learning approach to create document processing pipelines that provide accurate and efficient data extraction from documents that include structured text, semi-structured text, unstructured text, or any combination thereof.","['G06F40/169', 'G06F16/93', 'G06F3/0482', 'G06N20/00', 'G06Q10/10', 'G06Q30/0201', 'G06Q30/04', 'G06Q40/12', 'G06Q50/18']"
US11625540B2,"Encoder, system and method for metaphor detection in natural language processing","Provided is an encoder, system and method for metaphor detection in natural language processing. The system comprises an encoding module configured to convert words included in a sentence into BiLSTM representation vectors; a first encoder configured to generate a first entire representation vector of a WSD resolving task; a second encoder configured to generate a second entire representation vector of an MD task; and a multi-task learning module configured to perform knowledge transfer between the first and second encoders. Wherein, each of the first and second encoders includes a graph convolutional neural network (GCN) module configured to encode a link between a target word and a core word to generate GCN representation vectors; a control module configured to regulate the GCN representation vectors to generate an entire representation vector.","['G06F40/30', 'G06F40/205', 'G06F40/279', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096']"
US11755912B2,Controlling distribution of training data to members of an ensemble,"A machine learning system includes a coach machine learning system that uses machine learning to help a student machine learning system learn its system. By monitoring the student learning system, the coach machine learning system can learn (through machine learning techniques) “hyperparameters” for the student learning system that control the machine learning process for the student learning system. The machine learning coach could also determine structural modifications for the student learning system architecture. The learning coach can also control data flow to the student learning system.","['G06N3/045', 'G06F18/2185', 'G06F18/285', 'G06N3/042', 'G06N3/0499', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06N3/0985']"
US12412564B2,Text data processing method and apparatus,"This application discloses example text data processing method. One example method includes obtaining a target text. The target text can then be processed based on a noise generation model to obtain a noisy text, where when the noise generation model is trained, training data of the noise generation model at least includes a first text and a second text, the first text is a correct text corresponding to speech data, and the second text is obtained by performing speech recognition on the speech data by using a first speech recognition model. A text processing model can then be trained, by using at least the noisy text as training data, to obtain a trained text processing model.","['G10L15/26', 'G06F40/279', 'G06F40/30', 'G06F40/40', 'G06N3/0442', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G10L15/063', 'G10L15/16', 'G10L15/20', 'G10L15/22', 'G06F40/295']"
CN110363090B,"Intelligent heart disease detection method, device and computer readable storage medium","The invention relates to an artificial intelligence technology, and discloses an intelligent heart disease detection method, which comprises the following steps: acquiring a data set consisting of heart sound signals of a heart disease patient, establishing a label for the data set, generating a label set, and classifying the data set according to the label set; normalizing the classified data set to obtain a source data set, and storing the source data set into a database; training a pre-constructed combined classifier model by using the source data set to obtain a training value, calculating an unweighted average recall rate of the training value, and completing training of the combined classifier model when the unweighted average recall rate is greater than a preset threshold value; and inputting heart sound signal data of the user to be detected into the trained combined classifier model, and detecting the user suffering from the potential heart disease. The invention also provides an intelligent heart disease detection device and a computer readable storage medium. The invention realizes accurate detection of heart diseases.","['A61B7/04', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G16H50/20', 'G06F2218/12', 'Y02A90/10']"
US12306919B2,Systems and methods for dynamic passphrases,"Systems, devices, methods, and computer readable media are provided in various embodiments relating to generating a dynamic challenge passphrase data object. The method includes establishing, a plurality of data record clusters, representing a mutually exclusive set of structured data records of an individual, ranking the plurality of feature data fields based on a determined contribution value of each feature data field relative to the establishing of the data record cluster, and identifying, using the ranked plurality of feature data fields, a first and a second feature data field of the plurality of feature data fields. The method includes generating the dynamic challenge passphrase data object, wherein the first or the second feature data field is used to establish a statement string portion, and a remaining one of the first or the second feature data field is used to establish a question string portion and a correct response string.","['G06F21/32', 'G06F18/2113', 'G06F18/22', 'G06F18/24137', 'G06F18/251', 'G06F21/31', 'G06F21/33', 'G06F21/46', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06Q20/108', 'G06Q20/1085', 'G06Q20/202', 'G06Q20/206', 'G06Q20/322', 'G06Q20/3267', 'G06Q20/3276', 'G06Q20/36', 'G06Q20/38215', 'G06Q20/3825', 'G06Q20/385', 'G06Q20/4014', 'G06Q20/40145', 'G06Q20/4016', 'G06V10/17', 'G06V10/454', 'G06V10/764', 'G06V10/771', 'G06V10/776', 'G06V10/803', 'G06V10/82', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06V40/20', 'G06V40/40', 'G07G1/009', 'G10L15/25', 'G10L17/24', 'H04L63/0838', 'H04L63/0876', 'H04L9/0866', 'H04L9/3213', 'H04L9/3226', 'H04L9/3231', 'H04L9/3271', 'G06N3/047', 'G10L17/14']"
CN103945533B,Wireless real time position localization methods based on big data,"The invention discloses wireless real time position localization method based on big data, step is as follows: the detection region gridding that will be positioned, the some wireless routers being arranged in detection region launch wireless signal, by the information of the wireless signal of wireless signal receiver multi collect wireless router in each grid of gridding rear region, the wireless signal information composition large data sets wireless signal fingerprint base that will gather；Signal Pretreatment；Parameter training: training deep neural network DNN；The signal characteristic abstraction of deep neural network DNN based on training and tagsort；Location estimation based on HMM HMM.The present invention promotes the accuracy of positioning result in the case of not affecting real-time positioning speed, successfully orientation problem is dissolved in the background of big data, and effectively utilizes the advantage of big data to improve the performance of real-time positioning system.",[]
US11625553B2,"Rapid and accurate modeling of a building construction structure including estimates, detailing, and take-offs using artificial intelligence","Some embodiments relate to generating three dimensional virtual representations of a building construction structure based on two-dimensional real-world construction plans, such as architectural plans or building plans. Some embodiments further produce autonomous, near real-time, and highly accurate and comprehensive building take-offs, complete construction detailing or estimates, detailed bill of materials, plan analysis (including detection of a number of non-standardized objects, such as doors or windows), as well as transforming 2D drawings into 3D and/or providing Building Information Modeling (BIM). The two dimensional real-world architectural plan can include multivariate non-standardized architectural symbols, which define numerous objects including trees, bathrooms, doors, stairs, windows, and floor finishes, lines, including solid, hollow, dashed and dotted lines, which define features including internal or external walls, windows, doors, stairs, property boundaries, easements, footpaths, rooflines, driveways, rights of way, paving stones, landscaping, water, power, drainage, and dimensions, shading, and patterns which define materials and areas on the two dimensional real-world architectural plan, and text which indicate the purposes of the rooms, dimensions, features, construction methods, and regulatory standards.","['G06K9/6201', 'G06F18/22', 'G06Q50/08', 'G06F18/214', 'G06F30/13', 'G06F30/27', 'G06K9/6256', 'G06Q10/06313', 'G06Q10/0875', 'G06Q10/103', 'G06V10/7753', 'G06V10/82', 'G06V30/413', 'G06F40/30', 'G06T17/00']"
US11458542B2,Systems and methods for powder bed additive manufacturing anomaly detection,"Detection and classification of anomalies for powder bed metal additive manufacturing. Anomalies, such as recoater blade impacts, binder deposition issues, spatter generation, and some porosities, are surface-visible at each layer of the building process. A multi-scaled parallel dynamic segmentation convolutional neural network architecture provides additive manufacturing machine and imaging system agnostic pixel-wise semantic segmentation of layer-wise powder bed image data. Learned knowledge is easily transferrable between different additive manufacturing machines. The anomaly detection can be conducted in real-time and provides accurate and generalizable results.","['B22F12/90', 'B22F10/80', 'B22F10/37', 'B29C64/153', 'B29C64/386', 'G06T3/40', 'G06T3/4046', 'G06T3/4053', 'G06T7/0004', 'G06T7/001', 'G06T7/11', 'G06T7/174', 'B22F10/28', 'B22F2999/00', 'B33Y10/00', 'B33Y50/02', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30144', 'Y02P10/25']"
US20240355022A1,Personalized text-to-image generation,"One or more aspects of a method, apparatus, and non-transitory computer readable medium include obtaining an input description and an input image depicting a subject, encoding the input description using a text encoder of an image generation model to obtain a text embedding, and encoding the input image using a subject encoder of the image generation model to obtain a subject embedding. A guidance embedding is generated by combining the subject embedding and the text embedding, and then an output image is generated based on the guidance embedding using a diffusion model of the image generation model. The output image depicts aspects of the subject and the input description.","['G06T11/60', 'G06T9/00', 'G06T11/00', 'G06T7/194', 'G06T2207/20081']"
WO2020228217A1,"Human body posture visual recognition method for transfer carrying nursing robot, and storage medium and electronic device","A human body posture visual recognition method for a transfer carrying nursing robot, and a storage medium and an electronic device. The method comprises: inputting a color image and a depth image of a human body posture to be recognized into a two-stage series neural network based on a part affinity field (PAF) and an improved deep residual network (ResNet), and outputting U-V-Z coordinates of a human body joint (810); and mapping the U-V-Z coordinates of the human body joint according to a depth camera parameter, calculating X-Y-Z coordinates of the human body joint, and outputting global coordinates of the human body joint (820).","['G06F18/24147', 'G06N3/045', 'G06N3/08', 'G06V40/10', 'G06V40/28']"
US20230168894A1,System and method enabling one-hot neural networks on a machine learning compute platform,"One embodiment provides for a graphics processor comprising a cache memory and a graphics core coupled with the cache memory. The graphics core includes circuitry configured to generate an approximate weight matrix including a set of one-hot coded weights, perform a forward compute pass with mini batch samples to compute a loss function, perform a backward compute pass to compute a gradient update via stochastic gradient descent according to a loss update, and update the approximate weight matrix based on the gradient update to generate an updated weight matrix.","['G06F9/30196', 'G06F9/30032', 'G06F9/30036', 'G06F9/3016', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
US20190283254A1,System and method for fault detection in robotic actuation,"A data driven approach for fault detection in robotic actuation is disclosed. Here, a set of robotic tasks are received and analyzed by a Deep Learning (DL) analytics. The DL analytics includes a stateful (Long Short Term Memory) LSTM. Initially, the stateful LSTM is trained to match a set of activities associated with the robots based on a set of tasks gathered from the robots in a multi robot environment. Here, the stateful LSTM utilizes a master slave framework based load distribution technique and a probabilistic trellis approach to predict a next activity associated with the robot with minimum latency and increased accuracy. Further, the predicted next activity is compared with an actual activity of the robot to identify any faults associated robotic actuation.","['B25J9/1674', 'B25J9/161', 'B25J9/163', 'B25J9/1697', 'G05B2219/24082', 'G05B2219/24083', 'G05B2219/31357', 'G05B2219/39271', 'Y02P90/02']"
US20230245654A1,Systems and Methods for Implementing Smart Assistant Systems,"In one embodiment, a system includes an automatic speech recognition (ASR) module, a natural-language understanding (NLU) module, a dialog manager, one or more agents, an arbitrator, a delivery system, one or more processors, and a non-transitory memory coupled to the processors comprising instructions executable by the processors, the processors operable when executing the instructions to receive a user input, process the user input using the ASR module, the NLU module, the dialog manager, one or more of the agents, the arbitrator, and the delivery system, and provide a response to the user input.","['G06N5/027', 'G10L15/063', 'G10L15/1815', 'G10L15/1822', 'G10L15/197', 'G10L15/22', 'H04L63/0428', 'G06N3/0442', 'G06N3/0455', 'G06N3/0895', 'G06N3/096', 'G06N3/098', 'G06N5/04', 'G10L15/183', 'G10L15/30', 'G10L2015/086', 'G10L2015/223', 'G10L25/87']"
CN110930295B,"Image style migration method, system, device and storage medium","The invention discloses an image style migration method, an image style migration system, an image style migration device and a storage medium, wherein the method comprises the following steps: acquiring a content picture; inputting the content picture into a pre-trained image style migration model for style migration treatment, and outputting a target picture with a specific style and retaining the original content; the image conversion network and the discrimination network form a generating type countermeasure network (GAN), and are updated alternately in the model training process. According to the invention, the network is continuously updated and optimized through the sensing counterloss function until the loss is minimized, and the image style migration model with better effect is obtained, so that an output picture which is closer to a content picture and a style picture can be obtained, the problem of picture background distortion is effectively avoided, and the method can be widely applied to the field of data image processing.","['G06T3/04', 'G06N3/045', 'G06N3/08']"
CN113297364B,Natural language understanding method and device in dialogue-oriented system,"The invention belongs to the technical field of intelligent dialogue, in particular to a natural language understanding method and a natural language understanding device in a dialogue-oriented system, which comprises a word embedding layer, a coding representation layer and a joint learning layer, and has reasonable structure, and is based on a collected specific field data set and 1) an original BERT-WWM model 2) an original ERNIE model 3) a 3-layer BERT-WWM model based on a pre-trained joint learning model 4) after knowledge distillation. The four models are subjected to comparison experiments, on a data set in a specific field, 3) the model is better than 1) and 2) the model in two performance indexes of the intended classification accuracy and the slot identification F1, and 4) the model parameter scale after knowledge distillation is greatly reduced, the reasoning delay is effectively reduced, and the performance loss is smaller.","['G06F16/3329', 'G06F16/3344', 'G06F16/35', 'G06F40/242', 'G06F40/30', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
US11093829B2,Interaction-aware decision making,"Interaction-aware decision making may include training a first agent based on a first policy gradient, training a first critic based on a first loss function to learn goals in a single-agent environment using a Markov decision process, training a number N of agents based on the first policy gradient, training a second policy gradient and a second critic based on the first loss function and a second loss function to learn goals in a multi-agent environment using a Markov game to instantiate a second agent neural network, and generating an interaction-aware decision making network policy based on the first agent neural network and the second agent neural network. The N number of agents may be associated with a driver type indicative of a level of cooperation. When a collision occurs, a negative reward or penalty may be assigned to each agent involved based on a lane priority level of respective agents.","['G06N3/006', 'G06N3/08', 'B60W10/04', 'B60W10/18', 'B60W10/20', 'B60W30/18109', 'B60W30/18163', 'B60W50/00', 'G05D1/0088', 'G06N3/0464', 'G06N3/084', 'G06N3/092', 'G06N5/043', 'B60W2050/0014', 'B60W2556/00', 'B60W2710/18', 'B60W2710/20', 'B60W2720/106']"
CN107408384B,Deployed end-to-end speech recognition,"Embodiments of an end-to-end deep learning system and method are disclosed to recognize speech in a distinct language, such as English or Mandarin. In an embodiment, the entire pipeline of manually engineered components is replaced with a neural network, and end-to-end learning allows processing of a wide variety of voices including noisy environments, accents, and different languages. Applying the trained embodiments and the embodiments of the batch scheduling technique using GPUs in a data center, an end-to-end deep learning system can be deployed into an online setting at a lower cost, providing low latency in large-scale customer service.","['G10L15/16', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G10L15/02', 'G10L15/063', 'G10L15/14', 'G10L15/183', 'G10L15/197', 'G10L25/18', 'G10L25/21', 'G10L2015/0635']"
US11823425B2,Few-shot defect detection method based on metric learning,"A few-shot defect detection method based on metric learning, including: (S1) performing data enhancement on a to-be-detected few-shot defect data set through a G2-Generative adversarial network (G2-GAN); (S2) extracting features of a defect data set similar to the to-be-detected few-shot defect data set based on an adaptive convolution kernel-based convolutional neural network (SKM-CNN) to generate a pre-training model; and (S3) transferring the pre-training model to a few-shot defect detection network (S2D2N) based on metric learning; and performing target feature extraction and metric learning in sequence to realize rapid identification and location of defects.","['G06F18/214', 'G06V10/774', 'G06F18/22', 'G06F18/24', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T7/0004', 'G06T7/73', 'G06V10/454', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30164', 'G06V2201/06']"
US10949715B1,Methods and systems for image and voice processing,"Systems and methods are disclosed configured to train an autoencoder using images that include faces, wherein the autoencoder comprises an input layer, an encoder configured to output a latent image from a corresponding input image, and a decoder configured to attempt to reconstruct the input image from the latent image. An image sequence of a face exhibiting a plurality of facial expressions and transitions between facial expressions is generated and accessed. Images of the plurality of facial expressions and transitions between facial expressions are captured from a plurality of different angles and using different lighting. An autoencoder is trained using source images that include the face with different facial expressions captured at different angles with different lighting, and using destination images that include a destination face. The trained autoencoder is used to generate an output where the likeness of the face in the destination images is swapped with the likeness of the source face, while preserving expressions of the destination face.","['G06T11/60', 'G06K9/6256', 'G06F18/214', 'G06K9/00268', 'G06K9/00302', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06T1/20', 'G06T11/001', 'G06T13/40', 'G06T13/80', 'G06T17/00', 'G06T7/32', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/168', 'G06V40/174', 'G06T2207/20081', 'G10L2021/0135', 'G10L2021/105', 'G10L21/0356']"
US10803646B1,Methods and systems for image and voice processing,"Systems and methods are disclosed configured to train an autoencoder using images that include faces, wherein the autoencoder comprises an input layer, an encoder configured to output a latent image from a corresponding input image, and a decoder configured to attempt to reconstruct the input image from the latent image. An image sequence of a face exhibiting a plurality of facial expressions and transitions between facial expressions is generated and accessed. Images of the plurality of facial expressions and transitions between facial expressions are captured from a plurality of different angles and using different lighting. An autoencoder is trained using source images that include the face with different facial expressions captured at different angles with different lighting, and using destination images that include a destination face. The trained autoencoder is used to generate an output where the likeness of the face in the destination images is swapped with the likeness of the source face, while preserving expressions of the destination face.","['G06N3/088', 'G06K9/00228', 'G06K9/00268', 'G06K9/00288', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06T5/60', 'G06T5/77', 'G06V10/764', 'G06V10/82', 'G06V40/161', 'G06V40/168', 'G06V40/172', 'G06V40/174', 'G06T2207/20084', 'G06T2207/30201']"
US11151769B2,Graphics architecture including a neural network pipeline,"One embodiment provides for a graphics processor comprising a block of graphics compute units, a graphics processor pipeline coupled to the block of graphics compute units, and a programmable neural network unit including one or more neural network hardware blocks. The programmable neural network unit is coupled with the block of graphics compute units and the graphics processor pipeline. The one or more neural network hardware blocks include hardware to perform neural network operations and activation operations for a layer of a neural network. The programmable neural network unit can configure settings of one or more hardware blocks within the graphics processor pipeline based on a machine learning model trained to optimize performance of a set of workloads.","['G06T15/005', 'G06F12/0862', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06T1/20', 'G06T1/60', 'G06T15/40', 'G06T17/20', 'G06F2212/455', 'G06F2212/502', 'G06F2212/6024', 'G06N3/044', 'G06N3/047', 'Y02D10/00']"
US10769459B2,Method and system for monitoring driving behaviors,"A method and a system are provided for monitoring driving conditions. The method includes receiving video data comprising video frames from one or more sensors where the video frames may represent an interior or exterior of a vehicle, detecting and recognizing one or more features from the video data where each feature is associated with at least one driving condition, extracting the one or more features from the video data, developing intermediate features by associating and aggregating the extracted features among the extracted features, and developing a semantic meaning for the at least one driving condition by utilizing the intermediate features and the extracted one or more features.","['G06K9/00845', 'G06V20/597', 'G06V40/167', 'G06K9/00261', 'G06K9/00281', 'G06V40/171', 'G08B21/06']"
US10546238B2,Pre-training of neural network by parameter decomposition,"A technique for training a neural network including an input layer, one or more hidden layers and an output layer, in which the trained neural network can be used to perform a task such as speech recognition. In the technique, a base of the neural network having at least a pre-trained hidden layer is prepared. A parameter set associated with one pre-trained hidden layer in the neural network is decomposed into a plurality of new parameter sets. The number of hidden layers in the neural network is increased by using the plurality of the new parameter sets. Pre-training for the neural network is performed.","['G06N3/08', 'G06N3/084', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/082', 'G06N3/09', 'G06N7/01', 'G10L15/144', 'G10L15/16', 'G10L15/26', 'G10L25/30', 'G10L15/063']"
CN113077913B,"Online consultation and dispatching method, device and system","The invention discloses an on-line inquiry and dispatch method, device and system, and relates to the technical field of computers. The method comprises the steps of receiving a consultation order submitted by a patient terminal, wherein the consultation order contains description information related to consultation, inputting the description information into a pre-trained consultation model, determining a target department corresponding to the consultation order from the consultation result when the consultation result is output by the consultation model, matching the description information with a plurality of preset mapping rules when the consultation result is not output by the consultation model, determining the target department corresponding to the consultation order from the mapping rules matched with the description information, determining a target doctor from doctors belonging to the target department according to a pre-calculated doctor weight value, and sending an order dispatching notification generated based on the consultation order to the target doctor terminal. According to the embodiment, department diagnosis accuracy and patient experience in non-directional inquiry of an Internet hospital can be improved.","['G16H80/00', 'G06N20/00', 'G16H40/20']"
US10671838B1,Methods and systems for image and voice processing,"Systems and methods are disclosed configured to train an autoencoder using images that include faces, wherein the autoencoder comprises an input layer, an encoder configured to output a latent image from a corresponding input image, and a decoder configured to attempt to reconstruct the input image from the latent image. An image sequence of a face exhibiting a plurality of facial expressions and transitions between facial expressions is generated and accessed. Images of the plurality of facial expressions and transitions between facial expressions are captured from a plurality of different angles and using different lighting. An autoencoder is trained using source images that include the face with different facial expressions captured at different angles with different lighting, and using destination images that include a destination face. The trained autoencoder is used to generate an output where the likeness of the face in the destination images is swapped with the likeness of the source face, while preserving expressions of the destination face.","['G06K9/00281', 'G06F18/2413', 'G06K9/00228', 'G06K9/00288', 'G06T11/001', 'G06T11/60', 'G06T13/40', 'G06T13/80', 'G06T15/205', 'G06V10/26', 'G06V10/40', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/161', 'G06V40/171', 'G06V40/172', 'G06T2207/30201', 'G10L2021/0135', 'G10L2021/105']"
US11741139B2,Systems and methods for determining a response to a user query,Systems and methods are presented for providing a response to a user query. Reception of a user query is detected. An augmentation machine learning model is utilized to determine one or more variations of the user query that correspond to a semantic meaning of the user query. A plurality of response candidates is determined that correspond to the user query by comparing the user query and the one or more variations of the user query to a plurality of documents. A final response candidate is determined from the plurality of response candidates based on utilizing a semantic machine learning model to perform a semantic comparison between the plurality of response candidates and at least the user query.,"['G06F40/247', 'G06F16/3322', 'G06F16/3329', 'G06F16/3334', 'G06F16/3338', 'G06F40/216', 'G06F40/30', 'G06N20/00', 'H04L51/02']"
US12020425B2,Fast anomaly detection method and system based on contrastive representation distillation,"Provided are a method and system for anomaly detection. The method includes: acquiring a picture of an object to be detected; inputting the acquired picture to each of a trained teacher network and a student network distilled from the teacher network, to obtain a feature map output by the teacher network and a feature map output by the student network, where the teacher network is trained by constructing a defective sample to learn feature distribution of normal samples from a pre-trained expert network; and determining a greatest anomalous pixel in a difference map between the feature map output by the teacher network and the feature map output by the student network as an anomaly value of the acquired picture, to output an anomaly detection result.","['G06N3/045', 'G06T7/001', 'G06N3/0464', 'G06N3/096', 'G06T2207/20084', 'G06T2207/20224']"
US11367271B2,Similarity propagation for one-shot and few-shot image segmentation,"Embodiments of the present invention provide systems, methods, and computer storage media for one-shot and few-shot image segmentation on classes of objects that were not represented during training. In some embodiments, a dual prediction scheme may be applied in which query and support masks are jointly predicted using a shared decoder, which aids in similarity propagation between the query and support features. Additionally or alternatively, foreground and background attentive fusion may be applied to utilize cues from foreground and background feature similarities between the query and support images. Finally, to prevent overfitting on class-conditional similarities across training classes, input channel averaging may be applied for the query image during training. Accordingly, the techniques described herein may be used to achieve state-of-the-art performance for both one-shot and few-shot segmentation tasks.","['G06V10/462', 'G06V10/82', 'G06F18/2193', 'G06F18/253', 'G06K9/6265', 'G06K9/629', 'G06V10/25', 'G06V10/26', 'G06V10/454', 'G06V10/761']"
US10658005B1,Methods and systems for image and voice processing,"Systems and methods are disclosed configured to train an autoencoder using images that include faces, wherein the autoencoder comprises an input layer, an encoder configured to output a latent image from a corresponding input image, and a decoder configured to attempt to reconstruct the input image from the latent image. An image sequence of a face exhibiting a plurality of facial expressions and transitions between facial expressions is generated and accessed. Images of the plurality of facial expressions and transitions between facial expressions are captured from a plurality of different angles and using different lighting. An autoencoder is trained using source images that include the face with different facial expressions captured at different angles with different lighting, and using destination images that include a destination face. The trained autoencoder is used to generate an output where the likeness of the face in the destination images is swapped with the likeness of the source face, while preserving expressions of the destination face.","['G11B27/036', 'G06F18/214', 'G06F18/40', 'G06K9/00255', 'G06K9/00315', 'G06K9/00744', 'G06K9/6253', 'G06K9/6256', 'G06T9/002', 'G06V10/82', 'G06V20/46', 'G06V40/166', 'G06V40/175', 'G06V40/176', 'G10L21/003', 'G10L21/055', 'G10L25/24', 'G10L25/57', 'G11B27/031', 'G11B27/10', 'G11B27/28', 'G10L2021/0135']"
WO2020258654A1,Answer acquisition method and device,"An answer acquisition method and device. The method comprises: acquiring a question text (301); determining, by means of a pretrained question classification model, whether the question type of the question text matches the answer type in a preset answer type library (302); and if the question type of the question text does not match the answer type in the preset answer type library, acquiring the answer of the question text according to at least one semantic similarity between a first deep semantic vector of each answer in the preset answer library and a second deep semantic vector of the question text (303). When the method is applied to finance technology, whether the question type of the question text matches the answer type in the pre-set answer type library or not is determined firstly by means of a pretrained question classification model; and if the question type of the question text does not match the answer type in the preset answer type library, the semantic matching degree of the question text and each answer in the preset answer library is represented by at least one semantic similarity, thereby improving the answer acquisition accuracy.","['G06F16/3329', 'G06F16/3343', 'G06F16/3344', 'G06F40/30']"
US11875253B2,Low-resource entity resolution with transfer learning,"Methods, systems, and computer program products for low-resource entity resolution with transfer learning are provided herein. A computer-implemented method includes processing input data via a first entity resolution model, wherein the input data comprise labeled input data and unlabeled input data; identifying one or more portions of the unlabeled input data to be used in training a neural network entity resolution model, wherein said identifying comprises applying one or more active learning algorithms to the first entity resolution model; training, using (i) the one or more portions of the unlabeled input data and (ii) one or more deep learning techniques, the neural network entity resolution model; and performing one or more entity resolution tasks by applying the trained neural network entity resolution model to one or more datasets.","['G06N3/08', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096']"
US11790500B2,Method and apparatus for inverse tone mapping,"In this invention, we propose a convolutional neural network (CNN) based architecture designed for the ITM to HDR consumer displays, called ITM-CNN, and its training strategy for enhancing the performance based on image decomposition using the guided filter. We demonstrate the benefits of decomposing the image by experimenting with various architectures and also compare the performance for different training strategies. To the best of our knowledge, this invention first presents the ITM problem using CNNs for HDR consumer displays, where the network is trained to restore lost details and local contrast. Our ITM-CNN can readily up-convert LDR images for direct viewing on an HDR consumer medium, and is a very powerful means to solve the lack of HDR video contents with legacy LDR videos.","['G06T5/92', 'G06T5/009', 'G06F17/11', 'G06N3/02', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T5/20', 'G06T5/50', 'G06T5/60', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US11604626B1,Analyzing code according to natural language descriptions of coding practices,Code may be analyzed according to natural language descriptions of coding practices. A practice for code written in a natural language description may be received. An embedding of the natural language description may be generated using a machine learning model trained to detect examples of practices. The embedding may be compared with embeddings of code portions stored in an index to detect one or more portions of code that satisfy a facet of the practice. The detected portions of code may be identified.,"['G06F8/33', 'G06F8/75', 'G06F8/36', 'G06F8/38', 'G06N20/00', 'G06N3/045', 'G06N3/09', 'G06N3/096']"
KR20220110453A,"Method and apparatus for generating data for estimating 3 dimensional pose of object included in input image, and prediction model for estimating 3 dimensional pose of object",The present invention relates to a method of generating data for estimating the 3D pose of an object included in an input image. The method includes: obtaining an input image including an object; using a pre-trained inference model to estimate position information for each of a plurality of joints of the object; estimating position information for each of the plurality of joints of the object; and creating animation data representing the motion of the object using estimated position information.,"['G06T7/73', 'G06T13/40', 'G06T7/70', 'G06V10/82', 'G06V10/98', 'G06V40/10', 'G06V40/103', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30196']"
RU2679785C1,System and method of classification of objects,FIELD: data processing.,"['G06F21/562', 'G06F21/566', 'G06F21/56', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N5/01', 'G06F2221/034', 'G06N20/10', 'G06N3/044']"
US11556716B2,Intent prediction by machine learning with word and sentence features for routing user requests,"Systems and methods may be used to generate and use intent predictions to enhance user experience. The intent predictions may describe the data required to resolve a user request included in a user input (e.g., question, search query, and the like) submitted by a user. The intent predictions may be generated using a machine learning model that comprises a model framework for extracting features and classifying user inputs into intent classes based on the extracted features. The intent predictions may be integrated into an information service to improve business metrics including contact rate, transfer rate, helpful rate, and net total promoter score.","['G06F40/30', 'G06F40/237', 'G06F40/284', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N5/04']"
CN115019405B,A tumor classification method and system based on multimodal fusion,"The invention provides a tumor classification method and system based on multi-mode fusion, which comprises the steps of constructing a multi-mode image according to multi-mode images from the same user, wherein vertexes in the multi-mode image are single-frame images in the multi-mode image, edges in the multi-mode image are matching edges among vertexes with different modes, extracting and fusing features of all matching edges in the multi-mode image by using a tumor classification model to obtain confidence degrees of all edges, selecting and constructing a trusted edge set according to the confidence degrees of all edges, and carrying out weighted fusion on the confidence degrees of the trusted edge set and clinical information of the user to obtain a tumor recognition result of the multi-mode image construction. Therefore, the tumor can be classified with high precision by combining the image data of different modes of the user.","['G06V40/60', 'G06N3/084', 'G06N3/088', 'G06V10/40', 'G06V10/761', 'G06V10/764', 'G06V10/774', 'G06V10/806', 'G06V10/82']"
US12019982B2,Event understanding with deep learning,Systems and methods for natural language processing are described. One or more embodiments of the present disclosure generate a word representation vector for each word of a text comprising an event trigger word and an argument candidate word; generate a dependency tree based on the text and the word representation vector; determine that at least one word of the text is independent of a relationship between the event trigger word and the argument candidate word; remove the at least one word from the dependency tree based on the determination to obtain a pruned dependency tree; generate a modified representation vector for each word of the pruned dependency tree using a graph convolutional network (GCN); and identify the relationship between the event trigger word and the argument candidate word based on the modified representation vector for each word of the pruned dependency tree.,"['G06F40/211', 'G06F40/166', 'G06F40/279', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/0895', 'G06F40/30']"
RU2739865C2,System and method of detecting a malicious file,FIELD: antivirus technologies.,"['G06N20/00', 'G06F11/00', 'G06F21/52', 'G06F21/554', 'G06F21/56', 'G06F21/566', 'G06N5/025', 'G06N5/04', 'G06F2221/033', 'G06F2221/034', 'G06F2221/2101', 'G06N3/08']"
CN110490960B,Synthetic image generation method and device,"One or more embodiments of the present specification provide a method and apparatus for generating a composite image, the method including: generating a rendering image based on the simulation scene of the target scene; determining annotation information of the rendered image; acquiring a real shooting image of a target scene; and according to the photographed image, performing style remodeling on the generated rendered image to obtain a composite image, and determining the determined annotation information as the annotation information of the composite image. The method comprises the steps of utilizing a three-dimensional rendering technology to render to obtain a plurality of initial marked images, utilizing an image style migration technology to perform image style migration on the initial marked images based on a real shot image to obtain a plurality of target marked images with real image styles, so that a large number of real shot images do not need to be shot on site, the real shot images do not need to be manually marked, a synthetic image with high image sense of reality and high marking accuracy can be rapidly generated, and a large amount of available sample data with marked information is provided for model training.","['G06F18/214', 'G06T15/005', 'G06T15/50', 'G06T17/00', 'G06T19/20', 'G06T2200/08', 'G06T2219/2024']"
US12008796B2,Systems and methods for pose detection and measurement,"A method for estimating a pose of an object includes: receiving a plurality of images of the object captured from multiple viewpoints with respect to the object; initializing a current pose of the object based on computing an initial estimated pose of the object from at least one of the plurality of images; predicting a plurality of 2-D keypoints associated with the object from each of the plurality of images; and computing an updated pose that minimizes a cost function based on a plurality of differences between the 2-D keypoints and a plurality of 3-D keypoints associated with a 3-D model of the object as arranged in accordance with the current pose, and as projected to each of the viewpoints.","['G06T7/579', 'G06T7/75', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/647', 'G06T2207/10012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2219/2004']"
US20240273387A1,Learning coach for machine learning system,"A machine learning (ML) system includes a student ML system, a learning coach ML system, and a reference system that generates training data for the student ML system. The learning coach ML system learns to make an enhancement to the student ML system or to its learning process, such as updated hyperparameter or a network structural change, based on training of the student ML system with the training data generated by the reference system. The system may also comprise a learning experimentation system that communicates with the reference system to conduct experiments on the learning of the student learning system. Also, the learning experimentation system can determine a cost function for the learning coach ML system.","['G06N20/20', 'G06N5/04', 'G06N20/00', 'G06N3/045', 'G06N3/082', 'G06N3/084', 'G06N20/10', 'G06N5/01', 'G06N7/01']"
US11361418B2,Transfer learning based capsule endoscopic images classification system and method thereof,"The present invention provides a transfer learning based capsule endoscopic images classification system. The system removes the capsule endoscopic images with an average brightness value beyond the preset threshold, and removes the capsule endoscopic images without details based on image brightness standard deviation and image brightness gradient. The system also removes similar images from the capsule endoscopic images using optical flow method, classifies the capsule endoscopic images according to the corresponding anatomical structure, and obtains the classified capsule endoscopic images list arranged in chronological order. The system further determines and labels the position of the first image of each specific anatomical structure in the classified capsule endoscopic images list arranged in chronological order.","['G16H30/20', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06T7/0002', 'G06T7/215', 'G06T7/248', 'G06T7/44', 'G06V10/34', 'G06V10/462', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G06N3/08', 'G06T2207/10068', 'G06T2207/30028', 'G06V2201/031']"
CN119090490B,Automatic operation and maintenance method and system for electric power distribution network based on artificial intelligence,"The invention provides an automatic operation and maintenance method and system of an electric power distribution network based on artificial intelligence, which relate to the technical field of electric power operation and maintenance and comprise the steps of collecting operation data of the electric power distribution network in real time through a distributed sensor network, transmitting the collected operation data to a cloud data center to design a multi-agent reinforcement learning framework, dividing the power distribution network into a plurality of subareas, and an intelligent operation and maintenance agent making an individualized fault treatment scheme by carrying out real-time monitoring and analysis on a digital twin model and making an optimal execution plan based on the fault treatment scheme and combining real-time road condition information and positions of maintenance personnel; and respectively issuing the optimal execution plan to mobile terminals of automatic equipment and maintenance personnel through a safe encryption channel, extracting preventive maintenance rules from the historical operation and maintenance records, and formulating a preventive maintenance plan based on the extracted preventive maintenance rules and combining a pre-trained equipment life prediction model.","['G06Q10/20', 'G06F18/2433', 'G06N3/044', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N5/02', 'G06N5/04', 'G06Q10/04', 'G06Q10/063', 'G06Q50/06', 'Y04S10/50']"
US11854562B2,High-quality non-parallel many-to-many voice conversion,"A method (and structure and computer product) to permit zero-shot voice conversion with non-parallel data includes receiving source speaker speech data as input data into a content encoder of a style transfer autoencoder system, the content encoder providing a source speaker disentanglement of the source speaker speech data by reducing speaker style information of the input source speech data while retaining content information and receiving target speaker input speech as input data into a target speaker encoder. The output of the content encoder and the target speaker encoder are combined in a decoder of the style transfer autoencoder, and the output of the decoder provides the content information of the input source speech data in a style of the target speaker speech information.","['G10L17/04', 'G10L21/013', 'G06N20/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G10L17/18', 'G10L19/00', 'G10L25/30', 'G10L25/51', 'G10L2021/0135']"
US10979625B2,Method for editing image based on artificial intelligent and artificial device,"A method for editing an image based on artificial intelligence and an artificial intelligence device are disclosed. In the method for editing an image based on artificial intelligence, a recommended photographic composition is created by applying an image acquired by a camera to a pre-trained composition recommendation model, and the image is corrected based on the created recommended photographic composition, whereby it is possible to capture and edit an image at the same time without the trouble of correcting the image after capturing it. One or more of an artificial intelligence device of the present disclosure can be associated with artificial intelligence modules, drones (unmanned aerial vehicles (UAVs)), robots, augmented reality (AR) devices, virtual reality (VR) devices, devices related to 5G service, etc.","['H04N5/23222', 'G06N3/08', 'G06K9/6256', 'G06N3/0464', 'G06N3/09', 'H04N23/61', 'H04N23/632', 'H04N23/633', 'H04N23/64', 'H04N23/675', 'H04N5/232127', 'H04N5/23218', 'H04N5/232935', 'H04N5/232939', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
US11521052B2,Hardware and neural architecture co-search,"Hardware and neural architecture co-search may be performed by operations including obtaining a specification of a function and a plurality of hardware design parameters. The hardware design parameters include a memory capacity, a number of computational resources, a communication bandwidth, and a template configuration for performing neural architecture inference. The operations further include determining, for each neural architecture among a plurality of neural architectures, an overall latency of performance of inference of the neural architecture by an accelerator within the hardware design parameters. Each neural architecture having been trained to perform the function with an accuracy. The operations further include selecting, from among the plurality of neural architectures, a neural architecture based on the overall latency and the accuracy.","['G06N3/04', 'G06N3/063', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/0985', 'G06N7/01']"
CN112765306B,"Intelligent question-answering method, intelligent question-answering device, computer equipment and storage medium","The application relates to an intelligent question-answering method, an intelligent question-answering device, computer equipment and a storage medium. The method comprises the following steps: receiving a to-be-answered question text input by a client; acquiring at least two candidate question texts matched with the to-be-answered question text from a question and answer library; determining a target question text with the maximum similarity with the to-be-answered question text in the candidate question text through a sequencing model; when the similarity between the target question text and the to-be-answered question text is greater than a similarity threshold, feeding back a first reply text corresponding to the target question text to the client; when the similarity between the target question text and the to-be-answered question text is smaller than or equal to a similarity threshold value, feeding back a keyword prompt list to the client; and when the problem keywords selected by the client in the keyword prompt list are received, feeding back a second reply text matched with the problem keywords to the client. By adopting the method, the accuracy of the answers can be improved.","['G06F16/316', 'G06F16/332', 'G06F16/3329', 'G06F16/3344', 'G06F40/216', 'G06F40/30', 'Y02D10/00']"
US11314950B2,Text style transfer using reinforcement learning,"A computer-implemented method is provided for transferring a target text style using Reinforcement Learning (RL). The method includes pre-determining, by a Long Short-Term Memory (LSTM) Neural Network (NN), the target text style of a target-style natural language sentence. The method further includes transforming, by a hardware processor using the LSTM NN, a source-style natural language sentence into the target-style natural language sentence that maintains the target text style of the target-style natural language sentence. The method also includes calculating an accuracy rating of a transformation of the source-style natural language sentence into the target-style natural language sentence based upon rewards relating to at least the target text style of the source-style natural language sentence.","['G06F40/253', 'G06F40/166', 'G06F40/30', 'G06F40/35', 'G06F40/56', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/049', 'G06N3/08', 'G06N3/092', 'G06N3/094']"
US10424087B2,"Systems and methods for providing convolutional neural network based image synthesis using stable and controllable parametric models, a multiscale synthesis framework and novel network architectures","Systems and methods for providing convolutional neural network based image synthesis using localized loss functions is disclosed. A first image including desired content and a second image including a desired style are received. The images are analyzed to determine a local loss function. The first and second images are merged using the local loss function to generate an image that includes the desired content presented in the desired style. Similar processes can also be utilized to generate image hybrids and to perform on-model texture synthesis. In a number of embodiments, Condensed Feature Extraction Networks are also generated using a convolutional neural network previously trained to perform image classification, where the Condensed Feature Extraction Networks approximates intermediate neural activations of the convolutional neural network utilized during training.","['G06T11/001', 'G06T11/00', 'G06T7/45', 'G06T2207/20084', 'G06T2207/20221', 'G06T5/004', 'G06T5/20', 'G06T5/40', 'G06T5/75']"
US10701394B1,Real-time video super-resolution with spatio-temporal networks and motion compensation,"A method includes selecting a plurality of low-resolution frames associated with a video, performing a first motion estimation between a first frame and a second frame, performing a second motion estimation between a third frame and the second frame, generating a high-resolution frame representing the second frame based on the first motion estimation, the second motion estimation and the second frame using a sub-pixel convolutional neural network.","['H04N19/577', 'H04N19/59', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'H04N19/33', 'H04N19/43', 'H04N19/523']"
US20220230628A1,Generation of optimized spoken language understanding model through joint training with integrated knowledge-language module,A system is provided for generating an optimized speech model by training a knowledge module on a knowledge graph. A language module is trained on unlabeled text data and a speech module is trained on unlabeled acoustic data. The knowledge module is integrated with the language module to perform semantic analysis using knowledge-graph based information. The speech module is then aligned to the language module of the integrated knowledge-language module. The speech module is then configured as an optimized speech model configured to leverage acoustic and language information in natural language processing tasks.,"['G10L15/063', 'G06F16/90332', 'G06F16/9024', 'G06F40/30', 'G06N3/042', 'G06N3/045', 'G06N3/088', 'G06N5/02', 'G06N5/022', 'G10L15/18', 'G10L15/1822', 'G10L15/183', 'G06F40/216', 'G06F40/284', 'G06F40/35', 'G10L15/16', 'G10L15/1815', 'G10L25/30', 'G10L25/63']"
US20230052903A1,System and method for multi-task lifelong learning on personal device with improved user experience,"This disclosure relates to recommendations made to users based on learned behavior patterns. User behavior data is collected and grouped according labels. The grouped user behavior data is labeled and used to train a machine learning model based on features and tasks associated with the classification. User behavior is then predicted by applying the trained machine learning model to the collected user behavior data, and a task is recommended to the user.","['G06Q10/107', 'G06F11/3438', 'G06F18/22', 'G06K9/6215', 'G06N20/20', 'G06N3/006', 'G06N5/022', 'G06N3/045', 'G06N3/082']"
CN111738172B,Cross-domain object re-identification method based on feature adversarial learning and self-similarity clustering,"The invention belongs to the field of computer vision and pattern recognition, and particularly relates to a cross-domain target re-recognition method, a system and a device based on feature countermeasure learning and self-similarity clustering, aiming at solving the problem that the existing target re-recognition method limits the discrimination of feature expression due to unfixed number of clustering centers and causes poor robustness of recognition results. The system method comprises the following steps: acquiring an image to be identified as an input image; extracting the characteristics of the input image through a pre-trained characteristic extraction network to serve as first characteristics; and calculating the Euclidean distance between the first feature and the corresponding feature of each image in the image library, sequencing the first feature and the corresponding feature of each image in the image library, and outputting a sequencing result. The invention improves the robustness of cross-domain target re-identification.","['G06V20/20', 'G06F18/214', 'G06F18/22', 'G06F18/23213', 'G06N3/045', 'G06N3/08']"
US10691975B2,Lookup-based convolutional neural network,"Systems and methods are disclosed for lookup-based convolutional neural networks. For example, methods may include applying a convolutional neural network to image data based on an image to obtain an output, in which a layer of the convolutional network includes filters with weights that are stored as a dictionary (D) of channel weight vectors, a respective lookup index tensor (I) that indexes the dictionary, and a respective lookup coefficient tensor (C), and in which applying the convolutional neural network includes: convolving the channel weight vectors of the dictionary (D) with an input tensor based on the image to obtain an input dictionary (S), and combining entries of the input dictionary (S) that are indexed with indices from the respective lookup index tensor (I) and multiplied with corresponding coefficients from the respective lookup coefficient tensor (C); and storing, displaying, or transmitting data based on the output of the convolutional neural network.","['G06K9/6255', 'G06V10/82', 'G06F18/214', 'G06F18/217', 'G06F18/24133', 'G06F18/28', 'G06K9/00624', 'G06K9/6256', 'G06K9/6262', 'G06K9/6271', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V20/00']"
US12192820B2,Reinforcement learning for multi-access traffic management,"The present disclosure is related to multi-access traffic management in edge computing environments, and in particular, artificial intelligence (AI) and/or machine learning (ML) techniques for multi-access traffic management. A scalable AI/ML architecture for multi-access traffic management is provided. Reinforcement learning (RL) and/or Deep RL (DRL) approaches that learn policies and/or parameters for traffic management and/or for distributing multi-access traffic through interacting with the environment are also provided. Deep contextual bandit RL techniques for intelligent traffic management for edge networks are also provided. Other embodiments may be described and/or claimed.","['H04W28/0268', 'H04W74/08', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N3/092', 'G06N3/098', 'G06N7/01', 'H04W24/06', 'H04W28/0231', 'H04W28/0247', 'H04W28/06', 'H04W28/24']"
US11995803B1,Training and deployment of image generation models,"In some embodiments, a method receives a text prompt and executes a text encoder on the text prompt to generate an embedding representation. A set of base images is generated based on the embedding representation and parameters of a base image generation model. A high resolution model is executed to upsample one or more base images in the set of base images based on parameters of the high resolution model to generate a set of final images. The method ranks the set of base images or the set of final images using reward values that are generated by a reward model. The reward model is trained using human input that provided feedback on a quality of generated images using the base image generation model and the high resolution model. One or more final images are output based on the ranking in response to the text prompt.","['G06T5/70', 'G06T11/00', 'G06T2207/20081', 'G06T2207/20084']"
US12127059B2,Intelligence and learning in O-RAN for 5G and 6G cellular networks,"A radio access network (RAN) intelligent controller (RIC) and corresponding method may be implemented within RAN and in next-generation cellular networks to improve performance. The RIC comprises an interface to a RAN and further comprises a data-driven logic unit. The data-driven logic unit (i) produces, based on data received from the RAN via the interface, a representation describing a state of the RAN and (ii) based on the representation describing the state, instructs an action associated with at least one network element. The interface transmits a message based on the action instructed. The message is to be routed to the at least one network element. The representation is based on a context of the RAN. The message transmitted enabling re-configuration of the at least one network element. The re-configuration improves performance of the at least one network element within the context.","['H04W36/06', 'H04B17/15', 'H04B17/17', 'H04B17/336', 'H04W28/0236', 'H04W28/0967', 'H04W28/24', 'H04W36/30']"
US11983846B2,Machine learning based image adjustment,"An imaging system can obtain image data, for instance from an image sensor. The imaging system can supply the image data as input data to a machine learning system, which can generate one or more maps based on the image data. Each map can identify strengths at which a certain image processing function is to be applied to each pixel of the image data. Different maps can be generated for different image processing functions, such as noise reduction, sharpening, or color saturation. The imaging system can generate a modified image based on the image data and the one or more maps, for instance by applying each of one or more image processing functions in accordance with each of the one or more maps. The imaging system can supply the image data and the one or more maps to a second machine learning system to generate the modified image.","['G06T5/00', 'G06N3/084', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06T1/20', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T5/90', 'H04N23/88', 'H04N25/60', 'H04N9/643', 'H04N9/646', 'H04N9/68', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'H04N23/84']"
CN115943394B,"Method, apparatus and system for secure longitudinal federal learning","The machine learning model is learned using secure vertical federal learning by the network machine learning model receiving a set of private machine learning model outputs from the plurality of private machine learning models. The set of private machine learning models outputs data that is exclusively owned based on each of the plurality of private machine learning models. The set of private machine learning models output sample ID alignments based on the data. The network machine learning model provides predictions that are output by the network model based on the set of private machine learning model outputs. The network model transmits the prediction to one of the plurality of private machine learning models, the one of the plurality of private machine learning models including a tag. The network model receives a loss based on the tag and the prediction from the one of the plurality of private machine learning models, calculates a gradient based on the loss, and updates parameters of the network model based on the loss.","['G06N3/045', 'G06N20/00', 'G06N3/09', 'G06N3/098', 'G06Q30/0201']"
CN113326731B,Cross-domain pedestrian re-identification method based on momentum network guidance,"Aiming at the problem of pseudo tag noise interference caused by domain offset phenomenon in a cross-domain pedestrian re-recognition task, the invention provides a cross-domain pedestrian re-recognition algorithm based on momentum network guidance. The method comprises the following steps: step S1, initializing a backbone network by using a pre-trained model on an ImageNet data set; s2, performing pre-fine adjustment on the model by using marked data on the source domain data set so as to fully utilize the marked information of the source domain; s3, initializing a proposed momentum learning frame by using a model trained by setting different random parameters on a source domain data set, and clustering according to the extracted features of the model by using a clustering algorithm to generate a hard pseudo tag with the confidence coefficient of 1; s4, designing a new softened pseudo tag and a loss function to combine with the traditional loss to train an optimization model; and S5, updating the hard pseudo tag before each iteration starts, dynamically updating the soft pseudo tag in real time, and continuously iterating the pseudo tag generation and optimization steps until the model converges.","['G06V40/103', 'G06F18/214', 'G06F18/23213', 'G06F18/2415', 'G06N3/045', 'G06N3/088', 'Y02T10/40']"
US12105773B2,Semantic relation preserving knowledge distillation for image-to-image translation,"GANs based generators are useful to perform image to image translations. GANs models have large storage sizes and resource use requirements such that they are too large to be deployed directly on mobile devices. Systems and methods define through conditioning a student GANs model having a student generator that is scaled downwardly from a teacher GANs model (and generator) using knowledge distillation. A semantic relation knowledge distillation loss is used to transfer semantic knowledge from an intermediate layer of the teacher to an intermediate layer of the student. Student generators thus defined are stored and executed by mobile devices such as smartphones and laptops to provide augmented reality experiences. Effects are simulated on images, including makeup, hair, nail and age simulation effects.","['G06F18/22', 'G06N3/088', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/02', 'G06Q30/0631', 'G06Q30/0643', 'G06T19/006']"
CN108133013B,"Information processing method, information processing device, computer equipment and storage medium","The invention relates to an information processing method, an information processing device, a computer device and a storage medium, wherein the method comprises the following steps: acquiring a user to be recommended and incidence relation information of the user to be recommended; obtaining the associated users of the users to be recommended according to the associated relation information of the users to be recommended; acquiring a user portrait of the associated user and a user portrait of the user to be recommended; obtaining portrait difference according to the user portrait of the user to be recommended and the user portrait of the associated user; obtaining a resource influence weight corresponding to the associated user according to the image difference; and obtaining resource recommendation information corresponding to the user to be recommended according to the historical resource transfer data of each associated user and the corresponding resource influence weight. The method improves the accuracy of the recommendation information and saves computer resources and time of the user.","['G06Q40/08', 'G06F16/9535', 'G06F18/214', 'G06F18/2411', 'G06Q40/06']"
US11049250B2,Systems and methods to deliver point of care alerts for radiological findings,"Apparatus, systems, and methods to improve imaging quality control, image processing, identification of findings in image data, and generation of notification at or near a point of care for a patient are disclosed and described. An example imaging apparatus includes a memory including chest image data and instructions and a processor. The example processor is to execute the instructions to at least: process the chest image data using a trained learning network in real time after acquisition of the chest image data to identify a pneumothorax in the chest image data; receive feedback regarding the identification of the pneumothorax; and, when the feedback confirms the identification of the pneumothorax, trigger a notification at the imaging apparatus to notify a healthcare practitioner regarding the pneumothorax and prompt a responsive action with respect to a patient associated with the chest image data.","['G16H30/40', 'G06T7/0016', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06N5/046', 'G06T7/0014', 'G16H30/20', 'G16H40/63', 'G16H50/20', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061']"
US11341646B2,Systems and methods to deliver point of care alerts for radiological findings,"Apparatus, systems, and methods to improve imaging quality control, image processing, identification of findings, and generation of notification at or near a point of care are disclosed and described. An example imaging apparatus includes a processor to at least: process the first image data using a trained learning network to generate a first analysis of the first image data; identify a clinical finding in the first image data based on the first analysis; compare the first analysis to a second analysis, the second analysis generated from second image data obtained in a second image acquisition; and, when comparing identifies a change between the first analysis and the second analysis, generate a notification at the imaging apparatus regarding the clinical finding to trigger a responsive action.","['G06T7/0014', 'G06T7/70', 'G16H10/60', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30168']"
CN109146440B,"Transaction settlement method, device, server and storage medium","The application discloses a transaction settlement method, a device, a server and a storage medium, wherein the method comprises the following steps: acquiring a transaction record to be settled; determining the matching degree of the transaction record with a plurality of preset transaction settlement rules respectively by utilizing a rule matching model obtained by pre-training; determining a target transaction settlement rule required for performing transaction settlement on the transaction record from the preset multiple transaction settlement rules according to the matching degree of the transaction record and the preset multiple transaction settlement rules; transaction settlement is performed on the transaction record based on the target transaction settlement rule. The scheme of the application can reduce the situation of transaction settlement failure caused by the fact that the transaction settlement rule cannot be matched, and further reduce the situation of settlement and posting delay of a payee in a payment platform.","['G06Q20/085', 'G06Q20/08', 'G06Q20/10', 'G06Q20/102', 'G06Q20/3821', 'G06Q30/00', 'H04M15/00']"
WO2023050992A1,"Network training method and apparatus for facial reconstruction, and device and storage medium","Disclosed in the embodiments of the present application are a network training method and apparatus for facial reconstruction, and a device and a storage medium. The method comprises: acquiring a plurality of frames of first facial images of a first target object; inputting each frame of first facial image into a corresponding coefficient regression network, so as to obtain a facial reconstruction coefficient of each frame of first facial image, wherein each coefficient regression network has the same network parameter, and the facial reconstruction coefficients comprise: an identity coefficient, an expression coefficient, a texture coefficient, a pose coefficient and an illumination coefficient; obtaining a two-dimensional reconstructed image of the corresponding frame of first facial image according to the facial reconstruction coefficient; constructing loss functions of the coefficient regression network according to the first facial image, the corresponding two-dimensional reconstructed image and the facial reconstruction coefficient, wherein the loss functions comprise an unsupervised training loss function and an identity constraint loss function of each frame of first facial image; and updating the network parameter of the coefficient regression network according to the loss functions. By using the method, the technical problem of low expression accuracy during the reconstruction of a three-dimensional facial image can be solved.","['G06N3/04', 'G06N3/08', 'G06T13/40', 'G06T7/11', 'G06T7/194', 'G06V10/774']"
US12210971B2,Methods of providing data privacy for neural network based inference,"Methods and systems that provide data privacy for implementing a neural network-based inference are described. A method includes injecting stochasticity into the data to produce perturbed data, wherein the injected stochasticity satisfies an ε-differential privacy criterion and transmitting the perturbed data to a neural network or to a partition of the neural network for inference.","['G06N3/08', 'G06F18/15', 'G06F18/211', 'G06F21/60', 'G06F21/6245', 'G06N3/0464', 'G06N3/063', 'G06N3/09', 'G06T3/4046', 'G06V10/771']"
US11748555B2,Systems and methods for machine content generation,"Computerized systems and methods are disclosed to generate a document by providing a document structure having one or more seed landmark texts therein, each landmark text including a milestone overview text and a plurality of component texts; from the milestone overview text, generating one or more computer-generated text suggestions to supplement the milestone overview text; combining the milestone overview text with each component text and generating one or more computer-generated component text suggestions; and creating the document by combining the milestone overview, the one or more computer-generated text suggestions, and each component text with corresponding one or more computer-generated component text suggestions.","['G06F40/169', 'G06F21/1015', 'G06F21/32', 'G06F40/137', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'G06F21/105', 'G06F40/30']"
CN111062215B,Named entity recognition method and device based on semi-supervised learning training,"The application relates to a named entity recognition method, a named entity recognition device, a named entity recognition computer device and a named entity recognition storage medium based on semi-supervised learning training. The method comprises the following steps: acquiring marked data and unmarked data; performing supervision training on the sequence annotation model by using the annotation data; calculating semantic vectors corresponding to the annotation data and the non-annotation data through the trained sequence annotation model, and identifying the non-annotation data which are distributed with the annotation data according to the semantic vectors; invoking a semi-supervised learning model, wherein the semi-supervised learning model is composed of the trained sequence labeling model and an auxiliary prediction network with limited input visual angles; training the semi-supervised learning model through uniformly distributed unmarked data, and outputting a corresponding named entity recognition result through Viterbi decoding. By adopting the method, the data labeling cost can be effectively reduced, and the accuracy of named entity identification can be effectively improved.","['G06N3/045', 'G06N3/049', 'G06N3/08']"
US11712208B2,Systems and methods to deliver point of care alerts for radiological findings,"Apparatus, systems, and methods to deliver point of care alerts for radiological findings are disclosed. An example imaging apparatus includes an image data store, an image quality checker, and a training learning network. The example image data store is to store image data acquired using the imaging apparatus. The example image quality checker is to evaluate image data from the image data store in comparison to an image quality measure. The example trained learning network is to process the image data to identify a clinical finding in the image data, the identification of a clinical finding to trigger a notification at the imaging apparatus to notify a healthcare practitioner regarding the clinical finding and prompt a responsive action with respect to a patient associated with the image data.","['A61B5/747', 'A61B5/0013', 'A61B6/032', 'A61B6/037', 'G16H15/00', 'G16H30/40', 'G16H50/20', 'A61B5/0035', 'A61B5/055', 'A61B6/467', 'G06T7/0012']"
US12399892B2,System and method for transferable natural language interface,"A computer system and method for answering a natural language question is provided. The system comprises at least one processor and a memory storing instructions which when executed by the processor configure the processor to perform the method. The method comprises receiving a natural language question, generating a SQL query based on the natural language question, generating an explanation regarding a solution to the natural language question as answered by the SQL query, and presenting the solution and the explanation.","['G06F16/2433', 'G06F16/243']"
US11928957B2,Audiovisual secondary haptic signal reconstruction method based on cloud-edge collaboration,"An audio visual haptic signal reconstruction method includes first utilizing a large-scale audio-visual database stored in a central cloud to learn knowledge, and transferring same to an edge node; then combining, by means of the edge node, a received audio-visual signal with knowledge in the central cloud, and fully mining semantic correlation and consistency between modals; and finally fusing the semantic features of the obtained audio and video signals and inputting the semantic features to a haptic generation network, thereby realizing the reconstruction of the haptic signal. The method effectively solves the problems that the number of audio and video signals of a multi-modal dataset is insufficient, and semantic tags cannot be added to all the audio-visual signals in a training dataset by means of manual annotation. Also, the semantic association between heterogeneous data of different modals are better mined, and the heterogeneity gap between modals are eliminated.","['G06F18/253', 'G08B6/00', 'G06F18/2415', 'G06N3/0455', 'G06N3/084', 'G06N3/0895', 'G06V10/806', 'G06V10/82', 'G06V20/46', 'H04L67/1097', 'Y02D10/00']"
US11568315B2,Systems and methods for learning user representations for open vocabulary data sets,"Systems and methods adapted for training a machine learning model to predict data labels are described. The approach includes receiving a first data set comprising first data objects and associated first data labels, and processing, with a user representation model, respective first data objects and associated data labels associated with a unique user representation by fusing the respective first data object and the associated first data labels. First data object representations of the respective first data objects are generated, and the first data object representations and the user representation model outputs are fused to create a user conditional object representation. The machine learning model updates corresponding parameters based on an error value based on a maximum similarity of the projections of the respective user conditional object representation and first data labels in a joint embedding space.","['G06F16/367', 'G06N20/00', 'G06F16/285', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09']"
US11935167B2,Method and apparatus for virtual fitting,"Disclosed in embodiments of the present disclosure are a method and apparatus for virtual fitting. A specific implementation of the method comprises: receiving a fitting request comprising a model picture and a user image; performing human body positioning and surface coordinate analysis on the model picture and the user image respectively; performing clothing segmentation on the model picture and the user image respectively; on the basis of the clothing segmentation result and the surface coordinate analysis result, covering the pixels corresponding to a piece of clothing in the model picture to corresponding positions in the user image to obtain a synthesized image and information to be completed; and inputting the synthesized image, the positioning result of the user image, and said information into a pre-trained image completion network to obtain a completed image.","['G06T11/60', 'H04N5/272', 'G06F18/214', 'G06F18/253', 'G06F3/011', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06Q30/0621', 'G06Q30/0643', 'G06T11/001', 'G06T7/11', 'G06T7/70', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06V40/103', 'H04N5/265', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30196', 'G06T2210/16', 'H04N2005/2726']"
TWI736262B,Methods for training machine learning model for computation lithography,"Described herein are different methods of training machine learning models related to a patterning process. Described herein is a method for training a machine learning model configured to predict a mask pattern. The method including obtaining (i) a process model of a patterning process configured to predict a pattern on a substrate, wherein the process model comprises one or more trained machine learning models, and (ii) a target pattern, and training, by a hardware computer system, the machine learning model configured to predict a mask pattern based on the process model and a cost function that determines a difference between the predicted pattern and the target pattern.","['G06N20/00', 'G06N3/08', 'G03F1/36', 'G06F30/20', 'G06N3/04', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/045']"
RU2659737C1,System and method of managing computing resources for detecting malicious files,FIELD: information technology.,"['G06F21/561', 'G06F21/56', 'G06F21/563', 'G06F21/566', 'G06F21/57', 'G06N20/00', 'G06N20/10', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06F2221/033', 'G06N20/20', 'G06N5/01', 'G06N7/01']"
US20220101127A1,Automatic optimization of machine learning algorithms in the presence of target datasets,"Methods, systems and computer program products for transferring knowledge using machine learning techniques by automatically generating training datasets are provided. New training datasets based on target datasets are automatically generated and used in machine learning techniques to perform tasks on images. One of the main benefits is the possibility to transfer the knowledge learned in one domain to another domain in which extracting data or labeling images would be costly or simply infeasible. The methods and systems also provide image training sets based on image target sets which augments data in a more efficient way and improves the content of the training set and the prediction of the machine learning techniques.","['G05B13/0265', 'G06F18/214', 'G06F18/2163', 'G06F18/22', 'G06K9/6215', 'G06K9/6256', 'G06K9/6261', 'G06N3/045', 'G06N3/08', 'G06V10/26', 'G06V10/774', 'G06V20/13', 'G06N20/10']"
US20220060639A1,Live style transfer on a mobile device,"Various embodiments of the present invention relate generally to systems and processes for transforming a style of video data. In one embodiment, a neural network is used to interpolate native video data received from a camera system on a mobile device in real-time. The interpolation converts the live native video data into a particular style. For example, the style can be associated with a particular artist or a particular theme. The stylized video data can viewed on a display of the mobile device in a manner similar to which native live video data is output to the display. Thus, the stylized video data, which is viewed on the display, is consistent with a current position and orientation of the camera system on the display.","['H04N5/77', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'H04L65/601', 'H04L65/75', 'H04L65/756', 'H04N23/632', 'H04N5/232935', 'H04N5/2621', 'H04N5/2628', 'H04N5/9201', 'H04N9/8227']"
US11052309B2,Wireless interactive game having both physical and virtual elements,"Embodiments of the invention provide a unique interactive game that connects both physical and virtual play environments and includes multiple dynamic layers in which a participant may complete a variety of challenges and/or tasks. For example, the participant may obtain a physical gaming item such as a toy from a retail phase that is usable in an interactive entertainment phase that provides virtual play via computer animation. The interactive entertainment phase may include multiple interrelated layers such that progress in one or more layers may affect the participant's experience in one or more other layers. The participant may also receive training on how to use and improve the physical gaming item to help achieve one or more special effects or complete one or more adventures and/or quests. During or following the interactive entertainment phase, the participant may use accumulated points and/or powers to redeem prizes and/or compete against other participants, such as in a duel or other face-off challenge.","['A63F13/245', 'A63F13/10', 'A63F13/00', 'A63F13/12', 'A63F13/211', 'A63F13/235', 'A63F13/30', 'A63F13/31', 'A63F13/32', 'A63F13/327', 'A63F13/45', 'A63F13/65', 'A63F13/73', 'A63F13/825', 'A63F13/90', 'A63F13/95', 'A63F13/98', 'A63F9/24', 'A63H30/04', 'A63H33/26', 'A63J21/00', 'A63F2009/2492', 'A63F2300/1025', 'A63F2300/1031', 'A63F2300/105', 'A63F2300/1062', 'A63F2300/406', 'A63F2300/5513', 'A63F2300/5533', 'A63F2300/609', 'A63F2300/807', 'A63H2200/00']"
US11687776B2,Method for controlling cook based on artificial intelligent and intelligent device,"A method for controlling cooking based on artificial intelligence and an artificial intelligence device are disclosed. In the method for controlling cooking based on artificial intelligence, it is possible to continuously monitor how food ingredients are progressing by generating reference information including image information of completed dishes using food ingredient image information acquired through a monitoring unit provided in a kitchen appliance (for example, oven) and determining the cooked state of the food ingredients based on the reference information. An artificial intelligence device according to the present disclosure may be linked with an artificial intelligence module, a drone (unmanned aerial vehicle (UAV)), a robot, an augmented reality (AR) device, a virtual reality (VR) device, devices related to 5G services, and the like.","['G06N3/08', 'F24C7/085', 'A47J36/321', 'G06F16/951', 'G06F18/214', 'G06N3/006', 'G06N3/0464', 'G06N3/09', 'G06V20/68']"
AU2018202658B2,Computer generated three dimensional virtual reality environment for improving memory,"The present disclosure relates to a computer generated 3D virtual environment for improving memory (e.g. spatial, temporal, spatial-temporal, working and short-term memory). In an aspect, there is provided a computer-implemented method for generating a 3D virtual reality 5 (VR) environment for improving spatial memory. In an embodiment, the method comprises executing at least one VR memory training module including one or more memory training tasks to be performed within a navigable three-dimensional (3D) environment; displaying a navigable 3D environment via an output to a display; and receiving an input from an interactive navigational controller. In another embodiment, the method may further comprise performing 0 one or more scans of brain activity, whereby, the effectiveness of the at least one VR memory training module in targeting a region of the brain can be measured. The determination of which VR memory training modules to retrieve and execute may be made based on the measured effectiveness of a previous VR memory training module training session in targeting a selected region of the brain. 45","['G09B19/00', 'G06T19/003', 'G16H30/20', 'G16H50/50', 'A61B5/055', 'G06T2210/41', 'G09B5/02', 'G09B9/00', 'G16H10/20', 'G16H20/70']"
US12164873B2,System and method for hybrid question answering over knowledge graph,"Aspects of the subject disclosure may include, for example, identifying an entity of a natural language question, locating a node of a knowledge graph corresponding to the entity, and generating a candidate answer set including a group of other entities located a predetermined proximity to the node. Contextual information for the group of other entities is determined from the knowledge graph, and the natural language question and contextual information are separately encoded to obtain separate encoded vectorial representations of the natural language question and members of the candidate answer set. The encoding uses pre-trained language model embeddings obtained via a bidirectional encoder representations from transformer encoding process. The encoded vectorial representations of the question under an influence of aspects of the contextual information are scored and a member of the candidate answer set selected according to the score to obtain an answer to the original question. Other embodiments are disclosed.","['G06F16/9024', 'G06F16/3347', 'G06F16/90332', 'G06F40/295', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N5/02', 'G06N5/04', 'G06N5/041']"
US10482639B2,Deep high-resolution style synthesis,"In some embodiments, techniques for synthesizing an image style based on a plurality of neural networks are described. A computer system selects a style image based on user input that identifies the style image. The computer system generates an image based on a generator neural network and a loss neural network. The generator neural network outputs the synthesized image based on a noise vector and the style image and is trained based on style features generated from the loss neural network. The loss neural network outputs the style features based on a training image. The training image and the style image have a same resolution. The style features are generated at different resolutions of the training image. The computer system provides the synthesized image to a user device in response to the user input.","['G06T11/60', 'G06F18/214', 'G06K9/46', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06T11/001', 'G06V10/40', 'G06V10/774', 'G06V10/82']"
US20250182756A1,Systems and methods for local automated speech-to-text processing,"Systems and methods are described herein for enabling, on a local device, a voice control system that limits the amount of data needed to be transmitted to a remote server. A data structure is built at the local device to support a local speech-to-text model by receiving a query and transmitting, to a remote server over a communication network, a request for a speech-to-text transcription of the query. The transcription is received from the remote server and stored in the data structure at the local device in association with an audio clip of the query. Metadata describing the query is used to train the local speech-to-text model to recognize future instances of the query.","['G10L15/22', 'G10L15/063', 'G10L15/26', 'G10L15/30', 'G10L15/32', 'G06F3/167', 'G10L2015/0635', 'G10L2015/223']"
US11279361B2,Efficiency improvement for machine learning of vehicle control using traffic state estimation,A method of improving efficiency of a vehicle behavior controller using a traffic state estimation network is described. The method includes feeding an input of a feature extraction network of the vehicle behavior controller with a sequence of images. The sequence of images include a highway section and corresponding traffic data. The method also includes disentangling an estimated behavior of a controlled ego vehicle. by the traffic state estimation network. The traffic state estimate network disentangles the estimated of the controlled ego vehicle from extracted traffic state features of the input provided by the feature extraction network. The method further includes selecting an action to adjust an autonomous behavior of the controlled ego vehicle according to the estimated behavior of the controlled ego vehicle.,"['B60W30/18163', 'B60W60/001', 'G05D1/0088', 'G06N3/006', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/092', 'G08G1/0112', 'G08G1/0116', 'G08G1/0141', 'G08G1/167', 'H04W4/40', 'B60W2050/0088', 'B60W2554/80', 'G05D2201/0213', 'G06N7/01']"
US8998815B2,Wearable heart rate monitor,"A biometric monitoring device is used to determine a user's heart rate by using a heartbeat waveform sensor and a motion detecting sensor. In some embodiments, the device collects collecting concurrent output data from the heartbeat waveform sensor and output data from the motion detecting sensor, detects a periodic component of the output data from the motion detecting sensor, and uses the periodic component of the output data from the motion detecting sensor to remove a corresponding periodic component from the output data from the heartbeat waveform sensor. From this result, the device may determine and present the user's heart rate.","['A61B5/02405', 'A61B5/0205', 'A61B5/1118', 'A61B5/1123', 'A61B5/318', 'A61B5/681', 'A61B5/6824', 'A61B5/6831', 'A61B5/721', 'A61B2562/0219', 'A61B5/02416', 'A61B5/0245', 'A61B5/0402', 'A61B5/742']"
US11404145B2,Medical machine time-series event data processor,"Systems, apparatus, instructions, and methods for medical machine time-series event data processing are disclosed. An example time series event data processing apparatus includes memory storing instructions and one-dimensional time series healthcare-related data; and at least one processor. The example at least one processor is to: execute artificial intelligence model(s) trained on aggregated time series data to at least one of a) predict a future medical machine event, b) detect a medical machine event, or c) classify the medical machine event using the one-dimensional time series healthcare-related data; when the artificial intelligence model(s) are executed to predict the future medical machine event, output an alert related to the predicted future medical machine event to trigger a next action; and when the artificial intelligence model(s) are executed to detect and/or classify the medical machine event, label the medical machine event and output the labeled event to trigger the next action.","['G16H50/20', 'G16H10/00', 'A61B5/7267', 'G06F9/451', 'G06N20/00', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/049', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G16H10/60', 'G16H15/00', 'G16H40/67', 'G16H50/30', 'G16H50/50', 'A61B5/7275', 'G06T2207/20081', 'G06T2207/20084', 'G16H30/00', 'G16H70/20']"
CN106910351B,A traffic signal adaptive control method based on deep reinforcement learning,"The invention relates to the technical field of traffic control and artificial intelligence, in particular to a traffic signal self-adaptive control method based on deep reinforcement learning, which comprises the following steps: (1) defining a traffic signal control agent, a state space S, an action space A and a return function r, (2) pre-training a deep neural network, (3) training the neural network by using a deep reinforcement learning method, and (4) controlling traffic signals according to the trained deep neural network. Preprocessing traffic data acquired by magnetic induction, video, RFID, Internet of vehicles and the like to acquire a low-level representation of a traffic state containing vehicle position information; secondly, sensing the traffic state through a deep-learning multilayer sensor to obtain high-level abstract characteristics of the current traffic state; on the basis, a proper timing scheme is selected by using the decision-making capability of reinforcement learning according to the high-level abstract characteristics of the current traffic state, so that the self-adaptive control of traffic signals is realized, the travel time of vehicles is reduced, and the safe, smooth, ordered and efficient operation of traffic is ensured.","['G08G1/08', 'G06N3/045', 'G06N3/08']"
US20210174347A1,User Routing Application and Recommendation Engine for Distributed Terminal Network,"A graphical user interface (GUI) for user routing and recommendation application in a distributed terminal network is described. In some embodiments, the terminals may be hardware terminals, kiosks, or clients. In some embodiments, a security analysis may be performed, and security scores may be determined, for visitors requesting operations at terminals based on an operator configuration. Security scores may be determined by a provider, in communication with the operator terminals, based on aggregation of a plurality of factors, wherein each factor may be weighted. The factors may incorporate operator settings or preferences. In one embodiment, the factors include one or more facial recognition factors. The one or more facial recognition factors may be used for biometric authentication. The provider may use the security scores to determine user privileges or permissions for the operations. The provider may deliver instructions or messages to the terminals based on the determinations. In some embodiments, the GUI is a map visualization for intelligently routing and recommending nearby terminals created from information delivered by the provider.","['G06Q20/3674', 'G07F19/211', 'G06F3/048', 'G06Q20/065', 'G06Q20/1085', 'G06Q20/18', 'G06Q20/20', 'G06Q20/204', 'G06Q20/3255', 'G06Q20/326', 'G06Q20/3274', 'G06Q20/363', 'G06Q20/381', 'G06Q20/3823', 'G06Q20/4014', 'G06Q20/40145', 'G06Q20/4016', 'G06Q20/405', 'G06Q20/425', 'H04L63/0272', 'H04L63/0428', 'H04L63/0861', 'H04L63/166', 'H04W4/021', 'H04W4/029', 'H04L2463/082']"
WO2022199032A1,"Model construction method, task allocation method, apparatus, device, and medium","In a model construction method, a task allocation method, an apparatus, a device, and a medium, a training device splits a scheduling policy for unmanned-aerial-vehicle-aided mobile edge computing into sub-problems of two levels, namely, unmanned aerial vehicle position optimization and task computation unloading optimization; and a corresponding position model and task model are alternately optimized by using hierarchical reinforcement learning, such that the complexity of each sub-problem is reduced, and the learning efficiency and convergence efficiency of the overall system are improved.","['G06F30/15', 'G06F30/20', 'G06F9/44594', 'G06F9/4881', 'G06F9/5038', 'G06F2119/12', 'G06F2209/509']"
WO2021244207A1,Method and apparatus for training driving behavior decision-making model,"A method and apparatus for training a driving behavior decision-making model. The method comprises: using a driving behavior decision-making model to make a decision according to state information of a vehicle, so as to obtain driving behavior decision-making information; sending the driving behavior decision-making information to a server; receiving a first parameter, sent by the server, of an imitation learning model, wherein the first parameter is obtained after the server uses the driving behavior decision-making information to train the imitation learning model on the basis of an imitation learning method; and adjusting parameters of the driving behavior decision-making model according to the driving behavior decision-making information and the first parameter. The present method facilitates improvement of the efficiency of training a driving behavior decision-making model, and the driving behavior decision-making model obtained after training can output rational and reliable driving behavior decision-making information.","['G05D1/024', 'G05D1/02', 'G05D1/0214', 'G05D1/0221', 'G05D1/0223', 'G05D1/0242', 'G05D1/0246', 'G05D1/0257', 'G05D1/0263', 'G05D1/0278', 'G05D1/028', 'G05D1/0285', 'G06N3/02']"
US11250088B2,Method and apparatus for processing user interaction sequence data,"Computer-implemented methods, computer-implemented systems, and non-transitory, computer-readable media for processing interaction sequence data are disclosed. One computer-implemented method includes: obtaining a dynamic interaction graph is obtained, where the dynamic interaction graph is constructed based on a dynamic interaction sequence, including a plurality of interactions arranged in a chronological order, where each interaction includes two objects involved in the interaction and a time of the interaction. In the dynamic interaction graph, a sub-graph corresponding to a target node is determined, where nodes in the sub-graph comprise the target node and connection nodes connected to the target node through a predetermined amount of edges originating from the target node. A feature vector corresponding to the target node is determined based on a node feature of each of the nodes of the sub-graph and directions of edges of the sub-graph.","['G06F16/958', 'G06F16/9536', 'G06F16/9024']"
US10305766B1,Coexistence-insensitive presence detection,"A system and method include processing logic receiving, from a wireless transceiver of a first device, first data indicative of channel state information (CSI) of a first communication link between the wireless transceiver and a wireless transmitter of a second device, the first device and the second device being located in a building. The logic pre-preprocesses the first data to generate input vectors composed of statistical parameter values derived from sets of discrete samples of the first data. The logic processes, through a long short-term memory (LSTM) layer of a neural network, the input vectors to generate multiple hidden state values of the neural network. The logic processes, through a set of additional layers of the neural network, respective hidden state values of the multiple hidden state values to determine that a human is present in the building.","['H04B17/391', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/048', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G08B21/0484', 'H04B17/318', 'H04B7/0626', 'H04L43/08', 'H04W4/029', 'H04W4/33', 'H04W64/003', 'G06N20/00', 'H04M1/724', 'H04M1/72403', 'H04M1/72519', 'H04M1/72522', 'H04W4/02', 'H04W64/00']"
US20230223035A1,Systems and methods for visually guided audio separation,A system for separating audio based on sound producing objects includes a processor configured to receive video data and audio data. The processor is also configured to perform object detection using the video data to identify a number of sound producing objects in the video data and predict a separation for each sound producing object detected in the video data. The processor is also configured to generate separated audio data for each sound producing object using the separation and the audio data.,"['G10L21/028', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06T7/11', 'G06T7/168', 'G06T7/174', 'G06T7/70', 'G10L25/18', 'G10L25/51', 'G10L25/57', 'G06T2207/10016', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G10L25/30']"
CN109935336B,Intelligent auxiliary diagnosis system for respiratory diseases of children,"The application provides an intelligent auxiliary diagnosis system for respiratory diseases of children, which comprises: s1, acquiring auxiliary examination information and/or doctor inquiry record information of a child to be diagnosed; s2, screening key information according to the auxiliary examination information and/or doctor inquiry record information; s3, processing the key information by adopting a pre-trained typical symptom diagnosis model according to a pre-established knowledge base system of the children diseases to obtain a diagnosis result; the diagnostic result includes: at least one possible disease, and each possible disease corresponds to a characteristic of the child to be diagnosed. The intelligent auxiliary diagnosis system can help non-expert doctors to improve diagnosis level of difficult and complicated diseases and reduce misdiagnosis.",['Y02A90/10']
CN110341690B,PHEV energy management method based on deterministic strategy gradient learning,"The invention provides a PHEV energy management method based on deterministic strategy gradient learning, which realizes the closed-loop application of the PHEV energy management based on the deterministic strategy gradient learning, including strategy training, on-line application, effect detection, feedback updating and other aspects, has higher accuracy compared with the prior art, greatly improves the efficiency and reliability of the PHEV energy management, and has beneficial effects which are not possessed by a plurality of current management strategies.","['B60W20/11', 'B60W50/00', 'G06N3/045', 'B60W2050/0008', 'Y02T90/14']"
US11562244B2,Robust pruned neural networks via adversarial training,"Systems, methods, and computer readable media are described to train a compressed neural network with high robustness. The neural network is first adversarially pre-trained with both original data as well as data perturbed by adversarial attacks for some epochs, then “unimportant” weights or filters are pruned through criteria based on their magnitudes or other method (e.g., Taylor approximation of the loss function), and the pruned neural network is retrained with both clean and perturbed data for more epochs.","['G06N3/082', 'G06F17/13', 'G06F21/552', 'G06F21/577', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
US9767381B2,Similarity-based detection of prominent objects using deep CNN pooling layers as features,"A system and method provide object localization in a query image based on a global representation of the image generated with a model derived from a convolutional neural network. Representations of annotated images and a query image are each generated based on activations output by a layer of the model which precedes the fully-connected layers of the neural network. A similarity is computed between the query image representation and each of the annotated image representations to identify a subset of the annotated images having the highest computed similarity. Object location information from at least one of the subset of annotated images is transferred to the query image and information is output, based on the transferred object location information.","['G06V10/82', 'G06K9/6215', 'G06F16/54', 'G06F16/5854', 'G06F17/30259', 'G06F17/30274', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T7/10', 'G06T7/74', 'G06V10/255', 'G06V10/454', 'G06V10/7715', 'G06V20/63', 'G06K2209/15', 'G06T2207/20084', 'G06T2210/12', 'G06V20/625', 'G06V40/103']"
CN118233936B,Integrated networking method and system based on satellite communication and short wave communication,"The invention discloses a fusion networking method and system based on satellite communication and short wave communication, comprising the following steps: acquiring demand data of an application scene, constructing a converged communication network, and configuring initial parameters of a system; collecting and preprocessing historical communication data of an application scene to form a training set, constructing a converged communication network optimization module and training, and updating initial parameters of the converged communication network after training is completed to obtain a converged communication network with optimized parameters; configuring a fusion communication network with optimized parameters, respectively estimating channel parameters of a current satellite communication system and a short wave communication system, and estimating channel quality according to the channel parameters; and adjusting a modulation and coding scheme by adopting an adaptive modulation and coding module according to the channel quality, performing cross-layer route optimization on the constructed converged communication network, and transmitting the packet data in a preset mode. Through fusion complementation of multi-level heterogeneous networks, global information transmission can be realized in a complex environment.","['H04W24/02', 'H04B17/373', 'H04B17/382', 'H04B7/18513', 'H04W24/06', 'H04W40/12', 'H04W84/06', 'H04W84/18', 'Y02D30/70']"
CN114022693B,Single-cell RNA-seq data clustering method based on double self-supervision,"The invention discloses a single-cell RNA-seq data clustering method based on double self-supervision, which comprises the steps of firstly constructing a deep neural network by combining gene ontology knowledge to extract single-cell RNA-seq data characteristics, and reconstructing single-cell RNA-seq data through zero expansion negative binomial distribution to reduce data noise; secondly, constructing a graph structure by utilizing a unified manifold approximation and projection technology, and mining topology structure information among data samples by adopting a graph neural network; combining the graph neural network and the deep neural network by adopting a double self-supervision strategy; and finally, realizing single-cell RNA-seq data clustering by minimizing a joint loss function of a deep neural network, a graph neural network and a double self-supervision three modules and a random Gaussian noise item. The invention adopts a self-supervision method in the field of non-supervision, and can effectively solve the problems of lack of topology structure information between learning data, poor biological interpretability and the like in the existing single-cell RNA-seq data clustering method.","['G06F18/23213', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G16B40/30']"
US12162170B2,Method and device for collaborative servo control of motion vision of robot in uncalibrated agricultural scene,"A device and method for collaborative servo control of motion vision of a robot in an uncalibrated agricultural scene is provided. The device includes a robot arm, a to-be-gripped target object, an image sensor and a control module. An end of a robot arm is provided with a mechanical gripper, and a to-be-gripped target object is within a grip range of the robot arm. A control module drives the mechanical gripper to grip the to-be-gripped target object, and controls an image sensor to perform image sampling on a process of gripping the to-be-gripped target object by the robot arm. The image sensor sends sampled image data to the control module. The device does not need to perform precise spatial calibration on the to-be-gripped target object and the related environment in the scene. The robot arm is guided to complete the gripping task according to trained networks.","['G06T7/73', 'A01B63/002', 'B25J13/08', 'B25J13/087', 'B25J15/0253', 'B25J15/08', 'B25J9/1605', 'B25J9/161', 'B25J9/1612', 'B25J9/163', 'B25J9/1661', 'B25J9/1697', 'G05B19/4155', 'G06T7/70', 'A01M7/0089', 'G05B2219/40269', 'G06T2207/20081', 'G06T2207/20084']"
US11871901B2,Method for situational awareness for surgical network or surgical network connected device capable of adjusting function based on a sensed situation or usage,"A computer-implemented method for contextually controlling a surgical device is disclosed. The method includes receiving, by a computer system, perioperative data from the surgical device, the perioperative data associated with a surgical procedure; receiving, by the computer system, images from a scope, the images visualizing the surgical device during the surgical procedure; determining, by the computer system, an attribute of the surgical device from the images; determining, by the computer system, procedural context data based at least on the perioperative data and the attribute of the surgical device; and controlling, by the computer system, the surgical device according to the procedural context data.","['A61B1/00006', 'A61B1/000094', 'A61B1/000096', 'A61B1/00042', 'A61B1/0052', 'A61B1/051', 'A61B1/0661', 'A61B1/0684', 'A61B18/00', 'A61B18/1445', 'A61B34/25', 'A61B34/37', 'A61B5/0071', 'A61B90/361', 'G16H20/40', 'G16H40/20', 'G16H40/60', 'G16H40/67', 'A61B17/068', 'A61B2017/00022', 'A61B2017/00044', 'A61B2017/00061', 'A61B2017/00106', 'A61B2017/00119', 'A61B2017/00442', 'A61B2034/254', 'A61B2090/061', 'A61B2090/365', 'A61B2218/008', 'A61B2505/05', 'A61B5/0035', 'A61B5/02042', 'A61B5/021', 'A61B5/026', 'A61B5/318', 'A61B5/4821', 'A61B5/7264', 'G06F18/24143', 'G06T2207/10068', 'G06T7/20', 'G06T7/70', 'G06V2201/03', 'G06V2201/034']"
CN115427898B,"Monitoring, simulation, and control of biological processes","Methods for monitoring, controlling, and simulating biological processes including cell cultures in bioreactors are provided. The method includes obtaining values of one or more process conditions of a biological process at one or more maturity and determining a rate of unit transport of one or more metabolites in a cell culture using the obtained values as input to a machine learning model trained to predict the rate of unit transport of one or more metabolites at a latest maturity or later maturity of the one or more maturity based at least in part on the values of the one or more process conditions of the biological process at the one or more maturity. The method further includes predicting one or more characteristics of the biological process based at least in part on the determined rate of transport per unit. Systems, computer-readable media, and methods for providing tools to implement these methods are also provided.","['G16B40/00', 'C12Q3/00', 'C12M41/30', 'C12M41/38', 'C12M41/48', 'G05B13/048']"
US9710729B2,Domain adaptation for image classification with class priors,"In camera-based object labeling, boost classifier ƒT(x)=Σr=1 Mβrhr(x) is trained to classify an image represented by feature vector x using a target domain training set DT of labeled feature vectors representing images acquired by the same camera and a plurality of source domain training sets DS 1 , . . . , DS N acquired by other cameras. The training applies an adaptive boosting (AdaBoost) algorithm to generate base classifiers hr(x) and weights βr. The rth iteration of the AdaBoost algorithm trains candidate base classifiers hr k(x) each trained on a training set DT∪DS k , and selects hr(x) from previously trained candidate base classifiers. The target domain training set DT may be expanded based on a prior estimate of the labels distribution for the target domain. The object labeling system may be a vehicle identification system, a machine vision article inspection system, or so forth.","['G06K9/6259', 'G06V10/774', 'G06F18/21', 'G06F18/214', 'G06F18/2148', 'G06F18/2155', 'G06F18/24', 'G06F18/2413', 'G06F18/25', 'G06K9/00624', 'G06K9/00771', 'G06K9/00785', 'G06K9/46', 'G06K9/62', 'G06K9/6217', 'G06K9/6256', 'G06K9/6257', 'G06K9/6267', 'G06K9/627', 'G06K9/6288', 'G06V20/52', 'G06V20/54']"
US20230186601A1,Model-based machine-learning and inferencing,"Apparatus having model-based machine learning and inferencing logic for controlling object transfer, comprises: an image input component to receive image data derived from a captured image of an object; a captured image classifier to 5 generate a first classification of the object by activating a trained model to analyse the image data; an input component to receive an object identifier for the object; an object identification classifier to generate a second classification of the object according to the object identifier; matching logic to detect failure to reconcile the first and second classification; heuristic logic responsive to the matching logic to 10 determine a causal factor in the failure; and training logic, operable when the heuristic logic determines that a causal factor in the failure to reconcile is a deficient first classification, to provide model training input comprising the image data and the object identifier to the model-based machine learning logic.","['G06N3/08', 'G06F16/5866', 'G06F18/214', 'G06F18/256', 'G06K7/1447', 'G06N20/00', 'G06Q20/20', 'G06Q20/208', 'G06Q30/00', 'G06Q30/06', 'G06Q40/00', 'G06V10/764', 'G06V20/52', 'G06V30/194', 'G07G1/0063', 'G06F18/24', 'G06V20/625', 'G06V2201/09', 'G06V2201/10']"
EP3929853A1,Systems and methods for feature engineering based on graph learning,"In one embodiment, a computing system may receive query information associated with a machine-learning model. The system may access a knowledge graph that defines relationships between a number of machine-learning models and a number of features of the machine-learning models. The system may determine, based on the knowledge graph and the query information, one or more correlation metrics indicating correlations between the machine-learning model and one or more features of the features in the knowledge graph. The system may determine one or more recommended features for the machine-learning model based on the one or more correlation metrics and the one or more features.","['G06N20/20', 'G06N20/00', 'G06Q30/0631', 'G06F16/9024', 'G06F16/903', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06N3/096', 'G06N5/02', 'G06N5/022', 'G06N5/04', 'G06Q30/0241', 'G06Q30/0282', 'G06Q50/01', 'G06N5/01']"
US12023149B2,Sensing system and method for monitoring time-dependent processes,"Systems and methods for detecting the quality of signals captured by a sensor device monitoring a biological function. Sensor data associated with the sensor device is received, the sensor data representing time-series measurement samples of one or more parameters associated with the biological function, the sensor data including usable and unusable samples of the time-series measurements. Data representing two or more features of samples of the time-series measurements is extracted and filtered to reduce outliers in the extracted data based on an expected outlier ratio. A machine learning algorithm is then trained to identify events based on the filtered extracted data.","['A61B5/113', 'A61B5/7221', 'A61B5/7225', 'A61B5/7267', 'A61B5/7282', 'G16H20/10', 'G16H50/20', 'G16H50/30']"
US11798529B2,Generation of optimized knowledge-based language model through knowledge graph multi-alignment,"A language module is joint trained with a knowledge module for natural language understanding by aligning a first knowledge graph with a second knowledge graph. The knowledge module is trained on the aligned knowledge graphs. Then, the knowledge module is integrated with the language module to generate an integrated knowledge-language module.","['G10L15/063', 'G10L13/086', 'G06F18/2155', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/022', 'G10L13/033', 'G10L13/047', 'G10L15/1815', 'G10L15/16']"
US11593560B2,System and method for relation extraction with adaptive thresholding and localized context pooling,"System and method for relation extraction using adaptive thresholding and localized context pooling (ATLOP). The system includes a computing device, the computing device has a processer and a storage device storing computer executable code. The computer executable code is configured to provide a document; embed entities in the document into embedding vectors; and predict relations between a pair of entities in the document using their embedding vectors. The relation prediction is performed based on an improved language model. Each relation has an adaptive threshold, and the relation between the pair of entities is determined to exist when a logit of the relation between the pair of entities is greater than a logit function of the corresponding adaptive threshold.","['G06F40/284', 'G06F40/295', 'G06F16/316', 'G06F16/3344', 'G06F16/3347', 'G06F16/35', 'G06F16/93', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06N3/09', 'G06N5/022', 'G06Q10/10', 'G16H70/60']"
CN108898044B,"Loading rate obtaining method, device and system and storage medium","The application discloses a method, a device and a system for acquiring a loading rate and a storage medium. The method comprises the following steps: the method comprises the following steps: acquiring a video frame at a first moment, wherein the video frame comprises a first left view and a first right view of a target area, the target area is a compartment area after a vehicle carries cargo, and the first moment is a moment corresponding to a first trigger state; computing a depth map based on the first left view and the first right view, wherein the depth map comprises a plurality of depth values; extracting a first region of interest from the first left view or the first right view, wherein the first region of interest is a target region; determining a subset of depth values from the depth map corresponding to the edge of the first region of interest; the loading rate of the vehicle is calculated based on the subset. According to the technical scheme of the embodiment of the application, manual intervention is not needed, the human resources are saved, and meanwhile the efficiency of obtaining the vehicle-mounted rate is improved.","['G06V20/584', 'G06V20/46', 'G06V2201/08']"
US10671511B2,Automated bug fixing,"Disclosed is a system for removing bugs present in a software code. A determination module determines a usage pattern of a software code by using an Artificial Neural Network (ANN) technique. A comparison module compares the usage pattern with a set of pre-stored usage patterns of software applications similar to the software code. An execution module executes a set of test suites, on the software code, associated to at least one software application of the software applications, when a usage pattern of the at least one software application is matched with the usage pattern of the software code. An identification module identifies a code snippet comprising the bug. A recommendation module recommends a code patch, corresponding to the code snippet, from a ranked list of code patches determined by a Deep RNN technique. Further, a replacement module replaces the code snippet with the code patch thereby removing the bug.","['G06F11/3636', 'G06F11/3612', 'G06F11/3688', 'G06F8/65', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/096']"
US11900665B2,"Graphics neural network processor, method, and system","A graphics processor can include a processing cluster array including a plurality of processing clusters coupled with the plurality of memory controllers, each processing cluster of the plurality of processing clusters including a plurality of streaming multiprocessors, the processing cluster array configured for partitioning into a plurality of partitions. The plurality of partitions include a first partition including a first plurality of streaming multiprocessors configured to perform operations for a first neural network, The operations for the first neural network are isolated to the first partition. The plurality of partitions also include a second partition including a second plurality of streaming multiprocessors configured to perform operations for a second neural network. The operations for the second neural network are isolated to the second partition and protected from operations performed for the first neural network.","['G06V40/161', 'G06F16/5838', 'G06F16/784', 'G06F18/24143', 'G06V10/764', 'G06V10/82', 'G06V10/955', 'G06V40/10', 'G06V40/103', 'G06V40/23']"
US20230316003A1,Natural Language Processing for Identifying Bias in a Span of Text,"A computing machine accesses text from a record. The computing machine identifies, using a natural language processing engine, an entity mapped to a first span of the text. The first span includes a contiguous sequence of one or more words or subwords in the text. The computing machine determines a bias category for the entity. The bias category is selected from a predefined list of bias categories. The determined bias category for the entity depends on a second span of the text. The second span includes a contiguous sequence of one or more words or subwords in the text. The second span is different from the first span.","['G06F40/279', 'G06F40/40', 'G06F40/166', 'G06F40/284', 'G06F40/30', 'G06F40/58', 'G06N3/0442', 'G06N3/045', 'G06N3/06', 'G06N3/08', 'G06N5/022', 'G06F40/205', 'G06N3/0464', 'G06N3/048']"
US11066917B2,Earth-boring tool rate of penetration and wear prediction system and related methods,"An earth-boring tool system that includes a drilling assembly for drilling a wellbore and a surface control unit. The surface control unit includes a prediction system that is configured to train a hybrid physics and machine-learning model based on input data, provide, via the hybrid model, a predictive model representing a rate of penetration of an earth-boring tool and wear of the earth-boring tool during a planned drilling operation, provide one or more recommendations of drilling parameters based on the predictive model, utilize the one or more recommendations in a drilling operation, receive real-time data from the drilling operation, retrain the hybrid model based on a combination of the input data and the real-time data, and provide, via the retrained model, an updated predictive model of a rate of penetration of an earth-boring tool and wear of the earth-boring tool during a remainder of the planned drilling operation.","['E21B44/02', 'E21B21/08', 'E21B44/005', 'E21B45/00', 'E21B47/26', 'E21B49/003', 'E21B2200/20', 'E21B2200/22']"
US10769532B2,Network rating prediction engine,"A rating prediction engine builds and applies models to predict ratings based on an analysis of textual reviews and comments. The engine can build multiple models simultaneously through distributed parallel model building that employs deep convolutional neural networks (CNNs). The engine can also incorporate user moment feature data, including user status and context information, to provide better performance and more accurate predictions. The engine can also employ heuristic unsupervised pre-training and/or adaptive over-fitting reduction for model building. In some instances, the techniques described herein can be used in a service to predict personalized ratings for reviews or other published items, in instances where the original author of the item did not include a rating and/or in instances where the publication channel does not provide a mechanism to enter ratings.","['G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06N3/0985', 'G06F40/30']"
WO2021218238A1,Image processing method and image processing apparatus,"Embodiments of the present application relate to computer image processing technology in the field of artificial intelligence. Disclosed is an image processing method, which is applied to the naked eye recognition of a face image or the recognition of a face recognition system. By reconstructing an unblocked front face image, the success rate of face recognition is improved. The method comprises: an image processing apparatus obtains the face features of a face image and the position information of key points; the image processing apparatus obtains, by means of a first neural network model, an unblocked front face image corresponding to the face image according to the face features and the position information of the key points.","['G06F18/241', 'G06N3/04', 'G06N3/045', 'G06N3/08']"
US10902705B1,"Biometric authentication, decentralized learning framework, and adaptive security protocols in distributed terminal network","Biometric authentication, decentralized learning frameworks, and adaptive security protocols and services for a distributed operator terminals network are described. In some embodiments, the terminals may be hardware terminals, kiosks, or clients. In some embodiments, a security analysis may be performed, and security scores may be determined, for visitors requesting operations at terminals. Security scores may be determined by a vendor, in communication with the operator terminals, based on aggregation of a plurality of factors, wherein each factor may be weighted. The factors may incorporate operator settings or preferences. In one embodiment, the factors include one or more facial recognition factors. The one or more facial recognition factors may be used for biometric authentication. The vendor may use the security scores to determine user privileges or permissions for the operations. The vendor may deliver instructions or messages to the terminals based on the determinations.","['H04L63/0272', 'G06F21/31', 'G06F21/602', 'G06F21/606', 'G06F21/6209', 'G06Q20/065', 'G06Q20/1085', 'G06Q20/18', 'G06Q20/36', 'G06Q20/4014', 'G06Q20/40145', 'G06Q20/4016', 'G07F19/206', 'H04L63/0428', 'H04L63/0823', 'H04L63/0861', 'H04L63/168', 'H04L67/02', 'H04W12/72', 'G06Q2220/00']"
CN112820361B,A drug molecule generation method based on adversarial imitation learning,"The invention discloses a drug molecule generation method based on anti-imitation learning, which generates drug molecules based on anti-imitation learning and multi-task reinforcement learning and comprises the following steps: constructing an effective drug molecule library; an improved drug molecule generation model is created, comprising: designing and realizing a multitasking reinforcement learning module and designing and realizing an antagonism imitation learning module; model pre-training; executing a drug molecule generation flow; candidate drug molecule results are generated. By adopting the technical scheme provided by the invention, the optimization of the biochemical property of the drug molecules can be effectively promoted, the stability of model training is improved, and better drug molecules are obtained.","['G16C20/70', 'G16C20/50']"
US11176381B2,Video object segmentation by reference-guided mask propagation,"Various embodiments describe video object segmentation using a neural network and the training of the neural network. The neural network both detects a target object in the current frame based on a reference frame and a reference mask that define the target object and propagates the segmentation mask of the target object for a previous frame to the current frame to generate a segmentation mask for the current frame. In some embodiments, the neural network is pre-trained using synthetically generated static training images and is then fine-tuned using training videos.","['G06V10/25', 'G06K9/00765', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06K9/627', 'G06T7/155', 'G06T9/002', 'G06V10/774', 'G06V10/82', 'G06V20/49', 'G06K2209/21', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/07']"
US10346726B2,"Image recognition method and apparatus, image verification method and apparatus, learning method and apparatus to recognize image, and learning method and apparatus to verify image","A method of recognizing a feature of an image may include receiving an input image including an object; extracting first feature information using a first layer of a neural network, the first feature information indicating a first feature corresponding to the input image among a plurality of first features; extracting second feature information using a second layer of the neural network, the second feature information indicating a second feature among a plurality of second features, the indicated second feature corresponding to the first feature information; and recognizing an element corresponding to the object based on the first feature information and the second feature information.","['G06V10/82', 'G06K9/66', 'G06F18/2413', 'G06K9/00624', 'G06K9/4604', 'G06K9/4628', 'G06K9/48', 'G06K9/6202', 'G06K9/627', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06K9/00275', 'G06K9/00288', 'G06N3/084', 'G06V40/169', 'G06V40/172']"
US11501191B2,Recommending machine learning models and source codes for input datasets,Asset recommendation for a particular input dataset is provided. Candidate data analysis assets having a corresponding relatedness score associated with the particular input dataset greater than a defined relatedness score threshold value are selected. Those candidate data analysis assets having a corresponding relatedness score greater than the defined relatedness score threshold value are ranked by score. Those candidate data analysis assets having a corresponding relatedness score greater than the defined relatedness score threshold value are listed by rank from highest to lowest. A justification for each candidate data analysis asset is inserted in the ranked list of candidate data analysis assets. The ranked list of candidate data analysis assets along with each respective justification is outputted on a display device.,"['G06N20/20', 'G06F16/211', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N5/045', 'G06Q30/0201']"
US11093805B2,"Image recognition method and apparatus, image verification method and apparatus, learning method and apparatus to recognize image, and learning method and apparatus to verify image","A method of recognizing a feature of an image may include receiving an input image including an object; extracting first feature information using a first layer of a neural network, the first feature information indicating a first feature corresponding to the input image among a plurality of first features; extracting second feature information using a second layer of the neural network, the second feature information indicating a second feature among a plurality of second features, the indicated second feature corresponding to the first feature information; and recognizing an element corresponding to the object based on the first feature information and the second feature information.","['G06K9/66', 'G06N3/084', 'G06F18/2413', 'G06K9/00624', 'G06K9/4604', 'G06K9/4628', 'G06K9/48', 'G06K9/6202', 'G06K9/627', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06V10/454', 'G06V10/82', 'G06K9/00275', 'G06K9/00288', 'G06N3/048', 'G06V40/169', 'G06V40/172']"
US12167084B2,Methods and apparatus for playback using pre-processed information and personalization,"Methods, apparatus, systems and articles of manufacture are disclosed for playback using pre-processed profile information and personalization. Example apparatus disclosed herein include a synchronizer to, in response to receiving a media signal to be played on a playback device, access an equalization (EQ) profile corresponding to the media signal; an EQ personalization manager to generate a personalized EQ setting; and an EQ adjustment implementor to modify playback of the media signal on the playback device based on a blended equalization generation based on the EQ profile and the personalized EQ setting.","['G11B31/00', 'G06F3/165', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G10L25/30', 'G10L25/51', 'G11B20/10', 'H03G5/025', 'H03G5/165', 'H04N21/439', 'H04N21/44224', 'H04N21/4524', 'H04N21/4532', 'H04N21/462', 'H04N21/4667', 'H04N21/4852', 'H04N9/87', 'H04R3/04', 'H04R5/04', 'H03F3/181', 'H04R2430/01', 'H04R2499/11', 'H04R2499/13']"
CN110458663B,"Vehicle recommendation method, device, equipment and storage medium","The embodiment of the invention discloses a vehicle recommendation method, a vehicle recommendation device, vehicle recommendation equipment and a storage medium. The method comprises the following steps: acquiring a user characteristic vector of a current user, and determining a vehicle characteristic vector of a vehicle to be recommended; inputting the user characteristic vector and the vehicle characteristic vector into a pre-trained DDPG model as intelligent state vectors, and determining a behavior prediction score of an interactive behavior generated by a current user on the vehicle to be recommended according to an output result of the DDPG model; and sequencing the vehicles to be recommended according to the behavior prediction scores corresponding to the vehicles to be recommended, and recommending the vehicles to the current user based on the sequencing result. According to the technical scheme of the embodiment of the invention, the recommended content can be adjusted according to the feedback of the user in the vehicle recommending process, so that the matching degree of the recommended vehicle and the user is improved, and the use experience of the user is further improved.","['G06Q30/0631', 'G06Q30/0645', 'G06Q50/40']"
US11900396B2,Systems and methods for generating a relationship among a plurality of datasets to generate a desired attribute value,A system or method for identifying a plurality of entities in a first dataset that satisfy a predetermined target attribute by deploying on the first dataset a relationship model generated from a second dataset having a plurality of entities not in the first dataset.,"['G06Q30/0201', 'G06F16/288', 'G06N20/10', 'G06N20/20', 'G06N3/126', 'G06N5/01', 'G06N5/041', 'G06N5/048', 'G06N7/01', 'G06Q10/06315', 'G06N3/084']"
US10573003B2,Systems and methods for computational pathology using points-of-interest,"Systems, methods and devices for determination of disease class scores for patient tissue are disclosed. The disease class scores may be based on the probability or probability-like metric for a disease condition or outcome. The system includes an imaging apparatus and a computing system with instructions executable by a processor. The computer system may locate one or more points-of-interest on the pre-processed images of the patient tissue using a point-of-interest detector and generate one or more disease spatial maps including one or more probability or probability-like metric of disease classifications on the detected points-of-interest. The information in the disease spatial maps is aggregated to produce disease class scores.","['G06T7/0014', 'G06F18/24', 'G06F18/2415', 'G06F18/2431', 'G06K9/4671', 'G06K9/6267', 'G06K9/6277', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G06K2209/05', 'G06K2209/051', 'G06K2209/053', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N5/01', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G06V2201/03', 'G06V2201/031', 'G06V2201/032', 'G16H20/10']"
EP4244770A1,Architecture for explainable reinforcement learning,An exemplary embodiment may provide an explainable reinforcement learning system. Explanations may be incorporated into an exemplary reinforcement learning agent/model or a corresponding environmental model. The explanations may be incorporated into an agent's state and/or action space. An explainable Bellman equation may implement an explainable state and explainable action as part of an explainable reward function. An explainable reinforcement learning induction method may implement a dataset to provide a white-box model which mimics a black-box reinforcement learning system. An explainable generative adversarial imitation learning model may implement an explainable generative adversarial network to train the occupancy measure of a policy and may generate multiple levels of explanations. Explainable reinforcement learning may be implemented on a quantum computing system using an embodiment of an explainable Bellman equation.,"['G06N3/08', 'G06N20/00', 'G06N3/042', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G09B9/00', 'G06N3/045', 'G06N3/047', 'G06N7/01']"
US11380034B2,Semantically-consistent image style transfer,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for semantically-consistent image style transfer. One of the methods includes: receiving an input source domain image; processing the source domain image using one or more source domain low-level encoder neural network layers to generate a low-level representation; processing the low-level representation using one more high-level encoder neural network layers to generate an embedding of the input source domain image; processing the embedding using one or more high-level decoder neural network layers to generate a high-level feature representation of features of the input source domain image; and processing the high-level feature representation of the features of the input source domain image using one or more target domain low-level decoder neural network layers to generate an output target domain image that is from the target domain but that has similar semantics to the input source domain image.","['G06N3/088', 'G06F16/55', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0895', 'G06N3/094', 'G06T11/60']"
US10445609B1,Government ID card validation systems,"Systems and methods for pre-validating a digital image of an identification (ID) card (e.g., a government-issued passport, driver's license, etc.) are disclosed. A mobile computing device captures image(s) of an ID card. In response, a pre-validation system in communication with the mobile computing device analyzes one or more quality features of the image(s), which includes determining, utilizing a trained neural network (trained using a dataset including images that have been accepted by a post-validation platform and images that have been rejected by the post-validation platform) and based on the one or more quality features, whether at least a first image of the captured image(s) is usable by a remote post-validation process. Responsive to the determining that the at least a first image is usable, the mobile computing device transmits the first image to a remote server for post-validation of the identification card.","['G06N3/08', 'G06K9/3241', 'G06F18/214', 'G06F18/2178', 'G06F18/22', 'G06K9/6215', 'G06K9/6256', 'G06K9/6263', 'G06N3/0499', 'G06N3/09', 'G06Q50/265', 'G06V10/255', 'G06V10/40', 'G06V10/82']"
US12211262B2,Yarn quality control,"A textile package production system includes an imager, a transporter, a sorter, and a controller. The imager is configured to generate an optical image for a textile package. The imager has at least one optical detector and an optical emitter. The imager has an inspection region. The transporter has a test subject carrier configured for relative movement as to the carrier and the inspection region. The sorter is coupled to the transporter and is configured to make a selection as to a first classification and a second classification. The controller has a processor and a memory. The controller is coupled to the imager, the transporter, and the sorter. The controller is configured to implement an artificial engine classifier in which the sorter is controlled based on the optical image and based on instructions and training data in the memory.","['G06V10/993', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0004', 'G06V10/774', 'G06V10/82', 'G06V30/19147', 'G06T2207/20081', 'G06T2207/20084']"
US11373092B2,Training of artificial neural networks,"Methods are provided for training weights of an artificial neural network to be implemented by inference computing apparatus in which the trained weights are stored as programmed conductance states of respective predetermined memristive devices. Such a method includes deriving for the memristive devices a probability distribution indicating distribution of conductance errors for the devices in the programmed conductance states. The method further comprises, in a digital computing apparatus: training the weights via an iterative training process in which the weights are repeatedly updated in response to processing by the network of training data which is propagated over the network via the weights; and applying noise dependent on said probability distribution to weights used in the iterative training process.","['G11C11/54', 'G06N3/08', 'G06N3/0464', 'G06N3/0495', 'G06N3/065', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N7/005', 'G06N7/01', 'G11C13/0004', 'G11C13/0007', 'G11C13/0069']"
US20230131694A1,"Systems, methods, and apparatus for artificial intelligence and machine learning for a physical layer of communication system","An apparatus may include a receiver configured to receive a signal using a channel, a transmitter configured to transmit a representation of channel information relating to the channel, and at least one processor configured to determine a condition of the channel based on the signal, and generate the representation of the channel information based on the condition of the channel using a machine learning model. A method may include determining, at a wireless apparatus, physical layer information for the wireless apparatus, generating a representation of the physical layer information using a machine learning model, and transmitting, from the wireless apparatus, the representation of the physical layer information.","['G06N3/0455', 'G06N3/08', 'H04B7/0626', 'G06N20/00', 'G06N3/0495', 'G06N3/084', 'H04B7/0417', 'H04B7/0456', 'H04W24/08', 'G06N3/0442', 'G06N3/0464']"
CN109344840B,"Image processing method and apparatus, electronic device, storage medium, and program product","The embodiment of the application discloses an image processing method and device, electronic equipment, a storage medium and a program product, wherein the method comprises the following steps: performing feature extraction on an image to be processed to generate a feature map of the image; determining a feature weight corresponding to each feature point in a plurality of feature points included in the feature map; and respectively transmitting the feature information of the feature points corresponding to the feature weight to a plurality of other feature points included in the feature map to obtain the feature map with enhanced features. Based on the above embodiments of the present application, context information can be better used through information transmission between feature points, so that the feature map contains more information.","['G06V10/462', 'G06N3/08', 'G05D1/0231', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06T7/73', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/10', 'G06T2207/20084', 'G06T2207/30252']"
CN111709241B,Named entity identification method oriented to network security field,"The invention discloses a named entity identification method facing the field of network security. The method consists of two stages of model training and sample selection. The first stage is as follows: and (3) obtaining an initial character vector which contains semantic information and dynamically changes through the training of a pre-training language model ALBERT, sending the initial character vector into a Bi-LSTM + CRF network for training, and outputting a label sequence with the maximum probability of an input text sequence. And a second stage: based on the model obtained by the first-stage training, the network security text data with the marking value and the training value is selected to be marked manually and mechanically by adopting a mode of combining active learning and self-learning, and the model is iteratively trained after the network security text data with the marking value and the training value is added to the existing marked text data. The invention not only obviously improves the accuracy of network security entity identification, but also effectively relieves the problems of insufficient marking language material, high marking cost and the like in the field of network security.","['G06F40/295', 'G06F16/951', 'G06F40/117', 'G06F40/126', 'G06F40/216', 'G06F40/30', 'G06N3/045', 'G06N3/049']"
US11556796B2,Compressing weight updates for decoder-side neural networks,"A method, apparatus, and computer program product are provided for training a neural network or providing a pre-trained neural network with the weight-updates being compressible using at least a weight-update compression loss function and/or task loss function. The weight-update compression loss function can comprise a weight-update vector defined as a latest weight vector minus an initial weight vector before training. A pre-trained neural network can be compressed by pruning one or more small-valued weights. The training of the neural network can consider the compressibility of the neural network, for instance, using a compression loss function, such as a task loss and/or a weight-update compression loss. The compressed neural network can be applied within a decoding loop of an encoder side or in a post-processing stage, as well as at a decoder side.","['G06N3/082', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06T3/4046', 'G06T9/002', 'H04N19/103', 'H04N19/154', 'G06N3/063']"
US20230117143A1,Efficient learning and using of topologies of neural networks in machine learning,"A mechanism is described for facilitating learning and application of neural network topologies in machine learning at autonomous machines. A method of embodiments, as described herein, includes monitoring and detecting structure learning of neural networks relating to machine learning operations at a computing device having a processor, and generating a recursive generative model based on one or more topologies of one or more of the neural networks. The method may further include converting the generative model into a discriminative model.","['G06N3/08', 'G06N7/01', 'G06N3/044', 'G06N3/045', 'G06T1/20']"
CN112818676B,A joint extraction method of medical entity relationships,"The application discloses a medical entity relationship joint extraction method, and relates to an entity relationship extraction method. Comprising the following steps: creating a Chinese pre-training model ChineseMedBert for the medical field, and acquiring a training example; fine tuning the ChineseMedBert by using a training example, and acquiring word vector representation of a given medical text through the ChineseMedBert; acquiring a feature vector representation of the text according to the word vector representation of the text; obtaining enhanced semantic vector characterization of a text; predicting a tag sequence of the given medical text by utilizing the enhanced semantic vector representation of the text; and extracting the relation triples of the text according to the predicted tag sequence. The problem of error accumulation of the traditional assembly line method is solved, the problem that subtask interaction information is ignored by a joint extraction method based on parameter sharing and the problem of overlapping relations commonly existing in medical texts are solved, the fact triplet information of various overlapping relation types can be effectively extracted, and the accuracy of medical entity relation extraction is improved.","['G06F40/279', 'G06F40/284', 'G06N3/049', 'G06N3/08']"
WO2022160701A1,"Special effect generation method and apparatus, device, and storage medium","Disclosed are a special effect generation method and apparatus, a device and a storage medium, relating to the technical field of computer vision. Said method comprises: step 101, performing blur processing on a hair region in a target face image to obtain a blurred hair image; step 102, generating a texture image, a face mask and a hair mask according to the target face image; step 103, fusing the face mask and the hair mask to obtain a fused mask; step 104, fusing the blurred hair image and the texture image on the basis of a fusion coefficient determined according to the fused mask, to obtain a special effect image of the target face image.","['G06T3/04', 'G06N3/045', 'G06T5/50', 'G06T5/70', 'G06T7/90', 'G06V40/168', 'G06T2207/20221', 'G06T2207/30201']"
AU2022202698B2,Systems and methods for making a product,"DCC-2 /04/2022 ABSTRACT A method used in making a product, wherein a characteristic of the product is at least in part determined by values of parameters used in making the product, the method including the steps of: (a) applying a machine-based transfer learning process to prior result data, the application of the transfer learning process resulting in the generation of predictive data; (b) selecting one or more parameter values to be used in making the product based on the generated predictive data; (c) making the whole or a part of the product using the selected one or more parameter values.","['G06N3/08', 'G06Q50/04', 'G06F9/455', 'G06N3/047', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/02', 'G06N7/01', 'G06Q99/00', 'G05B2219/32015', 'G05B2219/32018', 'G16C20/00', 'G16C20/70', 'Y02P90/30']"
US12367249B2,Framework for optimization of machine learning architectures,"The present disclosure is related to framework for automatically and efficiently finding machine learning (ML) architectures that are optimized to one or more specified performance metrics and/or hardware platforms. This framework provides ML architectures that are applicable to specified ML domains and are optimized for specified hardware platforms in significantly less time than could be done manually and in less time than existing ML model searching techniques. Furthermore, a user interface is provided that allows a user to search for different ML architectures based on modified search parameters, such as different hardware platform aspects and/or performance metrics. Other embodiments may be described and/or claimed.","['G06N3/082', 'G06F16/953', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/086', 'G06N3/09', 'G06N3/0985', 'G06N3/044', 'G06N3/088', 'G06N3/092', 'G06N3/12', 'G06N5/027']"
CN115560983B,Rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions,"The invention provides a rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions, and relates to the technical field of rolling bearing fault diagnosis. The method comprises the technical key points of performing wavelet transformation on rolling bearing time domain vibration data to obtain a time-frequency spectrogram, taking priori labeled public data as a source domain and multi-user label-free island privacy data as a target domain, introducing a multi-representation feature extraction structure to improve an original residual error network, extracting multi-representation features of the source domain and the target domain to respectively construct a multi-user local model, improving a parameter transfer strategy in a federal migration learning framework by using a model compression idea of a deep neural network, enhancing the safety of the federal framework and reducing communication expenditure, and constructing a federal global model which can be used for fault diagnosis of the rolling bearing under different working conditions at a server side. The island data knowledge can be integrated without multi-user sharing data, and the island data knowledge integration method has higher accuracy and stronger generalization.","['G01M13/04', 'G01M13/045', 'G06N20/00']"
US11954572B2,Optimizing training data for image classification,"A method for machine learning-based classification may include training a machine learning model with a full training data set, the full training data set comprising a plurality of data points, to generate a first model state of the machine learning model, generating respective embeddings for the data points in the full training data set with the first model state of the machine learning model, applying a clustering algorithm to the respective embeddings to generate one or more clusters of the embeddings, identifying outlier embeddings from the one or more clusters of the embeddings, generating a reduced training data set comprising the full training data set less the data points associated with the outlier embeddings, training the machine learning model with the reduced training data set to a second model state, and applying the second model state to one or more data sets to classify the one or more data sets.","['G06N20/20', 'G06F18/2148', 'G06F18/2155', 'G06F18/217', 'G06F18/23', 'G06F18/23211', 'G06F18/2433', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/763', 'G06V10/764', 'G06V10/7747', 'G06V10/82', 'G06N5/01']"
RU2655661C2,Nonlinear system identification for object detection in wireless power transfer system,"FIELD: electrical engineering.SUBSTANCE: method of detecting whether a foreign object is near a transmit coil in a wireless power transfer system (WPTS) includes steps of: applying a pseudo-random signal to the transmit coil, while the pseudo-random signal is being applied to the transmit coil, recording one or more signals produced within the WPTS in response to the applied pseudo-random signal, by using the one or more recorded signals, generating model of system for electrical aspects of the WPTS. Method includes using the generated system model in combination with stored training data to determine whether an object having characteristics recognisable from the stored training data as characteristic of the foreign object is near the transmit coil.EFFECT: technical result is high efficiency and reliability of power transmission.26 cl, 21 dwg","['H02J7/007', 'H02J7/025', 'G01R19/2509', 'G01R23/02', 'G01R25/00', 'G01R31/001', 'H02J50/10', 'H02J50/12', 'H02J50/60', 'H02J50/80', 'H02J50/90', 'G06F30/00', 'Y02P90/02', 'Y02T10/70', 'Y02T10/7072', 'Y02T90/12', 'Y02T90/14']"
US12377290B2,Predictive maintenance of dynamic leaf guide based on deep learning,"Systems and methods for detecting and diagnosing faults in a radiotherapy system, such as a fault related to a dynamic leaf guide (DLG), are discussed. An exemplary predictive maintenance system includes a processor configured to receive machine data indicative of configuration and operation of a DLG in a target radiotherapy machine, apply a trained deep learning model to the received machine data, and detect and diagnose a DLG fault. The predictive maintenance system can train the deep learning model using data sequences constructed from the received machine data of the one more normal DLGs and the one or more faulty DLGs. Diagnosis of the DLG fault in the target radiotherapy machine includes classifying the DLG faults into different fault types or different fault severities.","['A61N5/1075', 'A61N5/1045', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/0985']"
US12181553B2,Deep learning techniques for magnetic resonance image reconstruction,"A magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a B0 magnet configured to provide a B0 field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; and a controller configured to: control the magnetics system to acquire MR spatial frequency data using non-Cartesian sampling; and generate an MR image from the acquired MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation.","['A61B5/055', 'G01R33/4824', 'G01R33/5608', 'G01R33/561', 'G01R33/5611', 'G06F17/141', 'G06F17/142', 'G06F17/18', 'G06F18/24143', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T11/006', 'G06T5/60', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'G06V10/768', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20084', 'G06T2210/41', 'G06V2201/03']"
RU2668710C1,Computing device and method for detecting malicious domain names in network traffic,"FIELD: information technology.SUBSTANCE: invention relates to devices, methods, and a machine-readable medium for domain name analysis. Device contains a communication module that provides a domain name from a source of domain names, analysis module that provides a domain name module from the communication module and analyzes each of the received domain names using a specified set of analysis techniques, ensuring that a given numerical value is assigned to each of a given set of domain name suspiciousness characteristics, corresponding to one of a given set of analysis techniques, for each analyzed domain name, depending on the results of its analysis using specified analysis techniques, processing module that provides the analysis module with signs of suspicion with the numerical values assigned to them for each domain name and analysis using a specified set of analysis techniques to ensure that each domain name is assigned to malicious domain names if the results of the analysis of suspiciousness characteristics are characteristic of malicious domain names.EFFECT: technical result is higher accuracy of detection of malicious domain names in network traffic.31 cl, 2 dwg","['G06F21/00', 'H04L63/0236', 'H04L63/1416', 'H04L65/00', 'H04L61/3025', 'H04L61/4511']"
US9533413B2,Trainable modular robotic apparatus and methods,"Apparatus and methods for a modular robotic device with artificial intelligence that is receptive to training controls. In one implementation, modular robotic device architecture may be used to provide all or most high cost components in an autonomy module that is separate from the robotic body. The autonomy module may comprise controller, power, actuators that may be connected to controllable elements of the robotic body. The controller may position limbs of the toy in a target position. A user may utilize haptic training approach in order to enable the robotic toy to perform target action(s). Modular configuration of the disclosure enables users to replace one toy body (e.g., the bear) with another (e.g., a giraffe) while using hardware provided by the autonomy module. Modular architecture may enable users to purchase a single AM for use with multiple robotic bodies, thereby reducing the overall cost of ownership.","['B25J9/163', 'A63H3/20', 'B25J13/08', 'B25J9/1694', 'G06N20/00', 'G06N3/008', 'G06N99/005', 'G06N3/049', 'Y10S901/02', 'Y10S901/04', 'Y10S901/09', 'Y10S901/50']"
US11334036B2,Power grid aware machine learning device,"A system and method for managing operation of electrical devices includes a control module that monitors status of multiple sources of electrical power to one or more electrical devices and electrical usage of the one or more electrical devices that receive electricity from the source of electrical power. The operation of the one or more electrical devices is managed using a machine learning model that forecasts status of the at least one source of electrical power and generates operational rules for the one or more electrical devices from historical values of control parameters of the one or more electrical devices, the status of the source of electrical power, and the electrical usage of the one or more electrical devices. The system may optimize renewable energy utilization, power grid stabilization, cost of electrical power usage, and the like.","['H02J3/004', 'G05B13/027', 'G05B13/048', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/096', 'G06Q50/06', 'H02J3/32', 'H02J2203/20', 'H02J3/008', 'Y02E60/00', 'Y04S10/50', 'Y04S40/20', 'Y04S50/10']"
US11448412B2,Air conditioner with an artificial intelligence,"Discussed is an air conditioner disposed in an indoor space. The air conditioner includes a sensor, a memory configured to store a plurality of learning results respectively corresponding to a plurality of members, and a processor configured to identify at least one member that is present in the indoor space among the plurality of members by using data acquired by the sensor, control operation of at least one of a compressor, a fan motor, or a vane motor based on the learning result corresponding to an identified member so as to adjust a set value including at least one of a set temperature, an air volume, or a wind direction, and update the learning results by using feedback on the adjusted set value.","['F24F11/62', 'F24F1/0007', 'F24F11/30', 'F24F11/46', 'F24F11/50', 'F24F11/63', 'F24F11/79', 'G06N3/045', 'G06N3/08', 'G06N3/092', 'F24F2013/205', 'F24F2110/10', 'F24F2120/00', 'F24F2120/12', 'F24F2120/20']"
US20240362286A1,Semantic search and summarization for electronic documents,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,"['G06F16/901', 'G06F16/93', 'G06F16/9538', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06N5/022']"
US20200272899A1,Systems and Methods for Deploying and Updating Neural Networks at the Edge of a Network,"Methods, devices and system for updating a neural network on an edge device that has low-bandwidth uplink capability include a centralized site/device that is configured to train and send the neural network to the edge device. In response, the centralized site/device may receive neural network information from the edge device that includes all or portions of a dataset, output activations, and/or overall inference result that is collected or generated in the edge device. The centralized site/device may use the received neural network information to update all or a part of the trained neural network, generate updated neural network information based on the updated neural network, and send the updated neural network information to the edge device.","['G06N3/08', 'G06F18/254', 'G06F18/285', 'G06F8/61', 'G06F8/658', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/082', 'G06N3/049']"
US11900052B2,Automatic generation of transformations of formatted templates using deep learning modeling,"The present disclosure applies trained artificial intelligence (AI) processing adapted to automatically generating transformations of formatted templates. Pre-existing formatted templates (e.g., slide-based presentation templates) are leveraged by the trained AI processing to automatically generate a plurality of high-quality template transformations. In transforming a formatted template, the trained AI processing not only generates feature transformation of objects thereof but may also provide style transformations where attributes associated with a presentation theme may be modified for a formatted template or set of formatted templates. The trained AI processing is novel in that it is tailored for analysis of feature data of a specific type of formatted template. The trained AI processing converts a formatted template into a feature vector and utilizes conditioned generative modeling to generate one or more transformed templates using a representation of the feature data and feature data from one or more other formatted templates.","['G06F16/4393', 'G06F40/186', 'G06F40/103', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06V10/40', 'G06N3/042', 'G06N3/08', 'G06N5/047']"
US11120353B2,Efficient driver action prediction system based on temporal fusion of sensor data using deep (bidirectional) recurrent neural network,"By way of example, the technology disclosed by this document may be implemented in a method that includes receiving stored sensor data describing characteristics of a vehicle in motion at a past time and extracting features for prediction and features for recognition from the stored sensor data. The features for prediction may be input into a prediction network, which may generate a predicted label for a past driver action based on the features for prediction. The features for recognition may be input into a recognition network, which may generate a recognized label for the past driver action based on the features for recognition. In some instances, the method may include training prediction network weights of the prediction network using the recognized label and the predicted label.","['G06N7/01', 'G06N7/005', 'B60W40/09', 'B60W50/0097', 'G01C21/26', 'G01C21/32', 'G01C21/3848', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'B60W2050/0029', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2420/54', 'B60W2556/10', 'B60W2556/55', 'B60W2556/65']"
US20200372154A1,Blockchain security,"A method and apparatus utilize a peer-to-peer network of security nodes collectively adhering to a protocol for inter-node communication. The system is comprised a plurality of first security nodes, at least one second security node, and at least one third security node. The plurality of first security nodes receive at least one of pre-trained detection models and rules, monitor at least one of a blockchain and connected devices for malicious behavior based on the received at least one of pre-trained detection models and rules, and report the malicious behavior. The at least one second security node creates and communicates the at least one of pre-trained detection models and rules to the plurality of first security nodes. The at least one third security node is informed by the at least one second security node of the reported malicious behavior.","['H04L41/145', 'G06F16/1824', 'G06F16/1834', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06N20/00', 'H04L41/0681', 'H04L43/065', 'H04L63/1408', 'H04L63/1433', 'G06N3/045', 'G06N3/08', 'G06N5/022', 'H04L41/16']"
US12299050B2,"Multi-model, multi-task trained neural network for analyzing unstructured and semi-structured electronic documents","Embodiments of the invention describe a computer-implemented method of analyzing an electronic version of a document. The computer-implemented method can include an architecture of machine learning sub-models that performs the global task of translating unstructured and semi-structured inputs into numerical representations that can be recognized and manipulated by a content-analysis (CA) sub-model without relying on brute force analysis. Embodiments of the invention achieve these results by separating the global task into auxiliary tasks and assigning each sub-model to at least one of the auxiliary tasks. The auxiliary tasks can include parsing the unstructured or semi-structured inputs into format types (e.g., lists, tables, figures, text, etc. of a PDF document), extracting features of the parsed document, and performing a computer-based CA on the extracted features. The sub-models are trained in stages and in groups, wherein both the stages and the groupings are based on the complexity of the sub-model's assigned task.","['G06F16/93', 'G06F16/35', 'G06F40/103', 'G06F40/177', 'G06F40/205', 'G06F40/216', 'G06F40/30', 'G06F40/35', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N5/025', 'G06V10/82', 'G06V30/19173', 'G06V30/413', 'G06N20/00', 'G06N5/04', 'G06V30/10']"
US20230252224A1,Systems and methods for machine content generation,"Computerized systems and methods are disclosed to generate a document with a transformer by prompt-engineering the transformer with a title and a summary to generate a description of the document; displaying a set of claims and allowing user editing of the set of claims; receiving one or more figures; receiving a part list with a plurality of element names for each figure; generating an expanded description of each element name through prompt engineering based on prior text in the document; selecting one or more boilerplate texts for major sections of the document; and organizing the document with the title, a background, the summary, a brief description of the drawings, and a detailed description.","['G06F40/151', 'G06F3/0482', 'G06F3/04845', 'G06F40/166', 'G06F40/40', 'G06F40/56', 'G06Q10/10', 'G06Q50/184']"
WO2023029351A1,"Self-supervised learning-based method, apparatus and device for predicting properties of drug small molecules","A self-supervised learning-based method, apparatus and device for predicting the properties of drug small molecules, relating to the technical field of artificial intelligence. The method comprises: generating a molecular graph structure according to a chemical molecular structure of a target drug small molecule and determining, by using a target graph neural network model, a first feature vector corresponding to the molecular graph structure (101); extracting first molecular linear input specification data corresponding to the target drug small molecule and second molecular linear input specification data corresponding to a drug small molecule the chemical molecular structure of which is different from that of the target drug small molecule, and determining, by using a preset language model, a second feature vector corresponding to the first molecular linear input specification data and a third feature vector corresponding to the second molecular linear input specification data (102); adjusting model parameters of the target graph neural network model by using the first feature vector, the second feature vector, and the third feature vector so as to output, on the basis of the adjusted target graph neural network model, a target feature vector that corresponds to the target drug small molecule and that meets a preset feature constraint condition (103); and inputting the target feature vector into a trained property prediction model and determining a property prediction result of the target drug small molecule (104).","['G16C20/30', 'G06N3/04', 'G06N3/08', 'G16C20/20', 'G16C20/70']"
CN110852426B,Pre-training model integration acceleration method and device based on knowledge distillation,"The invention discloses a pre-training model integration acceleration method and a device based on knowledge distillation, wherein the device uses the method and comprises the steps of defining a teacher model group and a student model; inputting training data labeled with classification labels into a teacher model group and a student model for training, and outputting likelihood estimation probability values corresponding to each teacher model and likelihood estimation probability values of the student models; pooling likelihood estimation probability values output by the teacher model group, and outputting the pooled likelihood estimation probability values; measuring a difference value between the likelihood estimation probability value of the teacher model group after pooling and the likelihood estimation probability value of the student model; updating the parameters of the student models to finally obtain the student models with likelihood estimation probability values closest to the likelihood estimation probability values after the teacher model clustering; and (3) using the obtained feature extractor and feature encoder of the student model as a student pre-training model to predict data to be trained, and encoding the data into a data feature vector.","['G06N3/045', 'G06F18/2415', 'G06N3/044', 'G06N5/022', 'Y02D10/00']"
CN112823375B,"Image resynthesis using forward warping, gap discriminator, and coordinate-based repair","The present invention relates to image processing, and in particular to image re-synthesis for synthesizing new views of a person or object based on input images to address tasks such as predicting views of a person or object from new points of view and new poses. The technical result is to improve the accuracy of image re-synthesis based on at least one input image. An image resynthesis system, a system for training a gap-filling module to be used in an image resynthesis system, an image resynthesis method, a computer program product, and a computer readable medium are provided. The image resynthesis system includes a source image input module, a forward warping module configured to predict, for each source image pixel, a corresponding location in a target image, a forward warping module configured to predict a forward warping field aligned with the source image, and a gap filling module configured to fill in gaps created by application of the forward warping module. The image re-synthesis method comprises the steps of inputting a source image, predicting for each source image pixel a corresponding position in a target image, wherein a forward warping field aligned with the source image is predicted, predicting a binary mask of a gap generated from the forward warping, generating a texture image by predicting a pair of coordinates in the source image for each pixel in the texture image, filling the gap based on the binary mask of the gap, and mapping the complete texture back to a new pose using the backward warping.","['G06T3/18', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T15/04', 'G06T15/205', 'G06T5/60', 'G06T5/77', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11402496B2,Method and apparatus for enhancing semantic features of SAR image oriented small set of samples,"The present disclosure relates to a method for enhancing sematic features of SAR image oriented small set of samples, comprising: acquiring a sample set of an SAR target image, and performing transfer learning and training on the sample set to obtain a initialized deep neural network of an SAR target image, the sample set comprising an SAR target image and an SAR target virtual image; performing network optimization on the deep neural network by an activation function, and extracting features of the SAR target image by the optimized deep neural network to obtain a feature map; and mapping, by an auto-encoder, the feature map between a feature space and a semantic space to obtain a deep visual feature with an enhanced semantic feature.","['G01S13/9027', 'G01S13/9005', 'G01S7/417', 'G06F18/213', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V20/13', 'G01S13/9029']"
US12175348B2,Method and apparatus for managing vehicle's resource in autonomous driving system,"A method for managing a vehicle's resource includes: executing at least one application requiring a resource in a first mode, the at least one application associated with autonomous driving process of the vehicle, obtaining driving route information, obtaining, from a position data generation device disposed at the vehicle, location information providing a current location of the vehicle, predicting resource utilization expected to be required in the first mode by using the driving route information and the location information, and switching from the first mode executing the at least one application to a second mode, wherein the at least one application is executed in the second mode requiring less resources than being executed in the first mode based on the predicted resource utilization exceeding a first threshold.","['G06N3/02', 'G06N3/084', 'B60W30/14', 'B60W40/06', 'B60W40/072', 'B60W40/10', 'B60W50/0097', 'B60W50/082', 'G01C21/26', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'B60W2050/0005', 'B60W2050/0054', 'G01C21/3626', 'G06N3/044', 'G06N3/045']"
US11222138B2,Privacy-preserving machine learning in the three-server model,"Methods and systems according to embodiments of the invention provide for a framework for privacy-preserving machine learning which can be used to obtain solutions for training linear regression, logistic regression and neural network models. Embodiments of the invention are in a three-server model, wherein data owners secret-share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Embodiments of the invention provide for efficient conversions between arithmetic, binary, and Yao 3PC, as well as techniques for fixed-point multiplication and truncation of shared decimal values. Embodiments also provide customized protocols for evaluating polynomial piecewise functions and a three-party oblivious transfer protocol.","['G06N3/082', 'A63B21/023', 'A63B21/0435', 'A63B21/222', 'A63B69/34', 'A63B71/023', 'G06F21/6245', 'G06N20/00', 'G06N3/063', 'G06N3/084', 'A63B2071/0063', 'A63B2071/026', 'A63B21/0552', 'A63B21/0628', 'A63B2225/093', 'A63B2244/10']"
CN110473141B,"Image processing method, device, storage medium and electronic equipment","The embodiment of the application discloses an image processing method, an image processing device, a storage medium and electronic equipment, wherein the embodiment of the application acquires an image to be processed, and extracts first content characteristics of the image to be processed according to a coding network of a preset convolutional neural network model, wherein the convolutional neural network model comprises a coding network, a characteristic fusion layer and a decoding network, and structures of the coding network and the decoding network are mirror images; acquiring a first style characteristic; at the feature fusion layer, carrying out fusion processing on the first content features and the first style features to obtain first fusion features; and decoding the first fusion characteristic according to the decoding network to generate a first style migration image, so that the efficiency of image style migration is improved.","['G06N3/045', 'G06N3/08', 'G06T3/04', 'G06F18/241']"
US11263726B2,"Method, apparatus, and system for task driven approaches to super resolution","An approach is provided for generating a super-resolution image as a higher resolution version of an input image. The approach, for example, involves determining a set of tasks to be performed on the input image to facilitate generating the super-resolution image. The approach also involves selecting a combination of loss functions, wherein each loss function of the combination of loss functions is respectively a task-specific neural network pre-trained to perform a corresponding one of the set of tasks. The approach also involves training the super resolution neural network using the combination of loss functions as one or more layers of the super resolution neural network. The approach also involves using the trained super resolution neural network to generate the super-resolution image as a higher resolution version of the input image.","['G06T3/4053', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T3/4046', 'G06T5/003', 'G06T5/009', 'G06T5/73', 'G06T5/92', 'G06T7/73', 'G06T2207/20081', 'G06T2207/20084']"
US11398034B2,"Method and apparatus for training semantic segmentation model, computer device, and storage medium","A method and apparatus for training a semantic segmentation model, a computer device, and a storage medium are described herein. The method includes: constructing a training sample set; inputting the training sample set into a deep network model for training; inputting the training sample set into a weight transfer function for training to obtain a bounding box prediction mask parameter; and constructing a semantic segmentation model.","['G06V10/267', 'G06T7/11', 'G06F18/2113', 'G06F18/214', 'G06K9/623', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/061', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06T7/10', 'G06V10/26', 'G06V10/82', 'G06V30/19173', 'G06V30/274', 'G06T2207/20081', 'G06T2207/20084']"
US20200342359A1,Methods for Using Machine Learning and Mechanistic Models for Biological Feature Mapping with Multiparametric MRI,"Described here are systems and methods for generating and implementing a hybrid machine learning and mechanistic model to produce biological feature maps, or other measurements of biological features, based on an input of multiparametric magnetic resonance or other images. The hybrid model can include a combination of a machine learning model and a mechanistic model that takes as an input multiparametric MRI, or other imaging, data to generate biological feature maps (e.g., tumor cell density maps), or other measures or predictions of biological features (e.g., tumor cell density). The hybrid models have capabilities of learning individual-specific relationships between imaging features and biological features.","['G06N20/10', 'G06F18/2155', 'G06K9/6259', 'G06N5/022', 'G06N7/01', 'G06T7/0012', 'G16H30/40', 'G16H50/20', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/30016', 'G06T2207/30096', 'G16H20/40']"
EP4202768A1,Machine learning model training method and related device,"A machine learning model training method and a related device are provided, and relate to the artificial intelligence field. The method is applied to a first client, a plurality of clients are communicatively connected to a server, the server stores a plurality of modules, and the plurality of modules are configured to construct at least two machine learning models. The method includes: obtaining a first machine learning model, where at least one first machine learning model is selected based on a data feature of a first training data set stored in the first client; performing a training operation on the at least one first machine learning model by using the first data set, to obtain at least one trained first machine learning model; and sending at least one updated module to the server, where the updated module is used by the server to update weight parameters of the stored modules. Different neural networks are allocated to training data with different data features, so that personalized matching between the neural networks and the data features is implemented.","['G06N20/00', 'G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06N3/0985', 'G06V10/454', 'G06V10/74', 'G06V10/762', 'G06V10/764', 'G06V10/766', 'G06V10/82', 'G06V10/95', 'H04L67/34']"
US10949951B2,Patient-specific deep learning image denoising methods and systems,"Systems and methods for improved image denoising using a deep learning network model are disclosed. An example system includes an input data processor to process a first patient image of a first patient to add a first noise to the first patient image to form a noisy image input. The example system includes an image data denoiser to process the noisy image input using a first deep learning network to identify the first noise. The image data denoiser is to train the first deep learning network using the noisy image input. When the first deep learning network is trained to identify the first noise, the image data denoiser is to deploy the first deep learning network as a second deep learning network model to be applied to a second patient image of the first patient to identify a second noise in the second patient image.","['G06T5/002', 'G06T5/70', 'A61B5/0033', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06T11/008', 'G06T3/40', 'G06T5/60', 'G16H30/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2210/41']"
US11714972B2,Systems and methods for transferring stylistic expression in machine translation of sequence data,"Embodiments of the present disclosure are directed to a system, methods, and computer-readable media for facilitating stylistic expression transfers in machine translation of source sequence data. Using integrated loss functions for style transfer along with content preservation and/or cross entropy, source sequence data is processed by an autoencoder trained to reduce loss values across the loss functions at each time step encoded for the source sequence data. The target sequence data generated by the autoencoder therefore exhibits reduced loss values for the integrated loss functions at each time step, thereby improving content preservation and providing for stylistic expression transfer.","['G06F40/30', 'G06F40/58', 'G06F40/44', 'G06F40/47']"
US10217346B1,Presence detection with neural networks,"In a disclosed method, a computing device receiver, from a wireless receiver (RX), first data indicative of channel properties of a first communication link between the wireless receiver (RX) in a first device and a wireless transmitter (TX) in a second device. The first device and the second device are located in a building. The computing device further executes a neural network to process the first data to distinguish humans from stationary objects within the building and detect presence of the human in the building. The computing device transmits result data indicative of the presence to at least one of the first device or the second device.","['G08B21/22', 'G01S5/0269', 'G01S5/0278', 'G06N3/048', 'G06N3/0499', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G08B29/186', 'H04B17/318', 'G01S2205/02', 'G06N7/01', 'G08B13/00', 'H04M1/724', 'H04M1/72403', 'H04M1/72519', 'H04M1/72522', 'H04W4/02', 'H04W8/245']"
US20220092216A1,Privacy-preserving machine learning in the three-server model,"Methods and systems according to embodiments of the invention provide for a framework for privacy-preserving machine learning which can be used to obtain solutions for training linear regression, logistic regression and neural network models. Embodiments of the invention are in a three-server model, wherein data owners secret-share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Embodiments of the invention provide for efficient conversions between arithmetic, binary, and Yao 3PC, as well as techniques for fixed-point multiplication and truncation of shared decimal values. Embodiments also provide customized protocols for evaluating polynomial piecewise functions and a three-party oblivious transfer protocol.","['G06N3/084', 'G06F21/6245', 'G06N20/00', 'G06N3/063', 'H04L9/085', 'H04L2209/46']"
US12400296B2,Image super-resolution,"There is provided a solution for image processing. In this solution, first and second information is determined based on texture features of an input image and a reference image. The first information at least indicates for a first pixel block in the input image a second pixel block in the reference image most relevant to the first pixel block in terms of the texture features, and the second information at least indicates a relevance of the first pixel block to the second pixel block. A transferred feature map with a target resolution is determined based on the first information and the reference image. The input image is transformed into an output image with the target resolution based on the transferred feature map and the second information. The output image reflects a texture feature of the reference image.","['G06T3/4053', 'G06T3/4046', 'G06T7/40', 'G06N3/045', 'G06N3/08', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US12070859B2,Robot base position planning,"A method includes receiving sensor data representative of surfaces in a physical environment containing an interaction point for a robotic device and determining, based on the sensor data, a height map of the surfaces in the physical environment. The method also includes determining, by inputting the height map and the interaction point into a pre-trained model, one or more candidate positions for a base of the robotic device to allow a manipulator of the robotic device to reach the interaction point. The method additionally includes determining a collision-free trajectory to be followed by the manipulator of the robotic device to reach the interaction point when the base of the robotic device is positioned at a selected candidate position of the one or more candidate positions and, based on determining the collision-free trajectory, causing the base of the robotic device to move to the selected candidate position within the physical environment.","['B25J9/163', 'B25J9/162', 'G05D1/0088', 'G05D1/0246', 'G05D1/227', 'G05D1/249', 'G05B2219/39271', 'G05B2219/40298', 'G05B2219/40364']"
US12198432B2,Systems and methods for video and language pre-training,"Embodiments described a method of video-text pre-learning to effectively learn cross-modal representations from sparse video frames and text. Specifically, an align and prompt framework provides a video and language pre-training framework that encodes the frames and text independently using a transformer-based video encoder and a text encoder. A multi-modal encoder is then employed to capture cross-modal interaction between a plurality of video frames and a plurality of texts. The pre-training includes a prompting entity modeling that enables the model to capture fine-grained region-entity alignment.","['G06V20/41', 'G06F40/279', 'G06F40/284', 'G06V10/26', 'G06V10/761', 'G06V10/774', 'G06V10/776', 'G06V10/806', 'G06V20/46', 'G06V20/47', 'G06F40/30']"
CN111241279B,Natural language relation extraction method based on multi-task learning mechanism,"The invention discloses a natural language relation extraction method based on a multitask learning mechanism, which comprises the following steps: a plurality of auxiliary tasks are utilized to introduce mutually implicit information among different tasks to improve the effect of relation extraction. Knowledge distillation is introduced to enhance the effect of assisting tasks to guide and train the multitask model, and a teacher annealing algorithm is introduced for relation and extraction based on multitask learning, so that the effect of the multitask model can be used as a single task model for guiding tasks, and finally the accuracy of relation extraction is improved. The method includes the steps that firstly, a multi-task model for guiding training is obtained through training on different auxiliary tasks, then the model learned by the auxiliary tasks and a real label are used as supervision information to simultaneously guide the learning of the multi-task model, and finally evaluation is conducted on a SemEval2010 task-8 data set.","['G06F16/355', 'G06N3/045', 'G06N3/08']"
US11244450B2,Systems and methods utilizing artificial intelligence for placental assessment and examination,"Systems and methods for completing a morphological characterization of an image of a placenta and providing suggested pathological diagnoses are disclosed. A system includes programming instructions that, when executed, cause processing devices to execute commands according to the following logic modules: an Encoder module that receives the digital image of the placenta and outputs a pyramid of feature maps, a SegDecoder module that segments the pyramid of feature maps on a fetal side image and on a maternal side image, a Classification Subnet module that classifies the fetal side image and the maternal side image, and a convolutional IPDecoder module that localizes an umbilical cord insertion point of the placenta from the classified fetal side image and the classified maternal side image. The localized umbilical cord insertion point, segmentation maps for the classified fetal side and maternal side images are provided to an external device for determining the morphological characterization.","['G06T7/0012', 'G06F18/214', 'G06F18/2415', 'G06K9/6256', 'G06K9/6277', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/11', 'G06V10/44', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30024', 'G06V2201/03']"
US20230350775A1,"Optimization of Parameters of a System, Product, or Process","The present disclosure provides computing systems and associated methods for optimizing one or more adjustable parameters (e.g. operating parameters) of a system. In particular, the present disclosure provides a parameter optimization system that can perform one or more black-box optimization techniques to iteratively suggest new sets of parameter values for evaluation. The iterative suggestion and evaluation process can serve to optimize or otherwise improve the overall performance of the system, as evaluated by an objective function that evaluates one or more metrics. The present disclosure also provides a novel black-box optimization technique known as “Gradientless Descent” that is more clever and faster than random search yet retains most of random search's favorable qualities.","['G06F17/11', 'G06F11/3409', 'G06F11/3006', 'G06N20/00', 'G06N5/01', 'G06N7/01']"
AU2024202817B2,Machine Learning For Recognizing And Interpreting Embedded Information Card Content,"#$%^&*AU2024202817B220250703.pdf##### - 63 - MARKED-UP COPY MARKED-UP COPY MACHINE LEARNING FOR RECOGNIZING AND INTERPRETING EMBEDDED INFORMATION CARD CONTENT ABSTRACT OF THE DISCLOSURE Metadata for highlights of a video stream is extracted from card images embedded in the video stream. The highlights may be segments of a video stream, such as a broadcast of a sporting event, that are of particular interest to one or more users. Card images embedded in video frames of the video stream are identified and processed to extract text. The text characters may be recognized by applying a machine-learned model trained with a set of characters extracted from card images embedded in sports television programming contents. The training set of character vectors may be pre- processed to maximize metric distance between the training set members. The text may be interpreted to obtain the metadata. The metadata may be stored in association with the portion of the video stream. The metadata may provide information regarding the highlights, and may be presented concurrently with playback of the highlights. MACHINE LEARNING FOR RECOGNIZING AND INTERPRETING EMBEDDED INFORMATION CARD CONTENT ABSTRACT OF THE DISCLOSURE Metadata for highlights of a video stream is extracted from card images embedded in the video stream. The highlights may be segments of a video stream, such as a broadcast of a sporting event, that are of particular interest to one or more users. Card images embedded in video frames of the video stream are identified and processed to extract text. The text characters may be recognized by applying a machine-learned model trained with a set of characters extracted from card images embedded in sports television programming contents. The training set of character vectors may be pre- processed to maximize metric distance between the training set members. The text may be interpreted to obtain the metadata. The metadata may be stored in association with the portion of the video stream. The metadata may provide information regarding the highlights, and may be presented concurrently with playback of the highlights. - 63 20 24 20 28 17 30 A pr 2 02 4 M A C H I N E L E A R N I N G F O R R E C O G N I Z I N G A N D I N T E R P R E T I N G E M B E D D E D I N F O R M A T I O N C A R D C O N T E N T 2 0 2 4 2 0 2 8 1 7 3 0 A p r 2 0 2 4 A B S T R A C T O F T H E D I S C L O S U R E M e t a d a t a f o r h i g h l i g h t s o f a v i d e o s t r e a m i s e x t r a c t e d f r o m c a r d i m a g e s e m b e d d e d i n t h e v i d e o s t r e a m . T h e h i g h l i g h t s m a y b e s e g m e n t s o f a v i d e o s t r e a m , s u c h a s a b r o a d c a s t o f a s p o r t i n g e v e n t , t h a t a r e o f p a r t i c u l a r i n t e r e s t t o o n e o r m o r e u s e r s . C a r d i m a g e s e m b e d d e d i n v i d e o f r a m e s o f t h e v i d e o s t r e a m a r e i d e n t i f i e d a n d p r o c e s s e d t o e x t r a c t t e x t . T h e t e x t c h a r a c t e r s m a y b e r e c o g n i z e d b y a p p l y i n g a m a c h i n e - l e a r n e d m o d e l t r a i n e d w i t h a s e t o f c h a r a c t e r s e x t r a c t e d f r o m c a r d i m a g e s e m b e d d e d i n s p o r t s t e l e v i s i o n p r o g r a m m i n g c o n t e n t s . T h e t r a i n i n g s e t o f c h a r a c t e r v e c t o r s m a y b e p r e - p r o c e s s e d t o m a x i m i z e m e t r i c d i s t a n c e b e t w e e n t h e t r a i n i n g s e t m e m b e r s . T h e t e x t m a y b e i n t e r p r e t e d t o o b t a i n t h e m e t a d a t a . T h e m e t a d a t a m a y b e s t o r e d i n a s s o c i a t i o n w i t h t h e p o r t i o n o f t h e v i d e o s t r e a m . T h e m e t a d a t a m a y p r o v i d e i n f o r m a t i o n r e g a r d i n g t h e h i g h l i g h t s , a n d m a y b e p r e s e n t e d c o n c u r r e n t l y w i t h p l a y b a c k o f t h e h i g h l i g h t s . - 6 3 -","['H04N21/8549', 'G06F16/908', 'G06T7/12', 'G06V20/41', 'G06V20/42', 'G06V20/46', 'G06V20/48', 'G06V20/49', 'G06V20/635', 'G06V30/153', 'G06V40/20', 'G06V40/23', 'H04N21/23418', 'H04N21/234336', 'H04N21/251', 'H04N21/435', 'H04N21/44008', 'H04N21/458', 'H04N21/8133', 'H04N21/84', 'H04N21/845', 'G06T2207/20132', 'G06V20/44']"
US20230342609A1,Optimization of Parameter Values for Machine-Learned Models,"The present disclosure provides computing systems and associated methods for optimizing one or more adjustable parameters (e.g. operating parameters) of a system. In particular, the present disclosure provides a parameter optimization system that can perform one or more black-box optimization techniques to iteratively suggest new sets of parameter values for evaluation. The iterative suggestion and evaluation process can serve to optimize or otherwise improve the overall performance of the system, as evaluated by an objective function that evaluates one or more metrics. The present disclosure also provides a novel black-box optimization technique known as “Gradientless Descent” that is more clever and faster than random search yet retains most of random search's favorable qualities.","['G06N3/08', 'G06N20/00', 'G06N7/01']"
US11551284B2,Session-based recommendation method and device,"A session-based recommendation method and device according to one or more embodiments of this disclosure are provided, which use a pre-trained recommendation model to perform item recommend. The method includes following contents: a directed session graph is constructed according to a session to be predicted; the directed session graph is then input into a gated graph neural network which outputs the item embedding vector; a user's dynamic preference is determined according to a user's current preference and a first long-term preference, the current preference is an item embedding vector of a last item in the session and the first long-term preference is determined according to the item embedding vector and an importance score of the item; a prediction score of a respective item is determined according to the dynamic preference and the item embedding vector; and a recommended item is output according to the prediction score of the respective item.","['G06Q30/0202', 'G06Q30/0631', 'G06F16/3329', 'G06N3/0442', 'G06N3/047', 'G06N3/0472', 'G06N3/0895', 'G06N3/09', 'G06N5/022', 'G06N3/084']"
US9418674B2,Method and system for using vehicle sound information to enhance audio prompting,Sound related vehicle information representing one or more sounds may be received in a processor associated with a vehicle. The sound related vehicle information may or may not include an audio signal. An audio signal output to a passenger may be modified based on the sound related vehicle information.,"['G10L21/003', 'G10L15/20', 'G10L21/057', 'G10L13/04', 'G10L15/19', 'G10L15/22', 'G10L2021/03643']"
CN110837803B,Diabetic retinopathy grading method based on deep graph network,"The invention provides a diabetic retinopathy grading method based on a depth map network, which can effectively simulate the actual diagnosis process of an ophthalmologist on diabetic retinopathy and carry out information transmission and integration of diseased characteristics on a plurality of images of a single eye of a patient so as to obtain a more accurate diagnosis result, and is characterized by comprising the following steps: the method comprises the following steps that S1, preprocessing at least including image quality detection and left and right eye classification identification is carried out on a plurality of fundus images to be detected of two eyes of a patient, and a preprocessed fundus image is obtained; step S2, constructing logic diagram data according to a plurality of preprocessed eye fundus images corresponding to a single eye of a patient, wherein the logic diagram data comprises a full-connection diagram with the preprocessed eye fundus images as nodes; and S3, inputting the logic diagram data into a pre-trained diabetic retinopathy hierarchical model so as to obtain diabetic retinopathy hierarchical information of the patient.","['G06V40/193', 'G06N3/045', 'G06N3/084', 'G06V40/197', 'G16H30/40', 'G16H50/20']"
US20240267344A1,Chatbot for interactive platforms,"A chatbot system for filtering conversation content. A chatbot system receives, from a client system, a prompt of a user during an interactive session. The chatbot system filters the prompt of the user based on a set of platform policies and generates a response based on the filtering of the prompt of the user, and communicates the response to the client system.","['H04L51/02', 'H04L51/04', 'H04L51/212', 'H04L51/214']"
RU2724710C1,System and method of classifying objects of computer system,"FIELD: calculating; counting.SUBSTANCE: invention relates to computer engineering. Disclosed is a system for classifying objects of a computer system, which comprises a) a collection means for collecting data describing an object of a computer system (hereinafter, an object); b) a convolution generating means for generating, on the basis of the feature vector describing the state of the object collected by the object state data collection means; c) a similarity degree calculation means for calculating, on the basis of the feature vector generated by the convolution generating means, using a trained model for calculating similarity parameters representing a numerical value which characterizes the probability that the classified object can belong to a given class, and the maximum degree of difference, which is a numerical value, characterizing the probability that the classified object is guaranteed to be belonging to another given class; d) an analysis means designed to make a decision on whether an object belongs to a given class, in the case when data collected before the specified collection rule has been triggered satisfy the given criterion for determining the class formed on the basis of the degree of similarity calculated by the means of calculating degrees of similarity and the limiting degree of difference, wherein said criterion is the object classification rule according to the established relationship between the degree of similarity and the maximum degree of difference.EFFECT: technical result consists in improvement of accuracy of classification of objects of computer system due to use of two degrees of evaluation of belonging of objects of computer system to classes.26 cl, 12 dwg, 1 tbl","['G06F21/552', 'G06F18/00', 'G06F18/2148', 'G06F18/23', 'G06F18/2413', 'G06F18/2414', 'G06F18/24147', 'G06F18/2415', 'G06F21/56', 'G06F21/561', 'G06F21/562', 'G06F21/564', 'G06F21/566', 'G06N20/00', 'G06N3/045', 'G06N5/025', 'G06N20/10', 'G06N20/20', 'G06N5/01']"
US11903587B2,Adjustment to the surgical stapling control based on situational awareness,"A method of adjusting a staple parameter of a surgical stapling instrument is disclosed. The method includes determining, by a control circuit of the surgical stapling instrument, a first stroke length for a first staple driver of the surgical stapling instrument to drive a first row of staples of a circular stapling head assembly of the surgical stapling instrument; detecting, by the control circuit, a malformed staple in the first row of staples; adjusting, by the control circuit, the staple parameter, based on the detection of the malformed staple; and determining, by the control circuit, a second stroke length for a second staple driver of the surgical stapling instrument to drive a second row of staples of the circular stapling head assembly.","['A61B17/1155', 'A61B1/000096', 'A61B1/00045', 'A61B1/051', 'A61B1/0661', 'A61B17/0682', 'A61B17/072', 'A61B17/07207', 'A61B17/1114', 'A61B17/1285', 'A61B17/320092', 'A61B34/20', 'A61B34/32', 'A61B34/71', 'A61B5/0066', 'A61B5/0075', 'A61B5/0261', 'A61B6/5247', 'A61B90/35', 'A61B90/361', 'A61B90/98', 'A61M1/73', 'A61M1/79', 'B25J13/006', 'B25J9/1697', 'G16H10/60', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H70/20', 'H01Q1/22', 'H04L63/1416', 'H04L67/10', 'H04N5/272', 'H04N7/183', 'H05K1/028', 'H05K1/189', 'A61B18/1206', 'A61B18/1442', 'A61B18/1445', 'A61B2017/00017', 'A61B2017/00022', 'A61B2017/00026', 'A61B2017/0003', 'A61B2017/00039', 'A61B2017/00044', 'A61B2017/00057', 'A61B2017/00061', 'A61B2017/00075', 'A61B2017/00084', 'A61B2017/00097', 'A61B2017/00106', 'A61B2017/0011', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/00199', 'A61B2017/00203', 'A61B2017/00221', 'A61B2017/00398', 'A61B2017/00402', 'A61B2017/00442', 'A61B2017/00734', 'A61B2017/00809', 'A61B2017/00818', 'A61B2017/07235', 'A61B2017/07257', 'A61B2017/07264', 'A61B2017/07271', 'A61B2017/07278', 'A61B2017/07285', 'A61B2017/1132', 'A61B2017/32007', 'A61B2017/320074', 'A61B2017/320084', 'A61B2017/320095', 'A61B2017/320097', 'A61B2018/00541', 'A61B2018/00589', 'A61B2018/00595', 'A61B2018/00601', 'A61B2018/00607', 'A61B2018/0063', 'A61B2018/00642', 'A61B2018/00684', 'A61B2018/00791', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00988', 'A61B2018/00994', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/301', 'A61B2034/305', 'A61B2090/061', 'A61B2090/064', 'A61B2090/0808', 'A61B2090/309', 'A61B2217/005', 'A61B2217/007', 'A61B2218/002', 'A61B2218/007', 'A61B2218/008', 'A61B34/30', 'A61M1/80', 'A61M13/003', 'A61M16/00', 'A61M2205/3306', 'A61M2205/3313', 'A61M2205/3327', 'A61M2205/3331', 'A61M2205/3365', 'A61M2205/3368', 'A61M2230/005', 'A61M2230/04', 'A61M2230/30', 'G05B2219/40174', 'G05B2219/45119', 'G06K19/07749', 'G06K7/10316', 'G16H20/40', 'H04L67/12']"
CN114186563B,"Electronic device and semantic parsing method, medium and human-computer dialogue system thereof","The application relates to the technical field of man-machine conversation, in particular to electronic equipment, a semantic analysis method, a medium and a man-machine conversation system thereof, wherein the semantic analysis method comprises the steps of obtaining corpus data to be analyzed, calculating the intention correlation degree of words included in the corpus data to be analyzed and intention represented by the corpus data to be analyzed and the slot phase correlation degree of the words and slots represented by the corpus data to be analyzed, and predicting the slots of the corpus data to be analyzed based on semantic information of the words and the above semantic information of the words and the intention correlation degree and the slot phase correlation degree of the words. The method has the advantages that the plurality of intentions close to the real intentions of the user are identified from the user voice, and then the slot information is predicted by adopting the identified plurality of intentions, so that the slot filling accuracy is improved, the slot filling speed or efficiency is correspondingly improved, and the semantic analysis accuracy in man-machine conversation is further improved.","['G06F40/205', 'G06F40/295', 'G06F40/30', 'G10L15/26']"
US11691278B2,Hybrid computing achitectures with specialized processors to encode/decode latent representations for controlling dynamic mechanical systems,Provided is a robot that includes: a first sensor having a first output and configured to sense state of a robot or an environment of the robot; a first hardware machine-learning accelerator coupled to the first output of the first sensor and configured to transform information sensed by the first sensor into a first latent-space representation; a second sensor having a second output and configured to sense state of the robot or the environment of the robot; a second hardware machine-learning accelerator configured to transform information sensed by the second sensor into a second latent-space representation; and a processor configured to control the robot based on both the first latent-space representation and the second latent-space representation.,"['B25J9/163', 'B25J13/086', 'B25J9/161']"
CN110196967B,Sequence labeling method and device based on deep conversion architecture,"Methods and apparatus for language sequence labeling are described herein. The method for labeling the language sequence comprises the following steps: reading a first embedded representation of the language sequence, the first embedded representation of the language sequence comprising a character-level word embedded representation, a pre-training word embedded representation, and a global word embedded representation; performing a first depth transcoding on the first embedded representation of the read language sequence to obtain a set of hidden layer states; and decoding the set of hidden layer states to obtain a labeling result of the language sequence, wherein the global word embedded representation is a global context representation for the language sequence obtained through pre-encoding calculation.","['G06F40/289', 'G06F40/30', 'G06F40/151', 'G06F40/117', 'G06F40/126', 'G06F40/279', 'G06F40/295', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/049', 'G06N3/09', 'G06F40/58', 'G06N3/08']"
US11593683B2,Event model training using in situ data,"A method of identifying events within a wellbore comprises obtaining a first set of measurements of a first signal within a wellbore, identifying one or more events within the wellbore using the first set of measurements, obtaining a second set of measurements of a second signal within the wellbore, wherein the first signal and the second signal represent different physical measurements, training one or more event models using the second set of measurements and the identification of the one or more events as inputs, and using the one or more event models to identify at least one additional event within the wellbore.","['G06N5/04', 'E21B47/135', 'E21B41/00', 'E21B47/00', 'E21B47/10', 'G06N20/00', 'E21B2200/20', 'E21B2200/22']"
US12056906B2,Compression of machine learning models utilizing pseudo-labeled data training,"Embodiments are generally directed to compression in machine learning and deep learning processing. An embodiment of an apparatus for compression of untyped data includes a graphical processing unit (GPU) including a data compression pipeline, the data compression pipeline including a data port coupled with one or more shader cores, wherein the data port is to allow transfer of untyped data without format conversion, and a 3D compression/decompression unit to provide for compression of untyped data to be stored to a memory subsystem and decompression of untyped data from the memory subsystem.","['G06F12/08', 'G06T9/002', 'G06F12/023', 'G06T1/20', 'G06T15/005', 'G06F2212/302', 'G06F2212/401']"
WO2019128660A1,"Method and device for training neural network, image processing method and device and storage medium","Disclosed are a method and device for training a neural network, an image processing method and device and a storage medium. The neural network comprises a projection domain network for processing input projection data to obtain estimated projection data; a parsing and reconstruction network layer for obtaining a reconstructed image from the estimated projection data; an image domain network for processing the reconstructed image to obtain an estimated image; a projection layer for obtaining a projection result of the estimated image; and a statistical model layer for determining a statistical model-based consistency of the input projection date, the estimated projection data and the projection result of the estimated image. The neural network may further comprise a prior model layer. The method comprises: adjusting convolution kernel parameters of the image domain network and the projection domain network using a consistency cost function of a data model based on the input projection data, the estimated projection data and the projection result of the estimated image. By use of the described solution, the neural network obtained by training can reconstruct an image having higher quality when projection date has a defect.","['G06T11/006', 'A61B6/03', 'G01N23/04', 'G06N3/045', 'G06N3/084', 'G06T11/003', 'G06T11/005', 'G06T11/008', 'G06T2207/10081', 'G06T2207/20084', 'G06T2207/20088', 'G06T2211/416', 'G06T2211/421', 'G06T2211/436']"
WO2022022001A1,"Method for compressing style transfer network, and style transfer method, apparatus and system","Disclosed are a method for compressing a style transfer network, and a style transfer method, apparatus and system. The style transfer method comprises: after content feature maps corresponding to a content image and style feature maps corresponding to a style image are obtained, respectively sorting the content feature maps and the style feature maps channel by channel; acquiring order statistic information of the sorted content feature maps, and resorting the sorted style feature maps according to the order statistic information; and generating a style transfer image according to the content feature maps before sorting and the resorted style feature maps.","['G06T3/04', 'G06F18/214', 'G06N3/045', 'G06T9/00']"
CN112269901B,Fault distinguishing and reasoning method based on knowledge graph,"The invention provides a fault distinguishing and reasoning method based on a knowledge graph, which comprises the steps of obtaining equipment data, fault data and disposal scheme data; establishing an equipment map based on the equipment data, establishing a fault map based on the fault data, and establishing a disposal scheme map based on the disposal scheme data; performing map fusion, map completion and map inference on the equipment map, the fault map and the disposal scheme map based on an event extraction algorithm and a TranSE algorithm to obtain a knowledge map; carrying out fault discrimination reasoning by using a knowledge graph of a graph neural network; the method comprises the steps of establishing maps by utilizing a large amount of equipment data, historical fault data and disposal scheme data, fusing and complementing the maps, carrying out fault distinguishing and reasoning by utilizing a final knowledge map, and automatically providing methods for distinguishing, diagnosing and overhauling faults of the transformer.","['G06F16/83', 'G06F40/295', 'G06N3/044', 'G06N3/045', 'G06N5/04', 'G06Q10/20', 'G06Q50/06']"
US11431300B2,Machine learning based digital pre-distortion for power amplifiers,"Example embodiments relate to machine learning based digital pre-distortion for power amplifiers. A device may amplify a signal with a power amplifier and transmit the signal. The signal may be received by an internal feedback receiver of the device. The device may further comprise a first machine learning model configured to emulate an external feedback receiver and to generate an emulated feedback signal based on the internal feedback signal. The device may further comprise a second machine learning model configured to determine digital pre-distortion parameters for the power amplifier based on the emulated feedback signal. Apparatuses, methods, and computer programs are disclosed.","['H03F1/3247', 'H03F1/32', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'H03F3/19', 'H03F3/24', 'H03F3/245', 'H04B1/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H03F1/3258', 'H03F2200/451', 'H03F2201/3227', 'H03F2201/3231', 'H03F2201/3233', 'H04B2001/0425']"
US11356619B2,"Video synthesis method, model training method, device, and storage medium","Embodiments of this application disclose methods, systems, and devices for video synthesis. In one aspect, a method comprises obtaining a plurality of frames corresponding to source image information of a first to-be-synthesized video, each frame of the source image information. The method also comprises obtaining a plurality of frames corresponding to target image information of a second to-be-synthesized video. For each frame of the plurality of frames corresponding to the target image information of the second to-be-synthesized video, the method comprises fusing a respective source image from the first to-be-synthesized video, a corresponding source motion key point, and a respective target motion key point corresponding to the frame using a pre-trained video synthesis model, and generating a respective output image in accordance with the fusing. The method further comprises repeating the fusing and the generating steps for the second to-be-synthesized video to produce a synthesized video.","['H04N5/265', 'G06F18/25', 'G06F18/253', 'G06K9/6288', 'G06K9/629', 'G06V10/449', 'G06V10/806', 'G06V20/47', 'G09G5/377', 'G09G2340/10']"
US10062010B2,System for building a map and subsequent localization,"SLAM systems are provided that utilize an artificial neural network to both map environments and locate positions within the environments. In some example embodiments, a sensor arrangement is used to map an environment. The sensor arrangement acquires sensor data from the various sensors and associates the sensor data, or data derived from the sensor data, with spatial regions in the environment. The sensor data may include image data and inertial measurement data that effectively describes the visual appearance of a spatial region at a particular location and orientation. This diverse sensor data may be fused into camera poses. The map of the environment includes camera poses organized by spatial region within the environment. Further, in these examples, an artificial neural network is adapted to the features of the environment by a transfer learning process using image data associated with camera poses.","['G01C21/3833', 'G06K9/6256', 'G05D1/0246', 'G06F18/217', 'G06F18/24137', 'G06K9/4604', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T7/73', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V20/10', 'G06F18/23213', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
US20240210330A1,Systems and methods for artificial intelligence powered inspections and predictive analyses,A system to identify potential building and infrastructure issues by using artificial intelligence powered assessment and predictive analysis. The system employs big data from autonomous vehicles or robots coupled with visual and thermal cameras for autonomous inspections. The system may further inspect the operation status of the machineries based on their vibrations.,"['G01N21/95', 'G05B23/0283', 'G06T7/00', 'E01D22/00']"
US20220328064A1,Acoustic and natural language processing models for speech-based screening and monitoring of behavioral health conditions,The present disclosure provides acoustic and natural language processing (NLP) models for predicting whether a subject has a behavioral or mental health state of interest based at least in part on input speech from said subject.,"['G10L25/63', 'G10L25/30', 'A61B5/0077', 'A61B5/165', 'A61B5/4803', 'A61B5/7267', 'G10L15/26', 'G10L25/66', 'A61B2562/0204']"
US11587646B2,Method for simultaneous characterization and expansion of reference libraries for small molecule identification,"A variational autoencoder (VAE) has been developed to learn a continuous numerical, or latent, representation of molecular structure to expand reference libraries for small molecule identification. The VAE has been extended to include a chemical property decoder, trained as a multitask network, to shape the latent representation such that it assembles according to desired chemical properties. The approach is unique in its application to metabolomics and small molecule identification, focused on properties that are obtained from experimental measurements (m/z, CCS) paired with its training paradigm, which involves a cascade of transfer learning iterations. First, molecular representation is learned from a large dataset of structures with m/z labels. Next, in silico property values are used to continue training. Finally, the network is further refined by being trained with the experimental data. The trained network is used to predict chemical properties directly from structure and generate candidate structures with desired chemical properties. The network is extensible to other training data and molecular representations, and for use with other analytical platforms, for both chemical property and feature prediction as well as molecular structure generation.","['G06N3/088', 'G16C20/20', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G16C20/30', 'G16C20/60', 'G16C20/62', 'G16C20/70', 'G16C60/00', 'G06N20/10', 'G06N3/048', 'G06N7/01']"
WO2020220439A1,Highway traffic flow state recognition method based on deep neural network,"A highway traffic flow state recognition method based on a deep neural network, which relates to the technical field of intelligent traffic. The method comprises: classifying and defining a traffic flow state, carrying out noise reduction processing and feature extraction on an audio signal, carrying out modeling by means of a deep neural network (DNN) to obtain a deep neural network model for recognizing a highway traffic flow state, and pre-training the deep neural network model; then, tuning parameters of the deep neural network model; decoding a highway traffic flow state recognition model by means of a hidden Markov model (HMM); and finally, estimating an observation probability of the audio signal of different highway traffic flow states by means of the deep neural network model, and giving a recognition result of the highway traffic flow state according to the calculated probability. By means of the method, the problems of poor image analysis accuracy, a large amount of calculation for dynamic image analysis, etc. of monitoring traffic information using existing image analysis technology can be effectively solved.","['G06F18/241', 'G06F18/24147', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G08G1/0133', 'G08G1/065', 'G06F2218/06', 'G06F2218/08', 'G06F2218/12']"
US10783401B1,Black-box adversarial attacks on videos,"A method for generating black-box adversarial attacks on video recognition models is provided, comprising a) passing input video frames into a public image model, to obtain pixel-wise tentative perturbations; b) partitioning the tentative perturbations into tentative perturbation patches; c) estimating the rectification weight required for each patch, via querying the target video model; d) applying the patch-wise rectification weight on the patches, to obtain the rectified pixel-wise perturbations; e) applying one step projected gradient descent (PGD) perturbation on the input video, according to the rectified pixel-wise perturbations; and f) iteratively performing steps a)-e) until an attack succeeds or a query limit is reached. Systems and networks therefor are also provided.","['G06F16/73', 'G06K9/6257', 'G06F18/2148', 'G06F18/217', 'G06F18/2431', 'G06F21/577', 'G06K9/00765', 'G06K9/6262', 'G06K9/628', 'G06N20/00', 'G06N3/0442', 'G06N3/0464', 'G06N3/047', 'G06N3/086', 'G06N3/088', 'G06N7/005', 'G06N7/01', 'G06V10/764', 'G06V10/7747', 'G06V10/776', 'G06V10/82', 'G06V20/41', 'G06V20/49', 'G06F2221/034']"
US11961511B2,System and method for disambiguation and error resolution in call transcripts,"A system and method for detecting and resolving mis-transcriptions in a transcript generated by an automatic speech recognition system when transcribing spoken words. The system and method receive a machine language generated transcript of a speech signal by at least one of a first machine learning system and a second machine learning system, and analyze the machine language generated transcript to find a region of low confidence indicative of a mis-transcription and predict an improvement to the region of low confidence indicative of the mis-transcription. The system and method select a replacement word for the mis-transcription based on the predicted improvement to the region of low confidence and replace the mis-transcription by the replacement word to generate a corrected transcript.","['G10L15/32', 'G10L15/16', 'G06F40/279', 'G10L15/183', 'G10L15/26']"
US12086717B2,Devices and methods employing optical-based machine learning using diffractive deep neural networks,"An all-optical Diffractive Deep Neural Network (D2NN) architecture learns to implement various functions or tasks after deep learning-based design of the passive diffractive or reflective substrate layers that work collectively to perform the desired function or task. This architecture was successfully confirmed experimentally by creating 3D-printed D2NNs that learned to implement handwritten classifications and lens function at the terahertz spectrum. This all-optical deep learning framework can perform, at the speed of light, various complex functions and tasks that computer-based neural networks can implement, and will find applications in all-optical image analysis, feature detection and object classification, also enabling new camera designs and optical components that can learn to perform unique tasks using D2NNs. In alternative embodiments, the all-optical D2NN is used as a front-end in conjunction with a trained, digital neural network back-end.","['G02B27/4277', 'G02B27/4205', 'G02B5/1866', 'G03H1/0244', 'G03H1/26', 'G06F18/214', 'G06F18/2431', 'G06N3/04', 'G06N3/0455', 'G06N3/0499', 'G06N3/0675', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06V10/95', 'G03H2240/24']"
US11868889B2,Object detection in images,"In implementations of object detection in images, object detectors are trained using heterogeneous training datasets. A first training dataset is used to train an image tagging network to determine an attention map of an input image for a target concept. A second training dataset is used to train a conditional detection network that accepts as conditional inputs the attention map and a word embedding of the target concept. Despite the conditional detection network being trained with a training dataset having a small number of seen classes (e.g., classes in a training dataset), it generalizes to novel, unseen classes by concept conditioning, since the target concept propagates through the conditional detection network via the conditional inputs, thus influencing classification and region proposal. Hence, classes of objects that can be detected are expanded, without the need to scale training databases to include additional classes.","['G06V20/00', 'G06N3/08', 'G06F18/214', 'G06F18/22', 'G06F18/241', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/10', 'G06V20/20', 'G06V20/40', 'G06V20/64', 'G06N3/048']"
US11727327B2,Method and system for multistage candidate ranking,"Systems and methods for candidate recommendation are provided. Candidate vectors are generated from candidate documents, and an initial ranking is performed according to a distance metric between the candidate vector and an objective vector generated based on an objective document to select a subset of the candidate documents. A feature vector is generated for each of the selected candidate documents. The feature vector includes features derived from a first vectorized representation of content from one of the candidate document and the objective document and a second vectorized representation of content from the one of the candidate document and the objective document. The feature vector is provided to a machine learning model to generate a score for each of the selected candidate documents. The selected candidate documents are ranked according the scores generated at the machine learning model to provide a ranked candidate list.","['G06Q10/063112', 'G06F16/24578', 'G06N20/00', 'G06N3/09', 'G06Q10/1053', 'G06N3/08', 'G06N5/01']"
US11593558B2,Deep hybrid neural network for named entity recognition,"In an example, a text sentence comprising a plurality of words is obtained. Each of the plurality of words is passed through a deep compositional character-to-word model to encode character-level information of each of the plurality of words into a character-to-word expression. The character-to-word expressions are combined with pre-trained word embeddings. The combined character-to-word expressions and pre-trained word embeddings are fed into one or more bidirectional long short-term memories to learn contextual information for each of the plurality of words. Then, sequential conditional random fields are applied to the contextual information for each of the plurality of words.","['G06F40/295', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N7/005', 'G06N7/01', 'G06F40/30', 'G06F40/47', 'G06N3/048', 'G06N3/0481']"
CN113221277B,Bearing performance degradation evaluation method and system based on digital twin model,"The invention discloses a bearing performance degradation evaluation method and system based on a digital twin model, wherein the bearing digital twin model is adopted to carry out simulation calculation on vibration response signals of bearings in different health states under service working conditions; extracting characteristic indexes capable of representing the damage degree of the bearing; acquiring vibration data of the actual degradation process of the bearing, and extracting characteristic indexes capable of representing the damage degree from the vibration data; constructing a migration long-time memory network, training a TLSTM (transport layer test frame) model by utilizing simulation and actual acquired data to obtain the index of the current bearing health state, and evaluating the performance degradation state of the bearing; and alarming when the bearing health state index HI exceeds the alarm threshold value for m times continuously. The method provided by the invention utilizes the bearing degradation data obtained by simulating the digital twin model which is updated synchronously with the actual bearing, so that the bearing degradation data with high signal-to-noise ratio can be obtained, the bearing evaluation precision is improved, and the problem that a deep learning model needs a large amount of label data can be avoided.","['G06F30/17', 'G06F30/27', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06F2113/28', 'G06F2119/02']"
CN112734641B,"Training method and device for target detection model, computer equipment and medium","The embodiment of the application discloses a training method and device of a target detection model, computer equipment and a medium, and belongs to the technical field of computers. The method comprises the following steps: generating a first sample image based on an original sample image, wherein the original sample image contains an object to be detected, the first sample image contains at least two sub-images, and the sub-images are obtained by cutting the object to be detected contained in the original sample image; pre-training a target detection model based on the first sample image, wherein the pre-training aims at adjusting network parameters of a feature extraction network in the target detection model; generating a second sample image based on the original sample images, the second sample image comprising at least two original sample images; the object detection model is fine-tuned based on the second sample image. The diversity of data in the sample image is increased, and the target detection model obtained through sample image training is prevented from being dependent on certain attributes, so that the robustness and accuracy of the target detection model are increased.","['G06T3/4038', 'G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/084', 'G06T7/11', 'G06T7/62', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06V2201/07', 'Y02T10/40']"
US10586310B2,Denoising Monte Carlo renderings using generative adversarial neural networks,"Supervised machine learning using neural networks is applied to denoising images rendered by MC path tracing. Specialization of neural networks may be achieved by using a modular design that allows reusing trained components in different networks and facilitates easy debugging and incremental building of complex structures. Specialization may also be achieved by using progressive neural networks. In some embodiments, training of a neural-network based denoiser may use importance sampling, where more challenging patches or patches including areas of particular interests within a training dataset are selected with higher probabilities than others. In some other embodiments, generative adversarial networks (GANs) may be used for training a machine-learning based denoiser as an alternative to using pre-defined loss functions.","['G06T5/002', 'G06T5/70', 'G06F18/2113', 'G06F18/2148', 'G06F18/2413', 'G06K9/4628', 'G06K9/623', 'G06K9/6257', 'G06K9/627', 'G06K9/6298', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06V10/454', 'G06V10/72', 'G06V10/764', 'G06V10/7747', 'G06V10/82', 'G06T15/06', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/30168', 'G06T2207/30201', 'G06T7/90']"
US11948128B2,Intelligent preprocessing routing to decisioning services,"The system and methods described herein allow users to give their applicant information when seeking to purchase a good with financing from multiple potential lenders, and may be pre-screened by one or more rule sets implemented by a marketplace client in an eligibility analysis to ultimately submit applicant information to a subset of the multiple potential lenders which are found to be suitable for lending to an applicant based on the applicant information, wherein lender microservices are then run in a jailed, firewalled, and self-contained, autonomous environment, and the results of said lender microservices are reported to the user and may be used to change the one or more rule sets implemented by the marketplace client for future pre-screening of applicants.","['G06Q10/10', 'G06F16/258', 'G06F16/9558', 'G06F16/9562', 'G06F18/24', 'G06F21/53', 'G06F21/602', 'G06F21/604', 'G06F21/606', 'G06F21/6209', 'G06F21/6227', 'G06F21/6245', 'G06F40/103', 'G06F40/174', 'G06F40/18', 'G06F9/44505', 'G06F9/54', 'G06F9/547', 'G06N20/00', 'G06N3/02', 'G06N3/084', 'G06N5/025', 'G06N5/047', 'G06Q20/382', 'G06Q20/4014', 'G06Q30/0185', 'G06Q30/0206', 'G06Q30/0601', 'G06Q30/0613', 'G06Q30/0619', 'G06Q30/0637', 'G06Q30/0643', 'G06Q40/02', 'G06Q40/03', 'H04L63/0428', 'H04L63/0435', 'H04L63/0471', 'H04L63/0478', 'H04L63/08', 'H04L63/0815', 'H04L63/102', 'H04L63/123', 'H04L63/166', 'H04L63/168', 'H04L67/01', 'H04L9/0825', 'H04L9/0894', 'G06F2221/2107', 'G06F8/65', 'G06F8/71', 'G06K7/1417', 'G06N20/10', 'G06N3/048', 'G06N5/01', 'G06Q2220/00', 'G06Q50/265', 'H04L63/0442', 'H04L9/0822']"
US12106210B2,Scaling half-precision floating point tensors for training deep neural networks,"One embodiment provides for a machine-learning accelerator device a multiprocessor to execute parallel threads of an instruction stream, the multiprocessor including a compute unit, the compute unit including a set of functional units, each functional unit to execute at least one of the parallel threads of the instruction stream. The compute unit includes compute logic configured to execute a single instruction to scale an input tensor associated with a layer of a neural network according to a scale factor, the input tensor stored in a floating-point data type, the compute logic to scale the input tensor to enable a data distribution of data of the input tensor to be represented by a 16-bit floating point data type.","['G06N3/063', 'G06F5/012', 'G06F7/487', 'G06F7/5443', 'G06F9/30014', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20']"
US11488008B2,Hardware implemented point to point communication primitives for machine learning,"One embodiment provides for a system to compute and distribute data for distributed training of a neural network, the system including first memory to store a first set of instructions including a machine learning framework; a fabric interface to enable transmission and receipt of data associated with the set of trainable machine learning parameters; a first set of general-purpose processor cores to execute the first set of instructions, the first set of instructions to provide a training workflow for computation of gradients for the trainable machine learning parameters and to communicate with a second set of instructions, the second set of instructions facilitate transmission and receipt of the gradients via the fabric interface; and a graphics processor to perform compute operations associated with the training workflow to generate the gradients for the trainable machine learning parameters.","['G06N3/08', 'G06T1/20', 'G06N3/063', 'G06F9/547', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/098']"
US11710307B2,Urban remote sensing image scene classification method in consideration of spatial relationships,"An urban remote sensing image scene classification method in consideration of spatial relationships is provided and includes following steps of: cutting a remote sensing image into sub-images in an even and non-overlapping manner; performing a visual information coding on each of the sub-images to obtain a feature image Fv; inputting the feature image Fv into a crossing transfer unit to obtain hierarchical spatial characteristics; performing convolution of dimensionality reduction on the hierarchical spatial characteristics to obtain dimensionality-reduced hierarchical spatial characteristics; and performing a softmax model based classification on the dimensionality-reduced hierarchical spatial characteristics to obtain a classification result. The method comprehensively considers the role of two kinds of spatial relationships being regional spatial relationship and long-range spatial relationship in classification, and designs three paths in a crossing transfer unit for relationships fusion, thereby obtaining a better urban remote sensing image scene classification result.","['G06V20/176', 'G06F18/2134', 'G06F18/217', 'G06F18/241', 'G06F18/2415', 'G06F18/253', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06V10/32', 'G06V10/7515', 'G06V10/7715', 'G06V10/776', 'G06V10/806', 'G06V20/13', 'G06N3/044']"
US10812992B1,Cellular system,A system includes a cellular transceiver to communicate with a predetermined target; one or more antennas coupled to the 5G transceiver each electrically or mechanically steerable to the predetermined target; a processor to control a directionality of the one or more antennas in communication with the predetermined target; and an edge processing module coupled to the processor and the one or more antennas to provide low-latency computation for the predetermined target.,"['H04B7/0695', 'B64C39/024', 'G06N20/00', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'H04B17/12', 'H04B7/0617', 'B64B2201/00', 'B64D39/00', 'B64U10/13', 'B64U2101/23', 'B64U2201/102', 'G06N20/10', 'G06N3/063', 'G06N3/08', 'H04B17/21', 'H04B17/318', 'H04W16/28']"
US11622418B2,Synchronization of artificial intelligence based microservices,"Aspects of the subject disclosure may include, for example, receiving network-related information associated with a first RAN that includes a first RIC, obtaining, from an artificial intelligence (AI) model synchronization system associated with a second RAN, data relating to an AI model deployed by a second RIC of the second RAN, determining, based on the data relating to the AI model and the network-related information associated with the first RAN, that the AI model can be leveraged by the first RAN to improve network performance of the first RAN, performing synchronization with the AI model synchronization system to obtain the AI model, responsive to the determining that the AI model can be leveraged by the first RAN to improve the network performance of the first RAN, and causing the first RIC to deploy the AI model in the first RAN after the performing the synchronization. Other embodiments are disclosed.","['H04W56/0015', 'H04W88/182', 'H04L5/0048', 'H04W24/02', 'H04W24/08', 'H04W28/0289', 'H04L41/083', 'H04W28/084', 'H04W88/085']"
CN114429153B,Gearbox incremental fault diagnosis method and system based on lifelong learning,"The invention discloses a gear box increment fault diagnosis method and system based on life learning, comprising the following steps: s101: collecting vibration data of a gear box to construct an increment health state data set, and dividing the increment health state data set into fault diagnosis tasks of different stages; s102: constructing an initial stage diagnosis model by utilizing the fault diagnosis task of the initial stage of the original ResNet-32 network learning; s103: initializing a ResNet-32 double-branch aggregation network by using an initial stage diagnosis model, and increasing the number of neurons of a classification layer according to the number of newly-increased fault types; s104: training the stage diagnosis model through the selected typical cases and the stage fault diagnosis task data together, and selecting the typical cases of the stage fault diagnosis task data after training is completed; s105: repeating the steps S103-S104 in the subsequent increment stage to obtain a final fault diagnosis model, and performing fault diagnosis. The invention aims to solve the problem that the existing fault diagnosis model based on deep learning and transfer learning cannot diagnose actual unexpected faults of the gear box.","['G06F2218/12', 'G06F18/2414', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N5/01', 'G06F2218/08']"
CN111639710B,"Image recognition model training method, device, equipment and storage medium","The embodiment of the application discloses an image recognition model training method, an image recognition model training device and a storage medium, and relates to the technical fields of artificial intelligence, deep learning and image processing. One embodiment of the method comprises the following steps: acquiring a sample image set; for a sample image in a sample image set, inputting the sample image into a pre-trained teacher model to obtain probability distribution of targets in the sample image belonging to various categories; and taking the sample image as input, taking probability distribution corresponding to the sample image as output, and training the student model to obtain an image recognition model. According to the embodiment, the novel knowledge distillation technology is provided, probability distribution predicted by the teacher model is introduced to serve as supervision, training of the student model is induced, the knowledge distillation technology does not depend on a labeling sample in the training process, the precision of the non-labeling sample can be fully improved, and the sample labeling cost in image recognition is effectively reduced.","['G06F18/2415', 'G06N3/045', 'G06N3/084', 'Y02T10/40']"
US10769761B2,Generating high resolution images from low resolution images for semiconductor applications,Methods and systems for generating a high resolution image for a specimen from a low resolution image of the specimen are provided. One system includes one or more computer subsystems configured for acquiring a low resolution image of a specimen. The system also includes one or more components executed by the one or more computer subsystems. The one or more components include a deep convolutional neural network that includes one or more first layers configured for generating a representation of the low resolution image. The deep convolutional neural network also includes one or more second layers configured for generating a high resolution image of the specimen from the representation of the low resolution image. The second layer(s) include a final layer configured to output the high resolution image and configured as a sub-pixel convolutional layer.,"['G06T5/90', 'G06T5/007', 'G06T3/4046', 'G06T3/4053', 'G06T2207/20084', 'G06T2207/20208']"
US20230229960A1,"Systems and methods for facilitating integrative, extensible, composable, and interpretable deep learning","Some disclosed systems are configured to obtain a knowledge module configured to receive one or more knowledge inputs corresponding to one or more different modalities and generate a set of knowledge embeddings to be integrated with a set of multi-modal embeddings generated by a multi-modal main model. The systems receive a knowledge input at the knowledge module, identify a knowledge type associated with the knowledge input, and extract a knowledge unit from the knowledge input. The systems select a representation model that corresponds to the knowledge type and select a grounding type configured to ground the at least one knowledge unit into the representation model. The systems then ground the knowledge unit into the representation model according to the grounding type.","['G06N3/042', 'G06N20/00', 'G06F40/40', 'G06N3/045', 'G06N3/096', 'G06V10/774', 'G10L15/063']"
US20210312725A1,Vehicle-data analytics,Provided is a system configured to determine and push adjustments to vehicle operations using machine-learning systems across multiple computing layers.,"['G06N3/08', 'B60W50/0098', 'G06N3/045', 'G07C5/008', 'G07C5/02', 'G07C5/0841', 'G08G1/0112', 'G08G1/0116', 'G08G1/0133', 'G08G1/0141', 'G08G1/096716', 'G08G1/096741', 'G08G1/096775', 'H04L67/12', 'H04Q9/00', 'H04W4/021', 'H04W4/44', 'G06N3/044', 'G06N3/047']"
US12412242B2,"Electronic device, control method thereof, and system","An example electronic device may include a memory configured to include at least one instruction; and a processor configured to be connected to the memory to control the electronic device, and obtain an output image by upscaling an input image using an artificial intelligence model trained to upscale an image, wherein the processor is configured to control the electronic device to: obtain parameter information of the artificial intelligence model based on pre-processing related information performed on the input image, and upscale the input image using the artificial intelligence model corresponding to the obtained parameter information.","['G06N3/0455', 'H04N19/42', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T3/4046', 'G06T9/002', 'H04N19/117', 'H04N19/59', 'H04N21/234', 'H04N21/44', 'H04N7/0127']"
US12182721B2,Deep learning-based anomaly detection in images,"A method comprising: receiving, as input, training images, wherein at least a majority of the training images represent normal data instances; receiving, as input, a target image; extracting (i) a set of feature representations from a plurality of image locations within each of the training images, and (ii) target feature representations from a plurality of target image locations within the target image; calculating, with respect to a target image location of the plurality of target image locations in the target image, a distance between (iii) the target feature representation of the target image location, and (iv) a subset from the set of feature representations comprising the k nearest the feature representations to the target feature representation; and determining that the target image location is anomalous, when the calculated distance exceeds a predetermined threshold.","['G06N3/088', 'G06F18/24147', 'G06F18/2433', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/096', 'G06V10/44', 'G06V10/761', 'G06V10/762', 'G06V10/82']"
US20220332335A1,Vehicle-data analytics,Provided is a system configured to determine and push adjustments to vehicle operations using machine-learning systems across multiple computing layers.,"['H04W4/44', 'B60W50/045', 'B60W50/02', 'G06N3/08', 'G07C5/008', 'G07C5/0841', 'G08G1/0112', 'G08G1/0116', 'G08G1/0137', 'H04W4/021', 'B60W2050/0075', 'B60W2050/0215', 'B60W2540/106', 'B60W2556/10', 'B60W2556/45', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
WO2024183181A1,"Object detection method and apparatus, device, and storage medium","Embodiments of the present application relate to the technical field of graphical data reading, and provide an object detection method and apparatus, a device, and a storage medium. The method comprises: on the basis of a result, obtained by a vision Transformer model, of performing correlation aggregation operation on a query feature map sequence and a support feature map sequence, determining a second query feature map sequence; and on the basis of a result of a self-attention operation and/or a cross-attention operation of the second query feature map sequence, determining a prediction result corresponding to a query image for obtaining the query feature map sequence. According to the object detection method provided by the present application, the convergence time of the vision Transformer model is greatly shortened, the difficulty of predicting a bounding box by using the model is reduced, a target feature area related to a support category in the query image can be effectively extracted, and the query branches are not limited to target instances of specific support categories, and thus a target instance of any category can be detected.","['G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06V10/25', 'G06V10/52', 'G06V10/764', 'G06V10/82', 'Y04S10/50']"
US20200082188A1,Methods and systems for real-time monitoring of vehicles,"Embodiments disclosed herein relate to surveillance systems and more particularly providing an Artificial Intelligence (AI) assisted security surveillance device in vehicles. Embodiments herein provide real-time monitoring of vehicle and surrounding environment of the vehicle including, but not limited to, gestures, voice, behaviors of both drivers and passengers, and so on. Embodiments herein provide real-time alerts to at least one external entity on identifying an emergency situation.","['G06N20/00', 'G06K9/00832', 'G06V20/59', 'G06K9/00711', 'G06K9/00791', 'G06V20/40', 'G06V20/56', 'G08B21/06', 'G08B25/009', 'G08B25/016', 'G08B25/10', 'G06K2009/00738', 'G06V20/44']"
US10664527B1,Response retrieval system and method,"A method of obtaining a response to a query inputted by a user, the method comprising:","['G06F16/90332', 'G06F16/3334', 'G06F16/3347', 'G06F16/538']"
US10694399B1,Cellular system,A system includes a cellular transceiver to communicate with a predetermined target; one or more antennas coupled to the 5G transceiver each electrically or mechanically steerable to the predetermined target; a processor to control a directionality of the one or more antennas in communication with the predetermined target; and an edge processing module coupled to the processor and the one or more antennas to provide low-latency computation for the predetermined target.,"['H04W88/085', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/096', 'G06N3/098', 'H01Q1/02', 'H01Q3/01', 'H01Q3/20', 'H04B7/0617', 'H04W16/28', 'H04W4/40', 'G06N20/10', 'G06N3/08', 'H04B7/0413', 'H04B7/10']"
US20240295625A1,Methods and apparatus for training based positioning in wireless communication systems,"The disclosure pertains to methods and apparatus for using artificial intelligence and machine learning for positioning of nodes (e.g., wireless transmit/receive units (WTRUs)) in wireless communications. In an example, a method implemented by a WTRU for wireless communications includes receiving configuration information indicating a plurality of positioning methods and a threshold, determining a respective weight for each of the plurality of positioning methods, and sending the respective weights for the plurality of positioning methods based on determining that at least one of the respective weights is greater than the threshold and/or after a preconfigured time period.","['G01S5/0236', 'G01S5/0263', 'G01S5/0268', 'G01S5/0278']"
US11636147B2,Training neural networks to perform tag-based font recognition utilizing font classification,"The present disclosure relates to a tag-based font recognition system that utilizes a multi-learning framework to develop and improve tag-based font recognition using deep learning neural networks. In particular, the tag-based font recognition system jointly trains a font tag recognition neural network with an implicit font classification attention model to generate font tag probability vectors that are enhanced by implicit font classification information. Indeed, the font recognition system weights the hidden layers of the font tag recognition neural network with implicit font information to improve the accuracy and predictability of the font tag recognition neural network, which results in improved retrieval of fonts in response to a font tag query. Accordingly, using the enhanced tag probability vectors, the tag-based font recognition system can accurately identify and recommend one or more fonts in response to a font tag query.","['G06F16/55', 'G06F16/5846', 'G06F16/90335', 'G06F16/906', 'G06F18/2148', 'G06F18/217', 'G06F18/2415', 'G06F18/28', 'G06F40/109', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06V10/454', 'G06V10/82', 'G06V30/19173', 'G06V30/2264', 'G06V30/245']"
CN111460838B,"Pre-training method, device and storage medium of intelligent translation model","The invention provides a pre-training method, device and storage medium of an intelligent translation model. The method comprises the following steps: acquiring a pre-training source language sentence comprising source language words and a pre-training target language sentence comprising target language words; screening candidate translation words corresponding to the source language words from the target language words based on the similarity between the source language words and the target language words, wherein each source language word corresponds to a preset number of candidate translation words; replacing at least one source language word in the pre-training source language sentence according to the candidate translation word corresponding to the source language word in the pre-training source language sentence to obtain a language mixed coding sentence corresponding to the pre-training source language sentence; and pre-training the initial translation model based on the language mixed coding sentence to obtain a pre-training translation model. The method utilizes the implicit alignment information in the monolingual corpus of the source language and the target language to improve the pre-training accuracy of the translation model, thereby greatly improving the performance of the translation task.",['Y02D10/00']
US11526679B2,Efficient transformer language models with disentangled attention and multi-step decoding,Systems and methods are provided for facilitating the building and use of natural language understanding models. The systems and methods identify a plurality of tokens and use them to generate one or more pre-trained natural language models using a transformer. The transformer disentangles the content embedding and positional embedding in the computation of its attention matrix. Systems and methods are also provided to facilitate self-training of the pre-trained natural language model by utilizing multi-step decoding to better reconstruct masked tokens and improve pre-training convergence.,"['G06F40/40', 'G06N3/088', 'G06F40/237', 'G06F40/30', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/048', 'G06N3/0499', 'G06N3/0895']"
US11823013B2,Text data representation learning using random document embedding,"Embodiments of the present invention provide a computer-implemented method for performing unsupervised feature representation learning for text data. The method generates reference text data having a set of random text sequences, in which each text sequence of set of random text sequences is of a random length and comprises a number of random words, and in which each random length is sampled from a minimum length to a maximum length. The random words of each text sequence in the set are drawn from a distribution. The method generates a feature matrix for raw text data based at least in part on a set of computed distances between the set of random text sequences and the raw text data. The method provides the feature matrix as an input to one or more machine learning models.","['G06N7/01', 'G06N20/10', 'G06N20/00', 'G06F16/3331', 'G06N3/008', 'G06N3/088']"
CN109621431B,Game action processing method and device,"The embodiment of the invention provides a method and a device for processing game actions, wherein the method comprises the following steps: acquiring the current game state and action space of a non-player character; inputting the current game state into a pre-trained reinforcement learning network model to obtain a reinforcement strategy, wherein the reinforcement strategy comprises a first selection probability of each game action; inputting the action space into a pre-trained auxiliary rule network model to obtain an auxiliary strategy, wherein the auxiliary strategy comprises a second selection probability of each game action; determining a target strategy according to the strengthening strategy and the auxiliary strategy, wherein the target strategy comprises target probabilities generated by all game actions based on the first selection probability and the second selection probability; and screening target game actions from the action space according to the target probability of each game action, and controlling a non-player character to execute the target game actions. The embodiment of the invention can improve the game experience of the player.","['A63F13/822', 'G06N3/08']"
US12017142B2,System and method for real-time calibration of virtual apparel using stateful neural network inferences and interactive body measurements,"An Augmented Reality (AR) and Artificial Intelligence (AI) based interactive virtual try-on solution that facilitates trying on, fitting, and modularizing a virtual apparel in real-time—as if a consumer were wearing the apparel. A user with a mobile device defines retail adjustment operations on the virtual apparel using an AR-based visual interface. The user can interact with the virtual apparel for identifying, defining, and changing the look, fit, and design of the apparel on the user's body. The real-time interaction is with the same virtual apparel. The system defines operations based on user's features, sartorial measurements, intent, gestures, position, pressure values received from a controller operated by the user, and the sensed motion of the user to translate into a set of machine learning inference models that predict a series of states that visually generate the outcome the user anticipates based on the user's interaction with the virtual clothing.","['G06Q30/0643', 'A63F13/53', 'A63F13/31', 'G06F3/011', 'G06F3/016', 'G06F3/017', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06Q30/0621', 'G06Q30/0623', 'G06T17/20', 'G06T19/006', 'G06T2210/16']"
US20210192412A1,Cognitive Intelligent Autonomous Transformation System for actionable Business intelligence (CIATSFABI),"A Utility patent with new concepts, methods, a comprehensive step-by-step procedure/system to produce semi-autonomous, self-curing customizable Cognitive Intelligent Autonomous Transformation System aided by Digital Assistants based on AI, Machine Learning enhanced RPA, natural language processing, speech recognition and image recognition with Deep Learning and Neural networks, that will transform an existing business system to the latest version supported by vendor for the industry with superior process automation. By Combining AI and cognitive computing in a single operating environment using the same sets of data—configuration data, Master Data, Transaction Data and historical transaction data, we propose to revolutionize existing customer's information systems to be a self-evolving cognitive intelligent automation systems where it not only knows the ultimate target information systems but also how to get there every step of the way seamlessly, similar to autonomous cars taking to destination, except in this case, information systems that run your business.","['G06Q10/0637', 'G06N3/08', 'G06N7/04', 'G06Q10/06316', 'G06Q10/06375', 'G06Q10/06393', 'G06Q10/101', 'G06Q10/103', 'G06Q30/018', 'G06Q30/0201', 'Y02P90/80']"
TWI682357B,Compute optimizations for low precision machine learning operations,"One embodiment provides a general-purpose graphics processing unit comprising a dynamic precision floating-point unit including a control unit having precision tracking hardware logic to track an available number of bits of precision for computed data relative to a target precision, wherein the dynamic precision floating-point unit includes computational logic to output data at multiple precisions.","['G06T1/20', 'G06F9/3867', 'G06F12/0811', 'G06F7/483', 'G06F9/30014', 'G06F9/30185', 'G06F9/3863', 'G06F9/5044', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06F2212/401', 'G06F3/14', 'G06T1/60', 'G06T15/005', 'Y02D10/00']"
US11681951B2,Semantic learning in a federated learning system,"A method, a computer system, and a computer program product are provided for federated learning. An aggregator may receive cluster information from distributed computing devices. The cluster information may relate to identified clusters in sample data of the distributed computing devices. The cluster information may include centroid information per cluster. The aggregator may include a processor. The aggregator may integrate the cluster information to define data classes for machine learning classification. The integrating may include computing a respective distance between centroids of the clusters in order to determine a total number of the data classes. The aggregator may send a deep learning model that includes an output layer that has a total number of nodes equal to the total number of the data classes. The deep learning model may be for the distributed computing devices to perform machine learning classification in federated learning.","['G06N20/00', 'G06F40/30', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'H04L67/10']"
US11682052B2,Machine learning systems and methods for determining home value,Techniques for determining value of a home by applying one or more neural network models to images of spaces in the home. The techniques include: obtaining at least one image of a first space inside or outside of a home; determining a type of the first space by processing the at least one image of the first space with a first neural network model; identifying at least one feature in the first space by processing the at least one image with a second neural network model different from the first neural network model and trained using images of spaces of a same type as the first space; and determining a value of the home at least in part by using the at least one feature as input to a machine learning model different from the first neural network model and the second neural network model.,"['G06Q30/0278', 'G06F18/214', 'G06F18/254', 'G06N20/20', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/096', 'G06N5/01', 'G06Q50/16', 'G06V10/764', 'G06V10/774', 'G06V10/809', 'G06V10/82']"
US9940575B2,Image searching,"As provided herein, a domain model, corresponding to a domain of an image, may be merged with a pre-trained fundamental model to generate a trained fundamental model. The trained fundamental model may comprise a feature description of the image converted into a binary code. Responsive to a user submitting a search query, a coarse image search may be performed, using a search query binary code derived from the search query, to identify a candidate group, comprising one or more images, having binary codes corresponding to the search query binary code. A fine image search may be performed on the candidate group utilizing a search query feature description derived from the search query. The fine image search may be used to rank images within the candidate group based upon a similarity between the search query feature description and feature descriptions of the one or more images within the candidate group.","['G06N3/08', 'G06N3/084', 'G06F16/5838', 'G06F17/30256', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'Y04S10/50']"
CN119250172B,Method for constructing plastic industry chain knowledge graph by utilizing graph convolution network,"The invention provides a method for constructing a knowledge graph of a plastic industry chain by utilizing a graph convolution network, which relates to the technical field of knowledge graphs, and comprises the steps of acquiring multi-source heterogeneous data of the plastic industry chain through a data acquisition system to form an initial data set; the method comprises the steps of preprocessing an initial data set to generate a standardized data set, carrying out knowledge modeling based on the standardized data set to form a domain knowledge model, constructing an initial knowledge graph according to the domain knowledge model, optimizing the initial knowledge graph by using a graph rolling network, including constructing a design graph convolution network model and a training model, and carrying out automatic complementation and error correction on the knowledge graph through the trained model to obtain an optimized plastic industry chain knowledge graph. According to the invention, by systematic data processing, knowledge modeling and graph convolution network optimization methods, efficient expression, automatic completion and error correction of knowledge of the plastic industry chain are realized, so that an accurate and reliable knowledge map of the plastic industry chain with automatic optimization capability is constructed.","['G06N5/02', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'Y02P90/30']"
US12183462B2,"Method for predicting lung cancer development based on artificial intelligence model, and analysis device therefor","A method for determining a probability of developing lung cancer by using an artificial intelligence model, includes: receiving, by an analysis device, a chest fluorodeoxyglucose (FDG) PET/CT image for a sample; inputting, by the analysis device, the F-18 FDG PET/CT image to a first classification neural network, and outputting prediction information related to development of lung cancer for the sample; and predicting, by the analysis device, a probability of developing lung cancer for the sample on the basis of the prediction information. The first classification neural network is trained by using chest F-18 FDG PET/CT images for healthy people and training images excluding lung cancer regions from chest F-18 FDG PET/CT images for lung cancer patients.","['A61B6/032', 'A61B6/037', 'A61B6/5217', 'G06N3/02', 'G06T7/0012', 'G06T7/0014', 'G06V10/22', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G16B20/00', 'G16B40/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06T2207/10081', 'G06T2207/10104', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30061', 'G06V2201/03', 'G16B20/20']"
US10171161B1,Machine learning for link parameter identification in an optical communications system,"Technology for link parameter identification in an optical communications network is described. A first trained artificial neural network (ANN) may be applied to first input values representative of nonlinear noise in a signal received at a receiver from a transmitter over a link in the optical communications system, thereby generating first output values. A second trained ANN may be applied to second input values comprising the first output values and one or more known parameters of the link, thereby generating second output values. One or more link parameter estimates may be identified based on the second output values. In some examples, the first trained ANN has an architecture specialized for two-dimensional image recognition and therefore suitable for the image-like properties of the first input values. For example, the first trained ANN may comprise a deep residual learning network (ResNet) or a Convolution Neural Network (CNN).","['H04B10/0793', 'G06T7/0004', 'H04B10/6161', 'H04Q3/528', 'G06T2207/20084', 'H04Q2213/13343']"
CN110084281B,"Image generation method, neural network compression method, related device and equipment","The application discloses an image generation method, a compression method of a neural network, a related device and equipment in the artificial intelligence field, wherein the image generation method comprises the steps of inputting a first matrix into an initial image generator to obtain a generated image; inputting the generated image into a preset discriminator to obtain a discrimination result, wherein the preset discriminator is obtained through real image and classification training corresponding to the real image; updating the initial image generator according to the discrimination result to obtain a target image generator; further, the second matrix is input to the target image generator, and a sample image is obtained. Further, a compression method of the neural network is also disclosed, and the preset discriminator is compressed based on the sample image obtained by the image generation method.","['G06V30/19', 'G06F18/2148', 'G06F18/243', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/088', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V40/16', 'G06V40/174', 'G06V40/178', 'G06N3/048']"
CN108897989B,Biological event extraction method based on candidate event element attention mechanism,"The invention relates to a biological event extraction method, in particular to a biological event extraction method based on a candidate event element attention mechanism, which comprises the following steps: (1) preprocessing a corpus, carrying out word vector training by using a PubMed database corpus, constructing a distributed representation mode of a sequence, constructing a feature representation mode based on BilSTM-Attention, 5, learning by using CRF (learning reference frame) and acquiring an optimal sequence labeling result of a current document sequence, and 6, extracting a biological event. The method of the invention has the following advantages: the method comprises the steps of firstly, adopting a sequence labeling mode to identify event elements aiming at trigger words, identifying a plurality of event elements aiming at one trigger word, secondly, constructing an Attention layer aiming at candidate event elements, and thirdly, simplifying the steps of generating events compared with the traditional sequence labeling method.","['G06N3/049', 'G06N3/08']"
US20230078763A1,"Image generation device, image generation method, recording medium generation method, learning model generation device, learning model generation method, learning model, data processing device, data processing method, inference method, electronic device, generation method, program and non-temporary computer readable medium","[Object]Training data is acquired using a computer graphics.[Solution]An image generation method includes acquiring a CG model or an artificial image generated based on the CG model and performing, by a processor, processing on the CG model or the artificial image and generating metadata of a processed image used for AI learning used for an image acquired by a sensor or the artificial image.","['G06V10/774', 'G06T15/00', 'G06N3/09', 'G06T11/00', 'G06T5/60', 'G06T5/80', 'G06V20/58', 'G06N3/0464', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'G06V2201/07', 'G06V2201/08']"
CN112991346B,Training method and training system for learning network for medical image analysis,"The present disclosure relates to a training method and a training system for a learning network for medical image analysis. The training method comprises the following steps: setting a learning network with a preset structure and acquiring an original training data set; pre-training the learning network by using an original training data set by a processor to obtain a pre-trained learning network; evaluating the pre-trained learning network by the processor to judge whether a preset evaluation defect exists or not; the processor performs data enhancement on the basis of an original training data set aiming at the existing assessment defects under the condition that the pre-trained learning network has the assessment defects; and performing, by the processor, fine training of the learning network using the data-enhanced training data set based on the parameters of the pre-training model. The method and the system can evaluate and train the learning network in stages, so that the complexity of medical image processing is reduced, and the efficiency and the accuracy of medical image analysis are improved.","['G06V10/7747', 'G06T7/0012', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06T7/11', 'G06V10/776', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30101', 'G06V2201/03']"
US11291532B2,Dental CAD automation using deep learning,A computer-implemented method of recognizing dental information associated with a dental model of dentition includes training a deep neural network to map a plurality of training dental models representing at least a portion of each one of a plurality of patients' dentitions to a probability vector including probability of the at least a portion of the dentition belonging to each one of a set of multiple categories. The category of the at least a portion of the dentition represented by the training dental model corresponds to the highest probability in the probability vector. The method includes receiving a dental model representing at least a portion of a patient's dentition and recognizing dental information associated with the dental model by applying the trained deep neural network to determine a category of the at least a portion of the patient's dentition represented by the received dental model.,"['A61C13/0004', 'G06F18/24143', 'G06K9/6274', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06T7/0012', 'G06T7/579', 'G06V10/764', 'G06V10/82', 'G06V20/653', 'A61C2007/004', 'A61C7/002', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/033']"
US11868884B2,Method and system for providing machine learning service,"The present disclosure provides methods and systems for providing machine learning model service. The method may comprise: (a) generating, by a first computing system, a first output data using a first machine learning model, wherein the first machine learning model is trained on a first training dataset; (b) transmitting the first output data to a second computing system, wherein the first training dataset and the first machine learning model are inaccessible to the second computing system; (c) creating an input data by joining the first output data with a selected set of input features accessible to the second computing system; and (d) generating a second output data using a second machine learning model to process the input data.","['G06N3/08', 'G06N3/088', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06Q30/0202', 'G06Q30/0241', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/047', 'G06N5/01', 'G06N7/01']"
WO2019174130A1,"Bill recognition method, server, and computer readable storage medium","Disclosed is a bill recognition method. The method comprises: receiving a bill image to be recognized, and processing the bill image by means of a pre-trained bill image recognition model; performing text detection on the bill image by using a pre-trained text detection model, and determining a target character zone comprising characters in the bill image and fields to be recognized in the target character zone; and invoking, for the fields to be recognized, a corresponding text recognition model for character recognition, so as to separately recognize character information contained in the multiple fields to be recognized in the target character zone, and outputting the recognition result. The present application further provides a server and a computer readable storage medium. The bill recognition method, the server, and the computer readable storage medium provided in the present application can improve the digitalization efficiency of bills, reduce the work intensity of service staff, and enhance the accuracy or refinement level of data.","['G06Q30/04', 'G06F18/2414', 'G06Q40/08', 'G06V10/22', 'G06V10/245', 'G06V10/30', 'G06V10/34', 'G06V30/153', 'G06V30/413', 'G06V30/10']"
US20220301666A1,System and methods of monitoring a patient and documenting treatment,"This disclosure provides an efficient, hands-free system and method for capturing and recording patient treatment and physiological data in critical care environments. The systems and methods described herein enables clinicians to record and transcribe patient information and physiological data onto an individual disposable medical record tag, which accompanies the patientthroughout initial stabilization and presentation to a treatment center. The data tag digitally stores a patient's health status, and displays a specific color based on a patient's degree of injury or if treatment is required. The data tag forms the center of a patient centric network PCN of connectedhealth devices. An artificial intelligence machine learning model is used in combination with predictive analytics to assess a patient's condition and provide clinical decision support for clinicians based on predictive analytical models.","['A61B5/002', 'G16H10/60', 'G06F1/163', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06F3/015', 'G06F3/016', 'G06F3/017', 'G06F3/03547', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/09', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H80/00', 'A61B5/0022', 'A61B5/01', 'A61B5/0205', 'A61B5/021', 'A61B5/024', 'A61B5/02405', 'A61B5/02416', 'A61B5/031', 'A61B5/0816', 'A61B5/14532', 'A61B5/14542', 'A61B5/165', 'A61B5/318', 'A61B5/369', 'A61B5/445', 'A61B5/6824', 'A61B5/7264', 'A61B5/7275', 'G02B2027/014', 'G06N3/082']"
CN110832596B,Deep convolutional neural network training method based on deep learning,"The disclosed technology relates to constructing a convolutional neural network-based classifier for variant classification. And more particularly, to a method for training a convolutional neural network based classifier using a back-propagation gradient-based update method on training data, which gradually matches the output of the convolutional neural network based classifier with corresponding truth value labels. The classifier based on the convolutional neural network comprises residual block groups, wherein each residual block group is parameterized by the number of convolutional filters in the residual block, the convolutional window size of the residual block and the hole convolutional rate of the residual block, the convolutional window size is changed among the residual block groups, and the hole convolutional rate is changed among the residual block groups. The training data includes benign training examples and pathogenic training examples of transformed sequence pairs generated from benign variants and pathogenic variants.","['G06F18/2414', 'G16B40/00', 'G06F18/00', 'G16B40/20', 'G16B20/00', 'G06F18/2148', 'G06F18/2155', 'G06F18/24', 'G06F18/24133', 'G06N20/00', 'G06N20/20', 'G06N3/002', 'G06N3/02', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/061', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/086', 'G06N3/0895', 'G06N3/09', 'G06N3/123', 'G06N7/00', 'G06N7/01', 'G06V10/454', 'G06V10/82', 'G16B20/20', 'G16B20/30', 'G16B20/50', 'G16B30/00', 'G16B30/10', 'G16B50/00', 'G16B50/50', 'G16H70/60', 'G06N3/048', 'G06V2201/03', 'Y02A90/10']"
US20240020968A1,Improving geo-registration using machine-learning based object identification,"A Geo-synchronization system involves a video camera in a vehicle, such as a drone, that captures aerial images of an area. The success rate and the accuracy of the geo-synchronization algorithms is improved by using a trained feed-forward Artificial Neural Network (ANN) for identifying dynamic objects, that changes overtime, in frames captured by the video camera. Such frames are tagged, such as by adding metadata. The tagged frames may be used in a geosynchronization algorithm that may be based on comparing with reference images or may be based on another or same ANN, by removing the dynamic object from the fame, or removing the tagged frame for the algorithm. A dynamic object may change over time due to environmental conditions, such as weather changes, or geographical changes. The environmental condition may change is in response to the Earth rotation, the Moon orbit, or the Earth orbit around the Sun.","['G06V20/17', 'G06F16/29', 'G06F16/51', 'G06F16/587', 'G06F16/7837', 'G06F16/787', 'G06V10/14', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G06V20/52']"
US10528846B2,Method and apparatus for analyzing facial image,"A method to analyze a facial image includes: inputting a facial image to a residual network including residual blocks that are sequentially combined and arranged in a direction from an input to an output; processing the facial image using the residual network; and acquiring an analysis map from an output of an N-th residual block among the residual blocks using a residual deconvolution network, wherein the residual network transfers the output of the N-th residual block to the residual deconvolution network, and N is a natural number that is less than a number of all of the residual blocks, and wherein the residual deconvolution network includes residual deconvolution blocks that are sequentially combined, and the residual deconvolution blocks correspond to respective residual blocks from a first residual block among the residual blocks to the N-th residual block.","['G06K9/623', 'G06V10/82', 'G06F18/2113', 'G06F18/2193', 'G06F18/2413', 'G06F18/295', 'G06K9/00281', 'G06K9/00288', 'G06K9/6265', 'G06K9/66', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/764', 'G06V10/85', 'G06V40/171', 'G06V40/172']"
US20220327655A1,"Unified architecture for bvh construction based on hardware pre-sorting and a parallel, reconfigurable clustering array","An apparatus comprising a sorting unit to sort primitives of a graphics image, the primitives to be grouped, each group to form a first level node of a hierarchical acceleration structure; a parallel reconfigurable clustering array to construct the hierarchical acceleration structure, the parallel reconfigurable clustering array comprising a plurality of processing clusters, each cluster comprising: parallel efficiency analysis circuitry to evaluate different groupings of the first level nodes for a next level of the hierarchical acceleration structure to determine efficiency values for the different groupings; and node merge circuitry to merge the first level nodes based on the efficiency values to form second level nodes.","['G06T1/20', 'G06F16/9027', 'G06F9/3877', 'G06F9/3891', 'G06F9/5077', 'G06T15/005', 'G06T15/06', 'G06T15/10']"
US11430083B2,Machine learning sparse computation mechanism,Techniques to improve performance of matrix multiply operations are described in which a compute kernel can specify one or more element-wise operations to perform on output of the compute kernel before the output is transferred to higher levels of a processor memory hierarchy.,"['G06F12/0207', 'G06F12/0811', 'G06F12/0815', 'G06F12/0831', 'G06F12/0888', 'G06F17/16', 'G06F18/2136', 'G06F9/3001', 'G06F9/3885', 'G06F9/4881', 'G06K9/6249', 'G06N20/00', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T1/20', 'G06T1/60', 'G06T15/005', 'H03M7/30', 'G06F2212/1024', 'G06F2212/302', 'G06F2212/401', 'G06F2212/621', 'G06T2200/28', 'Y02D10/00']"
CN108734286B,Coordination and increased utilization of GPUs during inference,"A mechanism for facilitating inferred coordination and processing utilization of machine learning at an autonomous machine is described. As described herein, a method of an embodiment includes detecting information related to one or more tasks to be performed during training from a training data set related to a processor including a graphics processor. The method may further include analyzing the information to determine one or more portions of hardware associated with the processor that are capable of supporting the one or more tasks, and configuring the hardware to pre-select the one or more portions to perform the one or more tasks while other portions of the hardware remain available for other tasks.","['G06F9/46', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06N3/044', 'G06N3/084', 'Y02D10/00']"
US20250078200A1,Utilizing a generative neural network to interactively create and modify digital images based on natural language feedback,"The present disclosure relates to systems, non-transitory computer-readable media, and methods that implement a neural network framework for interactive multi-round image generation from natural language inputs. Specifically, the disclosed systems provide an intelligent framework (i.e., a text-based interactive image generation model) that facilitates a multi-round image generation and editing workflow that comports with arbitrary input text and synchronous interaction. In particular embodiments, the disclosed systems utilize natural language feedback for conditioning a generative neural network that performs text-to-image generation and text-guided image modification. For example, the disclosed systems utilize a trained model to inject textual features from natural language feedback into a unified joint embedding space for generating text-informed style vectors. In turn, the disclosed systems can generate an image with semantically meaningful features that map to the natural language feedback. Moreover, the disclosed systems can persist these semantically meaningful features throughout a refinement process and across generated images.","['G06T3/10', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T11/00', 'G06T11/60', 'G10L15/22', 'G10L15/26', 'G06F3/167', 'G10L2015/223']"
EP4566019A2,Social network with network-based rewards,"A user interface system is provided, comprising a content display output for presentation of content to a user; a communication network interface port; and at least one automated processor configured to: receive at least one hyperlink in a social network record of a social network; request content associated with the hyperlink; receive an advertisement associated with at least one of the user, the social network record, the hyperlink, and the content; verify presentation of the advertisement to the user; present the content to the user; and account for presentation of the advertisement to the user, by crediting at least one account distinct from an account associated with the user, an account associated with a content owner, and an account associated with a social network.","['G06Q30/0277', 'G06Q20/36', 'G06Q20/384', 'G06Q20/389', 'G06Q30/0214', 'G06Q30/0271', 'G06Q30/0273', 'G06Q30/0631', 'G06Q50/01', 'G06Q20/10']"
CN110197714B,"Image analysis method, device, method for generating deep learning algorithm after learning","The present invention aims to evaluate the layer structure of a structure based on a fixed judgment standard instead of a pathologist. The present invention solves this problem by an image analysis method for analyzing an image of a tissue acquired from a subject using a neural network structure deep learning algorithm (60). The image analysis method comprises the following steps: the analysis data (80) is generated from an analysis object image (78) including an analysis object tissue, the analysis data (80) is input to a deep learning algorithm (60), and data representing the layer structure of the analysis object image (78) constituting the tissue is generated by the deep learning algorithm.","['G06V20/698', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/0012', 'G06V10/44', 'G06V10/56', 'G16H30/40', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
CN107622485B,Medical image data analysis method and system fusing depth tensor neural network,"The invention belongs to the technical field of computer application, in particular to the technical field of medical image analysis, and particularly relates to a medical image data analysis method and system fusing a depth tensor neural network. Compared with the traditional recurrent neural network, the parameter scale of the tensor recurrent neural network is far smaller than the network parameter scale when the traditional network processes the same tensor data. Therefore, the reliability and the efficiency of the imaging analysis can be effectively improved, and a basis is provided for adjusting and optimizing a treatment scheme.",[]
US12257025B2,AI enabled multisensor connected telehealth system,"This invention presents a multisensor-connected, AI-enabled telehealth system for assisting healthcare providers with differential diagnosis and patients with early health concern detection. The system comprises a multi-sensor medical device with at least seven sensors, a secure cloud-based platform, and an interactive telehealth module. The device preprocesses and securely transmits patient information to the cloud platform, where an ensemble of deep learning models analyzes the data to generate ranked potential diagnoses with likelihood scores. The telehealth module facilitates communication between providers, patients, and the cloud platform, presenting visualizations and receiving feedback. The system continuously updates and fine-tunes its models using incremental learning algorithms, adapting to new data while retaining previous knowledge. It also generates alerts for providers and patients when deviations from normal physiological patterns are detected, accompanied by explainable AI visualizations.","['A61B5/0261', 'A61B5/0022', 'A61B5/1171', 'A61B5/7267', 'A61B5/746', 'G06Q10/04', 'G06Q10/06', 'G06Q10/10', 'G06Q30/018', 'G06Q30/0269', 'G06Q30/0271', 'G06Q50/01', 'G06Q50/22', 'G06Q50/265', 'G06V10/82', 'G06V40/14', 'G06V40/18', 'G06V40/197', 'G16H20/00', 'G16H50/20', 'A61B5/7264', 'G06Q2220/00']"
CN108629687B,"Anti-money laundering method, device and equipment","The embodiment of the specification discloses an anti-money laundering method, an anti-money laundering device and anti-money laundering equipment. Through the model obtained by pre-training, the relevant characteristics of the user are automatically recognized, the user types are classified, the auditing efficiency is improved, and full-automatic auditing can be realized when the recognition accuracy reaches a certain degree.","['G06Q40/00', 'G06Q40/04']"
WO2022083784A1,Road detection method based on internet of vehicles,"Disclosed is a road detection method based on the Internet of Vehicles. The method is applied to a vehicular end, and comprises: acquiring target road images photographed by image collection ends; inputting the target road images into an improved YOLOv3 network, and performing feature extraction by using a densely connected backbone network, so as to obtain x feature maps of different scales, x being a natural number greater than or equal to 4; performing top-to-bottom densely connected feature fusion on the x feature maps of different scales by using an improved FPN network, so as to obtain prediction results corresponding to various scales; and acquiring attribute information of the target road images on the basis of all prediction results, the attribute information comprising positions and categories of targets in the target road images. The improved YOLOv3 network is formed after changing, on the basis of a YOLOv3 network, residual modules in the backbone network into dense-connection modules, increasing scales of feature extraction, optimizing a feature fusion means of an FPN network, performing pruning, and guiding network recovery processing in combination with knowledge distillation.","['G06V20/588', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/082', 'G06N5/02', 'G06V10/255', 'G06V10/454', 'G06V10/462', 'G06V10/75', 'G06V10/762', 'G06V10/806', 'G06V10/82', 'G06V10/95', 'G06V20/58', 'H04L12/40', 'H04L67/12', 'G06V2201/08', 'H04L2012/40273']"
CN111652852B,"Product surface defect detection method, device and equipment","The invention provides a method, a device and equipment for detecting surface defects of a product, comprising the following steps: acquiring an image and determining whether the image is an image to be detected, which needs to be detected for the specified type of defects; if yes, performing sliding sampling on the image to be detected by utilizing a sliding window through a pre-trained defect detection model, performing defect detection on a sampled window area, and outputting a window area position mark with defects in the image to be detected; image segmentation is carried out on the window area with the defects by utilizing an image segmentation algorithm, so that outline areas of all defects in the window area with the defects are obtained; and connecting adjacent contour areas through an area growth algorithm to obtain the shape and the number of defects in the image to be detected. The invention can carry out sliding sampling detection on the image, and solves the problems that the prior art is time-consuming and labor-consuming, can not detect tiny defects on the surface and has poor positioning property.","['G06T7/0004', 'G06N3/045', 'G06V10/25', 'G06V10/267', 'G06T2207/30124', 'Y02P90/30']"
AU2018203274B2,Training an RGB-D classifier with only depth data and privileged information,"TRAINING AN RGB-D CLASSIFIER WITH ONLY DEPTH DATA AND PRIVILEGED INFORMATION Embodiments of the present invention provide a computer-implemented method for training an RGB-D classifier for a scene classification task. The method receives task-relevant labeled depth data, task-irrelevant RGB-D data, and a given trained representation in RGB. The method simulates an RGB representation using only the task-irrelevant RGB-D data. The method builds a joint neural network using only the task-irrelevant RGB-D data and the task relevant labeled depth data.","['G06V10/82', 'G06F18/214', 'G06F18/24', 'G06F18/25', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V10/80', 'G06V20/64']"
EP4220575A1,Multimodal multitask machine learning system for document intelligence tasks,"Multimodal multitask machine learning system for document intelligence tasks includes a feature extractor processing token values obtained from a document to obtain features, and a token extraction head classifying, using the features, the token values to obtain classified tokens. The classified tokens are aggregated into entities. A document classification model is executed on the features to classify the document and obtain a document label prediction. Further a confidence head model applying the document label prediction processes the entities to obtain a result.","['G06V30/413', 'G06V10/82', 'G06N3/084', 'G06V30/10', 'G06V30/224', 'G06V30/41', 'G06V30/412']"
US11742073B2,Methods and devices for grading a medical image,"Method and system for grading a medical image. For example, a system for grading a medical image comprising a grading network configured to provide a grading result corresponding to the medical image based on at least the medical image and/or a list of lesion candidates generated by a lesion identification network.","['G16H50/20', 'G16H30/40', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T7/0012', 'G16H50/30', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06T2207/30096']"
US11646492B2,Cellular system,A system includes one or more antennas and a processor to communicate with a predetermined target using 5G or 6G protocols.,"['H01Q3/46', 'F21S8/086', 'G06F18/24133', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V40/20', 'H01Q1/246', 'H01Q1/44', 'H01Q21/205', 'H01Q21/26', 'H01Q21/28', 'H04L67/12', 'H04L67/52', 'H04L67/535', 'H04L69/22', 'H04W4/40', 'F21W2131/103', 'G06N20/10', 'G06V40/172', 'G06V40/25', 'G10L25/51', 'H04B17/309', 'H04L67/10', 'H04W4/70']"
US10192163B2,Audio processing method and apparatus based on artificial intelligence,"The present disclosure discloses an audio processing method and apparatus based on artificial intelligence. A specific embodiment of the method comprises: converting a to-be-processed audio to a to-be-processed picture; extracting a content characteristic of the to-be-processed picture; determining a target picture based on a style characteristic and the content characteristic of the to-be-processed picture, the style characteristic being obtained from a template picture converted from a template audio; and converting the target picture to a processed audio. The present embodiment achieves the processing effect that the processed audio takes a template audio style, improves the efficiency and the flexibility of audio processing, while without changing the content of the to-be-processed audio.","['G10L19/00', 'H04N1/00204', 'G06F16/50', 'G06F16/53', 'G06F16/60', 'G06F16/63', 'G06F17/30244', 'G06F17/3074', 'G06K9/00013', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06N3/10', 'G06V10/44', 'G10L19/02', 'H04N1/00129']"
TWI790410B,"Graphics processing unit, data processing system and method for accelerating machine learning operations","One embodiment provides for a compute apparatus to perform machine learning operations, the compute apparatus comprising instruction decode logic to decode a single instruction including multiple operands into a single decoded instruction, the multiple operands having differing precisions and a general-purpose graphics compute unit including a first logic unit and a second logic unit, the general-purpose graphics compute unit to execute the single decoded instruction, wherein to execute the single decoded instruction includes to perform a first instruction operation on a first set of operands of the multiple operands at a first precision and a simultaneously perform second instruction operation on a second set of operands of the multiple operands at a second precision.","['G06F9/3887', 'G06F13/4068', 'G06F13/4282', 'G06F15/80', 'G06F16/2425', 'G06F9/3001', 'G06F9/30014', 'G06F9/30036', 'G06F9/30094', 'G06F9/30109', 'G06F9/30112', 'G06F9/3016', 'G06F9/3851', 'G06F9/3888', 'G06F9/38885', 'G06F9/3891', 'G06F9/50', 'G06N20/00', 'G06N20/10', 'G06N3/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06N5/04', 'G06T1/20', 'G06F2213/0026', 'Y02D10/00']"
US12014265B2,"Machine learning sparse computation mechanism for arbitrary neural networks, arithmetic compute microarchitecture, and sparsity for training mechanism","An apparatus to facilitate processing of a sparse matrix for arbitrary graph data is disclosed. The apparatus includes a graphics processing unit having a data management unit (DMU) that includes a scheduler for scheduling matrix operations, an active logic for tracking active input operands, and a skip logic for tracking unimportant input operands to be skipped by the scheduler. Processing circuitry is coupled to the DMU. The processing circuitry comprises a plurality of processing elements including logic to read operands and a multiplication unit to multiply two or more operands for the arbitrary graph data and customizable circuitry to provide custom functions.","['G06N3/063', 'G06F16/9024', 'G06F17/16', 'G06F18/214', 'G06F7/483', 'G06F7/52', 'G06F9/4843', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06T15/005', 'G06F2207/382', 'G06N3/047']"
CN111630356B,Method for characterizing a sample using a neural network,"The invention relates to a method for characterizing a sample to be characterized using a set of spectral images of the sample, which have been acquired beforehand, in particular by infrared thermal imaging or spectral imaging, and at least one neural network, comprising the following steps: -generating from the spectral image at least one value volume of values of observed parameters for a plurality of coordinates and a plurality of acquisitions of pixels of the image, -extracting from the data volume a set of at least one input data corresponding to values of the observed parameters for pixels having the same coordinates according to different acquisitions, wherein at least one conversion function has been applied to the values, -training the at least one neural network using the input data in order to extract at least one feature of the sample to be characterized.","['G01J3/2823', 'G01J3/28', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T7/0004', 'G01J2003/2826', 'G01N2021/8883', 'G01N2021/8887', 'G06N20/10', 'G06N3/048', 'G06T2207/10024', 'G06T2207/10036', 'G06T2207/10048', 'G06T2207/20084', 'G06T2207/30188']"
US9263040B2,Method and system for using sound related vehicle information to enhance speech recognition,"An audio signal may be received, in a processor associated with a vehicle. Sound related vehicle information representing one or more sounds may be received by the processor. The sound related vehicle information may or may not include an audio signal. A speech recognition process or system may be modified based on the sound related vehicle information.","['G10L15/20', 'G10L15/01', 'G10L2015/226', 'G10L21/0208']"
CN108694694B,Abstract library for enabling scalable distributed machine learning,"One embodiment provides a non-transitory machine-readable medium storing instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising: an interface is provided for defining a neural network using machine learning domain-specific terms, wherein the interface enables selection of a neural network topology and abstracts low-level communication details of distributed training of the neural network.","['G06T1/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/60']"
US9363386B2,Acoustic echo cancellation based on ultrasound motion detection,A method includes receiving an ultrasound signal at an ultrasound receiver from an ultrasound transmitter. The method also includes detecting movement of at least one object based on the received ultrasound signal and at least one previously received ultrasound signal. The method further includes modifying a parameter of an acoustic echo canceller in response to the detected movement.,"['H04M9/082', 'G06F1/1694']"
CN111340922B,Positioning and mapping method and electronic device,"A method and an electronic device for positioning and map construction are provided. The method may comprise: acquiring an image of a current frame; and determining the equipment pose corresponding to the current frame and the current global sparse map based on the image of the current frame. The method and the electronic device can improve the accuracy of the determined pose of the device and the map, and have robustness.","['G06T15/005', 'G06T7/593', 'G06N3/045', 'G06T7/11', 'G06T7/33', 'G06T7/73', 'H04N13/271', 'G06T2207/10028', 'G06T2207/30244']"
US12361219B2,Context tag integration with named entity recognition models,"Techniques are provided for using context tags in named-entity recognition (NER) models. In one particular aspect, a method is provided that includes receiving an utterance, generating embeddings for words of the utterance, generating a regular expression and gazetteer feature vector for the utterance, generating a context tag distribution feature vector for the utterance, concatenating or interpolating the embeddings with the regular expression and gazetteer feature vector and the context tag distribution feature vector to generate a set of feature vectors, generating an encoded form of the utterance based on the set of feature vectors, generating log-probabilities based on the encoded form of the utterance, and identifying one or more constraints for the utterance.","['G06F40/295', 'G06F40/205', 'G06F40/242', 'G06F40/279', 'G06F40/35', 'G06F40/40', 'G06N3/0455', 'G06N3/08', 'G06N5/041', 'G06V30/19147']"
US10867416B2,Harmonizing composite images using deep learning,"Methods and systems are provided for generating harmonized images for input composite images. A neural network system can be trained, where the training includes training a neural network that generates harmonized images for input composite images. This training is performed based on a comparison of a training harmonized image and a reference image, where the reference image is modified to generate a training input composite image used to generate the training harmonized image. In addition, a mask of a region can be input to limit the area of the input image that is to be modified. Such a trained neural network system can be used to input a composite image and mask pair for which the trained system will output a harmonized image.","['H04N1/6066', 'G06F18/2413', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06T11/00', 'G06V10/26', 'G06V10/454', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20221']"
US12367248B2,Hardware-aware machine learning model search mechanisms,"The present disclosure is related to framework for automatically and efficiently finding machine learning (ML) architectures that generalize well across multiple artificial intelligence (AI) and/or ML domains, AI/ML tasks, and datasets. The ML architecture search framework accepts a list of tasks and corresponding datasets as inputs, and may also include relevancy scores/weights for each item in the input. A combined performance metric is generated, where this combined performance metric quantifies the performance of the ML architecture across all the specified AI/ML domains, AI/ML tasks, and datasets. The system then performs a multi-objective ML architecture search with the combined performance metric, along with hardware-specific performance metrics as the objectives. Other embodiments may be described and/or claimed.","['G06N3/086', 'G06F16/953', 'G06N5/01']"
US12197498B2,"Method, apparatus, and system for determining pose","A method, an apparatus, and a medium for determining a pose are provided. The method includes: receiving a query image sent by a terminal and N text fields included in the query image; determining a candidate reference image based on a prestored correspondence between a reference image and a text field and based on the N text fields; determining an initial pose of the terminal at the first location based on the query image and the candidate reference image; and sending the initial pose to the terminal. According to the method, a candidate reference image is queried based on a text field, and an initial pose of a terminal is obtained based on a candidate reference image with higher accuracy. Therefore, the obtained pose is more accurate.","['G06F16/587', 'G06V20/62', 'G06F16/532', 'G06F16/9537', 'G06F18/22', 'G06T7/0002', 'G06T7/11', 'G06T7/74', 'G06V10/24', 'G06V10/74', 'G06V20/63', 'G06T2207/10004', 'G06T2207/20084', 'G06T2207/30168', 'G06T2207/30176', 'G06T2207/30184', 'G06T2207/30244']"
US12136213B2,Method based on image conditioning and preprocessing for human embryo classification,"The invention relates to a method that allows a set of embryos to be ranked on the basis of ploidy potential and/or pregnancy generation potential, to aid the process of selecting embryos for transfer in an in-vitro fertilisation procedure. The method measures properties or characteristics of the entire blastocyst; extracts characteristics by identifying different cell types, mainly blastocyst structures and patterns, without extracting characteristics of the first cell divisions and the behaviour thereof over time; and predicts the prognosis of pregnancy and/or ploidy (result of genetic study and successful implantation), using micrographs standardised for the management thereof and by means of sequential preprocessing and machine learning algorithms implemented in a computer in order to rank the potential of a set of embryos, to obtain a successful, live, full-term pregnancy.","['G06T7/0012', 'G06V10/16', 'G06V10/26', 'G06N20/00', 'G06N3/0464', 'G06T2207/10056', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30044', 'G06V2201/03']"
CN109857990B,A financial announcement information extraction method based on document structure and deep learning,"The invention relates to a financial bulletin information extraction method based on document structure and deep learning, and belongs to the technical field of information extraction. The method comprises the following steps: s1: generating a document structure tree; s2: extracting node information: designing a convenient node information searching method based on a document structure tree, and extracting node information of the tree by using rules; s3: and (3) extracting an information sentence: for the extracted node information, a sentence triggering word set is defined, and on the basis of the sentence triggering word set, a local sentence structure rule containing the triggering word set is expanded, so that information sentences meeting the rule are extracted; s4: training word vectors: pre-training word vectors of the context, and training character word vectors by using CNN; s5: extracting structured information: and constructing a Bi-LSTM-CRF-based deep learning model, and training the model for field identification. The invention can extract various required structured information rapidly and efficiently under the condition of less manual intervention.",[]
CN110148142B,"Training method, device and equipment of image segmentation model and storage medium","The application provides a training method, a device, equipment and a storage medium of an image segmentation model. The method comprises the following steps: training an initial image segmentation model by adopting a source domain sample to obtain a pre-trained image segmentation model; extracting a prediction segmentation result of a source domain image and a prediction segmentation result of a target domain image through a pre-trained image segmentation model; training a first discriminator by adopting a prediction segmentation result of the source domain image and a prediction segmentation result of the target domain image; training a second discriminator by adopting a prediction segmentation result of the source domain image and a standard segmentation result of the source domain image; and retraining the pre-trained image segmentation model according to the loss function of the pre-trained image segmentation model, the countermeasure loss function of the first discriminator and the countermeasure loss function of the second discriminator, and repeating the loop training until convergence to obtain the trained image segmentation model, so that the segmentation result of the target domain image is more accurate.","['G06T7/0012', 'G06F18/241', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/11', 'G06T7/162', 'G06T7/174', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/048', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/031']"
US11501563B2,Image processing method and system,"A neural network-based image processing method may include receiving, by a trained neural network, a first image including a first object, the first object being partially covered by a second object. The method may also include generating, by the trained neural network, a second image based on the first image. The second image is a representation of the first image with the second object substantially removed, and the first object is a human face.","['G06N3/084', 'G06F18/2148', 'G06F18/217', 'G06F18/25', 'G06K9/6257', 'G06K9/6262', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06V10/80', 'G06V10/82', 'G06V40/165', 'G06V40/168', 'G06V40/171', 'G06F18/214']"
US11883157B2,"System, sensor and method for monitoring health related aspects of a patient",A method is provided for detecting an undesirable event or condition in a patient. The method may comprise receiving a first input signal from an UWB radar configured to monitor an environment occupied by the patient and including information representative of the patient's motion. Data derived from the first input signal is processed using a pattern recognition model to detect and classify patterns in the data derived from the first input signal as indicative or predictive of an undesirable event or condition involving the patient. When a pattern is classified as indicative or predictive of an undesirable event or condition in the patient an alarm is issued. A log of data derived from the first input signal and associated with a detection of a pattern classified as indicative or predictive of an undesirable event enables further machine learning in order to create an updated pattern recognition model based on individual patient behavior.,"['A61B5/1115', 'G16H50/20', 'A61B5/1117', 'A61B5/4094', 'A61B5/7264', 'A61B5/7275', 'A61B5/746', 'A61B5/747', 'G01S13/66', 'G06N20/00', 'G16H40/20', 'G16H40/67', 'G16H50/70', 'A61B2562/02']"
CN111656357B,"Modeling method, device and system for ophthalmic disease classification model","A modeling method, apparatus and system for an ophthalmic disease classification model, the method comprising creating an ophthalmic image dataset and an ophthalmic non-image disease diagnosis questionnaire dataset (S101); training a first neural network model with the ophthalmic image dataset to obtain a first classification model (S102); training a second classification model using the ophthalmic non-image disease diagnosis questionnaire dataset (S103); and fusing the first classification model and the second classification model to obtain a target classification network model, and taking a test result output based on the target classification network model as a diagnosis result obtained by diagnosing the eye diseases (S104). The method can integrate clinical and ophthalmic images and assist patient personal information to carry out ophthalmic diagnosis, can enable an artificial intelligence technology to better assist ophthalmic disease diagnosis modeling, effectively improves the intellectualization and the accuracy of ophthalmic full-class disease diagnosis modeling, and improves the diagnosis effect.","['G06N3/08', 'A61B3/12', 'A61B3/14', 'G06F18/214', 'G06F18/2178', 'G06F18/25', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0012', 'G06V10/764', 'G06V10/80', 'G06V10/82', 'G06V20/698', 'G16H10/20', 'G16H50/20', 'G06N20/20', 'G06T2207/20081', 'G06T2207/20084']"
US11983210B2,Methods and systems for generating summaries given documents with questions and answers,"Described herein are systems and methods to enable generation of high-quality summaries of documents that have questions and answers. To help summarize such documents, parsing methods are disclosed that account for different document formats. Question-answer groups are transformed into declarative sentences. Sentence correction can be applied to the declarative sentences. Candidate summary sentences are identified from the declarative sentences, and a subset of the candidate summary sentences are selected for inclusion in a summary. Aspects, segmentation, and augmentation can help with generation and tailoring of summaries.","['G06F16/345', 'G06F16/335', 'G06F16/338', 'G06F16/35', 'G06F40/216', 'G06F40/289', 'G06F40/35', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06F40/42', 'G06F40/58']"
WO2020119030A1,"Model training method, device and equipment used for answering questions and storage medium","A model training method, device and equipment used for answering questions, and a storage medium, which are applied to the technical field of deep learning and are used for solving the problem of the rate of answering questions queried by a user being low. The present method comprises: whenever an answer to a question raised by a user is fed back by means of a target deep learning model, detecting whether the user has submitted negative evaluation information regarding the answer (101); if detected that the user submits negative evaluation information regarding the answer, obtaining an evaluation question corresponding to the negative evaluation information (102); when the number of obtained evaluation questions reaches a preset first number threshold, performing unsupervised text clustering on each evaluation question until a preset condition is met, and then obtaining each question set by clustering (103); determining a vector center of each question set (104); for each question set, respectively calculating the distance between the vector center of the question set and the vector center of each preset question group (105); if the smallest distance obtained by calculation is less than a preset distance threshold value, combining said question set with a preset question group corresponding to the smallest distance (106); if the smallest distance obtained by calculation is greater than or equal to the preset distance threshold, determining the question set to be a new preset question group (107); and re-training the target deep learning model by employing each updated preset question group, so as to obtain a trained target deep learning model (108).","['G06F16/332', 'G06F16/35']"
WO2020125623A1,"Method and device for live body detection, storage medium, and electronic device","A method and device for live body detection, a storage medium, and an electronic device. The method comprises: first, photographing via a monocular camera a two-dimensional color image of a face to be detected (101), then, inputting the two-dimensional color image into a pretrained depth estimation model for depth estimation to produce a corresponding depth image (102), and finally, inputting the two-dimensional color image and the depth image corresponding thereto into a pretrained live body detection model for live body detection to produce a detection result (103).","['G06V40/161', 'G06V40/45']"
US11861888B2,Logo recognition in images and videos,"Accurately detection of logos in media content on media presentation devices is addressed. Logos and products are detected in media content produced in retail deployments using a camera. Logo recognition uses saliency analysis, segmentation techniques, and stroke analysis to segment likely logo regions. Logo recognition may suitably employ feature extraction, signature representation, and logo matching. These three approaches make use of neural network based classification and optical character recognition (OCR). One method for OCR recognizes individual characters then performs string matching. Another OCR method uses segment level character recognition with N-gram matching. Synthetic image generation for training of a neural net classifier and utilizing transfer learning features of neural networks are employed to support fast addition of new logos for recognition.","['G06V10/82', 'G06F18/24', 'G06T7/11', 'G06T7/337', 'G06T7/60', 'G06V10/462', 'G06V10/764', 'G06T2207/20052', 'G06V10/50', 'G06V2201/09']"
US10909647B2,Damage data propagation in predictor of structural damage,"Methods, systems, and computer programs are presented for updating estimates of damage caused by a disaster based on newly acquired damage data. One method includes operations for generating block damage estimates in a geographical region after an event (e.g., a natural disaster such as an earthquake or a tornado), accessing input damage data for one or more buildings within a first block, and adjusting the block damage estimate of the first block based on the input damage data. One or more related blocks within a threshold distance from the first block are identified, and for each related block, a respective propagation coefficient is determined based on a comparison of features of the first block with features of each related block. The block damage estimate for the one or more related blocks is recalculated based on the respective propagation coefficient.","['G06Q50/265', 'G06Q30/0283', 'G06Q50/16']"
KR102271070B1,Method and apparatus for determining mixed coal combination,"The present invention relates to a method and an apparatus for determining a mixed coal combination which use data collected from a coal-fired power plant to establish a combustion result prediction model of a boiler of the coal-fired power plant, and determine an optimal mixed coal combination satisfying an objective function and a constraint based on the combustion result prediction model. According to an embodiment of the present invention, the method for determining a mixed coal combination comprises: a step of loading a boiler combustion result prediction model for a coal-fired power plant; a step of selecting a boiler combination becoming a target of mixed coal combination determination among a plurality of boilers provided in the coal-fired power plant; a step of optimizing the boiler combustion result prediction model for the selected boiler combination; a step of setting an objective function as an operating issue to be optimized through a mixed coal combination among operating issues for the coal-fired power plant; a step of setting a constraint to be reflected when determining the mixed coal combination; and a step of determining a coal type and a mixed coal ratio satisfying the objective function and the constraint as an optimal mixed coal combination based on the optimized boiler combustion result prediction model. According to the present invention, the boilers of the coal-fired power plant can be operated in an optimal state by determining the coal type and the mixed coal ratio satisfying the objective function and the constraint as the optimal mixed coal combination based on the boiler combustion result prediction model.","['G05B13/026', 'F23K3/00', 'F23N1/002', 'G06N3/02', 'G06Q50/06', 'F23K2201/50', 'F23N2223/08', 'F23N2223/48', 'F23N2239/02', 'Y02E40/70', 'Y04S10/50']"
US12314861B2,Systems and methods for semi-supervised learning with contrastive graph regularization,"Embodiments described herein provide an approach (referred to as “Co-training” mechanism throughout this disclosure) that jointly learns two representations of the training data, their class probabilities and low-dimensional embeddings. Specifically, two representations of each image sample are generated: a class probability produced by the classification head and a low-dimensional embedding produced by the projection head. The classification head is trained using memory-smoothed pseudo-labels, where pseudo-labels are smoothed by aggregating information from nearby samples in the embedding space. The projection head is trained using contrastive learning on a pseudo-label graph, where samples with similar pseudo-labels are encouraged to have similar embeddings.","['G06V10/82', 'G06F18/21375', 'G06F18/2155', 'G06F18/22', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/7753']"
US9633282B2,Cross-trained convolutional neural networks using multimodal images,"Embodiments of a computer-implemented method for training a convolutional neural network (CNN) that is pre-trained using a set of color images are disclosed. The method comprises receiving a training dataset including multiple multidimensional images, each multidimensional image including a color image and a depth image; performing a fine-tuning of the pre-trained CNN using the depth image for each of the plurality of multidimensional images; obtaining a depth CNN based on the pre-trained CNN, wherein the depth CNN is associated with a first set of parameters; replicating the depth CNN to obtain a duplicate depth CNN being initialized with the first set of parameters; and obtaining a depth-enhanced color CNN based on the duplicate depth CNN being fine-tuned using the color image for each of the plurality of multidimensional images, wherein the depth-enhanced color CNN is associated with a second set of parameters.","['G06K9/6256', 'G06V10/56', 'G06F18/214', 'G06K9/4652', 'G06K9/48', 'G06K9/6232', 'G06V10/449', 'G06V20/647', 'G06V30/194']"
CN114168709B,A text classification method based on lightweight pre-trained language model,"The invention discloses a text classification method based on a lightweight pre-training language model, aiming at improving the text classification accuracy on the premise of less occupied resources. The technical scheme is as follows: constructing a text classification model based on a pre-training language model, wherein the text classification model comprises a teacher model and a student model; processing the GLUE data set into a format required by a text classification model for classification; initializing parameters of the teacher model, and finely adjusting the teacher model by adopting the processed GLUE data set; secondly, initializing parameters of the student model, and obtaining network weight parameters of the student model by adopting a GLUE data set and using a teacher model subjected to light weight fine tuning by a knowledge distillation method; initializing a student model by using a student model network weight parameter to obtain a lightweight student model; and finally, carrying out text classification on the text input by the user by using a lightweight student model to obtain a classification result. The invention realizes high accuracy of text classification on the premise of less occupied resources.","['G06F16/35', 'G06F16/3344', 'G06F18/214']"
US20210019657A1,"Fraud detection and risk assessment method, system, device, and storage medium","The present application provides a fraud detection and risk assessment method, a system, a device, and a computer readable storage medium. Said method comprises the following steps: acquiring original data of a client user; using a data processing algorithm to extract characteristic data from the original data; inputting the characteristic data into a pre-trained machine learning model matching the characteristic data, generating a model output result, and uploading same onto a server; and outputting a fraud detection and risk assessment result using a risk control decision engine in conjunction with the model output result, historical data associated with the client user, and third party data. By using the present application, the computing capability of a client device can be fully utilized, reducing the computing pressure on the server. As the client does not need to upload the original data to the server, the present application can also reduce the data transmission pressure on the client and the server and reduce the risk of leakage of the user's private data and security information.","['G06Q10/0635', 'G06Q50/265', 'G06F18/214', 'G06F18/22', 'G06F8/71', 'G06K9/6215', 'G06K9/6256', 'G06N20/00', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G06Q30/0185', 'G06V10/764', 'H04L63/1441', 'H04L67/34']"
US10950352B1,"System, computer-readable storage medium and method of deep learning of texture in short time series","A computer-readable storage medium storing program instructions to perform a method of classification of short time series in order to detect a neurodegenerative disorder. The method includes receiving a plurality of sensor data collected from subjects with and without the neurodegenerative disorder over a period of a few seconds as the short time series, generating phase-space vectors from the plurality of sensor data in which each vector is a state of a dynamical system in space and time, transforming the phase-space vectors into a grayscale image representing recurrences of a state-space vector in the same area of the phase space, extracting temporal texture features of the grayscale image to obtain a multi-dimensional time series; inputting the multidimensional time series, without the grayscale image, to the Long Short Term Memory (LSTM) network, and classifying, by the LSTM network, the plurality of the sensor data as the neurodegenerative disorder or not.","['A61B5/1128', 'A61B5/4082', 'A61B5/7267', 'G06F18/241', 'G06F3/011', 'G06F3/017', 'G06K9/6232', 'G06K9/6268', 'G06N3/043', 'G06N3/0436', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06V10/82', 'G16H20/70', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G06T2207/20021']"
US20190147296A1,Creating an image utilizing a map representing different classes of pixels,"A method, computer readable medium, and system are disclosed for creating an image utilizing a map representing different classes of specific pixels within a scene. One or more computing systems use the map to create a preliminary image. This preliminary image is then compared to an original image that was used to create the map. A determination is made whether the preliminary image matches the original image, and results of the determination are used to adjust the computing systems that created the preliminary image, which improves a performance of such computing systems. The adjusted computing systems are then used to create images based on different input maps representing various object classes of specific pixels within a scene.","['G06K9/6257', 'G06V10/454', 'G06F18/2148', 'G06F18/24133', 'G06K9/6857', 'G06K9/726', 'G06T1/20', 'G06T11/001', 'G06V10/82', 'G06V30/19173', 'G06V30/2504', 'G06V30/274']"
US11978452B2,Handling explicit invocation of chatbots,"The present disclosure relates to chatbot systems, and more particularly, to techniques for identifying an explicit invocation of a chatbot and determining an input for the chatbot being invoked. In certain embodiments, explicit invocation analysis involves detecting an invocation name in an utterance. The invocation name is an identifier assigned to a particular chatbot. In response to detection of the invocation name, the utterance is refined for input to the particular chatbot by determining which parts of the utterance, if any, contain relevant information for the particular chatbot and generating a new utterance, using the relevant parts of the utterance, for processing by the particular chatbot. The refining can involve removal of a portion of the utterance associated with the invocation name.","['G10L15/26', 'G06F40/211', 'G06F40/263', 'G06F40/284', 'G06F40/295', 'G06F40/30', 'G06F40/35', 'G06N20/00', 'G06N5/041', 'G10L15/02', 'G10L15/22', 'H04L51/02', 'H04L51/18']"
TWI864288B,Automatic optimization of an examination recipe,"There is provided a system and method of automatic optimization of an examination recipe. The method includes obtaining one or more inspection images each representative of at least a portion of the semiconductor specimen, the one or more inspection images being indicative of respective defect candidates selected from a defect map using a first classifier included in the examination recipe; obtaining label data respectively associated with the one or more inspection images and informative of types of the respective defect candidates; extracting inspection features characterizing the one or more inspection images; retraining the first classifier using the first features and the label data, giving rise to a second classifier; and optimizing the examination recipe by replacing the first classifier with the second classifier; wherein the optimized examination recipe is usable for examining a subsequent semiconductor specimen.","['G01N21/9501', 'G01N21/8851', 'G01N21/956', 'G03F7/7065', 'G03F7/706841', 'G06T7/0004', 'G06T7/001', 'H01L22/12', 'G01N2021/8854', 'G01N2021/8883', 'G01N2021/8887', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30148']"
CN111191835B,IES Incomplete Data Load Forecasting Method and System Based on C-GAN Migration Learning,"The invention provides an IES incomplete data load prediction method and system based on C-GAN transfer learning. Firstly, original sample data are collected and normalized, then the sample data after normalization are extracted by adopting a depth variation self-coding network, the extracted sample features are input into a first constructed C-GAN generator, incomplete sample data are expanded when the Nash equilibrium is achieved by the generator and the discriminator game, an expanded sample data set is input into a second constructed conditional C-GAN generator, electric, gas and heat loads are predicted in parallel when the Nash equilibrium is achieved by the generator and the discriminator game, prediction precision is judged by the discriminator based on the C-GAN, and the prediction precision of comprehensive energy load prediction is continuously corrected and improved in the Nash equilibrium process is achieved by the generator and the discriminator game.","['G06Q10/04', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'Y04S10/50']"
US20220414237A1,Secure decentralized control of network access to ai models and data,"Decentralized database technology is applied to decentralized artificial intelligence (AI) information enabling collaborative AI techniques to enhance the performance of AI models and gain new insights with larger and/or better curated data sets. AI information from multiple independent sources is linked together and synthesized to render the AI information searchable, discoverable, accessible, and traceable, while also ensuring that information remains under its source's control over its lifetime, e.g., controlling the conditions under which other entities may access which pieces of AI information at a particular time.","['G06F21/604', 'G06N20/00']"
US10932847B2,Detecting short circuits in electrosurgical medical devices,A control circuit for use with an electrosurgical system is disclosed. The control circuit is programmed to provide an electrosurgical signal comprising a plurality of pulses to first and second electrodes and receive a first reading of an impedance between the first and second electrodes. The control circuit is programmed to receive a second reading of the impedance between the first and second electrodes. The control circuit is programmed to determine a difference between the first and second readings and determine that a short circuit is present between the first and second electrodes based on a magnitude of the difference between the first reading and the second reading. The control circuit is programmed to generate a signal indicating the short circuit between the first and second electrodes.,"['A61B18/1445', 'A61B18/1206', 'A61B18/18', 'A61B2017/00154', 'A61B2018/00642', 'A61B2018/0069', 'A61B2018/00875', 'A61B2018/00898', 'A61B2018/162']"
US12211117B2,Data parallelism and halo exchange for distributed machine learning,"One embodiment provides for a method of transmitting data between multiple compute nodes of a distributed compute system, the method comprising multi-dimensionally partitioning data of a feature map across multiple nodes for distributed training of a convolutional neural network; performing a parallel convolution operation on the multiple partitions to train weight data of the neural network; and exchanging data between nodes to enable computation of halo regions, the halo regions having dependencies on data processed by a different node.","['G06T1/20', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06T1/60', 'G06N3/044', 'G06T2207/20081', 'G06T2207/20084']"
CN112734723B,Multi-source data-oriented breast tumor image classification prediction method and device,"The invention provides a multisource data-oriented breast tumor image classification prediction method, which is used for acquiring multisource data of a breast tumor image to be detected, wherein the multisource data comprises labeled image data and unlabeled image data; semi-supervised training is carried out on a preset coder-decoder network segmentation model by using multi-source data to obtain an ROI segmentation result; and carrying out feature extraction on the ROI segmentation result to obtain an image geometric texture feature vector, inputting the ROI segmentation result into an encoder part in a teacher-student network segmentation model to obtain a depth-learned image feature vector, and carrying out classification prediction by using a cascade random forest classification model trained in advance by combining a non-image data vector obtained by non-image data preprocessing to obtain a corresponding classification result which is malignant or benign. By implementing the method, the heterogeneity among different source data sets can be reduced, and multi-source data breast tumor image classification prediction can be realized.","['G06T7/0012', 'G06F18/214', 'G06F18/24323', 'G06F18/253', 'G06N3/006', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/30068', 'G06T2207/30096']"
US11720647B2,Synthetic training data generation for improved machine learning model generalizability,"Systems and techniques that facilitate synthetic training data generation for improved machine learning generalizability are provided. In various embodiments, an element augmentation component can generate a set of preliminary annotated training images based on an annotated source image. In various aspects, a preliminary annotated training image can be formed by inserting at least one element of interest or at least one background element into the annotated source image. In various instances, a modality augmentation component can generate a set of intermediate annotated training images based on the set of preliminary annotated training images. In various cases, an intermediate annotated training image can be formed by varying at least one modality-based characteristic of a preliminary annotated training image. In various aspects, a geometry augmentation component can generate a set of deployable annotated training images based on the set of intermediate annotated training images. In various instances, a deployable annotated training image can be formed by varying at least one geometric characteristic of an intermediate annotated training image. In various embodiments, a training component can train a machine learning model on the set of deployable annotated training images.","['G06F18/2148', 'G06F18/214', 'G06F18/2163', 'G06N20/00', 'G06N20/10', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N5/048', 'G06N7/01', 'G06T11/00', 'G06V10/774', 'G06V10/776', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06V2201/03']"
US20200187841A1,System and Method for Measuring Perceptual Experiences,"There is provided a method for determining perceptual experiences. The method comprises obtaining a plurality of signals acquired by a measurement device comprising a plurality of sensors positioned to measure brain activity of users being measured by the measurement device; providing the plurality of signals, without pre-processing, to a processing system comprising at least one deep learning module, the at least one deep learning module being configured to process the signals to generate at least one capability, wherein combinations of one or more of the at least one capability form the perceptual experiences; and providing an output corresponding to a combination of one or more of the at least one capability to an application utilizing the corresponding perceptual experience.","['G16H50/20', 'A61B5/165', 'A61B5/0022', 'A61B5/04842', 'A61B5/04845', 'A61B5/11', 'A61B5/377', 'A61B5/378', 'A61B5/38', 'A61B5/4806', 'A61B5/6803', 'A61B5/7267', 'G06F3/015', 'G06F3/017', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G16H20/70', 'H04L67/12', 'A61B5/16', 'A61B5/369', 'G06F2203/011']"
US20220101480A1,Abstraction layers for scalable distributed machine learning,"One embodiment provides for a method of transmitting data between multiple compute nodes of a distributed compute system, the method comprising creating a global view of communication operations to be performed between the multiple compute nodes of the distributed compute system, the global view created using information specific to a machine learning model associated with the distributed compute system; using the global view to determine a communication cost of the communication operations; and automatically determining a number of network endpoints for use in transmitting the data between the multiple compute nodes of the distributed compute system.","['G06T1/20', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/084']"
US12182720B2,"Pattern recognition apparatus, pattern recognition method, and computer-readable recording medium","An apparatus for pattern recognition includes a generator which transforms noisy feature vectors into denoised feature vectors, a discriminator which takes the denoised feature vectors and the original clean feature vectors corresponding to the denoised feature vectors as input and predicts probability for both of the input features of being an original clean feature, classifies the input feature vectors into its corresponding classes, an objective function calculator which calculates generator and discriminator losses using the denoised feature vectors, the clean feature vectors from which the noisy feature vectors have been made, the estimated classes and their true classes, and a Parameter updater which updates parameters of the generator and the discriminator according to loss minimization.","['G06N3/088', 'G06F18/10', 'G06F18/2132', 'G06F18/21343', 'G06F18/2185', 'G06F18/2193', 'G06F18/2411', 'G06F18/24133', 'G06F18/2415', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N20/10', 'G10L17/04', 'G10L17/18', 'G10L17/20']"
TWI846980B,"Computing device, method, graphics processing system, non-transitory machine-readable media, and graphics processor for systolic arithmetic on sparse data",Embodiments described herein provided for an instruction and associated logic to enable a processing resource including a tensor accelerator to perform optimized computation of sparse submatrix operations. One embodiment provides hardware logic to apply a numerical transform to matrix data to increase the sparsity of the data. Increasing the sparsity may result in a higher compression ratio when the matrix data is compressed.,"['G06T9/002', 'G06F9/3877', 'G06F15/8046', 'G06F17/16', 'G06F9/28', 'G06F9/45533', 'G06F9/5027', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/098', 'G06T1/20', 'G06T15/005', 'G06T9/007', 'G06T9/008', 'H04N19/42', 'G06F2009/45579', 'G06F2009/45583', 'G06N3/048', 'G06N3/084']"
CN110929774B,"Classification method, model training method and device for target objects in image","The application provides a classification method, a model training method and a device for target objects in images, belongs to the technical field of computers, and relates to the artificial intelligence and computer vision technologies. According to the method, the feature image of the image to be processed is extracted through the feature extraction model, the region to be classified corresponding to the target object bounding box calibrated in advance in the image to be processed in the feature image is determined, the target object category corresponding to the region to be classified is determined through the image classification model, and the classification result is output. The feature extraction model and the image classification model are obtained by training based on training images, wherein the training images comprise sample targets and background environments where the sample targets are located. The training image comprising the background environment is used for training the feature extraction model and the image classification model, so that the background information in the training image can be fully utilized, and the feature extraction model and the image classification model obtained through training can accurately distinguish the target object from the background, thereby improving the classification accuracy.",['G06F18/24']
US20240243838A1,Systems and methods for adaptive transmit signal quality,"A method by a transmitting node for adapting a transmission mode based on a capability of a receiving node includes obtaining information indicating a capability of the receiving node to receive signals having a certain level of distortion. The transmitting node transmits a signal to the receiving node, the signal transmitted using a transmission mode selected based on the capability of the receiving node.","['H04L1/0001', 'H04L1/0025', 'H04B1/0475']"
TWI853134B,Deep learning based selection of samples for adaptive supersampling,"An apparatus to facilitate deep learning based selection of samples for adaptive supersampling is disclosed. The apparatus includes one or more processing elements to: receive training data comprising input tiles and corresponding supersampling values for the input tiles, wherein each input tile comprises a plurality of pixels, and train, based on the training data, a machine learning model to identify a level of supersampling for a rendered tile of pixels.","['G06T5/70', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N5/02', 'G06T1/20', 'G06T1/60', 'G06T11/40', 'G06T15/00', 'G06T15/005', 'G06T15/06', 'G06T2207/20081', 'G06T2207/20084']"
US20220113790A1,Intent-driven power management,"Various systems and methods for implementing intent-driven power management are described herein. A system includes: a power monitoring unit to collect real-time telemetry of a processor on a compute node; and a power level controller to: receive a power intent for execution of an application on the compute node; configure a power level of the processor of the compute node based on the power intent, the processor to execute the application; set an initial execution priority of the application on the compute node based on the power intent; and modify the initial execution priority based on the power intent and the real-time telemetry of the compute node.","['G06F21/577', 'G06F1/3228', 'G06F1/3296', 'G06F11/3433', 'G06F11/3495', 'G06F21/51', 'G06F9/3875', 'G06F9/44505', 'G06F9/5027', 'H04L41/5003', 'H04L41/5009', 'H04L41/5019', 'H04L41/5025', 'H04L41/5054', 'H04L43/08', 'H04L43/0823', 'H04L47/72', 'H04L47/821', 'H04L47/822', 'H04L47/83', 'H04L63/083', 'H04L63/1433', 'H04L67/1097', 'H04L67/146', 'H04L67/52', 'H04L9/50', 'G06F2201/875', 'G06F2209/503', 'G06F2221/033', 'G06F2221/2135', 'G06N20/00', 'G06Q10/087']"
WO2021249053A1,Image processing method and related apparatus,"An image processing method and a related apparatus, which are applied to an electronic device, the method comprising: acquiring a facial image to be processed, and inputting said facial image into a pretrained target model to obtain a target mask set, the target mask set comprising multiple masks that each correspond to a part of the face (401); according to the target mask set, performing facial parsing on each part of the face in a facial image to be parsed to obtain multiple binary images of multiple channels corresponding to the number of target masks in the target mask set, wherein each channel corresponds to one part of the face, and each binary image corresponds to one color (402); and synthesizing the multiple binary images to obtain a facial parsing result (403), which helps to improve the facial parsing effect.","['G06V40/165', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08']"
US10796394B2,Estimation of damage prevention with building retrofit,"Methods, systems, and computer programs are presented for estimating the differences, due to building retrofitting, in damage caused to a building by an earthquake. One method includes operations for accessing a database to retrieve current fragility functions for predicting structural damage to a building, and for identifying features of the building. The method further includes operations for identifying a retrofit measure having a cost to improve the building structure, and for estimating a first building damage after a simulated earthquake utilizing a machine-learning program and the current fragility functions. The method further includes operations for determining new fragility functions for the building based on the retrofit measure and the current fragility functions, for estimating a second building damage after the simulated earthquake utilizing the new fragility functions, and for determining the difference in damage resulting from the retrofit measure based on the first and the second building damage.","['G06Q50/265', 'G06F30/13', 'G06F30/20', 'G06N20/00', 'G06N20/10', 'G06Q10/06375', 'G06N20/20', 'G06N3/02', 'G06N5/003', 'G06N5/01', 'G06Q40/08']"
US11448727B2,"Method, apparatus, and system for human recognition based on gait features","Methods, apparatus and systems for human recognition based on one or more gait features detected wirelessly are described. In one example, a described system comprises: a transmitter configured to transmit a first wireless signal through a wireless channel of a venue; a receiver configured to receive a second wireless signal through the wireless channel, wherein the second wireless signal comprises a reflection of the first wireless signal by at least one object in the venue; and a processor. The processor is configured for: obtaining a time series of channel information (CI) of the wireless channel based on the second wireless signal, determining a presence of a person moving in the venue based on the time series of CI (TSCI), extracting at least one gait feature of the person from the TSCI, and recognizing an identity of the person based on the at least one gait feature.","['G01S7/415', 'G01S13/584', 'G01S7/006', 'G01S7/354', 'G01S7/356', 'G01S7/417', 'H04W4/023']"
US12377863B2,System and method for future forecasting using action priors,A system and method for future forecasting using action priors that include receiving image data associated with a surrounding environment of an ego vehicle and dynamic data associated with dynamic operation of the ego vehicle. The system and method also include analyzing the image data to classify dynamic objects as agents and to detect and annotate actions that are completed by the agents that are located within the surrounding environment of the ego vehicle and analyzing the dynamic data to process an ego motion history that is associated with the ego vehicle that includes vehicle dynamic parameters during a predetermined period of time. The system and method further include predicting future trajectories of the agents located within the surrounding environment of the ego vehicle and a future ego motion of the ego vehicle within the surrounding environment of the ego vehicle based on the annotated actions.,"['B60W50/0097', 'B60W60/00272', 'G06T7/70', 'G06V10/764', 'G06V10/82', 'G06V20/58', 'B60W2554/4029', 'B60W2554/4049', 'B60W2556/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30261', 'G06T2210/12']"
US11080602B1,Universal attention-based reinforcement learning model for control systems,"Alternatively, or additionally, a computing system generates an indication of a selected outcome according to the reinforcement learning model and sends a selection output to the second environment (e.g., a second traffic intersection with more lanes than the first traffic intersection) to implement the selected action in the second environment.","['G06N3/08', 'G08G1/0145', 'G06F17/18', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/092', 'G08G1/0129', 'G08G1/08', 'G08G1/081', 'G08G1/093', 'G06N5/022']"
EP3866025A1,Natural language and knowledge graph-based method and device for representating learning,"The present application discloses a text processing method and device based on natural language processing and a knowledge graph, and relates to the in-depth field of artificial intelligence technology. A specific implementation is: an electronic device uses a joint learning model to obtain a semantic representation, which is obtained by the joint learning model by combining knowledge graph representation learning and natural language representation learning, it combines a knowledge graph learning representation and a natural language learning representation, compared to using only the knowledge graph representation learning or the natural language representation learning to learn semantic representation of a prediction object, factors considered by the joint learning model are more in quantity and comprehensiveness, so accuracy of semantic representation can be improved, and thus accuracy of text processing can be improved.","['G06F16/367', 'G06F16/9024', 'G06N3/04', 'G06N3/042', 'G06N3/0442', 'G06N3/08', 'G06N3/09', 'G06N5/02']"
CN112001868B,Infrared and visible light image fusion method and system based on generation of antagonism network,"The invention discloses an infrared and visible light image fusion method and system based on a generation countermeasure network, comprising the following steps: acquiring an infrared image and a visible light image to be fused; simultaneously inputting an infrared image and a visible light image to be fused into a pre-trained generation antagonism network, and outputting the fused image; as one or more embodiments, the generating an antagonistic network includes: a total loss function; the total loss function includes: content loss function, detail loss function, target edge enhancement loss function, and contrast loss function.","['G06T5/50', 'G06T5/73', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/20221', 'Y02T10/40']"
US12019990B2,Representation learning method and device based on natural language and knowledge graph,"The present application discloses a text processing method and device based on natural language processing and a knowledge graph, and relates to the in-depth field of artificial intelligence technology. A specific implementation is: an electronic device uses a joint learning model to obtain a semantic representation, which is obtained by the joint learning model by combining knowledge graph representation learning and natural language representation learning, it combines a knowledge graph representation learning and a natural language representation learning, compared to using only the knowledge graph representation learning or the natural language representation learning to learn semantic representation of a prediction object, factors considered by the joint learning model are more in quantity and comprehensiveness, so accuracy of semantic representation can be improved, and thus accuracy of text processing can be improved.","['G06N5/02', 'G06F18/214', 'G06F18/2413', 'G06F18/24147', 'G06F40/279', 'G06F40/30', 'G06N3/04', 'G06N3/042', 'G06N3/044', 'G06N3/0442', 'G06N3/09', 'G06N3/098', 'G06N5/022']"
WO2021175300A1,"Data transmission method and apparatus, electronic device, and readable storage medium","The embodiments of the present application are applicable in the technical field of communications. Disclosed are a data transmission method and apparatus, an electronic device, and a computer-readable storage medium. The method comprises: a first electronic device acquiring data to be transmitted; the first electronic device determining whether a first communication channel meets transmission service requirements of said data, wherein the first communication channel is an existing connection channel between the first electronic device and a second electronic device; and if the first communication channel does not meet the transmission service requirements of said data, the first electronic device establishing, by means of the first communication channel, a second communication channel, that meets the transmission service requirements of said data, with the second electronic device, and then transmitting said data to the second electronic device by means of the second communication channel. According to the embodiments of the present application, when the current transmission channel does not meet transmission service requirements, a communication channel that meets the transmission service requirements can be automatically established according to the transmission service requirements of data to be transmitted, thereby improving the user experience.","['H04M1/72409', 'H04M1/72403', 'H04M1/72412', 'H04M1/725', 'H04W76/00', 'H04W76/10', 'H04W76/15']"
US20200302296A1,Systems and method for optimizing educational outcomes using artificial intelligence,"The present invention is directed, in one particular implementation, to a cloud computing-based categorization system that comprises at least one electronic database having one or more performance assessment data associated with a plurality of entities matriculated at one or more educational institutions. The system further includes a processor, communicatively coupled to the at least one database, and configured to execute an electronic process that analyzes and converts said performance assessment data. Through one or more modules, the processor is configured to select performance assessment data corresponding to at least one structured assessment data value; and at least one unstructured assessment data set for an individual and evaluate the structured and un-structed data of the individual using an assessment model configured to classify the entity into one of a plurality of assessment categories. The processor is further configured by one or more modules to generate a graphical representation, for display and output to one or more remote users, of the likelihood that the individual is assigned to one of the plurality of assessment categories.","['G09B5/00', 'G06F16/2379', 'G06F16/252', 'G06N20/20', 'G06N3/042', 'G06N3/0427', 'G06N3/08', 'G06N5/01', 'G06Q50/20', 'G09B7/00', 'G09B7/02', 'G06N20/10', 'G06N3/044', 'G06N3/045']"
EP4498262A1,Tuning a generative artificial intelligence model,"Systems and methods are disclosed for tuning a generative artificial intelligence (AI) model based on a knowledge base. Instead of manually generating questions relevant to the knowledge base, providing those questions to the generative AI model, and manually reviewing the answers generated by the generative AI model in order to tune the generative AI model over many iterations, a natural language processing model may be configured to leverage the knowledge base to automatically generate questions and answers based on the knowledge base. In this manner, the natural language processing model is able to generate tuning data that may be used to automatically tune the generative AI model. The systems and methods also disclose automatic tuning of the generative AI model, including testing and feedback that may be used to improve tuning of the generative AI model.","['G06F40/30', 'G06F16/3329', 'G06F40/40', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N5/04', 'G06F40/216', 'G06F40/289']"
US11341722B2,Computer vision method and system,"A computer vision method for processing an omnidirectional image to extract understanding of a scene, the method comprising:receiving an omnidirectional image of a scene;mapping the omnidirectional image to a mesh on a three-dimensional polyhedron;convert the three dimensional polyhedron into a representation of a neighbourhood structure, wherein the representation of a neighbourhood structure represents vertices of said mesh and their neighbouring vertices; andprocessing the representation of the neighbourhood structure with a neural network processing stage to produce an output providing understanding of the scene,wherein the neural network processing stage comprising at least one module configured to perform convolution with a filter, aligned with a reference axis of the three-dimensional polyhedron.","['G06T3/00', 'G06T3/12', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06T17/10', 'G06T17/20', 'G06T5/00', 'G06T7/00', 'G06T7/10', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06T2207/20']"
US20200364501A1,Retail checkout terminal fresh produce identification system,"Disclosed are systems and methods including starting with a first number of images, generating a second number of images by digital operations on the first number of images, extracting features from the second number of images, and generating a classification model by training a neural network on the second number of images wherein the classification model provides a percentage likelihood of an image's categorisation, embedding the classification model in a processor and receiving an image for categorisation, wherein the processor is in communication with a POS system, the processor running the classification model to provide output to the POS system of a percentage likelihood of the image's categorisation.","['G06K9/6256', 'G06Q30/06', 'G06F18/214', 'G06F18/24', 'G06K9/6267', 'G06N3/0464', 'G06T5/50', 'G06T7/194', 'G06T7/40', 'G06T7/41', 'G06T7/90', 'G06V10/454', 'G06V10/774', 'G06V10/82', 'G06V20/52', 'G07G1/0054', 'G07G1/0063', 'G07G1/12', 'A47F9/04', 'G06K2209/17', 'G06T2207/10024', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20221', 'G06T2207/30128', 'G06T7/246', 'G06V20/68']"
US10402701B2,Face recognition system for face recognition in unlabeled videos with domain adversarial learning and knowledge distillation,"A face recognition system is provided that includes a device configured to capture a video sequence formed from a set of unlabeled testing video frames. The system includes a processor configured to pre-train a face recognition engine formed from reference CNNs on a still image domain that includes labeled training still image frames of faces. The processor adapts the face recognition engine to a video domain to form an adapted engine, by applying non-reference CNNs to domains including the still image and video domains and a degraded image domain. The degraded image domain includes labeled synthetically degraded versions of the frames included in the still image domain. The video domain includes random unlabeled training video frames. The processor recognizes, using the adapted engine, identities of persons corresponding to at least one face in the video sequence to obtain a set of identities. A display device displays the set of identities.","['G06K9/66', 'G08B13/19613', 'G06F18/21', 'G06F18/217', 'G06F18/22', 'G06F18/24143', 'G06K9/00268', 'G06K9/00288', 'G06K9/00718', 'G06K9/00744', 'G06K9/00771', 'G06K9/4628', 'G06K9/6201', 'G06K9/6217', 'G06K9/6262', 'G06K9/6274', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/70', 'G06T9/002', 'G06V10/454', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/52', 'G06V30/19173', 'G06V40/168', 'G06V40/172', 'G06K2009/00738', 'G06T2207/20081', 'G06V20/44', 'G08B13/196']"
US11610360B2,Real-time neural network radiance caching for path tracing,"A real-time neural radiance caching technique for path-traced global illumination is implemented using a neural network for caching scattered radiance components of global illumination. The neural (network) radiance cache handles fully dynamic scenes, and makes no assumptions about the camera, lighting, geometry, and materials. In contrast with conventional caching, the data-driven approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. The neural radiance cache is trained via online learning during rendering. Advantages of the neural radiance cache are noise reduction and real-time performance. Importantly, the runtime overhead and memory footprint of the neural radiance cache are stable and independent of scene complexity.","['G06T15/506', 'G06T15/06', 'G06N3/0499', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/045', 'G06N3/048']"
US10970375B2,Privacy preserving biometric signature generation,"Methods, systems, and devices are provided for generating biometric signatures. The system can detect, at an electronic device, one or more biometric acoustic signals. The system can generate a biometric signal input of the one or more biometric acoustic signals. The system can apply a machine learning model to conduct feature extraction of the biometric signal input having one or more biometric acoustic signals. The system can generate a biometric user signature of the user from the machine learning model. The system can perform one or more privacy preserving hashing functions to the biometric user signature to generate a hashed biometric user signature. The system can determine whether the hashed biometric user signature satisfies a predetermined threshold with an enrollment hashed signature of the user. And the system can authenticate an identity of the user upon detecting that the hashed biometric user signature satisfies the predetermined threshold.","['G06F21/32', 'G06F3/045', 'G06K9/0002', 'G06K9/00355', 'G06K9/00892', 'G06V10/454', 'G06V10/82', 'G06V40/1306', 'G06V40/70', 'G07C9/257', 'G06V40/15', 'G06V40/28', 'G07C9/26']"
US12130923B2,Methods and apparatus for augmenting training data using large language models,"In some embodiments, a processor receives natural language data for performing an identified cybersecurity task. The processor can provide the natural language data to a first machine learning (ML) model. The first ML model can automatically infer a template query based on the natural language data. The processor can receive user input indicating a finalized query and to provide the finalized query as input to a system configured to perform the identified computational task. The processor can provide the finalized query as a reference phrase to a second ML model, the second ML model configured to generate a set of natural language phrases similar to the reference phrase. The processor can generate supplemental training data using the set of natural language phrases similar to the reference phrase to augment training data used to improve performance of the first ML model and/or the second ML model.","['G06F16/24522', 'G06F21/57', 'G06F16/243', 'G06F40/205', 'G06F40/30', 'G06F40/35', 'G06N3/045', 'G06N3/08', 'G06F2221/034', 'G06F40/274', 'G06F40/289']"
US11141088B2,Electronic device for recognition of mental behavioral attributes based on deep neural networks,"An electronic device that handles recognition of mental behavioral, affect, emotional, mental states, mental health, or mood-based attributes based on deep neural networks (DNNs), stores a set of EEG signals and a set of bio-signals associated with a subject. The electronic device trains a plurality of first recognition models on a training set of EEG signals and a training set of bio-signals associated with different training subjects. The electronic device trains a second recognition model on a feature vector from output layers of the plurality of first recognition models. The electronic device estimates a plurality of dependency or relationship data by application of the trained plurality of first recognition models on the set of EEG signals and bio-signals. The electronic device identifies a mental behavioral attribute of the subject by application of the trained second recognition model on the plurality of signals and their relationship data.","['A61B5/165', 'A61B5/316', 'A61B5/369', 'A61B5/377', 'A61B5/6814', 'A61B5/7267', 'G06F18/285', 'G06F18/41', 'G06F3/015', 'G06K9/00892', 'G06K9/6227', 'G06K9/6254', 'G06N20/10', 'G06N20/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G06V40/70', 'G16H20/70', 'G16H40/63', 'G16H50/20', 'G16H50/70', 'A61B5/0205', 'G06N5/01']"
US11145105B2,Multi-tile graphics processor rendering,"Embodiments are generally directed to multi-tile graphics processor rendering. An embodiment of an apparatus includes a memory for storage of data; and one or more processors including a graphics processing unit (GPU) to process data, wherein the GPU includes a plurality of GPU tiles, wherein, upon geometric data being assigned to each of a plurality of screen tiles, the apparatus is to transfer the geometric data to the plurality of GPU tiles.","['G06T15/005', 'G06T1/20', 'G06T1/60', 'G06T17/20']"
CN113902761B,Knowledge distillation-based unsupervised segmentation method for lung disease focus,"The invention discloses a knowledge distillation-based unsupervised segmentation method for lung disease focus, and belongs to the field of medical image processing and computer vision. The invention firstly builds and trains a self-encoder to obtain a pre-training teacher network with abundant CT image semantic knowledge, then only distills the knowledge of normal CT images from the pre-training teacher network to train a student network with the same architecture as the teacher network, and finally utilizes the teacher and the student network to segment focus according to the difference of the characteristics extracted by focus images. Meanwhile, in addition to the conventional pixel-level distillation, the method also designs affinity-level distillation considering the relationship between pixels so as to sufficiently distill effective knowledge. Experiments prove that the invention can effectively improve the focus segmentation precision on different data sets. The method is easy to construct, the unmarked lung disease focus segmentation result can be obtained only by means of normal data, and generalization and operation efficiency are relatively considerable.","['G06T7/11', 'G06N5/02', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20221', 'G06T2207/30061', 'G06T2207/30096']"
US11514543B2,System and method for ride order dispatching,"Systems and methods are provided for ride order dispatching. Such method may comprise obtaining information on a location of a vehicle and a time to input into a trained neural network algorithm; and based on a policy generated from the trained neural network algorithm, obtaining action information for the vehicle, the action information comprising: staying at a current position of the vehicle, re-positioning the vehicle, or accepting a ride order.","['G06Q50/30', 'G06Q50/40', 'G06Q10/063', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/08', 'G06N3/092', 'G06N3/096', 'G06Q10/047', 'G06Q10/06316', 'G06Q10/1057', 'G06Q30/02']"
US12313497B2,Cross-domain mechanical fault diagnosis method based on multi-channel feature fusion of CBAM and use thereof,"A cross-domain mechanical fault diagnosis method based on multi-channel feature fusion of a CBAM and use thereof includes conducting preliminary feature extraction in a grey-scale graph formed by original signals with convolutional neural network, obtaining high-level features, and compressing the high-level features with a full-connection layer module; conducting deep-level multi-sensor feature extraction with an improved convolutional block attention module (CBAM); conducting fusion for multi-sensor features extracted with an improved convolutional block attention module and obtaining multi-sensor fusion features; and inputting the multi-sensor fusion features into a tag assignor for fault diagnosis results. In the present invention, the latest multi-channel domain adaptation fault diagnosis method is used to realize efficiently intelligent fault diagnosis tasks of bearings in different working states.","['G06N3/08', 'G01M13/028', 'G01M13/045', 'G06F18/253']"
CN110889503B,"Data processing method, data processing device, computer equipment and storage medium","The present disclosure relates to a data processing method, apparatus, computer device, and storage medium. Including the integrated circuit board in the device, this integrated circuit board includes: the device comprises a storage device, an interface device, a control device and an artificial intelligence chip comprising a data processing device; the artificial intelligent chip is respectively connected with the storage device, the control device and the interface device; a memory device for storing data; the interface device is used for realizing data transmission between the artificial intelligent chip and external equipment; and the control device is used for monitoring the state of the artificial intelligent chip. The data quantization processing method, the data quantization processing device, the computer equipment and the storage medium of the neural network provided by the embodiment of the disclosure improve the determination speed and efficiency of determining the quantization bit width of different layers to be quantized in the neural network.","['G06N3/08', 'G06N3/02']"
WO2020082579A1,"Risk review and approval method, device, storage medium, and server","The present application provides a risk review and approval method, a device, a storage medium, and a server. The method comprises: upon detecting a service application request of a user, acquiring application information of the user; extracting, according to a specified feature template corresponding to the service application request and from the application information, an application feature parameter corresponding to an application feature in the specified feature template, the application feature parameter comprising a user identifier; determining whether the application feature parameter meets a pre-determined condition; if so, acquiring historical behavior information of the user according to the user identifier; acquiring, on the basis of the historical behavior information, a credit feature parameter of the user; and performing risk review and approval of the service application request according to the application feature parameter and the credit feature parameter, and outputting a result of the risk review and approval to a smart terminal associated with the user. The present application reduces labor costs, and improves efficiency of risk review and approval.","['G06Q40/03', 'G06Q10/10']"
CN111178074B,A Chinese Named Entity Recognition Method Based on Deep Learning,"The invention relates to a Chinese named entity recognition method based on deep learning, which is characterized by comprising the following steps of: the identification method comprises the following steps: 1) Embedding word position information mixed vectors into the data text; 2) Inputting the vectors obtained in the step into a Bi-LSTM layer for vector coding, and simulating long-term relations among the vectors captured by the time sequence; 3) Inputting the vector output by the Bi-LSTM layer into the self-attention layer, clearly learning the dependency relationship between any two characters in the sentence, and capturing the internal structure information of the sentence; 4) And inputting the output vector sequence to the CRF layer, making independent marking decisions, and performing label decoding. The invention has scientific and reasonable design, can run multiple data sets, has strong applicability and high accuracy, and can be applied to named entity recognition models of multi-field texts.","['G06N3/044', 'G06N3/045', 'G06N3/084', 'Y02D10/00']"
US11244232B2,"Feature relationship recommendation method, apparatus, computing device, and storage medium","Disclosed herein are methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating relationship recommendations. One of the methods includes: determining, by a computing device, parameter entities that comprise event entities associated with node entities; constructing, by the computing device, a knowledge graph based on relationships between the parameter entities and predetermined operator entities; extracting, by the computing device, a newly added relationship from the knowledge graph based on an inference rule; and providing, by the computing device, a relationship recommendation corresponding to the newly added relationship.","['G06F18/214', 'G06F16/906', 'G06F18/2113', 'G06F18/213', 'G06F18/22', 'G06F18/24', 'G06F18/29', 'G06K9/6201', 'G06K9/623', 'G06K9/6232', 'G06K9/6256', 'G06K9/6296', 'G06N20/00', 'G06N5/003', 'G06N5/01', 'G06N5/022', 'G06N5/025', 'G06N5/047', 'G06N3/08']"
US12039435B2,Machine learning accelerator mechanism,An apparatus to facilitate acceleration of machine learning operations is disclosed. The apparatus comprises at least one processor to perform operations to implement a neural network and accelerator logic to perform communicatively coupled to the processor to perform compute operations for the neural network.,"['G06N3/063', 'G06F7/78', 'G06F9/00', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/084', 'G06F2207/4824', 'G06N3/047', 'G06N3/048', 'G06N3/088', 'G06T1/20']"
US20230074074A1,Intelligent recognition method for while-drilling safety risk based on convolutional neural network,"The present invention discloses an intelligent recognition method for while-drilling safety risks based on a convolutional neural network. The method includes the following steps: 1, processing while-drilling safety risk parameter features and data, and establishing a correlation analysis model for monitoring-while-drilling parameters by using a Pearson coefficient correlation analysis method; 2, processing while-drilling safety monitoring data, analyzing a time span of each sample, constructing training sample data and test sample data, and preprocessing the samples; 3, designing a while-drilling safety risk recognition network structure; and 4, recognizing while-drilling safety risks by the trained safety risk recognition network. The method of the present invention is applied to monitoring-while-drilling engineering, which can greatly improve the drilling efficiency and a reservoir drilling rate, reduce a complex accident rate and cost in drilling, provide a powerful safety guarantee for drilling work, meet the current urgent demands for cost reduction and efficiency enhancement in drilling to a certain extent, and also provide a new idea for the development of intelligent drilling technologies in China.","['E21B44/00', 'G06Q10/0635', 'E21B49/003', 'G06F18/2135', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G06N3/094', 'G06Q50/02', 'E21B2200/22', 'G06N3/0464', 'G06N3/048', 'Y02P90/30']"
US20200284883A1,"Component for a lidar sensor system, lidar sensor system, lidar sensor device, method for a lidar sensor system and method for a lidar sensor device","The present disclosure relates to various embodiments of an optical component for a LIDAR Sensor System. The optical component may include an optical element having a first main surface and a second main surface opposite to the first main surface, a first lens array formed on the first main surface, and/or a second lens array formed on the second main surface. The optical element has a curved shape in a first direction of the LIDAR Sensor System.","['G01S17/10', 'G01S17/894', 'G01S7/4817', 'B60W60/00', 'G01S17/36', 'G01S17/86', 'G01S17/931', 'G01S7/4811', 'G01S7/4815', 'G01S7/4816', 'G01S7/484', 'G01S7/4863', 'G01S7/4865', 'G01S7/4914', 'G01S7/497', 'H04N25/773', 'H05B47/105', 'H05B47/11', 'H05B47/16', 'B60W2420/20', 'B60W2420/24', 'B60W2420/40', 'B60W2420/50', 'B60W2420/506', 'H10F39/182', 'H10F39/184', 'H10F39/191']"
US20230351542A1,Dynamic precision management for integer deep learning primitives,"One embodiment provides for a graphics processing unit to perform computations associated with a neural network, the graphics processing unit comprising a hardware processing unit having a dynamic precision fixed-point unit that is configurable to convert elements of a floating-point tensor to convert the floating-point tensor into a fixed-point tensor.","['G06T1/20', 'G06F17/153', 'G06F17/16', 'G06F5/01', 'G06F7/00', 'G06F7/501', 'G06F7/523', 'G06F7/5443', 'G06F9/3885', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06F2207/382', 'G06F2207/4824']"
US10984286B2,Domain stylization using a neural network model,"A style transfer neural network may be used to generate stylized synthetic images, where real images provide the style (e.g., seasons, weather, lighting) for transfer to synthetic images. The stylized synthetic images may then be used to train a recognition neural network. In turn, the trained neural network may be used to predict semantic labels for the real images, providing recognition data for the real images. Finally, the real training dataset (real images and predicted recognition data) and the synthetic training dataset are used by the style transfer neural network to generate stylized synthetic images. The training of the neural network, prediction of recognition data for the real images, and stylizing of the synthetic images may be repeated for a number of iterations. The stylization operation more closely aligns a covariate of the synthetic images to the covariate of the real images, improving accuracy of the recognition neural network.","['G06K9/6256', 'G06V10/82', 'G06F18/214', 'G06F18/24', 'G06F18/24133', 'G06K9/00664', 'G06K9/00986', 'G06K9/3233', 'G06K9/6267', 'G06K9/6271', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T11/00', 'G06T15/00', 'G06T3/0056', 'G06T3/10', 'G06T7/10', 'G06V10/764', 'G06V10/774', 'G06V10/955', 'G06V20/10', 'G06N7/01']"
CN109993789B,"A method, device and camera for judging illegal parking of shared bicycles","The embodiment of the invention provides a parking violation determination method and device for a shared bicycle and a camera, wherein the parking violation determination method for the shared bicycle comprises the following steps: acquiring an image to be detected in an appointed scene, wherein the appointed scene comprises a pre-divided shared single-vehicle parking violation area; positioning the region where the shared bicycle is located in the image to be detected through a deep learning model obtained through pre-training to obtain the position information of the region where the shared bicycle is located; judging whether the overlapping area of the area where the shared bicycle is located and the illegal parking area of the shared bicycle is larger than or equal to a first preset threshold value or not based on the position information of the area where the shared bicycle is located; and if so, determining that the shared bicycle is the illegal shared bicycle. Whether the shared bicycle is illegal to stop or not can be accurately judged through the scheme.","['G06T7/12', 'G06T7/70', 'G06V20/54', 'G08G1/205', 'G08G1/207', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232']"
US10467820B2,Image style transfer for three-dimensional models,"Example aspects of the present disclosure are directed to systems and methods that perform image style transfer for three-dimensional models. In some implementations, the systems and methods can use machine-learned models such as, for example, convolutional neural networks to generate image style and content information used to perform style transfer. The systems and methods of the present disclosure can operate in a rendered image space. In particular, a computing system can iteratively modify an attribute rendering map (e.g., texture map, bump map, etc.) based on information collected from a different rendering of the model at each of a plurality of iterations, with the end result being that the attribute rendering map mimics the style of one or more reference images in content-preserving way. In some implementations, a computation of style loss at each iteration can be performed using multi-viewpoint averaged scene statistics, instead of treating each viewpoint independently.","['G06T15/20', 'G06K9/6212', 'G06T15/00', 'G06T15/04', 'G06T15/205', 'G06T19/20', 'G06V10/44', 'G06V10/758', 'G06V20/653', 'G06T2219/2012', 'G06T2219/2024']"
US20230334316A1,Dynamic distributed training of machine learning models,"Described herein is a graphics processor comprising a memory device and a graphics processing cluster coupled with the memory device. The graphics processing cluster includes a plurality of graphics multiprocessors interconnected via a data interconnect. A graphics multiprocessor includes circuitry configured to load a modular neural network including a plurality of subnetworks, each of the plurality of subnetworks trained to perform a computer vision operation on a separate subject.","['G06T1/20', 'G06N3/08', 'G06F11/1482', 'G06F11/1629', 'G06F9/5027', 'G06F9/5066', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/048']"
CN110263350B,"Model training method, device, computer readable storage medium and computer equipment","The application relates to a model training method, a device, a computer readable storage medium and a computer apparatus, wherein the method comprises the following steps: acquiring training text pairs; the training text pair comprises a corresponding source text and a desired text; inputting the source text into a translation model to generate translation text corresponding to the source text; acquiring a hidden layer vector output by a hidden layer of the translation model as a training sample of a quality evaluation model; the hidden layer vector fuses the source text and the translation text; determining a training label corresponding to the training sample according to the translation text and the expected text; and training the quality evaluation model through the training samples and the corresponding training labels. The scheme provided by the application can reduce the model training cost.","['G06F40/58', 'G06N3/045', 'G06N3/08']"
CN113807399B,"A neural network training method, detection method and device","The application discloses a neural network training method and device in the field of artificial intelligence, which are used for obtaining multiple neural networks by combining knowledge distillation, selecting at least one unlabeled sample for labeling through deviation among outputs of the multiple neural networks, and retraining by using the labeled sample to improve training efficiency of a model. The method comprises the following steps: and respectively taking samples in the data set as input of a teacher model, a first student model and a second student model to obtain a first output result, a second output result and a third output result, screening at least one unlabeled sample from the data set through the first deviation and the second deviation to label, updating at least one labeled sample into the training set, training the teacher model by using the updated training set to obtain a trained teacher model, and performing knowledge distillation on the second student model by using the trained teacher model to obtain a trained second student model.","['G06N3/02', 'G06F18/214', 'G06N3/08', 'Y02T10/40']"
WO2020000688A1,"Financial risk verification processing method and apparatus, computer device, and storage medium","A financial risk verification processing method and apparatus, a computer device, and a storage medium. The financial risk verification processing method comprises: obtaining a financial approval request, the financial approval request comprising financial document data (S10); carrying out feature extraction on the financial document data to obtain feature item data (S20); inputting the feature item data into a target risk identification model based on a decision tree algorithm to carry out risk identification, and obtaining a target risk level (S30); and classifying the financial document data according to the target risk level, and distributing the financial document data to a subordinate processing flow corresponding to the target risk level so as to perform corresponding risk verification on the financial document data (S40). According to the financial risk verification processing method, risk identification is carried out based on a target risk identification model, classification processing is carried out according to risk levels, the approval efficiency for financial document data is improved, the workload of financial document data approval is saved, and the costs of manual approval are reduced.","['G06Q10/0635', 'G06Q40/125']"
US11409994B2,"Methods for image segmentation, computer devices, and storage mediums","Methods for image segmentation, computer devices, and storage mediums. The method includes acquiring a to-be-segmented image, inputting the to-be-segmented image into an input variable of a full convolution neural network and outputting a convolution characteristic pattern; inputting the convolution characteristic pattern into an input variable of a context-switchable neural network and outputting context expression information; and generating an intermediate characteristic pattern for image segmentation according to the convolution characteristic pattern and the context expression information.","['G06K9/6261', 'G06T7/11', 'G06F18/214', 'G06F18/2163', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/26', 'G06V10/751', 'G06T2207/10004', 'G06T2207/10028', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
CN110598157B,"Target information identification method, device, equipment and storage medium","The embodiment of the disclosure provides a target information identification method, a device, equipment and a storage medium, wherein the method comprises the following steps: acquiring target data uploaded by a terminal corresponding to a first account and statistical information of historical data uploaded by the terminal corresponding to the first account; determining a first probability that the target data is target information through a target information identification model according to the target data; according to the target data and the statistical information, training a gradient lifting decision tree model to determine a second probability that the first account is a target account; and determining whether the target data is target information according to the first probability and the second probability. The method and the device for identifying the target article can solve the problem that whether the article is the abnormal target article cannot be timely and effectively identified in the prior art.","['G06F16/958', 'G06N3/08']"
US11537851B2,Methods and systems using improved training and learning for deep neural networks,"Methods and systems are disclosed using improved training and learning for deep neural networks. In one example, a deep neural network includes a plurality of layers, and each layer has a plurality of nodes. The nodes of each L layer in the plurality of layers are randomly connected to nodes of an L+1 layer. The nodes of each L+1 layer are connected to nodes in a subsequent L layer in a one-to-one manner. Parameters related to the nodes of each L layer are fixed. Parameters related to the nodes of each L+1 layers are updated. In another example, inputs for the input layer and labels for the output layer of a deep neural network are determined related to a first sample. A similarity between different pairs of inputs and labels is estimated using a Gaussian regression process.","['G06N3/063', 'G06N3/0472', 'G06F17/18', 'G06F18/22', 'G06K9/6215', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06T1/20']"
EP4095797A1,Autonomous segmentation of three-dimensional nervous system structures from medical images,"A method for autonomous segmentation of three-dimensional nervous system structures from raw medical images, the method comprising the following steps: receiving (301) a 3D scan volume comprising a set of medical scan images of a region of the anatomy; autonomously processing (302) the set of medical scan images to perform segmentation of a bony structure of the anatomy to obtain bony structure segmentation data; autonomously processing (304) a subsection of the 3D scan volume as a 3D region of interest (ROI) by combining (303) the raw medical scan images and the bony structure segmentation data, wherein the 3D ROI contains a subvolume of the bony structure with a portion of surrounding tissues, including the nervous system structure; autonomously processing the ROI (306) to determine the 3D shape, location, and size of the nervous system structures by means of a pre-trained convolutional neural network (CNN) (400).","['G06T7/0012', 'A61B5/4058', 'A61B5/4566', 'G06F18/214', 'G06N20/00', 'G06T7/0014', 'G06T7/11', 'G06T7/143', 'G06T7/62', 'G06V20/653', 'G16H30/40', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30012', 'G06V2201/033', 'G06V2201/034']"
CN108804205B,Intelligent thread dispatch and vectorization of atomic operations,"Intelligent thread dispatch and vectorization of atomic operations is provided. A mechanism is described for facilitating intelligent dispatch and vectorization at an autonomous machine. The method of embodiments as described herein includes detecting a plurality of threads corresponding to a plurality of workloads associated with tasks involving a graphics processor. The method may further include determining a first set of threads of the plurality of threads that are similar to each other or have adjacent surfaces, and physically clustering the first set of threads together by using a first set of adjacent computing blocks.","['G06F9/3009', 'G06F9/466', 'G06F12/0862', 'G06F15/167', 'G06F15/17', 'G06F9/30036', 'G06F9/30038', 'G06F9/30145', 'G06F9/3836', 'G06F9/3867', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/5033', 'G06F9/5066', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06T1/60', 'G06F2212/602', 'G06F2212/6028', 'Y02D10/00']"
CN110046266B,Intelligent management method and device for photos,"The invention discloses an intelligent management method of photos, which comprises the steps of receiving the photos uploaded by each terminal; generating a photo group with shooting information in a photo database, wherein the shooting information at least comprises the time, the place or the terminal model of photo shooting; generating a query call of a photo database according to the shooting information and the image object identification, wherein the query call at least comprises a face classification identification, a scene identification and a real object identification; and generating query call of the photo database according to the shooting information and the image object identification. According to the invention, the image identification, the clustering and the classification are carried out through the deep learning neural network to obtain the image object identification, the image object identification and the shooting information are used for generating the query calling of the photo database, and a user can query the photo database more quickly and conveniently according to the information such as time, place, people, scene, real object and the like, so that the user experience is improved.","['G06F16/51', 'G06F16/583', 'G06F18/22', 'G06F18/23', 'G06V40/161', 'G06V40/168', 'G06V40/172']"
US11164109B2,Artificial intelligence engine for mixing and enhancing features from one or more trained pre-existing machine-learning models,"An AI engine having an architect module to create a number of nodes and how the nodes are connected in a graph of concept nodes that make up a resulting AI model. The architect module also creates a first concept node by wrapping an external entity of code into a software container with an interface configured to exchange information in a protocol of a software language used by the external entity of code. The architect module also creates a second concept node derived from its description in a scripted file coded in a pedagogical programming language, and connects the second concept node into the graph of nodes in the resulting AI model.","['G06F8/31', 'G06F15/80', 'G06F16/2228', 'G06F16/951', 'G06F18/2148', 'G06F3/0482', 'G06F30/20', 'G06F8/311', 'G06F8/38', 'G06F8/437', 'G06F9/451', 'G06F9/4881', 'G06F9/5066', 'G06K9/6257', 'G06N20/00', 'G06N3/008', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/0985', 'G06N3/105', 'G06N5/04', 'G06Q10/00', 'H04L67/42', 'G06F3/03543', 'G06F30/333', 'G06F40/166', 'H04L67/02']"
WO2021047593A1,"Method for training recommendation model, and method and apparatus for predicting selection probability","Disclosed are a method for training a recommendation model, and a method and an apparatus for predicting selection probability, wherein same relate to the field of artificial intelligence. The training method comprises: acquiring a training sample, wherein the training sample comprises a sample user behavior log, location information of a sample recommendation object, and a sample label (410); and performing joint training on a location offset model and a recommendation model by taking the sample user behavior log and the location information of the sample recommendation object as input data and taking the sample label as a target output value, so as to obtain a trained recommendation model, wherein the location offset model is used for predicting the probability of a user paying attention to a target recommendation object when the target recommendation object is at different locations, and the recommendation model is used for predicting the probability of the user selecting the target recommendation object when the user pays attention to the target recommendation object (420). By means of the technical solution, an error introduced into a recommendation model by location information can be eliminated, thus improving the accuracy of the recommendation model.","['G06F16/9535', 'G06N5/022', 'G06N3/084', 'G06F16/9538', 'G06N5/04', 'G06Q30/02', 'G06Q30/0255', 'G06N3/045', 'G06N7/01']"
US11210777B2,System and method for detection of mobile device fault conditions,"There is presented a system and method for detecting mobile device fault conditions, including detecting fault conditions by software operating on the mobile device. In one embodiment, the present invention provides for systems and methods for using a neural network to detect, from an image of the device, that the mobile device has a defect, for instance a cracked or scratched screen. Systems and methods also provide for, reporting the defect status of the device, working or not, so that appropriate action may be taken by a third party.","['G01N21/8851', 'G01N21/95', 'G06K9/52', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T7/0002', 'G06T7/0004', 'G06T7/001', 'G06T7/13', 'G06T7/80', 'H04N23/64', 'H04N23/73', 'H04N23/74', 'H04N5/23222', 'H04N5/2353', 'H04N5/2354', 'H04N5/2628', 'H04N7/18', 'G01N2021/8854', 'G01N2021/8858', 'G01N2021/8887', 'G01N2021/8893', 'G01N2021/9513', 'G01N21/958', 'G01N2201/0221', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/30121', 'G06T2207/30168', 'G06T2207/30244']"
US20230224158A1,System and method for processing a battery passport,A system and method for processing a battery passport that include receiving battery related data associated with a battery. The system will therefore store battery related data associated with many batteries and also be able to capture aggregated data across all of these. The system and method also include determining a level of sustainability associated with the battery. The system and method further include processing the battery passport to include the battery related data and the level of sustainability associated with the battery and indeed the level of sustainability with all batteries that have a battery passport.,"['H04L9/32', 'G06Q10/06315', 'G06Q10/30']"
CN113297975B,"Method, device, storage medium and electronic equipment for table structure recognition","The present disclosure relates to a method, an apparatus, a storage medium, and an electronic device for identifying a table structure, where a table image corresponding to a table to be identified may be used as an input of a target detection model to obtain a position feature and an element category of each table element in the table to be identified, where the element category includes a text line; carrying out character recognition on the characters by using a character recognition model to obtain text semantic features of each character row; extracting features of the table images through an image feature extraction model to obtain image feature images, and sampling the image feature images to obtain target image features corresponding to each table element respectively; according to the position features, the text semantic features and the target image features, obtaining target relation features for representing the topological relation between every two table elements in the table to be identified through a preset relation extraction model, and determining a graph adjacency matrix for representing the table structure of the table to be identified through a preset classification model according to the target relation features.","['G06V30/414', 'G06F18/24147', 'G06N3/045', 'G06N3/08', 'G06V10/22']"
US11039675B2,"Systems and methods for virtual facial makeup removal and simulation, fast facial detection and landmark tracking, reduction in input video lag and shaking, and method for recommending makeup","The present disclosure provides systems and methods for virtual facial makeup simulation through virtual makeup removal and virtual makeup add-ons, virtual end effects and simulated textures. In one aspect, the present disclosure provides a method for virtually removing facial makeup, the method comprising providing a facial image of a user with makeups being applied thereto, locating facial landmarks from the facial image of the user in one or more regions, decomposing some regions into first channels which are fed to histogram matching to obtain a first image without makeup in that region and transferring other regions into color channels which are fed into histogram matching under different lighting conditions to obtain a second image without makeup in that region, and combining the images to form a resultant image with makeups removed in the facial regions. The disclosure also provides systems and methods for virtually generating output effects on an input image having a face, for creating dynamic texturing to a lip region of a facial image, for a virtual eye makeup add-on that may include multiple layers, a makeup recommendation system based on a trained neural network model, a method for providing a virtual makeup tutorial, a method for fast facial detection and landmark tracking which may also reduce lag associated with fast movement and to reduce shaking from lack of movement, a method of adjusting brightness and of calibrating a color and a method for advanced landmark location and feature detection using a Gaussian mixture model.","['G06T19/20', 'A45D44/005', 'G06K9/00268', 'G06K9/00281', 'G06K9/00671', 'G06T1/0007', 'G06T11/60', 'G06T15/80', 'G06T17/205', 'G06T5/40', 'G06V20/20', 'G06V40/168', 'G06V40/171', 'G06K9/4642', 'G06T2207/30201', 'G06T7/90', 'G06V10/50']"
US20230352133A1,Systems and methods for processing medical data,"The present disclosure provides methods for processing medical data. The method may comprise receiving a plurality of data inputs associated with (i) at least one medical patient or (ii) at least one surgical procedure. The method may further comprise receiving one or more annotations for at least a subset of the plurality of data inputs. The method may further comprise generating an annotated data set using (i) the one or more annotations and (ii) one or more data inputs of the plurality of data inputs. The method may further comprise using the annotated data set to (i) perform data analytics for the plurality of data inputs, (ii) develop one or more medical training tools, or (iii) train one or more medical models.","['G16H20/40', 'G16H20/00', 'A61B34/10', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'A61B2034/105', 'A61B2034/107']"
US11797862B2,Extreme language model compression with optimal sub-words and shared projections,"Provided is a knowledge distillation technique for training a student language model that, relative to a larger teacher language model, has a significantly smaller vocabulary, lower embedding dimensions, and/or hidden state dimensions. Specifically, aspects of the present disclosure are directed to a dual-training mechanism that trains the teacher and student language models simultaneously to obtain optimal word embeddings for the student vocabulary. In some implementations, this approach can be combined with learning shared projection matrices that transfer layer-wise knowledge from the teacher language model to the student language model. Example experimental results have also demonstrated higher compression efficiency and accuracy when compared with other state-of-the-art compression techniques, including the ability to compress the BERTBASE model by more than 60×, with only a minor drop in downstream task metrics, resulting in a language model with a footprint of under 7 MB.","['G06N3/088', 'G06F40/284', 'G06N3/045', 'G06N3/0495', 'G06N3/09', 'G06N3/096']"
US10825127B2,Dynamic precision management for integer deep learning primitives,"One embodiment provides for a graphics processing unit to perform computations associated with a neural network, the graphics processing unit comprising compute unit including a hardware logic unit having dynamic precision fixed-point logic, the compute unit to receive a set of dynamic fixed-point tensors, compute, via the dynamic precision fixed-point logic, a right-shift value using an absolute maximum value within the set of dynamic fixed-point tensors and a dynamic range of the set of dynamic fixed-point tensors, right-shift data values within the set of dynamic fixed-point tensors based on the right-shift value, increment a shared exponent associated with the set of dynamic fixed-point tensors based on the right-shift value, perform a compute operation on the set of dynamic fixed-point tensors, and generate an output tensor via the compute operation on the set of dynamic fixed-point tensors.","['G06T1/20', 'G06F17/153', 'G06F17/16', 'G06F5/01', 'G06F7/501', 'G06F7/523', 'G06F7/5443', 'G06F9/3885', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06F2207/382', 'G06F2207/4824']"
CN108733051B,Autonomous Vehicle Advanced Sensing and Response,"The application discloses autonomous vehicle advanced sensing and response. One embodiment provides a computing device within an autonomous vehicle, the computing device comprising a wireless network device to enable a wireless data connection with an autonomous vehicle network, a set of multiple processors including a general purpose processor and a general purpose graphics processor to execute a computing manager to manage execution of computing workloads associated with the autonomous vehicle, the computing workloads being associated with autonomous operation of the autonomous vehicle, and offload logic configured to execute on the set of multiple processors to determine offloading of one or more of the computing workloads to one or more autonomous vehicles within range of the wireless network device.","['G07C5/008', 'G05D1/0214', 'B60W30/00', 'B60W50/0098', 'G01C21/34', 'G01C21/3415', 'G01C21/3492', 'G05D1/0088', 'G05D1/0276', 'G06F9/5027', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06T1/60', 'G08G1/012', 'H04L67/12', 'H04W4/40', 'B60W2050/0006', 'B60W2556/65', 'G01S19/13', 'G05D1/0257', 'G06F2209/509', 'G08G1/0112', 'G08G1/052', 'H04L43/0852', 'H04L43/16', 'Y02D10/00']"
CN114358128B,Method for training end-to-end automatic driving strategy,"The invention discloses a method for training an end-to-end automatic driving strategy. The method comprises the following steps: inputting high-dimensional visual information reflecting a driving environment into a pre-trained representation network, and automatically learning low-dimensional information, wherein the representation network utilizes collected teaching data to conduct supervised learning, and the low-dimensional information is an abstract feature with strong correlation with an automatic driving task; and constructing a reinforcement learning model, wherein the intelligent agent acquires an observation result through a low-dimensional information representation result of a pre-trained representation network to obtain an optimized driving strategy, the reinforcement learning process is realized based on a Markov decision process of discrete time, and the reinforcement learning is aimed at acquiring a maximum-period return expectation. According to the method, the abstract feature characterization with strong correlation with the automatic driving task is learned before reinforcement learning, so that the optimal driving strategy can be obtained more quickly and accurately.","['G06N3/04', 'G06N3/08']"
WO2019196546A1,Method and apparatus for determining risk probability of service request event,"A method and an apparatus for determining the risk probability of a service request event, the method comprising: acquiring event characteristics of a service request event (21); acquiring user personal characteristics of the user to which the service request event relates (22); on the basis of a population relationship graph based on a specific population, determining user relationship characteristics (23); and, on the basis of the event characteristics, the user personal characteristics, and the user relationship characteristics, determining the risk probability of the service request event (24). Thus, the risk of the service request event can be comprehensively evaluated.","['G06Q30/018', 'G06Q40/02', 'G06Q40/08', 'G06Q10/0635', 'G06Q50/01']"
CN113314144B,"Voice recognition and power equipment fault early warning method, system, terminal and medium","The invention provides a voice recognition method and a voice recognition system, which are used for marking voice data in a voice data set to obtain marked audio information; after denoising the sound data in the sound data set sequentially through digital signal processing and Kalman filtering, extracting the frequency spectrum characteristics of the sound data; constructing a machine learning classification model, training the machine learning model by adopting spectral features of the marked audio information and the sound data, and obtaining a sound recognition model based on machine learning; and acquiring the audio data to be identified, denoising the audio data to be identified sequentially through digital signal processing and Kalman filtering, and inputting the audio data to be identified into a voice identification model to obtain a corresponding classification result, thereby realizing voice identification. Meanwhile, the power equipment fault early warning method and system based on the voice recognition method are provided, and the power equipment fault is early warned according to the voice recognition result. The invention improves the accuracy of voice recognition, and further improves the accuracy of fault detection of the power equipment.","['G10L25/24', 'G08B21/185', 'G10L15/063', 'G10L15/08', 'G10L21/0208']"
US20250124810A1,System and program for cognitive skill training,"This invention enables targeting, personalized measurement, and management of cognitive skills development by users, clinicians, teachers, and parents. The invention features a game based virtual learning curriculum for targeting and developing the underlying cognitive skills of executive functions. The methods and systems of the invention provide an effective and rapid video game-based training curriculum to improve the cognitive skills such as focused attention, sustained attention, cognitive inhibition, behavioral inhibition, selective attention, alternating attention, divided attention, interference control, novelty inhibition, delay of gratification, inner voice, motivational inhibition, and self-regulation. This curriculum utilizes: (i) each of the cognitive processes that underlie attention control and impulse inhibition; (ii) the identification of measurable and trainable cognitive skills; and (iii) game design and game mechanics that effectively train and enable retention of those skills. The game-based system provides a medical professional, clinician, parent, teacher and user with the ability to measure and manage training of targeted cognitive skills to reach a desired performance goal.","['G09B19/00', 'A61B5/168', 'A61B5/369', 'A61B5/375', 'A61B5/744', 'A63F13/46', 'A63F13/67', 'A63F13/69', 'A63F13/85', 'G09B5/02', 'G09B5/06']"
US20240054233A1,"Device, System, and Method for Protecting Machine Learning (ML) Units, Artificial Intelligence (AI) Units, Large Language Model (LLM) Units, and Deep Learning (DL) Units","Systems and methods for protecting machine learning engines, artificial intelligence engines, large language models, and deep learning engines. An Offline Protection Unit is configured to analyze one or more characteristics of a Protected Engine, and to perform offline fortification of the Protected Engine against attacks by changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks. An Online Protection Unit is configured to perform analysis of at least one of: (i) inputs that are directed to be inputs of the Protected Engine, (ii) outputs that are generated by the Protected Engine; and based on the analysis, to dynamically perform online fortification of the Protected Engine against attacks by dynamically changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks.","['G06F21/577', 'G06F21/54', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06N3/094', 'G06F2221/032', 'G06N20/20', 'G06N3/126', 'G06N5/01']"
US12336804B2,System and method for diagnosing and treating biological rhythm disorders,"A heart treatment system is disclosed capable of diagnosing one or more critical regions of interest for a biological rhythm disorder by sensing signals from biological tissue. If a critical region is not present at the current location of sensed signals, the system is capable of indicating a guidance direction in which to navigate to reach one or more critical regions. Ablation energy is delivered to treat said region of interest. Signals are again sensed and analyzed to assess the impact of treatment. This process is repeated until all critical regions of interest are treated. In some embodiments, all functionality is provided by a single sensing and treating catheter with display device and analytical software.","['A61B5/068', 'A61B18/1492', 'A61B5/277', 'A61B5/287', 'A61B5/367', 'A61B5/4836', 'A61B5/6858', 'A61B5/6885', 'A61B5/7264', 'A61B5/7267', 'A61B5/742', 'G16H20/30', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'G16H50/30', 'A61B2018/00351', 'A61B2018/00357', 'A61B2018/00577', 'A61B2018/00839', 'G16H50/70']"
US12367546B2,Panorama generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate panoramas from individual images. In at least one embodiment, one or more generative neural networks are used to generate a spherical panoramic image using features extracted from a single input image.","['G06T3/4038', 'G06T1/20', 'G06T19/006', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T17/10', 'G06T2207/20084', 'G06T3/4046']"
CN106909924B,Remote sensing image rapid retrieval method based on depth significance,"A remote sensing image rapid retrieval method based on depth saliency belongs to the field of computer vision, and particularly relates to technologies such as depth learning, saliency target detection and image retrieval. The invention takes the remote sensing image as a research object and researches a quick retrieval method of the remote sensing image by utilizing a deep learning technology. Firstly, a multi-task saliency target detection model is constructed by adopting a full-convolution neural network, a saliency detection task and a semantic segmentation task are simultaneously carried out on the model, and the depth saliency characteristics of the remote sensing image are learned in the network pre-training process. And then, improving a deep network structure, adding a hash layer fine tuning network, and learning to obtain a binary hash code of the remote sensing image. And finally, comprehensively utilizing the significance characteristics and the hash codes to measure the similarity. The method is practical and feasible for realizing accurate and efficient retrieval of the remote sensing image and has important application value.","['G06V10/267', 'G06V20/05', 'G06F16/583', 'G06F18/22', 'G06N3/045', 'G06N3/084', 'G06V10/462']"
WO2024155584A1,"Systems, methods, devices, and platforms for industrial internet of things","In example embodiments, a method of detecting an anomaly associated with a machine includes recording a data set associated with the machine; determining, by a first machine learning model, a label associated with the data set; determining whether the label is to be reviewed; and responsive to determining that the label is to be reviewed, subjecting the data set and the label to a review, and updating the label based on the review. Alternatively or additionally, in example embodiments, a method of presenting an analysis of a machine included in an industrial facility includes generating a digital twin of the machine; determining at least one property of the digital twin based on a simulation of an operation of the machine; and generating a presentation of the industrial facility that includes a visualization of the digital twin and a visual indicator of the at least one property of the digital twin.","['G05B23/024', 'G05B19/4184', 'G05B19/41885', 'G06N20/00', 'G06N7/01', 'G05B2219/31356', 'G05B2219/31467', 'G06N3/006']"
US20220277064A1,System and methods for implementing private identity,"In various embodiments, a fully encrypted private identity based on biometric and/or behavior information can be used to securely identify any user efficiently. According to various aspects, once identification is secure and computationally efficient, the secure identity/identifier can be used across any number of devices to identify a user an enable functionality on any device based on the underlying identity, and even switch between identified users seamlessly all with little overhead. In some embodiments, devices can be configured to operate with function sets that transition seamlessly between the identified users, even, for example, as they pass a single mobile device back and forth. According to some embodiments, identification can extend beyond the current user of any device, into identification of actors responsible for activity/content on the device.","['G06F18/253', 'G06F21/32', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V40/1365', 'G06V40/172', 'G06V40/45', 'G06V40/70', 'H04L9/008', 'H04L9/3231']"
US20220147602A1,System and methods for implementing private identity,"In various embodiments, a fully encrypted private identity based on biometric and/or behavior information can be used to securely identify any user efficiently. According to various aspects, once identification is secure and computationally efficient, the secure identity/identifier can be used across any number of devices to identify a user an enable functionality on any device based on the underlying identity, and even switch between identified users seamlessly all with little overhead. In some embodiments, devices can be configured to operate with function sets that transition seamlessly between the identified users, even, for example, as they pass a single mobile device back and forth. According to some embodiments, identification can extend beyond the current user of any device, into identification of actors responsible for activity/content on the device.","['G06F21/31', 'G06F21/316', 'G06F18/253', 'G06F21/32', 'G06F21/41', 'G06F21/602', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V40/1365', 'G06V40/172', 'G06V40/45', 'G06V40/70', 'H04L63/0815', 'H04L63/0861', 'H04L9/008', 'H04L9/3231']"
US20240346124A1,System and methods for implementing private identity,"In various embodiments, a fully encrypted private identity based on biometric and/or behavior information can be used to securely identify any user efficiently. According to various aspects, once identification is secure and computationally efficient, the secure identity/identifier can be used across any number of devices to identify a user an enable functionality on any device based on the underlying identity, and even switch between identified users seamlessly all with little overhead. In some embodiments, devices can be configured to operate with function sets that transition seamlessly between the identified users, even, for example, as they pass a single mobile device back and forth. According to some embodiments, identification can extend beyond the current user of any device, into identification of actors responsible for activity/content on the device.","['G06F21/316', 'G06F18/253', 'G06F21/32', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V40/1365', 'G06V40/172', 'G06V40/45', 'G06V40/50', 'G06V40/70', 'H04L9/008', 'H04L9/3231']"
CN114283287B,Robust field adaptive image learning method based on self-training noise label correction,"The invention discloses a robust field self-adaptive image learning method based on self-training noise label correction, which comprises the following steps: acquiring a source domain, a target domain image set and a source domain low-quality label; initializing various parameters; building a model and a loss function; sequentially inputting the image sets of the source domain and the target domain into two mark classifiers; the two mark classifiers detect noise for the opposite side before each iterative training, then predict pseudo marks again for the noise source domain sample and the target domain sample, and perform rebalance sampling to participate in the next iterative training; inputting a target domain pseudo label set into target domain specific network training; and after the training is finished, performing a class prediction task on the target domain image by using the target domain specific classifier. Aiming at the problem that the category distribution of a source domain is inconsistent with that of a target domain, the method adopts a rebalanced sampling pseudo-mark sample mechanism to ensure that the sampling proportion of each category of the source domain and the target domain is consistent, and the accuracy of a deep learning model on the target domain is improved.",[]
US11481906B1,Custom labeling workflows in an active learning-based data labeling service,"Techniques for active learning-based data labeling are described. An active learning-based data labeling service enables a user to build and manage large, high accuracy datasets for use in various machine learning systems. Machine learning may be used to automate annotation and management of the datasets, increasing efficiency of labeling tasks and reducing the time required to perform labeling. Embodiments utilize active learning techniques to reduce the amount of a dataset that requires manual labeling. As subsets of the dataset are labeled, this label data is used to train a model which can then identify additional objects in the dataset without manual intervention. The process may continue iteratively until the model converges. This enables a dataset to be labeled without requiring each item in the data set to be individually and manually labeled by human labelers.","['G06N20/00', 'G06F16/335', 'G06F16/383', 'G06F18/2148', 'G06F18/2155', 'G06F18/217', 'G06K9/6259', 'G06K9/6262', 'G06T7/187', 'G06V10/7753', 'G06V10/776', 'G06V10/7788', 'G06V30/414', 'G06F40/40', 'H04L67/10']"
WO2023283545A1,Systems and method for providing security against deception and abuse in distributed and tokenized environments,"Systems and methods for providing security in distributed and tokenized environments in accordance with various embodiments of the invention are described. A method for bridging between blockchains, includes: bridging an entry from a first blockchain to a second blockchain, where the entry is associated with an event; determining a classification of the entry, where the classification is one of confirmed, delayed, and blocked; performing an action based on the classification of the entry; where the action includes at least one action selected from a group including: determining the classification is confirmed and recording (130) on the second blockchain the entry and removing the entry from several entries, determining the classification is blocked and removing the entry from the several entries, and determining the classification is delayed and keeping the entry for an additional time period.","['H04L63/0428', 'H04L63/0807', 'H04L63/10', 'H04L63/1441', 'H04L9/50']"
US20220222778A1,Upsampling an image using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to generate one or more images using one or more pixel weights determined based, at least in part, on one or more sub-pixel offset values.","['G06T3/4053', 'G06T1/20', 'G06T3/4046', 'G06T3/4069', 'G06T5/002', 'G06T5/20', 'G06T5/50', 'G06T5/70', 'H04N23/80', 'H04N23/951', 'H04N25/48', 'G06T2207/10016', 'G06T2207/20016', 'G06T2207/20084', 'G06T2207/20221']"
US20220147607A1,System and methods for implementing private identity,"In various embodiments, a fully encrypted private identity based on biometric and/or behavior information can be used to securely identify any user efficiently. According to various aspects, once identification is secure and computationally efficient, the secure identity/identifier can be used across any number of devices to identify a user an enable functionality on any device based on the underlying identity, and even switch between identified users seamlessly all with little overhead. In some embodiments, devices can be configured to operate with function sets that transition seamlessly between the identified users, even, for example, as they pass a single mobile device back and forth. According to some embodiments, identification can extend beyond the current user of any device, into identification of actors responsible for activity/content on the device.","['G06F21/316', 'G06F18/253', 'G06F21/32', 'G06F21/52', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V40/1365', 'G06V40/172', 'G06V40/45', 'G06V40/70', 'H04L9/008', 'H04L9/3231', 'G06N3/048']"
US11645530B2,Transforming convolutional neural networks for visual sequence learning,"A method, computer readable medium, and system are disclosed for visual sequence learning using neural networks. The method includes the steps of replacing a non-recurrent layer within a trained convolutional neural network model with a recurrent layer to produce a visual sequence learning neural network model and transforming feedforward weights for the non-recurrent layer into input-to-hidden weights of the recurrent layer to produce a transformed recurrent layer. The method also includes the steps of setting hidden-to-hidden weights of the recurrent layer to initial values and processing video image data by the visual sequence learning neural network model to generate classification or regression output data.","['G06N3/082', 'G06F18/24', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/41']"
AU2020103905A4,Unsupervised cross-domain self-adaptive medical image segmentation method based on deep adversarial learning,"The invention provides an unsupervised cross-domain self-adaptive medical image segmentation method based on deep adversarial learning, which comprises the following steps: constructing deep encoder-decoder fully convolutional network segmentation model, constructing a domain discriminator network model, segmentation system pre-training and parameter optimization, constructing the target domain MRI automatic semantic segmentation system to form an MRI semantic segmentation image. In this application, the deep encoder decoder fully convolutional neural network is adopted to model segmentation system, and the high-level semantic features and low-level detail features are jointly utilized to predict pixel label; and the domain discriminaor network is used to guide the segmentation model to learn domain invariant features and strong generalized segmentation functions through adversarial learning, so as to minimize the data distribution difference between the source domain and the target domain indirectly, so that the learned segmentation system has the same segmentation accuracy in the target domain as in the source domain, which improves the cross domain generalization performance of the MRI automatic semantic segmentation method, and realizes the unsupervised cross domain adaptive MRI accurate segmentation. -1/4 MRI segmentation image MRI images and Training MRI brain tumor automatic segmentation segmentation labels of -system with the data set of the source domain Label predictor the source domain MR I images and Feature extractor for the source domain (fixed domain labels of the _ parameters) source domain Training domain discriminator adversarial training MRI images and Feature extractor for domain labels of the Training feature extractor for the target domain the target domain target domain images ofthe trget domain Figure 1","['G06T7/0012', 'A61B5/0033', 'A61B5/05', 'A61B5/7267', 'G06N3/0455', 'G16H30/40', 'G06N20/00', 'G06T2207/10088', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/03']"
CN111062217B,"Language information processing method and device, storage medium and electronic equipment","The embodiment of the application discloses a language information processing method, a device, a storage medium and electronic equipment. The method comprises the following steps: acquiring language information text content to be processed, and preprocessing the text content to obtain Chinese character content with part-of-speech tags; inputting the Chinese character content with the part of speech labels into a BERT model to obtain the coding vector of the Chinese character content; mapping the coding vector into a part-of-speech set through a full connection layer to obtain target parts-of-speech and target part-of-speech probability of each Chinese character of Chinese character content, wherein the target parts-of-speech and the target part-of-speech probability are used as state characteristics of the Chinese character content; and calculating transfer feature probability among the labels through a CRF layer, and determining the part-of-speech labels of each Chinese character of the Chinese character content according to the state features and the transfer feature probability. Through the technical scheme provided by the application, the BiLSTM model adopted in the prior art can be replaced by the BERT model, so that the obtained vector features are richer, and the training efficiency can be improved.",['Y02D10/00']
US20210012198A1,Method for training deep neural network and apparatus,"The present disclosure relates to artificial intelligence, and proposes a cooperative adversarial network. A loss function is set at a lower layer of the cooperative adversarial network, and is used to learn a domain discriminating feature. In addition, a cooperative adversarial target function includes the loss function and a domain invariant loss function that is set at a last layer (that is, a higher layer) of the cooperative adversarial network, to learn both the domain discriminating feature and a domain-invariant feature. Further, an enhanced collaborative adversarial network is proposed. Based on the collaborative adversarial network, target domain data is added to training of the collaborative adversarial network, an adaptive threshold is set based on precision of a task model, to select a target domain training sample, network confidence is discriminated based on a domain, and a weight of the target domain training sample is set.","['G06N3/084', 'G06F18/211', 'G06F18/214', 'G06K9/6228', 'G06K9/6256', 'G06N3/04', 'G06N3/045', 'G06N3/08']"
US20210374756A1,Methods and systems for generating rules for unseen fraud and credit risks using artificial intelligence,"Embodiments provide methods and systems for detecting frauds in payment transactions made by payment instrument using spend patterns of multiple payment instruments associated with user. The method performed by server system includes accessing payment transaction data associated with a plurality of customers from a transaction database. The method includes training a first generative adversarial network (GAN) model based on the payment transaction data and a plurality of probable fraud risk conditions. The first GAN model is trained to generate simulated customer fraud behaviors. The method includes filtering, by the server system, the simulated customer fraud behaviors based on a predetermined filtering criteria. The method includes generating, by the server system, fraud risk scores for the simulated customer fraud behaviors based on a fraud risk model. The method includes extracting fraud risk rules based on a set of simulated customer fraud behaviors from the simulated customer fraud behaviors.","['G06Q20/4016', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N5/01', 'G06Q20/20', 'G06N3/042', 'G06N3/044', 'G06N5/025', 'G06Q20/34', 'G06Q20/403']"
US20220036153A1,Ultra large language models as ai agent controllers for improved ai agent performance in an environment,"Methods and artificial intelligence agents are provided to train or guide an artificial intelligence agent. Visual data and/or text data are received from the artificial intelligence agent and/or an environment of the artificial intelligence agent. A text prompt is generated based on the visual information and/or the text data. The text prompt is provided to an ultra-large language model. Text output of the ultra-large language model is received in response to the text prompt. The artificial intelligence agent is supplied with the text output of the ultra-large language model and/or the text output converted into an alternative format. The artificial intelligence agent is configured to select an action, a series of actions, and/or the policy based on the state of an environment of the artificial intelligence agent and on the text output of the ultra-large language model and/or the text output converted into the alternative format.","['G06N3/0427', 'G06F40/40', 'G06N3/042', 'G06N3/006', 'G06N3/045', 'G06N3/08', 'G06N5/02']"
CN114386694B,"Drug molecular property prediction method, device and equipment based on contrast learning","The application discloses a drug molecular property prediction method, device and equipment based on contrast learning, relates to the technical field of artificial intelligence, and can solve the technical problems of low efficiency and poor prediction performance of the existing drug molecular property prediction. Comprising the following steps: generating a target molecular graph structure of the target drug molecule according to the chemical molecular structure, and generating a target three-dimensional conformation of the target drug molecule; determining a first feature vector corresponding to the target molecular diagram structure by using the trained diagram neural network model; determining a second feature vector corresponding to the target three-dimensional conformation by using the trained convolutional neural network model, wherein the graph neural network model and the convolutional neural network model are obtained through contrast learning of a positive sample pair and a negative sample pair and combined training; and constructing a third feature vector according to the first feature vector and the second feature vector, and inputting the third feature vector into the property prediction model after training to obtain a property prediction result of the target drug molecule.","['G06Q10/04', 'G06F18/25', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G16B15/00', 'G16C20/50']"
US11927738B2,Computational microscopy based-system and method for automated imaging and analysis of pathology specimens,"Described herein are systems and methods for assessing a biological sample. The methods include: characterizing a speckled pattern to be applied by a diffuser; positioning a biological sample relative to at least one coherent light source such that at least one coherent light source illuminates the biological sample; diffusing light produced by the at least one coherent light source; capturing a plurality of illuminated images with the embedded speckle pattern of the biological sample based on the diffused light; iteratively reconstructing the plurality of speckled illuminated images of the biological sample to recover an image stack of reconstructed images; stitching together each image in the image stack to create a whole slide image, wherein each image of the image stack at least partially overlaps with a neighboring image; and identifying one or more features of the biological sample. The methods may be performed by a near-field Fourier Ptychographic system.","['G02B21/367', 'G01N21/4788', 'G01N21/6458', 'G02B21/06', 'G02B21/086', 'G02B21/365', 'G02B27/58', 'G06T5/50', 'G06T5/60', 'G06T7/0012', 'G06T7/33', 'G06V20/693', 'G06V20/698', 'G01N2021/479', 'G06T2200/32', 'G06T2207/10056', 'G06T2207/10152', 'G06T2207/20056', 'G06T2207/20084', 'G06T2207/30024']"
US11568860B2,"System and method for federated, context-sensitive, acoustic model refinement","A system and method for federated, context-sensitive, acoustic model refinement comprising a federated language model server and a plurality of edge devices. The federated language model server may comprise one or more machine learning models trained and developed centrally on the server, and distribute these one or more machine learning models to edge devices wherein they may be operated locally on the edge devices. The edge devices may gather or generate context data that can be used by a speech recognition engine, and the local language models contained therein, to develop adaptive, context-sensitive, user-specific language models. Periodically, the federated language model server may select a subset of edge devices from which to receive uploaded local model parameters, that may be aggregated to perform central model updates wherein the updated model parameters may then be sent back to edge devices in order to update the local model parameters.","['G10L15/16', 'G06N20/20', 'G06N3/044', 'G06Q50/12', 'G10L15/005', 'G10L15/07', 'G10L15/183', 'G10L15/22', 'H04L67/34', 'G06N3/096', 'G06N3/098', 'G06N5/02', 'G10L2015/228']"
CN110459282B,"Sequence labeling model training method, electronic medical record processing method and related device","The embodiment of the invention relates to the technical field of natural language processing, and provides a sequence annotation model training method, an electronic medical record processing method and a related device. Namely, the first recurrent neural network layer is adopted to capture the context information of the sequence, and then the attention layer is introduced to further learn the long-distance characteristic information in the sequence, so that the accuracy can be effectively improved when the sequence labeling model obtained by training is used for sequence labeling.","['G06F18/214', 'G06N3/044', 'G06N3/045', 'G16H10/60']"
WO2020168752A1,Speech recognition and speech synthesis method and apparatus based on dual learning,"A speech recognition and speech synthesis method and apparatus based on dual learning. The method comprises: initializing a marked data set Φ(x,y), a speech recognition parameter θxy and a speech synthesis parameter θyx, wherein Φ(x,y) = {(x(j),y(j))}K, x(j) is speech data, and y(j) is text data; selecting, from Φ(x,y), N pairs of marked data {(x(i),y(i))}N; extracting an acoustic feature of x(i), and according to the acoustic feature of x(i), acquiring the posterior probability of a phoneme corresponding to x(i) and the transition probability of the phoneme corresponding to x(i) to generate the text data (a), and calculating the first log likelihood of (a) equaling y(i); acquiring a sound feature sequence corresponding to y(i) to generate the speech data (b), and calculating the second log likelihood of (b) equaling x(i); and taking the maximum first log likelihood and the maximum second log likelihood as target functions, and taking the probabilistic duality of speech recognition and speech synthesis as a constraint condition to optimize θxy and θyx. According to the method, dual learning is effectively used to perform speech recognition and speech synthesis, thereby increasing the training speed of speech recognition and speech generation and improving the accuracy of an output result.","['G10L13/02', 'G10L15/02', 'G10L15/06', 'G10L15/14', 'G10L15/16', 'G10L15/26', 'Y02T10/40']"
US11138731B2,"Methods for generating synthetic training data and for training deep learning algorithms for tumor lesion characterization, method and system for tumor lesion characterization, computer program and electronically readable storage medium","A method is for generating synthetic training data and for training deep learning algorithms for tumor lesion characterization. In an embodiment, the method for generating synthetic training data for training a deep learning algorithm includes training a Generative Adversarial Network to generate synthetic image data, the Generative Adversarial Network including a generator and a discriminator; and using the generator of the Generative Adversarial Network to generate synthetic image data as the synthetic training data.","['G06N3/084', 'G06T7/0014', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
CN108229649B,Method and apparatus for deep learning training,"Methods and apparatus for deep learning training are described. In one aspect, candidate units such as detected bounding boxes in an image or phonemes of an input audio feature are classified using soft labels, wherein in the case of an image the labels have at least a range of possible values between 0 and 1 based on an overlap of the detected bounding boxes with one or more classes of ground truth bounding boxes.","['G06N3/08', 'G06N3/045', 'G06F18/214', 'G06N20/00', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N7/01', 'G06V10/70', 'G06V10/774', 'G06V10/82', 'G10L17/16', 'G10L17/18']"
CN109299258B,"Public opinion event detection method, device and equipment","The application discloses a public opinion event detection method, device and equipment, wherein the method comprises the following steps: and on the basis of a basic model obtained through training a large amount of data in the source field, respectively utilizing a small amount of data in other fields to perform transfer learning training again to obtain a text classification model capable of performing public opinion detection on the corresponding field, and taking the basic model as the text classification model for performing public opinion detection on the source field. And obtaining a text classification model of the target field to which the event to be detected belongs from the obtained text classification models, carrying out public opinion analysis on the event to be detected, analyzing the probability value of the event belonging to the target field public opinion, judging whether the event to be detected is the public opinion event of the target field according to the result of comparing the probability value with a corresponding preset threshold value, and further carrying out public opinion processing on the public opinion event in time. The scheme can shorten modeling time and avoid the influence of low data volume in the corresponding field on the model public opinion detection precision.",['Y02D10/00']
US12223417B2,Efficient convolution in machine learning environments,"A mechanism is described for facilitating smart convolution in machine learning environments. An apparatus of embodiments, as described herein, includes one or more processors including one or more graphics processors, and detection and selection logic to detect and select input images having a plurality of geometric shapes associated with an object for which a neural network is to be trained. The apparatus further includes filter generation and storage logic (“filter logic”) to generate weights providing filters based on the plurality of geometric shapes, where the filter logic is further to sort the filters in filter groups based on common geometric shapes of the plurality of geographic shapes, and where the filter logic is further to store the filter groups in bins based on the common geometric shapes, wherein each bin corresponds to a geometric shape.","['G06N3/063', 'G06F18/2113', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09']"
US10621513B2,System and method for deploying and versioning machine learning models,Embodiments disclosed herein generally relate to a method and system for generating a container image. A computing system receives a request from a remote computer to provision a container comprising a machine learning model. The computing system generates a first API accessible by the remote computer. The computing system receives one or more parameters for the container via the API. The one or more parameters include a machine learning model type. The computing system retrieves from a library of a plurality of machine learning models a machine learning model corresponding to a type of model specified in the one or more parameters. The computing system generates a container image that includes the machine learning model. The computing system provisions a container based on the container image.,['G06N20/00']
US12210825B2,Image captioning,Systems and methods for image captioning are described. One or more aspects of the systems and methods include generating a training caption for a training image using an image captioning network; encoding the training caption using a multi-modal encoder to obtain an encoded training caption; encoding the training image using the multi-modal encoder to obtain an encoded training image; computing a reward function based on the encoded training caption and the encoded training image; and updating parameters of the image captioning network based on the reward function.,"['G06F16/583', 'G06F18/214', 'G06F18/217', 'G06F40/253', 'G06V10/774', 'G06V10/82']"
US11513205B2,System and method associated with user authentication based on an acoustic-based echo-signature,A system associated with predicting authentication of a device user based on a joint features representation related to an echo-signature associated with a device is disclosed. The system performs operations that include emitting acoustic signals in response to a request for processing of a profile associated with the device. The system receives a set of echo acoustic signals that are tailored based on reflection of the acoustic signals from unique contours of one or more depth portions associated with the user relative to a discrete epoch. One or one or more region segments associated with the echo acoustic signals are extracted in order to train a classification model. A classification model is generated based on the one or more region segments as extracted. A joint features representation based on the classification model is generated. A vector-based classification model is used in the prediction of the joint features representation. The system determines whether the joint features representation is associated with the echo-signature based on the prediction of the joint features representation.A corresponding method and computer-readable device are also disclosed.,"['G01S7/539', 'G01S15/32', 'G01S15/86', 'G01S15/88', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06V40/171', 'G06V40/172']"
US10723479B2,Synthetic air data output generation,"In one example, a method includes receiving, over an aircraft data communications bus, a plurality of non-pneumatic inputs corresponding to aircraft operational parameters. The method further includes processing the plurality of non-pneumatic inputs through an artificial intelligence network to generate an air data output value, and outputting the air data output value to a consuming system for use when a pneumatic-based air data output value is determined to be unreliable.","['G01P5/16', 'B64D43/00', 'B64D43/02', 'G01C21/165', 'G01P13/025', 'G01P21/025', 'G01P5/00', 'G05B13/0265', 'G06N3/04', 'G06N3/0499', 'G06N3/09', 'G06N3/091', 'G07C5/0808']"
US11551353B2,Content based image retrieval for lesion analysis,"Computed Tomography (CT) and Magnetic Resonance Imaging (MRI) are commonly used to assess patients with known or suspected pathologies of the lungs and liver. In particular, identification and quantification of possibly malignant regions identified in these high-resolution images is essential for accurate and timely diagnosis. However, careful quantitative assessment of lung and liver lesions is tedious and time consuming. This disclosure describes an automated end-to-end pipeline for accurate lesion detection and segmentation.","['G06T7/0012', 'G16H50/20', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/0985', 'G06T7/11', 'G06T7/143', 'G06T7/194', 'G06V10/82', 'G16H10/60', 'G16H20/10', 'G16H20/40', 'G16H30/40', 'G16H50/70', 'G16H70/20', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20152', 'G06T2207/30056', 'G06T2207/30064', 'G06T2207/30096']"
CN108885784B,Real-time eye contact correction using neural network-based machine learning,The discussion relates to techniques for providing eye contact correction of a virtual user gaze aligned with a camera while the user views a display. These techniques may include: encoding an eye region of the source image using a pre-trained neural network to generate compressed features; applying a pre-trained classifier to the features to determine a motion vector field for the eye region; and twisting the eye region and inserting it into the source image to generate a gaze contact corrected image.,"['G06V10/82', 'G06F18/214', 'G06F18/24', 'G06T3/18', 'G06T3/40', 'G06V40/171', 'G06V40/18', 'G06V40/193', 'G06V40/197', 'H04N7/147']"
US11741109B2,"Dialogue system, a method of obtaining a response from a dialogue system, and a method of training a dialogue system","A method of obtaining a response to a query inputted by a user, the method comprising: receiving a user inputted query; representing the user inputted query as a sequence of embedding vectors using a first model; encoding the sequence of embedding vectors to produce a context vector using a second model; retrieving responses with associated response vectors; scoring response vectors against the context vector, wherein the scoring is a measure of the similarity between the context vector and a response vector; and outputting the responses with the closest response vectors, wherein the first model is configured to segment a user inputted query into a sequence of units from a vocabulary of units and represent each unit in the sequence as an embedding vector, wherein at least one of the units in the vocabulary is an incomplete word, and wherein the first model comprises parameters that are stored using eight bits per parameter; and wherein the second model has been trained using corresponding queries and responses such that an encoding is used that maximises the similarity between the response vector and context vector for a corresponding query and response.","['G06F16/3344', 'G06F16/24578', 'G06F16/243', 'G06N3/045', 'G06N3/0455', 'G06N3/0495', 'G06N3/0499', 'G06N3/08', 'G06N3/084', 'G06N3/09']"
US11210306B2,"Dialogue system, a method of obtaining a response from a dialogue system, and a method of training a dialogue system","A method of obtaining a response to a query inputted by a user, the method comprising: receiving a user inputted query; representing the user inputted query as a sequence of embedding vectors using a first model; encoding the sequence of embedding vectors to produce a context vector using a second model; retrieving responses with associated response vectors; scoring response vectors against the context vector, wherein the scoring is a measure of the similarity between the context vector and a response vector; and outputting the responses with the closest response vectors, wherein the first model is configured to segment a user inputted query into a sequence of units from a vocabulary of units and represent each unit in the sequence as an embedding vector, wherein at least one of the units in the vocabulary is an incomplete word, and wherein the first model comprises parameters that are stored using eight bits per parameter; and wherein the second model has been trained using corresponding queries and responses such that an encoding is used that maximises the similarity between the response vector and context vector for a corresponding query and response.","['G06F16/24578', 'G06F40/284', 'G06F16/243', 'G06F16/3344', 'G06F40/216', 'G06F40/237', 'G06F40/35', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0495', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/096']"
US20230162049A1,Artificial intelligence (ai) method for cleaning data for training ai models,"Computational methods and systems for cleaning AI training data are described which clean datasets by dividing a training dataset into a plurality of training subsets. For each training subset we train a plurality of Artificial Intelligence (AI) models on two or more of the remaining plurality of training subsets and using these trained AI models to obtain an estimated label for each sample in the training subset for each AI model. We then remove or relabel samples in the training dataset which are consistently incorrectly predicted by the plurality of AI models and then proceed to generate and deploy a final AI model by training one or more AI models using the cleansed training dataset. A variation of the method may also be used to label a new dataset wherein the new dataset is inserted into the training dataset, and then the training process is itself used to determine the classification of the new dataset using a voting strategy on the estimated labels.","['G06F18/2148', 'G06F18/217', 'G06F18/28', 'G06N20/20', 'G06N3/0464', 'G06N3/098', 'G06N5/02', 'G16H15/00', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G06N20/10', 'G06N3/045', 'G06N5/01', 'G16H50/70']"
US11853875B2,Neural network apparatus and method,"A processor-implemented neural network method includes acquiring connection weight of an analog neural network (ANN) node of a pre-trained ANN; and determining, a firing rate of a spiking neural network (SNN) node of an SNN, corresponding to the ANN node, based on an activation of the ANN node which is determined based on the connection weight. and the firing rate is also determined based on information indicating a timing at which the SNN node initially fires.","['G06N3/049', 'G06N3/08', 'G06N3/04', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/105', 'G06N3/045']"
US20230181042A1,"Machine learning systems and methods for assessment, healing prediction, and treatment of wounds","Machine learning systems and methods are disclosed for prediction of wound healing, such as for diabetic foot ulcers or other wounds, and for assessment implementations such as segmentation of images into wound regions and non-wound regions. Systems for assessing or predicting wound healing can include a light detection element configured to collect light of at least a first wavelength reflected from a tissue region including a wound or portion thereof, and one or more processors configured to generate an image based on a signal from the light detection element having pixels depicting the tissue region, automatically segment the pixels into wound pixels and non-wound pixels, determine one or more optically determined tissue features of the wound or portion thereof, and generate a predicted or assessed healing parameter associated with the wound or portion thereof over a predetermined time interval.","['A61B5/0059', 'G06T7/0012', 'A61B5/0075', 'A61B5/0077', 'A61B5/445', 'A61B5/4842', 'A61B5/7267', 'A61P17/02', 'A61B2562/046', 'A61B2576/02', 'G06T2207/10048', 'G06T2207/30088', 'G06T2207/30096', 'G16H30/40']"
US20240296425A1,Automated description generation for job posting,"Embodiments of the described technologies receive, via a user interface, an input associated with a first user of a user connection network. The input identifies first position data related to a position capable of being filled by a hiring of a person. In response to validating the first position data, second position data different from the first position data is extracted from the user connection network, based on the first position data. A first prompt is formulated based on the first position data and the second position data. The first prompt is sent to a generative language model. A first piece of writing is received from the generative language model. The first piece of writing includes a position description output by the generative language model based on the first prompt. The position description is sent to the user interface in response to the input.","['G06F40/166', 'G06F16/9535', 'G06F40/194', 'G06F40/197', 'G06F40/40', 'G06Q10/1053']"
US11651229B2,Methods and systems for face recognition,"Systems and methods for face recognition are provided. The systems may perform the methods to obtain a neural network comprising a first sub-neural network and a second sub-neural network; generate a plurality of preliminary feature vectors based on an image associated with a human face, the plurality of preliminary feature vectors comprising a color-based feature vector; obtain at least one input feature vector based on the plurality of preliminary feature vectors; generate a deep feature vector based on the at least one input feature vector using the first sub-neural network; and recognize the human face based on the deep feature vector.","['G06N3/084', 'G06F18/23213', 'G06F18/253', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06V10/454', 'G06V10/462', 'G06V10/50', 'G06V10/763', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V40/168', 'G06V40/172']"
US20240193426A1,Quantizing Neural Networks Using Shifting and Scaling,"Some embodiments of the invention provide a novel method for training a quantized machine-trained network. Some embodiments provide a method of scaling a feature map of a pre-trained floating-point neural network in order to match the range of output values provided by quantized activations in a quantized neural network. A quantization function is modified, in some embodiments, to be differentiable to fix the mismatch between the loss function computed in forward propagation and the loss gradient used in backward propagation. Variational information bottleneck, in some embodiments, is incorporated to train the network to be insensitive to multiplicative noise applied to each channel. In some embodiments, channels that finish training with large noise, for example, exceeding 100%, are pruned.","['G06F5/012', 'G06F7/483', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N5/046', 'G06N5/01', 'G06N7/01']"
TWI872157B,Apparatus and method for displaced mesh compression and non-transitory machine-readable medium,"Apparatus and method for lossy displaced mesh compression. For example, one embodiment of an apparatus comprises: displacement mapping circuitry/logic to generate an original displacement-mapped mesh by performing a displacement mapping of a plurality of vertices of a base subdivision mesh; and mesh compression circuitry/logic to compress the original displacement-mapped mesh, the mesh compression circuitry/logic comprising a quantizer to quantize the displacement mapping of the plurality of vertices in view of a base mesh to generate a displacement array.","['G06T9/001', 'G06F9/5027', 'G06T1/20', 'G06T15/005', 'G06T15/06', 'G06T15/08', 'G06T17/10', 'G06T17/20', 'G06T17/205', 'G06T3/4007', 'G06T9/00', 'G06T2200/28']"
CN111932435B,Optimized computing hardware for machine learning operations,"The application discloses optimized computing hardware for machine learning operations. One embodiment provides a computing device for performing machine learning operations, the computing device comprising: a fetch unit to fetch a single instruction having a plurality of input operands, wherein the plurality of operands have unequal bit lengths, a first input having a first bit length and a second input having a second bit length; a decode unit to decode a single instruction into decoded instructions; an operand length unit to determine a smaller bit length of the first bit length and the second bit length; and a calculation unit for performing a matrix operation on the plurality of input operands to generate an output value having a bit length of smaller bit length.","['G06F9/3888', 'G06N3/084', 'G06T1/20', 'G06F17/16', 'G06F7/5443', 'G06F9/30014', 'G06F9/30036', 'G06F9/3016', 'G06F9/30181', 'G06F9/30192', 'G06F9/3851', 'G06F9/3887', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06F2207/382', 'G06N3/048']"
US11904101B2,Digital virtual limb and body interaction,"Methods and systems for pre-action training are described. In an aspect, a method is presented for constructing a user-controllable image comprising obtain anatomical and physiological data associated with a body, storing the anatomical and physiological data in a database; and creating the user-controllable image based on the stored anatomical and physiological data. At least a moveable portion of the user-controllable image may be constructed to move based on input from a user. Victims of stroke, TBI, or other neurological setbacks may pre-train their nervous system for use of one or more injured body parts. The methods and systems described provide pre-action training control of non-virtual prostheses, exoskeleton body parts, powered orthotic devices, robots or other motile or audiovisual output devices used to improve therapy, rehabilitation, and in some circumstances to lessen or prevent blood clots. Therapy may be remotely delivered.","['G06F3/015', 'A61M21/00', 'G06F3/016', 'G09B19/003', 'A61B2505/09', 'A61B5/01', 'A61B5/024', 'A61B5/0816', 'A61B5/4064', 'A61B5/4848', 'A61M2021/005', 'A61M2205/056', 'A61M2205/583', 'G06F3/014']"
US10984245B1,Convolutional neural network based on groupwise convolution for efficient video analysis,"In one embodiment, a method includes receiving a request for information associated with a video, determining the information associated with the video by processing the video using a machine-learning model which is based on a convolutional neural network comprising a plurality of layers, wherein at least one of the plurality of layers comprises one or more building blocks, wherein at least one of the one or more building blocks comprises a first filter configured to perform a three-dimensional (3D) pointwise convolutional operation and a second filter configured to perform a three-dimensional (3D) groupwise convolutional operation, and outputting the information associated with the video in response to the request.","['G06V10/82', 'G06K9/00718', 'G06F18/2111', 'G06F18/2113', 'G06F18/214', 'G06K9/6229', 'G06K9/623', 'G06K9/6256', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V20/41', 'G06N3/045', 'G06N5/022']"
CN107705066B,Information input method and electronic equipment during commodity warehousing,"The invention discloses an information input method and electronic equipment when commodities are put in storage, and belongs to the technical field of computers. The method comprises the following steps: when the commodity is put in storage, commodity information of the commodity provided by a supplier is acquired; if the original commodity information is incomplete, identifying the commodity picture by utilizing a pre-trained neural network, and extracting the attribute information of the commodity from the commodity picture; according to the attribute information of the commodity, commodity information corresponding to the attribute information is obtained from a relation network of a commodity knowledge graph established in advance; and incomplete inputting information of the commodities by applying the obtained commodity information, and merging the incomplete inputting information into the library. Therefore, the commodity information required when the commodities are put in storage is automatically acquired in a mode of combining the automatic commodity picture attribute extraction with the commodity knowledge map, the whole process is automatically completed, manual inquiry and classification are not needed, the labor cost of entering the storage information is greatly reduced, the commodity storage efficiency is improved, and the accuracy is improved.","['G06Q10/087', 'G06F16/367', 'G06F16/583', 'G06F40/295']"
US9949714B2,"Method, electronic apparatus, and computer readable medium of constructing classifier for disease detection","The disclosure provides a method, an electronic apparatus, and a computer readable medium of constructing a classifier for disease detection. The method includes the following steps. A codebook of representative features is constructed based on a plurality of disease-irrelevant data. Transfer-learned disease features are extracted from disease-relevant bio-signals according to the codebook without any medical domain knowledge, where both the disease-irrelevant data and the disease-relevant bio-signals are time-series data. Supervised learning is performed based on the transfer-learned disease features to train the classifier for disease detection.","['A61B7/04', 'A61B5/0402', 'A61B5/316', 'A61B5/346', 'A61B5/7267', 'G06F18/2178', 'G06F18/2411', 'G06F18/253', 'G06F18/254', 'G06K9/6263', 'G06K9/6269', 'G06K9/629', 'G06K9/6292', 'G16H50/20']"
WO2021188354A1,Automated and adaptive design and training of neural networks,"Systems and methods are described for developing and using neural network models. An example method of training a neural network includes: oscillating a learning rate while performing a preliminary training of a neural network; determining, based on the preliminary training, a number of training epochs to perform for a subsequent training session; and training the neural network using the determined number of training epochs. The systems and methods can be used to build neural network models that efficiently and accurately handle heterogeneous data.","['G06N3/04', 'G06F17/18', 'G06N3/08', 'G06N5/01']"
US20210290154A1,Method and system for determining an optimal set of operating parameters for an aesthetic skin treatment unit,"The present disclosure provides method and system determining an optimal set of operating parameters for desired clinical outcome. The method comprises to receive treatment or target skin data comprising skin characteristics associated with skin to be treated with an aesthetic treatment by the aesthetic skin treatment unit and preset operating parameters for performing the aesthetic treatment. Further, the treatment data is analyzed using plurality of trained models to predict plurality of sets of operating parameters for the aesthetic skin treatment unit to perform the aesthetic treatment. Using the plurality of sets of operating parameters, an optimal set of operating parameters is determined for performing the aesthetic treatment by the using the aesthetic skin treatment unit. By proposed system and method, accurate set of operation parameters may be predicted to achieve desired clinical outcomes, without human intervention.","['G16H50/50', 'A61B18/203', 'A61B5/0033', 'A61B5/0035', 'A61B5/0075', 'A61B5/0077', 'A61B5/441', 'A61B5/4836', 'A61B5/7246', 'A61B5/7267', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B2018/00452', 'A61B2018/00464', 'A61B2018/00642', 'A61B2018/00785', 'A61B2034/105', 'A61B2576/02', 'A61N2005/0626', 'A61N5/0616', 'G06N3/08']"
US11127107B2,Apparatus and method for real time graphics processing using local and cloud-based graphics processing resources,"An apparatus and method for scheduling threads on local and remote processing resources. For example, one embodiment of an apparatus comprises: a local graphics processor to execute threads of an application; graphics processor virtualization circuitry and/or logic to generate a virtualized representation of a local processor; a scheduler to identify a first subset of the threads for execution on a local graphics processor and a second subset of the threads for execution on a virtualized representation of a local processor; the scheduler to schedule the first subset of threads on the local graphics processor and the second subset of the threads by transmitting the threads or a representation thereof to Cloud-based processing resources associated with the virtualized representation of the local processor; and the local graphics processor to combine first results of executing the first subset of threads on the local graphics processor with second results of executing the second subset of threads on the Cloud-based processing resources to render an image frame.","['G06F9/45504', 'G06F9/5072', 'A63F13/25', 'A63F13/355', 'A63F13/60', 'G06F15/7807', 'G06F15/8007', 'G06F9/3009', 'G06F9/3851', 'G06F9/45558', 'G06F9/4806', 'G06F9/4881', 'G06F9/5027', 'G06N20/00', 'G06T1/20', 'A63F13/358', 'A63F2300/534', 'G06F2009/4557', 'G06F2009/45595', 'G06F2209/5017', 'G06F2209/5018', 'G06F2209/509']"
US10643109B2,Method and system for automatically classifying data expressed by a plurality of factors with values of text word and symbol sequence by using deep learning,Disclosed are a method and a system for automatically classifying data expressed as a plurality of factors with values of a text word and a symbol sequence by using deep learning. The method comprises the steps of: inputting the data expressed by the plurality of factors so as to express a word vector including sequence information of the factors through sequence learning of words corresponding to the factors with respect to each factor constituting the data in a first model; inputting an output of the first model so as to calculate points of each category for classifying the categories of the data by using the word vector including the sequence information of the factor in a second model; and determining at least one category for the data by using the points of each category.,"['G06K9/6277', 'G06F16/355', 'G06F18/2411', 'G06F18/24143', 'G06F18/24147', 'G06F18/2415', 'G06F40/20', 'G06F40/258', 'G06K9/6269', 'G06K9/6274', 'G06K9/6276', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N5/046', 'G06Q10/067', 'G06Q30/0201', 'G06Q30/0282', 'G06V10/82', 'G06V2201/10']"
CN113573331B,"Communication method, device and system","The embodiment of the application provides a communication method, a communication device and a communication system, relates to the field of data analysis, and can expand the application scene of data analysis. The method comprises the following steps: the first data analysis network element sends a first request to the service discovery network element, the first request being for information of the second data analysis network element, the first request comprising: one or more of the information for distributed learning and first indication information, wherein the information for distributed learning includes a type of distributed learning, and the first indication information is used for indicating a type of the second data analysis network element. The first data analysis network element receives information from one or more second data analysis network elements of the service discovery network element, the second data analysis network element supporting a type of distributed learning.","['H04L41/16', 'H04W8/00', 'H04W24/02', 'G06N3/098', 'H04L41/14', 'H04L41/145', 'H04L41/5058', 'H04W60/00', 'H04W24/08']"
CN113283444B,Heterogeneous image migration method based on generation countermeasure network,"The invention discloses a heterogeneous image migration technology based on a generation countermeasure network, and belongs to the technical field of image generation. The method comprises the following specific steps: s1 selecting and making infrared and visible light image data set; s2 performs a loop training of the network model based on the proposed generation countermeasure network architecture STVGAN. S3, reducing the value of the total loss function in the network model to obtain a trained generator network; s4 implements migration from infrared images to visible images through a trained generator network. The invention discloses a heterogeneous image migration algorithm for semi-supervised learning, which is characterized in that a semi-supervised learning method is applied to the field of heterogeneous image migration for the first time, and compared with the traditional supervision method, the image migration effect can be better only by partial matched data.","['G06V10/44', 'G06F18/2132', 'G06N3/045', 'G06N3/088']"
US12367382B2,Training with adaptive runtime and precision profiling,"A mechanism is described for facilitating efficient training of neural networks at computing devices. A method of embodiments, as described herein, includes detecting one or more inputs for training of a neural network, and introducing randomness in floating point (FP) numbers to prevent overtraining of the neural network, where introducing randomness includes replacing less-significant low-order bits of operand and result values with new low-order bits during the training of the neural network.","['G06N3/063', 'G06F7/483', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/098']"
US12293155B2,Out-of-domain data augmentation for natural language processing,"A method includes receiving a training set of utterances for training a machine-learning model to identify one or more intents for one or more utterances, and augmenting the training set of utterances with out-of-domain (OOD) examples. The augmenting includes: generating a data set of OOD examples, filtering out OOD examples from the data set of OOD examples, determining a difficulty value for each OOD example remaining within the filtered data set of the OOD examples, and generating augmented batches of utterances including utterances from the training set of utterances and utterances from the filtered data set of the OOD based on the difficulty value for each OOD. Thereafter, the machine-learning model is trained using the augmented batches of utterances in accordance with a curriculum training protocol.","['G06F40/289', 'G06F40/242', 'G06F40/284', 'G06F40/295', 'G06F40/30', 'G06N20/00', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'H04L51/02']"
US11886446B2,Cross-lingual language models and pretraining of cross-lingual language models,"Existing research on cross-lingual retrieval cannot take good advantage of large-scale pretrained language models, such as multilingual BERT and XLM. The absence of cross-lingual passage-level relevance data for finetuning and the lack of query-document style pretraining are some of the key factors of this issue. Accordingly, embodiments of two novel retrieval-oriented pretraining tasks are presented herein to further pretrain cross-lingual language models for downstream retrieval tasks, such as cross-lingual ad-hoc retrieval (CUR) and cross-lingual question answering (CLQA). In one or more embodiments, distant supervision data was constructed from multilingual texts using section alignment to support retrieval-oriented language model pretraining. In one or more embodiments, directly finetuning language models on part of an evaluation collection was performed by making Transformers capable of accepting longer sequences. Experiments show that model embodiments significantly improve upon general multilingual language models in at least the cross-lingual retrieval setting and the cross-lingual transfer setting.","['G06N20/00', 'G06F16/24578', 'G06F16/3329', 'G06F16/3337', 'G06F40/284', 'G06F40/289', 'G06F40/58']"
US20240370479A1,Semantic search and summarization for electronic documents,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,"['G06V30/416', 'G06F16/316', 'G06F16/3347', 'G06F40/30']"
CN114417421B,Shared information privacy protection method and related device based on meta universe,"According to the shared information privacy protection method and the related device based on the metauniverse, which are provided by the scheme of the application, the transaction data blockchain is established in the online activities based on the application scene of the metauniverse virtual reality; constructing a database model corresponding to the characteristics of the participants in the metauniverse virtual reality application scene according to the transaction data blockchain; the method comprises the steps that through intelligent contracts of a transaction data blockchain, an operation node is controlled to acquire training tasks of information data in a database model; after the running node completes the federal learning training task, the information data is shared. By implementing the scheme of the application, the transaction data blockchain is established in the online activity based on the metauniverse virtual reality application scene, the database model is established on the premise that the data is not separated from the local, the training task of sharing machine learning is issued in the form of intelligent contract, and the information sharing of the online data is realized under the condition of protecting the privacy of the participators.","['G06F21/6245', 'G06F21/602', 'G06F21/6227', 'G06N20/20']"
US11475536B2,Context-aware synthesis for video frame interpolation,"Systems, methods, and computer-readable media for context-aware synthesis for video frame interpolation are provided. Bidirectional flow may be used in combination with flexible frame synthesis neural network to handle occlusions and the like, and to accommodate inaccuracies in motion estimation. Contextual information may be used to enable frame synthesis neural network to perform informative interpolation. Optical flow may be used to provide initialization for interpolation. Other embodiments may be described and/or claimed.","['G06T3/0093', 'G06T3/18', 'G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N5/046', 'G06T3/4007', 'G06T5/50', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'H04N7/0127']"
WO2023161630A1,"Computer implemented methods for the automated analysis or use of data, including use of a large language model","Methods are provided, such as a method of interacting with a large language model (LLM), including the step of a processing system using a structured, machine- readable representation of data that conforms to a machine-readable language, such as a universal language, to provide new context data for the LLM, in order to improve the output, such as continuation text output, generated by the LLM in response to a prompt; and such as a method of interacting with a LLM, including the step of providing continuation data generated by the LLM to a processing system that uses a structured, machine-readable representation of data that conforms to a machine- readable language, such as a universal language, in which the processing system is configured to analyse the continuation output (e.g. text output) generated by the LLM in response to a prompt to enable an improved version of that continuation output to be provided to a user. Related computer systems are provided.","['G06F40/44', 'G06F40/30']"
US10565708B2,Disease detection algorithms trainable with small number of positive samples,"Disease detection from medical images is provided. In various embodiments, a medical image of a patient is read. The medical image is provided to a trained anatomy segmentation network. A feature map is received from the trained anatomy segmentation network. The feature map indicates the location of at least one feature within the medical image. The feature map is provided to a trained classification network. The trained classification network was pre-trained on a plurality of feature map outputs of the segmentation network. A disease detection is received from the trained classification network. The disease detection indicating the presence or absence of a predetermined disease.","['G06V10/82', 'G06F18/24', 'G06K9/00127', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/0012', 'G06T7/0014', 'G06V10/764', 'G06V20/69', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/047', 'G06N5/01', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30048', 'G06V2201/03']"
US20210398338A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate view-specific representations of an object or environment. In at least one embodiment, one or more neural networks are used to generate one or more images based, at least in part, on two or more two-dimensional (2D) images having different frames of reference.","['G06T11/003', 'G06T17/05', 'G06V10/772', 'G06F18/21', 'G06F18/214', 'G06K9/46', 'G06K9/6217', 'G06K9/726', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T11/00', 'G06T15/00', 'G06T17/10', 'G06T17/30', 'G06T7/20', 'G06T7/55', 'G06T7/70', 'G06V10/774', 'G06V10/82', 'G06V20/58', 'G06V30/274', 'H04N13/271', 'G06N3/063', 'G06T2207/10028', 'G06T2207/20004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
US20210073291A1,Adaptive parameter transfer for learning models,"A process includes obtaining a directed graph of a symbolic artificial intelligence model used by a first entity, the directed graph comprising a first set of vertices and a first set of edges associating pairs of vertices of the first set of vertices. The method also includes determining a set of features based on the directed graph that includes an identifier of a graph portion template, where each respective vertex of the graph portion template of the graph portion template is labeled with a same category from the set of mutually-exclusive categories as a corresponding respective vertex of a graph portion of the directed graph. The method also includes obtaining a set of model parameter values for a machine learning model based on the graph portion template and providing the set of model parameter values and the graph portion templates the first entity.","['G06F21/64', 'G06F8/33', 'G06F16/1858', 'G06F16/23', 'G06F16/9024', 'G06F16/904', 'G06F16/951', 'G06F17/18', 'G06F8/65', 'G06F9/44505', 'G06F9/5038', 'G06F9/547', 'G06N3/006', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/086', 'G06N5/01', 'H04L63/123', 'H04L67/133', 'H04L67/40', 'H04L9/3239', 'H04L9/3263', 'H04L9/50', 'G06N3/044']"
US11052874B2,Recognizing authorized vehicle user with movement data,"The invention relates to a method for authenticating a vehicle user. In the method, movement data of a sensor identification circuit are detected by sensors. The detected movement data are supplied to a self-learning system. The self-learning system ascertains a movement profile based on the supplied movement data and assigns this to a vehicle user. Upon approach of the vehicle by a vehicle user, it is checked whether movement data detected at the point in time of the approach corresponds to a movement profile, which is assigned to a vehicle user authorized to use the vehicle. In the event of a match, the vehicle user approaching the vehicle is authorized to use the vehicle.","['B60R25/31', 'B60R25/01', 'B60R25/24', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/09', 'G06N3/091', 'G06N3/08']"
US20230255553A1,Speech analysis for monitoring or diagnosis of a health condition,"The invention relates to a computer-implemented method of training a machine learning model for performing speech analysis for monitoring or diagnosis of a health condition. The method uses training data comprising audio speech data and comprises obtaining one or more linguistic representations that each encode a sub-word, word, or multiple word sequence, of the audio speech data; obtaining one or more audio representations that each encode audio content of a segment of the audio speech data; combining the linguistic representations and audio representations into an input sequence comprising: linguistic representations of a sequence of one or more words or sub-words of the audio speech data; and audio representations of segments of the audio speech data, where the segments together contain the sequence of the one or more words or sub-words. The method further includes training a machine learning model using unsupervised learning to map the input sequence to a target output to learn combined audio-linguistic representations of the audio speech data for use in speech analysis for monitoring or diagnosis of a health condition.","['G10L25/66', 'A61B5/4803', 'A61B5/7264', 'A61B5/7267', 'G10L25/30']"
US20200222010A1,System and method for deep mind analysis,"Embodiments of the present invention may provide techniques for brain interfacing, mapping neuronal structure, manipulating cellular structure, cognitive and brain augmentation via implants, and curing, not just managing, neurological disorders. For example, a method for deep mind analysis may comprise receiving electrical and optical signals from electrophysiological neural signals of brain tissue from at least one read modality, encoding the received electrical and optical signals using a Fundamental Code Unit, automatically generating at least one machine learning model using the Fundamental Code Unit encoded electrical and optical signals, generating at least one optical or electrical signal to be transmitted to the brain tissue using the generated at least one machine learning model, and transmitting the generated at least one optical or electrical signal to the brain tissue to provide electrophysiological stimulation of the brain tissue using at least one write modality.","['A61N5/0601', 'A61B5/04001', 'A61B5/24', 'A61B5/4836', 'A61B5/686', 'A61B5/7267', 'A61N1/0529', 'A61N1/3605', 'A61N1/36139', 'A61N5/0603', 'A61N5/0622', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/126', 'G06N5/01', 'G06N5/02', 'G06N7/01', 'G16H20/30', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/50', 'A61B5/0042', 'A61B5/053', 'A61B5/055', 'A61B5/11', 'A61B5/16', 'A61B5/369', 'A61B5/4803', 'A61B6/032', 'A61B6/037', 'A61N1/0531', 'A61N1/0536', 'A61N2/002', 'A61N2/006', 'A61N2005/0626', 'A61N2005/0651', 'G06N3/006', 'G06N3/044', 'G06N3/047']"
US20210142448A1,Adaptive deformable kernel prediction network for image de-noising,"Embodiments are generally directed to an adaptive deformable kernel prediction network for image de-noising. An embodiment of a method for de-noising an image by a convolutional neural network implemented on a compute engine, the image including a plurality of pixels, the method comprising: for each of the plurality of pixels of the image, generating a convolutional kernel having a plurality of kernel values for the pixel; generating a plurality of offsets for the pixel respectively corresponding to the plurality of kernel values, each of the plurality of offsets to indicate a deviation from a pixel position of the pixel; determining a plurality of deviated pixel positions based on the pixel position of the pixel and the plurality of offsets; and filtering the pixel with the convolutional kernel and pixel values of the plurality of deviated pixel positions to obtain a de-noised pixel.","['G06T1/20', 'G06T5/002', 'G06T5/70', 'G06F9/3802', 'G06F9/3804', 'G06F9/3887', 'G06F9/5027', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/082', 'G06T3/4046', 'G06T5/60', 'G06N3/084', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084']"
US11278668B2,Analyte sensor and medicant delivery data evaluation and error reduction apparatus and methods,"Apparatus and methods for error modeling and correction in one or both of (i) a partially or fully implanted or non-implanted medicant delivery mechanism (such as a pump), and (ii) implanted physiologic parameter sensor. In one exemplary embodiment, the apparatus and methods employ a training mode of operation, whereby the apparatus conducts “machine learning” to model one or more errors (e.g., unmodeled variable system errors) associated with the medicant dose calculation process, and (ii) generation of a medicant delivery operational model (based at least in part on data collected/received in the training mode), which is applied to correct or compensate for the errors during normal operation of the sensor and pump system. This enhances accuracy of medicant delivery, such as over the lifetime of an implanted pump at a single implantation site, or during multiple relocations of a transcutaneously implanted pump), and enables “personalization” of the pump to each user.","['A61M5/14276', 'A61B5/0004', 'A61B5/14532', 'A61B5/1468', 'A61B5/4839', 'A61M5/1723', 'G16H10/60', 'G16H20/17', 'G16H40/63', 'G16H50/00', 'G16H50/20', 'G16H50/50', 'A61B2560/0247', 'A61B5/7264', 'Y02A90/10']"
US20210138249A1,System and method for neural stimulation using spike frequency modulation,"Embodiments may comprise receiving electrical and optical signals from electrophysiological neural signals of neural tissue from at least one read modality, wherein the electrophysiological neural signals are at least one of Spike frequency modulated or Spike frequency demodulated, encoding the received electrical and optical signals using a Fundamental Code Unit, automatically generating at least one machine learning model using the Fundamental Code Unit encoded electrical and optical signals, generating at least one optical or electrical signal to be transmitted to the brain tissue using the generated at least one machine learning model, wherein the generated signals are at least one of Spike frequency modulated or Spike frequency demodulated, and transmitting the generated at least one optical or electrical signal to the neural tissue to provide electrophysiological stimulation of the neural tissue using at least one write modality.","['A61B5/0031', 'A61B5/0084', 'A61B5/076', 'A61B5/1473', 'A61B5/37', 'A61B5/375', 'A61B5/4076', 'A61B5/6868', 'A61N1/36139', 'A61N1/37252', 'A61N5/0622', 'A61N5/067', 'B82Y10/00', 'G06F3/015', 'G06N3/049', 'G06N3/086', 'G16H10/60', 'G16H20/30', 'G16H20/40', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'A61B5/0024', 'A61B5/6815', 'A61N1/0531', 'A61N1/36067', 'A61N1/36071', 'A61N1/36082', 'A61N2005/0612', 'A61N2005/0626', 'A61N2005/063', 'A61N2005/0652', 'A61N2005/0663', 'A61N5/0601', 'A61N5/0618', 'B82Y30/00', 'B82Y5/00', 'G06N3/084', 'G06N3/088']"
US12254526B2,On chip dense memory for temporal buffering,"Apparatuses including general-purpose graphics processing units having on chip dense memory for temporal buffering are disclosed. In one embodiment, a graphics multiprocessor includes a plurality of compute engines to perform first computations to generate a first set of data, cache for storing data, and a high density memory that is integrated on chip with the plurality of compute engines and the cache. The high density memory to receive the first set of data, to temporarily store the first set of data, and to provide the first set of data to the cache during a first time period that is prior to a second time period when the plurality of compute engines will use the first set of data for second computations.","['G06T1/20', 'G06F15/7807', 'G06F12/0868', 'G06F15/17', 'G06F16/1724', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06T1/60']"
US12373912B2,Prefetch status notification for memory prefetching,"Embodiments are generally directed to memory prefetching in multiple GPU environment. An embodiment of an apparatus includes multiple processors including a host processor and multiple graphics processing units (GPUs) to process data, each of the GPUs including a prefetcher and a cache; and a memory for storage of data, the memory including a plurality of memory elements, wherein the prefetcher of each of the GPUs is to prefetch data from the memory to the cache of the GPU; and wherein the prefetcher of a GPU is prohibited from prefetching from a page that is not owned by the GPU or by the host processor.","['G06F12/0862', 'G06T1/20', 'G06F12/084', 'G06F12/0842', 'G06F12/1009', 'G06F9/3802', 'G06F9/3877', 'G06T1/60', 'G06T15/005']"
US12124383B2,Systems and methods for cache optimization,"Systems and methods for improving cache efficiency and utilization are disclosed. In one embodiment, a graphics processor includes processing resources to perform graphics operations and a cache controller of a cache memory that is coupled to the processing resources. The cache controller is configured to set an initial aging policy using an aging field based on age of cache lines within the cache memory and to determine whether a hint or an instruction to indicate a level of aging has been received. In one embodiment, the cache memory configured to be partitioned into multiple cache regions, wherein the multiple cache regions include a first cache region having a cache eviction policy with a configurable level of data persistence.","['G06F12/123', 'G06F12/0875', 'G06F12/0891', 'G06F12/126', 'G06T1/60', 'G06F2212/302']"
US10909039B2,Data prefetching for graphics data processing,"Embodiments are generally directed to data prefetching for graphics data processing. An embodiment of an apparatus includes one or more processors including one or more graphics processing units (GPUs); and a plurality of caches to provide storage for the one or more GPUs, the plurality of caches including at least an L1 cache and an L3 cache, wherein the apparatus to provide intelligent prefetching of data by a prefetcher of a first GPU of the one or more GPUs including measuring a hit rate for the L1 cache; upon determining that the hit rate for the L1 cache is equal to or greater than a threshold value, limiting a prefetch of data to storage in the L3 cache, and upon determining that the hit rate for the L1 cache is less than a threshold value, allowing the prefetch of data to the L1 cache.","['G06F12/0862', 'G06F12/0888', 'G06F12/0897', 'G06T1/20', 'G06T1/60', 'G06F2212/1024', 'G06F2212/502', 'G06F2212/602', 'G06F2212/608', 'G06F9/3802', 'Y02D10/00']"
US11823381B2,Knowledge distillation with adaptive asymmetric label sharpening for semi-supervised fracture detection in chest x-rays,"Knowledge distillation method for fracture detection includes obtaining medical images including region-level labeled images, image-level diagnostic positive images, and image-level diagnostic negative images, in chest X-rays; performing a supervised pre-training process on the region-level labeled images and the image-level diagnostic negative images to train a neural network to generate pre-trained weights; and performing a semi-supervised training process on the image-level diagnostic positive images using the pre-trained weights. A teacher model is employed to produce pseudo ground-truths (GTs) on the image-level diagnostic positive images for supervising training of a student model, and the pseudo GTs are processed by an adaptive asymmetric label sharpening (AALS) operator to produce sharpened pseudo GTs to provide positive detection responses on the image-level diagnostic positive images.","['G06T7/0012', 'G06F18/2155', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06V10/82', 'G06V20/70', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06V2201/03']"
CN109815955B,Question assisting method and system,"The disclosure relates to a topic auxiliary method, comprising: acquiring an image at least comprising a first subject presented on a first surface through an image acquisition device; identifying a first region where the first subject is located in the image based on the image through a first computing device and a pre-trained first neural network model; identifying, by a second computing device and a pre-trained second neural network model, characters in the first region based on the first region, thereby obtaining the first topic; judging the type of the first question based on the first question through a third computing device and a pre-trained third neural network model; if the type of the first topic is a calculation topic, then: generating a first answer to the computational questions and a stepped problem solving process by a fourth computing device and a fifth computing device respectively; and displaying the question of the calculation question, the first answer and the step solving question process through a display device.","['G09B19/025', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V20/62', 'G06V30/274', 'G09B7/00', 'G09B7/02', 'G06N5/041', 'G06V30/10']"
US11803751B2,Training text summarization neural networks with an extracted segments prediction objective,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a text summarization neural network. One of the methods includes pre-training the text summarization neural network including learning values of a plurality of network parameters through self-supervised learning using unlabeled data comprising unlabeled first texts, the pre-training including: obtaining an unlabeled first text comprising a plurality of segments; selecting one or more of the plurality of segments; processing a masked first text that excludes the one or more selected segments to generate a prediction of the one or more selected segments; and determining, based on a difference between the prediction and the one or more selected segments, an update to the current values of the plurality of network parameters; adapting the pre-trained text summarization neural network for a specific text summarization task using labeled data comprising second texts and respective summaries of the second texts.","['G06F40/56', 'G06N3/08', 'G06F40/284', 'G06F40/30', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/0895', 'G06N3/09']"
US11341368B2,Methods and systems for advanced and augmented training of deep neural networks using synthetic data and innovative generative networks,"Methods and systems for advanced and augmented training of deep neural networks (DNNs) using synthetic data and innovative generative networks. A method includes training a DNN using synthetic data, training a plurality of DNNs using context data, associating features of the DNNs trained using context data with features of the DNN trained with synthetic data, and generating an augmented DNN using the associated features.","['G06V30/194', 'G06K9/6257', 'G06F18/2148', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T1/20', 'G06V10/82', 'G06V10/955', 'G06N3/088', 'G06N3/098']"
EP4101371A1,"Electroencephalogram signal classifying method and apparatus, electroencephalogram signal classifying model training method and apparatus, and medium","An electroencephalogram signal classifying method and apparatus, an electroencephalogram signal classifying model training method and apparatus, and a medium, relating to the field of transfer learning. The method comprises: obtaining an electroencephalogram signal (201); performing feature extraction on the electroencephalogram signal to obtain a signal feature corresponding to the electroencephalogram signal (202); obtaining a differential distribution ratio for representing an effect of different types of differential distributions on the distribution of the signal feature and a source domain feature on a feature domain, the source domain feature being a feature corresponding to a source domain electroencephalogram signal (203); aligning the signal feature with the source domain feature according to the differential distribution ratio, to obtain an aligned signal feature (204); and classifying the aligned signal feature to obtain a motor imagery type corresponding to the electroencephalogram signal (205). By dynamically adjusting, by means of a differential distribution ratio, the distribution of a signal feature corresponding to an electroencephalogram signal on a feature domain, an electroencephalogram signal classifying model can recognize multiple types of electroencephalogram signals on the basis of the idea of transfer learning.","['B25J9/0006', 'A61B5/7267', 'A61B5/369', 'A61B5/374', 'A61B5/7275', 'A61G5/04', 'A61G5/1051', 'A61H3/00', 'A63F13/212', 'A63F13/35', 'A63F13/42', 'A63F13/55', 'A63F13/67', 'B25J13/00', 'B25J13/006', 'G06F3/015', 'G16H50/20', 'G16H50/70', 'A61B2505/09', 'A61G2203/10', 'A61G2203/18', 'A61G5/10', 'A61H2003/005', 'A61H2003/007', 'A61H2201/5007', 'A61H2201/5041', 'A63F2300/1012', 'A63F2300/8082']"
US20200405204A1,Detection of catecholamine levels inside the neurocranium,"Embodiments of the present invention may provide techniques that provide improved detection of catecholamines, such as dopamine. For example, in an embodiment, a method for catecholamine sensing may comprise outputting a signal responsive to a level of at least one catecholamine in neural tissue from a catecholamine sensor, analyzing the signal responsive to a catecholamine level in the neural tissue using circuitry connected to the catecholamine sensor, the circuitry comprising at least one computing device comprising a processor, memory accessible by the processor, and program instructions stored in the memory and executable by the processor, generating, using the circuitry, data representing the catecholamine level in the neural tissue, and transmitting the generated data representing the catecholamine level in the neural tissue using communication circuitry.","['A61B5/14503', 'A61B5/14546', 'A61B5/686', 'A61B5/6868', 'A61B5/72', 'A61B5/7267', 'B82Y15/00', 'A61B2562/0285', 'A61B5/167', 'A61B5/168', 'A61B5/4082', 'A61B5/4088', 'A61N1/0531', 'A61N1/3605', 'B82Y30/00']"
KR102097905B1,Apparatus and method for recognizing one or more objects in images,"According to one embodiment of the present disclosure, an image object recognition apparatus may comprise: a preprocessing module configured to receive an image including an object and output a preprocessed image by performing image enhancement processing on the received image in order to improve a recognition rate of the object included in the received image; and an object recognition module configured to recognize the object included in the image by inputting the preprocessed image as an input layer of an artificial neural network for object recognition.","['G06T7/11', 'G06V10/82', 'G06V20/10', 'G06F18/2148', 'G06F18/217', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06N5/041', 'G06T3/4015', 'G06T5/00', 'G06T5/002', 'G06T5/003', 'G06T5/007', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T5/90', 'G06T5/92', 'G06T7/10', 'G06T7/74', 'G06V10/20', 'G06V10/7792', 'G06V10/95', 'G06V20/41', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
CN117573834B,Multi-robot dialogue method and system for software-oriented instant service platform,"The invention provides a multi-robot dialogue method and a system for a software-oriented service platform, wherein the method comprises the following steps: receiving dialogue content input by a user, performing dialogue management on complexity and question types of the dialogue content, and determining whether a flow robot is triggered or whether questions answered by a similar question robot belong to; preprocessing the current dialogue content of the user to obtain the user intention of the dialogue content; judging whether to trigger the corresponding business process directly according to the user intention, and triggering to guide the user to enter the business process directly; the user intention does not have a corresponding business flow, a model RAG flow is generated by calling the retrieval enhancement of the dialogue according to the enterprise from which the user dialogue comes and the intention of the user, a final answer is provided for the user, and the dialogue is ended; the system comprises: the device comprises a dialogue management module, a preprocessing module and a trigger judgment module. The invention improves the intelligence and the accuracy of the dialogue system, can better understand and answer the user questions, and provides better user experience.","['G06F16/3329', 'G06F40/151', 'G06F40/295', 'G06F40/30', 'G06N3/04', 'G06N3/08', 'G06Q10/103', 'Y02D10/00']"
WO2023016007A1,"Method and apparatus for training facial recognition model, and computer program product","The present disclosure relates to the field of artificial intelligence, and particularly relates to computer vision and deep learning technology. Provided are a method and apparatus for training a facial recognition model, and an electronic device, a storage medium and a computer program product, which can be applied to a facial recognition scenario. The specific implementation solution involves: acquiring a training sample set, wherein training samples in the training sample set comprise sample facial images and category labels; and by using a machine learning method, taking the sample facial images as inputs and taking the category labels, which correspond to the input sample facial images, as expected outputs of two target fully connected layers in an initial facial recognition model, performing training to obtain a facial recognition model, wherein the two target fully connected layers sequentially model a sample facial image which comprises a covering object and a sample facial image which does not comprise a covering object. By means of the present disclosure, the recognition accuracy of a facial recognition model is improved.",['G06F18/214']
US20200184838A1,Apparatus and method for remotely providing instructional and/or educational information and/or services in a network environment,"An apparatus, including a first device, which includes a first display and first video and audio recording device; a second device, which includes a second display and second video and audio recording device, wherein the first and second video and audio recording devices facilitate a video conference between a first and second individual; a memory which stores information regarding an instructional or educational account for the first or second individual; a third video and audio recording device which records video of a class, lesson, or seminar, and which is located at a location of the same; a computer which processes information for providing a first video transmission and a second video transmission to the first device and the second device, and a transmitter which transmits the first and second video transmissions to the first device and second devices simultaneously and in a split screen or multiple screen format.","['G09B5/06', 'G09B19/00', 'G09B19/0038', 'H04L12/1831', 'H04N7/15']"
US11592817B2,Storage management for machine learning at autonomous machines,"A mechanism is described for facilitating storage management for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting one or more components associated with machine learning, where the one or more components include memory and a processor coupled to the memory, and where the processor includes a graphics processor. The method may further include allocating a storage portion of the memory and a hardware portion of the processor to a machine learning training set, where the storage and hardware portions are precise for implementation and processing of the training set.","['G06T1/20', 'G05D1/0088', 'G05D1/00', 'G06F15/167', 'G06F15/17', 'G06F7/57', 'G06F9/3867', 'G06F9/3887', 'G06F9/5016', 'G06F9/5061', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/0499', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/60', 'G06N3/044', 'G06N3/0445', 'Y02D10/00']"
US12353334B2,System cache optimizations for deep learning compute engines,"In an example, an apparatus comprises a plurality of compute engines; and logic, at least partially including hardware logic, to detect a cache line conflict in a last-level cache (LLC) communicatively coupled to the plurality of compute engines; and implement context-based eviction policy to determine a cache way in the cache to evict in order to resolve the cache line conflict. Other embodiments are also disclosed and claimed.","['G06F12/128', 'G06F12/084', 'G06F12/0895', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06F2212/601', 'G06F2212/6042', 'G06F2212/6046', 'G06N20/00']"
US20230222314A1,"System and Method for Capturing, Preserving, and Representing Human Experiences and Personality Through a Digital Interface","A system and method to capture and interact with a comprehensive digital record of an individual's biographical history and produce a synthetic model of their personality. The captured biographical history is a detailed record of this individual's actions, interactions, and experiences over a period which may span decades of their lifetime. The biographical history is indexed by areas of data variability and neural network confidence variability to identify points of likely human interest. A synthetic personality model is generated as a representation of the individual's personality structure, biases, sentiments, and traits. The synthetic personality can be interacted with through a digital interface and demonstrates the interaction patterns, triggers, and habits of the original individual. The functioning and the performance of the system over an individual's lifespan are optimized through data synthesis and disposition.","['G06F16/2219', 'A61B5/167', 'G06F16/2477', 'G06F16/285', 'G06F16/287', 'G06N3/006', 'G06N3/094', 'G06T13/40', 'G06V10/764', 'G06V40/174', 'G06V40/20', 'G10L25/63', 'G06N3/045', 'G06N3/08']"
WO2023092923A1,Composite interference signal recognition method and system,"Disclosed in the present application are a composite interference signal recognition method and system. The method comprises: preprocessing a composite interference signal to be recognized, and acquiring multi-domain features of said preprocessed composite interference signal; respectively inputting the acquired multi-domain features into a pre-trained deep learning neural network model on the basis of dimensions corresponding thereto, inputting one-dimensional sequence features into a one-dimensional sequence feature extraction module, inputting multi-dimensional sequence features into a multi-dimensional sequence feature extraction module, and then respectively extracting domain features of different dimensions; and inputting the extracted domain features of different dimensions into a feature fusion layer and a fully connected layer of the pre-trained deep learning neural network model, so as to obtain a classification recognition result of the composite interference signal.","['G06F2218/04', 'G06N3/044', 'G06N3/045', 'G06F2218/08', 'G06F2218/12', 'G06F2218/22']"
US20230144184A1,Advanced geological prediction method and system based on perception while drilling,"An advanced geological prediction method and system based on perception while drilling, and relates to advanced geological prediction. The solution includes: acquiring drilling parameters during drilling; obtaining physical and mechanical parameters of tunnel surrounding rocks by inversion based on drilling parameters; acquiring rock slag or powder based on flushing fluid collected during drilling; acquiring geochemical characteristic parameters of rock slag or powder; and obtaining at least one adverse geology recognition result and surrounding rock classification result using a pre-trained deep learning model, and realizing advanced geological prediction. Combined with advanced geological drilling, the solution reflects geological characteristics from changes of physical and mechanical properties of tunnel surrounding rocks and changes of geochemical characteristic parameters. Advanced prediction of geology ahead of a tunnel face is realized by collection and analysis of drilling parameters and flushing fluid during advanced drilling and the fusion of big data and a deep learning algorithm.","['E21B49/003', 'G06F30/13', 'E21B47/00', 'E21B49/005', 'E21D9/003', 'E21F17/18', 'G06F30/27', 'G06N3/045', 'G06N3/084', 'E21B2200/20', 'E21B2200/22', 'G06F2119/14']"
EP3754548A1,A method for recognizing an object in an image using features vectors of an encoding neural network,"The present disclosure relates to a method for recognizing an object in an input image. The method comprises: providing an image encoder (120, 502, 601) configured to encode an image to provide a visual feature vector representing the image in an image space, the image encoder comprising a trained convolutional neural network (121), wherein the image space is defined by a fully connected layer of the convolutional neural network. Visual center of mass vectors (122, 123, 124, 504.1-M, 533.1-M) representing object classes in the image space may be provided. The image encoder (120, 502, 601) may encode the input image (505) to provide an input visual feature vector (506) representing the input image (505). The object may be recognized by selecting one of the visual center of mass vectors (504.1-M, 533.1-M) using a proximity criterion relative to the input visual feature vector (506).",['G06F18/24133']
US10638979B2,Analyte sensor data evaluation and error reduction apparatus and methods,"Apparatus and methods for error modeling and correction in a blood analyte sensor or system. In one exemplary embodiment, the apparatus employs: (i) a training mode of operation, whereby the apparatus conducts “machine learning” to model one or more errors (e.g., unmodeled variable system errors) associated with the blood analyte measurement process, and (ii) generation of an operational model (based at least in part on data collected/received in the training mode), which is applied to correct or compensate for the errors during normal operation and collection of blood analyte data. This enhances device signal stability and accuracy over extended periods, thereby enabling among other things extended periods of blood analyte sensor implantation, and “personalization” of the sensor apparatus to each user receiving an implant. In one variant, the blood analyte is glucose, and the implanted sensor utilizes an oxygen-based molecular measurement principle.","['A61B5/7267', 'A61B5/0022', 'A61B5/14532', 'A61B5/1473', 'A61B5/686', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G06N99/005', 'G16H10/40', 'G16H40/67', 'G16H50/50', 'G16H50/70', 'A61B2560/0223']"
US9443320B1,Multi-object tracking with generic object proposals,"A tracking system and method are suited to tracking multiple of objects of different categories in a video sequence. A sequence of video frames is received and a set of windows is extracted from each frame in turn, based on a computed probability that the respective window contains an object, without reference to any specific category of object. For each of these windows, a feature representation is extracted. A trained detector for a selected category detects windows that constitute targets in that category, based on the respective feature representations. More than one detector can be used when there is more than one category of objects to be tracked. A target-specific appearance model is generated for each of the targets (e.g., learned or updated, if the target is present in a prior frame). The detected targets are tracked over one or more subsequent frames based on the target-specific appearance models of the targets.","['G06V10/764', 'G06T7/2033', 'G06V10/454', 'G06F18/24133', 'G06K9/00', 'G06T7/004', 'G06T7/20', 'G06V10/25', 'G06V20/52', 'G06T2207/10016', 'G06T2207/20081', 'G06V10/62']"
US20240153499A1,Contextual natural language processing,"Multi-modal natural language processing systems are provided. Some systems are context-aware systems that use multi-modal data to improve the accuracy of natural language understanding as it is applied to spoken language input. Machine learning architectures are provided that jointly model spoken language input (“utterances”) and information displayed on a visual display (“on-screen information”). Such machine learning architectures can improve upon, and solve problems inherent in, existing spoken language understanding systems that operate in multi-modal contexts.","['G10L15/16', 'G06F3/167', 'G10L15/02', 'G10L15/144', 'G10L15/1822', 'G10L15/197', 'G10L15/22', 'G10L15/26', 'G10L2015/025', 'G10L2015/228']"
US11170395B2,Digital banking platform and architecture,"A computer implemented device is described that is adapted for improving memory efficiency for conducting machine learning on multi-dimensional vectors stored as specially configured data structures. The device includes network interfaces adapted for receiving data sets and communicating with data harvesting applications, as well as data storage and memory for storing the configured data structures. The multi-dimensional vectors and the system provide a data architecture that processes disparate data sets to programmatically extract features transformed from raw information, the extracted features stored in the form of data values suitable for conducting data approximations and neural network processing.","['G06Q30/02', 'G06F18/214', 'G06F18/24', 'G06K9/6256', 'G06K9/6267', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06Q30/0211', 'G06Q30/0214', 'G06Q40/02', 'G06Q50/01', 'G06N3/044', 'G06N3/0445']"
RU2762936C2,System for assessing substance preparation,FIELD: computer technology.,"['G06T7/62', 'C12M41/46', 'G01N35/1011', 'G01N35/1016', 'G06T7/0014', 'G06T7/10', 'G06T7/90', 'G06V10/255', 'G06V10/50', 'G06V10/56', 'G06V20/50', 'G06V20/69', 'G01N15/075', 'G01N2015/012', 'G01N2035/103', 'G06T2207/10024', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30072']"
US11977625B2,Using multimodal model consistency to detect adversarial attacks,"A method, apparatus and computer program product to defend learning models that are vulnerable to adversarial example attack. It is assumed that data (a “dataset”) is available in multiple modalities (e.g., text and images, audio and images in video, etc.). The defense approach herein is premised on the recognition that the correlations between the different modalities for the same entity can be exploited to defend against such attacks, as it is not realistic for an adversary to attack multiple modalities. To this end, according to this technique, adversarial samples are identified and rejected if the features from one (the attacked) modality are determined to be sufficiently far away from those of another un-attacked modality for the same entity. In other words, the approach herein leverages the consistency between multiple modalities in the data to defend against adversarial attacks on one modality.","['G06F21/554', 'G06F21/52', 'G06F21/54', 'G06F21/64', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06F2221/033', 'G06N3/048']"
US11360819B2,Systems and methods for data management,"A method for data management is provided. The method comprises: storing the plurality of items in a contiguous space within the memory, executing an instruction containing an address and a size that together identify the contiguous space to transmit the plurality of items from the main memory to a random-access memory (RAM) on a chip, and the chip includes a computing unit comprising a plurality of multipliers; and instructing the computing unit on the chip to: retrieve multiple of the plurality of items from the RAM; and perform a plurality of parallel operations using the plurality of multipliers with the multiple items to yield output data.","['G06F9/5044', 'G06F13/1678', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06V10/82', 'G06V10/95', 'G06N3/02', 'G06N3/06', 'Y02D10/00']"
EP4242926A1,Systems and methods for securing artificial intelligence systems for edge computing systems,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media that support security-aware compression of machine learning (ML) and/or artificial intelligence (AI) models, such as for use by edge computing systems. Aspects described herein leverage cybersecurity threat models, particularly models of ML/AI-based threats, during iterative pruning to improve security of compressed ML models. To illustrate, iterative pruning may be performed on a pre-trained ML model until stop criteria are satisfied. This iterative pruning may include pruning an input ML model based on pruning heuristic(s) to generate a candidate ML model, testing the candidate ML model based on attack model(s) to generate risk assessment metrics, and updating the heuristic(s) based on the risk assessment metrics. If the risk assessment metrics fail to satisfy the stop criteria, the candidate ML model may be provided as input to a next iteration of the iterative pruning.","['G06F21/577', 'G06N3/082', 'G06N3/0495', 'G06N3/094', 'H04L63/08', 'G06N3/048']"
US9992641B2,"Electronic device, server, and method for outputting voice","According to an embodiment of the present disclosure, an electronic device may include a camera module obtaining image data of a user, a controller configured to detect at least one feature corresponding to an intention of the user from the image data obtained by the camera module, to obtain a pattern based on the at least one feature, to determine text data corresponding to the pattern, and to convert at least a portion of the text data into voice data, and an output module outputting the voice data. Other various embodiments of the pattern recognition are also provided.","['G10L15/26', 'G10L13/08', 'H04W4/14', 'G06K9/00288', 'G06K9/00302', 'G06K9/00355', 'G06V40/172', 'G06V40/174', 'G06V40/28', 'G10L15/24', 'G10L15/30', 'G10L25/30', 'G10L25/57', 'H04M1/724', 'H04M1/72475', 'H04M1/72519', 'H04M1/72588', 'G09B21/04', 'H04M1/663', 'H04M2250/52', 'H04M2250/74']"
US20230315722A1,Methods and apparatus for natural language interface for constructing complex database queries,"In some embodiments, a processor receives, via an interface, natural language data associated with a user request for performing an identified computational task associated with a cybersecurity management system. The processor is configured to provide the natural language data as input to a machine learning (ML) model. The ML model is configured to automatically infer a template query based on the natural language data. The processor is further configured to cause the template query to be displayed, via the interface. The processor is further configured to receive, via the interface, user input indicating a finalized query associated with the identified computational task, and to provide the finalized query as input to a system configured to perform the identified computational task. The processor is further configured to modify a security setting in the cybersecurity management system based on the performance of the identified computational task.","['G06F16/2428', 'G06F16/3322', 'G06F16/243', 'G06F16/90324', 'G06N20/00', 'H04L63/20']"
US12028452B2,Establishing a trained machine learning classifier in a blockchain network,"Disclosed is a neural network enabled interface server and blockchain interface establishing a blockchain network implementing event detection, tracking and management for rule based compliance, with significant implications for anomaly detection, resolution and safety and compliance reporting.","['H04L9/14', 'H04L9/0822', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N5/025', 'H04L9/3239', 'H04L9/50', 'G06N3/048']"
US20250053797A1,Compute optimization mechanism for deep neural networks,An apparatus to facilitate compute optimization is disclosed. The apparatus includes a at least one processor to perform operations to implement a neural network and compute logic to accelerate neural network computations.,"['G06F9/3851', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/046', 'G06T1/20', 'G06N3/048', 'G06N3/088']"
US12001944B2,Tool for facilitating efficiency in machine learning,"A mechanism is described for facilitating smart distribution of resources for deep learning autonomous machines. A method of embodiments, as described herein, includes detecting one or more sets of data from one or more sources over one or more networks, and introducing a library to a neural network application to determine an optimal point at which to apply frequency scaling without degrading performance of the neural network application at a computing device.","['G06N3/063', 'G06F9/46', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06N5/01', 'G06F9/505']"
AU2020293557B2,A neural network model for cochlear mechanics and processing,"A method and hearing device (100) for emulating cochlear processing of auditory stimuli are disclosed, in which a multilayer convolutional encoder-decoder neural network (10) sequentially compresses and then decompresses a time-domain input comprising a plurality of samples. At least one nonlinear unit for applying a nonlinear transformation is mimicking a level-dependent cochlear filter tuning associated with cochlear mechanics and outer hair cells. Other described modules cover inner-hair-cell and auditory-nerve fiber processing. A plurality of shortcut connections (15) is directly forwarding inputs between convolutional layers of the encoder (11) and the decoder (12). An output layer (14) is generating, for each input to the neural network, N output sequences of cochlear response parameters corresponding to N emulated cochlear filters associated with N different center frequencies to span a cochlear tonotopic place-frequency map. A transducer (105) of the hearing device converts output sequences generated by the neural network (10) into auditory-stimulus dependent audible time-varying pressure signals, or basilar-membrane vibrations, inner-hair-cell potentials, auditory-nerve firing patterns or population coding thereof for auditory or augmented hearing applications.","['G06N3/084', 'A61N1/36038', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G10L21/0364', 'H04R25/606', 'G10L25/30', 'H04R2225/41', 'H04R25/507']"
US12198221B2,Compute optimization mechanism for deep neural networks,"Embodiments provide mechanisms to facilitate compute operations for deep neural networks. One embodiment comprises a graphics processing unit comprising one or more multiprocessors, at least one of the one or more multiprocessors including a register file to store a plurality of different types of operands and a plurality of processing cores. The plurality of processing cores includes a first set of processing cores of a first type and a second set of processing cores of a second type. The first set of processing cores are associated with a first memory channel and the second set of processing cores are associated with a second memory channel.","['G06F9/45533', 'G06F9/5061', 'G06F9/5094', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06F2009/45583', 'G06F8/41', 'Y02D10/00']"
CN112989834B,Named entity identification method and system based on flat grid enhanced linear converter,"The invention discloses a named entity recognition method and system based on a plain grid enhanced linear converter, and belongs to the field of natural language processing named entity recognition. Firstly, acquiring a text sequence sample, labeling the label type of an entity, and converting the text sequence into a flat lattice structure; then, identifying a model, and training the named entity identification model through a minimized negative log-likelihood loss function; in the named entity recognition process, a text sequence to be recognized is preprocessed through a text and then used as an input of a trained named entity recognition model, and a recognition result is obtained according to a maximum prediction score. The invention introduces the vocabulary information to enhance the vocabulary based on a more efficient flat structure, provides prior knowledge and the vocabulary boundary information of the entity for the model, and improves the recognition accuracy of the model to the entity boundary and the entity type. The linear converter is used for modeling the context information, so that the model complexity is reduced, the model operation efficiency is obviously improved, and the method has higher practical value.","['G06F40/295', 'G06N3/044', 'G06N3/08']"
US11410050B2,Imitation training for machine learning systems with synthetic data generators,"Various systems and methods are described herein for improving the aggressive development of machine learning systems. In machine learning, there is always a trade-off between allowing a machine learning system to learn as much as it can from training data and overfitting on the training data. This trade-off is important because overfitting usually causes performance on new data to be worse. However, various systems and methods can be utilized to separate the process of detailed learning and knowledge acquisition and the process of imposing restrictions and smoothing estimates, thereby allowing machine learning systems to aggressively learn from training data, while mitigating the effects of overfitting on the training data.","['G06N3/088', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/048', 'G06N3/0499', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/0985', 'G06N7/005', 'G06N7/01', 'G06F12/0815', 'G06F17/18', 'G06N3/0481']"
US11763140B2,Smart memory handling and data management for machine learning networks,"A mechanism is described for facilitating memory handling and data management in machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting multiple tables associated with multiple neural networks at multiple autonomous machines, where each of the multiple tables include an index. The method may further include combining the multiple tables and multiple indexes associated with the multiple tables into a single table and a single index, respectively, where the single table is communicated to the multiple autonomous machines to allow simultaneous processing of one or more portions of the single table using one or more memory devices and one or more processors of one or more of the multiple autonomous machines.","['G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/098']"
US12033063B2,Scheduling configuration for deep learning networks,"In an example, an apparatus comprises a plurality of execution units comprising and logic, at least partially including hardware logic, to traverse a solution space, score a plurality of solutions to a scheduling deep learning network execution, and select a preferred solution from the plurality of solutions to implement the deep learning network. Other embodiments are also disclosed and claimed.","['G06N3/063', 'G01N33/5306', 'G01N33/54306', 'G01N33/54393', 'G01N33/6887', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098']"
US11748106B2,Data operations and finite state machine for machine learning via bypass of computational tasks based on frequently-used data values,"A mechanism is described for facilitating fast data operations and for facilitating a finite state machine for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting input data to be used in computational tasks by a computation component of a processor including a graphics processor. The method may further include determining one or more frequently-used data values (FDVs) from the data, and pushing the one or more frequent data values to bypass the computational tasks.","['G06F9/4498', 'G06F9/4881', 'G06F9/3832', 'G06F9/5027', 'G06F9/544', 'G06T1/20', 'G06F2209/5018']"
WO2022252881A1,"Image processing method and apparatus, and readable medium and electronic device","The present disclosure relates to an image processing method and apparatus, and a readable medium and an electronic device, and relates to the technical field of image processing. The method comprises: acquiring a target image in a video to be processed; determining, according to the target image and by means of a pre-trained image detection model, image detection information corresponding to the target image, wherein the image detection model comprises a target convolutional layer and a processing layer, the target convolution layer is used for extracting features of the target image, the processing layer is used for determining the image detection information according to the features of the target image, the image detection information is used for indicating whether the target image is an abnormal image, the target convolutional layer is a convolutional layer in a first encoder, the first encoder is obtained by means of training a preset network by using an unlabeled sample set, and the processing layer is obtained by means of training a preset neural network layer by using a labeled sample set; and when the image detection information indicates that the target image is an abnormal image, performing abnormal-image processing on the target image.","['G06T7/0002', 'G06N3/045', 'G06N3/08', 'G06T2207/10016', 'G06T2207/20081']"
CN110378366B,A Cross-Domain Image Classification Method Based on Coupling Knowledge Transfer,"The invention discloses a cross-domain image classification method based on coupling knowledge migration, which is characterized in that a common low-dimensional subspace of a source domain and a target domain is searched based on a maximum mean difference criterion, and the difference between the edge distribution and the class condition distribution of data of the source domain and the target domain is eliminated; constructing respective adjacent maps according to label information of source domain data and pseudo label information of target domain data, keeping structural consistency of the data from an original space to a low-dimensional subspace, and simultaneously dynamically adjusting the structure of the adjacent maps to promote the forward migration of domain knowledge; training a nearest neighbor classifier by using source domain data with label information in a low-dimensional subspace, and continuously iterating and optimizing pseudo label information of target domain data to obtain final label information of the target domain data, namely finishing cross-domain image classification; in addition, the method of the invention endows different confidence degrees of the pseudo label of the target domain image by designing a sample reweighting strategy, effectively reduces the negative transfer of the knowledge in the domain, and improves the precision of cross-domain image classification.","['G06F18/24147', 'G06N3/044', 'G06N3/045', 'G06V10/40']"
TWI859496B,Computer readable medium,"A pattern grouping method may include receiving an image of a first pattern, generating a first fixed-dimensional feature vector using trained model parameters applying to the received image, and assigning the first fixed-dimensional feature vector a first bucket ID. The method may further include creating a new bucket ID for the first fixed-dimensional feature vector in response to determining that the first pattern does not belong to one of a plurality of buckets corresponding to defect patterns, or mapping the first fixed-dimensional feature vector to the first bucket ID in response to determining that the first pattern belongs to one of a plurality of buckets corresponding to defect patterns.","['G06N20/00', 'G06F18/24', 'G06N20/20', 'G06N3/08', 'G06T7/001', 'G06V10/70', 'G06V10/74', 'G06V10/778', 'G06V10/7784', 'G06V10/7788', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20088', 'G06T2207/30148']"
US11257226B1,Low-overhead motion classification,"A method of classifying motion from video frames involves generating motion frames indicative of changes in pixel values between pairs of frames. The method also involves determining one-dimensional feature values based on the video frames or motion frames, such as the statistical values or linear transformation coefficients. Each one-dimensional feature value may be stored in a buffer, from which additional temporal feature values can be extracted indicative of the change of the one-dimensional feature values across a set of frames. A classifier may receive the one-dimensional feature values and the additional temporal feature values as inputs, and determine the class of motion present in the video frames. Some classes of motion, such as irrelevant motion, may be considered irrelevant to the execution of certain motion-triggered actions, such that the method may involve suppressing the performance of a motion-triggered action based on the determined class of motion.","['H04N7/183', 'G06F17/141', 'G06F17/18', 'G06F18/22', 'G06F18/2411', 'G06K9/6215', 'G06K9/6269', 'G06N3/0499', 'G06N3/09', 'G06T3/4084', 'G06T7/254', 'G06T7/262', 'G06V10/72', 'H04N7/185', 'G06N3/045', 'G06N3/08', 'G06T2207/10016', 'G06T2207/20052', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232']"
US11599998B2,"Machine learning systems and methods for assessment, healing prediction, and treatment of wounds","Machine learning systems and methods are disclosed for prediction of wound healing, such as for diabetic foot ulcers or other wounds, and for assessment implementations such as segmentation of images into wound regions and non-wound regions. Systems for assessing or predicting wound healing can include a light detection element configured to collect light of at least a first wavelength reflected from a tissue region including a wound, and one or more processors configured to generate an image based on a signal from the light detection element having pixels depicting the tissue region, determine reflectance intensity values for at least a subset of the pixels, determine one or more quantitative features of the subset of the plurality of pixels based on the reflectance intensity values, and generate a predicted or assessed healing parameter associated with the wound over a predetermined time interval.","['A61B5/445', 'G06T7/0012', 'A61B5/7275', 'G06T7/11', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'H04N25/135', 'A61B5/0077', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088', 'G06T2207/30096']"
CN112966712B,"Language model training method and device, electronic equipment and computer readable medium","The embodiment of the application discloses a language model training method and device, electronic equipment and a computer readable medium. An embodiment of the method comprises: a method for language model training, the method comprising: selecting a first text sample set based on the natural language processing task, and training a first pre-training model by using the first text sample set to obtain an initial language model; testing the test texts in the preset test text set by using the initial language model, and generating a second text sample set based on the test result and the test texts; training the first pre-training model by using a second text sample set to obtain a second pre-training model; and training the second pre-training model by using the first text sample set to obtain a target language model. The embodiment can obtain a model applied to a natural language processing task, and the model can improve the accuracy of a processing result.","['G06F18/214', 'G06F16/35', 'G06N20/00']"
CN110598847B,Method and device for processing interactive sequence data,"The embodiment of the specification provides a method and a device for processing interactive sequence data. In the method, a dynamic interaction graph constructed according to a dynamic interaction sequence is firstly obtained, wherein the dynamic interaction sequence comprises a plurality of interaction events which are arranged according to a time sequence, the dynamic interaction graph comprises nodes which represent each interaction object in each interaction event, and any node i points to two nodes corresponding to the last interaction event in which the object represented by the node i participates through a connecting edge. Then, in the dynamic interaction graph, determining a target subgraph corresponding to the target node, wherein the target subgraph comprises nodes which start from the target node and reach a predetermined range through a connecting edge; then, based on the node features of each node included in the target subgraph and the pointing relationship of the connection edges between the nodes, a feature vector corresponding to the target node can be determined.","['G06F18/24', 'G06N3/049', 'G06N3/08']"
US11823059B2,Generating a personalized preference ranking network for providing visually-aware item recommendations,"The present disclosure relates to a fashion recommendation system that employs a task-guided learning framework to jointly train a visually-aware personalized preference ranking network. In addition, the fashion recommendation system employs implicit feedback and generated user-based triplets to learn variances in the user's fashion preferences for items with which the user has not yet interacted. In particular, the fashion recommendation system uses triplets generated from implicit user data to jointly train a Siamese convolutional neural network and a personalized ranking model, which together produce a user preference predictor that determines personalized fashion recommendations for a user.","['G06N3/084', 'G06F16/51', 'G06N3/045', 'G06N3/0464', 'G06N3/09']"
US11740618B2,Systems and methods for global cyber-attack or fault detection model,"An industrial asset may have monitoring nodes that generate current monitoring node values representing a current operation of the industrial asset. An abnormality detection computer may detect when a monitoring node is currently being attacked or experiencing a fault based on a current feature vector, calculated in accordance with current monitoring node values, and a detection model that includes a decision boundary. A model updater (e.g., a continuous learning model updater) may determine an update time-frame (e.g., short-term, mid-term, long-term, etc.) associated with the system based on trigger occurrence detection (e.g., associated with a time-based trigger, a performance-based trigger, an event-based trigger, etc.). The model updater may then update the detection model in accordance with the determined update time-frame (and, in some embodiments, continuous learning).","['G05B23/024', 'G05B19/0428', 'G05B23/0221', 'G05B23/027', 'G06F21/552', 'G06N3/006', 'G06N3/045', 'G06N3/0475', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096']"
US12210900B2,Efficient thread group scheduling,"A mechanism is described for facilitating intelligent thread scheduling at autonomous machines. A method of embodiments, as described herein, includes detecting dependency information relating to a plurality of threads corresponding to a plurality of workloads associated with tasks relating to a processor including a graphics processor. The method may further include generating a tree of thread groups based on the dependency information, where each thread group includes multiple threads, and scheduling one or more of the thread groups associated a similar dependency to avoid dependency conflicts.","['G06F9/4881', 'G06F9/3851', 'G06F9/3887', 'G06F9/5066', 'G06T1/20', 'G06F2209/483', 'G06F2209/484']"
US12412086B2,Neural network optimization mechanism,"An apparatus to facilitate optimization of a neural network (NN) is disclosed. The apparatus includes optimization logic to define a NN topology having one or more macro layers, adjust the one or more macro layers to adapt to input and output components of the NN and train the NN based on the one or more macro layers.","['G06T1/20', 'G06N3/08', 'G06N3/045', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/082', 'G06N3/09', 'G06N3/098', 'G06N3/0985', 'G06N3/063']"
CN114118156B,"Equipment fault diagnosis method and device, electronic equipment and storage medium","The disclosure provides an equipment fault diagnosis method, an equipment fault diagnosis device, electronic equipment and a storage medium. The method comprises the following steps: determining a plurality of participants based on a joint learning architecture, and acquiring vibration signals generated by equipment of the participants in the operation process; preprocessing the vibration signals to obtain signal characteristic data, and clustering the equipment to obtain a plurality of similar equipment groups; integrating signal characteristic data corresponding to equipment in the same similar equipment group in each participant to obtain training data, and training the multi-fault diagnosis model by using the training data to obtain a local model; and executing aggregation operation on the local models based on the local models corresponding to each similar equipment group and a preset model aggregation method to obtain a global model, updating the local models by using the global model, and performing fault diagnosis on the equipment based on the updated local models. The method and the device can improve the accuracy of the equipment fault diagnosis result and the efficiency of equipment fault diagnosis.","['G06F2218/02', 'G06F18/214', 'G06F18/22', 'G06F2218/12']"
US20250104179A1,Enabling product skus based on chiplet configurations,"A disaggregated processor package can be configured to accept interchangeable chiplets. Interchangeability is enabled by specifying a standard physical interconnect for chiplets that can enable the chiplet to interface with a fabric or bridge interconnect. Chiplets from different IP designers can conform to the common interconnect, enabling such chiplets to be interchangeable during assembly. The fabric and bridge interconnects logic on the chiplet can then be configured to confirm with the actual interconnect layout of the on-board logic of the chiplet. Additionally, data from chiplets can be transmitted across an inter-chiplet fabric using encapsulation, such that the actual data being transferred is opaque to the fabric, further enable interchangeability of the individual chiplets. With such an interchangeable design, cache or DRAM memory can be inserted into memory chiplet slots, while compute or graphics chiplets with a higher or lower core count can be inserted into logic chiplet slots.","['G06T1/20', 'G06F13/4027']"
US11809905B2,Local memory sharing between kernels,"One embodiment provides for a general-purpose graphics processing unit comprising a set of processing elements to execute one or more thread groups of a second kernel to be executed by the general-purpose graphics processor, an on-chip memory coupled to the set of processing elements, and a scheduler coupled with the set of processing elements, the scheduler to schedule the thread groups of the kernel to the set of processing elements, wherein the scheduler is to schedule a thread group of the second kernel to execute subsequent to a thread group of a first kernel, the thread group of the second kernel configured to access a region of the on-chip memory that contains data written by the thread group of the first kernel in response to a determination that the second kernel is dependent upon the first kernel.","['G06F9/5038', 'G06F9/4881', 'G06F13/1668', 'G06F13/4282', 'G06F9/52', 'G06F9/544', 'G06N3/0442', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/098', 'G06F2209/5018', 'G06F2209/509', 'G06F2213/0026', 'G06F2213/0042', 'G06T1/20', 'Y02D10/00']"
CN114493991B,"Style transfer system, method, and device based on attention recurrent adversarial network","The invention discloses a style migration system, a method and a device based on an attention cycle countermeasure network, wherein the method firstly selects A and B images of two different styles of images to be input into the network; A, randomly nested cutting a plurality of small blocks of an image A, inputting the small blocks into a multi-scale block transducer encoder for learning features, merging low-dimensional global information layer by layer through deconvolution and up-sampling, finally merging high-dimensional global information subjected to dynamic filtering to generate migration results, simultaneously training the mapping of A2B and B2A in a cyclic countermeasure mode, introducing a block-based discriminator and content loss function training convergence, and finally completing the mutual migration of styles of A and B. The invention provides a zero-order learning style migration method based on a cyclic countermeasure network for the first time, and a real and reasonable migration effect can be generated by utilizing the relation characteristics between the interior of a small excavation block and the blocks of a nested cutting small excavation block. The method is superior to the existing method, and has the advantages of strong universality, small data dependence, strong individuation of style generation and the like.","['G06T3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T9/002']"
US12118559B2,Training a machine learning system for transaction data processing,"A method of training a supervised machine learning system to detect anomalies within transaction data is described. The method includes obtaining a training set of data samples; assigning a label indicating an absence of an anomaly to unlabelled data samples in the training set; partitioning the data of the data samples in the training set into two feature sets, a first feature set representing observable features and a second feature set representing context features; generating synthetic data samples by combining features from the two feature sets that respectively relate to two different uniquely identifiable entities; assigning a label indicating a presence of an anomaly to the synthetic data samples; augmenting the training set with the synthetic data samples; and training a supervised machine learning system with the augmented training set and the assigned labels.","['G06N3/08', 'G06Q20/4016', 'G06N20/20', 'G06N3/02', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/09', 'G06N5/00', 'G06Q20/085', 'G06Q20/389', 'G06Q20/4015', 'G06Q40/02']"
US12299842B2,Adaptive deep learning model for noisy image super-resolution,"Embodiments described herein are generally directed to an end-to-end trainable degradation restoration network (DRN) that enhances the ability of a super-resolution (SR) subnetwork to deal with noisy low-resolution images. An embodiment of a method includes estimating, by a noise estimator (NE) subnetwork of the DRN, an estimated noise map for a noisy input image; and predicting, by the SR subnetwork of the DRN, a clean upscaled image based on the input image and the noise map by, for each of multiple conditional residual dense blocks (CRDBs) stacked within one or more cascade blocks representing the SR subnetwork, adjusting, by a noise control layer of the CRDB that follows a stacked set of a multiple residual dense blocks of the CRDB, feature values of an intermediate feature map associated with the input image by applying (i) a scaling factor and (ii) an offset factor derived from the noise map.","['G06N3/088', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/09', 'G06T3/4046', 'G06T3/4053', 'G06N3/048', 'G06N3/063']"
WO2022178969A1,"Voice conversation data processing method and apparatus, and computer device and storage medium","The embodiments of the present application belong to the field of artificial intelligence, and relate to a voice conversation data processing method and apparatus, and a computer device and a storage medium. The method comprises: according to a triggered voice conversation data processing instruction, acquiring call voice information of the current call and a user label of a user in the current call; converting the call voice information and the user label into vector matrixes having weights; inputting the vector matrixes having weights into an emotion determination model to obtain a machine conversation emotion parameter; according to the machine conversation emotion parameter, carrying out voice adjustment on a pre-recorded standard conversation voice to obtain an adapted conversation voice, wherein voice adjustment comprises acoustic adjustment and modal particle adjustment; and carrying out a man-machine conversation on the basis of the adapted conversation voice. In addition, the present application further relates to blockchain technology, and a standard conversation voice can be stored in a blockchain. By means of the present application, the intelligence of man-machine voice conversation interaction is improved.","['G10L17/02', 'G06F16/3329', 'G06F16/3343', 'G06F40/35', 'G10L17/04', 'G10L17/18', 'G10L17/22', 'G10L25/63']"
US9881208B2,Neural network based recognition of mathematical expressions,"Provided are methods and system for recognizing characters such as mathematical expressions or chemical formulas. An example method comprises the steps of receiving and processing an image by a pre-processing module to obtain one or more candidate regions, extracting features of each of the candidate regions by a feature extracting module such as a convolutional neural network (CNN), encoding the features into a distributive representation for each of the candidate regions separately using an encoding module such as a first long short-term memory (LSTM) based neural network, decoding the distributive representation into output representations using a decoding module such as a second LSTM-based recurrent neural network, and combining the output representations into an output expression, which is outputted in a computer-readable format or a markup language.","['G06K9/00409', 'G06V30/333', 'G06F18/2178', 'G06K9/325', 'G06K9/6263', 'G06K9/6269', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06T7/0083', 'G06T7/13', 'G06V10/82', 'G06V20/62', 'G06V30/19167', 'G06K2209/01', 'G06T2207/20081', 'G06T2207/20084', 'G06V30/10']"
US11403523B2,Sparsity constraints and knowledge distillation based learning of sparser and compressed neural networks,"Implementations of the present disclosure build a Bayesian student network using the knowledge learnt by an accurate but complex pre-trained teacher network, and sparsity induced by the variational parameters in a student network. Further, the sparsity inducing capability of the teacher on the student network is learnt by employing a Block Sparse Regularizer on a concatenated tensor of teacher and student network weights. Specifically, the student network is trained using the variational lower bound based loss function, constrained on the hint from the teacher, and block-sparsity of weights.","['G06N3/08', 'G06N3/047', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/09']"
US11709714B2,Thread group scheduling for graphics processing,"Embodiments are generally directed to thread group scheduling for graphics processing. An embodiment of an apparatus includes a plurality of processors including a plurality of graphics processors to process data; a memory; and one or more caches for storage of data for the plurality of graphics processors, wherein the one or more processors are to schedule a plurality of groups of threads for processing by the plurality of graphics processors, the scheduling of the plurality of groups of threads including the plurality of processors to apply a bias for scheduling the plurality of groups of threads according to a cache locality for the one or more caches.","['G06F9/5027', 'G06F12/0837', 'G06F9/3455', 'G06F9/3851', 'G06F9/3877', 'G06F9/3885', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/4881', 'G06F9/5033', 'G06F9/5066', 'G06F9/545', 'G06F16/24569', 'G06F9/30178', 'G06T1/20', 'G06T1/60', 'G06T15/005']"
US11562461B2,Compute optimization mechanism for deep neural networks,"An apparatus to facilitate compute optimization is disclosed. The apparatus includes one or more processing units to provide a first set of shader operations associated with a shader stage of a graphics pipeline, a scheduler to schedule shader threads for processing, and a field-programmable gate array (FPGA) dynamically configured to provide a second set of shader operations associated with the shader stage of the graphics pipeline.","['G06T1/20', 'G06F3/0613', 'G06F3/0659', 'G06F3/0679', 'G06F3/1438', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/60', 'G09G5/363', 'G06F3/1431', 'G06T15/80', 'G09G2352/00', 'G09G2360/06', 'G09G2360/08', 'G09G2360/121', 'G09G2360/123', 'G09G2370/08', 'G09G5/001']"
TWI855201B,"Apparatus, method and machine-readable medium for performing non-local means filtering using motion estimation circuitry of a graphics processor","Apparatus and method for non-local means filtering using a media processor of a graphics processor. For example, one embodiment of a processor comprises: ray tracing circuitry to execute a first set of one or more commands to traverse rays through a bounding volume hierarchy (BVH) to identify BVH nodes and/or primitives intersected by the ray; shader execution circuitry to execute one or more shaders responsive to a second set of one or more commands to render a sequence of image frames based on the BVH nodes and/or primitives intersected by the ray; and a media processor comprising motion estimation circuitry to execute a third set of one or more commands to perform non-local means filtering to remove noise from the sequence of image frames based on a mean pixel value collected across the sequence of image frames.","['G06T1/20', 'G06T1/60', 'G06T15/005', 'G06T15/06', 'G06T15/80', 'G06T5/20', 'G06T5/70', 'G06T7/20', 'G06T2200/28', 'G06T2207/10016', 'G06T2207/20032']"
CN111681219B,"New coronavirus infection CT image classification method, system and equipment based on deep learning","The invention discloses a new coronavirus infection CT image classification method, a system and equipment based on deep learning, wherein the method comprises the following steps: n images are selected from a CT sequence and input into a pre-trained first novel coronavirus infection deep learning model for classification, and a classification result of whether the virus infection exists is obtained; inputting an image with virus infection into a pre-trained second new coronavirus infection deep learning model for classification to obtain a first classification result of whether a patient has new coronavirus infection or not; inputting clinical diagnosis characteristic data corresponding to an image with virus infection into a pre-trained SVM model for classification to obtain a second classification result of whether the image has new coronavirus infection or not; and fusing the first classification result and the second classification result, and obtaining the classification result of whether the patient suffers from new coronavirus infection or not according to the fusion result.","['G06T7/0012', 'G06F18/2411', 'G06N20/10', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/30061']"
CN116756579B,Training method of large language model and text processing method based on large language model,"The embodiment of the application provides a training method of a large language model and a text processing method based on the large language model, relates to the fields of artificial intelligence, cloud technology, natural language processing, machine learning and the like, and particularly relates to a language model in a pre-training language model. The method comprises the following steps: acquiring a training set and a pre-training language model corresponding to each task in a plurality of natural language processing tasks in the same target field, acquiring a second feature extraction network corresponding to each task, repeatedly executing training operation on the second feature extraction network corresponding to each task based on the training set corresponding to the task for each task until a training ending condition is met, acquiring a trained second feature extraction network corresponding to the task, and acquiring a target large language model of the target field based on the pre-training language model and the trained second feature extraction networks corresponding to each task. Based on the method, the accuracy of the text processing result output by the large language model can be improved.","['G06F18/214', 'G06F18/213', 'G06F18/22', 'G06F18/25', 'G06F40/205', 'G06F40/279', 'Y02D10/00']"
US12222970B2,Generative event extraction method based on ontology guidance,"The present invention is a generative event extraction method based on ontology guidance, including: (1) constructing an event ontology knowledge base; (2) designing an event trigger word extraction template and an event argument extraction template; mapping an input event text to a first input sequence, and mapping an input event text integrating an event ontology to a second input sequence; (3) designing a class label mapping function that maps multi-word labels to event types and/or role types; (4) extracting the event ontology corresponding to the input event from the event ontology knowledge base, and constructing the first input sequence and the second input sequence according to the event trigger word extraction template and the event argument extraction template; and (5) predicting, by the event extraction model, the event type and the role type according to the class label mapping function and a processing mechanism thereof, and outputting an event trigger word span and an event argument span.","['G06N5/022', 'G06F16/313', 'G06F16/254', 'G06F16/35', 'G06F40/289', 'G06N20/00', 'G06N3/08', 'G06N5/02']"
US11636639B2,"Mobile application for object recognition, style transfer and image synthesis, and related systems, methods, and apparatuses","Trained segmentation, classification, and style transformation models are used to apply style effects to image segments corresponding to objects (e.g., a portrait of a person) present in an image. When depth information is included with a source image it may be used to segment, classify, and/or apply style transformation to an image or image segments (as the case may be). One or more of the segmentation, classification, and style transformations may be performed at a computing apparatus or as a service for example, in the cloud. A model management tool implemented at a server(s) may continuously train models using supervised or unsupervised training techniques to improve the quality of segmentation, classification and style transformation as well as add new capabilities. Updated models may be pushed to services offering image processing. Additionally or alternatively, a mobile application can inquire about versions of models and request updated models, or in another case, the model management tool may push updates to the mobile application. Thus, the mobile application may perform on-board image processing including segmentation, classification, and style transformation.","['G06T11/001', 'G06F18/2413', 'G06K9/627', 'G06T11/60', 'G06T7/194', 'G06V10/26', 'G06V10/764', 'G06V10/82', 'G06T2207/20081']"
US11644890B2,Image capturing in extended reality environments,"Techniques and systems are provided for capturing self-images in extended reality environments. In some examples, a system captures a pose of a user of an extended reality system. The pose of the user includes a location of the user within a real-world environment associated with the extended reality system. The system also generates a digital representation of the user. The digital representation of the user reflects the pose of the user. The system further captures one or more frames of the real-world environment and overlays the digital representation of the user onto the one or more frames of the real-world environment.","['G06T19/006', 'G06F3/011', 'G06F3/017', 'G06F3/0484', 'G06N20/00', 'G06N20/20', 'G06T7/70', 'H04N23/64', 'H04N5/2621']"
