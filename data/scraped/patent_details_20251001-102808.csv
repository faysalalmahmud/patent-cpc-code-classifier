publication_number,title,abstract,cpc_codes
US11551137B1,Machine learning adversarial campaign mitigation on a computing device,"Machine learning adversarial campaign mitigation on a computing device. The method may include deploying an original machine learning model in a model environment associated with a client device; deploying a classification monitor in the model environment to monitor classification decision outputs in the machine learning model; detecting, by the classification monitor, a campaign of adversarial classification decision outputs in the machine learning model; applying a transformation function to the machine learning model in the model environment to transform the adversarial classification decision outputs to thwart the campaign of adversarial classification decision outputs; determining a malicious attack on the client device based in part on detecting the campaign of adversarial classification decision outputs; and implementing a security action to protect the computing device against the malicious attack.","['G06F18/217', 'G06N20/00', 'G06F18/2113', 'G06F18/2411', 'G06F21/554', 'G06F21/56', 'G06K9/623', 'G06K9/6269', 'G06F2221/034', 'G06N3/094']"
US11741365B2,Generalizable and interpretable deep learning framework for predicting MSI from histopathology slide images,"A generalizable and interpretable deep learning model for predicting microsatellite instability from histopathology slide images is provided. Microsatellite instability (MSI) is an important genomic phenotype that can direct clinical treatment decisions, especially in the context of cancer immunotherapies. A deep learning framework is provided to predict MSI from histopathology images, to improve the generalizability of the predictive model using adversarial training to new domains, such as on new data sources or tumor types, and to provide techniques to visually interpret the topological and morphological features that influence the MSI predictions.","['G06N3/084', 'G06N20/10', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/02', 'G06T7/0012', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
US11616960B2,Machine learning video processing systems and methods,"System and method for improving video encoding and/or video decoding. In embodiments, a video encoding pipeline includes a main encoding pipeline that compresses source image data corresponding with an image frame by processing the source image data based at least in part on encoding parameters to generate encoded image data. Additionally the video encoding pipeline includes a machine learning block communicatively coupled to the main encoding pipeline, in which the machine learning block analyzes content of the image frame by processing the source image data based at least in part on machine learning parameters implemented in the machine learning block when the machine learning block is enabled by the encoding parameters; and the video encoding pipeline adaptively adjusts the encoding parameters based at least in part on the content expected to be present in the image frame to facilitate improving encoding efficiency.","['H04N19/159', 'H04N19/40', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T9/002', 'H04N19/102', 'H04N19/117', 'H04N19/132', 'H04N19/136', 'H04N19/154', 'H04N19/172', 'H04N19/189', 'H04N19/46', 'H04N19/59', 'H04N19/86', 'H04N19/90', 'H04N19/436']"
US10825219B2,Segmentation guided image generation with adversarial networks,"Embodiments provide methods and systems for image generation through use of adversarial networks. An embodiment trains an image generator comprising (i) a generator implemented with a first neural network configured to generate a fake image based on a target segmentation, (ii) a discriminator implemented with a second neural network configured to distinguish a real image from a fake image and output a discrimination result as a function thereof and (iii) a segmentor implemented with a third neural network configured to generate a segmentation from the fake image. The training includes (i) operating the generator to output the fake image to the discriminator and the segmentor and (ii) iteratively operating the generator, discriminator, and segmentor during a training period, whereby the discriminator and generator train in an adversarial relationship with each other and the generator and segmentor train in a collaborative relationship with each other.","['G06V10/82', 'G06F18/217', 'G06K9/6262', 'G06K9/726', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T11/60', 'G06T7/0002', 'G06T7/11', 'G06V10/7715', 'G06V30/274', 'G06V40/16', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06T2207/30248']"
US11452077B2,Wireless network resource allocation method employing generative adversarial reinforcement learning,A wireless network resource allocating method comprises: initializing a generator network G and a discriminator network D; performing resource allocation; training weights of the generator network G and the discriminator network D; and implementing wireless network resource allocation.,"['H04W72/04', 'G06N3/08', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/092', 'G06N3/094', 'H04W72/53', 'H04W28/16']"
US11526601B2,Detection and prevention of adversarial deep learning,"A method for detecting and/or preventing an adversarial attack against a target machine learning model may be provided. The method may include training, based at least on training data, a defender machine learning model to enable the defender machine learning model to identify malicious input samples. The trained defender machine learning model may be deployed at the target machine learning model. The trained defender machine learning model may be coupled with the target machine learning model to at least determine whether an input sample received at the target machine learning model is a malicious input sample and/or a legitimate input sample. Related systems and articles of manufacture, including computer program products, are also provided.","['G06F21/554', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'H04L63/1425', 'G06F2221/034']"
US20200410090A1,Robust von neumann ensembles for deep learning,"Computer-implemented systems and methods build and train an ensemble of machine learning systems to be robust against adversarial attacks by employing a probabilistic mixed strategy with the property that, even if the adversary knows the architecture and parameters of the machine learning system, any adversarial attack has an arbitrarily low probability of success.","['G06N3/084', 'G06F21/55', 'G06F21/57', 'G06F21/602', 'G06N20/20', 'G06N3/045', 'G06F2221/034', 'G06N3/048', 'G06N5/01']"
US12106058B2,Multi-turn dialogue response generation using asymmetric adversarial machine classifiers,"In a variety of embodiments, machine classifiers may model multi-turn dialogue as a one-to-many prediction task. The machine classifier may be trained using adversarial bootstrapping between a generator and a discriminator with multi-turn capabilities. The machine classifiers may be trained in both auto-regressive and traditional teacher-forcing modes, with the generator including a hierarchical recurrent encoder-decoder network and the discriminator including a bi-directional recurrent neural network. The discriminator input may include a mixture of ground truth labels, the teacher-forcing outputs of the generator, and/or noise data. This mixture of input data may allow for richer feedback on the autoregressive outputs of the generator. The outputs can be ranked based on the discriminator feedback and a response selected from the ranked outputs.","['G06F40/35', 'G06F18/2185', 'G06F18/24133', 'G06F40/20', 'G06F40/47', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
US20230269263A1,Adversarial Machine Learning Attack Detection and Prevention System,"A machine learning (ML) attack detection and prevention system may monitor operation of an explainable artificial intelligence (AI) model processed by an application server to provide a product or service to a user. The AI model outputs explainable data and/or other outputs used in decision making. The ML attack detection and prevention system derives business rules based on the explainable data produced by the explainable AI model. Additionally, the ML attack detection and prevention system processes rules repositories of simulation failure data, historical failure data and business rules to derive possible fraud rules based on the data collected in above step. Based on a comparison of rules derived from the AI model output and the possible fraud rules, the ML attack detection and prevention system issues an alert if a fraud condition is suspected and causes the application server to revert back to a previous version of the AI model.","['H04L63/1425', 'G06F18/20', 'G06F18/2155', 'G06K9/6259', 'H04L41/16', 'H04L63/1466']"
US20220012637A1,Federated teacher-student machine learning,"A node for a federated machine learning system that comprises the node and one or more other nodes configured for the same machine learning task, the node comprising:a federated student machine learning network configured to update a machine learning model in dependence upon updated machine learning models of the one or more node;a teacher machine learning network;means for receiving unlabeled data;means for teaching, using supervised learning, at least the federated first machine learning network using the teacher machine learning network, wherein the teacher machine learning network is configured to receive the data and produce pseudo labels for supervised learning using the data and wherein the federated student machine learning network is configured to perform supervised learning in dependence upon the same received data and the pseudo-labels.","['G06N20/00', 'G06N3/088', 'G06N20/10', 'G06N3/045', 'G06N3/084', 'G06N3/098', 'G06N3/047', 'G06N3/08']"
US11392132B2,Generative adversarial network enriched driving simulation,A computer-implemented method and a system for training a computer-based autonomous driving model used for an autonomous driving operation by an autonomous vehicle are described. The method includes: creating time-dependent three-dimensional (3D) traffic environment data using at least one of real traffic element data and simulated traffic element data; creating simulated time-dependent 3D traffic environmental data by applying a time-dependent 3D generic adversarial network (GAN) model to the created time-dependent 3D traffic environment data; and training a computer-based autonomous driving model using the simulated time-dependent 3D traffic environmental data.,"['G05D1/0221', 'G06N3/08', 'B60W50/06', 'G05D1/0088', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'B60W2050/0028', 'B60W2050/0088', 'G05D2201/0213']"
US12307349B2,Systems and methods of large language model driven orchestration of task-specific machine learning software agents,"Systems and methods of the present disclosure may receive, from a user computing device, a user-provided data record query including a natural language request for information associated with one or more data sources. User persona attributes of the user may be determined, such as a user role or security parameters or both. Based on the user persona attributes a context query may be generated to obtain context attributes associated with the user-provided query. The natural language request and the context attributes are input into the model orchestration large language model (LLM) to output instructions to machine learning (ML) agents based on the context attributes. The ML agents output responses associated with the user-provided data record query based on the instructions, and the responses are input into the model orchestration LLM to output to the user computing device a natural language response based on the context attributes.","['G06N20/00', 'G06N3/0455', 'G06N3/094', 'G06N3/10']"
US11157772B2,System and method for generating adversarial examples,"Methods and systems for generating adversarial examples are disclosed. The method comprises accessing a set of inputs and generating an instance of a variable auto-encoder (VAE), the instance of the VAE encoding the set of inputs into latent representation elements associated with a latent space. The method further comprises applying a manifold learning routine on the instance of the VAE to establish a characterization of a manifold in the latent space and applying a perturbation routine to generate perturbed latent representation elements while constraining the perturbed latent representation elements to remain within the manifold. The method further comprises generating adversarial examples based on the perturbed latent representation elements and outputting the adversarial examples.","['G06N3/088', 'G06K9/6257', 'G06F18/2148', 'G06F18/217', 'G06K9/6206', 'G06K9/6262', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06N3/094', 'G06V10/7715', 'G06V10/7747', 'G06V10/82']"
US20220309179A1,Defending against adversarial queries in a data governance system,A computer implemented method and related apparatus defend a system against adversarial queries. An enforcement graph is provided and used to enforce data policies for a system. A generative adversarial model (GAN) is used for querying the enforcement graph to detect a potential adversarial query-based attack against the enforcement graph A policy is provided to protect the enforcement graph against the potential adversarial attack.,"['G06F21/6227', 'G06F18/214', 'G06F18/24143', 'G06F21/31', 'G06F21/604', 'G06K9/6256', 'G06N3/0442', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06N3/086', 'G06N3/092']"
US11790237B2,Methods and apparatus to defend against adversarial machine learning,"Methods, apparatus, systems and articles of manufacture to defend against adversarial machine learning are disclosed. An example apparatus includes memory; computer readable instructions; and processor circuitry to execute the computer readable instructions to: generate a first output indicating a feature that contributed to the generation of a classification by a machine learning model; compare the first output with a second output generated by a server that trained the machine learning model; and flag the machine learning model as corresponding to at least one of model drift or an adversarial attack when first output differs from the second output by more than a threshold.","['G06N3/084', 'G06F16/9027', 'G06F21/56', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N5/01', 'G06N5/045', 'G06F18/22', 'G06F18/24', 'G06N3/048']"
US10990677B2,Adversarial quantum machine learning,"In this disclosure, a number of ways that quantum information can be used to help make quantum classifiers more secure or private are disclosed. In particular embodiments, a form of robust principal component analysis is disclosed that can tolerate noise intentionally introduced to a quantum training set. Under some circumstances, this algorithm can provide an exponential speedup relative to other methods. Also disclosed is an example quantum approach for bagging and boosting that can use quantum superposition over the classifiers or splits of the training set to aggregate over many more models than would be possible classically. Further, example forms of k-means clustering are disclosed that can be used to prevent even a powerful adversary from even learning whether a participant even contributed data to the clustering algorithm.","['G06F21/566', 'G06N10/00', 'G06N10/60', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/06', 'G06N3/08']"
US11984038B2,Concept for designing and using an UAV controller model for controlling an UAV,"Examples relate to a method for generating an Unmanned Aerial Vehicle (UAV) controller model for controlling an UAV, a system including an UAV, a wind generator, a motion-tracking system and a control module, and to an UAV. The method for training the UAV controller model includes providing a wind generator control signal to a wind generator, to cause the wind generator to emit a wind current towards the UAV. The method includes operating the UAV using the UAV controller model. A flight of the UAV is influenced by the wind generated by the wind generator. The method includes monitoring the flight of the UAV using a motion-tracking system to determine motion-tracking data. The method includes training the UAV controller model using a machine-learning algorithm based on the motion-tracking data.","['G08G5/0069', 'G05B13/027', 'F03D80/00', 'B64C39/024', 'F03D7/00', 'F03D7/0276', 'F03D7/04', 'G05B13/042', 'G05D1/0825', 'G05D1/101', 'G05D1/606', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/006', 'G06N3/045', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N3/126', 'G06T7/20', 'G06T7/70', 'G06T7/75', 'G08G5/0013', 'G08G5/26', 'G08G5/57', 'B64U2101/30', 'B64U2201/10', 'B64U2201/20', 'F03D7/045', 'F03D7/046', 'G05D2101/15', 'G05D2109/20', 'G06N7/01', 'G08G5/00', 'G08G5/22', 'G08G5/55', 'Y02E10/72']"
US11562244B2,Robust pruned neural networks via adversarial training,"Systems, methods, and computer readable media are described to train a compressed neural network with high robustness. The neural network is first adversarially pre-trained with both original data as well as data perturbed by adversarial attacks for some epochs, then “unimportant” weights or filters are pruned through criteria based on their magnitudes or other method (e.g., Taylor approximation of the loss function), and the pruned neural network is retrained with both clean and perturbed data for more epochs.","['G06N3/082', 'G06F17/13', 'G06F21/552', 'G06F21/577', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
US20230119658A1,Adversarial attack prevention and malware detection system,"Systems and methods may be used to classify incoming testing data, such as binaries, function calls, an application package, or the like, to determine whether the testing data is contaminated using an adversarial attack or benign while training a machine learning system to detect malware. A method may include using a sparse coding technique or a semi-supervised learning technique to classify the testing data. Training data may be used to represent the testing data using the sparse coding technique or to train the supervised portion of the semi-supervised learning technique.","['G06F21/563', 'G06F21/564', 'G06F21/566', 'G06N20/00', 'G06N20/10', 'G06N7/01']"
US11494667B2,Systems and methods for improved adversarial training of machine-learned models,"Example aspects of the present disclosure are directed to systems and methods that enable improved adversarial training of machine-learned models. An adversarial training system can generate improved adversarial training examples by optimizing or otherwise tuning one or hyperparameters that guide the process of generating of the adversarial examples. The adversarial training system can determine, solicit, or otherwise obtain a realism score for an adversarial example generated by the system. The realism score can indicate whether the adversarial example appears realistic. The adversarial training system can adjust or otherwise tune the hyperparameters to produce improved adversarial examples (e.g., adversarial examples that are still high-quality and effective while also appearing more realistic). Through creation and use of such improved adversarial examples, a machine-learned model can be trained to be more robust against (e.g., less susceptible to) various adversarial techniques, thereby improving model, device, network, and user security and privacy.","['G06N3/084', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06N5/04']"
US11721090B2,Adversarial method and system for generating user preferred contents,"A recommendation method includes retrieving content consumption data including content consumed and content not consumed. Based on the content consumption data, identifying a first piece of content not consumed. A first feature of the first piece of content related to negative consumption of the first piece of content is determined. A first system is used to revise the first feature to a second feature. A second piece of content including the second feature is provided to an electronic device. The second piece of content is a revised instance of the first piece of content.","['G06V10/82', 'G06F16/435', 'G06F18/2155', 'G06F18/241', 'G06F18/245', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06Q30/0269', 'G06Q30/0631', 'G06V10/764', 'G06V10/7753', 'G06V20/46', 'H04N21/251', 'H04N21/45', 'H04N21/466', 'H04N21/4666', 'H04N21/4668']"
US11601468B2,Detection of an adversarial backdoor attack on a trained model at inference time,"Systems, computer-implemented methods, and computer program products that can facilitate detection of an adversarial backdoor attack on a trained model at inference time are provided. According to an embodiment, a system can comprise a memory that stores computer executable components and a processor that executes the computer executable components stored in the memory. The computer executable components can comprise a log component that records predictions and corresponding activation values generated by a trained model based on inference requests. The computer executable components can further comprise an analysis component that employs a model at an inference time to detect a backdoor trigger request based on the predictions and the corresponding activation values. In some embodiments, the log component records the predictions and the corresponding activation values from one or more layers of the trained model.","['G06F18/214', 'H04L63/145', 'G06F18/23', 'G06F21/55', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N5/04', 'G06N3/02']"
EP4235523A1,Identifying and correcting vulnerabilities in machine learning models,"A device may receive a machine learning model and training data utilized to train the machine learning model, and may perform a data veracity assessment of the training data to identify and remove poisoned data from the training data. The device may perform an adversarial assessment of the machine learning model to generate adversarial attacks and to provide defensive capabilities for the adversarial attacks, and may perform a membership inference assessment of the machine learning model to generate membership inference attacks and to provide secure training data as a defense for the membership inference attacks. The device may perform a model extraction assessment of the machine learning model to identify model extraction vulnerabilities and to provide a secure application programming interface as a defense to the model extraction vulnerabilities, and may perform actions based on results of one or more of the assessments.","['G06N20/00', 'G06F21/577', 'G06N3/094', 'G06V10/7747', 'G06V10/776', 'G06F2221/033', 'G06N5/045']"
US20210201116A1,Progressive neural networks,"Methods and systems for performing a sequence of machine learning tasks. One system includes a sequence of deep neural networks (DNNs), including: a first DNN corresponding to a first machine learning task, wherein the first DNN comprises a first plurality of indexed layers, and each layer in the first plurality of indexed layers is configured to receive a respective layer input and process the layer input to generate a respective layer output; and one or more subsequent DNNs corresponding to one or more respective machine learning tasks, wherein each subsequent DNN comprises a respective plurality of indexed layers, and each layer in a respective plurality of indexed layers with index greater than one receives input from a preceding layer of the respective subsequent DNN, and one or more preceding layers of respective preceding DNNs, wherein a preceding layer is a layer whose index is one less than the current index.","['G06N3/0454', 'G06N3/0464', 'G06N3/045', 'G06F17/16', 'G06N3/0455', 'G06N3/08', 'G06N3/084', 'G06N3/096']"
WO2021211207A1,Adversarial pretraining of machine learning models,This document relates to training of machine learning models. One example method involves providing a machine learning model having one or more mapping layers. The one or more mapping layers can include at least a first mapping layer configured to map components of pretraining examples into first representations in a space. The example method also includes performing a pretraining stage on the one or more mapping layers using the pretraining examples. The pretraining stage can include adding noise to the first representations of the components of the pretraining examples to obtain noise-adjusted first representations. The pretraining stage can also include performing a self-supervised learning process to pretrain the one or more mapping layers using at least the first representations of the training data items and the noise-adjusted first representations of the training data items.,"['G06N3/084', 'G06F18/24', 'G06F40/20', 'G06F40/242', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06V10/7784', 'G06V10/82', 'G06F40/284', 'G06N3/082', 'G06T2207/20081']"
KR102471201B1,Outlier detection and automatic threshold system for unsupervised learning-based time series data,The present invention is an outlier detection and automatic threshold point system for unsupervised learning-based time series data. The system comprises: a database unit that stores time series data collected from an open source and sensors in a factory; a data preprocessing unit that refines the data to extract and distinguish features for detecting outliers from the time series data; an outlier detection unit that trains the data preprocessed by the data preprocessing unit in an outlier prediction model by using an autoencoder structure in adversarial machine learning and detects outliers; a threshold calculation unit that derives a threshold for finding an outlier using a machine learning algorithm based on the outlier prediction model; and an outlier distinguishing unit that distinguishes an outlier of the time series data based on the threshold. The present invention aims to detect outliers of the time series data not labeled in advance by applying an outlier detection algorithm and deep learning technology.,"['G06N3/088', 'G06N20/00', 'G06N3/049', 'G06N5/02']"
EP3830793A1,"Multi-modal, multi-resolution deep learning neural networks for segmentation, outcomes prediction and longitudinal response monitoring to immunotherapy and radiotherapy","Systems and methods for multi-modal, multi-resolution deep learning neural networks for segmentation, outcomes prediction and longitudinal response monitoring to immunotherapy and radiotherapy are detailed herein. A structure-specific Generational Adversarial Network (SSGAN) is used to synthesize realistic and structure-preserving images not produced using state-of-the art GANs and simultaneously incorporate constraints to produce synthetic images. A deeply supervised, Multi-modality, Multi-Resolution Residual Networks (DeepMMRRN) for tumor and organs-at-risk (OAR) segmentation may be used for tumor and OAR segmentation. The DeepMMRRN may combine multiple modalities for tumor and OAR segmentation. Accurate segmentation is may be realized by maximizing network capacity by simultaneously using features at multiple scales and resolutions and feature selection through deep supervision. DeepMMRRN Radiomics may be used for predicting and longitudinal monitoring response to immunotherapy. Auto-segmentations may be combined with radiomics analysis for predicting response prior to treatment initiation. Quantification of entire tumor burden may be used for automatic response assessment.","['A61B6/5211', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06N7/01', 'G06T3/4053', 'G06T5/50', 'G06T7/0012', 'G06T7/11', 'G06T7/187', 'G16H50/20', 'A61B5/055', 'A61B6/03', 'A61B6/5229', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
US20220253714A1,Generating unsupervised adversarial examples for machine learning,"A trained machine learning model and a training dataset used to train the trained machine learning model can be received. Based on the training dataset, unsupervised adversarial examples can be generated. Robustness of the trained machine learning model can be determined using the generated unsupervised adversarial examples. The training dataset can be augmented with the generated unsupervised adversarial examples. The trained machine learning model can be retrained using the augmented training dataset.","['G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06V10/82', 'G06V30/10']"
US12242613B2,Automated evaluation of machine learning models,"Various embodiments are provided for automated evaluation of machine learning models in a computing environment by one or more processors in a computing system. A level of robustness of a machine learning model against adversarial whitebox operations may be evaluated and determined by applying a data set used for testing the machine learning model, one or more adversarial operation objectives, an adversarial threat model, and a selected number of hyperparameters. Results from the adversarial operation may be analyzed and a modified machine learning model may be generated while performing the evaluating and determining.","['G06F21/577', 'G06N20/00', 'G06N3/04', 'G06N3/082', 'G06N3/094', 'G06N3/0985', 'G06F2221/034', 'G06F2221/2125']"
CN112464245B,A generalized security assessment method for deep learning image classification models,"The invention discloses a generalized safety assessment method for a deep learning image classification model, and belongs to the technical field of machine learning. The important problem to be solved in the related research of the deep learning at present is to improve the robustness of the model while solving the security threat problem with generalization characteristics faced by the deep learning image classification model, the invention utilizes the generalization security evaluation method facing the deep learning image classification model, by testing the indexes of the deep learning image classification model, such as active defense capacity aiming at the countermeasure sample, detection capacity of the countermeasure sample, passive defense capacity aiming at the countermeasure sample and the like, the safety of the deep learning image classification model is comprehensively evaluated, the security holes existing in the model are discovered in the evaluation process, and meanwhile, due to the generalization characteristic, the method can be suitable for most deep learning image classification models, and has important theoretical and practical significance for improving the safety in the field of deep learning.","['G06F21/577', 'G06F18/214', 'G06F18/22', 'G06F18/241', 'G06N3/045', 'G06N3/088']"
WO2018231708A2,Robust anti-adversarial machine learning,"Systems and methods to improve the robustness of a network that has been trained to convergence, particularly with respect to small or imperceptible changes to the input data. Various techniques, which can be utilized either individually or in various combinations, can include adding biases to the input nodes of the network, increasing the minibatch size of the training data, adding special nodes to the network that have activations that do not necessarily change with each data example of the training data, splitting the training data based upon the gradient direction, and making other intentionally adversarial changes to the input of the neural network. In more robust networks, a correct classification is less likely to be disturbed by random or even intentionally adversarial changes in the input values.","['G06N3/084', 'G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/088', 'G06N5/01']"
WO2018005001A1,Machine learning in adversarial environments,"An adversarial environment classifier training system includes feature extraction circuitry to identify a number of features associated with each sample included in an initial data set that includes a plurality of samples. The system further includes sample allocation circuitry to allocate at least a portion of the samples included in the initial data set to at least a training data set; machine-learning circuitry communicably coupled to the sample allocation circuitry, the machine-learning circuitry to: identify at least one set of compromiseable features for at least a portion of the initial data set; define a classifier loss function [l(xi, yi, w)] that includes: a feature vector (xi) for each sample included in the initial data set; a label (yi) for each sample included in the initial data set; and a weight vector (w) associated with the classifier; and determine the minmax of the classifier loss function (minwmaxi l(xi, yi, w)).","['G06N20/00', 'G06F21/55']"
US20250005358A1,"System, Method, and Computer Program Product for Determining Adversarial Examples","Provided are systems for determining adversarial examples that include at least one processor to determine a first additional input from a plurality of additional inputs based on a proximity of the first additional input to an initial input, determine a second additional input from the plurality of additional inputs based on a proximity of the second additional input to the first additional input, generate a first vector embedding, a second vector embedding and a third vector embedding based on the second additional input, generate a first relational embedding, a second relational embedding, and a third relational embedding based on the third vector embedding and the first vector embedding, concatenate the first relational embedding, the second relational embedding, and the third relational embedding to provide a concatenated version, and determine whether the first input is an adversarial example based on the concatenated version. Methods and computer program products are also provided.","['G06N3/08', 'G06F18/2411', 'G06F18/24137', 'G06N20/00', 'G06N3/045', 'G06N3/048']"
US20230105547A1,Machine learning model fairness and explainability,"Methods, systems, and apparatus, including computer programs encoded on computer-storage media, for machine learning model fairness and explainability. In some implementations, a method includes obtaining data relating to a plurality of potential borrowers; providing the data to the trained machine learning model; obtaining, by the trained machine learning model’s processing of the provided data, the one or more outputs of the trained machine learning model; and automatically generating a report that explains the one or more outputs of the trained machine learning model with respect to one or more fairness metrics and one or more accuracy metrics; and providing the automatically generated report for display on a user device.","['G06Q40/025', 'G06Q40/03']"
US20200134180A1,Enhanced protections against adversarial machine learning threats utilizing cryptography and hardware assisted monitoring in accelerators,"Embodiments are directed to enhanced protections against adversarial machine learning threats utilizing cryptography and hardware assisted monitoring in hardware accelerators. An embodiment of a system includes one or more processors including a trusted execution environment (TEE), the TEE including a machine learning (ML) service enclave, the ML service enclave including monitoring software; a hardware accelerator including a cryptographic engine and metering hardware, the hardware accelerator to perform processing related to an ML model and the metering hardware to generate statistics regarding data transfers; and an interface with one or more data owners, the ML service enclave to provide access control and data protection for ML data related to the ML model, including establishing secret encryption keys with the data owners and the hardware accelerator; and the monitoring software to analyze the statistics to identify suspicious patterns in the data transfers.","['G06F21/566', 'G06F21/604', 'G06N20/00', 'G06N5/04', 'H04L9/0822', 'H04L9/085', 'H04L9/14', 'G06F2221/033']"
US20230419122A1,Adaptive Learning Rates for Training Adversarial Models with Improved Computational Efficiency,"Provided are systems and methods that use a novel learning rate scheduling technique to dynamically adapt the learning rate of an adversarial model to maintain an appropriate balance between adversarial components of the model. The scheduling technique is driven by the fact that, in some settings, the loss of an ideal adversarial network can be analytically determined a priori. A scheduler component can thus operate to keep the loss of the optimized network close to that of an ideal adversarial net.","['G06N3/045', 'G06N3/094', 'G06N3/0475', 'G06N3/084']"
CN114866341A,Vulnerability amplification type backdoor attack security assessment method for network intrusion detection system,"The invention relates to a vulnerability amplification type backdoor attack security assessment method for a network intrusion detection system, which relates to the technical field of network security intrusion detection assessment.A novel backdoor attack test method which can enable any traditional network attack flow to bypass an online machine learning network intrusion detection system and enter a target host or a server is realized by utilizing machine learning model vulnerabilities and combining data virus projection and countermeasure samples based on generation of an countermeasure network and tests the security of the network intrusion detection system according to attack results; the improved generation countermeasure network can realize the generation of the poisoning sample and the countermeasure sample with high concealment, high aggressivity and high timeliness; the poisoned sample can interfere the training of the online machine learning network intrusion detection system and form a specific attack backdoor, and the backdoor can enable the flow of a specific attack type to bypass the detection of the online machine learning network intrusion detection system without influencing the flow of other attack types.","['H04L63/1433', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'H04L63/1425']"
US12086274B2,Variant inconsistency attack (VIA) as a simple and effective adversarial attack method,"The present disclosure relates to techniques for using variant inconsistency attack (VIA) as a simple and effective adversarial attack method to create useful adversarial examples for adversarial training of machine-learning models. In one particular aspect, a method is provided that includes obtaining a set of input examples for attacking a machine-learning model (the set of examples do not have corresponding labels), modifying an example from the set of examples in a utility preserving manner to generate a pair of modified examples, attacking the machine-learning model with the pair of modified examples in order generate a pair of predictions for the pair of modified examples, comparing the pair of predictions to determine whether the pair of predictions are the same or different, and in response to the pair of predictions being different, adding the pair of modified examples to a set of adversarial examples.","['G06F21/60', 'G06F40/295', 'H04L51/02']"
US20230314657A1,Climate risk and impact analytics at high spatial resolution and high temporal cadence,Environmental information combined with satellite driven observations and ground observations to create a predictor for wildfire at high spatial resolution. Temperature and precipitation are bias corrected using modeling and processing techniques driven from reanalysis datasets. Such techniques can be used to provide projections of future climate risk data at high temporal cadence over individual addresses or over large regions using spatial aggregation using polygon processing techniques.,['G01W1/10']
CN114598526B,Structured query language injection detection method,"The invention discloses a structured query language injection detection method, which relates to the technical field of network security, and comprises the following steps: obtaining a structured query language statement to be detected; carrying out grammar analysis on the structured query language sentence to obtain an analyzed structured query language sentence; serializing the parsed structured query language sentence to obtain serialized data; vectorizing the serialized data to obtain vectorized data; and inputting the vectorized data into a trained structured query language injection detection model to obtain a detection result of whether the structured query language statement has structured query language injection attack. The invention solves the technical problem that the existing detection method for structured query language injection can not detect structured query language injection under the attack of resisting machine learning by carrying out grammar analysis, serialization processing and vectorization processing on the structured query language statement and then detecting the structured query language injection through the structured query language injection detection model.","['H04L63/1466', 'G06F8/427', 'Y02D10/00']"
CN108604309A,Antagonism deep neural network,"System, method and apparatus, including the computer program on computer storage media is encoded, for concentrating selection to wait for the action executed by the agency with environmental interaction from action.In an aspect, which includes antagonism deep neural network.Antagonism deep neural network includes value subnet, advantage subnet and combination layer.The expression of value subnet processing observation is estimated with generating value.The expression of advantage subnet processing observation is with to the action generation advantage estimation of each of the behavior aggregate.Combination layer combines value estimations to generate the corresponding Q values for the action with the corresponding advantage estimation for each acting.The system uses the corresponding Q values for the action in the behavior aggregate, and Response to selection is in the observation, the action that will be executed by the agency.","['G06N3/047', 'G06N3/006', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N3/088', 'Y04S10/50']"
US12242615B2,Adversarial reinforcement learning system for simulating security checkpoint environments,"An adversarial reinforcement learning system is used to simulate a spatial environment. The system includes a simulation engine configured to simulate a spatial environment and various objects therein. The system further includes a first model configured to control objects in the simulation and a second model configured to control objects in the simulation. The first model generates a threat-mitigation input to control one or more objects in the simulation, and the second model generates a threat input to control one or more objects in the simulation. The system then executes a first portion of the simulation based at least in part of the threat mitigation input and the threat input.","['G06N20/00', 'G06F21/577', 'G06F21/566', 'G06F2221/034']"
US11972335B2,System and method for improving classification in adversarial machine learning,"Methods and systems are provided for automatic classification of information in an adversarial machine learning setting. For example, a learner that includes multiple classifiers may perform data classification automatically. Each classifier may be trained with adversarial data of a different strength. For a given query to be classified, the learner is configured to intelligently select a classifier that is commensurate with the adversarial strength of the data inside the query, without explicit knowledge of that data or its adversarial strength.","['G06N20/20', 'G06F18/2413', 'G06F18/24155', 'G06F18/2431', 'G06F18/285', 'G06N5/01', 'G06N7/01']"
CN113076615B,A highly robust robotic arm operation method and system based on adversarial deep reinforcement learning,"The invention provides a high robustness mechanical arm operation method and system based on countermeasure type deep reinforcement learning, which comprises the following steps: the industrial camera shoots the mechanical arm operation environment to acquire RGB image information and depth information of the mechanical arm operation environment; the sensor senses the pose of the industrial camera, acquires the pose information of the camera and obtains an external parameter matrix T of the camera; calculating to obtain an environment point cloud according to an external reference matrix and an internal reference matrix of the camera based on the acquired RGB image information and depth information of the environment; the method comprises the steps that an environment point cloud is sampled by the farthest distance to obtain a three-dimensional point cloud domain tensor, and the three-dimensional point cloud domain tensor is input into a point cloud feature extraction network to extract point cloud features of the environment; constructing a simulated physical environment built by a physical engine, and setting a confrontation type deep reinforcement learning model of a specific task of the mechanical arm; and training the confrontation type deep reinforcement learning frame by using empirical data obtained by the interaction of the mechanical arm and the environment until convergence, and obtaining the trained confrontation type deep reinforcement learning frame.","['G06F30/17', 'G06F30/27', 'G06N3/04', 'G06N3/08', 'G06T7/0004', 'G06T7/74', 'G06T7/80', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30164', 'G06T2207/30244']"
US11832103B2,Neural network for adversarial deep learning in wireless systems,A method of determining a response of a radio frequency wireless communication system to an adversarial attack is provided. Adversarial signals from an adversarial node are transmitted to confuse a target neural network of the communication system. An accuracy of classification of the incoming signals by the target neural network is determined.,"['H04W12/122', 'H04L41/16', 'H04W12/12', 'H04W12/121', 'H04W12/79']"
US11809988B2,Artificial intelligence system for classification of data based on contrastive learning,"An artificial intelligence (AI) system that includes a processor configured to execute modules of the AI system. The modules comprise a feature extractor, an adversarial noise generator, a compressor and a classifier. The feature extractor is trained to process input data to extract features of the input data for classification of the input data. The adversarial noise generator is trained to generate noise data for distribution of features of the input data such that a misclassification rate of corrupted features that include the extracted features corrupted with the generated noise data is greater than a misclassification rate of the extracted features. The compressor is configured to compress the extracted features. The compressed features are closer to the extracted features than to the corrupted features. The classifier is trained to classify the compressed features.","['G06N3/08', 'G06F17/18', 'G06F18/21', 'G06F18/24', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094']"
US12373671B2,Method and apparatus for generating Q and A model by using adversarial learning,"A method of generating a question-answer learning model through adversarial learning may include: sampling a latent variable based on constraints in an input passage; generating an answer based on the latent variable; generating a question based on the answer; and machine-learning the question-answer learning model using a dataset of the generated question and answer, wherein the constraints are controlled so that the latent variable is present in a data manifold while increasing a loss of the question-answer learning model.","['G06F16/31', 'G06F16/3329', 'G06F16/3334', 'G06F16/3347', 'G06F16/338', 'G06F16/951', 'G06F18/22', 'G06F40/30', 'G06F40/51', 'G06F40/58', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06N5/041']"
EP3695784A1,Prediction of coronary microvascular dysfunction from coronary computed tomography,"The present invention relates to assessing coronary microvascular dysfunction. In order to provide a more effective assessment of potential coronary microvascular dysfunction, the decision-support system comprises an input unit, a cardiac anatomy segmentation unit, a perfusion data extraction unit, a coronary microvascular dysfunction prediction unit, and an output unit. The input unit is configured to receive coronary computed tomography angiography data of a patient and a corresponding scan protocol. The cardiac anatomy segmentation unit is configured to segment the received coronary computed tomography angiography data to generate a cardiac segmentation map depicting multiple anatomical segments including myocardium segments. The perfusion data extraction unit is configured to extract perfusion data from the received coronary computed tomography angiography data. The coronary microvascular dysfunction prediction unit is configured to use a statistical model to determine an indicator for a presence of coronary microvascular dysfunction based on the received coronary computed tomography angiography data, the corresponding scan protocol, and patient-related data including the generated cardiac segmentation map and the extracted perfusion data. The output unit is configured to output the indicator for a presence of coronary microvascular dysfunction.","['A61B6/503', 'A61B6/504', 'A61B6/5217', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B6/4441']"
US20230325982A1,"Methods, systems and computer programs for processing image data for generating a filter","A method, system and computer program for processing image data, to a vehicle comprising such a system, and to a method, system and computer program for generating a filter. Image data processing may include obtaining the image data, and applying a filter on the image data to generate filtered image data, the filter being configured to suppress adversarial perturbations within the image data. The filtered image data is processed using a machine-learning model.","['G06T5/70', 'G06N3/08', 'G06T5/002', 'G06N3/045', 'G06N3/047', 'G06T5/20', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
US20240320562A1,Adversarial robustness of deep learning models in digital pathology,"The present disclosure relates to techniques for pre-processing training data, augmenting training data, and using synthetic training data to effectively train a machine learning model to (i) reject adversarial example images, and (ii) detect, characterize and/or classify some or all regions of images that do not include adversarial example regions. Particularly, aspects of the present disclosure are directed to receiving a training set of images for training a machine learning algorithm to detect, characterize, classify, or a combination thereof some or all regions or objects within the images, augmenting the training set of images with synthetic images generated from one or more adversarial algorithms to generate augmented batches of images, and train the machine learning algorithm using the augmented batches of images to generate a machine learning model configured to detect, characterize, classify, or a combination thereof some or all regions or objects within new images.","['G06V10/82', 'G06N20/00', 'G06V10/774', 'G06V2201/03']"
US11386300B2,Artificial intelligence adversarial vulnerability audit tool,"An image with a known, first classification by the machine learning model is received. This image is then iteratively modified using at least one perturbation algorithm and such modified images are input into the machine learning model until such time as the machine learning model outputs a second classification different from the first classification. Data characterizing the modifications to the image that resulted in the second classification can be provided (e.g., displayed in a GUI, loaded into memory, stored in physical persistence, transmitted to a remote computing device). Related apparatus, systems, techniques and articles are also described.","['G06K9/6262', 'G06N20/00', 'G06F18/217', 'G06F18/24', 'G06F18/2413', 'G06K9/6267', 'G06N3/006', 'G06N5/04', 'G06N7/01', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06N3/105']"
CN115879315A,Crowd Emergency Evacuation Robot Model Based on Adversarial Reinforcement Learning,"The invention aims at the problems of path planning and intelligent decision making of the crowd evacuation robot. By modeling the fire environment of a multi-storey building, the building has a perfect building structure and a fire development mode. An intelligent agent behavior model used for simulating limited visual field and having no prior knowledge on building construction is designed by combining crowd behaviors, and the evacuation robot is trained based on a multi-intelligent agent post credit allocation reinforcement learning algorithm. Meanwhile, an antagonistic fire source generator agent is realized and used for deciding the generation position of the next fire source in a fire scene, modeling optimization is finally carried out on the robot behavior by combining an antagonistic reinforcement learning method, a generator-solver mode is formed, and an agent decision model with the optimal evacuation crowd effect is obtained through repeated iterative training.",['Y02A10/40']
US11960994B2,Artificial intelligence-based hierarchical planning for manned/unmanned platforms,"A method, apparatus and system for artificial intelligence-based HDRL planning and control for coordinating a team of platforms includes implementing a global planning layer for determining a collective goal and determining, by applying at least one machine learning process, at least one respective platform goal to be achieved by at least one platform, implementing a platform planning layer for determining, by applying at least one machine learning process, at least one respective action to be performed by the at least one of the platforms to achieve the respective platform goal, and implementing a platform control layer for determining at least one respective function to be performed by the at least one of the platforms. In the method, apparatus and system despite the fact that information is shared between at least two of the layers, the global planning layer, the platform planning layer, and the platform control layer are trained separately.","['G06N3/092', 'G06N3/08', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/0455', 'G06N3/0475', 'G06N3/084', 'G06N3/096', 'G06N3/098', 'G06N3/0464', 'G06N3/09', 'G06N5/02']"
US12157063B2,Adversarial reinforcement learning for procedural content generation and improved generalization,"Methods, apparatus and systems are provided for training a first reinforcement-learning (RL) agent and a second RL agent coupled to a computer game environment using RL techniques. The first RL agent iteratively generates a sub-goal sequence in relation to an overall goal within the computer game environment, where the first RL agent generates a new sub-goal for the sub-goal sequence after a second RL agent, interacting with the computer game environment, successfully achieves a current sub-goal in the sub-goal sequence. The second RL agent iteratively interacts with the computer game environment to achieve the current sub-goal in which each iterative interaction includes an attempt by the second RL agent for interacting with the computer game environment to achieve the current sub-goal. The first RL agent is updated using a first reward issued when the second RL agent successfully achieves the current sub-goal. The second RL agent is updated when a second reward is issued by the computer game environment based on the performance of the second RL agent attempting to achieve said current sub-goal. Once validly trained, the first RL agent forms a final first RL agent for automatic procedural content generation (PCG) in the computer game environment and the second RL agent forms a final second RL agent for automatically interacting with a PCG computer game environment.","['A63F13/56', 'A63F13/67', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0499', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N3/044']"
US20220405643A1,System and method for risk sensitive reinforcement learning architecture,"A computer-implemented system and method for training an auomated agent are disclosed. An example system includes: a communication interface; at least one processor; memory in communication with said at least one processor; software code stored in said memory, which when executed causes said system to: instantiate an automated agent that maintains a reinforcement learning neural network and generates, according to outputs of said reinforcement learning neural network, signals for communicating task requests; receive a plurality of states and a plurality of actions for the automated agent; initialize a learning table Q for the automated agent based on the plurality of states and the plurality of actions; compute a plurality of updated learning tables based on the initialized learning table Q using a utility function, the utility function comprising a monotonically increasing concave function; and generate an averaged learning table Q′ based on the plurality of updated learning tables.","['G06N3/092', 'G06N20/00', 'G06N3/006', 'G06N3/094', 'G06N7/01']"
US20230267216A1,Machine learning models with multi-budget differential privacy,"Various examples are directed to systems and methods for using a machine learning model. A computing system may access training data comprising a plurality of training data items. Each of the plurality of training data items may comprise a plurality of features. From a first training data item of the plurality of training data items, the computing system may generate a first transformed training data item using a first privacy budget corresponding to a first portion of the first training data item and a second privacy budget corresponding to a second portion of the first training data item. The computing system may train a machine learning model using the first transformed training data item and use the trained machine learning model to generate at least one class probability for a data item.","['G06F21/60', 'G06V10/7747', 'G06V10/776', 'G06F21/6245', 'G06F21/6254', 'G06N20/20', 'G06N3/0455', 'G06N3/08', 'G06N7/01', 'G06T2207/20084', 'G06V10/82']"
CN118427713A,"A rolling bearing fault diagnosis method, device and computer-readable storage medium based on joint adversarial deep transfer learning","The invention belongs to the technical field of fault diagnosis based on deep migration learning, and particularly relates to a rolling bearing fault diagnosis method based on combined countermeasure deep migration learning. The method includes collecting an original vibration signal; preprocessing the collected data; different layers of features extracted according to the multi-layer deep convolution network; constructing a pseudo tag model, and generating a target domain fault data sample pseudo tag value through semi-supervised learning; constructing a combined countermeasure depth migration model, and calculating combined distribution by utilizing a combined generalized slice Wasserstein distance criterion; inputting the edge characteristics and the condition distribution into a domain discriminator to distinguish different domains; the final label is then predicted by the input classifier. The invention solves the problems that the prior art is limited by the need of a large amount of fault data for training, the working condition of the rolling bearing is changed at any moment in actual working, the fault data is rare, a sample without a label is not available, and the like.","['G06F18/2415', 'G06F18/10', 'G06F18/2131', 'G06F18/2155', 'G06F18/2431', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/0895', 'G06N3/096', 'G06F2218/02', 'G06F2218/08', 'G06F2218/12']"
US11961283B2,Model-based robust deep learning,"Methods, systems, and computer readable media for model-based robust deep learning. In some examples, a method includes obtaining a model of natural variation for a machine learning task. The model of natural variation includes a mapping that specifies how an input datum can be naturally varied by a nuisance parameter. The method includes training, using the model of natural variation and training data for the machine learning task, a neural network to complete the machine learning task such that the neural network is robust to natural variation specified by the model of natural variation.","['G06V10/7747', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/72', 'G06V10/82', 'G06V20/582', 'G06V20/63']"
WO2022268058A1,Mitigating adversarial attacks for simultaneous prediction and optimization of models,"An approach for providing prediction and optimization of an adversarial machine-learning model is disclosed. The approach can comprise of a training method for a defender that determines the optimal amount of adversarial training that would prevent the task optimization model from taking wrong decisions caused by an adversarial attack from the input into the model within the simultaneous predict and optimization framework. Essentially, the approach would train a robust model via adversarial training. Based on the robust training model, the user can mitigate against potential threats by (adversarial noise in the task-based optimization model) based on the given inputs from the machine learning prediction that was produced by an input.","['G06N3/094', 'G06N20/00', 'G06F21/577', 'G06N5/02']"
US20220292339A1,Machine learning techniques for predictive conformance determination,"Various embodiments of the present invention provide methods, apparatus, systems, computing devices, computing entities, and/or the like for performing risk score generation predictive data analysis. Certain embodiments of the present invention utilize systems, methods, and computer program products that perform risk conformance mining predictive data analysis by utilizing machine learning frameworks that include state processing machine learning models and attribute processing machine learning models, where the machine learning frameworks may be trained as part of generative adversarial machine learning frameworks.","['G06N3/08', 'G06N3/088', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454']"
CN118606485A,A reinforcement learning knowledge graph reasoning method and system guided by adversarial and attention mechanisms,"The invention discloses a reinforcement learning knowledge graph reasoning method and a system guided by an antagonism and attention mechanism, wherein the method comprises the following steps: constructing a knowledge graph environment, and carrying out state coding on entities and relations in the knowledge graph by using a knowledge graph embedding model; calculating based on the triple relation of the state codes and the query to obtain an accumulated interaction weight value, and pruning the working space of the current state according to the accumulated interaction weight value; the intelligent agent selects one action from the space actions under each state according to an inference strategy, records the exploration path of the intelligent agent by using the LSTM, returns the selected action to the knowledge-graph environment, updates the state of the knowledge-graph environment, and judges whether the target node reaches the expected target node according to the current state; the agent learns the optimal knowledge-graph inference strategy through interaction with the environment to maximize long-term rewards. The invention improves the interpretability of the reasoning result and provides powerful support for the application and understanding of the reasoning model.","['G06F16/367', 'G06N3/0442', 'G06N3/045', 'G06N3/0475', 'G06N3/092', 'G06N3/094', 'G06N5/04']"
WO2025092272A1,"Method, system and apparatus for oral cavity cbct ultralow-dose imaging","The present invention relates to the technical field of medical imaging. Disclosed are a method, system and apparatus for oral cavity CBCT ultralow-dose imaging. The method comprises: collection of high-dose oral cavity CBCT image data, data splitting processing, data three-dimensional reconstruction processing, model training, image data inputting, image enhancement, and image data outputting; and the specific process involves: performing three-dimensional reconstruction processing on oral cavity CBCT two-dimensional projection data in an ultralow-dose mode of a patient, so as to obtain ultralow-dose oral cavity CBCT three-dimensional reconstruction image data, inputting same into an oral cavity CBCT ultralow-dose imaging image enhancement network model, and performing outputting to obtain high-quality oral cavity CBCT image data for a subsequent clinical diagnosis and treatment process. The present invention can significantly reduce a radiation dose for imaging and accelerate an imaging speed while ensuring the imaging quality, thereby improving the safety of oral cavity CBCT imaging, and having broad clinical application prospects.","['G06T17/00', 'G06N3/0475', 'G06N3/094', 'G06T11/008', 'Y02T10/40']"
WO2020011361A1,Byzantine machine learning,"The present invention concerns computer-implemented methods for training a machine learning model using Stochastic Gradient Descent, SGD. In one embodiment, the method is performed by a first computer in a distributed computing environment and comprises performing a learning round, comprising broadcasting a parameter vector to a plurality of worker computers in the distributed computing environment, and upon receipt of one or more respective estimate vectors from a subset of the worker computers, determining an updated parameter vector for use in a next learning round based on the one or more received estimate vectors, wherein the determining comprises ignoring an estimate vector received from a given worker computer when a sending frequency of the given worker computer is above a threshold value. The method aggregates the gradients in an asynchronous communication model with unbounded communication delays.","['G06N3/084', 'G06N20/00']"
US20210201192A1,Method and apparatus of generating question-answer learning model through reinforcement learning,The present invention relates to a method of operating a question-answer model through reinforcement learning in an apparatus of generating an answer to a question. The method includes: sampling a latent variable from any passage by a first agent; extracting a question-answer dataset from the passage based on the latent variable; determining whether or not to apply the extracted question-answer dataset to learning of a question-answer model generating an answer to any question by a second agent; and applying a change value of performance of the question-answer model as a reward to the first agent and the second agent.,"['G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N5/02', 'G06N5/04']"
US20250246311A1,A method to predict lifespan and healthspan,"The invention relates to a method for predicting the lifespan of an individual, comprising I. providing biological input data of the subject, ii. providing a list of confounding variables, iii. predicting an age-related mortality or disease, preferably the time to death and/or the mortality risk and/or the risk of age-related disease, for the subject by analyzing the data with an algorithm, wherein the algorithm comprises a neural network, which is trained on at least one reference dataset comprising biological data of at least one reference subject by applying: a) a selector layer to filter input data of i., and b) an adversarial learning framework, that removes from the input data the information related to the confounding variables, wherein preferably the adversarial learning framework, is a neural network comprising three elements: a feature extractor (FE), a predictor (P), and a confounder predictor (C). The invention further relates to a device or system comprising means for carrying out the steps of the method according to the invention, a computer program and a computer-readable storage medium.","['G06N3/094', 'G16B20/40', 'G16B25/10', 'G16B40/20', 'G16B40/30', 'G16B5/10', 'G16H50/20', 'G16H50/30']"
US20230301614A1,Systems and methods for image denoising via adversarial learning,"Various examples are provided related to reconstructing images such as, e.g., medical images from low-dose image scans. Adversarial learning such as, e.g., a Cyclic Simulation and Denoising (CSD) framework can be used to address challenges of complicated mixed noise in real low-dose scans. The CSD framework can include a simulator model that can extract low-dose noise and features (e.g., tissue features) from separate image spaces into a unified feature space and a denoiser model that can learn how to remove noise and restore features, simultaneously. Both the simulator model and the denoiser model can regularize each other in a cyclic manner to optimize network learning effectively. The CSD framework in combination with phantom scans can embrace the realistic low-dose noise and features into a unified learning environment to address the challenge of real low-dose image restoration.","['A61B6/5258', 'A61B5/0042', 'A61B5/7203', 'A61B5/7267', 'A61B5/7278', 'A61B6/032', 'A61B6/5205', 'A61B6/5235', 'A61B6/5282', 'A61B6/542', 'A61B6/544', 'A61B6/545', 'A61B6/58', 'A61B6/583', 'G06T5/002', 'G06T5/50', 'G06T5/70', 'A61B2576/026', 'A61B5/055', 'A61B6/037', 'G06T2207/20081', 'G06T2207/30004', 'G06T2207/30168']"
US11507878B2,Adversarial training for event sequence analysis,"Techniques are disclosed for the generation of adversarial training data through sequence perturbation, for a deep learning network to perform event sequence analysis. A methodology implementing the techniques according to an embodiment includes applying a long short-term memory attention model to an input data sequence to generate discriminative sequence periods and attention weights associated with the discriminative sequence periods. The attention weights are generated to indicate the relative importance of data in those discriminative sequence periods. The method further includes generating perturbed data sequences based on the discriminative sequence periods and the attention weights. The generation of the perturbed data sequences employs selective filtering or conservative adversarial training, to preserve perceptual similarity between the input data sequence and the perturbed data sequences. The input data sequence may be created by vectorizing a temporal input data stream comprising words, symbols, and the like, into a multidimensional vectorized numerical data sequence format.","['G06N20/00', 'G06N3/08', 'G06N3/044', 'G06N3/0442', 'G06N3/09', 'G06N3/094']"
US12056236B2,Defending against adversarial queries in a data governance system,"An apparatus and related method defend against adversarial queries. A policy enforcement hypergraph is constructed to express a set of security policies. Then, the hypergraph is repeatedly traversed to determine whether a user behavior is changing over time. The user behavior is measured by reference to a vertex or an edge in the hypergraph. If it is determined that the user behavior has changed over time an enforcement action is taken based on a security policy.","['G06F16/9024', 'G06F21/552', 'G06F21/554', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06F2221/034', 'G06F2221/2141', 'G06N3/088']"
JP2023118101A,Device and method for determining adversarial patch for machine learning system,"To provide a computer-implemented method for determining an adversarial patch for a machine learning system (60).SOLUTION: A machine learning system (60) is configured for image analysis and determines an output signal (y, yi) based on an input image (x, xi), the output signal (y, yi) being determined based on an output of an attention layer (l) of the machine learning system (60). An adversarial patch is determined by optimizing the adversarial patch with respect to a loss function, the loss function comprising a term (Lkq1l,Lkq2l,Lkq3l) that represents a sum of attention weights of the attention layer (l) with respect to a position of the adversarial patch in the input image (x, xi). The method comprises a step of maximizing the term.SELECTED DRAWING: Figure 1","['G06N3/084', 'G06N3/094', 'G06F21/64', 'G06N3/08', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06T7/0002', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06N3/047', 'G06N3/086', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
CN114692683B,Fall detection method and device based on CSI and storage medium,"The invention discloses a fall detection method, a fall detection device and a storage medium based on Channel State Information (CSI), wherein the fall detection method comprises the following steps: acquiring Channel State Information (CSI) data to be tested; preprocessing, segmenting signals, extracting features and obtaining feature data; inputting the extracted characteristic data into a pre-trained detection model to obtain an output falling detection result; the training data set of the detection model comprises a data set formed by falling, slowly sitting, walking, standing, quickly sitting down, falling articles, bending down to pick up articles and sitting on the ground, so that the data of falling-like behaviors are collected for subsequent machine learning classification, and the false alarm rate are reduced; training and optimizing the convolutional neural network model by adopting an countermeasure machine learning method, improving model generalization, and preventing the degradation of recognition accuracy caused by the occurrence of a fitting phenomenon in the learning process.","['G06F2218/06', 'G06F18/214', 'G06N3/045', 'G06N3/084', 'G06F2218/08', 'G06F2218/12']"
CN118737287B,Protein safety and controllable generation method and device based on adversarial reinforcement learning based on protein safety knowledge graph,"The invention discloses a protein safety controllable generation method and device for challenge reinforcement learning based on a protein safety knowledge graph, which comprises the steps of constructing the protein safety knowledge graph, extracting an initial embedded representation of a harmful protein sequence and an embedded vector of external knowledge, carrying out knowledge embedding based on the initial embedded representation of the harmful protein sequence and the embedded vector of the external knowledge and combining the protein safety knowledge graph to obtain an enhanced embedded representation, constructing a generation type challenge network comprising a generator and a punishment model, carrying out one-stage challenge learning, fixing parameters of the punishment model after the one-stage challenge learning, carrying out two-stage reinforcement learning, and generating a new safety controllable protein by using the generator after two-stage parameter optimization.","['G16B40/00', 'G06N3/0475', 'G06N3/092', 'G06N3/094', 'G06N5/022', 'G16B15/00', 'G16B30/00', 'G16B50/10']"
CN113378985B,A method and device for detecting adversarial samples based on layer-by-layer correlation propagation,"The invention discloses a method and a device for detecting an countermeasure sample based on layer-by-layer correlation propagation, wherein the method comprises the following steps: acquiring an image sample, and training a deep learning model by using the image sample; inputting benign image samples into a trained deep learning model, and calculating the relevance score of each benign image sample, wherein the relevance score of the benign image sample is calculated by the relevance score of a pixel, and the relevance score of the pixel is calculated by reversely transmitting layer by layer according to the relevance of a neuron; counting the correlation score distribution of most benign image samples to determine the discrimination basis of the countermeasure samples; and inputting the image sample to be detected into a trained deep learning model, calculating the correlation score of the image sample to be detected, and detecting whether the image sample to be detected is an countermeasure sample according to the discrimination basis. So as to realize the rapid and accurate detection of various countermeasure samples of various deep learning models.","['G06F18/214', 'G06N3/045', 'G06N3/047', 'G06N3/061', 'G06N3/084']"
WO2024086876A1,Detecting attacks on machine learning systems,"This disclosure relates to a method for detecting an attack on a machine learning system. A classical neural network comprises a first output indicative of a first classification by the classical neural network and a quantum neural network comprises a second output indicative of a second classification of the input data by the quantum neural network. The method comprises comparing the first output to the second output; and responsive to the first output being different to the second output, generating an indication that an attack is detected.","['G06F21/554', 'G06F21/54', 'G06F21/55', 'G06F21/577', 'G06N10/20', 'G06N10/40', 'G06N10/60', 'G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/09', 'G06N3/094']"
CN117111459A,A robust control method for aircraft engine performance degradation based on deep reinforcement learning,"The invention discloses an aeroengine performance degradation robust control method based on deep reinforcement learning, which belongs to the field of aeroengine intelligent control and comprises the following steps: introducing health parameters, and quantifying the performance degradation degree of a rotor component of the engine component level model; constructing an aeroengine depth network controller based on an actor-critic framework; providing performance degradation robust performance indexes; randomly initializing the health parameters of the component-level model by combining a random environment domain method; introducing an countermeasure intelligent agent, and forming zero and game with the controller; training a deep network controller based on a deterministic strategy deep reinforcement learning algorithm; and carrying out simulation experiment verification.",['Y02T90/00']
JP2023171171A,Internet service and security,"To expand Internet services and strengthen security.SOLUTION: The present invention relates to Internet services and security. Currently, an IT revolution called the third industrial revolution and an AI revolution called the fourth industrial revolution are progressing. There is an urgent need to develop new services through business ideas relating to streamlining via networks, and to strengthen security to protect these networks. Therefore, various business models are devised as business model patents, and a part of the security that protects the business models is claimed as an invention.SELECTED DRAWING: Figure 1",[]
US12242941B2,Method and system for creating an ensemble of machine learning models to defend against adversarial examples,"One embodiment provides a system which facilitates construction of an ensemble of machine learning models. During operation, the system determines a training set of data objects, wherein each data object is associated with one of a plurality of classes. The system divides the training set of data objects into a number of partitions. The system generates a respective machine learning model for each respective partition using a universal kernel function, which processes the data objects divided into a respective partition to obtain the ensemble of machine learning models. The system trains the machine learning models based on the data objects of the training set. The system predicts an outcome for a testing data object based on the ensemble of machine learning models and an ensemble decision rule.","['G06N20/20', 'G06F18/2163', 'G06F18/2193', 'G06F18/241', 'G06N20/10', 'G06N7/01']"
EP3846088A1,Method and apparatus of generating question-answer learning model through reinforcement learning,The present invention relates to a method of operating a question-answer model through reinforcement learning in an apparatus of generating an answer to a question. The method includes: sampling a latent variable from any passage by a first agent; extracting a question-answer dataset from the passage based on the latent variable; determining whether or not to apply the extracted question-answer dataset to learning of a question-answer model generating an answer to any question by a second agent; and applying a change value of performance of the question-answer model as a reward to the first agent and the second agent.,"['G06N5/022', 'G06F16/583', 'G06F40/30', 'G06N3/006', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/092', 'G06N3/094']"
US20220171848A1,System and Method for Synthesizing Dynamic Ensemble-Based Defenses to Counter Adversarial Attacks,"A method and device for synthesizing adaptive defenses of artificial intelligence (AI) systems against adversarial attacks. The method comprises, during a design phase, creating a library of weak defenses (WDs); preprocessing the WDs in the library; selecting a subset W of WDs from the WDs in the library; and, during a deployment phase, synthesizing an ensemble strategy based on an input of the selected subset W of WDs, the ensemble strategy used as a defense against adversarial attacks.","['G06F21/552', 'G06N20/00', 'G06F21/55', 'G06N5/01', 'G06F2221/034']"
US12067857B1,System and method for reducing a threat footprint of an area-of-interest,"A method for reducing a threat footprint for an area-of-interest by, determining a base risk score for an area-of-interest, deriving a graphical representation of the area-of-interest and one or more defense strategies for the area-of-interest, training an adversarial reinforcement learning agent to identify one or more successful attack paths on the graphical representation of the area-of-interest that are effective in bypassing the one or more defense strategies for the area-of-interest, determining an active risk score based upon the one or more successful attack paths identified by the adversarial reinforcement learning agent and determining one or more mitigation actions that will reduce the active risk score for the area-of-interest based upon the base risk score and one or more predetermined resource constraint.","['G08B21/02', 'G06F18/217', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06Q90/20', 'G08B29/18', 'G08B31/00']"
US12353994B2,System and method for reasoning about the diversity and robustness of an ensemble of classifiers,"One embodiment provides a system which facilitates reasoning about classifiers. During operation, the system determines a plurality of neural networks. The system derives, from a respective neural network, a linear model, wherein the linear model is constructed based on an output of a penultimate layer of the respective neural network. The system trains the linear model based on activations of the penultimate layer. The system maps parameters of the trained linear model into a version space.","['G06V10/82', 'G06F18/214', 'G06F18/2415', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/766', 'G06V10/776', 'G06N3/048']"
US20220245431A1,Adversarial 3d deformations learning,"A computer-implemented method of machine-learning. The method includes obtaining a dataset of 3D modeled objects representing real-world objects. The method further includes learning, based on the dataset, a generative neural network. The generative neural network is configured for generating a deformation basis of an input 3D modeled object. The learning includes an adversarial training.","['G06N3/0472', 'G06F30/27', 'G06N3/088', 'G06N3/047', 'G06F18/214', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T17/00', 'G06T19/20', 'G06T2219/2021']"
US20240031401A1,Method and system for adversarial malware threat prevention and adversarial sample generation,"There is provided systems and methods for adversarial sample generation and adversarial malware threat prevention. The method including: receiving an input executable sample; extracting features of the input executable sample and applying feature mapping to determine components of the features; determining a binary classifier representing whether the executable sample is adversarial using one or more machine learning models, the one or more machine learning models taking the components as input, the one or more machine learning models trained using, at least, generated adversarial samples, generating the generated adversarial samples includes determining code caves in training executable samples and inserting generated payloads as benign samples at the determined code caves; and where the binary classifier indicates adversarial, dropping the input executable sample, otherwise outputting the input executable sample.","['H04L63/145', 'H04L41/16']"
US11443130B2,Making a failure scenario using adversarial reinforcement learning background,"Making failure scenarios using adversarial reinforcement learning is performed by storing, in a first storage, a variety of first experiences of failures of a player agent due to an adversarial agent, and performing a simulation of an environment including the player agent and the adversarial agent. It also includes calculating a similarity of a second experience of a failure of the player agent in the simulation and each of the variety of first experiences in the first storage, and updating the first storage by adding the second experience as a new first experience of the variety of first experiences in response to the similarity being less than a threshold. Additionally, the use of adversarial reinforcement learning can include training the adversarial agent by using at least one of the plurality of first experiences in the first storage to generate an adversarial agent having diverse experiences.","['G06K9/6215', 'G06N3/08', 'B60W50/0097', 'G05D1/0088', 'G06F18/214', 'G06F18/217', 'G06F18/22', 'G06K9/6256', 'G06N20/00', 'G06N3/006', 'G06N3/092', 'G06N3/094']"
CN114565831A,A method for underwater target classification considering robustness of deep learning models,"The invention relates to a method for classifying underwater targets by considering robustness of a deep learning model, which aims to solve the problem of low accuracy of the existing deep learning model for classifying the underwater targets, and comprises the steps of predicting a training set of collected underwater target data by using a trained original model to obtain a set of all classified correct samples and a set of all classified wrong samples; inputting the set of all classified error samples into a trained original model, and clustering and compensating the characteristics of the classified error samples to obtain the characteristic compensation of the classified error samples; inputting the characteristic compensation into the trained original model to obtain an original model after the characteristic compensation; inputting the underwater target data training set into the original model after characteristic compensation, and outputting a sample with wrong classification; establishing an confrontation training model to obtain a well-trained confrontation training model; weighting and combining the confrontation training model and the original model after the characteristic compensation to generate a deep learning model; belongs to the field of underwater target classification.","['G06F18/214', 'G06F18/23213', 'G06F18/2415', 'G06N20/00']"
EP4357854A1,Method of predicting a parameter of interest in a semiconductor manufacturing process,"Described is a method for predicting a parameter of interest of a manufacturing process for manufacturing integrated circuits. The method comprises: obtaining metrology data relating to the parameter of interest; applying a first prediction sub-module to said metrology data to obtain non-anomalous prediction data; detecting anomalies in said metrology data (e.g., using an anomaly detection module); dividing said anomalies into systematic anomalies and non-systematic anomalies; using a first prediction strategy on said non-systematic anomalies to obtain first anomaly prediction data; using a second prediction strategy on said systematic anomalies to obtain second anomaly prediction data; wherein said first prediction strategy is different to said second prediction strategy; and combining said first anomaly prediction data and/or second anomaly prediction data with said non-anomalous prediction data to obtain a prediction of the parameter of interest.","['G03F9/7092', 'G03F7/706837', 'G03F7/706841', 'H01L22/20', 'H01L22/12']"
US12326940B2,Graph exploration framework for adversarial example generation,"A processor-implemented method generates adversarial example objects. One or more processors represent an adversarial input generation process as a graph. The processor(s) explore the graph, such that a sequence of edges on the graph are explored. The processor(s) create, based on the exploring, an adversarial example object, and utilize the created adversarial example object to harden an existing process model against vulnerabilities.","['G06F21/577', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N5/01', 'G06N5/022', 'G06N7/01', 'G06F2221/033', 'G06N20/00']"
US10600185B2,Automatic liver segmentation using adversarial image-to-image network,"A method and apparatus for automated liver segmentation in a 3D medical image of a patient is disclosed. A 3D medical image, such as a 3D computed tomography (CT) volume, of a patient is received. The 3D medical image of the patient is input to a trained deep image-to-image network. The trained deep image-to-image network is trained in an adversarial network together with a discriminative network that distinguishes between predicted liver segmentation masks generated by the deep image-to-image network from input training volumes and ground truth liver segmentation masks. A liver segmentation mask defining a segmented liver region in the 3D medical image of the patient is generated using the trained deep image-to-image network.","['G06T7/11', 'G06T7/0012', 'G06T7/143', 'G06T7/187', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30056']"
US20250007932A1,Anomaly detection using event sequence prediction,A method and system for anomaly detection using event sequence prediction include a conversation module applying a system topology to historical log data to generate first structured event sequences as training data. An event sequence generation engine then builds a machine learning model using the training data. The conversation module then applies a system topology to runtime log data to generate a second plurality of structured event sequences. The generation engine then runs the second structured event sequences through the machine learning model. The generation engine then calculates a probability for each of the second structured event sequences using the machine learning model. The generation engine then identifies probabilities for each of the second structured event sequences that are lower than a probability threshold of classified event sequences of the first structured event sequences are identified as an anomaly.,"['H04L63/1425', 'H04L41/16']"
US12069047B2,Using an enrolled biometric dataset to detect adversarial examples in biometrics-based authentication system,"Training an adversarial perturbation detector comprises accessing a training set comprising an enrolled biometric sample xi and a public biometric sample x of an enrolled user, and submitted biometric samples x′ of a second user, the submitted biometric samples x′ comprising perturbed adversarial samples x′+Δx′. A transformation function k(⋅) is provided having learnable a parameter θ and a classifier having a learnable parameter σ. The training set is used to learn the parameters θ and σ by inputting the training set to the transformation function k(⋅). The transformation function k(⋅) generates transformed enrolled samples k(xi), a transformed public biometric sample k(x), and a transformed adversarial sample k(x′+Δx′). The classifier classifies the transformed adversarial sample k(x′+Δx′) as a success or as a fail based on the transformed enrolled samples k(xi). Based on a result of the classification, the learnable parameters θ and σ are updated.","['H04L63/0861', 'G06F21/32', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04L63/1466', 'H04L63/1483', 'H04W12/06', 'H04W12/122', 'G06N20/10']"
US12158766B2,Real-time autonomous swarms conduct and orchestration,"The present invention discloses systems, modules and methods for an autonomous orchestrion of at least one first swarm, comprising offline model-based subsystem for precomputation of swarm strategies to be performed at real-time; and a real-time subsystem intercommunicated with the offline pre-commutating subsystem.","['G05D1/6983', 'G05D1/644', 'B64C39/024', 'G01C21/20', 'G05D1/225', 'G05D1/2265', 'G05D1/695', 'G05D1/6987', 'G06N3/006', 'G06N3/02', 'G08G5/34', 'G05D2107/17', 'G05D2109/254']"
KR20240095667A,Adversarial data generation method for vulnerability validation of psychological counseling chatbot machine learning model,"An adversarial data generation method for validating the vulnerability of a psychological counseling chatbot machine learning model according to the first aspect of the present invention comprises the steps of: performing tokenization on the basic sentences of user question data in an input dataset that includes user question data and chatbot response data and calculating the importance of each token; selecting tokens based on the calculated importance of each token and performing masking on the selected tokens to predict candidate tokens that replace the selected tokens; determining whether the parts of speech of the candidate tokens are the same as those of the selected tokens and whether the sentence replaced with the candidate tokens is similar to the basic sentence to filter the actual replacement tokens from the candidate tokens; and generating adversarial data for the machine learning model based on the modified sentences using the replacement tokens. Accordingly, the quantification of the success criteria for adversarial attacks becomes possible.","['G06N3/094', 'G06F40/205', 'G06F40/284', 'G06N3/006', 'G06N3/096', 'G16H20/70', 'H04L51/02']"
CN119670265B,Spacecraft swarm game method and system based on generative adversarial reinforcement learning,"The invention belongs to the technical field of aerospace, and particularly discloses a spacecraft cluster game method and a system based on generating stress-resistant reinforcement learning, wherein the method comprises the steps of establishing a relative motion dynamics model of two chase sides, and further establishing a game relationship model of the two chase sides based on a two-person zero and game model; based on the game relation model of the two sides of chase and flee, solving Nash equilibrium solution of the chase and flee game by utilizing a differential game method to generate an expert database, generating an inverse reinforcement learning algorithm based on the expert database design, and solving the game relation of the two sides of chase and flee by utilizing the inverse reinforcement learning algorithm to obtain an optimal game strategy. According to the method, the optimal control method and the artificial intelligence method are combined to solve the approach strategy of the virtual stars of the spacecraft cluster to the non-cooperative targets, so that the problems that convergence is difficult, rewards are difficult to set and the effect is poor when the artificial intelligence method solves the track game problem are solved, and finally the efficient and accurate approach to the targets is realized.",['Y02T10/40']
US20250217494A1,System and method for online blackbox adversarial attack in physical world,"A computer-implemented method for attacking a machine-learning model, comprising establishing a connection between a processor that is utilizing the machine-learning model, wherein the processor is in communication with a sensor located in a physical scene, outputting on a display device in the physical scene, an adversarial pattern, wherein the display device including the adversarial pattern is located in a sensor range of the sensor, obtaining, from the machine-learning model, a classification associated with the physical scene that includes the adversarial pattern, determining if a target classification has been met with a classification output from the machine-learning model, and in response to the target classification not being met, output additional adversarial patterns at the display device and repeat steps until the target classification has been met.","['G06F21/577', 'G06F2221/033']"
US20250191348A1,Vector bypass for generative adversarial image segmentation,"A method, computer system, and a computer program product are provided. A visual inspection machine learning model is trained using a generative adversarial network. Within the generative adversarial network a vector bypass is implemented. By transmitting a vector embedding representation of an unlabeled image through the vector bypass, the vector embedding representation is transmitted around the visual inspection machine learning model and to a generator to assist with image reconstruction.","['G06V10/82', 'G06T7/0002', 'G06T7/11', 'G06V10/764', 'G06V10/7753', 'G06T2207/20081', 'G06T2207/20084']"
WO2022199274A1,Defending against adversarial queries in a data governance system,"An apparatus and related method defend against adversarial queries. A policy enforcement hypergraph is constructed to express a set of security policies. Then, the hypergraph is repeatedly traversed to determine whether a user behavior is changing over time. The user behavior is measured by reference to a vertex or an edge in the hypergraph. If it is determined that the user behavior has changed over time an enforcement action is taken based on a security policy.",['G06F16/9024']
WO2025042692A1,Methods and systems for implementing secure and trustworthy artificial intelligence,"Provided herein are systems, methods, computer-readable media, and techniques for providing trusted artificial intelligence (AI) using Fully Homomorphic Encryption (FHE), comprising: (A) providing a deep neural network (DNN)-based model with modified architecture, wherein the modified architecture at least (i) uses a Gaussian function as an activation function and (ii) removes one or more pooling layers; (B) obtaining encrypted data, wherein the encrypted data are generated by applying the FHE to plaintext data; and (C) generating an inference with the DNN-based model based on the encrypted data. Further provided herein are systems, methods, computer-readable media, and techniques for providing trusted AI using stochastic computing, using noise based computing, using an artificial immune system, and with secure multi-party computation (SMPC) based at least in part on watermarking.","['H04L9/008', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06N3/0985', 'G06N5/04', 'H04L9/002', 'H04L9/50', 'H04L2209/608']"
EP4517467A1,Managing adversarial agents used for testing of autonomous vehicles,"A system and method for managing one or more adversarial agents (404) used for testing of an autonomous vehicle is disclosed. The method comprises obtaining, by a processing unit (120), offline data for initializing the one or more adversarial agents from one or more first sources, wherein the offline data comprises at least one of real data and statistical simulation data. The method further comprises using a feedback-based learning algorithm to train one or more adversarial agents (404) based on the offline data and expert inputs received from a second source, wherein the one or more adversarial agents (404) are trainable computational models that model behavior of one or more entities that affect behavior of autonomous vehicles in a physical environment. The method further comprises deploying the trained adversarial agents (404) onto a test execution platform for testing of a system-under-test, wherein the system-under-test is associated with an autonomous vehicle-to-be-tested.","['G06N3/08', 'G06F11/3684', 'G06N3/006', 'G06N3/045', 'G06N3/094', 'G06F11/3688', 'G06F11/3698']"
US20250181770A1,Utility preserving anonymization of visual content,"A method, computer system, and a computer program product for visual content privatization is provided. The present invention may include receiving visual content associated with a subject. The present invention may include altering the visual content using at least one or more image perturbations or one or more adversarial patches in response to a practitioner requesting an external consultation from a third party. The present invention may include presenting an altered visual content to the practitioner within a user interface. The present invention may include transmitting the altered visual content to the third party following an approval by the practitioner.","['G06F21/6263', 'G06F21/6245', 'G06F21/6254', 'G16H30/40', 'G16H40/67']"
US12326942B2,Identifying and assessing costs associated with correcting vulnerabilities in machine learning models,"A device may receive a machine learning model, training data, a pipeline configuration for the machine learning model, and impact costs associated with customer preferences, and may perform assessments of the machine learning model to identify attacks associated with the machine learning model and vulnerabilities associated with the attacks. The device may map the vulnerabilities to threats, may map the threats to the impact costs, and may determine success rates of the threats. The device may calculate probabilities of the threats based on the vulnerabilities and the success rates, and may calculate risk costs of the attacks based on the probabilities and the impact costs. The device may identify controls for limiting the vulnerabilities and control costs. The device may determine a total cost for eliminating the risk costs based on the risk costs and the control costs, and may perform actions based on the total cost.","['G06F21/577', 'G06N20/00', 'G06N5/01', 'G06N5/022', 'G06N7/01', 'G06F2221/034']"
WO2024180666A1,"Learning device, learning system, method, program, and storage medium","This learning device comprises: an acquisition unit that acquires a first dataset which belongs to a first domain that includes a first feature quantity space and which is labeled to only one of positive and negative instances in binary classification and a second dataset which belongs to a second domain that includes a second feature quantity space and which is not labeled by binary classification; and a model generation unit that generates an inference model for inferring, on the basis of the first and second datasets, whether the second data included in the second dataset is one of the positive and negative instances in binary classification.",['G06N20/00']
US20240214413A1,Cyber-hardening using adversarial simulated attacking and defender systems and machine learning,"In one general embodiment, a computer-implemented method includes applying a plurality of known cyber-attack techniques and variations thereof against a simulated defender system using a simulated attacking system. Known cyber-attack defense techniques are applied to the defender system. Instances of the defender system are logged in association with various combinations of respective cyber-attack techniques, various cyber-attack defense techniques, simulated system configurations, and simulated system outcomes as training instances. A machine learning model is trained using the logged training instances. A production product configuration is input to the trained machine learning model. Information related to cyber-hardening of the production product is output from the trained machine learning model.","['H04L41/16', 'G06N20/00', 'G06N7/08', 'H04L63/1433', 'H04L63/145']"
US20250211976A1,Devices and methods against adversarial attacks in wireless communication systems,"An apparatus may include a trusted execution environment and a processor configured to execute a machine learning (ML)-based application within the trusted execution environment, the ML-based application is configured to provide an output based on input data comprising telemetry data and decrypt encrypted data received by the trusted execution environment to obtain the telemetry data of the network.","['G06F21/57', 'H04W12/03', 'H04W12/04', 'H04W12/122']"
CN119341821B,Industrial Internet of things honeypot deployment method and device based on antagonism reinforcement learning,"The invention discloses an industrial Internet of things honeypot deployment method and device based on contrast reinforcement learning, and belongs to the technical field of network security. The dynamic and uncertainty of network attack behavior is mainly solved. The implementation scheme of the method comprises the steps of collecting industrial Internet of things equipment data, including industrial Internet of things equipment IP, industrial Internet of things equipment request data and response data, utilizing an LDA analysis method based on industrial Internet of things multi-mode request data to conduct cluster analysis of the request data, classifying the request data into different categories, utilizing a Markov decision model to construct an interaction model of a honeypot and an attacker, and finally utilizing a challenge reinforcement learning algorithm Repeated Update Q-learning (RUQL) to train the model. The invention can effectively attract and cope with network attacks, and remarkably improves the capability of capturing and analyzing the network attacks under the countermeasure environment.","['H04L63/1491', 'H04L63/20', 'H04L9/40']"
US20240311684A1,Artificial intelligence-based gamification for service background,"For AI-based recommendations in a service management system, the AI is machine trained using gamification. A model of the service management system is used in simulation to train a policy in reinforcement learning to implement strategies for improvement of KPI(s). By varying sampling of distribution of parameters of the model and/or varying the distributions of parameters used in the model, the policy learns to deal with a variety of situations using the simulations from the model. The resulting AI (machine-learned policy) is used to make recommendations for the service management system.","['G06N20/00', 'G06N3/006', 'G06N7/01']"
US20250184875A1,Systems and methods for radio-frequency adversarial deep-learning inference for automated network coverage estimation,"Example systems and methods for radio-frequency adversarial deep-learning inference for automated network coverage estimation include a generative adversarial network (GAN) based approach for synthesizing RF maps in indoor scenarios. In some examples, a semantic map is utilized—a high-level representation of the indoor environment to encode spatial relationships and attributes of objects within the environment and guide the radio frequency (RF) map generation process. A new gradient-based loss function is introduced that computes the magnitude and direction of change in RSS values from a point within the environment. Some examples incorporate this loss function along with the antenna pattern to capture signal propagation within a given indoor configuration and generate new patterns under new configuration, antenna (beam) pattern, and center frequency.","['H04W24/02', 'G06N3/0475', 'H04W48/16', 'H04B17/318']"
WO2024025152A1,"Adversarial learning apparatus and method for simultaneously training denoising network and deep neural network, and computer-readable recording medium having recorded thereon program for executing method","The present invention relates to a technology related to an adversarial learning apparatus, and to an adversarial learning apparatus and method for simultaneously training a denoising network and a deep neural network, and a computer-readable recording medium having recorded thereon a program for executing the method, wherein the deep neural network that classifies images can maintain classification accuracy for normal images, which are reconstructed through the denoising network, at a similar level to the related art, and can also correctly classify adversarial examples reconstructed through the denoising network.","['G06V10/82', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06T5/00', 'G06T5/70', 'G06V10/764', 'G06T2207/20081', 'G06T2207/20084']"
US20240419852A1,Method and Apparatus,"A computer-implemented method of generating trajectories of actors, the method comprising: simulating a first scenario comprising an environment having therein an ego-vehicle, a set of actors, including a first actor, and optionally a set of objects, including a first object, wherein simulating the first scenario comprises using a first trajectory of the first actor;","['G06N20/00', 'G06F30/15', 'G06F30/27', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/092', 'B60W60/001']"
CN114821227B,A deep neural network adversarial sample scoring method,"The invention discloses a deep neural network countersample scoring method, and provides a novel method for evaluating countersample attack effects in a black box mode, wherein the countersample attack effects are evaluated and quantified by adopting a fuzzy comprehensive evaluation method and an index named countersample scoring (Adversarial Examples Score, AES). The method specifically comprises the steps of calculating mobility, imperceptibility, attack success rate and label offset of a countermeasure sample, determining a membership subset table, determining evaluation weight A in each aspect by using a hierarchical analysis method, and blurring a comprehensive evaluation matrix to obtain a score index of the countermeasure sample. The output of the AES index is a score that measures the effect of combating a sample attack, which can be used to evaluate the hazard of combating a sample to a deep neural network.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
US11841949B2,System and method for antimalware application adversarial machine learning,"An exemplary system and method are disclosed for detecting malware via an antimalware application employing adversarial machine learning such as generative adversarial machine learning and the training and/or configuring of such systems. The exemplary system and method are configured with two or more generative adversarial networks (GANs), including (i) a first generative adversarial network (GAN) that can be configured using a library of malware code or non-malware code and (ii) a second generative adversarial network (GAN) that operates in conjunction with the first generative adversarial network (GAN) in which the second generative adversarial network is configured using a library of non-malware code.","['G06F21/565', 'G06F21/562', 'G06F2221/033']"
US20240320414A1,Summary generation based on comparison objects,"Summary generation based on comparison objects can include receiving text descriptions of a target object and at least one comparison object. Semantic vectors from the text descriptions can be obtained, using a deep learning based semantic extraction model. The semantic vectors can be input to a generator model trained using an adversarial machine learning technique, the generator model outputting a text summary of the target object describing only unique characteristics of the target object different from characteristics of the at least one comparison object and excluding the characteristics of the at least one comparison object.","['G06F40/30', 'G06F40/166', 'G06F40/284', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088']"
US12199995B2,System and method for authentication code generation based on adversarial machine learning,"A system and method for authentication code generation based on adversarial machine learning are provided in this disclosure. The method includes a defensive authentication code generation system, an authentication code formation module, an authentication code scheduling module, an authentication-code adversarial processing center, an attack sample generation module, a verification and error reporting system, a division module, a grouping and distribution system, a category checking module, a data recording unit, a detection module and an integration terminal. In the system and method for authentication code generation based on adversarial machine learning according to the disclosure, attack scenes are simulated for continuous training for the authentication code, error-reporting data are recorded and optimized into the defensive authentication code generation system, so as to improve defense performance of the authentication code.","['H04L63/1416', 'H04L41/16', 'H04L63/1466']"
US20230418246A1,Device and method for determining adversarial perturbations of a machine learning system,"A computer-implemented method for determining an adversarial perturbation for input signals, especially sensor signals or features of sensor signals, of a machine learning system. A best perturbation is determined iteratively, wherein the best perturbation is provided as adversarial perturbation after a predefined amount of iterations, wherein at least one iteration includes: sampling a perturbation; applying the sampled perturbation to an input signal thereby determining a potential adversarial example; determining an output signal from the machine learning system for the potential adversarial example, determining a loss value characterizing a deviation of the output signal to a desired output signal, wherein the desired output signal corresponds to the input signal, if the loss value is larger than a previous loss value setting the best perturbation to the sampled perturbation.","['G06N3/094', 'G06N20/00', 'G05B13/045', 'G05B13/0265', 'G06N3/0455', 'G06N3/0475', 'G06N3/088']"
CA3060613C,System and method for generating adversarial examples,"ABSTRACT Methods and systems for generating adversarial examples are disclosed. The method comprises accessing a set of inputs and generating an instance of a variable auto-encoder (VAE), the instance of the VAE encoding the set of inputs into latent representation elements associated with a latent space. The method further comprises applying a manifold learning routine on the instance of the VAE to establish a characterization of a manifold in the latent space and applying a perturbation routine to generate perturbed latent representation elements while constraining the perturbed latent representation elements to remain within the manifold. The method further comprises generating adversarial examples based on the perturbed latent representation elements and outputting the adversarial examples. 139405181 43078/8 CA 3060613 2019-10-28","['G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094']"
US20250119251A1,Federated learning system and method with adaptive noise and differential privacy,"A wireless communication network method and system that includes a central server, cellular base stations, edge computing devices, and client devices. The client devices send uplink pilot sequences, which are collected and aggregated by the base stations. The base stations then relay this aggregated pilot data to the central server. The central server deploys network weights for a global deep learning neural network model to the base stations for incorporation into respective local deep learning models, trained to predict optimal beamforming vectors, to the base stations for incorporation into respective local deep learning model. During training the central server integrates adaptive noise into weights received for each of the local deep learning models.","['H04L41/16', 'H04B7/0617', 'H04L5/0048', 'H04W12/02']"
WO2022244256A1,Adversarial attack generation device and risk evaluation device,The purpose of the present invention is to provide an adversarial attack generation device capable of generating an adversarial example robust to a non-linear change in brightness. An adversarial attack generation device 71 comprises a non-linear brightness conversion means 73. The non-linear brightness conversion means 73 non-linearly updates brightness of a training image during execution of an attack generation process that generates an adversarial example.,['G06T7/00']
US20240427903A1,Facilitating security verification of system designs using adversarial machine learning,"In some aspects, the techniques described herein relate to a method and apparatus for testing a system including: obtaining a design of a system to be tested by a computing device; generating a plurality of traces based on the design of the system by the computing device; training a model of the system using the generated traces by the computing device; generating a plurality of attack traces for the model of the system by the computing device; attacking the model of the system using the generated plurality of attack traces by the computing device; validating some of the plurality of attack traces by the computing device; for each attack trace that is validated, determining possible system vulnerability based on the validated attack trace by the computing device.",['G06F21/577']
CN110796603B,A high-resolution photoacoustic imaging method for deep tumor neovascularization,"The invention discloses a high-resolution photoacoustic imaging method of a deep tumor neovascular under a deep learning model, which belongs to the field of biomedical imaging and comprises the following specific steps of: collecting training data, collecting a low-resolution photoacoustic image of a tumor blood vessel under an acoustic resolution photoacoustic imaging system, and collecting a high-resolution photoacoustic image of the tumor blood vessel under an optical resolution photoacoustic microscopic imaging system; training a deep learning model based on the training data, the deep learning model generating an impedance deep learning network model; based on the trained deep learning model, high-resolution imaging of deep tumor neovasculature under the acoustic resolution photoacoustic imaging system is realized. The invention realizes the optical resolution photoacoustic image reconstruction under the acoustic resolution photoacoustic imaging system, can perform optical resolution imaging on the deep tumor neovascular, clearly acquire the neovascular network of the whole tumor area, and further provides high-quality vascular data for the subsequent quantitative analysis of various tumor blood vessels.","['G06T7/30', 'G06T11/005', 'G06T3/4053', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'Y02T10/40']"
CN114021635A,"Method, apparatus, device and storage medium for training a model","Embodiments of the present disclosure disclose methods and apparatus for training a model. One embodiment of the method comprises: acquiring a training sample set; the following training steps are performed: taking state information of each time point of the object, which is included in the training sample, as model input, taking action information of the object as model output, solving to obtain candidate parameters of the model based on a loss function and an objective function, wherein the loss function is constructed based on an antagonistic learning algorithm, and the candidate parameters are a set of optimal parameters of two antagonistic parties obtained by using the objective function; when the candidate parameters meet preset conditions, determining the candidate parameters as final parameters of the model, and outputting the final model after training, wherein the preset conditions are used for representing the setting of a set of optimal parameters of the two confronters based on the extreme value principle of the two confronters; and when the candidate parameters do not meet the preset conditions, repeatedly executing the training steps. The scheme realizes a brand-new model training method and device.",['G06F18/214']
CN110263845B,SAR Image Change Detection Method Based on Semi-supervised Adversarial Deep Network,"The invention discloses a SAR image change detection method based on a semi-supervised countermeasure depth network, which mainly solves the problems that the detection effect false alarm rate is high and the detection area is inaccurate when the label data are less in the existing change detection technology. The scheme is as follows: 1) Calculating a logarithmic ratio difference map of the two images by using the two-time-phase SAR image data; 2) Extracting training samples and test samples from the two-phase SAR image and the difference image; 3) Constructing a change detection dual network and two discrimination networks; 4) Performing supervision training by using the labeled data, performing countermeasure training and collaborative training by using the unlabeled data, and obtaining a trained detection network; 5) And inputting the test data into a trained change detection network to obtain a change detection result. The invention combines a large amount of non-tag data to extract the change detection characteristics of the separability, improves the generalization performance of the supervision training model when the labeled training sample is insufficient, and can be used for SAR image change detection.","['G06F18/214', 'G06F18/2155', 'G06F18/24', 'G06N3/04']"
US20230376961A1,Reinforcement learning agent simulation to measure monitoring system strength,"Systems, methods, and other embodiments associated with reinforcement learning agent simulation for measurement of monitoring system strength are described. In one embodiment, a method includes training a reinforcement learning agent to learn a policy that evades one or more scenarios of a monitoring system while completing a task. The policy is then sampled to simulate an episode of steps taken by the reinforcement learning agent. The steps taken in the episode are then analyzed to measure a strength of monitoring in the monitoring system. The strength of monitoring is then presented in a user interface.","['G06Q40/06', 'G06Q20/4016', 'G06F18/217', 'G06K9/6262', 'G06N20/00', 'G06N3/006', 'G06Q20/382', 'G06Q20/389', 'G06Q20/4014', 'G06Q40/02']"
US11310250B2,System and method for machine learning-based real-time electronic data quality checks in online machine learning and AI systems,"A system for machine learning-based real-time electronic data quality checks in online machine learning and AI systems is provided. In particular, the system may comprise a machine learning module which receives input data from a data quality learning module which serves to perform filtering or alteration functions on incoming data during the training and/or live phases of the machine learning module. Over time, the data quality module may increasingly become efficient and accurate at assessing incoming data to determine the data quality. In turn, improving data quality of input data may ensure that the various neural networks within the system produce adaptively accurate output values to drive the decisioning processes of the system.","['H04L63/1425', 'G06N20/00', 'G06N3/0442', 'G06N3/09', 'G06N3/092', 'G06N5/047', 'G06N3/08']"
US10614557B2,Digital image completion using deep learning,"Digital image completion using deep learning is described. Initially, a digital image having at least one hole is received. This holey digital image is provided as input to an image completer formed with a framework that combines generative and discriminative neural networks based on learning architecture of the generative adversarial networks. From the holey digital image, the generative neural network generates a filled digital image having hole-filling content in place of holes. The discriminative neural networks detect whether the filled digital image and the hole-filling digital content correspond to or include computer-generated content or are photo-realistic. The generating and detecting are iteratively continued until the discriminative neural networks fail to detect computer-generated content for the filled digital image and hole-filling content or until detection surpasses a threshold difficulty. Responsive to this, the image completer outputs the filled digital image with hole-filling content in place of the holey digital image's holes.","['G06T5/005', 'G06T5/77', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/20', 'G06T5/60', 'G06V30/194', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104']"
US20220051408A1,Systems and methods for generating normative imaging data for medical image processing using deep learning,"Methods and systems are provided for generating a normative medical image from an anomalous medical image. In an example, the method includes receiving an anomalous medical image, wherein the anomalous medical image includes anomalous data, mapping the anomalous medical image to a normative medical image using a trained generative network of a generative adversarial network (GAN), wherein the anomalous data of the anomalous medical image is mapped to normative data in the normative medical image. In some examples, the method may further include displaying the normative medical image via a display device, and/or utilizing the normative medical image for further image analysis tasks to generate robust outcomes from the anomalous medical image.","['G06T7/0012', 'G06T7/0014', 'G06T11/003', 'G06N3/045', 'G06N3/084', 'G06T11/008', 'G16H30/00', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30016', 'G06T2207/30096']"
WO2023246819A1,Model training method and related device,"A model training method, relating to the field of artificial intelligence. The method comprises: processing first data by means of a first reinforcement learning model to obtain a first processing result; processing the first data by means of a first target neural network selected from among a plurality of first neural networks to obtain a second processing result, wherein each first neural network is an iteration result obtained by performing iterative training on a first initial neural network; and updating the first reinforcement learning model according to the first processing result and the second processing result. According to the present application, the interference for a target task is output by utilizing a historical training result of a historical adversarial agent (an adversarial agent obtained in a historical iteration process), such that more effective interference for the target task under different scenarios can be obtained, thereby improving the training effect and generalization of a model.","['G06N3/04', 'G06N3/08']"
GB2608344A,Domain-invariant feature-based meta-knowledge fine-tuning method and platform,"Disclosed are a domain-invariant feature-based meta-knowledge fine-tuning method and a platform. In the method, highly-transferable common knowledge, that is, a domain-invariant feature, is learned on different data sets of similar tasks; and common domain features on different domains corresponding to different data sets of similar tasks are learned in a fine-tuning network set, and any different domain is quickly adapted to. In the present invention, the parameter initialization capability and generalization capability of a similar task universal language model are improved, and finally, the universal compression architecture of a similar downstream task language model is obtained by fine tuning. In a meta-knowledge fine-tuning network, a loss function of a domain-invariant feature is designed in the present invention, and general knowledge unrelated to a domain is learned, that is, a learning target of one domain-invariant feature is minimized to drive a language model to have domain-invariant feature coding capability.","['G06F18/00', 'G06F18/2414', 'G06N20/00', 'G06N3/045', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06F40/20', 'G06N3/08', 'G06N5/041']"
US20210063120A1,System and method for active shooter defense,"A security system including: a detector that senses and detects a physical threat to persons in a protected area; and a defensive weapon in the protected area that deploys to disable a detected physical threat. The defensive weapon can be, for example, a guided ordnance, a guided weaponized UAV, or a combination thereof. Also disclosed are methods of making and using the security system.","['F41H11/00', 'B64C39/024', 'B64U80/25', 'G06K9/00288', 'G06K9/00771', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V40/172', 'G06V40/20', 'B64U10/14', 'B64U2101/15', 'B64U2101/31', 'F41H13/0012', 'F41H9/00', 'F41H9/04', 'F42B12/54', 'G06V2201/05']"
US20240371134A1,Method and a system for real-time detection of attacks on ai-based object detectors,"An AI-based method for real-time detection and mitigation of attacks on object detectors being fed by input images acquired by one or more imagers, comprising the steps of mapping normal attributes of the outputs of an ML-model associated with the object detectors, using unsupervised learning; creating an anomaly detection model being capable of identifying adversarial attacks in the form of adversarial patches, based solely on the outputs of the object detectors and without accessing the object detectors model or any original frames acquired by the one or more imagers; calculating the anomaly score for each object being detected by the ML-model object detectors; comparing the anomaly scores of the detected objects to a preset threshold; protecting the object detectors against the attacks by identifying and mitigating the effects of the adversarial patch attacks using the comparison results.","['G06F18/24323', 'G06N20/20', 'G06V10/764', 'G06V10/82', 'G06V20/52']"
CN114896867A,Shock insulation structure and design method thereof,"The invention discloses a shock insulation structure, and particularly relates to the technical field of civil engineering shock insulation, which comprises a concrete box, a concrete cap, a low-rigidity rubber bearing, a steel cylinder and a metamaterial enveloping layer, wherein the concrete box is of a four-side hollow square column structure, the concrete cap comprises two cubic flat plates which are arranged up and down and have the same shape, the low-rigidity rubber bearing is positioned between the steel cylinder and the concrete cap, the diameter of the steel cylinder is the same as that of the low-rigidity rubber bearing, the metamaterial enveloping layer is uniformly wrapped on the side surface of the steel cylinder, and the metamaterial enveloping layer is made of a negative poisson's ratio material. The invention discloses a negative Poisson ratio local resonance type resonator which is invented by utilizing the characteristics that a negative Poisson ratio metamaterial has good damping and energy absorption characteristics and a local resonance type seismic metamaterial can realize low-frequency seismic isolation, and is periodically arranged to form a seismic metamaterial seismic isolation barrier, wherein the seismic isolation barrier can obtain a low-frequency band gap, and the isolation of low-frequency seismic waves is realized.","['G06F30/27', 'G06F16/212', 'G06F2111/10', 'Y02T90/00']"
WO2022151553A1,Domain-invariant feature-based meta-knowledge fine-tuning method and platform,"Disclosed are a domain-invariant feature-based meta-knowledge fine-tuning method and a platform. In the method, highly-transferable common knowledge, that is, a domain-invariant feature, is learned on different data sets of similar tasks; and common domain features on different domains corresponding to different data sets of similar tasks are learned in a fine-tuning network set, and any different domain is quickly adapted to. In the present invention, the parameter initialization capability and generalization capability of a similar task universal language model are improved, and finally, the universal compression architecture of a similar downstream task language model is obtained by fine tuning. In a meta-knowledge fine-tuning network, a loss function of a domain-invariant feature is designed in the present invention, and general knowledge unrelated to a domain is learned, that is, a learning target of one domain-invariant feature is minimized to drive a language model to have domain-invariant feature coding capability.","['G06F18/2414', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/041']"
US20250189498A1,System and method for autonomous botanical identification and adulteration detection,"A system and method for automating the identification of botanicals and detection of adulterants based on High Performance Thin-Layer Chromatography (“HPTLC”) images. The system and method includes a first neural network that augments an existing HPTLC image dataset with synthetic data created using an adversarial machine learning model. For example, the synthetic data may be created using a generative adversarial network (GAN). The system and method further includes a second neural network that is trained on a combination of real data and synthetic data produced by the adversarial machine learning model. For example, the second neural network may be a deep convolutional neural network (CNN). Following training, the CNN performs the identification of botanicals and detection of adulteration through machine vision-based analysis of the output image data corresponding to phytochemical composition from HPTLC. The system may provide confidence-based probabilities and other numerical outputs related to the identify and adulteration determinations.","['G01N30/95', 'G06N3/0464', 'G06N3/045', 'G06N3/047']"
US20240331156A1,Method and System for Automatic Multiple Lesion Annotation of Medical Images with Hybrid Deep-Learning Networks,"A method includes receiving, from a patient, an image having a visible lesion, modifying the image to appear as if the lesion were not present, thereby forming a second image, generating a delineation of the abnormality using a difference between the first and second images, and tagging the segmented lesions.","['G16H50/20', 'G06T7/0014', 'G06T7/136', 'G06V10/82', 'G16H30/40', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US11551084B2,System and method of robust active learning method using noisy labels and domain adaptation,"A system and method is disclosed for labeling an unlabeled dataset, with a labeling budget constraint and noisy oracles (i.e. noisy labels provided by annotator), using a noisy labeled dataset from another domain or application. The system and method combine active learning with noisy labels and active learning with domain adaptation to enhance classification performance.","['G06F18/2415', 'G06F9/4881', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06V10/30']"
WO2022001509A1,"Image optimisation method and apparatus, computer storage medium, and electronic device","The present application relates to the technical field of artificial intelligence, and provides an image optimisation method and apparatus, a computer storage medium, and an electronic device. The method comprises: acquiring an image to be optimised, and performing alignment processing on the image to be optimised to acquire an aligned image to be optimised, the points of each subject in a target area of the aligned image to be optimised being distributed in standard positions; inputting the aligned image to be optimised into a generative network, and performing feature extraction on the aligned image to be optimised by means of the generative network to acquire an optimised image, the generative network being obtained by means of using a low-quality image pair and a joint loss function to train a generative adversarial deep neural network to be trained, and the low-quality image pair comprising a target image and a low-quality image corresponding to the target image. The present technical solution can increase image optimisation efficiency and can eliminate noise in the images and generate details in the images to obtain clear optimised images.","['G06T5/70', 'G06T5/73', 'G06V40/161', 'G06N3/045', 'G06N3/084', 'G06T3/4046', 'G06T3/4053', 'G06T5/20', 'G06T5/60', 'G06T5/77', 'G06T7/10', 'G06T7/37', 'G06V10/82', 'G06V40/168', 'G06V40/172', 'G06T2200/24', 'G06T2207/20028', 'G06T2207/20032', 'G06T2207/20048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11948054B2,Masked projected gradient transfer attacks,"A system and method for transferring an adversarial attack involving generating a surrogate model having an architecture and a dataset that mirrors at least one aspect of a target model of a target module, wherein the surrogate model includes a plurality of classes. The method involves generating a masked version of the surrogate model having fewer classes than the surrogate model by randomly selecting at least one class of the plurality of classes for removal. The method involves attacking the masked surrogate model to create a perturbed sample. The method involves generalizing the perturbed sample for use with the target module. The method involves transferring the perturbed sample to the target module to alter an operating parameter of the target model.","['G06N20/00', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'H04L63/1416', 'H04L63/1425', 'H04L63/1466']"
US11580391B2,Attack-less adversarial training for robust adversarial defense,Disclosed herein is attack-less adversarial training for robust adversarial defense. The attack-less adversarial training for robust adversarial defense includes the steps of: (a) generating individual intervals (ci) by setting the range of color (C) and then discretizing the range of color (C) by a predetermined number (k); (b) generating one batch from an original image (X) and training a learning model with the batch; (c) predicting individual interval indices (ŷialat) from respective pixels (xi) of the original image (X) by using an activation function; (d) generating a new image (Xalat) through mapping and randomization; and (e) training a convolutional neural network with the image (Xalat) generated in step (d) and outputting a predicted label (Ŷ).,"['G06T1/005', 'G06F21/64', 'G06F21/55', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T2201/0063', 'G06T2207/20081', 'G06T2207/20084']"
US11977962B2,Immutable watermarking for authenticating and verifying AI-generated output,"Embodiments are directed to immutable watermarking for authenticating and verifying artificial intelligence (AI)-generated output. An embodiment of a system includes a processor of a monitoring system, wherein the processor is to: receive first content from an edge device and second content from an adversary system, wherein the first content comprises output of a machine learning (ML) model as applied to captured content at the edge device; receive a digital signature corresponding to the first content; process the digital signature to extract a global unique identifier (GUID) of the ML model that generated the first content; verify the extracted GUID against data obtained from a shared registry; in response to successfully verifying the extracted GUID, provide the first content for consumption at a monitoring consumption application; and in response to determining that the second content is not associated with a verifiable GUID, refuse the second content at the monitoring consumption application.","['G06N20/00', 'G06F9/30101', 'H04L9/0643', 'H04L9/3242', 'H04L9/3247', 'G06N3/08']"
US11514571B2,Hierarchical analysis of medical images for identifying and assessing lymph nodes,"Systems and methods for identifying and assessing lymph nodes are provided. Medical image data (e.g., one or more computed tomography images) of a patient is received and anatomical landmarks in the medical image data are detected. Anatomical objects are segmented from the medical image data based on the one or more detected anatomical landmarks. Lymph nodes are identified in the medical image data based on the one or more detected anatomical landmarks and the one or more segmented anatomical objects. The identified lymph nodes may be assessed by segmenting the identified lymph nodes from the medical image data and quantifying the segmented lymph nodes. The identified lymph nodes and/or the assessment of the identified lymph nodes are output.","['A61B5/418', 'G06T11/008', 'G06T7/0012', 'G06T7/11', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20101', 'G06T2207/20112', 'G06T2207/30096']"
US11195120B2,Detecting dataset poisoning attacks independent of a learning algorithm,"Methods an systems to classify a training dataset of network data as a poisoned training dataset based on a first dataset-level classifier, identify and remove poison samples of the poisoned training dataset based on a sample-level classifier to produce a non-poisoned dataset, training a machine-based model to analyze network traffic based on the modified non-poisoned dataset, and analyze network traffic with the machine-based model.","['H04L63/1466', 'G06N20/00', 'H04L63/1425', 'H04L63/1441']"
US12205029B2,Increasing accuracy and resolution of weather forecasts using deep generative models,"Embodiments of the present invention provide the use of a conditional Generative Adversarial Network (GAN) to simultaneously correct and downscale (super-resolve) global ensemble weather or climate forecasts. Specifically, a generator deep neural network (G-DNN) in the cGAN comprises a corrector DNN (C-DNN) followed by a super-resolver DNN (SR-DNN). The C-DNN bias-corrects coarse, global meteorological forecasts, taking into account other relevant contextual meteorological fields. The SR-DNN downscales bias-corrected C-DNN output into G-DNN output at a higher target spatial resolution. The GAN is trained in three stages: C-DNN training, SR-DNN training, and overall GAN training, each using separate loss functions. Embodiments of the present invention significantly outperform an interpolation baseline, and approach the performance of operational regional high-resolution forecast models across an array of established probabilistic metrics. Crucially, embodiments of the present invention, once trained, produce high-resolution predictions in seconds on a single machine.","['G01W1/10', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088']"
US11356320B2,Identifying and locating a root cause of issues in a network having a known topology,"Systems and methods for detecting patterns in data from a time-series are provided. According to some implementations, the systems and methods may use network topology information combined with object recognition techniques to detect patterns. One embodiment of a method includes the steps of obtaining information defining a topology of a multi-layer network having a plurality of Network Elements (NEs) and a plurality of links interconnecting the NEs and receiving Performance Monitoring (PM) metrics and one or more alarms from the multi-layer network. Based on the information defining the topology, the PM metrics, and the one or more alarms, the method also includes the step of utilizing a Machine Learning (ML) process to identify a problematic component from the plurality of NEs and links and to identify a root cause associated with the problematic component.","['H04J3/14', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/045', 'H04B10/07953', 'H04J3/1652', 'H04L41/0631', 'H04L41/065', 'H04L41/12', 'H04L41/145', 'H04L41/16', 'H04L43/0823', 'G06F2218/00', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'H04J2203/0057']"
US11743150B2,Automated root cause analysis of underperforming video streams by using language transformers on support ticket systems,"A method and system corrects a content delivery infrastructure. The method of the system includes receiving a request to resolve reported issues for the content delivery infrastructure, collecting content delivery metrics for the content delivery infrastructure, executes a language transformer model on the request and the content delivery metrics to generate a set of possible resolutions with confidence ratings, and implementing an automated solution based on a resolution from the set of possible resolutions, in response to the resolution having a confidence rating above a threshold.","['H04L41/0631', 'H04L41/509', 'G06N20/00', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G06N3/096', 'H04L41/0695', 'H04L41/16', 'H04L41/5009', 'H04L41/5048', 'H04L41/5061', 'H04L41/5074', 'H04L43/0829', 'H04L43/0852', 'H04L43/087', 'H04L43/0882', 'H04L43/0894']"
US12200014B2,"Lifelong learning based intelligent, diverse, agile, and robust system for network attack detection","A lifelong learning intrusion detection system and methods are provided. The system may capture network data directed to a host node. The host node may include a honeypot. The honeypot may emulate operation of a physical or virtual device to attract malicious activity. The system may classify, based on a supervised machine learning model, the network data as being not malicious or not malicious. The system may classify, based on an unsupervised machine learning model, the network data as being anomalous or not anomalous. The system may alter operation of the honeypot to induce malicious activity. The system may determine, after operation of the honeypot is altered, the honeypot is accessed. The system may retrain the supervised machine learning model and/or unsupervised machine learning model based the network data.","['G06N3/04', 'G06N3/088', 'G06N3/09', 'H04L63/1416', 'H04L63/1491', 'G06N3/045', 'G06N5/04']"
US11694042B2,Cross-lingual unsupervised classification with multi-view transfer learning,"Presented herein are embodiments of an unsupervised cross-lingual sentiment classification model (which may be referred to as multi-view encoder-classifier (MVEC)) that leverages an unsupervised machine translation (UMT) system and a language discriminator. Unlike previous language model (LM)-based fine-tuning approaches that adjust parameters solely based on the classification error on training data, embodiments employ an encoder-decoder framework of an UMT as a regularization component on the shared network parameters. In one or more embodiments, the cross-lingual encoder of embodiments learns a shared representation, which is effective for both reconstructing input sentences of two languages and generating more representative views from the input for classification. Experiments on five language pairs verify that an MVEC embodiment significantly outperforms other models for 8/11 sentiment classification tasks.","['G06F40/30', 'G06F40/58', 'G06F16/35', 'G06F16/353', 'G06F40/126', 'G06F40/151', 'G06F40/197', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F40/216', 'G06F40/284', 'G06N3/044']"
US11625813B2,Automatically removing moving objects from video streams,"The present disclosure describes systems, non-transitory computer-readable media, and methods for accurately and efficiently removing objects from digital images taken from a camera viewfinder stream. For example, the disclosed systems access digital images from a camera viewfinder stream in connection with an undesired moving object depicted in the digital images. The disclosed systems generate a temporal window of the digital images concatenated with binary masks indicating the undesired moving object in each digital image. The disclosed systems further utilizes a 3D to 2D generator as part of a 3D to 2D generative adversarial neural network in connection with the temporal window to generate a target digital image with the region associated with the undesired moving object in-painted. In at least one embodiment, the disclosed systems provide the target digital image to a camera viewfinder display to show a user how a future digital photograph will look without the undesired moving object.","['G06V20/41', 'G06T5/005', 'G06T5/77', 'G06F18/2134', 'G06K9/624', 'G06T7/73', 'G06V10/273', 'G06V10/62', 'H04N23/62', 'H04N23/631', 'H04N23/632', 'H04N5/232933', 'G06T2207/10016', 'G06T2207/20081']"
US11228517B2,Device fingerprinting for cyber-physical systems,Disclosed are various embodiments for identifying devices that are part of a network. Devices are modeled based on physical characteristics. Devices are classified or device communications can be verified.,"['H04L43/0876', 'H04L63/1408', 'G06F15/16', 'H04L43/065', 'H04L63/0876']"
US20200204375A1,Distributed ledgers for sharing data in the aeronautical field,"Systems and computer-implemented methods for sharing aeronautical data, include steps of: maintaining a private blockchain, the blockchain involving a plurality of predefined parties; conditionally communicating aeronautical data, in response to a request by one party, via a mechanism for controlling the exchanges, the data being collected beforehand from aeronautical computers, e.g. on-board flight management systems (FMS) of aircraft. Extensions in particular describe the use: of mechanisms for providing compensation or remuneration for and managing access rights and/or licenses to use; smart contracts; mechanisms for auctioning or trading datasets; management of avionic and non-avionic data; learning techniques applied to the shared and consolidated data; management of side chains; post-quantum encryption. Software aspects are described.","['G06Q10/101', 'H04L9/3242', 'G06F21/64', 'G06F16/1865', 'G06F21/602', 'G06F21/604', 'G06F21/6218', 'G06N20/10', 'G06N3/04', 'G07C5/0841', 'G08G5/30', 'H04L63/0428', 'H04L63/123', 'H04L9/0637', 'H04L9/0643', 'H04L9/0852', 'H04L9/088', 'H04L9/3221', 'H04L9/3297', 'G06F2221/2141', 'H04L2209/38', 'H04L2209/84', 'H04L9/50']"
US11991658B2,Learning communication systems using channel approximation,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training and deploying machine-learned communication over RF channels. In some implementations, information is obtained. An encoder network is used to process the information and generate a first RF signal. The first RF signal is transmitted through a first channel. A second RF signal is determined that represents the first RF signal having been altered by transmission through the first channel. Transmission of the first RF signal is simulated over a second channel implementing a machine-learning network, the second channel representing a model of the first channel. A simulated RF signal that represents the first RF signal having been altered by simulated transmission through the second channel is determined. A measure of distance between the second RF signal and the simulated RF signal is calculated. The machine-learning network is updated using the measure of distance.","['H04W56/0035', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'H04B17/391', 'H04B17/3912', 'H04L41/145', 'H04L5/0005', 'H04W16/22', 'H04W72/0453', 'G06N3/006', 'G06N3/048', 'G06N3/126']"
US11270188B2,Joint optimization of ensembles in deep learning,"Computer-implemented, machine-learning systems and methods relate to a combination of neural networks. The systems and methods train the respective member networks both (i) to be diverse and yet (ii) according to a common, overall objective. Each member network is trained or retrained jointly with all the other member networks, including member networks that may not have been present in the ensemble when a member is first trained.","['G06N3/0454', 'G06N3/045', 'G06N3/084', 'G06N3/044', 'G06N3/0442', 'G06N3/048', 'G06N3/0499', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06N3/0985', 'G06N20/20', 'G06N5/01']"
US11475130B2,Detection of test-time evasion attacks,"Embodiments of the present invention concern detecting Test-Time Evasion (TTE) attacks on neural network, particularly deep neural network (DNN), classifiers. The manner of detection is similar to that used to detect backdoors of a classifier whose training dataset was poisoned. Given knowledge of the classifier itself, the adversary subtly (even imperceptibly) perturbs their input to the classifier at test time in order to cause the class decision to change from a source class to a target class. For example, an image of a person who is unauthorized to access a resource can be modified slightly so that the classifier decides the image is that of an authorized person. The detector is based on employing a method (similar to that used to detect backdoors in DNNs) to discover different such minimal perturbations for each in a set of clean (correctly classified) samples, to change the sample's ground-truth (source) class to every other (target) class. For each (source, target) class pair, null distributions of the sizes of these perturbations are modeled. A test sample is similarly minimally perturbed by the detector from its decided-upon (target) class to every other (potential source) class. The p-values according to the corresponding null distributions of these test-sample perturbations are assessed using the corresponding nulls to decide whether the test sample is a TTE attack.","['G06F21/554', 'G06F17/18', 'G06F18/2155', 'G06K9/6259', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/003', 'G06N5/01', 'G06V10/764', 'G06V10/774', 'G06V10/7753', 'G06V10/7788', 'G06V10/82', 'G06V20/95', 'G06V40/172', 'G06F2221/033']"
US11704409B2,Post-training detection and identification of backdoor-poisoning attacks,"This patent concerns novel technology for detecting backdoors in neural network, particularly deep neural network (DNN) classification or prediction/regression models. The backdoors are planted by suitably poisoning the training dataset, i.e., a data-poisoning attack. Once added to an input sample from a source class of the attack, the backdoor pattern causes the decision of the neural network to change to the attacker's target class in the case of classification, or causes the output of the network to significantly change in the case of prediction or regression. The backdoors under consideration are small in norm so as to be imperceptible to a human or otherwise innocuous/evasive, but this does not limit their location, support or manner of incorporation. There may not be components (edges, nodes) of the DNN which are specifically dedicated to achieving the backdoor function. Moreover, the training dataset used to learn the classifier or predictor/regressor may not be available. In one embodiment of the present invention, which addresses such challenges, if the classifier or predictor/regressor is poisoned then the backdoor pattern is determined through a feasible optimization process, followed by an inference process, so that both the backdoor pattern itself and the associated source class(es) and target class are determined based only on the classifier or predictor/regressor parameters and using a set of clean (unpoisoned) samples, from the different classes (none of which may be training samples).","['G06F21/577', 'G06F21/566', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/045', 'G06F2221/033', 'G06N3/045', 'G06N3/048']"
US20190129405A1,Systems and methods for processing data collected in an industrial environment using neural networks,"Methods and an expert system for processing a plurality of inputs collected from sensors in an industrial environment are disclosed. A modular neural network, where the expert system uses one type of neural network for recognizing a pattern relating to at least one of: the sensors, components of the industrial environment and a different neural network for self-organizing a data collection activity in the industrial environment is disclosed. A data communication network configured to communicate at least a portion of the plurality of inputs collected from the sensors to storage device is also disclosed.","['H04B17/29', 'G05B23/0294', 'B62D15/0215', 'G01M13/028', 'G01M13/04', 'G01M13/045', 'G05B13/028', 'G05B19/4183', 'G05B19/4184', 'G05B19/41845', 'G05B19/4185', 'G05B19/41865', 'G05B19/41875', 'G05B23/0221', 'G05B23/0229', 'G05B23/024', 'G05B23/0264', 'G05B23/0283', 'G05B23/0286', 'G05B23/0289', 'G05B23/0291', 'G05B23/0297', 'G06F16/2477', 'G06F18/2178', 'G06F3/0608', 'G06F3/0619', 'G06F3/0635', 'G06F3/067', 'G06K9/6263', 'G06N20/00', 'G06N3/006', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06N5/046', 'G06N7/005', 'G06N7/01', 'G06Q10/04', 'G06Q10/0639', 'G06Q30/02', 'G06Q30/0278', 'G06Q30/06', 'G06Q50/00', 'G06V10/7784', 'G06V10/82', 'G16Z99/00', 'H02M1/12', 'H03M1/12', 'H04B17/26', 'H04B17/309', 'H04B17/318', 'H04L1/0002', 'H04L1/0041', 'H04L1/18', 'H04L1/1874', 'H04L67/1097', 'H04L67/12', 'H04W4/38', 'H04W4/70', 'B62D5/0463', 'F01D21/003', 'F01D21/12', 'F01D21/14', 'G05B19/042', 'G05B2219/32287', 'G05B2219/35001', 'G05B2219/37337', 'G05B2219/37351', 'G05B2219/37434', 'G05B2219/37537', 'G05B2219/40115', 'G05B2219/45004', 'G05B2219/45129', 'G05B23/02', 'G05B23/0208', 'G06F17/18', 'G06F18/21', 'G06F18/217', 'G06F18/25', 'G06N3/126', 'H04B17/23', 'H04B17/345', 'H04B17/40', 'H04L1/0009', 'H04L5/0064', 'H04L67/306', 'Y02P80/10', 'Y02P90/02', 'Y02P90/80', 'Y04S50/00', 'Y04S50/12', 'Y10S707/99939']"
US11609990B2,Post-training detection and identification of human-imperceptible backdoor-poisoning attacks,"This patent concerns novel technology for detecting backdoors of neural network, particularly deep neural network (DNN), classifiers. The backdoors are planted by suitably poisoning the training dataset, i.e., a data-poisoning attack. Once added to input samples from a source class (or source classes), the backdoor pattern causes the decision of the neural network to change to a target class. The backdoors under consideration are small in norm so as to be imperceptible to a human, but this does not limit their location, support or manner of incorporation. There may not be components (edges, nodes) of the DNN which are dedicated to achieving the backdoor function. Moreover, the training dataset used to learn the classifier may not be available. In one embodiment of the present invention which addresses such challenges, if the classifier is poisoned then the backdoor pattern is determined through a feasible optimization process, followed by an inference process, so that both the backdoor pattern itself and the associated source class(es) and target class are determined based only on the classifier parameters and a set of clean (unpoisoned attacked) samples from the different classes (none of which may be training samples).","['G06F21/564', 'G06F21/577', 'G06F21/554', 'G06F21/568', 'G06N3/008', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06F2221/033', 'G06N3/045', 'G06N3/048']"
US12327193B2,"Methods, apparatuses and computer program products for predicting measurement device performance","Methods, apparatuses, systems, computing devices, and/or the like are provided. An example method may include generating a plurality of encoded input data objects associated with a measurement device; generating, using at least a bidirectional Recurrent Neural Networks (RNN) machine learning model, a predictive performance data object associated with the measurement device and a plurality of predictive weight data objects associated with the predictive performance data object, and performing one or more prediction-based actions based at least in part on the predictive performance data object or the plurality of predictive weight data objects.","['G06N3/088', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
US11544472B2,"Structured adversarial, training for natural language machine learning tasks","A method includes obtaining first training data having multiple first linguistic samples. The method also includes generating second training data using the first training data and multiple symmetries. The symmetries identify how to modify the first linguistic samples while maintaining structural invariants within the first linguistic samples, and the second training data has multiple second linguistic samples. The method further includes training a machine learning model using at least the second training data. At least some of the second linguistic samples in the second training data are selected during the training based on a likelihood of being misclassified by the machine learning model.","['G06F40/216', 'G06F18/214', 'G06F18/2148', 'G06F40/166', 'G06F40/205', 'G06F40/30', 'G06F40/35', 'G06F40/44', 'G06F40/56', 'G06K9/6257', 'G06N20/00', 'G06N3/02', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/768', 'G06N5/04']"
US11514297B2,Post-training detection and identification of human-imperceptible backdoor-poisoning attacks,"This patent concerns novel technology for detecting backdoors of neural network, particularly deep neural network (DNN), classifiers. The backdoors are planted by suitably poisoning the training dataset, i.e., a data-poisoning attack. Once added to input samples from a source class (or source classes), the backdoor pattern causes the decision of the neural network to change to a target class. The backdoors under consideration are small in norm so as to be imperceptible to a human, but this does not limit their location, support or manner of incorporation. There may not be components (edges, nodes) of the DNN which are dedicated to achieving the backdoor function. Moreover, the training dataset used to learn the classifier may not be available. In one embodiment of the present invention which addresses such challenges, if the classifier is poisoned then the backdoor pattern is determined through a feasible optimization process, followed by an inference process, so that both the backdoor pattern itself and the associated source class(es) and target class are determined based only on the classifier parameters and a set of clean (unpoisoned attacked) samples from the different classes (none of which may be training samples).","['G06N3/0454', 'G06F21/577', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06F2221/033']"
US11501206B2,Method and machine learning system for detecting adversarial examples,"A method and machine learning system for detecting adversarial examples is provided. A first machine learning model is trained with a first machine learning training data set having only training data samples with robust features. A second machine learning model is trained with a second machine learning training data set, the second machine learning training data set having only training data samples with non-robust features. A feature is a distinguishing element in a data sample. A robust feature is more resistant to adversarial perturbations than a non-robust feature. A data sample is provided to each of the first and second trained machine learning models during an inference operation. if the first trained machine learning model classifies the data sample with high confidence, and the second trained machine learning model classifies the data sample differently with a high confidence, then the data sample is determined to be an adversarial example.","['G06N3/08', 'G06F18/2148', 'G06F18/217', 'G06F18/24', 'G06K9/6257', 'G06K9/6262', 'G06K9/6267', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094']"
US11586681B2,System and methods to mitigate adversarial targeting using machine learning,"A system for adversarial targeting mitigation is provided, the system generally comprising identifying, using an artificial intelligence and machine learning model engine, a user targeting pattern employed by an entity based on interaction data between the entity and one or more users, based on the identified pattern of targeting, training the machine learning model to identify specific user profile data correlated with specific responses from the entity, identifying, using the machine learning model, a subset of one or more favorable responses from the specific responses, and triggering the one or more favorable responses by altering the user profile data for the one or more users prior to interaction with the specific entity.","['G06F16/9035', 'G06F18/2115', 'G06F18/2148', 'G06F18/2185', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/094']"
US10997470B2,Adversarial patches including pixel blocks for machine learning,"Systems, apparatuses, and methods are directed towards identifying that an adversarial patch image includes a plurality of pixels. The systems, apparatuses, and methods include dividing the adversarial patch image into a plurality of blocks, that each include a different group of the pixels in which the pixels are contiguous to each other, and assigning a first plurality of colors to the plurality of blocks to assign only one of the first plurality of colors to each pixel of one of the plurality of blocks.","['G06K9/6265', 'G06N3/084', 'G06F18/2193', 'G06K9/4642', 'G06K9/4652', 'G06N20/00', 'G06V10/764']"
US12106198B2,Machine learning model robustness against adversarial attacks in production,This disclosure is directed to a generalizable machine learning model production environment and system with a defense mechanism that facilitates safe execution of machine learning models in production by effectively detecting potential known and new adversarial attacks. The disclosed exemplary systems and architectures gather data from the online execution of the machine learning models and communicate with an on-demand pipelines for further inspection and/or correction of vulnerabilities in the production machine learning model to the detected attacks. These systems and architectures provide an automatable process for continuous monitoring of model performance and correction of the production machine learning model to guard against current and future adversarial attacks.,"['G06N20/20', 'G06F21/64', 'G06N5/01', 'G06N5/04']"
US20250165792A1,Adversarial training of machine learning models,This document relates to training of machine learning models such as neural networks. One example method involves providing a machine learning model having one or more layers and associated parameters and performing a pretraining stage on the parameters of the machine learning model to obtain pretrained parameters. The example method also involves performing a tuning stage on the machine learning model by using labeled training samples to tune the pretrained parameters. The tuning stage can include performing noise adjustment of the labeled training examples to obtain noise-adjusted training samples. The tuning stage can also include adjusting the pretrained parameters based at least on the labeled training examples and the noise-adjusted training examples to obtain adapted parameters. The example method can also include outputting a tuned machine learning model having the adapted parameters.,"['G06N3/08', 'G06N3/088', 'G06N3/045']"
EP3591586A1,Data model generation using generative adversarial networks and fully automated machine learning system which generates and optimizes solutions given a dataset and a desired outcome,"Methods for generating data models using a generative adversarial network can begin by receiving a data model generation request by a model optimizer from an interface. The model optimizer can provision computing resources with a data model. As a further step, a synthetic dataset for training the data model can be generated using a generative network of a generative adversarial network, the generative network trained to generate output data differing at least a predetermined amount from a reference dataset according to a similarity metric. The computing resources can train the data model using the synthetic dataset. The model optimizer can evaluate performance criteria of the data model and, based on the evaluation of the performance criteria of the data model, store the data model and metadata of the data model in a model storage. The data model can then be used to process production data.","['G06N3/126', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06N5/01', 'G06N7/01']"
US11893111B2,Defending machine learning systems from adversarial attacks,"Techniques are disclosed for detecting adversarial attacks. A machine learning (ML) system processes the input into and output of a ML model using an adversarial detection module that does not include a direct external interface. The adversarial detection module includes a detection model that generates a score indicative of whether the input is adversarial using, e.g., a neural fingerprinting technique or a comparison of features extracted by a surrogate ML model to an expected feature distribution for the output of the ML model. In turn, the adversarial score is compared to a predefined threshold for raising an adversarial flag. Appropriate remedial measures, such as notifying a user, may be taken when the adversarial score satisfies the threshold and raises the adversarial flag.","['G06F21/554', 'G06N20/00', 'G06N3/04', 'G06N3/0464', 'G06F2221/034']"
EP3910479A1,"A method and a system for testing machine learning and deep learning models for robustness, and durability against adversarial bias and privacy attacks","A system for testing Machine Learning (ML) and deep learning models for robustness, and durability against adversarial bias and privacy attacks, comprising a Project Repository for storing metadata of ongoing projects each of which having a defined project policy, and created ML models and data sources being associated with the ongoing projects; a Secure Data Repository, for storing training and testing datasets and models used in each project for evaluating the robustness of the each project; a Data/Model Profiler for creating a profile, based on the settings and configurations of the datasets and the models; a Test Recommendation Engine for recommending the relevant and most indicative attacks/tests for each examined model and for creating indicative and effective test suites; a Test/Attack Ontology module for storing all attacks/tests with their metadata and mapping the attacks/tests to their corresponding settings and configurations; an Attack Repository for storing the implemented tests/attacks. An ML model is tested against each one of the robustness categories (privacy, bias and adversarial learning); a Test Execution Environment for Initializing a test suite, running multiple tests and prioritizing tests in the test suite; a Project/Test Analytics module for analyzing the test suite results and monitoring changes in performance over time; a Defenses Repository for storing implemented defense methods implemented for each robustness category.","['G06F21/577', 'G06F11/3612', 'G06F11/3684', 'G06F11/3688', 'G06F11/3692', 'G06F11/3698', 'G06F21/6245', 'G06N20/00', 'G06F2221/033', 'G06N5/02']"
US11227215B2,Quantifying vulnerabilities of deep learning computing systems to adversarial perturbations,"Mechanisms are provided for generating an adversarial perturbation attack sensitivity (APAS) visualization. The mechanisms receive a natural input dataset and a corresponding adversarial attack input dataset, where the adversarial attack input dataset comprises perturbations intended to cause a misclassification by a computer model. The mechanisms determine a sensitivity measure of the computer model to the perturbations in the adversarial attack input dataset based on a processing of the natural input dataset and corresponding adversarial attack input dataset by the computer model. The mechanisms generate a classification activation map (CAM) for the computer model based on results of the processing and a sensitivity overlay based on the sensitivity measure. The sensitivity overlay graphically represents different classifications of perturbation sensitivities. The mechanisms apply the sensitivity overlay to the CAM to generate and output a graphical visualization output of the computer model sensitivity to perturbations of adversarial attacks.","['G06N3/08', 'G06F21/55', 'G06N20/00', 'G06N3/0464', 'G06N3/09', 'G06N3/045']"
US11373093B2,Detecting and purifying adversarial inputs in deep learning computing systems,"Adversarial input detection and purification (AIDAP) preprocessor and deep learning computer model mechanisms are provided. The deep learning computer model receives input data and processes it to generate a first pass output that is output to the AIDAP preprocessor. The AIDAP preprocessor determines a discriminative region of the input data based on the first pass output and transforms a subset of elements in the discriminative region to modify a characteristic of the elements and generate a transformed input data. The deep learning computer model processes the transformed input data to generate a second pass output that is output to the AIDAP preprocessor which detects an adversarial input or not based on a comparison of the first pass and second pass outputs. If an adversarial input is detected, a responsive action that mitigates effects of the adversarial input is performed.","['G06N3/08', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/40']"
US10839265B2,Platform for preventing adversarial attacks on image-based machine learning models,"Methods, systems, and computer-readable storage media for receiving a set of training images and a set of classification labels, generating a set of target codebooks based on the set of classification labels, the set of target codebooks being provided as a first set of vectors of random value and dimension, generating a set of output codebooks based on the set of training images, the set of output codebooks being provided as a second set of vectors of random value and dimension, training a ML model by minimizing a loss function provided as a mean-squared-error (MSE) loss function, the loss function being measured by the Euclidean distance between an output codebook of the set of output codebooks and a target codebook of the set of target codebooks.","['G06K9/6256', 'G06V10/30', 'G06F18/214', 'G06K9/40', 'G06V10/764', 'G06V10/82', 'G06V20/70', 'G06V20/10']"
AU2019200896B2,Privatized machine learning using generative adversarial networks,"One embodiment provides for a mobile electronic device comprising a non-transitory machine readable medium to store instructions, the instructions to cause the mobile electronic device to receive a set of labeled data from a server; receive a unit of data from the server, the unit of data of a same type of data as the set of labeled data; determine a proposed label for the unit of data via a machine learning model on the mobile electronic device, the machine learning model to determine the proposed label for the unit of data based on the set of labeled data from the server and a set of unlabeled data associated with the mobile electronic device; encode the proposed label via a privacy algorithm to generate a privatized encoding of the proposed label; and transmit the privatized encoding of the proposed label to the server. 1/19 000 M 7:1c 00 '*ei .7f. 00 a)r","['G06F21/602', 'G06N3/088', 'H04L9/008', 'G06N20/00', 'G06F21/6245', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'H04L67/10', 'G06N3/063']"
CN113688977B,"Human-computer symbiosis reinforcement learning methods, devices, computing equipment and storage media for adversarial tasks","The invention discloses a man-machine symbiotic reinforcement learning method, a device, a computing device and a storage medium for an countermeasure task, which comprise the following steps: optimizing the CNN using simulated learning to obtain a policy function of the CNN according to the human-directed demonstration data; initializing a strategy function of a strategy network of a PPO algorithm according to the strategy function of the CNN, adding a target value network for the PPO algorithm to calculate a return value, and optimizing the PPO algorithm by adopting a distributed training mode to increase a loss function of the return value; initializing an average strategy network of the intelligent agent in the NFSP algorithm by using a PPO algorithm, and calculating an optimal response strategy of the intelligent agent by using an MCTS algorithm; and training the estimation of the rewarding value of the NFSP algorithm according to the human feedback data, and performing reinforcement learning on each agent in the NFSP algorithm in the environment state according to the estimated rewarding value so as to optimize the average strategy and the optimal response strategy of the agent. So as to improve the decision accuracy of the intelligent agent in the countermeasure task.","['G06N20/00', 'A63F13/67', 'G06F3/011', 'G06N3/045', 'G06N3/084', 'Y02T10/40']"
US11800379B2,Improving immune system of site using generative adversarial networks and reinforcement learning,"Methods include training, using a generative adversarial network, a generator model using data noise that includes data corresponding to real problems of a telecommunication site, generating a generated problem that has not occurred at the telecommunication site and that has a non-zero probability of occurring at the site in the future, providing the generated problem to a virtual agent that is configured to generate a solution action to resolve the generated problem, evaluating the solution action relative to the generated problem to determine a performance value corresponding to the solution action, and responsive to the performance value being higher than other performance values corresponding to other solution actions for the generated problem, generating a generic problem model that corresponds to the generated problem and that is associated with the solution action.","['H04L41/145', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'H04L41/16', 'H04W24/02', 'H04W24/06', 'H04L41/142']"
US11311247B2,System and methods for restorative dentistry treatment planning using adversarial learning,"Training a generator includes processing a dental image using the generator to obtain a synthetic pathology label, such has a pixel mask indicating portions of the dental image representing caries. The synthetic pathology label is compared to a target pathology label for the dental image and the generator is updated according to the comparison. The synthetic pathology may be evaluated by a discriminator along with a real pathology label to obtain a realism estimate. The discriminator and generator may be updated according to accuracy of the realism estimate. Inputs to the generator may further include tooth labels and/or labels of restorations. Machine learning models may be trained to label restorations and defects in restorations. A machine learning model may be trained to identify the surface of a tooth having a pathology thereon.","['A61B6/51', 'A61B1/00009', 'A61B1/24', 'A61B5/0088', 'A61B5/7267', 'A61B6/032', 'A61B6/14', 'A61B6/4085', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'G06F18/2148', 'G06K9/6257', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G16H20/30', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G16H70/20', 'G16H70/60', 'A61B1/000094', 'A61B1/000096', 'A61B5/055', 'G06K2209/05', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US20200372402A1,Population diversity based learning in adversarial and rapid changing environments,"An artificial intelligence system and method for improving machine learning model adaptability are provided for a population of machine learning models configured to monitor a real-time data stream. A controller is configured for training and reconfiguring the population of the machine learning models in response to changes in the data stream; continuously monitor the population of the machine learning models, wherein continuously monitoring the population comprises collecting performance metrics for each of the machine learning models; analyze the performance metrics for each of the machine learning models by comparing the performance metrics to threshold values; and based on analyzing the performance metrics, reconfigure the population of the machine learning models.","['G06N20/00', 'G06N3/088', 'G06N3/045', 'H04L63/1425']"
US11049500B2,Adversarial learning and generation of dialogue responses,"Systems and methods for generating responses to user input such as dialogues, and images are discussed. The system may generate, by a response generation module of at least one server, an optimal generated response to the user communication by applying an generative adversarial network. In some embodiments, the generative adversarial network may include a hierarchical recurrent encoder decoder generative adversarial network including a generator and a discriminator component.","['G10L15/22', 'G06F40/35', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G10L13/027', 'G10L15/26']"
CN112820361B,A drug molecule generation method based on adversarial imitation learning,"The invention discloses a drug molecule generation method based on anti-imitation learning, which generates drug molecules based on anti-imitation learning and multi-task reinforcement learning and comprises the following steps: constructing an effective drug molecule library; an improved drug molecule generation model is created, comprising: designing and realizing a multitasking reinforcement learning module and designing and realizing an antagonism imitation learning module; model pre-training; executing a drug molecule generation flow; candidate drug molecule results are generated. By adopting the technical scheme provided by the invention, the optimization of the biochemical property of the drug molecules can be effectively promoted, the stability of model training is improved, and better drug molecules are obtained.","['G16C20/70', 'G16C20/50']"
US11681918B2,Cohort based adversarial attack detection,"Mechanisms are provided to provide an improved computer tool for determining and mitigating the presence of adversarial inputs to an image classification computing model. A machine learning computer model processes input data representing a first image to generate a first classification output. A cohort of second image(s), that are visually similar to the first image, is generated based on a comparison of visual characteristics of the first image to visual characteristics of images in an image repository. A cohort-based machine learning computer model processes the cohort of second image(s) to generate a second classification output and the first classification output is compared to the second classification output to determine if the first image is an adversarial image. In response to the first image being determined to be an adversarial image, a mitigation operation by a mitigation system is initiated.","['G06N3/08', 'G06F18/22', 'G06F18/254', 'G06F9/3867', 'G06F9/542', 'G06N20/00', 'G06N3/0464', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V10/809', 'G06V10/82']"
US11398013B2,"Generative adversarial network for dental image super-resolution, image sharpening, and denoising","A novel GAN is trained to predict high fidelity synthetic images based on low quality input dental images. The GAN further takes input anatomic masks as inputs with each image, the masks labeling pixels of the image corresponding to dental features. The GAN includes an encoder-decoder generator with semantically aware normalization between stages of the decoder according to the masks. The predicted synthetic dental image and an unpaired dental image are evaluated by a first discriminator of the GAN to obtain a realism estimate. The synthetic image and an unpaired dental image may be processed using a pretrained dental encoder to obtain a perceptual loss. The GAN is trained with the realism estimate, perceptual loss, and L1 loss. Utilization may include inputting noisy, low contrast, low resolution, blurry, or degraded dental images and outputting high resolution, denoised, high contrast, deobfuscated, and sharp dental images.","['A61B5/1032', 'G06T5/002', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06T5/003', 'G06T5/70', 'G06T5/73', 'G06T7/0012', 'G06V10/764', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B1/000094', 'A61B1/000096', 'A61B1/24', 'A61B5/0088', 'A61B5/055', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US12184683B2,"Cybersecurity resilience by integrating adversary and defender actions, deep learning, and graph thinking","A technique for providing cyber resilience by integrating autonomous adversary and defender agents, deep learning, and graph thinking. An automated competitive environment of autonomous adversary and defender agents is provided such that the adversary agent can emulate the adversary activities, patterns, and intentions using all available cybersecurity measurements and observations, and, the defender agent can generate and suggest the best possible appropriate actions to mitigate or prevent adversary activities while recovering or protecting assets. An automated cyber resilience system with autonomous agents is provided using machine learning and security analytics to first predict the current and future adversary activities and then provide an automated critical asset protection and recovery by enabling agents to take appropriate reactive and pro-active actions at each time step to prevent, recover, or mitigate adversary activities over enterprise and tactical networks.","['H04L63/1433', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N7/01', 'H04L63/145', 'G06N5/022', 'G06N5/043']"
US11367188B2,Dental image synthesis using generative adversarial networks with semantic activation blocks,"A GAN is trained to process input images and produce a synthetic dental image. The GAN further takes masks as inputs with each image, the masks labeling pixels of the image corresponding to dental features (anatomy and/or treatments). The GAN includes an encoder-decoder with normalization between stages of the decoder according to the masks. A synthetic image and an unpaired dental image is evaluated by a first discriminator of the GAN to obtain a realism estimate. The synthetic image and an unpaired dental image may be processed using a pretrained dental encoder to obtain a perceptual loss. The GAN is trained with the realism estimate and perceptual loss. Utilization may include modifying a mask for an input image to include or exclude a shape of a feature such that the synthetic image includes or excludes a dental feature.","['A61B5/0088', 'A61B5/4547', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'G06N20/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06T3/40', 'G06T7/0012', 'G06T7/73', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B1/000096', 'A61B1/24', 'A61B5/0035', 'A61B5/055', 'A61B6/032', 'G06N3/048', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US20200372301A1,Adversarial Defense Platform For Automated Dental Image Classification,"Dental images are processed according to a first machine learning model to determine teeth labels. The teeth labels and image are concatenated and processed using a second machine learning model to label anatomy including CEJ, JE, GM, and Bone. The anatomy labels, teeth labels, and image are concatenated and processed using a third machine learning model to obtain feature measurements, such as pocket depth and clinical attachment level. The feature measurements, anatomy labels, teeth labels, and image may be concatenated and input to a fourth machine learning model to obtain a diagnosis for a periodontal condition. Feature measurements and/or the diagnosis may be processed according to a diagnosis hierarchy to determine whether a treatment is appropriate. Machine learning models may further be used to reorient, decontaminate, and restore the image prior to processing. A machine learning model may be made resistant to deception by images including added adversarial noise.","['G06K9/6259', 'G06N3/084', 'A61B6/469', 'A61C7/002', 'G06F18/2155', 'G06F18/2411', 'G06K9/6269', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06V10/764', 'G06V10/7753', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'A61B6/51', 'G06N3/048', 'G06V2201/033']"
WO2022101515A1,Method for an explainable autoencoder and an explainable generative adversarial network,"An exemplary embodiment provides an autoencoder which is explainable. An exemplary explainable autoencoder may explain the degree to which each feature of the input attributed to the output of the system, which may be a compressed data representation. An exemplary embodiment may be used for classification, such as anomaly detection, as well as other scenarios where an explainable autoencoder is used as input to another machine learning system or when an explainable autoencoder is a component in an end-to-end deep learning architecture. An exemplary embodiment provides an explainable generative adversarial network that adds explainable generation, simulation and discrimination capabilities. The underlying architecture of an exemplary embodiment may be based on an explainable or interpretable neural network, allowing the underlying architecture to be a fully explainable white-box machine learning system.","['G06N3/08', 'G06N3/045', 'G06N3/047', 'G06N5/022', 'G06N5/045']"
US12182258B2,Adversarial training to minimize data poisoning attacks,The techniques disclosed herein enable systems to train machine learning models using benign augmentation to enabled resistance various data poisoning attacks. This is achieved by first training a machine learning model using an initial dataset that is trustworthy and originates from a known source. The initial dataset is then modified to include known attack triggers such as syntactic paraphrasing to generate an augmented dataset. The augmented dataset is then used to train a robust machine learning model based using the initially trained machine learning model. The resultant robust machine learning model is then enabled to detect and resist attacks captured by the augmented dataset. The robust machine learning model can be retrained using an untrusted dataset that includes various compromised inputs in conjunction with the augmented dataset. Retraining results in an updated robust machine learning model that can learn and resist various data poisoning attacks on the fly.,"['G06F21/552', 'G06F21/554', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N5/022', 'G06F2221/03', 'G06N20/10']"
US12182263B2,Defending deep generative models against adversarial attacks,Adversarial attack detection operations may be applied on one or more deep generative models for defending deep generative models from adversarial attacks. The adversarial attack may be detected on the one or more deep generative models based on the one or more of a plurality of adversarial attack detection operations. The one or more deep generative models may be sanitized based on the adversarial attack.,"['G06F21/554', 'G06F21/56', 'G06F21/577', 'G06F2221/034']"
US11252188B1,Methods and apparatus to automate cyber defense decision process and response actions by operationalizing adversarial technique frameworks,"In some embodiments, a method can include identifying detection coverage of a set of adversarial techniques based on telemetry data and a detection instance of an environment. The method can further include determining a subset of detection coverage that has a metric value below a metric value threshold and among the detection coverage for the set of adversarial techniques. The method may further include identifying at least one detection instance associated with the subset of detection coverage. The method can further include presenting, via a graphical user interface, a representation of at least one of the subset of detection coverage or the at least one detection instance associated with the subset of detection coverage. The method can further include updating the subset of detection coverage based on the telemetry data, the detection instance, or the at least one detection instance to improve the metric value.","['H04L63/1433', 'H04L63/1466', 'G06F21/50', 'G06N3/0442', 'G06N3/08', 'G06N3/09', 'G06N5/025', 'H04L63/029', 'H04L63/1408', 'H04L63/1416', 'H04L63/20']"
US11657162B2,Adversarial training of neural networks using information about activation path differentials,"In one example an apparatus comprises a memory and a processor to create, from a first deep neural network (DNN) model, a first plurality of DNN models, generate a first set of adversarial examples that are misclassified by the first plurality of deep neural network (DNN) models, determine a first set of activation path differentials between the first plurality of adversarial examples, generate, from the first set of activation path differentials, at least one composite adversarial example which incorporates at least one intersecting critical path that is shared between at least two adversarial examples in the first set of adversarial examples, and use the at least one composite adversarial example to generate a set of inputs for a subsequent training iteration of the DNN model. Other examples may be described.","['G06F21/60', 'G06F21/52', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/126', 'G06N3/044']"
US11847414B2,Robustness to adversarial behavior for text classification models,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a text classification machine learning model. One of the methods includes training a model having a plurality of parameters and configured to generate a classification of a text sample comprising a plurality of words by processing a model input that includes a combined feature representation of the plurality of words in the text sample, wherein the training comprises receiving a text sample and a target classification for the text sample; generating a plurality of perturbed combined feature representations; determining, based on the plurality of perturbed combined feature representations, a region in the embedding space; and determining an update to the parameters based on an adversarial objective that encourages the model to assign the target classification for the text sample for all of the combined feature representations in the region in the embedding space.","['G06F40/279', 'G06F40/216', 'G06F40/166', 'G06F40/247', 'G06F40/284', 'G06F40/289', 'G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/04']"
US12248556B2,Authenticator-integrated generative adversarial network (GAN) for secure deepfake generation,"An apparatus to facilitate an authenticator-integrated generative adversarial network (GAN) for secure deepfake generation is disclosed. The apparatus includes one or more processors to: generate, by a generative neural network, samples based on feedback received from a discriminator neural network and from an authenticator neural network, the generative neural network aiming to trick the discriminator neural network to identify the generated samples as real content samples; digest, by the authenticator neural network, the real content samples, the generated samples from the generative neural network, and an authentication code; embed, by the authenticator neural network, the authentication code into the generated samples from the generative neural network by contributing to a generator loss provided to the generative neural network; generate, by the generative neural network, content comprising the embedded authentication code; and verify, by the authenticator neural network, the content based on the embedded authentication code.","['G06F21/44', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06F2221/2129']"
US20230334332A1,Detecting adversarial examples using latent neighborhood graphs,"Techniques are disclosed for performing adversarial object detection. In one example, a system obtains a feature vector upon receiving an object to be classified. The system then generates a graph using the feature vector for the object and other feature vectors that are respectively obtained from a reference set of objects, whereby the feature vector corresponds to a center node of the graph. The system uses a distance metric to select neighbor nodes from among the reference set of objects for inclusion into the graph, and then determines edge weights between nodes of the graph based on a distance between respective feature vectors between nodes. The system then applies a graph discriminator to the graph to classify the object as adversarial or benign, the graph discriminator being trained using (I) the feature vectors associated with nodes of the graph and (II) the edge weights between the nodes of the graph.","['G06V10/7635', 'G06N3/094', 'G06N3/045', 'G06N5/022', 'G06V10/761', 'G06V10/7747', 'G06V10/82', 'G06V20/95', 'G06N3/0464', 'G06N3/048', 'G06N3/09']"
US20230308465A1,System and method for dnn-based cyber-security using federated learning-based generative adversarial network,"The system comprises a FL-based generative adversarial network (GAN) for generating adversarial examples, wherein the GAN includes a generator for generating the adversarial examples and a discriminator for distinguishing the adversarial examples from the original data, wherein the FL network includes multiple clients, each having a local dataset and a local DNN model, and a central server for coordinating the training process; a DNN for classifying data, where the DNN is trained using the generated adversarial examples, wherein the training process includes exchanging the model updates between the client’s server and the central server; an evaluation module for measuring the adversarial accuracy and adversarial robustness of the DNN using appropriate metrics, including the adversarial accuracy, the adversarial loss, and the robustness to perturbations; and an adjustment module for adjusting the architecture or parameters of the DNN based on the evaluation results to improve its adversarial robustness.","['H04L63/1425', 'H04L63/205']"
US20210125104A1,Machine learning inference system,"The present invention relates to a machine learning inference system and processing modules thereof. In particular, the present invention relates to a machine learning inference system, a confidence module, a data minder module, a data remapping module, an adversarial defense module, and an update module. The machine learning inference system and processing modules thereof are useful for mission-critical applications to increase and maintain performance of a machine learning model.","['G06N3/082', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06T1/20', 'G06N3/044', 'G06N3/047']"
US11818163B2,Automatic machine learning vulnerability identification and retraining,"Techniques are disclosed relating to training a machine learning model to handle adversarial attacks. In some embodiments, a computer system perturbs, using a set of adversarial attack methods, a set of training examples used to train a machine learning model. In some embodiments, the computer system identifies, from among the perturbed set of training examples, a set of sparse perturbed training examples that are usable to train machine learning models to identify adversarial attacks, where the set of sparse perturbed training examples includes examples whose perturbations are below a perturbation threshold and whose classifications satisfy a classification difference threshold. In some embodiments, the computer system retrains, using the set of sparse perturbed training examples, the machine learning model. The disclosed techniques may advantageously enable a machine learning model to correctly classify data associated with adversarial attacks.","['H04L63/1441', 'G06F18/213', 'G06F18/214', 'G06F18/2148', 'G06F18/217', 'G06F18/2415', 'G06N20/00', 'G06N3/006', 'G06N5/04']"
US11036857B2,Protecting a machine learning model,"A method for protecting a machine learning model includes: generating a first adversarial example by modifying an original input using an attack tactic, wherein the model accurately classifies the original input but does not accurately classify at least the first adversarial example; training a defender to protect the model from the first adversarial example by updating a strategy of the defender based on predictive results from classifying the first adversarial example; updating the attack tactic based on the predictive results from classifying the first adversarial example; generating a second adversarial example by modifying the original input using the updated attack tactic, wherein the trained defender does not protect the model from the second adversarial example; and training the defender to protect the model from the second adversarial example by updating the at least one strategy of the defender based on results obtained from classifying the second adversarial example.","['G06F21/566', 'G06F21/554', 'G06N3/045', 'G06N3/0455', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06F21/556', 'G06F2221/033', 'G06F30/27', 'H04L29/06911', 'H04L63/1441']"
AU2022202958B2,Generation of protein sequences using machine learning techniques,"Amino acid sequences of antibodies can be generated using a generative adversarial network that includes a first generating component that generates amino acid sequences of antibody light chains and a second generating component that generates amino acid sequences of antibody heavy chains. Amino acid sequences of antibodies can be produced by combining the respective amino acid sequences produced by the first generating component and the second generating component. The training of the first generating component and the second generating component can proceed at different rates. Additionally, the antibody amino acids produced by combining amino acid sequences from the first generating component and the second generating component may be evaluated according to complentarity-determining regions of the antibody amino acid sequences. Training datasets may be produced using amino acid sequences that correspond to antibodies have particular binding affinities with respect to molecules, such as binding affinity with major histocompatibility complex (MHC) molecules.","['G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/123', 'G16B20/30', 'G16B30/00', 'G16B35/10', 'G16B40/20']"
US11651292B2,Methods and apparatuses for defense against adversarial attacks on federated learning systems,"Methods and computing apparatuses for defending against model poisoning attacks in federated learning are described. One or more updates are obtained, where each update represents a respective difference between parameters (e.g. weights) of the global model and parameters (e.g. weights) of a respective local model. Random noise perturbation and normalization are applied to each update, to obtain one or more perturbed and normalized updates. The parameters (e.g. weights) of the global model are updated by adding an aggregation of the one or more perturbed and normalized updates to the parameters (e.g. weights) of the global model. In some examples, one or more learned parameters (e.g. weights) of the previous global model are also perturbed using random noise.","['G06N20/00', 'G06N20/20', 'G06F17/16', 'G06F17/18', 'G06N7/01']"
US20210303695A1,Measuring Overfitting of Machine Learning Computer Model and Susceptibility to Security Threats,"Mechanisms are provided to determine a susceptibility of a trained machine learning model to a cybersecurity threat. The mechanisms execute a trained machine learning model on a test dataset to generate test results output data, and determine an overfit measure of the trained machine learning model based on the generated test results output data. The overfit measure quantifies an amount of overfitting of the trained machine learning model to a specific sub-portion of the test dataset. The mechanisms apply analytics to the overfit measure to determine a susceptibility probability that indicates a likelihood that the trained machine learning model is susceptible to a cybersecurity threat based on the determined amount of overfitting of the trained machine learning model. The mechanisms perform a corrective action based on the determined susceptibility probability.","['G06F17/18', 'G06F21/577', 'G06N20/10', 'G06N3/08', 'G06N3/045']"
US20220198339A1,Systems and methods for training machine learning model based on cross-domain data,"Systems and methods for training an initial machine learning model is provided. The system may train an initial machine learning model using source domain training data with sample labels and target domain training data without sample labels. The initial machine learning model may include a feature extraction unit, a first processing unit, and an adversarial unit, wherein the first processing unit is associated with a first loss function, and the adversarial unit is associated with a second loss function. In some embodiments, the initial machine learning model may also include a second processing unit. A third loss function that reflects the consistency of the first processing unit and the second processing unit may be determined. The initial machine learning model may be trained based on the feature extraction unit, the first processing unit, the adversarial unit, and the second processing unit.","['G06N20/20', 'G06N3/08', 'G06F18/214', 'G06F18/241', 'G06K9/6232', 'G06K9/6256', 'G06K9/6268', 'G06N3/045', 'G06V10/25', 'G06V10/82']"
US11568211B2,Defending neural networks by randomizing model weights,"The present disclosure is directed to systems and methods for the selective introduction of low-level pseudo-random noise into at least a portion of the weights used in a neural network model to increase the robustness of the neural network and provide a stochastic transformation defense against perturbation type attacks. Random number generation circuitry provides a plurality of pseudo-random values. Combiner circuitry combines the pseudo-random values with a defined number of least significant bits/digits in at least some of the weights used to provide a neural network model implemented by neural network circuitry. In some instances, selection circuitry selects pseudo-random values for combination with the network weights based on a defined pseudo-random value probability distribution.","['G06N3/0472', 'G06F17/18', 'G06F7/588', 'G06N3/047', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06F7/58', 'G06N20/10', 'G06N3/044', 'G06N3/045']"
US20230331723A1,Entangled conditional adversarial autoencoder for drug discovery,"A method is provided for generating new objects having given properties, such as a specific bioactivity (e.g., binding with a specific protein). In some aspects, the method can include: (a) receiving objects (e.g., physical structures) and their properties (e.g., chemical properties, bioactivity properties, etc.) from a dataset; (b) providing the objects and their properties to a machine learning platform, wherein the machine learning platform outputs a trained model; and (c) the machine learning platform takes the trained model and a set of properties and outputs new objects with desired properties. The new objects are different from the received objects. In some aspects, the objects are molecular structures, such as potential active agents, such as small molecule drugs, biological agents, nucleic acids, proteins, antibodies, or other active agents with a desired or defined bioactivity (e.g., binding a specific protein, preferentially over other proteins).","['C07D471/04', 'G06F18/2178', 'G06F18/2413', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06V10/764', 'G06V10/82', 'G16C20/30', 'G16C20/40', 'G16C20/50', 'G16C20/70']"
US20230222353A1,Method and system for training a neural network model using adversarial learning and knowledge distillation,"Method and system of training a student neural network using adversarial learning and knowledge distillation, including: training a generator to generate adversarial data samples for respective training data samples by masking parts of the training data samples with an objective of maximizing a divergence between output predictions generated by the student neural network and a teacher neural network model for the adversarial data samples; and training the student neural network based on objectives of (i) minimizing a divergence between output predictions generated by the student neural network and the teacher neural network model for the adversarial data samples, and (ii) minimizing a divergence between output predictions generated by the student neural network and the teacher neural network model for the training data samples.","['G06N3/094', 'G06N3/088', 'G06N3/045']"
US12406483B2,Online class-incremental continual learning with adversarial shapley value,"A method for scoring training data samples according to an ability to preserve latent decision boundaries for previously observed classes while promoting learning from an input batch of new images from an online data stream, comprising: receiving the input batch of the new images from the online data stream, performing a memory retrieval process that retrieves data to be learned along with a new set of data from the memory to retain the previously learned knowledge, and performing a memory update process that selects and exchanges a small set of data to be saved in the memory in the memory update process. In addition, the method performs data valuation based on KNN-SV for both the memory retrieval and memory update processes to perform strategic and intuitive data selection based on the properties of KNN-SV.","['G06V10/82', 'G06F18/2113', 'G06F18/217', 'G06F18/2431', 'G06N20/00', 'G06N3/044', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06N3/045']"
US20220114399A1,System and method for machine learning fairness testing,"Systems and methods for diagnosing and testing fairness of machine learning models based on detecting individual violations of group definitions of fairness, via adversarial attacks that aim to perturb model inputs to generate individual violations. The systems and methods employ auxiliary machine learning models using a local surrogate for identifying group membership and assess fairness by measuring the transferability of attacks from this model. The systems and methods generate fairness indicator values indicative of discrimination risk due to the target predictions generated by the machine learning model, by comparing gradients of the machine learning model to gradients of an auxiliary machine learning model.","['G06K9/6262', 'G06F18/217', 'G06N3/084', 'G06F18/24133', 'G06K9/6202', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06V10/751']"
US10636141B2,Adversarial and dual inverse deep learning networks for medical image analysis,"Methods and apparatus for automated medical image analysis using deep learning networks are disclosed. In a method of automatically performing a medical image analysis task on a medical image of a patient, a medical image of a patient is received. The medical image is input to a trained deep neural network. An output model that provides a result of a target medical image analysis task on the input medical image is automatically estimated using the trained deep neural network. The trained deep neural network is trained in one of a discriminative adversarial network or a deep image-to-image dual inverse network.","['G06T7/0012', 'G06F18/24', 'G06K9/6267', 'G06K9/66', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/005', 'G06N7/01', 'G06T7/11', 'G06V10/82', 'G06V30/19173', 'G06K2209/05', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
US11636380B2,Method for protecting a machine learning model against extraction using an ensemble of a plurality of machine learning models,"A method for protecting a machine learning model is provided. In the method, a first machine learning model is trained, and a plurality of machine learning models derived from the first machine learning model is trained. Each of the plurality of machine learning models may be different from the first machine learning model. During inference operation, a first input sample is provided to the first machine learning model and to each of the plurality of machine learning models. The first machine learning model generates a first output and the plurality of machine learning models generates a plurality of second outputs. The plurality of second outputs are aggregated to determine a final output. The final output and the first output are classified to determine if the first input sample is an adversarial input. If it is adversarial input, a randomly generated output is provided instead of the first output.","['G06N20/00', 'G06N20/20', 'G06F21/554', 'G06F7/582', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/045']"
US20220036199A1,System and method for predictive foliage impingement and wildfire management using generative adversarial network,"An exemplary system and method are disclosed for identifying anomalies relating to distribution power line disturbances and faults indicative of foliage impingement and potential equipment failure. The exemplary system and method employ neural network-based models such as generative adversarial networks models that can continuously monitor for electrical-signal anomalies to locate faults, predict power outages and safety hazards, thereby reducing the likelihood of wildfires. The exemplary system and method can beneficially learn and update its neural network models in a continuous and unsupervised manner using a live stream of sensor inputs.","['G06N3/088', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/084', 'G06N7/01']"
US11675896B2,Using multimodal model consistency to detect adversarial attacks,"A method, apparatus and computer program product to defend learning models that are vulnerable to adversarial example attack. It is assumed that data (a “dataset”) is available in multiple modalities (e.g., text and images, audio and images in video, etc.). The defense approach herein is premised on the recognition that the correlations between the different modalities for the same entity can be exploited to defend against such attacks, as it is not realistic for an adversary to attack multiple modalities. To this end, according to this technique, adversarial samples are identified and rejected if the features from one (the attacked) modality are determined to be sufficiently far away from those of another un-attacked modality for the same entity. In other words, the approach herein leverages the consistency between multiple modalities in the data to defend against adversarial attacks on one modality.","['G06F21/52', 'G06F21/554', 'G06F21/54', 'G06F21/64', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06F2221/033', 'G06N3/048']"
US10643602B2,Adversarial teacher-student learning for unsupervised domain adaptation,"Methods, systems, and computer programs are presented for training, with adversarial constraints, a student model for speech recognition based on a teacher model. One method includes operations for training a teacher model based on teacher speech data, initializing a student model with parameters obtained from the teacher model, and training the student model with adversarial teacher-student learning based on the teacher speech data and student speech data. Training the student model with adversarial teacher-student learning further includes minimizing a teacher-student loss that measures a divergence of outputs between the teacher model and the student model; minimizing a classifier condition loss with respect to parameters of a condition classifier; and maximizing the classifier condition loss with respect to parameters of a feature extractor. The classifier condition loss measures errors caused by acoustic condition classification. Further, speech is recognized with the trained student model.","['G10L15/063', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/044', 'G06N7/01', 'G10L15/02', 'G10L15/16']"
WO2021164334A1,"Adversarial attack model training method and apparatus, adversarial image generation method and apparatus, electronic device, and storage medium","An adversarial attack model training method and apparatus, an adversarial image generation method and apparatus, an electronic device, and a storage medium. An adversarial attack model comprises a generator network (201, 301). The training method comprises: generating an adversarial attack image by using the generator network (201, 301) on the basis of a training digital image (S41); performing adversarial attack on a target model on the basis of the adversarial attack image, and obtaining an adversarial attack result (S43); obtaining a physical image corresponding to the training digital image (S45); and training the generator network on the basis of the training digital image, the adversarial attack image, the adversarial attack result, and the physical image (S47).","['G06N3/08', 'H04L63/1416', 'G06F21/566', 'G06N20/00', 'G06V10/24', 'G06V10/28', 'G06V10/77', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V2201/07', 'H04L63/1433']"
US12214801B2,Generating autonomous vehicle testing data through perturbations and adversarial loss functions,"Techniques for generating testing data for an autonomous vehicle (AV) are described herein. A system can obtain sensor data descriptive of a traffic scenario. The traffic scenario can include a subject vehicle and actors in an environment. Additionally, the system can generate a perturbed trajectory for a first actor in the environment based on perturbation values. Moreover, the system can generate simulated sensor data. The simulated sensor data can include data descriptive of the perturbed trajectory for the first actor in the environment. Furthermore, the system can provide the simulated sensor data as input to an AV control system. The AV control system can be configured to process the simulated sensor data to generate an updated trajectory for the subject vehicle in the environment. Subsequently, the system can evaluate an adversarial loss function based on the updated trajectory for the subject vehicle to generate an adversarial loss value.","['B60W60/0011', 'G06N3/006', 'B60W60/0013', 'B60W60/00276', 'G06N20/00', 'G06N3/08', 'G06N3/086', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/126', 'G06N7/01', 'B60W2420/408']"
US11669746B2,System and method for active machine learning,An electronic device for active learning includes at least one memory and at least one processor coupled to the at least one memory. The at least one processor is configured to select one or more entries from a data set including unlabeled data based on a similarity between the one or more entries and labeled data. The at least one processor is further configured to cause the one or more entries to be labeled.,"['G06N3/088', 'G06F18/213', 'G06F18/214', 'G06F18/22', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V20/70']"
US10997464B2,Digital image layout training using wireframe rendering within a generative adversarial network (GAN) system,"Digital image layout training is described using wireframe rendering within a generative adversarial network (GAN) system. A GAN system is employed to train the generator module to refine digital image layouts. To do so, a wireframe rendering discriminator module rasterizes a refined digital training digital image layout received from a generator module into a wireframe digital image layout. The wireframe digital image layout is then compared with at least one ground truth digital image layout using a loss function as part of machine learning by the wireframe discriminator module. The generator module is then trained by backpropagating a result of the comparison.","['G06K9/6257', 'G06T11/60', 'G06F18/2148', 'G06F18/241', 'G06F18/28', 'G06K9/6202', 'G06K9/6255', 'G06K9/6268', 'G06V10/82', 'G06V30/19147', 'G06V30/19173', 'G06K9/726', 'G06T9/001', 'G06T9/002', 'G06V30/274']"
CN114861762A,"Information processing method and device, storage medium and vehicle-mounted electronic controller","The invention discloses an information processing method, an information processing device, a storage medium and a vehicle-mounted electronic controller; knowledge of the vehicle in normal running is combined into a generation countermeasure network, so that a sample generated by a generator is an offensive abnormal sample certainly, and the generated sample is a sample which is most likely to make mistakes in detection of the existing machine learning model, the effect of training the existing machine learning model is improved, and the generalization capability is improved; correspondingly, the invention also discloses corresponding device, medium and other related product embodiments, and the technical performance of related products or devices is improved by adopting the same or corresponding technical scheme.","['G06F18/214', 'G06F21/55', 'G06N20/00', 'Y02D30/70']"
US20240054233A1,"Device, System, and Method for Protecting Machine Learning (ML) Units, Artificial Intelligence (AI) Units, Large Language Model (LLM) Units, and Deep Learning (DL) Units","Systems and methods for protecting machine learning engines, artificial intelligence engines, large language models, and deep learning engines. An Offline Protection Unit is configured to analyze one or more characteristics of a Protected Engine, and to perform offline fortification of the Protected Engine against attacks by changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks. An Online Protection Unit is configured to perform analysis of at least one of: (i) inputs that are directed to be inputs of the Protected Engine, (ii) outputs that are generated by the Protected Engine; and based on the analysis, to dynamically perform online fortification of the Protected Engine against attacks by dynamically changing operational properties or operational parameters of the Protected Engine to reduce its vulnerability to attacks.","['G06F21/577', 'G06F21/54', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06N3/094', 'G06F2221/032', 'G06N20/20', 'G06N3/126', 'G06N5/01']"
US11992702B2,Machine learning optimization of fluence maps for radiotherapy treatment,"Systems and methods are disclosed for generating fluence maps for a radiotherapy treatment plan that uses machine learning prediction. The systems and methods include identifying image data that indicates treatment constraints for target dose areas and organs at risk areas in an anatomy of the subject, generating anatomy projection images that represent a view of the subject from respective beam angles, using a trained neural network model to generate the computer-simulated fluence map representations based on the anatomy projection images, where the fluence maps indicate a fluence distribution of the radiotherapy treatment at each of the beam angles.","['A61N5/103', 'A61N5/1031', 'A61N5/1038', 'A61N5/1045', 'A61N5/1081', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G16H20/40', 'G16H30/40', 'G16H50/20']"
US10535120B2,Adversarial learning of privacy protection layers for image recognition services,"Mechanisms are provided to implement an adversarial network framework. Using an adversarial training technique, an image obfuscation engine operating as a generator in the adversarial network framework is trained to determine a privacy protection layer to be applied by the image obfuscation engine to input image data. The image obfuscation engine applies the determined privacy protection layer to an input image captured by an image capture device to generate obfuscated image data. The obfuscated image data is transmitted to a remotely located image recognition service, via at least one data network, for performance of image recognition operations.","['G06N3/088', 'G06T5/002', 'G06F18/217', 'G06F18/22', 'G06F18/24143', 'G06F18/2431', 'G06K9/00979', 'G06K9/6215', 'G06K9/628', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T5/70', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V10/95', 'G06V20/52', 'G06K2209/27', 'G06N3/044', 'G06N7/01', 'G06T2207/20081', 'G06T2207/30232', 'G06V2201/10']"
US11836249B2,System and method for counteracting adversarial attacks,"Aspects of the present disclosure involve systems, methods, devices, and the like for generating an adversarially resistant model. In one embodiment, a novel architecture is presented that enables the identification of an image that has been adversarially attacked. The system and method used in the identification introduce the use of a denoising module used to reconstruct the original image from the modified image received. Then, further to the reconstruction, an adversarially trained model is used to make a prediction using at least a determination of a loss that may exist between the original image and the denoised image.","['G06F21/64', 'G06F21/554', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06T1/005']"
US11710300B2,Computing systems with modularized infrastructure for training generative adversarial networks,"Computing systems that provide a modularized infrastructure for training Generative Adversarial Networks (GANs) are provided herein. For example, the modularized infrastructure can include a lightweight library designed to make it easy to train and evaluate GANs. A user can interact with and/or build upon the modularized infrastructure to easily train GANs. The modularized infrastructure can include a number of distinct sets of code that handle various stages of and operations within the GAN training process. The sets of code can be modular. That is, the sets of code can be designed to exist independently yet be easily and intuitively combinable. Thus, the user can employ some or all of the sets of code or can replace a certain set of code with a set of custom-code while still generating a workable combination.","['G06V10/82', 'G06F18/2414', 'G06F18/40', 'G06F9/448', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06N3/082']"
US11049239B2,Deep neural network based identification of realistic synthetic images generated using a generative adversarial network,"Techniques are provided for deep neural network (DNN) identification of realistic synthetic images generated using a generative adversarial network (GAN). According to an embodiment, a system is described that can comprise a memory that stores computer executable components and a processor that executes the computer executable components stored in the memory. The computer executable components can comprise, a first extraction component that extracts a subset of synthetic images classified as non-real like as opposed to real-like, wherein the subset of synthetic images were generated using a GAN model. The computer executable components can further comprise a training component that employs the subset of synthetic images and real images to train a DNN network model to classify synthetic images generated using the GAN model as either real-like or non-real like.","['G16H50/20', 'G06F18/214', 'G06F18/241', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06T7/0012', 'G06V10/772', 'G06V10/774', 'G06V10/7784', 'G06V10/82', 'G16H30/40', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20221', 'G06T2207/30068', 'G06V2201/03']"
US20230081346A1,Generating realistic synthetic data with adversarial nets,"A generative network may be learned in an adversarial setting with a goal of modifying synthetic data such that a discriminative network may not be able to reliably tell the difference between refined synthetic data and real data. The generative network and discriminative network may work together to learn how to produce more realistic synthetic data with reduced computational cost. The generative network may iteratively learn a function that synthetic data with a goal of generating refined synthetic data that is more difficult for the discriminative network to differentiate from real data, while the discriminative network may be configured to iteratively learn a function that classifies data as either synthetic or real. Over multiple iterations, the generative network may learn to refine the synthetic data to produce refined synthetic data on which other machine learning models may be trained.","['G06N3/045', 'G06V10/774', 'G06N3/0454', 'G06N3/0455', 'G06N3/08', 'G06N3/094', 'G06V10/82', 'G06V40/113', 'G06F18/217', 'G06F18/24', 'G06F18/28', 'G06K9/6255', 'G06N3/0464']"
US11686848B2,Systems and methods for training object detection models using adversarial examples,"Systems and methods for training object detection models using adversarial examples are provided. A method includes obtaining a training scene and identifying a target object within the training scene. The method includes obtaining an adversarial object and generating a modified training scene based on the adversarial object, the target object, and the training scene. The modified training scene includes the training scene modified to include the adversarial object placed on the target object. The modified training scene is input to a machine-learned model configured to detect the training object. A detection score is determined based on whether the training object is detected, and the machine-learned model and the parameters of the adversarial object are trained based on the detection output. The machine-learned model is trained to maximize the detection output. The parameters of the adversarial object are trained to minimize the detection output.","['G01S17/89', 'G01S17/42', 'G01S17/894', 'G01S17/931', 'G06F18/214', 'G06F18/217', 'G06N20/00', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06V20/64', 'G06V2201/07', 'G06V2201/08']"
US11896847B2,Adversarial prediction of radiotherapy treatment plans,"Systems and methods are disclosed for generating radiotherapy treatment machine parameters based on projection images of a target anatomy. The systems and methods include operations including receiving a set of pairs of image data for each gantry angle of a radiotherapy treatment machine, wherein each pair of the set of pairs comprises a given projection image that represents a view of an anatomy of a subject from a given gantry angle and a given graphical aperture image of multi-leaf collimator (MLC) leaf positions at the given gantry angle based on the given projection image; training a generative adversarial network (GAN) model based on the set of pairs of image data for each gantry angle; and using the trained GAN model to predict an aperture image of MLC leaf positions for a desired gantry angle based on a projection image that represents a view of an anatomical region of interest.","['A61N5/1047', 'A61N5/103', 'A61N5/1031', 'A61N5/1039', 'A61N5/1067', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G16H20/40', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084']"
US11763093B2,Systems and methods for a privacy preserving text representation learning framework,Various embodiments of a computer-implemented system which learns textual representations while filtering out potentially personally identifying data and retaining semantic meaning within the textual representations are disclosed herein.,"['G06F40/30', 'G06F18/21322', 'G06F21/6245', 'G06F21/6254', 'G06F40/211', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06F18/21326', 'G06N3/047']"
US10944767B2,Identifying artificial artifacts in input data to detect adversarial attacks,"Mechanisms are provided for training a classifier to identify adversarial input data. A neural network processes original input data representing a plurality of non-adversarial original input data and mean output learning logic determines a mean response for each intermediate layer of the neural network based on results of processing the original input data. The neural network processes adversarial input data and layer-wise comparison logic compares, for each intermediate layer of the neural network, a response generated by the intermediate layer based on processing the adversarial input data, to the mean response associated with the intermediate layer, to thereby generate a distance metric for the intermediate layer. The layer-wise comparison logic generates a vector output based on the distance metrics that is used to train a classifier to identify adversarial input data based on responses generated by intermediate layers of the neural network.","['H04L63/1416', 'G06F21/566', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09']"
US10671735B2,Framework for security strength and performance analysis of machine learning based biometric systems,A framework for measuring the security strength of bio-metric security systems against spoofing attacks considering the adversary's knowledge about the system is disclosed.,"['G06F21/577', 'G06F21/32', 'G06F21/46', 'G06N20/00', 'G06N20/10', 'G06N3/02', 'G06N5/003', 'G06N5/01', 'G06N7/005', 'G06N7/01', 'G06F2221/034']"
US12299583B2,Systems and methods for expanding data classification using synthetic data generation in machine learning models,"Systems and methods for classifying data are disclosed. For example, a system may include at least one memory storing instructions and at least one processor configured to execute the instructions to perform operations. The operations may include receiving training data comprising a class. The operations may include training a data classification model using the training data to generate a trained data classification model. The operations may include receiving additional data comprising labeled samples of an additional class not contained in the training data. The operations may include creating a synthetic data generator. The operations may include training the synthetic data generator to generate synthetic data corresponding to the additional class. The operations may include generating a synthetic classified dataset comprising the additional class. The operations may include retraining the trained data classification model using the synthetic classified dataset.","['G06N3/08', 'G06N3/088', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/0985']"
US20230075100A1,Adversarial autoencoder architecture for methods of graph to sequence models,"A graph-to-sequence (G2S) architecture is configured to use graph data of objects to generate sequence data of new objects. The process can be used with objects types that can be represented as graph data and sequence data. For instance, such data is molecular data, where each molecule can be represented as molecular graph and in SMILES. Examples also include popular tasks in deep learning of image-to-text or/and image-to-speech translations. Images can be naturally represented as graphs, while text and speech can be natively represented as sequences. The G2S architecture can include a graph encoder and sample generator that produce latent data in a latent space, which latent data can be conditioned with properties of the object. The latent data is input into a discriminator to obtain real or fake objects, and input into a decoder for generating the sequence data of the new objects.","['G06N3/088', 'G06N3/08', 'G06N3/006', 'G06N3/045', 'G06N3/047', 'G06N7/01', 'G16C20/70', 'G16C20/80', 'G06N3/084']"
US11645753B2,"Deep learning-based multi-site, multi-primitive segmentation for nephropathology using renal biopsy whole slide images","Embodiments discussed herein facilitate segmentation of histological primitives from stained histology of renal biopsies via deep learning and/or training deep learning model(s) to perform such segmentation. One example embodiment is configured to access a first histological image of a renal biopsy comprising a first type of histological primitives, wherein the first histological image is stained with a first type of stain; provide the first histological image to a first deep learning model trained based on the first type of histological primitive and the first type of stain; and receive a first output image from the first deep learning model, wherein the first type of histological primitives is segmented in the first output image.","['G06T7/0014', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T11/001', 'G06T3/0006', 'G06T3/02', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30084', 'G06T2207/30096', 'G06T2207/30101']"
WO2021171090A1,An artificial intelligence adversary red team,"An Al adversary red team configured to pentest email and/or network defenses implemented by a cyber threat defense system used to protect an organization and all its entities. Al model(s) trained with machine learning on contextual knowledge of the organization and configured to identify data points from the contextual knowledge including language-based data, email/network connectivity and behavior pattern data, and historic knowledgebase data. The trained Al models cooperate with an Al classifier in producing specific organization-based classifiers for the Al classifier. A phishing email generator generates automated phishing emails to pentest the defense systems, where the phishing email generator cooperates with the Al models to customize the automated phishing emails based on the identified data points of the organization and its entities. The customized phishing emails are then used to initiate one or more specific attacks on one or more specific users associated with the organization and its entities.","['G06F21/577', 'G06N20/00', 'G06N20/20', 'G06N3/049', 'G06N7/01', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433']"
US10592386B2,Fully automated machine learning system which generates and optimizes solutions given a dataset and a desired outcome,"Automated systems and methods for optimizing a model are disclosed. For example, in an embodiment, a method for optimizing a model may comprise receiving a data input that includes a desired outcome and an input dataset identifier. The method may include retrieving an input dataset based on the identifier and receiving an input model based on the desired outcome. The method may also comprise using a data synthesis model to create a synthetic dataset based on the input dataset and a similarity metric. The method may also comprise debugging the input model using synthetic dataset to create a debugged model. The method may also comprise selecting an actual dataset based on the input dataset and the desired outcome. In some aspects, the method may comprise optimizing the debugged model using the actual dataset and storing the optimized model.","['G06F11/3608', 'G06F9/541', 'G06F11/3628', 'G06F11/3636', 'G06F11/3684', 'G06F11/3688', 'G06F16/215', 'G06F16/2237', 'G06F16/2264', 'G06F16/2423', 'G06F16/24568', 'G06F16/248', 'G06F16/254', 'G06F16/258', 'G06F16/283', 'G06F16/285', 'G06F16/288', 'G06F16/335', 'G06F16/35', 'G06F16/90332', 'G06F16/90335', 'G06F16/9038', 'G06F16/906', 'G06F16/93', 'G06F17/15', 'G06F17/16', 'G06F17/18', 'G06F18/2115', 'G06F18/213', 'G06F18/214', 'G06F18/2148', 'G06F18/217', 'G06F18/2193', 'G06F18/22', 'G06F18/23', 'G06F18/24', 'G06F18/2411', 'G06F18/2415', 'G06F18/285', 'G06F18/40', 'G06F21/552', 'G06F21/60', 'G06F21/6245', 'G06F21/6254', 'G06F30/20', 'G06F40/117', 'G06F40/166', 'G06F40/20', 'G06F8/71', 'G06F9/54', 'G06F9/547', 'G06K9/036', 'G06K9/6215', 'G06K9/6218', 'G06K9/6231', 'G06K9/6232', 'G06K9/6253', 'G06K9/6256', 'G06K9/6257', 'G06K9/6262', 'G06K9/6265', 'G06K9/6267', 'G06K9/6269', 'G06K9/6277', 'G06K9/66', 'G06K9/6885', 'G06K9/72', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/06', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06N5/00', 'G06N5/01', 'G06N5/02', 'G06N5/022', 'G06N5/04', 'G06N7/00', 'G06N7/005', 'G06N7/01', 'G06Q10/04', 'G06T11/001', 'G06T7/194', 'G06T7/246', 'G06T7/248', 'G06T7/254', 'G06V10/768', 'G06V10/993', 'G06V30/194', 'G06V30/1985', 'H04L63/1416', 'H04L63/1491', 'H04L67/306', 'H04L67/34', 'H04N21/23412', 'H04N21/8153', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US12034767B2,Artificial intelligence adversary red team,"An AI adversary red team configured to pentest email and/or network defenses implemented by a cyber threat defense system used to protect an organization and all its entities. AI model(s) trained with machine learning on contextual knowledge of the organization and configured to identify data points from the contextual knowledge including language-based data, email/network connectivity and behavior pattern data, and historic knowledgebase data. The trained AI models cooperate with an AI classifier in producing specific organization-based classifiers for the AI classifier. A phishing email generator generates automated phishing emails to pentest the defense systems, where the phishing email generator cooperates with the AI models to customize the automated phishing emails based on the identified data points of the organization and its entities. The customized phishing emails are then used to initiate one or more specific attacks on one or more specific users associated with the organization and its entities.","['G06F21/577', 'G06N20/00', 'G06N5/04', 'H04L51/212', 'H04L63/1425', 'H04L63/1433', 'H04L63/1483', 'H04L63/1416']"
US11049223B2,Class-aware adversarial pulmonary nodule synthesis,Systems and methods are provided for generating a synthesized medical image patch of a nodule. An initial medical image patch and a class label associated with a nodule to be synthesized are received. The initial medical image patch has a masked portion and an unmasked portion. A synthesized medical image patch is generated using a trained generative adversarial network. The synthesized medical image patch includes the unmasked portion of the initial medical image patch and a synthesized nodule replacing the masked portion of the initial medical image patch. The synthesized nodule is synthesized according to the class label. The synthesized medical image patch is output.,"['G06T5/50', 'G06T11/00', 'G06T5/005', 'G06T5/77', 'A61B5/7267', 'A61B6/032', 'A61B6/12', 'G06F18/22', 'G06F18/24', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T7/0012', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30064']"
US12353549B2,Method and system for thwarting attacks on machine-learning as a service,"A method for thwarting attacks on a machine-learning (ML) model is provided. The method includes determining, by the ML model, a classification vector based on an input. The method further includes evaluation the classification vector based on a threshold parameter to determine a threshold result. The method also includes outputting a classification prediction based on the threshold result.","['G06F21/566', 'G06F2221/033']"
US20220026905A1,Object modeling with adversarial learning,"Methods, computer-readable media, and devices are disclosed for improving an object model based upon measurements of physical properties of an object via an unmanned vehicle using adversarial examples. For example, a method may include a processing system capturing measurements of physical properties of an object via at least one unmanned vehicle, updating an object model for the object to include the measurements of the physical properties of the object, where the object model is associated with a feature space, and generating an example from the feature space, where the example comprises an adversarial example. The processing system may further apply the object model to the example to generate a prediction, capture additional measurements of the physical properties of the object via the at least one unmanned vehicle when the prediction fails to identify that the example is an adversarial example, and update the object model to include the additional measurements.","['G06V10/82', 'B60W30/0953', 'G05D1/0088', 'G05D1/0094', 'G06F18/2413', 'G06K9/00201', 'G06K9/00791', 'G06K9/627', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N5/022', 'G06V10/764', 'G06V20/56', 'G06V20/64', 'B60W30/09', 'B64C2201/141', 'B64U2101/30', 'B64U2201/10', 'G05D1/0246', 'G06N20/10', 'G06N5/01', 'G06V20/13']"
CN108549940B,Intelligent defense algorithm recommendation method and system based on multiple adversarial example attacks,"The invention discloses an intelligent defense algorithm recommendation method based on multiple counterexample attacks, which comprises the following steps: cleaning an original data set to obtain a training set; training a target identification model by using a training set to obtain a target attack model; selecting different counterexample attack algorithms to attack a target attack model; quantitatively evaluating the attack success rate of each anti-sample attack algorithm, and selecting a target attack algorithm according to the attack success rate; aiming at each target attack algorithm, the anti-attack defense algorithm is applied one by one to carry out defense; and recommending a corresponding anti-attack defense algorithm to the user according to the defense result. The invention also discloses an intelligent defense algorithm recommendation system adopted by the intelligent defense algorithm recommendation method. Aiming at a specific target model, the intelligent defense algorithm recommendation system can intelligently recommend an effective defense algorithm, so that the loss of the target model caused by resisting sample attack is reduced.",['G06F21/554']
US10764043B2,Identity and content authentication for phone calls,"Systems and methods for call authentication are provided. A method can include an enrollment protocol that ensures users control the number they claim to own, a handshake protocol that mutually authenticates the calling parties, and a call integrity protocol that ensures the security of the voice channel and the content it carries. A server can act as either an endpoint or intermediary between user clients and client-server architecture can be employed. All protocols can include end-to-end cryptography and the enrollment protocol can issue a certificate that binds the identity of the client to a phone number.","['H04L9/0844', 'H04L65/1076', 'H04L9/3263', 'H04L9/3268', 'H04W12/04', 'H04W12/0431', 'H04W12/06', 'H04W12/069', 'H04L2209/80', 'H04L63/0823', 'H04L9/3242', 'H04W12/00409', 'H04W12/1006', 'H04W12/106', 'H04W12/48']"
US11861643B2,Reinforcement learning method for driver incentives: generative adversarial network for driver-system interactions,"A system and method of determining a policy to prevent fading drivers is described. The system and method creates virtual trajectories of incentives such as coupons offered to drivers in a transportation hailing system and corresponding states of drivers in response to the incentives. A joint policy simulator is created from an incentive policy, a confounding incentive policy, and an incentive object policy to generate the simulated actions of drivers in response to different incentives. The rewards of the simulated actions of the drivers is determined by a discriminator. The incentive policy for preventing fading drivers is optimized by reinforcement learning based on the virtual trajectories generated by the joint policy simulator and discriminator.","['G06Q50/40', 'G06Q30/0211', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06Q10/06398', 'G06Q30/0208', 'G06Q50/30', 'G06Q30/0219']"
AU2019262835B2,Radiotherapy treatment plan modeling using generative adversarial networks,"Techniques for generating radiotherapy treatment plans and establishing machine learning models for the generation and optimization of radiotherapy dose data are disclosed. An example method for generating a radiotherapy dose distribution using a generative model, trained in a generative adversarial network, includes: receiving anatomical data of a human subject that indicates a mapping of an anatomical area for radiotherapy treatment; generating radiotherapy dose data corresponding to the mapping with use of the trained generative model, as the generative model processes the anatomical data as an input and provides the dose data as output; and identifying the radiotherapy dose distribution for the radiotherapy treatment of the human subject based on the dose data. Another example method for training of the generative model includes establishing values of the generative model and a discriminative model of the generative adversarial network using adversarial training, including in a conditional generative adversarial network arrangement.","['G16H20/40', 'A61N5/1031', 'A61N5/1039', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'A61N2005/1041', 'A61N5/1038']"
US11531900B2,Imitation learning for machine learning systems with synthetic data generators,"Computer systems and methods cooperatively train multiple generators and a classifier. Cooperative training includes: training, through machine learning, the multiple generators such that each generator is trained according to a first objective to output examples of a designated classification category; training, through machine learning, the classifier to determine, for each generated by the multiple generators, which of the multiple generators generated the example; and back-propagating partial derivatives of an error cost function from the classifier to the multiple generators.","['G06N3/088', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/0499', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/0985', 'G06N7/005', 'G06N7/01', 'G06F12/0815', 'G06F17/18', 'G06N3/048', 'G06N3/0481']"
US10803347B2,Image transformation with a hybrid autoencoder and generative adversarial network machine learning architecture,An encoder artificial neural network (ANN) may be configured to receive an input image patch and produce a feature vector therefrom. The encoder ANN may have been trained with a first plurality of domain training images such that an output image patch visually resembling the input image patch can be generated from the feature vector. A generator ANN may be configured to receive the feature vector and produce a generated image patch from the first feature vector. The generator ANN may have been trained with feature vectors derived from a first plurality of domain training images and a second plurality of generative training images such that the generated image patch visually resembles the input image patch but is constructed of a newly-generated image elements visually resembling one or more image patches from the second plurality of generative training images.,"['G06V10/82', 'G06K9/6215', 'G06F16/55', 'G06F16/583', 'G06F18/22', 'G06K9/6232', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/454', 'G06V10/764']"
US20200387836A1,Machine learning model surety,"Complex computer system architectures are described for providing a machine learning model management tool that monitors, detects, and makes revisions to machine learning models to prevent declines and maintain robustness and fairness in machine learning model performance in production over time. The machine learning model management tool achieves its goals via intelligent management, organization, and orchestration of detection, inspection, and correction engines.",['G06N20/20']
US20210264568A1,Super resolution using a generative adversarial network,"A neural network is trained to process received visual data to estimate a high-resolution version of the visual data using a training dataset and reference dataset. A set of training data is generated, and a generator convolutional neural network parameterized by first weights and biases is trained by comparing characteristics of the training data to characteristics of the reference dataset. The first network is trained to generate super-resolved image data from low-resolution image data and the training includes modifying first weights and biases to optimize processed visual data based on the comparison between the characteristics of the training data and the characteristics of the reference dataset. A discriminator convolutional neural network parameterized by second weights and biases is trained by comparing characteristics of the generated super-resolved image data to characteristics of the reference dataset, and where the second network is trained to discriminate super-resolved image data from real image data.","['G06T3/4053', 'G06N3/084', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06T3/4046', 'G06T2207/20081', 'G06T2207/20084']"
RU2648573C2,Allocation of machine learning resource,FIELD: physics.,"['G06N20/00', 'G06N20/20', 'G06N7/00', 'G06N99/00']"
US12260938B2,Machine learning driven gene discovery and gene editing in plants,"The present disclosure relates to leveraging explainable machine learning methods and feature importance mechanisms as a mechanism for gene discovery and furthermore leveraging the outputs of the gene discovery to recommend ideal gene expression profiles and the requisite genome edits that are conducive to a desired phenotype. Particularly, aspects of the present disclosure are directed to obtaining gene expression profiles for a set of genes measured in a tissue sample of a plant, inputting the gene expression profiles into a prediction model constructed for a task of predicting a phenotype as output data, generating, using the prediction model, the prediction of the phenotype for the plant, analyzing, by an explainable artificial intelligence system, decisions made by the prediction model to predict the phenotype, and identifying a set of candidate gene targets for the phenotype as having a largest contribution or influence on the prediction based on the analyzing.","['G16B25/10', 'G16B40/00', 'G06N20/10', 'G06N3/048', 'G06N3/084', 'G06N7/01', 'G06N7/02', 'G16B20/00', 'G16B20/50', 'G16B40/20', 'G16B5/20']"
US11055632B2,Method and device for improving the robustness against “adversarial examples”,"A method for generating a universal data signal interference for generating a manipulated data signal for deceiving a first machine learning system, which is configured to ascertain a semantic segmentation of a received one-dimensional or multidimensional data signal, The method includes a) ascertaining a training data set that includes pairs of data signals and associated desired semantic segmentations, b) generating the data signal interference, as a function of the data signals of the training data set, of the associated desired semantic segmentation, as well as of estimated semantic segmentations of the data signals acted upon by the data signal interference.","['G06N20/00', 'G05B15/02', 'G06N3/008', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094']"
US12322165B2,Hardened deep neural networks through training from adversarial misclassified data,"Various embodiments are generally directed to techniques for training deep neural networks, such as with an iterative approach, for instance. Some embodiments are particularly directed to a deep neural network (DNN) training system that generates a hardened DNN by iteratively training DNNs with images that were misclassified by previous iterations of the DNN. One or more embodiments, for example, may include logic to generate an adversarial image that is misclassified by a first DNN that was previously trained with a set of sample images. In some embodiments, the logic may determine a second training set that includes the adversarial image that was misclassified by the first DNN and the first training set of one or more sample images. The second training set may be used to train a second DNN. In various embodiments, the above process may be repeated for a predetermined number of iterations to produce a hardened DNN.","['G06V10/82', 'G06F18/217', 'G06F18/24143', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/086', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/776']"
US20210342669A1,"Method, system, and medium for processing satellite orbital information using a generative adversarial network","Method, electronic device, system, and computer-readable medium embodiments are disclosed. Some embodiments include a signal processing workflow incorporating a graphical user interface for displaying orbital information for satellites and other spacecraft. In some embodiments, a generative adversarial network (GAN) is employed for evaluating satellite orbital positions, for predicting future orbital movements, for detecting orbital maneuvers of a satellite, and for analyzing such maneuvers for potential nefarious intent.","['G06N3/0454', 'G01V3/38', 'G01V3/16', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084']"
US10824122B2,Method and device for improving the robustness with respect to “adversarial examples”,"A method for generating a manipulated data signal for misleading a first machine learning system, which is designed to ascertain a semantic segmentation of a received one-dimensional or multi-dimensional data signal, the method having the following steps: a) ascertaining a desired semantic segmentation of the manipulated data signal; and b) generating the manipulated signal as a function of the received data signal and the ascertained desired semantic segmentation as well as an estimated semantic segmentation of the manipulated data signal.","['G06N20/00', 'G05B13/027', 'G05B13/044', 'G06F17/18', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T7/10']"
US12393847B2,Gradient adversarial training of neural networks,"Systems and methods for gradient adversarial training of a neural network are disclosed. In one aspect of gradient adversarial training, an auxiliary neural network can be trained to classify a gradient tensor that is evaluated during backpropagation in a main neural network that provides a desired task output. The main neural network can serve as an adversary to the auxiliary network in addition to a standard task-based training procedure. The auxiliary neural network can pass an adversarial gradient signal back to the main neural network, which can use this signal to regularize the weight tensors in the main neural network. Gradient adversarial training of the neural network can provide improved gradient tensors in the main network. Gradient adversarial techniques can be used to train multitask networks, knowledge distillation networks, and adversarial defense networks.","['G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/048', 'G06N3/082']"
US20240338803A1,Methods and systems for using trained generative adversarial networks to impute 3d data for vehicles and transportation,"A method includes receiving a navigation data set; generating a combined data set using a trained generative adversarial network; and generating a high resolution map that includes spatial data. A computing system includes: one or more processors, and one or more memories having stored thereon computer-executable instructions that, when executed, cause the computing system to: receive a navigation data set; generate a combined data set using a trained generative adversarial network; and generate a high resolution map that includes spatial data. A non-transitory computer-readable medium includes computer-executable instructions that, when executed, cause a computer to: receive a navigation data set; generate a combined data set using a trained generative adversarial network; and generate a high resolution map that includes spatial data.","['G06N3/045', 'G06N3/088', 'G06T5/60', 'G06T5/77', 'G06T7/579', 'G06N3/084', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10032', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30184']"
US12147577B2,Interpretability framework for differentially private deep learning,"Data is received that specifies a bound for an adversarial posterior belief ρc that corresponds to a likelihood to re-identify data points from the dataset based on a differentially private function output. Privacy parameters ε, δ are then calculated based on the received data that govern a differential privacy (DP) algorithm to be applied to a function to be evaluated over a dataset. The calculating is based on a ratio of probabilities distributions of different observations, which are bound by the posterior belief ρc as applied to a dataset. The calculated privacy parameters are then used to apply the DP algorithm to the function over the dataset. Related apparatus, systems, techniques and articles are also described.","['G06F21/6245', 'G06F21/6254', 'G06F17/18', 'G06F18/2148', 'G06F18/2413', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/09']"
US20230044102A1,Ensemble machine learning models incorporating a model trust factor,"Methods for improving the prediction accuracy for an ensemble machine learning model are described. In some instances, the methods comprise: (i) receiving data characterizing levels of trust in one or more machine learning models that form the ensemble machine learning model; (ii) calculating a prediction error estimate for each of the one or more machine learning models based on a trust score for that machine learning model and relative weights calculated for the data points in a training data set used to train that machine learning model; (iii) calculating a normalized weight for each of the one or more machine learning models using the prediction error estimate calculated for each; and (iv) adjusting an output prediction equation for the ensemble machine learning model, where the adjustment is based, at least in part, on the normalized weights calculated in for each of the one or more machine learning models.","['G06N20/20', 'G06N20/10', 'G06N3/08', 'G06N5/01']"
US12333688B2,Denoising diffusion generative adversarial networks,"Apparatuses, systems, and techniques are presented to train and utilize one or more neural networks. A denoising diffusion generative adversarial network (denoising diffusion GAN) reduces a number of denoising steps during a reverse process. The denoising diffusion GAN does not assume a Gaussian distribution for large steps of the denoising process and applies a multi-model model to permit denoising with fewer steps. Systems and methods further minimize a divergence between a diffused real data distribution and a diffused generator distribution over several timesteps. Accordingly, various embodiments may enable faster sample generation, in which the samples are generated from noise using the denoising diffusion GAN.","['G06T5/70', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
US10937540B2,Medical image classification based on a generative adversarial network trained discriminator,"Mechanisms are provided to implement a generative adversarial network (GAN). A discriminator of the GAN is configured to discriminate input medical images into a plurality of classes including a first class indicating a medical image representing a normal medical condition, a second class indicating an abnormal medical condition, and a third class indicating a generated medical image. A generator of the GAN generates medical images and a training medical image set is input to the discriminator that includes labeled medical images, unlabeled medical images, and generated medical images. The discriminator is trained to classify training medical images in the training medical image set into corresponding ones of the first, second, and third classes. The trained discriminator is applied to a new medical image to classify the new medical image into a corresponding one of the first class or second class. The new medical image is either labeled or unlabeled.","['G06V10/82', 'G06F18/214', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06V10/764', 'G06V10/7753', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/03']"
US20200265219A1,Disentangled representation learning generative adversarial network for pose-invariant face recognition,"A system and method for identifying a subject using imaging are provided. In some aspects, the method includes receiving an image depicting a subject to be identified, and applying a trained Disentangled Representation learning-Generative Adversarial Network (DR-GAN) to the image to generate an identity representation of the subject, wherein the DR-GAN comprises a discriminator and a generator having at least one of an encoder and a decoder. The method also includes identifying the subject using the identity representation, and generating a report indicative of the subject identified.","['G06K9/00288', 'G06V40/172', 'G06F18/214', 'G06K9/00248', 'G06K9/00268', 'G06K9/6256', 'G06N20/00', 'G06V10/242', 'G06V40/165', 'G06V40/168']"
US10540578B2,Adapting a generative adversarial network to new data sources for image classification,"Mechanisms are provided to implement a generative adversarial network (GAN) that is trained based on labeled image data, unlabeled image data, and generated image data generated by a generator of the GAN. The GAN comprises a loss function that comprises error components for each of the labeled image data, unlabeled image data, and generated image data which is used to train the GAN. A new data source for which the trained GAN is to be adapted is identified and the trained GAN is adapted for the new data source. Image data in the new data source is classified by applying the adapted GAN to the data in the new data source. Adapting the trained GAN includes obtaining a minimized set of labeled images and utilizing the minimized set of images to perform the adapting of the trained GAN.","['G06K9/66', 'G06V10/82', 'G06F18/24', 'G06F18/2413', 'G06K9/6267', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/094', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G16H30/20', 'G16H30/40', 'G16H50/70', 'G06V2201/03']"
US11501438B2,Cone-beam CT image enhancement using generative adversarial networks,"Techniques for generating an enhanced cone-beam computed tomography (CBCT) image using a trained model are provided. A CBCT image of a subject is received. a synthetic computed tomography (sCT) image corresponding to the CBCT image is generated, using a generative model. The generative model is trained in a generative adversarial network (GAN). The generative model is further trained to process the CBCT image as an input and provide the sCT image as an output. The sCT image is presented for medical analysis of the subject.","['G06T11/008', 'G06T7/0014', 'G06F17/18', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US11902413B2,Secure machine learning analytics using homomorphic encryption,"Provided are methods and systems for performing a secure machine learning analysis over an instance of data. An example method includes acquiring, by a client, a homomorphic encryption scheme, and at least one machine learning model data structure. The method further includes generating, using the encryption scheme, at least one homomorphically encrypted data structure, and sending the encrypted data structure to at least one server. The method includes executing a machine learning model, by the at least one server based on the encrypted data structure to obtain an encrypted result. The method further includes sending, by the server, the encrypted result to the client where the encrypted result is decrypted. The machine learning model includes neural networks and decision trees.","['H04L9/008', 'G06N20/00', 'G06N20/10', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N5/01', 'H04L9/3242', 'H04L2209/46', 'H04L2209/88']"
US11610085B2,Prototype-based machine learning reasoning interpretation,"In some examples, a prototype model that includes a representative subset of data points (e.g., inputs and output classifications) of a machine learning model is analyzed to efficiently interpret the machine learning model's behavior. Performance metrics such as a critic fraction, local explanation scores, and global explanation scores are determined. A local explanation score capture an importance of a feature of a test point to the machine learning model determining a particular class for the test point and is computed by comparing a value of a feature of a test point to values for prototypes of the prototype model. Using a similar approach, global explanation scores may be computed for features by combining local explanation scores for data points. A critic fraction may be computed to quantify a misclassification rate of the prototype model, indicating the interpretability of the model.","['G06K9/6276', 'G06F11/302', 'G06F11/3006', 'G06F11/3072', 'G06F11/3086', 'G06F11/3409', 'G06F11/3447', 'G06F18/2113', 'G06F18/2413', 'G06F18/24147', 'G06N20/00', 'G06F11/3068', 'G06F2218/12', 'G06N5/045']"
CN111291828B,HRRP (high-resolution redundancy protocol) anti-sample black box attack method based on deep learning,"The invention belongs to the field of radar image recognition, and discloses a method for resisting sample black box attack by HRRP based on deep learning. Comprising the following steps: 1. the surrogate model is selected for generating the universal tamper with/without targets and obtaining a challenge sample. Firstly, selecting a deep neural network model as a substitute model for training, and taking the deep neural network model as a classifier of the HRRP; then, generating general countermeasure disturbance for the data set by adopting a method for generating the general countermeasure disturbance with/without targets; the perturbation is then added to each of the original samples of the data set separately, resulting in a target challenge/challenge sample. 2. And generating a black box model against sample attack by using the substitution model. First, the black box model is trained. And then, carrying out the attack on the black box model by the countermeasure sample obtained in the step one. The method can effectively improve the safety of radar target identification, provides thought and help for the generation mechanism and the defense method of the countermeasure sample, and has important practical application value.","['G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V2201/07']"
US11464491B2,Shape-based generative adversarial network for segmentation in medical imaging,"For segmentation in medical imaging, a shape generative adversarial network (shape GAN) is used in training. By including shape information in a lower dimensional space than the pixels or voxels of the image space, the network may be trained with a shape loss or optimization. The adversarial loss and the shape loss are used to train the network, so the resulting generator may segment complex shapes in 2D or 3D. Other optimization may be used, such as using a loss in image space.","['G06T7/11', 'G06T11/003', 'A61B8/5215', 'G06F18/2135', 'G06F18/22', 'G06F18/24', 'G06K9/6215', 'G06K9/6247', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06T7/10', 'G06T7/60', 'G16H30/40', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084']"
US10719742B2,Image composites using a generative adversarial neural network,"The present disclosure relates to an image composite system that employs a generative adversarial network to generate realistic composite images. For example, in one or more embodiments, the image composite system trains a geometric prediction neural network using an adversarial discrimination neural network to learn warp parameters that provide correct geometric alignment of foreground objects with respect to a background image. Once trained, the determined warp parameters provide realistic geometric corrections to foreground objects such that the warped foreground objects appear to blend into background images naturally when composited together.","['G06T11/00', 'G06K9/66', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06V20/20', 'G06V30/19173']"
CN113297572B,Deep learning sample-level anti-attack defense method and device based on neuron activation mode,"The invention discloses a deep learning sample-level anti-attack defense method and a device thereof based on a neuron activation mode, wherein the method comprises the following steps: constructing a deep learning model for target identification, wherein the deep learning model comprises a convolution layer, a pooling layer and a classification layer; extracting a characteristic diagram from a network layer of the deep learning model to construct a neuron activation mode, wherein the neuron activation mode and a cross entropy function form a loss function; when the normal image sample is used for training the deep learning model, parameters of the deep learning model are optimized by the constructed loss function; obtaining pixel increment according to the gradient of the loss function as the disturbance of defending against attack; when the target recognition is carried out by using the parameter-optimized deep learning model, the image to be recognized is input to the deep learning model after disturbance is added, and a target recognition result is obtained through calculation. The method can effectively defend against various counterattacks, and does not influence the accuracy of normal samples.","['G06F21/55', 'G06F18/241', 'G06N3/045', 'G06N3/084']"
US10841323B2,Detecting robotic internet activity across domains utilizing one-class and domain adaptation machine-learning models,"Methods, systems, and non-transitory computer readable storage media are disclosed for detecting robotic activity while monitoring Internet traffic across a plurality of domains. For example, the disclosed system identifies network session data for each domain of a plurality of domains, the network session data including network sessions comprising features that indicate human activity. In one or more embodiments, the disclosed system generates a classifier to output a probability that a network session at a domain includes human activity. In one or more embodiments, the disclosed system also generates a classifier to output a probability that a network session includes good robotic activity. Additionally, the disclosed system generates a domain-agnostic machine-learning model by combining models from a plurality of domains with network sessions including human activity.","['H04L41/16', 'H04L43/16', 'H04L63/1425', 'H04L63/1458', 'H04L43/0817']"
US10846407B1,Machine learning model robustness characterization,"Robustness of a machine learning model can be characterized by receiving a file with a known, first classification by the machine learning model. Thereafter, a selection is made as to which of a plurality of perturbation algorithms to use to modify the file. The perturbation algorithm is selected as to provide a shortest sequence of actions to cause the machine learning model to provide a desired classification. Subsequently, the received file is iteratively modified using the selected perturbation algorithm and inputting the corresponding modified file into the machine learning model until the machine learning model outputs a known, second classification. Related apparatus, systems, techniques and articles are also described.","['G06F21/566', 'G06N3/006', 'G06F21/53', 'G06N20/00', 'G06N7/005', 'G06N7/01', 'G06F2221/033', 'G06N5/045']"
US20190370969A1,"Methods for generating synthetic training data and for training deep learning algorithms for tumor lesion characterization, method and system for tumor lesion characterization, computer program and electronically readable storage medium","A method is for generating synthetic training data and for training deep learning algorithms for tumor lesion characterization. In an embodiment, the method for generating synthetic training data for training a deep learning algorithm includes training a Generative Adversarial Network to generate synthetic image data, the Generative Adversarial Network including a generator and a discriminator; and using the generator of the Generative Adversarial Network to generate synthetic image data as the synthetic training data.","['G06T7/0014', 'G06N3/084', 'G06N3/045', 'G06N3/047', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US11087864B2,"Systems and methods for automatically tagging concepts to, and generating text reports for, medical images based on machine learning",A system for assigning concepts to a medical image includes a visual feature module and a tagging module. The visual feature module is configured to obtain an image feature vector from the medical image. The tagging module is configured to apply a machine-learned algorithm to the image feature vector to assign a set of concepts to the image. The system may also include a text report generator that is configured to generate a written report describing the medical image based on the set of concepts assigned to the medical image.,"['G16H50/20', 'G06F16/36', 'G06F18/211', 'G06F18/2136', 'G06F40/284', 'G06K9/46', 'G06K9/6228', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'G06T7/0012', 'G06V10/82', 'G16B40/00', 'G16H10/60', 'G16H15/00', 'G16H20/10', 'G16H30/40', 'G16H70/60', 'H04L67/104', 'G06F18/2431', 'G06K2209/05', 'G06K9/628', 'G06K9/726', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03', 'G06V30/274', 'G16B50/00', 'G16H50/70', 'Y02A90/10']"
US10586310B2,Denoising Monte Carlo renderings using generative adversarial neural networks,"Supervised machine learning using neural networks is applied to denoising images rendered by MC path tracing. Specialization of neural networks may be achieved by using a modular design that allows reusing trained components in different networks and facilitates easy debugging and incremental building of complex structures. Specialization may also be achieved by using progressive neural networks. In some embodiments, training of a neural-network based denoiser may use importance sampling, where more challenging patches or patches including areas of particular interests within a training dataset are selected with higher probabilities than others. In some other embodiments, generative adversarial networks (GANs) may be used for training a machine-learning based denoiser as an alternative to using pre-defined loss functions.","['G06T5/002', 'G06T5/70', 'G06F18/2113', 'G06F18/2148', 'G06F18/2413', 'G06K9/4628', 'G06K9/623', 'G06K9/6257', 'G06K9/627', 'G06K9/6298', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06V10/454', 'G06V10/72', 'G06V10/764', 'G06V10/7747', 'G06V10/82', 'G06T15/06', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20192', 'G06T2207/30168', 'G06T2207/30201', 'G06T7/90']"
US20230325667A1,Robustness against manipulations in machine learning,"A method comprising: receiving observed data points each comprising a vector of feature values, wherein for each data point, the respective feature values are values of different features of a feature vector. Each observed data point represents a respective observation of a ground truth as observed in the form of the respective values of the feature vector. The method further comprises learning parameters of a machine-learning model based on the observed data points. The machine-learning model comprises one or more statistical models arranged to model a causal relationship between the feature vector and a latent vector, a classification, and a manipulation vector. The manipulation vector represents an effect of potential manipulations occurring between the ground truth and the observation thereof as observed via the feature vector. The learning comprises learning parameters of the one or more statistical models to map between the feature vector, latent vector, classification and manipulation vector.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N7/023', 'G06N3/048', 'G06T2207/20081', 'G06V10/811', 'G06V10/82']"
CA3089037C,Detecting duplicated questions using reverse gradient adversarial domain adaptation,"Detect duplicated questions using reverse gradient adversarial domain adaptation includes applying a general network to multiple general question pairs to obtain a first set of losses, A target domain network is applied to multiple domain specific network pairs to obtain a second set of losses. Further, a domain distinguishing network is applied to a set of domain specific questions and a set of general questions to obtain a third set of losses. A set of accumulated gradients is calculated from the first set of losses, the second set of losses, and the third set of losses. Multiple features are updated according to the set of accumulated gradients to train the target domain network.","['G06F16/215', 'G06F16/2455', 'G06F16/285']"
US11422217B2,Progressive generative adversarial network in medical image reconstruction,"For reconstruction in medical imaging, such as reconstruction in MR imaging, a high-resolution image is reconstructed using a generator of a progressive generative adversarial network (PGAN or progressive GAN). In machine training the network, both the generator and discriminator of the GAN are grown progressively: starting from a low resolution, new layers are added that model finer details as training progresses. The resulting generator may be better able to handle high-resolution information than a generator of a GAN.","['G01R33/54', 'G01R33/5608', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T11/008', 'G06T15/08', 'G06T2211/424', 'G16H30/40']"
US12067646B2,Cross-modal contrastive learning for text-to-image generation based on machine learning models,"A computer-implemented method includes receiving, by a computing device, a particular textual description of a scene. The method also includes applying a neural network for text-to-image generation to generate an output image rendition of the scene, the neural network having been trained to cause two image renditions associated with a same textual description to attract each other and two image renditions associated with different textual descriptions to repel each other based on mutual information between a plurality of corresponding pairs, wherein the plurality of corresponding pairs comprise an image-to-image pair and a text-to-image pair. The method further includes predicting the output image rendition of the scene.","['G06V10/82', 'G06F18/2148', 'G06F18/22', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T11/00', 'G10L15/26']"
US12326943B2,Intelligent adversary simulator,"An apparatus features processor(s) and a non-transitory storage medium including an intelligent-adversary simulator and a formatting modules. The simulator calculates path(s) of least resistance for a cyber threat in a cyber-attack scenario to compromise 1) a first virtualized instance (source device), 2) a second virtualized instance (targeted device), and 3) virtualized instances of components of a virtualized instance of a network associated with selected pathways of the cyber-attack scenario through the virtualized instance of the network. The virtualized instances may be based on historical knowledge of connectivity and behaviour patterns of users and devices within an actual network under analysis. The formatting module generates a report with identified devices that are communicatively coupled to the virtualized instance of the network and prioritized to allocate security resources. The simulator calculates the least resistance path(s) through the virtualized instance of the network and refrains from calculating every theoretically path therefrom.","['G06F21/554', 'G06F21/577', 'G06F16/953', 'G06F9/455', 'G06N20/00', 'G06N5/04', 'H04L51/212', 'H04L63/1425', 'G06Q10/107', 'H04L63/1416']"
US10985929B2,Enhanced chaincode analytics provenance in a blockchain,"A blockchain of transactions may be referenced for various purposes and may be later accessed by interested parties for ledger verification and information retrieval. One example method of operation may include one or more of storing original data in a blockchain, storing transformed data based on the original data in the blockchain, storing chaincode on the blockchain used to transform the original data to the transformed data, and retrieving a transaction from the blockchain with the transformed data and the chaincode.","['H04L9/3297', 'H04L9/3239', 'H04L9/50', 'H04L2209/38']"
US11036232B2,Iterative generation of adversarial scenarios,"A method and apparatus for generating adversarial scenarios and training an autonomous driving agent for an autonomous vehicle, using one or more sets of parameters, each set of parameters defining a respective driving scenario. A new set of parameters is generated by changing one or more parameters of one of the sets of parameters to define a new driving scenario, and performance of the autonomous driving agent is evaluated on the new driving scenario. The generating and evaluating is repeated until the autonomous driving agent fails to satisfy a predefined performance threshold for the new driving scenario. Each instance of changing the one or more parameters is based on a prior evaluated performance of the autonomous driving agent. The autonomous driving agent is trained to update a learned policy of the autonomous driving agent using at least one set of parameters, including the new set of parameters.","['G05D1/0221', 'G06N20/00', 'G05D1/0088', 'G05D1/0246', 'G05D1/0257', 'G05D1/0278', 'G06N3/006', 'G05D2201/0213']"
US10643320B2,Adversarial learning of photorealistic post-processing of simulation with privileged information,"Systems and method for generating photorealistic images include training a generative adversarial network (GAN) model by jointly learning a first generator, a first discriminator, and a set of predictors through an iterative process of optimizing a minimax objective. The first discriminator learns to determine a synthetic-to-real image from a real image. The first generator learns to generate the synthetic-to-real image from a synthetic image such that the first discriminator determines the synthetic-to-real image is real. The set of predictors learn to predict at least one of a semantic segmentation labeled data and a privileged information from the synthetic-to-real image based on at least one of a known semantic segmentation labeled data and a known privileged information corresponding to the synthetic image. Once trained, the GAN model may generate one or more photorealistic images using the trained GAN model.","['G06T5/77', 'G06T7/0002', 'G06T11/00', 'G06T5/005', 'G06T5/60', 'G06T7/149', 'G06T7/187', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
CN107909640B,Face relighting method and device based on deep learning,"The invention discloses a face relighting method and a face relighting device based on deep learning, wherein the method comprises the following steps: obtaining a face region image, a normal image and a representation illumination distribution image corresponding to the face image; processing the photo set by utilizing the camera parameter matrix, the human face three-dimensional model and the illumination model to obtain a network training data set; constructing a face relighting network by a deep learning method, wherein a network training data set is used for training to generate the face relighting network; and processing the face picture by using the camera parameter matrix, the face three-dimensional model and the illumination model, and processing an output result by using a face relighting network to obtain a face relighting result. The method can utilize a deep learning method to construct the face relighting network, utilize the face inverse relighting regular term and the face recognition network characteristic regular term to train the face relighting network, and utilize the face relighting network to relight the face, thereby effectively improving the reality and the reliability of the face relighting.","['G06T15/205', 'G06N3/08']"
US11755743B2,Protecting machine learning models from privacy attacks,This disclosure describes methods and systems for protecting machine learning models against privacy attacks. A machine learning model may be trained using a set of training data and causal relationship data. The causal relationship data may describe a subset of features in the training data that have a causal relationship with the outcome. The machine learning model may learn a function that predicts an outcome based on the training data and the causal relationship data. A predefined privacy guarantee value may be received. An amount of noise may be added to the machine learning model to make a privacy guarantee value of the machine learning model equivalent to or stronger than the predefined privacy guarantee value. The amount of noise may be added at a parameter level of the machine learning model.,"['G06F21/577', 'G06N20/00', 'G06F21/55', 'G06F21/6245', 'G06N5/04', 'G06F21/14', 'G06F2221/031', 'G06F2221/033', 'G06N5/02']"
US11842174B2,Translating between programming languages using machine learning,"Techniques are described herein for translating source code in one programming language to source code in another programming language using machine learning. In various implementations, one or more components of one or more generative adversarial networks, such as a generator machine learning model, may be trained to generate “synthetically-naturalistic” source code that can be used as a translation of source code in an unfamiliar language. In some implementations, a discriminator machine learning model may be employed to aid in training the generator machine learning model, e.g., by being trained to discriminate between human-generated (“genuine”) and machine-generated (“synthetic”) source code.","['G06F8/51', 'G06F8/41', 'G06F8/53', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/094']"
US11537880B2,System and methods for generation of synthetic data cluster vectors and refinement of machine learning models,"Embodiments of the present invention provide an improvement to conventional machine model training techniques by providing an innovative system, method and computer program product for the generation of synthetic data using an iterative process that incorporates multiple machine learning models and neural network approaches. A collaborative system for receiving data and continuously analyzing the data to determine emerging patterns is provided. The proposed invention involves generating synthetic data clusters to be stored and used for retraining the main model as well as other models. In addition, the invention includes using one or more (subset) of the synthetic data clusters to train or retrain machine learning models, developing and training machine learning models that are trained with emerging synthetic data clusters, and ensembling machine learning models trained with emerging synthetic data clusters.","['G06N3/08', 'G06F18/213', 'G06F18/214', 'G06F18/217', 'G06F18/23', 'G06F18/2413', 'G06K9/6218', 'G06K9/6232', 'G06K9/6256', 'G06K9/6262', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06Q20/4016', 'G06V10/82']"
US11531883B2,System and methods for iterative synthetic data generation and refinement of machine learning models,"Embodiments of the present invention provide an improvement to convention machine model training techniques by providing an innovative system, method and computer program product for the generation of synthetic data using an iterative process that incorporates multiple machine learning models and neural network approaches. A collaborative system for receiving data and continuously analyzing the data to determine emerging patterns is provided. Common characteristics of data from the identified emerging patterns are broadened in scope and used to generate a synthetic data set using a generative neural network approach. The resulting synthetic data set is narrowed based on analysis of the synthetic data as compared to the detected emerging patterns, and can then be used to further train one or more machine learning models for further pattern detection.","['G06N20/20', 'G06F18/213', 'G06F18/24133', 'G06F18/28', 'G06K9/6232', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/094']"
US11275819B2,Generative adversarial network training and feature extraction for biometric authentication,"Embodiments of the present invention provide a system for generative adversarial network training and feature extraction for biometric authentication. The system collects electronic biometric data of a user from one or more data sources, and stores the collected electronic biometric data as a biometric user account for the user in a personal NoSQL database library associated with the user. A generative adversarial neural network system then determines improved biometric feature selection and improved model refinements for existing biometric authentication models based on the biometric account for the user in the personal library associated with the user. The system can then determine user exposure levels for different authentication channels, including certain biometric authentication channels. A custom adversarial strategy for general adversarial network attacks is then established based on the user exposure levels to generate a biometric authentication process that is more accurate and secure.","['G06F21/32', 'G06F16/9535', 'G06F18/2413', 'G06F21/45', 'G06F21/577', 'G06K9/00926', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V40/40', 'G06V40/50', 'G06F2221/034']"
US11087215B1,Machine learning classification system,"A computing device classifies unclassified observations. A first batch of noise observations is generated. (A) A first batch of unclassified observations is selected. (B) A first batch of classified observations is selected. (C) A discriminator neural network model trained to classify unclassified observations and noise observations is updated with observations that include the first batch of unclassified observations, the first batch of classified observations, and the first batch of noise observations. (D) A discriminator loss value is computed that includes an adversarial loss term computed using a predefined transition matrix. (E) A second batch of unclassified observations is selected. (F) A second batch of noise observations is generated. (G) A generator neural network model trained to generate a fake observation vector for the second batch of noise observations is updated with the second batch of unclassified observations and the second batch of noise observations. (H) (A) to (G) is repeated.","['G06N3/08', 'G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/0895', 'G06N3/094']"
US10546408B2,Retargeting skeleton motion sequences through cycle consistency adversarial training of a motion synthesis neural network with a forward kinematics layer,"This disclosure relates to methods, non-transitory computer readable media, and systems that use a motion synthesis neural network with a forward kinematics layer to generate a motion sequence for a target skeleton based on an initial motion sequence for an initial skeleton. In certain embodiments, the methods, non-transitory computer readable media, and systems use a motion synthesis neural network comprising an encoder recurrent neural network, a decoder recurrent neural network, and a forward kinematics layer to retarget motion sequences. To train the motion synthesis neural network to retarget such motion sequences, in some implementations, the disclosed methods, non-transitory computer readable media, and systems modify parameters of the motion synthesis neural network based on one or both of an adversarial loss and a cycle consistency loss.","['G06T13/40', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T2207/20084', 'G06T2213/12']"
US20220180447A1,Artificial Intelligence Platform for Dental Claims Adjudication Prediction Based on Radiographic Clinical Findings,"Patient meta information, narratives, charts, and images are processed according to a first machine learning model to determine hidden features relating to the adjudication outcome of a proposed claim packet. Image are concatenated and processed using a second machine learning model to label anatomy including periodontal, endodontic, restorative, orthodontic, decay, and other general clinical findings. The meta information, anatomy labels, and image are concatenated and processed using a third machine learning model to obtain feature measurements, such as decay quantifications and periodontal measurements. The feature measurements, anatomy labels, teeth labels, and image information may be concatenated and input to a fourth machine learning model to obtain a diagnosis for a periodontal, decay, endodontic, orthodontic, or restorative condition. Feature measurements and/or the diagnosis may be processed according to a diagnosis hierarchy to determine whether a treatment is appropriate, and the most probable claim adjudication outcome.","['A61B5/0088', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'G06F18/24133', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06Q40/08', 'G06T7/0012', 'G06V10/82', 'G06V30/413', 'G16H30/40', 'G16H40/20', 'G16H50/20', 'A61B1/000094', 'A61B1/000096', 'A61B1/24', 'A61B5/055', 'A61B6/563', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US20200364624A1,Privacy Preserving Artificial Intelligence System For Dental Data From Disparate Sources,"Dental images are processed according to a first machine learning model to determine teeth labels. The teeth labels and image are processed using a second machine learning model to label anatomy. The anatomy labels, teeth labels, and image are processed using a third machine learning model to obtain feature measurements, such as pocket depth and clinical attachment level. The feature measurements, labels, and image may be input to a fourth machine learning model to obtain a diagnosis for a periodontal condition. Machine learning models may further be used to reorient, decontaminate, and restore the image prior to processing. A machine learning model may be made resistant to deception by images including added adversarial noise. Institutions with separate data stores may train static models that are combined and the combination is then trained by the institutions along with a combined moving model that is passed among the institutions.","['G06T7/0014', 'G06F18/214', 'G06F18/2413', 'G06F18/256', 'G06K9/6256', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N7/005', 'G06N7/01', 'G06T7/70', 'G06V10/454', 'G06V10/764', 'G06V10/811', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'A61B5/055', 'A61B5/4547', 'A61B5/7264', 'G06N3/048', 'G06T2207/10072', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036']"
US20210118132A1,"Artificial Intelligence System For Orthodontic Measurement, Treatment Planning, And Risk Assessment","A first machine learning model (e.g., GAN) is trained to take as inputs a dental image and masks of dental features in the image and outputs a set of orthodontic points. A second machine learning model may additionally take the orthodontic points as inputs and output distances between the orthodontic points. A third machine learning model may additionally take the orthodontic points and distances as inputs and output a deformation vector field for the orthodontic points. A fourth machine learning model may additionally take the orthodontic points as inputs and generate a vector indicating risk associated with orthodontic treatment. A fifth machine learning model may additionally take the orthodontic points, deformation vector field, and distances as inputs and output a treatment plan, including point clouds for brackets, retainers, appliances, mandibular surgery or movement, and/or maxillary surgery or movement.","['A61B5/1032', 'A61B1/000096', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61C7/002', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B1/24', 'A61B5/0088', 'A61B5/055', 'A61B5/11', 'A61B6/032', 'A61B6/563', 'A61B6/566', 'A61C7/08', 'A61C7/12', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US20220012815A1,Artificial Intelligence Architecture For Evaluating Dental Images And Documentation For Dental Procedures,"A dental procedure, one or more dental images, and documentation are processed to extract data and label and/or measure dental anatomy or pathologies using a first stage. The extracted data and labels are processed with a second stage to obtain predictions of deficiencies of the dental images and documentation. The predictions may include tasks to remedy the deficiencies, adjudication likelihood, instant payment amount, patient fee, and average time to payment. The first stage and second stage may each include a plurality of machine learning models. The second stage may include a plurality of machine learning models coupled to a concatenation layer. Inputs to the concatenation layer may include outputs of hidden layers of the plurality of machine learning models. The concatenation layer may take the extracted data and labels as inputs.","['A61B5/0088', 'A61B5/055', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'G06K9/00456', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06Q40/08', 'G06T7/0012', 'G06V10/82', 'G06V30/19173', 'G06V30/413', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B1/000094', 'A61B1/000096', 'A61B1/24', 'A61B2576/02', 'G06N5/046', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US11217350B2,Systems and method for artificial-intelligence-based dental image to text generation,"A first machine learning model is trained to classify dental anatomy and/or pathologies represented in an input dental image or to generate a label (pixel mask) for dental anatomy and/or pathologies represented in the input dental image. A final layer, such as one of two fully connected layers, may be removed from the first machine learning model to obtain a modified machine learning model. Hidden features output from the modified machine learning model may be input to a LSTM model that outputs a text sequence. The LSTM model may be trained with images labeled with text sequences to output a text sequence for a given input dental image.","['G16H70/60', 'G06T7/0014', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/049', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G16H30/40', 'G16H50/20', 'G06N20/20', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036']"
US12229920B2,"Systems, methods, and apparatuses for implementing fixed-point image-to-image translation using improved generative adversarial networks (GANs)","Described herein are means for implementing fixed-point image-to-image translation using improved Generative Adversarial Networks (GANs). For instance, an exemplary system is specially configured for implementing a new framework, called a Fixed-Point GAN, which improves upon prior known methodologies by enhancing the quality of the images generated through global, local, and identity transformation. The Fixed-Point GAN as introduced and described herein, improves many applications dependant on image-to-image translation, including those in the field of medical image processing for the purposes of disease detection and localization. Other related embodiments are disclosed.","['G06T5/50', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/094', 'G06T11/60', 'G06T7/0012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224']"
US11366985B2,Dental image quality prediction platform using domain specific artificial intelligence,"In medicine and dentistry, image quality affects computer vision accuracy. However, some problems are more tolerant of noise depending on disease severity and radiographic obviousness. There is a need to have a noise estimation model that adapts to each specific domain. A noise estimation model is trained to output a set of domain noise estimates for an input image, each estimate indicating an impact of noise present in the input image on a particular domain, e.g. labeling of a dental feature such as a dental anatomy, pathology, or treatment. The noise estimation model is trained by processing image pairs with a set of machine learning models for a plurality of domains, the image pairs including a raw image and a modified image obtained by adding noise to the raw image. Outputs of the set of machine learning models for the raw and modified images are compared to obtain measured noise metrics. The noise estimation model processes the modified image and is trained to estimate noise metrics. The noise estimation model is modified according to differences between the measured noise metrics and estimated noise metrics.","['G06K9/6257', 'A61B5/1032', 'A61B1/000096', 'A61B5/7267', 'A61B6/14', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'G06F18/2148', 'G06F18/2431', 'G06K9/628', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06T5/002', 'G06T5/70', 'G06T7/0012', 'G06V10/764', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B1/000094', 'A61B1/24', 'A61B5/0088', 'A61B5/055', 'G06N20/20', 'G06N3/047', 'G06N3/048', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US11357604B2,Artificial intelligence platform for determining dental readiness,"A comprehensive dental readiness platform is presented. Dental patient data including an image, proposed treatments, and a dental form are received and processed by first machine learning models to obtain clinical findings and predicted values for fields of the dental form. The clinical findings and other results are processed by a second machine learning model to obtain predictions of a future dental condition of a patient. The second machine learning model utilizes an ensemble of Transformer Neural Networks, Long-Short-Term-Memory Networks, Convolutional Neural Networks, and Tree-Based Algorithms to predict the dental readiness classification, dental readiness durability, dental readiness error, dental emergency likelihood, prognosis, and alternative treatment options.","['A61B5/1032', 'A61B5/0088', 'A61B5/7267', 'A61B6/51', 'A61B6/5217', 'A61B6/5294', 'A61B6/563', 'A61C9/0053', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06T7/0012', 'G06V10/82', 'G06V10/84', 'G06V30/18057', 'G06V30/19173', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B2576/02', 'A61B5/055', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US11610122B2,Generative adversarial neural network assisted reconstruction,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display.","['G06N3/08', 'G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06T5/003', 'G06T5/73', 'G06T7/73', 'G06T9/002', 'G06V40/168', 'H04N19/20', 'H04N19/85', 'G06N3/044', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'H04N7/157']"
US20190046068A1,Protocol independent image processing with adversarial networks,"Systems and methods are provided for generating a protocol independent image. A deep learning generative framework learns to recognize the boundaries and classification of tissues in an MRI image. The deep learning generative framework includes an encoder, a decoder, and a discriminator network. The encoder is trained using the discriminator network to generate a latent space that is invariant to protocol and the decoder is trained to generate the best output possible for brain and/or tissue extraction.","['A61B5/055', 'G06F18/241', 'G06F18/24133', 'G06K9/6268', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T11/003', 'G06T7/10', 'G06T7/11', 'G06T9/002', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06V2201/03']"
US20220301227A1,Image colorization using machine learning,"Implementations described herein relate to methods, systems, and computer-readable media to train and use a machine-learning model to colorize a grayscale image that depicts a person. In some implementations, a computer-implemented method includes receiving the grayscale image. The method further includes generating a colorized image based on the grayscale image as output of a trained convolutional neural network (CNN) by providing the grayscale image as input to the trained CNN. In some implementations, the trained CNN performs part segmentation to detect one or more parts of the person and colorizes the grayscale image.","['G06T11/001', 'G06F18/217', 'G06F18/2414', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T7/194', 'G06T7/90', 'G06V10/56', 'G06V10/764', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V40/10', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US12308101B2,Deep learning based dosed prediction for treatment planning and quality assurance in radiation therapy,"A method and system for generating a treatment plan are disclosed herein. A computing system receives a plurality of dose volume histograms for a plurality of patients and a plurality of volumetric dose distributions corresponding to the plurality of dose volume histograms. The computing system generates a volumetric dose prediction model using a neural network by learning, by the neural network, a relationship between a plurality of dose volume histograms for the plurality of patients and the corresponding plurality of volumetric dose distributions. The computing system receives a candidate dose volume histogram for a target patient. The computing system infers, via the volumetric dose prediction module, a volumetric dose prediction distribution matching the candidate dose volume histogram. The computing system generates a recommendation based on the inferred volumetric dose prediction distribution.","['G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G16H20/10', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/30']"
CN109460814B,Deep learning classification method with function of defending against sample attack,"The invention discloses a deep learning classification method with a function of defending against sample attack, and a device for realizing the classification method comprises the following steps: the method specifically comprises the following steps of generating an AG attack generation model, an antagonistic sample discrimination model D and a classification model DNN, wherein the specific method comprises the following steps: (1) training DNN by using a normal data set, stopping DNN training when the classification accuracy is greater than a preset value; (2) alternately training parameters of AG and D until AG-D realizes Nash equilibrium; (3) alternating the parameters of the training type AG and DNN until the AG-DNN realizes Nash equilibrium; (4) judging whether the countermeasure sample discrimination model D and the classification model DNN reach pareto optimal or not, if so, finishing DNN training, executing the step (5), and otherwise, returning to the step (2); (5) and inputting the samples to be classified into the trained classification model DNN to obtain a classification result. The invention can effectively solve the vulnerability of the classification model facing the confrontation sample in the actual classification application and improve the robustness of the model performance.",['G06N3/045']
US12063248B2,Deep learning for malicious URL classification (URLC) with the innocent until proven guilty (IUPG) learning framework,"Techniques for providing deep learning for malicious URL classification (URLC) using the innocent until proven guilty (IUPG) learning framework are disclosed. In some embodiments, a system, process, and/or computer program product includes storing a set comprising one or more innocent until proven guilty (IUPG) models for static analysis of a sample; performing a static analysis of one or more URLs associated with the sample, wherein performing the static analysis includes using at least one stored IUPG model; and determining that the sample is malicious based at least in part on the static analysis of the one or more URLs associated with the sample, and in response to determining that the sample is malicious, performing an action based on a security policy.","['H04L63/145', 'H04L63/1483', 'G06F21/552', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/0985']"
US20230267611A1,Optimization of a deep learning model for performing a medical imaging analysis task,Systems and methods are provided for optimizing a deep learning model. A multi-site dataset associated with different clinical sites and a deployment dataset associated with a deployment clinical site are received. A deep learning model is trained based on the multi-site dataset. The trained deep learning model is optimized based on the deployment dataset. The optimized trained deep learning model is output.,"['G06T7/0014', 'G06F18/214', 'G06F18/2411', 'G06N20/00', 'G06T7/0012', 'G06T7/11', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US20240354576A1,System and method for self constructing deep neural network design through adversarial learning,"The present disclosure is directed to a novel system for a self-constructing deep neural network. The system may comprise a hybrid logic library which contains the building structures needed to construct the neural network, which may include both traditional logic and memory structures as well as learning structures. In constructing the neural network from library structures, the system may use an algorithm to iteratively improve the performance of the neural network. In this way, the system may provide a way to generate complex neural networks that become increasingly optimized over time.","['G06N3/082', 'G06F17/11', 'G06F18/214', 'G06N3/044', 'G06N3/045', 'G06N3/086']"
US11625613B2,Generative adversarial neural network assisted compression and broadcast,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display.","['G06N3/088', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/70', 'G06V10/7747', 'G06V10/82', 'G06V40/166', 'G06V40/168', 'G06N3/044', 'G06N3/084']"
US11837354B2,Contrast-agent-free medical diagnostic imaging,Described herein is medical imaging technology for concurrent and simultaneous synthesis of a medical CA-free-AI-enhanced image and medical diagnostic image analysis comprising: receiving a medical image acquired by a medical scanner in absence of contrast agent enhancement; providing the medical image to a computer-implemented machine learning model; concurrently performing a medical CA-free-AI-enhanced image synthesis task and a medical diagnostic image analysis task with the machine learning model; reciprocally communicating between the image synthesis task and the image analysis task for mutually dependent training of both tasks. Methods and systems and non-transitory computer readable media are described for execution of concurrent and simultaneous synthesis of a medical CA-free-AI-enhanced image and medical diagnostic image analysis.,"['G16H30/40', 'G06T7/0012', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/0016', 'G06T7/11', 'G06T7/174', 'G16H30/20', 'G16H50/20', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096']"
US20240311909A1,Systems and methods for generating gradient-boosted models with improved fairness,"Systems and methods for generating tree-based models with improved fairness are disclosed. The disclosed process generates a first tree-based machine learning model, which is preferably trained to predict if a financial loan will be repaid. The process also determines an accuracy of the first tree-based machine learning mode. In addition, the process determines a fairness of the first tree-based machine learning model. The fairness is preferably associated with at least one of gender, race, ethnicity, age, marital status, military status, sexual orientation, and disability status. The process then generates a second different tree-based machine learning model, which is preferably trained based on the accuracy of the first tree-based machine learning model and the fairness of the first tree-based machine learning model. The process then combines the first tree-based machine learning model and the second tree-based machine learning model to produce a gradient-boosted machine learning model.","['G06N20/20', 'G06F18/2148', 'G06F18/24323', 'G06N20/00', 'G06N5/01', 'G06Q40/03', 'G06N3/045', 'G06N3/047', 'G06N3/088']"
US20200410228A1,Systems and methods for fast training of more robust models against adversarial attacks,"Described herein are embodiments for fast training of adversarially robust models against adversarial attacks. Embodiments for model training by perturbing both the image and the label, which may be referred to as Bilateral Adversarial Training (BAT), are disclosed. To generate the adversarial label, one or more closed-form heuristic solutions are derived. One-step targeted attack is used with the target label being the most confusing class. It is shown in various experiments that random start and the most confusing target attack effectively prevent the label leaking and gradient masking problem. Coupled with the adversarial label part, embodiments of presented models significantly improve the state-of-the-art results. Experiments on one or more computationally challenging dataset also demonstrate the effectiveness of the presented BAT method embodiments.","['G06K9/00456', 'G06F21/55', 'G06F18/214', 'G06F21/565', 'G06K9/6256', 'G06N3/04', 'G06V10/82', 'G06V30/1916', 'G06V30/19173', 'G06V30/413', 'G06N3/08']"
US11189028B1,"AI platform for pixel spacing, distance, and volumetric predictions from dental images","A machine learning model is trained to predict pixel spacing, distance, and volumetric measurements. Training images are obtained by inpainting around an original image and scaling the inpainted image to obtain the training image having a different pixel spacing than the original image. The machine learning model may include an encoder, a transformer, a first TC layer, and a second TC layer. During training, loss may be obtained from a comparison of the output to the first TC layer to a coarse pixel spacing matrix and a comparison of the output of the second TC layer to a fine pixel spacing matrix. During utilization, the pixel spacing of an image may be obtained using the machine learning model and used to correct the image or measurements obtained from the image.","['A61B5/1032', 'A61B5/7267', 'A61B6/5217', 'A61B6/5294', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'A61B5/0088', 'A61B5/055', 'A61B6/51', 'A61B6/563', 'G06N3/047', 'G06N3/048', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06V2201/03']"
US11276151B2,Inpainting dental images with missing anatomy,"Dental images are processed according to a first machine learning model to determine teeth labels. The teeth labels and image are processed using a second machine learning model to label anatomy. The anatomy labels, teeth labels, and image are processed using a third machine learning model to obtain feature measurements, such as pocket depth and clinical attachment level. The feature measurements, labels, and image may be input to a fourth machine learning model to obtain a diagnosis for a periodontal condition. Machine learning models may further be used to reorient, decontaminate, and restore the image prior to processing. A machine learning model may be trained with images and randomly generated masks in order to perform inpainting of dental images with missing information.","['G06T5/77', 'G06T5/005', 'A61B5/0088', 'A61B5/7267', 'A61B6/12', 'A61B6/51', 'A61B6/5217', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G06T5/60', 'G06T7/0012', 'G06T7/0014', 'A61B6/032', 'G06T2207/10028', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036']"
US11783025B2,Training diverse and robust ensembles of artificial intelligence computer models,"Mechanisms are provided to implement a hardened ensemble artificial intelligence (AI) model generator. The hardened ensemble AI model generator co-trains at least two AI models. The hardened ensemble AI model generator modifies, based on a comparison of the at least two AI models, a loss surface of one or more of the at least two AI models to prevent an adversarial attack on one AI model, in the at least two AI models, transferring to another AI model in the at least two AI models, to thereby generate one or more modified AI models. At least one of the one or more modified AI models then processes an input to generate an output result.","['G06F21/52', 'G06F18/22', 'G06F18/251', 'G06F18/254', 'G06F21/60', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06V10/761', 'G06V10/776', 'G06V10/809', 'G06V10/82', 'G06V10/98', 'G06F18/259']"
TWI846942B,Machine learning system and method to generate structure for target property,"A method and a system for material design utilizing machine learning are provided, where the underlying joint distribution p(S,P) of structure (S) - property (P) relationships is explicitly learned simultaneously and is utilized to directly generate samples (S,P) in a single step utilizing generative techniques, without any additional processing steps. The subspace of structures that meet or exceed the target for property P is then identified utilizing conditional generation of the distribution (e.g., p(P)), or through randomly generating a large number of samples (S,P) and filtering (e.g., selecting) those that meet target property criteria.","['G06N3/088', 'G06F30/13', 'G06F30/27', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06N7/01', 'G16C20/50', 'G16C20/70', 'G16C60/00', 'G06N3/084']"
US12069082B2,Interpreting and remediating network risk using machine learning,"A method, computer system, and computer program product are provided for mitigating network risk. A plurality of risk reports corresponding to a plurality of network devices in a network are processed to determine a multidimensional risk score for the network. The plurality of risk reports are analyzed using a semantic analysis model to identify one or more factors that contribute to the multidimensional risk score. One or more actions are determined using a trained learning model to mitigate one or more dimensions of the multidimensional risk score. The outcomes of applying the one or more actions are presented to a user to indicate an effect of each of the one or more actions on the multidimensional risk score for the network.","['G06F40/216', 'G06F21/577', 'G06F40/247', 'G06F40/295', 'G06F40/30', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'H04L63/1433', 'G06F11/004', 'G06F11/008', 'G06F11/0709', 'G06F11/0793']"
US20200250304A1,Detecting adversarial examples,"Systems and methods for detecting adversarial examples are provided. The method includes generating encoder direct output by projecting, via an encoder, input data items to a low-dimensional embedding vector of reduced dimensionality with respect to the one or more input data items to form a low-dimensional embedding space. The method includes regularizing the low-dimensional embedding space via a training procedure such that the input data items produce embedding space vectors whose global distribution is expected to follow a simple prior distribution. The method also includes identifying whether each of the input data items is an adversarial or unnatural input. The method further includes classifying, during the training procedure, those input data items which have not been identified as adversarial or unnatural into one of multiple classes.","['G06F21/55', 'G06F21/552', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06F2221/031', 'G06N3/084']"
US11847564B2,Privacy-preserving machine learning,"New and efficient protocols are provided for privacy-preserving machine learning training (e.g., for linear regression, logistic regression and neural network using the stochastic gradient descent method). A protocols can use the two-server model, where data owners distribute their private data among two non-colluding servers, which train various models on the joint data using secure two-party computation (2PC). New techniques support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions, such as sigmoid and softmax.","['G06F21/6254', 'G06N3/08', 'G06F21/6245', 'G06N3/045', 'G06N3/048', 'G06N3/0499', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'H04L9/008', 'H04L9/085', 'H04L2209/46']"
US11606389B2,Anomaly detection with graph adversarial training in computer systems,"Methods and systems for detecting and responding to an intrusion in a computer network include generating an adversarial training data set that includes original samples and adversarial samples, by perturbing one or more of the original samples with an integrated gradient attack to generate the adversarial samples. The original and adversarial samples are encoded to generate respective original and adversarial graph representations, based on node neighborhood aggregation. A graph-based neural network is trained to detect anomalous activity in a computer network, using the adversarial training data set. A security action is performed responsive to the detected anomalous activity.","['H04L63/1466', 'H04L63/1425', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'H04L63/20']"
EP4244770A1,Architecture for explainable reinforcement learning,An exemplary embodiment may provide an explainable reinforcement learning system. Explanations may be incorporated into an exemplary reinforcement learning agent/model or a corresponding environmental model. The explanations may be incorporated into an agent's state and/or action space. An explainable Bellman equation may implement an explainable state and explainable action as part of an explainable reward function. An explainable reinforcement learning induction method may implement a dataset to provide a white-box model which mimics a black-box reinforcement learning system. An explainable generative adversarial imitation learning model may implement an explainable generative adversarial network to train the occupancy measure of a policy and may generate multiple levels of explanations. Explainable reinforcement learning may be implemented on a quantum computing system using an embodiment of an explainable Bellman equation.,"['G06N3/08', 'G06N20/00', 'G06N3/042', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G09B9/00', 'G06N3/045', 'G06N3/047', 'G06N7/01']"
US10868825B1,Cybersecurity and threat assessment platform for computing environments,"An example network security and threat assessment system is configured to determine, based on one or more events that have occurred during execution of one or more applications, a potential security vulnerability of a target computing system, where the one or more events correspond to a node represented in the hierarchical risk model. The system is further configured to identify, based on a mapping of the node represented in the hierarchical risk model to a node represented in a hierarchical game tree model, one or more actions that are associated with the potential security vulnerability and that correspond to the node represented in the hierarchical game tree model, and to output, for display in a graphical user interface, a graphical representation of the potential security vulnerability and the one or more actions associated with the potential security vulnerability.","['H04L43/045', 'H04L43/06', 'H04L43/065', 'H04L43/50', 'H04L63/1433', 'H04L63/1441', 'H04L41/046', 'H04L41/22', 'H04L43/0817']"
US12254414B2,Autoencoding generative adversarial network for augmenting training data usable to train predictive models,"Techniques for using a deep generative model to generate synthetic data sets that can be used to boost the performance of a discriminative model are described. In an example, an autoencoding generative adversarial network (AEGAN) is trained to generate the synthetic data sets. The AEGAN includes an autoencoding network and a generative adversarial network (GAN) that share a generator. The generator learns how to the generate synthetic data sets based on a data distribution from a latent space. Upon training the AEGAN, the generator generates the synthetic data sets. In turn, the synthetic data sets are used to train a predictive model, such as a convolutional neural network for gaze prediction.","['G06N3/088', 'G06F18/214', 'G06F3/013', 'G06F3/017', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094']"
US20230186098A1,Distributed generative adversarial networks suitable for privacy-restricted data,"An asynchronous distributed generative adversarial network (AsynDGAN) can include a central computing system and at least two discriminator nodes. The central computing system can include a generator neural network, an aggregator, and a network interface. Each discriminator node can have its own corresponding training data set. In addition, different discriminator nodes can use different data modalities. The central computing system communicates with each of the at least two discriminator nodes via the network interface and aggregates data received from the at least two discriminator nodes, via the aggregator, to update a model for the generator neural network during training of the generator neural network. The central computing system can further include a data access system that supports third party access to synthetic data generated by the generator neural network.","['G06N3/091', 'G06N3/088', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N7/01', 'G16H30/40']"
CN111295674B,Protecting cognitive systems from gradient-based attacks by using spoof gradients,"Mechanisms for providing an enhanced neural network are provided. The mechanism configures an augmented neural network executing in a data processing system to introduce noise in an internal feature representation of the augmented neural network. Noise introduced in the internal feature representation diverts gradient calculations associated with the lost surface of the augmented neural network. The mechanism configures an augmented neural network executing in a data processing system to implement a consolidated layer of nodes that combines outputs of the augmented neural network's countertrained output nodes with the augmented neural network's output nodes trained based on the introduced noise. The mechanism processes the input data through the augmented neural network to generate classification labels for the input data, and thereby generates augmented input data that is output to a computing system for processing to perform computing operations.","['G06N3/08', 'G06F21/57', 'G06N3/02', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N5/041', 'G06F2221/034', 'G06N3/044', 'G06N3/047', 'G06N5/022']"
US20250033201A1,Machine learning methods and apparatus for robotic manipulation and that utilize multi-task domain adaptation,"Implementations are directed to training a machine learning model that, once trained, is used in performance of robotic grasping and/or other manipulation task(s) by a robot. The model can be trained using simulated training examples that are based on simulated data that is based on simulated robot(s) attempting simulated manipulations of various simulated objects. Portion(s) of the model can also be trained based on real training examples that are based on data from real-world physical robots attempting manipulations of various objects. The simulated training examples can be utilized to train the model to predict an output that can be utilized in a particular task—and the real training examples used to adapt at least a portion of the model to the real-world domain can be tailored to a distinct task. In some implementations, domain-adversarial similarity losses are determined during training, and utilized to regularize at least portion(s) of the model.","['B25J9/163', 'B25J9/1612', 'B25J9/1669', 'B25J9/1671', 'B25J9/1697', 'G05B2219/39316', 'G05B2219/39536', 'G05B2219/39543', 'G05B2219/40514', 'Y10S901/02', 'Y10S901/31', 'Y10S901/47']"
US11580375B2,Accelerated training of a machine learning based model for semiconductor applications,Methods and systems for accelerated training of a machine learning based model for semiconductor applications are provided. One method for training a machine learning based model includes acquiring information for non-nominal instances of specimen(s) on which a process is performed. The machine learning based model is configured for performing simulation(s) for the specimens. The machine learning based model is trained with only information for nominal instances of additional specimen(s). The method also includes re-training the machine learning based model with the information for the non-nominal instances of the specimen(s) thereby performing transfer learning of the information for the non-nominal instances of the specimen(s) to the machine learning based model.,"['G06N3/08', 'G01Q30/02', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/067', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F30/20', 'G06N3/0454', 'G06T2207/10061']"
EP3588382A1,A deep learning method for tumor cell scoring on cancer biopsies,"A score of a histopathological diagnosis of cancer is generated by loading an image patch of a digital image into a processing unit, determining how many pixels of the image patch belong to a first tissue, processing additional image patches cropped from the digital image to determine how many pixels of each image patch belong to the first tissue, computing the score and displaying it along with the digital image on a graphical user interface. The image patch is cropped from the digital image of a slice of tissue that has been immunohistochemically stained using a diagnostic antibody. The first tissue is positively stained by the diagnostic antibody. Determining how many pixels belong to the first tissue is performed by processing the image patch using a convolutional neural network. The score of the histopathological diagnosis is computed based on the total number of pixels that belong to the first tissue.","['G06V10/764', 'A61B5/7267', 'G06T7/0012', 'G06V10/82', 'G06V20/695', 'G06V20/698', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30061', 'G06V2201/03']"
US20250094571A1,Generative adversarial-based attack in federated learning,A method performed by a client node is provided for generating a generative adversarial network (GAN)-based attack for disruption of a global federated learning model. The method includes setting an attack strength factor to a value; and training the GAN using the attack strength factor and an initial adversarial dataset to obtain a malicious weight matrix. The initial adversarial dataset is generated from or by initial weights matrix received from a network node of the global federated learning model and initial malicious weights derived from an initial attack on the global federated learning model that used a deterministic attack to obtain the malicious weight matrix. The method further includes generating the GAN-based attack including an updated malicious weight matrix; and sending the updated malicious weight matrix to the network node.,"['G06N3/063', 'G06F21/554', 'G06N3/0475', 'G06N3/094', 'G06N3/098', 'G06F2221/034', 'G06N7/01']"
US20210334651A1,Learning point cloud augmentation policies,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a machine learning model to perform a machine learning task by processing input data to the model. For example, the input data can include image, video, or point cloud data, and the task can be a perception task such as classification or detection task. In one aspect, the method includes receiving training data including a plurality of training inputs; receiving a plurality of data augmentation policy parameters that define different transformation operations for transforming training inputs before the training inputs are used to train the machine learning model; maintaining a plurality of candidate machine learning models; for each of the plurality of candidate machine learning models: repeatedly determining an augmented batch of training data; training the candidate machine learning model using the augmented batch of the training data; and updating the maintained data.","['B60W50/06', 'B60W60/001', 'G01S17/894', 'G06F17/18', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N3/086', 'B60W2420/408', 'G06K9/00791', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N3/082', 'G06N5/01', 'G06V20/56']"
US10685663B2,Enabling in-ear voice capture using deep learning,"A method includes accessing, by at least one processing device, an audible signal including at least one in-ear microphone audible signal and at least one external microphone audible signal and at least one noise signal; training a generative network to generate an enhanced external microphone signal from an in-ear microphone signal based on the at least one in-ear microphone audible signal and the at least one external microphone audible signal; and outputting the generative network.","['G10L21/0208', 'G10K11/16', 'G10K11/17827', 'H04R3/00', 'G10K2210/1081', 'G10L25/30', 'G10L25/84', 'H04R1/1016', 'H04R2201/107']"
US10453444B2,Intent and slot detection for digital assistants,"Described herein is a mechanism to adapt a machine learning model used in a language understanding model that has been trained using a first set of user input having a first set of features to effectively operate using user input having a second set of features. Losses are defined based on the first set of features, the second set of features or features common to both the first set and second set. The losses comprise one or more of a source side tagging loss, a reconstruction loss, an adversarial domain classification loss, a non-adversarial domain classification loss, an orthogonality loss, and target side tagging loss. The losses are jointly minimized using a gradient descent method and the resulting coefficients are used to retrain the machine learning model.","['G10L15/063', 'G06F17/279', 'G06F40/35', 'G06N20/00', 'G10L15/1815']"
US10753997B2,Image standardization using generative adversarial networks,Systems and methods are provided for synthesizing protocol independent magnetic resonance images. A patient is scanned by a magnetic resonance imaging system to acquire magnetic resonance data. The magnetic resonance data is input to a machine learnt generator network trained to extract features from input magnetic resonance data and synthesize protocol independent images using the extracted features. The machine learnt generator network generates a protocol independent segmented magnetic resonance image from the input magnetic resonance data. The protocol independent magnetic resonance image is displayed.,"['G01R33/5608', 'G01R33/543', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094']"
AU2022200517B2,Image synthesis using adversarial networks,"A computer-implemented method for training a statistical learning model, the method comprising: training the statistical learning model using a similarity determination between training imaging data provided at a model input without reconstructing an image of a-first imaging modality type, the training imaging data including the first modality type and wherein synthesized imaging data at the model output corresponds to a second imaging modality type different from the first imaging modality type; and training a statistical learning model using a single generator and a separate statistical learning model, the separate statistical learning model configured to discriminate between measured imaging data corresponding to the second imaging modality and the synthesized imaging data.","['G06V10/764', 'A61N5/103', 'G06T7/0012', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081']"
US10733733B1,"Method for detecting anomaly using generative adversarial networks, apparatus and system thereof","There is provided an anomaly detection method, apparatus, and system that can improve the accuracy and reliability of a detection result using GAN (Generative Adversarial Networks). An anomaly detection apparatus according to some embodiments includes a memory that stores a GAN-based image translation model and an anomaly detection model, and a processor that translates a learning image with a low-difficulty level into a learning image with a high-difficulty level and learns the anomaly detection model using the translated learning image. The anomaly detection apparatus can improve the detection performance by learning the anomaly detection model with the learning image with the high-difficulty level in which it is difficult detect the anomaly.","['G06N3/088', 'G06F18/2413', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T3/00', 'G06T7/0012', 'G06T7/0014', 'G06V10/764', 'G06V10/82', 'G16H50/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US10922540B2,"Clustering, classifying, and searching documents using spectral computer vision and neural networks","Systems and associated methods relate to classification of documents according to their spectral frequency signatures using a deep neural network (DNN) and other forms of spectral analysis. In an illustrative example, a DNN may be trained using a set of predetermined patterns. A trained DNN may, during runtime, receive documents as inputs, where each document has been converted into a spectral format according to a (2D) Fourier transform. Some exemplary methods may extract periodicity/frequency information from the documents based on the spectral signature of each document. A clustering algorithm may be used in clustering/classification of documents, as well as searching for documents similar to a target document(s). A variety of implementations may save significant time to users in organizing, searching, and identifying documents in the areas of mergers and acquisitions, litigation, e-discovery, due diligence, governance, and investigatory activities, for example.","['G06K9/00483', 'G06F16/35', 'G06F16/93', 'G06K9/4647', 'G06K9/6232', 'G06K9/64', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V30/418', 'G06F18/2323', 'G06F18/24', 'G06K9/6224', 'G06K9/6267', 'G06N3/045', 'G06N3/088']"
US10706336B2,Recognition in unlabeled videos with domain adversarial learning and knowledge distillation,"An object recognition system is provided that includes a device configured to capture a video sequence formed from unlabeled testing video frames. The system includes a processor configured to pre-train a recognition engine formed from a reference set of CNNs on a still image domain that includes labeled training still image frames. The processor adapts the recognition engine to a video domain to form an adapted recognition engine, by applying a non-reference set of CNNs to a set of domains that include the still image and video domains and a degraded image domain. The degraded image domain includes labeled synthetically degraded versions of the labeled training still image frames included in the still image domain. The video domain includes random unlabeled training video frames. The processor recognizes, using the adapted engine, a set of objects in the video sequence. A display device displays the set of recognized objects.","['G08B13/19613', 'G06K9/66', 'G06F18/21', 'G06F18/217', 'G06F18/22', 'G06F18/24143', 'G06K9/00268', 'G06K9/00288', 'G06K9/00718', 'G06K9/00744', 'G06K9/00771', 'G06K9/4628', 'G06K9/6201', 'G06K9/6217', 'G06K9/6262', 'G06K9/6274', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/70', 'G06T9/002', 'G06V10/454', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/52', 'G06V30/19173', 'G06V40/168', 'G06V40/172', 'G06K2009/00738', 'G06T2207/20081', 'G06V20/44', 'G08B13/196']"
US10859657B2,"MRI reconstruction using deep learning, generative adversarial network and acquisition signal model","A method for diagnostic imaging includes measuring undersampled data y with a diagnostic imaging apparatus; linearly transforming the undersampled data y to obtain an initial image estimate {tilde over (x)}; applying the initial image estimate {tilde over (x)} as input to a generator network to obtain an aliasing artifact-reduced image x̆ as output of the generator network, where the aliasing artifact-reduced image x̆ is a projection onto a manifold of realistic images of the initial image estimate {tilde over (x)}; and performing an acquisition signal model projection of the aliasing artifact-reduced x̆ onto a space of consistent images to obtain a reconstructed image {circumflex over (x)} having suppressed image artifacts.","['G01R33/5608', 'A61B5/055', 'G01R33/4818', 'G01R33/483', 'G01R33/5611', 'G06T7/0012', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G06T2207/20081', 'G06T2207/20084']"
US11990224B2,Synthetically generating medical images using deep convolutional generative adversarial networks,"Methods, devices, and systems that are related to facilitating an automated, fast and accurate model for cardiac image segmentation, particularly for image data of children with complex congenital heart disease are disclosed. In one example aspect, a generative adversarial network is disclosed. The generative adversarial network includes a generator configured to generate synthetic imaging samples associated with a cardiovascular system, and a discriminator configured to receive the synthetic imaging samples from the generator and determine probabilities indicating likelihood of the synthetic imaging samples corresponding to real cardiovascular imaging sample. The discriminator is further configured to provide the probabilities determined by the discriminator to the generator and the discriminator to allow the parameters of the generator and the parameters of the discriminator to be adjusted iteratively until an equilibrium between the generator and the discriminator is established.","['G16H30/40', 'G06F18/2148', 'G06F18/2185', 'G06F18/2193', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06T7/0012', 'G06T7/11', 'G06T7/143', 'G06V10/82', 'G16H50/20', 'G16H50/50', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06V2201/031']"
US20210197335A1,Data Augmentation Method Based On Generative Adversarial Networks In Tool Condition Monitoring,"The invention provides a data augmentation method based on generative adversarial networks in tool condition monitoring. Firstly, the sensor acquisition system is used to obtain the vibration signal and noise signal during the cutting process of the tool; second, the noise data subject to the prior distribution is input to the generator to generate data, and the generated data and the collected real sample data are input to the discriminator for identification, the confrontation training between the generator and the discriminator until the training is completed; then, use the trained generator to generate sample data, and determine whether the generated sample data and the actual tool state sample data are similar in distribution; finally, combined with the accuracy of the deep learning network model to predict the state of the tool to verify the availability of the generated data.","['B23Q17/0976', 'G06N3/088', 'B23Q17/0957', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'B23Q2717/00']"
US20230229986A1,"Machine Learning Based Construction Methods, Techniques, and Algorithms","Techniques to automate various aspects related to construction projects, including but not limited to, creation of schedules, verification of construction progress, estimation of costs, updating of schedules, creation and estimation of construction status, use of information generated by construction equipment, and the use of granular information to continually update the same. Data analysis can be used to refine the cost per task and calculate a cost to complete for a construction project. The cost to complete can be viewed at any time and it will be made more accurate by having the cost per task refined from historical data. Additionally, a rate of production statistic can be generated to compare workers across tasks and see if the implicit task durations used to today can be refined. A learning algorithm can be created by using reinforced learning to figure out the next best step if a project task is delayed or put on hold. This action can normalize projects in an effort for them to complete as scheduled and priced.","['G06Q10/063114', 'G06N20/00', 'G06Q10/06', 'G06Q10/06312', 'G06Q10/103', 'G06Q20/102', 'G06Q20/38', 'G06Q40/02', 'G06Q50/08', 'G06N3/045', 'G06Q2220/00']"
US11276023B1,Machine learning optimization for fraud detection,"Devices and techniques are generally described for fraud detection. A machine learning model is used to determine a first fraud risk score for a first transaction. The machine learning model includes a first set of weights. A first covariance matrix is determined for the machine learning model based at least in part on the first fraud risk score. A second set of weights for the machine learning model is determined. The second set of weights is determined based on the first set of weights and the first covariance matrix. In various examples, the machine learning model with the second set of weights is used to determine a second fraud risk score for a second transaction. A fraud decision surface is determined and the second fraud risk score is compared to the fraud decision surface. Data indicating that the second transaction is fraudulent is sent to a computing device.","['G06Q10/0635', 'G06N20/00', 'G06N20/10', 'G06N3/08', 'G06N3/09', 'G06Q20/4016']"
US11893087B2,Defending multimodal fusion models against single-source adversaries,"A multimodal perception system for an autonomous vehicle includes a first sensor that is one of a video, RADAR, LIDAR, or ultrasound sensor, and a controller. The controller may be configured to, receive a first signal from a first sensor, a second signal from a second sensor, and a third signal from a third sensor, extract a first feature vector from the first signal, extract a second feature vector from the second signal, extract a third feature vector from the third signal, determine an odd-one-out vector from the first, second, and third feature vectors via an odd-one-out network of a machine learning network, based on inconsistent modality prediction, fuse the first, second, and third feature vectors and odd-one-out vector into a fused feature vector, output the fused feature vector, and control the autonomous vehicle based on the fused feature vector.","['G06V10/806', 'G06F18/256', 'G06F18/253', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T3/4038', 'G06T7/246', 'G06V10/761', 'G06V10/82', 'G06V40/20', 'G06T2200/32', 'G06T2207/20084', 'G06T2207/30248', 'G06V20/56']"
US10936949B2,Training machine learning models using task selection policies to increase learning progress,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a machine learning model. In one aspect, a method includes receiving training data for training the machine learning model on a plurality of tasks, where each task includes multiple batches of training data. A task is selected in accordance with a current task selection policy. A batch of training data is selected from the selected task. The machine learning model is trained on the selected batch of training data to determine updated values of the model parameters. A learning progress measure that represents a progress of the training of the machine learning model as a result of training the machine learning model on the selected batch of training data is determined. The current task selection policy is updated using the learning progress measure.","['G06N3/08', 'G06N3/09', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/047', 'G06N3/096', 'G06N3/0985']"
US20250036924A1,A self-learning method of generative adversarial multi-headed attention neural network for aero-engine data reconstruction,"A generative adversarial multi-headed attention neural network self-learning method for aero-engine data reconstruction belongs to the field of end-to-end self-learning of aero-engine missing data. First, the samples are pre-processed, and the machine learning algorithm is used to pre-fill the normalized data first, and the pre-filled information is involved in the network training as part of the training information. Second, a generative adversarial multi-headed attention network model is constructed and the trained sample set is used to train the generative adversarial multi-headed attention network model. Finally, the samples are generated using the trained sample generator G. The method uses the generative adversarial network to better learn the distribution information of the data, and uses parallel convolution and multi-headed attention mechanism to fully exploit the spatial and temporal information among the aero-engine data.","['G06N3/094', 'G06F30/27', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06F2111/08', 'Y02P90/30', 'Y02T90/00']"
US11113599B2,Image captioning utilizing semantic text modeling and adversarial learning,"The present disclosure includes methods and systems for generating captions for digital images. In particular, the disclosed systems and methods can train an image encoder neural network and a sentence decoder neural network to generate a caption from an input digital image. For instance, in one or more embodiments, the disclosed systems and methods train an image encoder neural network (e.g., a character-level convolutional neural network) utilizing a semantic similarity constraint, training images, and training captions. Moreover, the disclosed systems and methods can train a sentence decoder neural network (e.g., a character-level recurrent neural network) utilizing training sentences and an adversarial classifier.","['G06N20/00', 'G06F18/217', 'G06F18/24143', 'G06K9/00664', 'G06K9/00671', 'G06K9/6262', 'G06K9/6274', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V20/10', 'G06V20/20', 'G06V20/70']"
US11238312B2,Automatically generating labeled synthetic documents,"The present disclosure relates to systems, methods, and non-transitory computer readable media for generating diverse and realistic synthetic documents using deep learning. In particular, the disclosed systems can utilize a trained neural network to generate realistic image layouts comprising page elements that comply with layout parameters. The disclosed systems can also generate synthetic content corresponding to the page elements within the image layouts. The disclosed systems insert the synthetic content into the corresponding page elements of documents based on the image layouts to generate synthetic documents.","['G06K9/6257', 'G06V30/414', 'G06F18/2148', 'G06K9/00456', 'G06K9/00463', 'G06N3/045', 'G06N3/0454', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06V30/19147', 'G06V30/413', 'G06F18/24137', 'G06N3/084']"
US12223734B2,Systems and methods for training machine-learned models with deviating intermediate representations,Systems and methods for vehicle-to-vehicle communications are provided. An adverse system can obtain sensor data representative of an environment proximate to a targeted system. The adverse system can generate an intermediate representation of the environment and a representation deviation for the intermediate representation. The representation deviation can be designed to disrupt a machine-learned model associated with the target system. The adverse system can communicate the intermediate representation modified by the representation deviation to the target system. The target system can train the machine-learned model associated with the target system to detect the modified intermediate representation. Detected modified intermediate representations can be discarded before disrupting the machine-learned model.,"['G06V20/56', 'G01S17/931', 'G05D1/0088', 'G05D1/0221', 'G05D1/81', 'G06F18/2163', 'G06F18/217', 'G06F18/24', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G01S7/003', 'G06N3/044', 'G08G1/096791', 'G08G1/162']"
US20250023902A1,"Modeling of adversarial artificial intelligence in blind false data injection against ac state estimation in smart grid security, safety and reliability","Computer-implemented methods and systems for training an adversarial neural network to simulate a stealthy blind false data injection attack on a cyber physical system are provided. Supervised learning is used to generate an initial attack vector, by an adversarial attack generation model, based on inferred grid topology and historical measurements. A final attack vector is generated, by an adversarial verification model, based on a filtered subset of the initial attack vector utilizing a substitute bad data detection threshold, wherein the final attack vector enables creation of a counter measure.","['G06F21/55', 'H04L63/1433', 'G05B19/0428', 'G05B23/024', 'G05B23/0256', 'G06N3/09', 'G06N3/094', 'Y04S40/20']"
US10679626B2,Generating interactive audio-visual representations of individuals,"A system for generating an audio-visual representation of an individual is provided. The system includes an audio-visual representation generator to obtain audio-visual data of an individual communicating responses to prompts. The generator includes a recording analyzer and recording processor to segment the audio-visual data into responsive audio-video segments, or includes a machine learning model to generate artificial audio-visual responses, which simulate the individual communicating a response to the input prompt.","['G10L15/22', 'G06F16/48', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G10L15/1815', 'G06N3/006', 'G06N5/04', 'G10L15/26', 'G10L2015/088', 'G10L2015/223']"
US11687778B2,Fakecatcher: detection of synthetic portrait videos using biological signals,"Detection of synthetic content in portrait videos, e.g., deep fakes, is achieved. Detectors blindly utilizing deep learning are not effective in catching fake content, as generative models produce realistic results. However, biological signals hidden in portrait videos which are neither spatially nor temporally preserved in fake content, can be used as implicit descriptors of authenticity. 99.39% accuracy in pairwise separation is achieved. A generalized classifier for fake content is formulated by analyzing signal transformations and corresponding feature sets. Signal maps are generated, and a CNN employed to improve the classifier for detecting synthetic content. Evaluation on several datasets produced superior detection rates against baselines, independent of the source generator, or properties of available fake content. Experiments and evaluations include signals from various facial regions, under image distortions, with varying segment durations, from different generators, against unseen datasets, and under several dimensionality reduction techniques.","['G06N3/08', 'G06F18/2411', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V40/161', 'G06V40/169', 'G06V40/40', 'G06V40/45', 'G06N20/10', 'G06V40/15']"
US11769056B2,Synthetic data for neural network training using vectors,"Machine learning is performed using synthetic data for neural network training using vectors. Facial images are obtained for a neural network training dataset. Facial elements from the facial images are encoded into vector representations of the facial elements. A generative adversarial network (GAN) generator is trained to provide one or more synthetic vectors based on the one or more vector representations, wherein the one or more synthetic vectors enable avoidance of discriminator detection in the GAN. The training a GAN further comprises determining a generator accuracy using the discriminator. The generator accuracy can enable a classifier, where the classifier comprises a multi-layer perceptron. Additional synthetic vectors are generated in the GAN, wherein the additional synthetic vectors avoid discriminator detection. A machine learning neural network is trained using the additional synthetic vectors. The training a machine learning neural network further includes using the one or more synthetic vectors.","['G06N3/084', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/774', 'G06V10/82', 'G06V40/16', 'G06V40/165', 'G06V40/169', 'G06V40/174', 'G06N3/048', 'G06V40/179']"
US11443178B2,Deep neural network hardening framework,"Mechanisms are provided to implement a hardened neural network framework. A data processing system is configured to implement a hardened neural network engine that operates on a neural network to harden the neural network against evasion attacks and generates a hardened neural network. The hardened neural network engine generates a reference training data set based on an original training data set. The neural network processes the original training data set and the reference training data set to generate first and second output data sets. The hardened neural network engine calculates a modified loss function of the neural network, where the modified loss function is a combination of an original loss function associated with the neural network and a function of the first and second output data sets. The hardened neural network engine trains the neural network based on the modified loss function to generate the hardened neural network.","['G06N3/08', 'H04L63/1441', 'G06N3/04', 'G06N3/042', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N5/045']"
US20210286923A1,Sensor simulation and learning sensor models with generative machine learning methods,"In various examples, a sensor model may be learned to predict virtual sensor data for a given scene configuration. For example, a sensor model may include a deep neural network that supports generative learning—such as a generative adversarial network (GAN). The sensor model may accept an encoded representation of a scene configuration as an input using any number of data structures and/or channels (e.g., concatenated vectors, matrices, tensors, images, etc.), and may output virtual sensor data. Real-world data and/or virtual data may be collected and used to derive training data, which may be used to train the sensor model to predict virtual sensor data for a given scene configuration. As such, one or more sensor models may be used as virtual sensors in any of a variety of applications, such as in a simulated environment to test features and/or functionality of one or more autonomous or semi-autonomous driving software stacks.","['G06F30/27', 'G01S7/4052', 'G01S7/412', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G01S13/931', 'G01S2013/9323', 'G01S2013/9324']"
US20200065626A1,Systems and methods for deep model translation generation,"Embodiments of the present invention relate to systems and methods for improving the training of machine learning systems to recognize certain objects within a given image by supplementing an existing sparse set of real-world training images with a comparatively dense set of realistic training images. Embodiments may create such a dense set of realistic training images by training a machine learning translator with a convolutional autoencoder to translate a dense set of synthetic images of an object into more realistic training images. Embodiments may also create a dense set of realistic training images by training a generative adversarial network (“GAN”) to create realistic training images from a combination of the existing sparse set of real-world training images and either Gaussian noise, translated images, or synthetic images. The created dense set of realistic training images may then be used to more effectively train a machine learning object recognizer to recognize a target object in a newly presented digital image.","['G06K9/6257', 'G06V10/82', 'G06F18/214', 'G06F18/2148', 'G06K9/6232', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/088', 'G06V10/774', 'G06V10/70', 'G06V10/7747']"
US12288376B2,Systems and methods for defending against physical attacks on image classification,"An image classification system defends against physically realizable attacks. A training dataset of input images is retrieved and an adversarial image is generated based on one of the input images that is selected. The adversarial image is created by occluding a portion of the selected image by superimposing a predetermined shape (e.g., a rectangle) containing noise on the selected image. A defense against occlusion attacks (DOA) classifier is trained using the training dataset and the adversarial image. The DOA classifier is utilized to classify captured images of items (e.g., street signs) that may have been attacked (e.g., sticker placement, vandalism).","['G06V10/751', 'B60W60/00188', 'G06F18/214', 'G06F18/24', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'B60W2420/403', 'G06N20/00']"
US11893466B2,Systems and methods for model fairness,Systems and methods for training models to improve fairness.,"['G06N20/20', 'G06F18/2148', 'G06F18/24133', 'G06N3/045', 'G06N3/0499', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06N7/01', 'G06Q10/067', 'G06Q40/03', 'G06N20/10', 'G06N3/044']"
WO2023283357A1,Intelligent prioritization of assessment and remediation of common vulnerabilities and exposures for network nodes,"The node exposure score generator and the attack path modeling component are configured to cooperate to analyze the actual detected vulnerabilities that exist for that network node in the network, the importance of network nodes in the network compared to other network nodes in the network, and the key pathways within the network and the vulnerable network nodes in the network that a cyber-attack would use during the cyber- attack in order to provide an intelligent prioritization of remediation actions to remediate the actual detected vulnerabilities for each network node from the network protected by a cyber security appliance.","['H04L63/1416', 'G06F11/3604', 'G06F21/53', 'G06F21/563', 'G06F21/577', 'H04L41/16', 'H04L63/1408', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'G06F2221/033', 'G06F2221/034']"
US11222246B2,Generating a digital image using a generative adversarial network,"Various embodiments described herein utilize multiple levels of generative adversarial networks (GANs) to facilitate generation of digital images based on user-provided images. Some embodiments comprise a first generative adversarial network (GAN) and a second GAN coupled to the first GAN, where the first GAN includes an image generator and at least two discriminators, and the second GAN includes an image generator and at least one discriminator. According to some embodiments, the (first) image generator of the first GAN is trained by processing a user-provided image using the first GAN. For some embodiments, the user-provided image and the first generated image, generated by processing the user-provided image using the first GAN, are combined to produce a combined image. For some embodiments, the (second) image generator of the second GAN is trained by processing the combined image using the second GAN.","['G06Q30/0625', 'G06K9/66', 'G06F16/532', 'G06F16/5838', 'G06F16/9535', 'G06F18/214', 'G06F18/2413', 'G06K9/00369', 'G06K9/3233', 'G06K9/36', 'G06K9/6256', 'G06K9/627', 'G06Q30/0631', 'G06Q30/0643', 'G06V10/25', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V40/103']"
CA3122686C,Automated reservoir modeling using deep generative networks,"A method for generating one or more reservoir models using machine learning is provided. Generating reservoir models is typically a time-intensive idiosyncratic process. However, machine learning may be used to generate one or more reservoir models that characterize the subsurface. The machine learning may use geological data, geological concepts, reservoir stratigraphic configurations, and one or more input geological models in order to generate the one or more reservoir models. As one example, a generative adversarial network (GAN) may be used as the machine learning methodology. The GAN includes two neural networks, including a generative network (which generates candidate reservoir models) and a discriminative network (which evaluates the candidate reservoir models), contest with each other in order to generate the reservoir models.","['G01V20/00', 'G01V1/28', 'G01V1/303', 'G01V1/50', 'G06F17/18', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G01V2210/6652']"
US11171974B2,Distributed agent based model for security monitoring and response,"An architecture is provided for a widely distributed security system (SDI-SCAM) that protects computers at individual client locations, but which constantly pools and analyzes information gathered from machines across a network in order to quickly detect patterns consistent with intrusion or attack, singular or coordinated. When a novel method of attack has been detected, the system distributes warnings and potential countermeasures to each individual machine on the network. Such a warning may potentially include a probability distribution of the likelihood of an intrusion or attack as well as the relative probabilistic likelihood that such potential intrusion possesses certain characteristics or typologies or even strategic objectives in order to best recommend and/or distribute to each machine the most befitting countermeasure(s) given all presently known particular data and associated predicted probabilistic information regarding the prospective intrusion or attack. If any systems are adversely affected, methods for repairing the damage are shared and redistributed throughout the network.","['H04L63/1425', 'H04L63/1416', 'H04L63/1441', 'H04L63/145']"
US20230336581A1,Intelligent prioritization of assessment and remediation of common vulnerabilities and exposures for network nodes,"The node exposure score generator and the attack path modeling component are configured to cooperate to analyze the actual detected vulnerabilities that exist for that network node in the network, the importance of network nodes in the network compared to other network nodes in the network, and the key pathways within the network and the vulnerable network nodes in the network that a cyber-attack would use during the cyber-attack in order to provide an intelligent prioritization of remediation actions to remediate the actual detected vulnerabilities for each network node from the network protected by a cyber security appliance.","['G06F21/577', 'H04L63/1433', 'G06N20/00', 'G06N7/01', 'H04L41/0816', 'H04L51/212', 'H04L63/1416', 'H04L63/1425', 'H04L63/1483', 'H04L51/18']"
US11961219B2,Generative adversarial networks (GANs) for simulating specimen images,"Methods and systems for generating a simulated image for a specimen are provided. One system includes one or more computer subsystems and one or more components executed by the one or more computer subsystems. The one or more components include a generative adversarial network (GAN), e.g., a conditional GAN (cGAN), trained with a training set that includes portions of design data for one or more specimens designated as training inputs and corresponding images of the one or more specimens designated as training outputs. The one or more computer subsystems are configured for generating a simulated image for a specimen by inputting a portion of design data for the specimen into the GAN.","['G06N3/08', 'G06T7/0006', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/047', 'G06T2207/10061', 'G06T2207/10152', 'G06T2207/20081', 'G06T2207/30148']"
US11995525B2,Generative adversarial network model training using distributed ledger,"Embodiments are directed to the tracking of data in a generative adversarial network (GAN) model using a distributed ledger system, such as a blockchain. A learning platform implementing a classification model receives, from a third party, a set of data examples generated by a generator model. The set of data examples are processed by the classification model, which outputs a prediction for each data example indicating whether each data example is true or false. The distributed ledger keeps a record of data examples submitted to the learning platform, as well as of predictions determined by the classification model on the learning platform. The learning platform analyzes the records of the distributed ledger, and pairs the records corresponding to the submitted data examples and the generated predictions determined by the classification model, and determines if the predictions were correct. The classification model may then be updated based upon the prediction results.","['G06F16/906', 'G06N20/00', 'G06F16/182', 'G06N20/20', 'G06N3/006', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N5/02', 'G06Q20/065', 'G06Q20/0855', 'G06Q2220/00']"
US20200183041A1,Machine learning-augmented geophysical inversion,"A method and system of machine learning-augmented geophysical inversion includes obtaining measured data; obtaining prior subsurface data; (a) partially training a data autoencoder with the measured data to learn a fraction of data space representations and generate a data space encoder; (b) partially training a model autoencoder with the prior subsurface data to learn a fraction of model space representations and generate a model space decoder; (c) forming an augmented forward model with the model space decoder, the data space encoder, and a physics-based forward model; (d) solving an inversion problem with the augmented forward model to generate an inversion solution; and iteratively repeating (a)-(d) until convergence of the inversion solution, wherein, for each iteration: partially training the data and model autoencoders starts with learned weights from an immediately-previous iteration; and solving the inversion problem starts with super parameters from the previous iteration.","['G01V1/48', 'G01V1/282', 'G01V11/00', 'G01V20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G01V2200/14', 'G01V2210/665', 'G01V2210/667']"
US12001950B2,Generative adversarial network based audio restoration,"Mechanisms are provided for implementing a generative adversarial network (GAN) based restoration system. A first neural network of a generator of the GAN based restoration system is trained to generate an artificial audio spectrogram having a target damage characteristic based on an input audio spectrogram and a target damage vector. An original audio recording spectrogram is input to the trained generator, where the original audio recording spectrogram corresponds to an original audio recording and an input target damage vector. The trained generator processes the original audio recording spectrogram to generate an artificial audio recording spectrogram having a level of damage corresponding to the input target damage vector. A spectrogram inversion module converts the artificial audio recording spectrogram to an artificial audio recording waveform output.","['G06N3/08', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G10L21/0208']"
US12265612B2,Method for identifying vulnerabilities in computer program code and a system thereof,"Open-source software is prevalent in the development of new technologies. Monitoring software updates for vulnerabilities is expensive and time consuming. Online discussions surrounding new software updates can often provide vital information regarding emerging risks. It is presented a novel approach for automating surveillance of software through the use of natural language processing methods on open-source issues. Further, the potential of virtual adversarial training, a popular semi-supervised learning technique, is used to leverage the vast amounts of unlabeled data available to achieve improved performance. On industry data, it is found that a hierarchical attention network with virtual adversarial training that utilizes the innate document structure to encapsulate the text can be used with good results.","['G06F21/554', 'G06N3/088', 'G06F18/214', 'G06F18/2178', 'G06F21/552', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/047', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/082']"
WO2024060395A1,Deep learning-based high-precision point cloud completion method and apparatus,"Disclosed in the present invention are a deep learning-based high-precision point cloud completion method and apparatus, comprising: a dynamic kernel convolution PAConv is introduced into a feature extraction module, a weight coefficient can be learned according to a position relationship between each point and a neighborhood point thereof, and a weight matrix is combined to adaptively construct a convolution kernel. A spatial attention mechanism is added to a feature fusion module, so that a decoder can better learn a mutual relationship between various features, and these feature information can be better represented. Discriminator modules comprise global and local attention discriminator modules, classification is carried out by using multi-layer full connection, and whether a generation result satisfies real point cloud distribution is determined respectively from the whole and local aspects, so as to optimize the generation result, thereby improving the precision of point cloud completion to obtain a complete and accurate point cloud completion result, and also providing a guarantee for smooth execution of a plurality of downstream tasks such as point cloud segmentation, classification, object recognition, and point cloud reconstruction.","['G06V10/764', 'G06N3/08', 'G06V10/806', 'G06V10/82']"
US20230206603A1,High-precision point cloud completion method based on deep learning and device thereof,"The present disclosure discloses a high-precision point cloud completion method based on deep learning and a device thereof, which comprises the following steps: introducing dynamic kernel convolution PAConv into a feature extraction module, learning a weight coefficient according to the positional relationship between each point and its neighboring points, and adaptively constructing the convolution kernel in combination with the weight matrix. A spatial attention mechanism is added to a feature fusion module, which facilitates a decoder to better learn the relationship among various features, and thus better represent the feature information. A discriminator module comprises global and local attention discriminator modules, which use multi-layer full connection to classify and determine whether the generated results conform to the real point cloud distribution globally and locally, respectively, so as to optimize the generated results.","['G06V10/7715', 'G06V10/44', 'G06V10/454', 'G06V10/80', 'G06V10/806', 'G06V10/82', 'G06V20/64']"
US12344979B2,Jeans with laser finishing patterns created by neural network,"Software and lasers are used in finishing apparel to produce a desired wear pattern or other design. A technique includes using machine learning to create or extract a laser input file for wear pattern from an existing garment. Machine learning can be by a generative adversarial network, having generative and discriminative neural nets. The generative adversarial network is trained and then used to create a model. This model is used generate the laser input file from an image of the existing garment with the finishing pattern. With this laser input file, a laser can re-create the wear pattern from the existing garment onto a new garment.","['D06B11/0096', 'A41B1/08', 'A41D1/02', 'A41D1/04', 'A41D1/089', 'A41D1/14', 'A41D27/00', 'A41D27/08', 'A41D3/00', 'A41H43/00', 'B23K26/36', 'D03D1/00', 'D03D15/43', 'D06C23/02', 'D06M10/00', 'D06M10/005', 'D06P5/15', 'D06P5/2011', 'G06F18/214', 'G06N3/002', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'A41B2500/20', 'A41D1/06', 'A41D2500/20', 'D06P1/228', 'D10B2501/04']"
US12333427B2,Multi-scale output techniques for generative adversarial networks,"An improved system architecture uses a Generative Adversarial Network (GAN) including a specialized generator neural network to generate multiple resolution output images. The system produces a latent space representation of an input image. The system generates a first output image at a first resolution by providing the latent space representation of the input image as input to a generator neural network comprising an input layer, an output layer, and a plurality of intermediate layers and taking the first output image from an intermediate layer, of the plurality of intermediate layers of the generator neural network. The system generates a second output image at a second resolution different from the first resolution by providing the latent space representation of the input image as input to the generator neural network and taking the second output image from the output layer of the generator neural network.","['G06F18/211', 'G06F18/214', 'G06F18/2163', 'G06F18/40', 'G06F3/04845', 'G06F3/04847', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T11/001', 'G06T11/60', 'G06T3/02', 'G06T3/18', 'G06T3/40', 'G06T3/4038', 'G06T3/4046', 'G06T5/20', 'G06T5/77', 'G06V10/28', 'G06V10/82', 'G06V10/98', 'G06V40/168', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2210/22']"
US12182274B2,Testing adversarial robustness of systems with limited access,"An adversarial robustness testing method, system, and computer program product include testing, via an accelerator, a robustness of a black-box system under different access settings, where the testing includes tearing down the robustness testing to a subtask of a predetermined size.","['G06F21/577', 'G06F18/241', 'G06F18/2413', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06F2221/034']"
US10699161B2,Tunable generative adversarial networks,"A method of tuning a generative model may be provided. A method may include receiving, at a first generative adversarial network (GAN), a first input identifying an item and at least one user-defined attribute for the item. The method may also include generating, via the first GAN, a first image of the item based on the first input. Further, the method may include receiving, at a second GAN, the first image and a second input indicative of a desire for more or less of the at least one user-defined attribute. Moreover, the method may include generating, via the second GAN, a second image of the item based on the first image and the second input.","['G06K9/6254', 'G06V10/82', 'G06F18/214', 'G06F18/2433', 'G06F18/41', 'G06K9/6256', 'G06K9/6284', 'G06V10/764']"
US11042803B2,Method and apparatus for using generative adversarial networks in magnetic resonance image reconstruction,"A method of reconstructing imaging data into a reconstructed image may include training a generative adversarial network (GAN) to reconstruct the imaging data. The GAN may include a generator and a discriminator. Training the GAN may include determining a combined loss by adaptively adjusting an adversarial loss based at least in part on a difference between the adversarial loss and a pixel-wise loss. Additionally, the combined loss may be a combination of the adversarial loss and the pixel-wise loss. Training the GAN may also include updating the generator based at least in part on the combined loss. The method may also include receiving, into the generator, the imaging data and reconstructing, via the generator, the imaging data into a reconstructed image.","['G06N3/088', 'G01R33/5608', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G01R33/5611', 'G06T2207/20081']"
US10496898B2,State detection using machine-learning model trained on simulated image data,"A set of virtual images can be generated based on one or more real images and target rendering specifications, such that the set of virtual images correspond to (for example) different rendering specifications (or combinations thereof) than do the real images. An image style can be transferred to the at least some of the virtual images of the set of virtual images to generate a stylized virtual image. A machine-learning model can be trained using a plurality of stylized virtual images. Another real image can then be processed using the trained machine-learning model. The processing can include segmenting the other real image to detect whether and/or which objects are represented (and/or a state of the object). The object data can then be used to identify (for example) a state of a procedure.","['G06K9/6256', 'G06N3/08', 'A61B34/10', 'G06F18/214', 'G06F18/217', 'G06F18/2413', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/20', 'A61B2034/101', 'A61B2034/102', 'A61B2034/104', 'A61B2034/105', 'A61B2090/365', 'A61B2090/502', 'G06K2209/057', 'G06V2201/034']"
US11557123B2,Scene change method and system combining instance segmentation and cycle generative adversarial networks,"A scene change method and system combining instance segmentation and cycle generative adversarial networks are provided. The method includes: processing a video of a target scene and then inputting the video into an instance segmentation network to obtain segmented scene components, that is, obtain mask cut images of the target scene; and processing targets in the mask cut images of the target scene by using cycle generative adversarial networks according to the requirements of temporal attributes to generate data in a style-migrated state, and generating style-migrated targets with unfixed spatial attributes into a style-migrated static scene according to a specific spatial trajectory to achieve a scene change effect.","['G06T3/04', 'G06V20/49', 'G06V20/52', 'G06T7/10', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/70', 'G06V40/10', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
US11462304B2,Artificial intelligence engine architecture for generating candidate drugs,"An artificial intelligence engine architecture for generating candidate drugs is disclosed. In one embodiment, a method includes generating, via a creator module, a candidate drug compound including a sequence of a candidate drug compound, including the candidate drug compound as a node in a knowledge graph; generating, via a descriptor module, a description of the candidate drug compound at the node in the knowledge graph, wherein the description comprises drug compound structural information, drug compound activity information, and drug compound semantic information; based on the description, performing, via a scientist module, a benchmark analysis of a parameter of the creator module; and modifying, based on the benchmark analysis, the creator module to change the parameter in a desired way during a subsequent benchmark analysis.","['G16C20/50', 'G06N20/00', 'G06N3/042', 'G06N3/0427', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G16C20/70', 'G16C60/00', 'G06N3/044']"
CN108830912B,An Interactive Grayscale Image Colorization Method for Adversarial Learning of Deep Features,"The invention provides an interactive gray level image coloring method for depth feature antagonistic learning, which is based on a generative antagonistic network theory, is used for constructing a full convolution neural network based on a U-shaped network structure as a generator and can process images with any size. And automatically generating gray level image coloring training data in a random simulation interactive stroke mode, and simultaneously carrying out antagonistic training on the two neural networks of the discriminator and the generator. And finally, training a gray level image coloring neural network model to realize interactive gray level image coloring. The invention can color the gray level image with user stroke interaction, and can support the personalized coloring requirement of the user while efficiently and automatically processing, thereby realizing artistic creation.","['G06T11/40', 'G06N3/045', 'G06T2207/10024', 'G06T2207/20081']"
US11083913B2,Machine learning approach to real-time patient motion monitoring,"Systems and techniques may be used to estimate a patient state during a radiotherapy treatment. For example, a method may include generating a dictionary of expanded potential patient measurements and corresponding potential patient states using a preliminary motion model. The method may include training, using a machine learning technique, a correspondence motion model relating an input patient measurement to an output patient state using the dictionary. The method may include estimating, using a processor, the patient state corresponding to an input image using the correspondence motion model.","['A61N5/107', 'A61N5/1037', 'A61N5/1039', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'A61N2005/1034', 'A61N2005/1052', 'A61N2005/1054', 'A61N2005/1055', 'A61N2005/1058', 'A61N2005/1061', 'G06N20/10', 'G06N20/20', 'G06N3/08', 'G06N5/01', 'G06N7/01']"
US12260530B2,Generating a modified digital image utilizing a human inpainting model,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For example, in one or more embodiments the disclosed systems utilize generative machine learning models to create modified digital images portraying human subjects. In particular, the disclosed systems generate modified digital images by performing infill modifications to complete a digital image or human inpainting for portions of a digital image that portrays a human. Moreover, in some embodiments, the disclosed systems perform reposing of subjects portrayed within a digital image to generate modified digital images. In addition, the disclosed systems in some embodiments perform facial expression transfer and facial expression animations to generate modified digital images or animations.","['G06F3/0482', 'G06F3/04842', 'G06F3/04845', 'G06F3/04847', 'G06F3/0486', 'G06F3/04883', 'G06N3/02', 'G06T11/60', 'G06T5/60', 'G06T5/77', 'G06V10/25', 'G06V10/44', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US20220337557A1,System and method for monitoring and securing communications networks and associated devices,"A system and method for shielding a network from malicious or unauthorized activity includes an active monitoring device connected to the network for monitoring each data packet and controlling the network connection. End devices connected to the network are isolated from each other so that data cannot flow in the event one or more data packets, devices, and so on, are flagged as untrustworthy. The active monitoring device uses the filter data to determine whether unusual behavior, unauthorized access, attempted hacking occurred, and ensure isolation between network devices and prevent transfer of data. Continuous monitoring ensures once trusted devices that abnormally change behavior are flagged as untrusted, thereby preventing breaches of the network.","['H04L63/0272', 'H04L12/4633', 'H04L12/4641', 'H04L12/4645', 'H04L61/10', 'H04L63/0236', 'H04L63/0245', 'H04L63/029', 'H04L63/1433', 'H04L63/1441', 'H04L63/1466', 'H04L63/1483', 'H04L2101/622', 'H04L2212/00', 'H04L61/103', 'H04L61/2514', 'H04L61/2575', 'H04L61/4511', 'H04L61/5014']"
US11921819B2,Defense method and an application against adversarial examples based on feature remapping,"A defense method against adversarial examples based on feature remapping, includes the following steps: building the feature remapping model, the feature remapping model is composed of the significant feature generation model and the nonsignificant feature generation model, and a shared discriminant model, the significant generation model is used to generate significant features, the nonsignificant generation model is used to generate nonsignificant features, and the shared discriminant model is used to discriminate fake or true of generated significant and nonsignificant features. The method combines the significant feature generation model and the nonsignificant feature generation model to build the detector that is used to detect adversarial examples and benign examples; builds the re-recognizer according to the significant feature generation model, the re-recognizer is used to recognize the type of adversarial examples while detecting; connects the detector to the output of the target model, and then use the detector to detect adversarial examples. While recognizing adversarial examples, the method connects the re-recognizer to the output of the target model, and then uses the re-recognizer to recognize adversarial examples. The present invention can achieve dual defense effects of the detection and re-recognition of adversarial examples.","['G06V10/776', 'G06F18/2148', 'G06F18/214', 'G06F18/213', 'G06F18/241', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06V10/771', 'G06V10/7715', 'G06V10/7747']"
US11048974B2,Effective structure keeping for generative adversarial networks for single image super resolution,"A method of training a generator G of a Generative Adversarial Network (GAN) includes generating a real contextual data set {x1, . . . , xN} for a high resolution image Y; generating a generated contextual data set {g1, . . . , gN} for a generated high resolution image G(Z); calculating a perceptual loss Lpcept value using the real contextual data set {x1, . . . , xN} and the generated contextual data set {g1, . . . , gN}; and training the generator G using the perceptual loss Lpcept value. The generated high resolution image G(Z) is generated by the generator G of the GAN in response to receiving an input Z, where the input Z is a random sample that corresponds to the high resolution image Y.","['G06T3/4053', 'G06K9/6256', 'G06N3/088', 'G06F18/211', 'G06F18/214', 'G06K9/6228', 'G06K9/6232', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/771', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN110503630B,"Cerebral hemorrhage classifying, positioning and predicting method based on three-dimensional deep learning model","The invention discloses a cerebral hemorrhage classifying, positioning and predicting method based on a three-dimensional deep learning model, which is used for carrying out three-dimensional modeling on a two-dimensional CT image by a surface reconstruction method to obtain a three-dimensional CT image; then, a three-dimensional convolutional neural network is used for extracting features of the three-dimensional CT image, and the extracted features are classified through an SVM classifier, so that whether the CT image contains bleeding points or not is classified and judged; slicing the three-dimensional CT image which is judged to contain the bleeding points by the classifier again, and accurately positioning the bleeding point positions of the two-dimensional CT image after slicing through a target detection network; compression encoding is carried out on physical characteristic information of a patient to serve as a three-dimensional conditional generation condition of an countermeasure network, the generation condition is integrated with random noise, and a three-dimensional CT image is output according to physical indexes of the patient by using a three-dimensional generator in the countermeasure network model, so that the diffusion of blood clots of the brain of the patient with time or the absorption condition of the brain of the patient by a human body is predicted.","['G06F18/2411', 'G06T11/003', 'G06T7/0012', 'G06T7/73', 'G16H50/20', 'G16H50/50', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'Y02A90/10']"
US11100222B2,Method for hardening a machine learning model against extraction,"A method is provided for protecting a trained machine learning model that provides prediction results with confidence levels. The confidence level is a measure of the likelihood that a prediction is correct. The method includes determining if a query input to the model is an attempted attack on the model. If the query is determined to be an attempted attack, a first prediction result having a highest confidence level is swapped with a second prediction result having a relatively lower confidence level so that the first and second prediction results and confidence levels are re-paired. Then, the second prediction result is output from the model with the highest confidence level. By swapping the confidence levels and outputting the prediction results with the swapped confidence levels, the machine learning model is more difficult for an attacker to extract.","['G06F21/554', 'G06F21/75', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/0499', 'G06N3/09']"
US11977386B2,Adversarial scenarios for safety testing of autonomous vehicles,Techniques to generate driving scenarios for autonomous vehicles characterize a path in a driving scenario according to metrics such as narrowness and effort. Nodes of the path are assigned a time for action to avoid collision from the node. The generated scenarios may be simulated in a computer.,"['G05D1/0214', 'B60W30/09', 'B60W60/0011', 'B60W60/0015', 'G01S13/931', 'G05B13/027', 'G05D1/0088', 'G05D1/0212', 'G05D1/617', 'G05D1/81', 'B60W2050/0088', 'B60W2554/4046', 'B60W2710/20', 'B60W2720/106', 'B60W2720/125']"
US11275841B2,Combination of protection measures for artificial intelligence applications against artificial intelligence attacks,"A method and system of protecting an artificial intelligence (AI) application are provided. Parameters of the AI application are identified. An assessment of a vulnerability of the AI application is performed, including: applying a combination of protection measures comprising two or more protection measures against at least two different attacks and at least one dataset, and determining whether the combination of protection measures is successful in defending the AI application. A target configuration of an AI model to protect the AI application is determined based on the assessed vulnerability of the AI application. An AI enhanced algorithm is determined to adjust the AI model to include a combination of most computationally efficient defenses based on the target configuration. The adjusted AI model is used to protect the AI application.","['G06F21/577', 'G06F16/951', 'G06F18/24', 'G06F18/241', 'G06K9/6267', 'G06K9/6268', 'G06F2221/033']"
US20230162023A1,System and Method for Automated Transfer Learning with Domain Disentanglement,"A system and method for automated construction of an artificial neural network architecture are provided. The system includes a set of interfaces and data links configured to receive and send signals, wherein the signals include datasets of training data, validation data and testing data, wherein the signals include a set of random number factors in multi-dimensional signals, wherein part of the random number factors are associated with task labels to identify, and nuisance variations. The system further includes a set of memory banks to store a set of reconfigurable deep neural network (DNN) blocks, hyperparameters, trainable variables, intermediate neuron signals, and temporary computation values including forward-pass signals and backward-pass gradients. The system further includes at least one processor, in connection with the interface and the memory banks, configured to submit the signals and the datasets into the reconfigurable DNN blocks, wherein the at least one processor is configured to explore hyperparameters of regularization modules, pre-processing and post-processing methods such that the reconfigurable DNN blocks achieve nuisance-robust Bayesian inference to be transferable to new datasets with domain shifts.","['G06N3/096', 'G06N3/08', 'G06N3/04', 'G06N3/0455', 'G06N3/047', 'G06N3/0985', 'G06N7/01', 'G06N3/006', 'G06N3/044', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'G06N3/094']"
US11875269B2,Large scale generative neural network model with inference for representation learning using adversarial training,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a generator neural network and an encoder neural network. The generator neural network generates, based on a set of latent values, data items which are samples of a distribution. The encoder neural network generates a set of latent values for a respective data item. The training method comprises jointly training the generator neural network, the encoder neural network and a discriminator neural network configured to distinguish between samples generated by the generator network and samples of the distribution which are not generated by the generator network. The discriminator neural network is configured to distinguish by processing, by the discriminator neural network, an input pair comprising a sample part and a latent part.","['G06N3/084', 'G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/092', 'G06N3/094', 'G06N3/098', 'G06N5/04', 'G06N3/006']"
US10978051B2,Adversarial learning framework for persona-based dialogue modeling,"Various embodiments may be generally directed to the use of an adversarial learning framework for persona-based dialogue modeling. In some embodiments, automated multi-turn dialogue response generation may be performed using a persona-based hierarchical recurrent encoder-decoder-based generative adversarial network (phredGAN). Such a phredGAN may feature a persona-based hierarchical recurrent encoder-decoder (PHRED) generator and a conditional discriminator. In some embodiments, the conditional discriminator may include an adversarial discriminator that is provided with attribute representations as inputs. In some other embodiments, the conditional discriminator may include an attribute discriminator, and attribute representations may be handled as targets of the attribute discriminator. The embodiments are not limited in this context.","['G06F40/30', 'G10L15/16', 'G06F40/216', 'G06F40/35', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/041', 'G10L15/183', 'G10L15/22']"
US12307594B2,Generating geological facies models with fidelity to the diversity and statistics of training images using improved generative adversarial networks,Neural network systems and related machine learning methods for geological modeling are provided that employ an improved generative adversarial network including a generator neural network and a discriminator neural network. The generator neural network is trained to map a combination of a noise vector and a category code vector as input to a simulated image of geological facies. The discriminator neural network is trained to map at least one image of geological facies provided as input to corresponding probability that the at least one image of geological facies provided as input is a training image of geological facies or a simulated image of geological facies produced by the generator neural network.,"['G06T17/05', 'G06T7/0004', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/082', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084']"
US11222415B2,Systems and methods for deep learning microscopy,"A microscopy method includes a trained deep neural network that is executed by software using one or more processors of a computing device, the trained deep neural network trained with a training set of images comprising co-registered pairs of high-resolution microscopy images or image patches of a sample and their corresponding low-resolution microscopy images or image patches of the same sample. A microscopy input image of a sample to be imaged is input to the trained deep neural network which rapidly outputs an output image of the sample, the output image having improved one or more of spatial resolution, depth-of-field, signal-to-noise ratio, and/or image contrast.","['G06T5/50', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T3/4046', 'G06T3/4053', 'G06T3/4076', 'G06T5/002', 'G06T5/003', 'G06T5/009', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T5/92', 'G06T7/0014', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
US11620487B2,Neural architecture search based on synaptic connectivity graphs,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting a neural network architecture for performing a machine learning task. In one aspect, a method comprises: obtaining data defining a synaptic connectivity graph representing synaptic connectivity between neurons in a brain of a biological organism; generating data defining a plurality of candidate graphs based on the synaptic connectivity graph; determining, for each candidate graph, a performance measure on a machine learning task of a neural network having a neural network architecture that is specified by the candidate graph; and selecting a final neural network architecture for performing the machine learning task based on the performance measures.","['G06N3/084', 'G06F18/21', 'G06F18/211', 'G06F18/217', 'G06F18/232', 'G06F18/24', 'G06F18/2413', 'G06K9/6217', 'G06K9/6262', 'G06K9/6267', 'G06N3/006', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/086', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G06V10/426', 'G06V10/763', 'G06V10/764', 'G10L25/30', 'G10L25/51', 'G06N20/20', 'G06N3/048', 'G06N5/01', 'G06V2201/03']"
US11520923B2,Privacy-preserving visual recognition via adversarial learning,"A method for protecting visual private data by preventing data reconstruction from latent representations of deep networks is presented. The method includes obtaining latent features from an input image and learning, via an adversarial reconstruction learning framework, privacy-preserving feature representations to maintain utility performance and prevent the data reconstruction by simulating a black-box model inversion attack by training a decoder to reconstruct the input image from the latent features and training an encoder to maximize a reconstruction error to prevent the decoder from inverting the latent features while minimizing the task loss.","['G06F21/6245', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094']"
US11676007B2,Defect removal from manufactured objects having morphed surfaces,"Methods, systems, and apparatus, including medium-encoded computer program products, for computer aided repair of physical structures include: generating a two dimensional difference image from a first three dimensional model of at least one actual three dimensional surface of a manufactured object, and a second three dimensional model of at least one source three dimensional surface used as input to a manufacturing process that generated the manufactured object; obtaining from an image-to-image translation based machine learning algorithm, trained using pairs of input images representing deformed and deformed plus surface defected added versions of a nominal three dimensional surface, a translated version of the two dimensional image; generating from the translated version of the two dimensional image a third three dimensional model of at least one morphed three dimensional surface corresponding to the at least one source three dimensional surface. Further, defects can be removed based on the third three dimensional model.","['G06N3/08', 'G05B19/4097', 'G05B19/4207', 'G06F30/20', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G05B2219/32228', 'G05B2219/35134', 'Y02P90/02']"
US11886955B2,Self-supervised data obfuscation in foundation models,"Provided are methods and system for obtaining, by a computer system, a machine learning/machine learning model; obtaining, by the computer system, a training data set; training, with the computer system, an obfuscation transform based on the machine learning/machine learning model and the training data set; and storing, with the computer system, the obfuscation transform in memory.","['G06N3/0895', 'G06N3/0455', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098']"
US10642846B2,Using a generative adversarial network for query-keyword matching,"A computer-implemented technique is described herein for providing a digital content item using a generator component. The generator component corresponds to a sequence-to-sequence neural network that is trained using an adversarial generative network (GAN) system. In one approach, the technique involves: receiving a query from a user computing device over a computer network; generating random information; generating a key term using the generator component based on the query and the random information; selecting at least one content item based on the key term; and sending the content item(s) over the computer network to the user computing device.","['G06F16/24575', 'G06F16/2343', 'G06F16/334', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/092', 'G06N3/094', 'G06Q30/0256', 'H04L9/0662']"
US20230229901A1,Artificial neural network architectures based on synaptic connectivity graphs,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an artificial neural network architecture based on a synaptic connectivity graph. According to one aspect, there is provided a method comprising: obtaining a synaptic resolution image of at least a portion of a brain of a biological organism; processing the image to identify: (i) a plurality of neurons in the brain, and (ii) a plurality of synaptic connections between pairs of neurons in the brain; generating data defining a graph representing synaptic connectivity between the neurons in the brain; determining an artificial neural network architecture corresponding to the graph representing the synaptic connectivity between the neurons in the brain; and processing a network input using an artificial neural network having the artificial neural network architecture to generate a network output.","['G06N3/084', 'G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/105', 'G06N20/20', 'G06N3/044', 'G06N5/01']"
US11373115B2,Asynchronous parameter aggregation for machine learning,"Systems and methods are provided for training a machine learned model on a large number of devices, each device acquiring a local set of training data without sharing data sets across devices. The devices train the model on the respective device's set of training data. The devices communicate a parameter vector from the trained model asynchronously with a parameter server. The parameter server updates a master parameter vector and transmits the master parameter vector to the respective device.","['G01C21/3602', 'G01C25/00', 'G06N20/00', 'G06V20/56', 'G06V30/19147', 'G06V30/19167', 'G06V30/194']"
EP3968222A1,"Classification task model training method, apparatus and device and storage medium","A classification task model training method, apparatus and device and a storage medium, relating to the technical field of machine learning. The method comprises: using a first data set to train an initial feature extractor to obtain a feature extractor (101), wherein the first data set is a classimbalance data set; constructing a generative adversarial network, the generative adversarial network comprising the feature extractor and an initial feature generator (102); training the generative adversarial network using a second class of samples to obtain a feature generator (103); constructing a classification task model, the classification task model comprising the feature generator and the feature extractor (104); and training the classification task model using the first data set (105), the feature generator being used for amplifying the second class of samples in a feature space during the training process. The feature generator is used to amplify samples of minority classes in the feature space, thus improving the accuracy of the classification task model obtained by training.","['G06V10/82', 'G06F18/214', 'G06F18/22', 'G06F18/24', 'G06F18/2431', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/761', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G16H30/40', 'G16H50/20']"
US20230229891A1,Reservoir computing neural networks based on synaptic connectivity graphs,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for implementing a reservoir computing neural network. In one aspect there is provided a reservoir computing neural network comprising: (i) a brain emulation sub-network, and (ii) a prediction sub-network. The brain emulation sub-network is configured to process the network input in accordance with values of a plurality of brain emulation sub-network parameters to generate an alternative representation of the network input. The prediction sub-network is configured to process the alternative representation of the network input in accordance with values of a plurality of prediction sub-network parameters to generate the network output. The values of the brain emulation sub-network parameters are determined before the reservoir computing neural network is trained and are not adjusting during training of the reservoir computing neural network.","['G06N3/045', 'G06N3/084', 'G06N20/00', 'G06N3/044', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/086', 'G06N3/088', 'G06T7/0012', 'G06V10/82', 'G06V30/18057', 'G06N5/01', 'G06N5/022', 'G06T2207/10016', 'G06T2207/10061', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
US10824914B2,Apparatus and method of data generation for object detection based on generative adversarial networks,"An apparatus for generating data based on generative adversarial networks (GANs) is provided. The apparatus includes a first generator configured to receive input data and generate a first fake image, a first discriminator configured to receive the first fake image generated by the first generator and a first real image and verify whether an image is fake or real, a second generator configured to receive the first fake image and generate a second fake image; and a second discriminator configured to receive the second fake image and a second real image and verify whether an image received by the second discriminator is fake or real. The apparatus improves an object recognition performance as compared with a typical object recognition algorithm by generating an image of a class of which a sufficient database is not secured so as to reduce an object misrecognition caused by an insufficient amount of data.","['G06V20/00', 'G06T7/0002', 'G06K9/6262', 'G06F18/214', 'G06F18/217', 'G06F18/2413', 'G06K9/6256', 'G06N3/08', 'G06T7/11', 'G06T7/70', 'G06T7/97', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US11481416B2,Question Answering using trained generative adversarial network based modeling of text,"Mechanisms are provided for implementing a Question Answering (QA) system utilizing a trained generator of a generative adversarial network (GAN) that generates a bag-of-ngrams (BoN) output representing unlabeled data for performing a natural language processing operation. The QA system obtains a plurality of candidate answers to a natural language question, where each candidate answer comprises one or more ngrams. For each candidate answer, a confidence score is generated based on a comparison of the one or more ngrams in the candidate answer to ngrams in the BoN output of the generator neural network of the GAN. A final answer to the input natural language question is selected from the plurality of candidate answers based on the confidence scores associated with the candidate answers, and is output.","['G06F16/3329', 'G06F16/3347', 'G06F40/216', 'G06F40/30', 'G06N3/042', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06N5/02', 'G06N5/041', 'G10L15/16', 'G10L15/197', 'G10L15/22', 'G06N3/048', 'G10L2015/225']"
US11281976B2,Generative adversarial network based modeling of text for natural language processing,"Mechanisms are provided to implement a generative adversarial network (GAN) for natural language processing. With these mechanisms, a generator neural network of the GAN is configured to generate a bag-of-ngrams (BoN) output based on a noise vector input and a discriminator neural network of the GAN is configured to receive a BoN input, where the BoN input is either the BoN output from the generator neural network or a BoN input associated with an actual portion of natural language text. The mechanisms further configure the discriminator neural network of the GAN to output an indication of a probability as to whether the input BoN is from the actual portion of natural language text or is the BoN output of the generator neural network. Moreover, the mechanisms train the generator neural network and discriminator neural network based on a feedback mechanism that compares the output indication from the discriminator neural network to an indicator of whether the input BoN is from the actual portion of natural language text of the BoN output of the generator neural network.","['G06F40/216', 'G06F16/313', 'G06F18/2178', 'G06F40/30', 'G06K9/6263', 'G06N3/042', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/088', 'G06N3/094', 'G06N5/041', 'G06V10/464', 'G06V10/7784', 'G10L15/02', 'G10L15/197', 'G06N3/044', 'G06N3/048', 'G06N5/02']"
US11308587B2,Learning method of generative adversarial network with multiple generators for image denoising,"The present invention relates to a learning method of generative adversarial network (GAN) with multiple generators for image denoising, and provides a generative adversarial network with three generators. Such generators are used for removing Poisson noise, Gaussian blur noise and distortion noise respectively to improve the quality of low-dose CT (LDCT) images; the generators adopt the residual network structure. The mapped short connection used in the residual network can avoid the vanishing gradient problem in a deep neural network and accelerate the network training; the training of GAN is always a difficult problem due to the unreasonable measure between the generative distribution and real distribution. The present invention can stabilize training and enhance the robustness of training models by limiting the spectral norm of a weight matrix.","['G06T5/70', 'G06T5/002', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30096', 'Y02T10/40']"
US11468293B2,Simulating and post-processing using a generative adversarial network,A hybrid computing system comprising a quantum computer and a digital computer employs a digital computer to use machine learning methods for post-processing samples drawn from the quantum computer. Post-processing samples can include simulating samples drawn from the quantum computer. Machine learning methods such as generative adversarial networks (GANs) and conditional GANs are applied. Samples drawn from the quantum computer can be a target distribution. A generator of a GAN generates samples based on a noise prior distribution and a discriminator of a GAN measures the distance between the target distribution and a generative distribution. A generator parameter and a discriminator parameter are respectively minimized and maximized.,"['G06N3/0454', 'G06N3/045', 'G06N3/084', 'G06N10/00', 'G06N10/60', 'G06N3/047', 'G06N3/0475', 'G06N3/06', 'G06N3/088', 'G06N3/094', 'G06F17/11']"
US20210097439A1,Method and system for scalable and decentralized incremental machine learning which protects data privacy,"A computer-implemented method for client-specific federated learning is disclosed applicable in a system including a central server unit and a plurality of client units. The client units are respectively located at different local sites and respectively include local data which is subject to data privacy regulations. In an embodiment, the method includes providing, to one or more of the client units, a toolset, the toolset being configured such that a plurality of different machine learned models can be derived from the toolset at the one or more client units. It further includes receiving, from the one or more client units, one or more machine learned models, the one or more machine learned models being respectively derived from the toolset and trained based and the respective local data by the client units. Finally, the method includes storing the one or more machine learned models in the central server unit.","['G06N20/20', 'G06F18/214', 'G06F18/217', 'G06F8/71', 'G06K9/6256', 'G06K9/6262', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/126', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US11468206B2,Machine learning system for building renderings and building information modeling data,"Techniques are disclosed for using a computation engine executing a machine learning system to generate, according to constraints, renderings of a building or building information modeling (BIM) data for the building, wherein the constraints include at least one of an architectural style or a building constraint. In one example, an input device is configured to receive an input indicating one or more surfaces for the building and one or more constraints. A machine learning system executed by a computation engine is configured to apply a model, trained using images of buildings labeled with corresponding constraints for the buildings, to the one or more surfaces for the building to generate at least one of a rendering of the one or more surfaces for the building according to the constraints or BIM data for the building according to the constraints. Further, the machine learning system is configured to output the rendering or the BIM data.","['G06F30/13', 'G06N3/088', 'G06F30/27', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N20/10', 'G06N3/006', 'G06N3/084', 'G06N5/01', 'G06N5/041', 'G06N7/01']"
US12347169B2,Autonomous vehicle perception multimodal sensor data management,"The automated driving perception systems described herein provide technical solutions for technical problems facing navigation sensors for autonomous vehicle navigation. These systems may be used to combine inputs from multiple navigation sensors to provide a multimodal perception system. These multimodal perception systems may augment raw data within a development framework to improve performance of object detection, classification, tracking, and sensor fusion under varying external conditions, such as adverse weather and light, as well as possible sensor errors or malfunctions like miss-calibration, noise, and dirty or faulty sensors. This augmentation may include injection of noise, occlusions, and misalignments from raw sensor data, and may include ground-truth labeling to match the augmented data. This augmentation provides improved robustness of the trained perception algorithms against calibration, noise, occlusion, and faults that may exist in real-world scenarios.","['G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06V10/32', 'G06V10/774', 'G06V10/803', 'G06V20/56', 'B60W2420/403', 'B60W2420/408', 'B60W2555/20', 'B60W60/001', 'G06N20/00']"
US10984272B1,Defense against adversarial attacks on neural networks,"A neural network is trained to defend against adversarial attacks, such as by preparing an input image for classification by a neural network where the input image includes a noise-based perturbation. The input image is divided into source patches. Replacement patches are selected for the source patches by searching a patch library for candidate patches available for replacing ones of those source patches, such as based on sizes of those source patches. A denoised image reconstructed from a number of replacement patches is then output to the neural network for classification. The denoised image may be produced based on reconstruction errors determined for individual candidate patches identified from the patch library. Alternatively, the denoised image may be selected from amongst a number of candidate denoised images. A set of training images is used to construct the patch library, such as based on salient data within patches of those training images.","['G06F16/55', 'G06K9/03', 'G06K9/4671', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T5/002', 'G06T5/70', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06K2009/4695', 'G06N3/045']"
US11105942B2,Generative adversarial network seismic data processor,A method can include generating seismic data; training a generator network utilizing at least a portion of the generated seismic data and a discriminator network; and outputting a trained generator network.,"['G01V1/282', 'G01V1/364', 'G01V20/00', 'G01V99/005', 'G01V99/00']"
US11694085B2,Optimizing supervised generative adversarial networks via latent space regularizations,"A method of training a generator G of a Generative Adversarial Network (GAN) includes receiving, by an encoder E, a target data Y; receiving, by the encoder E, an output G(Z) of the generator G, where the generator G generates the output G(Z) in response to receiving a random sample Z and where a discriminator D of the GAN is trained to distinguish which of the G(Z) and the target data Y; training the encoder E to minimize a difference between a first latent space representation E(G(Z)) of the output G(Z) and a second latent space representation E(Y) of the target data Y, where the output G(Z) and the target data Y are input to the encoder E; and using the first latent space representation E(G(Z)) and the second latent space representation E(Y) to constrain the training of the generator G.","['G06N3/084', 'G06F18/217', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T3/4053', 'G06T5/00', 'G06T5/001', 'G06V10/776', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US11927967B2,Using machine learning models for generating human-like trajectories,"In one embodiment, a computing system of a vehicle may access sensor data associated with a surrounding environment of a vehicle. The system may generate, based on the sensor data, a first trajectory having one or more first driving characteristics for navigating the vehicle in the surrounding environment. The system may generate a second trajectory having one or more second driving characteristics by modifying the one or more first driving characteristics of the first trajectory. The modifying may use adjustment parameters based on one or more human-driving characteristics of observed human-driven trajectories such that the one or more second driving characteristics satisfy a similarity threshold relative to the one or more human-driving characteristics. The system may determine, based on the second trajectory, vehicle operations to navigate the vehicle in the surrounding environment.","['G05D1/0088', 'G05D1/228', 'G05D1/0221', 'G05D1/0214', 'G05D1/027', 'G05D1/22', 'G05D1/24', 'G05D1/617', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06V10/774', 'G06V10/82', 'G06V20/56', 'G05D2201/0213']"
US11565709B1,Vehicle controller simulations,"Techniques for generating simulations for evaluating a performance of a controller of an autonomous vehicle are described. A computing system may evaluate the performance of the controller to navigate the simulation and respond to actions of one or more objects (e.g., other vehicles, bicyclists, pedestrians, etc.) in a simulation. Actions of the objects in the simulation may be controlled by the computing system (e.g., by an artificial intelligence) and/or one or more users inputting object controls, such as via a user interface. The computing system may calculate performance metrics associated with the actions performed by the vehicle in the simulation as directed by the autonomous controller. The computing system may utilize the performance metrics to verify parameters of the autonomous controller (e.g., validate the autonomous controller) and/or to train the autonomous controller utilizing machine learning techniques to bias toward preferred actions.","['B60W50/06', 'G05B17/02', 'B60W50/00', 'B60W50/045', 'G05B13/027', 'G05B13/042', 'G06N20/00', 'G06N3/088', 'G08G1/0112', 'G08G1/0133', 'G08G1/0145', 'B60W2050/0075', 'G08G1/167']"
US11954610B2,Active surveillance and learning for machine learning model authoring and deployment,"Techniques are described for performing active surveillance and learning for machine learning (ML) model authoring and deployment workflows. In an embodiment, a method comprises applying, by a system comprising a processor, a primary ML model trained on a training dataset to data samples excluded from the training dataset to generate inferences based on the data samples. The method further comprises employing, by the system, one or more active surveillance techniques to regulate performance of the primary ML model in association with the applying, wherein the one or more active surveillance techniques comprise at least one of, performing a model scope evaluation of the primary ML model relative to the data samples or using a domain adapted version of the primary ML model to generate the inferences.","['G06N3/08', 'G16H40/20', 'G06N5/04', 'G06F11/0793', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06F11/0751', 'G06F11/302', 'G06F11/3409', 'G06F2201/865', 'G06N20/10', 'G06N5/01', 'G06N7/01']"
US10783401B1,Black-box adversarial attacks on videos,"A method for generating black-box adversarial attacks on video recognition models is provided, comprising a) passing input video frames into a public image model, to obtain pixel-wise tentative perturbations; b) partitioning the tentative perturbations into tentative perturbation patches; c) estimating the rectification weight required for each patch, via querying the target video model; d) applying the patch-wise rectification weight on the patches, to obtain the rectified pixel-wise perturbations; e) applying one step projected gradient descent (PGD) perturbation on the input video, according to the rectified pixel-wise perturbations; and f) iteratively performing steps a)-e) until an attack succeeds or a query limit is reached. Systems and networks therefor are also provided.","['G06F16/73', 'G06K9/6257', 'G06F18/2148', 'G06F18/217', 'G06F18/2431', 'G06F21/577', 'G06K9/00765', 'G06K9/6262', 'G06K9/628', 'G06N20/00', 'G06N3/0442', 'G06N3/0464', 'G06N3/047', 'G06N3/086', 'G06N3/088', 'G06N7/005', 'G06N7/01', 'G06V10/764', 'G06V10/7747', 'G06V10/776', 'G06V10/82', 'G06V20/41', 'G06V20/49', 'G06F2221/034']"
AU2019430859B2,Generative adversarial mechanism and attention mechanism-based standard face generation method,"A generative adversarial mechanism and attention mechanism-based standard face generation method, comprising: a dataset design step, constructing, according to database-related annotation data, face code having a plurality of non-limiting factors for a face image, and taking the code and the face image as inputs of a model; a model design and training step, using a generative adversarial mechanism and an attention mechanism to design a corresponding network structure, and using the constructed data pair to perform model training, so as to obtain a network model weight; and a model prediction step, predicting the acquired face image by means of the model. The present invention applies deep learning network technology to standard face generation to generate a colour, front-facing, and standard face image under normal light illumination. The method using a deep learning network is capable of obtaining an accurate standard face photograph, reducing the difficulty of matching with data in a single-sample database, and laying a solid foundation for subsequent face feature extraction and single-sample facial recognition.","['G06N3/09', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094']"
US11694248B2,Deep generation of user-customized items,"The present disclosure relates to a personalized fashion generation system that synthesizes user-customized images using deep learning techniques based on visually-aware user preferences. In particular, the personalized fashion generation system employs an image generative adversarial neural network and a personalized preference network to synthesize new fashion items that are individually customized for a user. Additionally, the personalized fashion generation system can modify existing fashion items to tailor the fashion items to a user's tastes and preferences.","['G06Q30/0621', 'G06F16/532', 'G06F16/535', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06Q30/0631', 'G06Q30/0643', 'G06T11/00']"
US20250265312A1,Efficient Training and Accuracy Improvement of Imaging Based Assay,"The present disclosure relates to devices, apparatuses and methods of improving the accuracy of image-based assay, that uses imaging system having uncertainties or deviations (imperfection) compared with an ideal imaging system. One aspect of the present invention is to add the monitoring marks on the sample holder, with at least one of their geometric and/optical properties of the monitoring marks under predetermined and known, and taking images of the sample with the monitoring marks, and training a machine learning model using the images with the monitoring mark.","['G06F18/2148', 'G06T7/0012', 'G06N20/00', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06T7/10', 'G06T7/11', 'G06T7/62', 'G06T7/70', 'G06V10/22', 'G06T2207/10061', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30024', 'G06T2207/30204']"
US12175641B2,Restoring degraded digital images through a deep learning framework,"The present disclosure relates to systems, methods, and non-transitory computer readable media for accurately, efficiently, and flexibly restoring degraded digital images utilizing a deep learning framework for repairing local defects, correcting global imperfections, and/or enhancing depicted faces. In particular, the disclosed systems can utilize a defect detection neural network to generate a segmentation map indicating locations of local defects within a digital image. In addition, the disclosed systems can utilize an inpainting algorithm to determine pixels for inpainting the local defects to reduce their appearance. In some embodiments, the disclosed systems utilize a global correction neural network to determine and repair global imperfections. Further, the disclosed systems can enhance one or more faces depicted within a digital image utilizing a face enhancement neural network as well.","['G06T5/77', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/18', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20221', 'G06T2207/30201']"
AU2023220143B2,System and method for implementing an artificial intelligence security platform,The present invention relates to an artificial intelligence (Al) platform to simplify Al security for enterprise and other applications. An embodiment of the present invention is directed to implementing an Al security platform that secures AI/ML models while keeping the configuration and implementation simple and streamlined. An embodiment of the present invention is directed to delivering visibility on Al models across an entire organization as well as other corporate structures.,"['H04L41/16', 'H04L63/1408', 'H04L63/1433', 'H04L63/1466', 'H04L63/20']"
US20200242774A1,Semantic image synthesis for generating substantially photorealistic images using neural networks,"A user can create a basic semantic layout that includes two or more regions identified by the user, each region being associated with a semantic label indicating a type of object(s) to be rendered in that region. The semantic layout can be provided as input to an image synthesis network. The network can be a trained machine learning network, such as a generative adversarial network (GAN), that includes a conditional, spatially-adaptive normalization layer for propagating semantic information from the semantic layout to other layers of the network. The synthesis can involve both normalization and de-normalization, where each region of the layout can utilize different normalization parameter values. An image is inferred from the network, and rendered for display to the user. The user can change labels or regions in order to cause a new or updated image to be generated.","['G06T7/11', 'G06T11/001', 'G06T15/00', 'G06N20/10', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T11/60', 'G06T2207/20084']"
US11651205B2,"Method for training a generative adversarial network (GAN), generative adversarial network, computer program, machine-readable memory medium, and device","A method for training a generative adversarial network, in particular a Wasserstein generative adversarial network. The generative adversarial network includes a generator and a discriminator, the generator and the discriminator being artificial neuronal networks. The method includes training the discriminator. In the step of training the discriminator, a parameter of the discriminator is adapted as a function of a loss function, the loss function including a term that represents the violation of the Lipschitz condition as a function of a first input datum and a second input datum and as a function of a first output of the discriminator when processing the first input datum and a second output of the discriminator when processing the second input datum, the second input datum being created starting from the first input datum by applying the method of the virtual adversarial training.","['G06K9/6234', 'G06N3/08', 'G06F18/2132', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/094']"
US20210150672A1,Method and apparatus for enhancing vehicle damage image on the basis of a generative adversarial network,"Embodiments of the present specification provide a method and system for improving the quality of a vehicle damage image on the basis of a GAN network. During operation, the system obtains a first vehicle damage image and inputs the first vehicle damage image to a machine-learning model to obtain a second vehicle damage image. The machine-learning model is trained using a plurality of labeled samples of vehicle damage images, and the second vehicle damage image has a better quality than the first vehicle damage image.","['G06T5/001', 'G06N3/08', 'G06F18/214', 'G06F18/22', 'G06K9/6215', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06T5/00', 'G06T5/60', 'G06T7/0002', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G06T2207/30248']"
US12217387B2,"Learning method, learning system, learned model, program, and super resolution image generating device","Provided are a learning method and a learning system of a generative model, a program, a learned model, and a super resolution image generating device that can handle input data of any size and can suppress the amount of calculation at the time of image generation. A learning method according to an embodiment of the present disclosure is a learning method for performing machine learning of a generative model that estimates, from a first image, a second image including higher resolution image information than the first image, the method comprising using a generative adversarial network including a generator which is the generative model and a discriminator which is an identification model that identifies whether provided data is data of a correct image for learning or data derived from an output from the generator and implementing a self-attention mechanism only in a network of the discriminator among the generator and the discriminator.","['A61B5/00', 'A61B6/03', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/40', 'G06T3/4046', 'G06T3/4053', 'G06T5/20', 'G06T5/70', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US11544905B2,Method and apparatus for providing virtual clothing wearing service based on deep-learning,"A method and apparatus provide a virtual clothing wearing service based on deep-learning. A virtual clothing wearing server based on deep-learning includes a communicator configured to receive a user image and a v clothing image; a memory configured to store a program including first and second deep-learning models; a processor configured to generate an image of virtually dressing a virtual wearing clothing on a user. The program is configured to: generate, by the first deep-learning model, a transformed virtual wearing clothing image by transforming the virtual wearing clothing image in accordance with a body of the user in the user image based on the user image and the virtual wearing clothing image, and generate, by the second deep-learning model, the virtual wearing person image by dressing the transformed virtual wearing clothing on the body of the user based on the user image and the transformed virtual wearing clothing image.","['G06T3/08', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06Q30/0643', 'G06T19/00', 'G06T3/0093', 'G06T3/18', 'G06T5/50', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V40/10', 'G06T2207/20221']"
CN107968962B,A video generation method for two non-adjacent images based on deep learning,"The video generation method of the invention discloses a kind of non-conterminous image of two frames based on deep learning, belong to confrontation study and video generates field, N frame input picture is obtained including carrying out linear interpolation processing to the non-conterminous image of two frames, N frame input picture is inputted into the first generator, obtains the video image that the N frame between the non-conterminous image of two frames obscures；N frame video image is inputted into trained second generator, obtains new N frame clearly video image, and the non-conterminous image of two frames and new N frame video image connect generation video.Wherein, dual training is used from convolutional network is encoded using complete the first depth of convolution layer building, obtain trained first generator, using full convolutional layer and parallel link the second depth of building is carried out from convolutional network is encoded, and using dual training, obtains trained second generator.The video quality that the present invention generates is good, and the time is long.","['H04N21/85', 'G06N3/045', 'H04N21/44016', 'H04N21/845']"
WO2021051561A1,"Adversarial defense method and apparatus for image classification network, electronic device, and computer-readable storage medium","Disclosed are an adversarial defense method and apparatus for an image classification network, an electronic device, and a computer-readable storage medium, belonging to the technical field of image classification. The method comprises: inputting an original image sample and an adversarial attack sample into a deep neural network so as to extract input features of target layers, the number of which is greater than a predetermined number, of the deep neural network; generating a loss function of the deep neural network according to the input features to serve as an adversarial defense denoiser; using the adversarial defense denoiser to denoise the adversarial attack sample to obtain a denoised adversarial attack sample; regularizing the loss function of the deep neural network to obtain a deep neural network subjected to regularization; and inputting the original image sample and the denoised adversarial attack sample into the deep neural network subjected to regularization to obtain a classification result of an original image. By means of the solution of the present application, the defense capability of an image classification deep neural network can be effectively improved.","['G06F18/241', 'G06N3/045']"
US20230370491A1,System and method for cyber exploitation path analysis and response using federated networks,"A system and method for cyber exploitation path analysis and response using federated networks to minimize network exposure and maximize network resilience, with the ability to simulate complex and large scale network traffic through the use of federated training networks, by gathering network entity information, establishing baseline behaviors for each entity, and monitoring each entity for behavioral anomalies that might indicate cybersecurity concerns. Further, the system and method involve incorporating network topology information into the analysis by generating a model of the network, annotating the model with risk and criticality information for each entity in the model and with a vulnerability level between entities, and using the model to evaluate cybersecurity risks to the network. Lastly, network attack path analysis and automated task planning for minimizing network exposure and maximizing resiliency is performed with machine learning, generative adversarial networks, hierarchical task networks, and Monte Carlo search trees.","['H04L63/1433', 'G06N3/0475', 'G06N3/094', 'G06N3/098', 'G06N5/01', 'H04L63/102', 'H04L63/1416', 'H04L63/1425', 'H04L63/20', 'G06N20/00', 'G06N3/084']"
US11625553B2,"Rapid and accurate modeling of a building construction structure including estimates, detailing, and take-offs using artificial intelligence","Some embodiments relate to generating three dimensional virtual representations of a building construction structure based on two-dimensional real-world construction plans, such as architectural plans or building plans. Some embodiments further produce autonomous, near real-time, and highly accurate and comprehensive building take-offs, complete construction detailing or estimates, detailed bill of materials, plan analysis (including detection of a number of non-standardized objects, such as doors or windows), as well as transforming 2D drawings into 3D and/or providing Building Information Modeling (BIM). The two dimensional real-world architectural plan can include multivariate non-standardized architectural symbols, which define numerous objects including trees, bathrooms, doors, stairs, windows, and floor finishes, lines, including solid, hollow, dashed and dotted lines, which define features including internal or external walls, windows, doors, stairs, property boundaries, easements, footpaths, rooflines, driveways, rights of way, paving stones, landscaping, water, power, drainage, and dimensions, shading, and patterns which define materials and areas on the two dimensional real-world architectural plan, and text which indicate the purposes of the rooms, dimensions, features, construction methods, and regulatory standards.","['G06K9/6201', 'G06F18/22', 'G06Q50/08', 'G06F18/214', 'G06F30/13', 'G06F30/27', 'G06K9/6256', 'G06Q10/06313', 'G06Q10/0875', 'G06Q10/103', 'G06V10/7753', 'G06V10/82', 'G06V30/413', 'G06F40/30', 'G06T17/00']"
US11150670B2,Autonomous behavior generation for aircraft,"Apparatus and methods for training a machine learning algorithm (MLA) to control a first aircraft in an environment that comprises the first aircraft and a second aircraft are described. Training of the MLA can include: the MLA determining a first-aircraft action for the first aircraft to take within the environment; sending the first-aircraft action from the MLA; after sending the first-aircraft action, receiving an observation of the environment and a reward signal at the MLA, the observation including information about the environment after the first aircraft has taken the first-aircraft action and the second aircraft has taken a second-aircraft action, the reward signal indicating a score of performance of the first-aircraft action based on dynamic and kinematic properties of the second aircraft; and updating the MLA based on the observation of the environment and the reward signal.","['G05D1/101', 'B64C13/18', 'B64D39/00', 'G05B13/0265', 'G05D1/0088', 'G06N3/006', 'G06N3/08', 'G06N3/092', 'G06N3/096', 'G06N3/044', 'G06N3/045']"
US20240008955A1,Automated Processing of Dental Scans Using Geometric Deep Learning,"Machine learning, or geometric deep learning, applied to various dental processes and 5 solutions. In particular, generative adversarial networks apply machine learning to smile design—finished smile, appliance rendering, scan cleanup, restoration appliance design, crown and bridges design, and virtual debonding. Vertex and edge classification apply machine learning to gum versus teeth detection, teeth type segmentation, and brackets and other orthodontic hardware. Regression applies machine learning to coordinate systems, diagnostics, case complexity, and 0 prediction of treatment duration. Automatic encoders and clustering apply machine learning to grouping of doctors, or technicians, and preferences.","['A61C7/002', 'A61C13/0004', 'G06T5/50', 'G06T5/60', 'G06T5/77', 'G06V10/82', 'G06V20/64', 'A61C2007/004', 'G06T2200/04', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036']"
US10665326B2,Deep proteome markers of human biological aging and methods of determining a biological aging clock,"A method of creating a biological aging clock for a subject can include: (a) receiving a proteome signature derived from a tissue or organ of the subject; (b) creating input vectors based on the proteome signature; (c) inputting the input vectors into a machine learning platform; (d) generating a predicted biological aging clock of the tissue or organ based on the input vectors by the machine learning platform, wherein the biological aging clock is specific to the tissue or organ; and (e) preparing a report that includes the biological aging clock that identifies a predicted biological age of the tissue or organ.","['G16B20/00', 'A61K35/28', 'C12N5/0606', 'G16B40/00', 'G16B40/20', 'G16B40/30', 'G16B5/00', 'G16B25/10']"
US10325673B2,Deep transcriptomic markers of human biological aging and methods of determining a biological aging clock,"A method of creating a biological aging clock for a subject can include: (a) receiving a transcriptome signature derived from a tissue or organ of the subject; (b) creating input vectors based on the transcriptome signature; (c) inputting the input vectors into a machine learning platform; (d) generating a predicted biological aging clock of the tissue or organ based on the input vectors by the machine learning platform, wherein the biological aging clock is specific to the tissue or organ; and (e) preparing a report that includes the biological aging clock that identifies a predicted biological age of the tissue or organ.","['G16B5/00', 'G16B30/10', 'G16B40/00', 'G16B40/20', 'G16B40/30']"
US20210097343A1,Method and apparatus for managing artificial intelligence systems,"Systems to quickly validate that no runtime exceptions occur when hyperparameter tuning and for employing automatic training model generators before training are disclosed. The system may include operations comprising investigating a hyperparameter space and retrieving a plurality of hyperparameters from the hyperparameter space based on a hyperparameter optimization task, identifying at least one of features, characteristics, or keywords of hyperparameters associated with a model generation task and retrieving the plurality of hyperparameters based on the identification. The operations may further include determining which of the retrieved hyperparameters returns the fastest model run time of the model generation task. The operations may further include launching a model training using the hyperparameters determined to return the fastest model run time of the model generation task and notifying a user and terminating the model training if one or more programmatic errors occur in the launched model training.","['G06K9/6257', 'G06N3/088', 'G06F18/214', 'G06F18/2148', 'G06F18/2178', 'G06F18/24133', 'G06F18/2415', 'G06K9/6263', 'G06K9/6277', 'G06N20/00', 'G06N3/045', 'G06N3/044', 'G06N7/01']"
CN111242290B,A Lightweight Privacy-Preserving Generative Adversarial Network System,"The invention relates to a lightweight privacy protection generation countermeasure network system, wherein entities comprise a data provider DS, a service provider SP and a first edge serverS 1And a second edge serverS 2The software comprises an LP-GAN security computing framework; the LP-GAN security computation framework comprises a security generation model SG and a security discrimination model SD. The invention can ensure the double privacy of the data and the model of the user.","['G06N3/045', 'G06F21/6245', 'G06N3/08']"
US11403565B2,Method and system for generating a learning path using machine learning,"This disclosure relates generally to information processing, and more particularly to method and system for generating a learning path for a topic. The method may include extracting a plurality of key phrases from each of a plurality of learning resources related to the topic, determining a learning context for each of the plurality of learning resources based on the plurality of key phrases, forming a set of key phrase groups from among the plurality of key phrases for each of the plurality of learning resources, determining a relationship among the key phrases in each of the set of key phrase groups based on the learning context, generating a structured graph for the plurality of learning resources based on the plurality of key phrases and the relationship among the key phrases, and generating the learning path for the topic based on the structured graph for the plurality of learning resources.","['G06N20/20', 'G09B7/00', 'G06F16/22', 'G06F16/954', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/02', 'G06N7/01']"
US11610139B2,System and method for the latent space optimization of generative machine learning models,"A system and method for optimizing the latent space in generative machine learning models, and applications of the optimizations for use in the de novo generation of molecules for both ligand-based and pocket-based generation. The ligand-based optimizations comprise a tunable reward system based on a multi-property model and further define new measurable metrics: molecular novelty and uniqueness. The pocket-based optimizations comprise an initial multi-property optimization followed up by either a seed-based optimization or a relaxed-based optimization.","['G06N3/088', 'G06F16/951', 'G06F18/22', 'G06K9/6215', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N5/022', 'G06N7/01', 'G06V10/751', 'G06V10/82', 'G16B15/00', 'G16B15/30', 'G16B40/00', 'G16B40/20', 'G16B45/00', 'G16B50/10', 'G16C20/50', 'G16C20/70', 'G06N3/044', 'G06N3/048', 'G06N3/096', 'G16C20/30', 'G16C20/90']"
US10910094B2,Computer-based diagnostic system,A computer-based diagnostic system includes an image generation unit adapted to generate tomographic images of a patient's organ; a deep machine learning unit configured to process generated tomographic images of the patient's organ to classify organ regions of diseased functional tissue of the patient's organ as belonging to one of a set of abnormal image patterns using trained deep neural networks; and a clinical decision support unit adapted to process classification results of the deep machine learning unit to calculate a diagnostic result output via an interface of the clinical decision support unit.,"['G16H30/40', 'A61B6/032', 'A61B6/5217', 'G06F18/214', 'G06F18/24', 'G06F18/241', 'G06F18/2431', 'G06K9/6267', 'G06K9/628', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T7/0016', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G16H30/20', 'G16H50/20', 'G06K2209/051', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/03', 'G06V2201/031']"
CN113050640B,Industrial robot path planning method and system based on generation of countermeasure network,"The invention realizes an industrial robot path planning method based on generation of a countermeasure network by a method in the field of artificial intelligence processing. The method specifically comprises the following steps: firstly, reading information related to a model of a robot, then analyzing the information content and establishing the robot model, then constructing a simulation environment of the robot, constructing and constructing a track planning environment and a data generation environment in the simulation environment, obtaining a planning result by the track planning environment, finally inputting the planning result into the data generation environment, forming a data set for neural network training together with an external scene, inputting the data set into a machine learning environment applying a neural network method, and outputting the final output result of the machine learning environment through a visual front end, so that the method has better effect on indexes such as success rate and the like compared with the prior art. On the basis, a system architecture suitable for the method is also realized.","['G05D1/0223', 'G05D1/0221', 'G05D1/0276']"
US20220152116A1,Multi-stage personalized longevity therapeutics,"A method of treating senescence in a subject can include applying a senoremediation drug treatment protocol to the subject in order to rescue one or more first cells in the subject, wherein the senoremediation drug treatment protocol is derived from a computational transcriptome analysis of the tissue or organ of the subject. The method can include applying a senolytic drug treatment protocol to the subject in order to remove one or more second cells in the subject. The method can include introducing stem cells into a tissue and/or organ of the subject in order to rejuvenate one or more tissue cells in the tissue and/or one or more organ cells in the organ. The method can include carrying out a reinforcement step that includes one or more actions that prevent further senescence or degradation of the tissue or organ.","['A61K35/28', 'A61K31/12', 'A61K31/192', 'A61K31/195', 'A61K31/196', 'A61K31/26', 'A61K31/352', 'A61K31/353', 'A61K31/416', 'A61K31/436', 'A61K31/44', 'A61K31/4412', 'A61K31/4439', 'A61K31/453', 'A61K31/4709', 'A61K31/4745', 'A61K31/506', 'A61K31/519', 'A61K31/585', 'A61K35/36', 'A61K38/16', 'A61K38/17', 'A61K45/06', 'A61K2039/505']"
US11126891B2,Systems and methods for simulating sensor data using a generative model,"System, methods, and other embodiments described herein relate to simulating sensor data for a scene. In one embodiment, a method includes, in response to receiving a request to generate simulated sensor data for the scene, acquiring simulation data about the scene. The simulation data includes at least simulated information about the scene that is computer-generated. The method includes computing the simulated sensor data using a generative neural network that accepts the simulation data as an input and produces the simulated sensor data as an output. The simulated sensor data is a simulated perception of the scene by a sensor. The method includes providing the simulated sensor data as part of the scene.","['G06T19/00', 'G06K9/6257', 'G06F18/2148', 'G06F18/251', 'G06K9/6289', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06N5/04', 'G06T19/003', 'G06V10/7747', 'G06V10/776', 'G06V10/82', 'G06F30/20', 'G06F30/27']"
US11394742B2,Detecting trojan neural networks,"One or more computer processors generate a plurality of adversarial perturbations associated with a model, wherein the plurality of adversarial perturbations comprises a universal perturbation and one or more per-sample perturbations. The one or more computer processors identify a plurality of neuron activations associated with the model and the plurality of generated adversarial perturbations. The one or more computer processors maximize the identified plurality of neuron activations. The one or more computer processors determine the model is a Trojan model by leveraging one or more similarities associated with the maximized neuron activations and the generated adversarial perturbations.","['G06V10/751', 'H04L63/145', 'G06F18/22', 'G06F21/554', 'G06K9/6215', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/454', 'G06V10/82']"
US10984905B2,Artificial intelligence for physiological quantification in medical imaging,"For quicker estimation of physiological parameters than using a numerical solution, a machine-learned network is applied. The PV loop may be estimated for a specific patient in real-time without invasive pressure measurements. Synthetic data instead of or in addition to actual patient examples may be used to machine train the network, providing a broader and/or controlled range of examples for more accurate estimation even in rarely occurring pathologies. The synthetic data may be generated by a generative adversarial network.","['G16H30/20', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G16H10/60', 'G16H50/20', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
CN109131348B,A decision-making method for intelligent vehicle driving based on generative adversarial network,"The invention discloses an intelligent vehicle driving decision method based on a generative countermeasure network, which comprises the steps of establishing a driving decision model and driving decision control. The invention processes the driving image based on the generating type countermeasure network, can process the vehicle driving path planning under the non-ideal road condition, and improves the performability of the end-to-end neural network. According to the method, the most essential characteristics of the driving image are extracted through the generative antagonistic network processing, the driving data of different sources are mapped into a unified virtual domain, the application of reinforcement learning to the real vehicle is realized, the generalization of the network is improved, and the capability of adapting to different samples is realized. For the input of the driving image, the input image used each time is the first few frames of video images of the time stamp at the current time. The predicted image obtained by the method can obtain a real predicted image to a greater extent to be used as judgment of the driving decision plan. The method is used as a basis for predicting the optimal decision of the vehicle, and a bridge for strengthening learning to the application of the real vehicle is established.","['B60W50/00', 'B60W2050/0028']"
US11210836B2,Applying artificial intelligence to generate motion information,"This disclosure describes techniques that include generating, based on a description of a scene, a movie or animation that represents at least one possible version of a story corresponding to the description of the scene. This disclosure also describes techniques for training a machine learning model to generate predefined data structures from textual information, visual information, and/or other information about a story, an event, a scene, or a sequence of events or scenes within a story. This disclosure also describes techniques for using GANs to generate, from input, an animation of motion (e.g., an animation or a video clip). This disclosure also describes techniques for implementing an explainable artificial intelligence system that may provide end users with information (e.g., through a user interface) that enables an understanding of at least some of the decisions made by the AI system.","['G06F40/216', 'G06F16/345', 'G06F16/738', 'G06F16/9024', 'G06F18/22', 'G06F40/205', 'G06F40/279', 'G06F40/30', 'G06F40/35', 'G06K9/00335', 'G06K9/00342', 'G06K9/00718', 'G06K9/00744', 'G06K9/6215', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N5/04', 'G06T13/40', 'G06T13/80', 'G06T7/251', 'G06V20/41', 'G06V20/46', 'G06V40/20', 'G06V40/23', 'G06N7/01', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11170166B2,Neural typographical error modeling via generative adversarial networks,"Systems and processes for operating an intelligent automated assistant are provided. In one example process, one or more input words can be received. The process can extract, based on the one or more input words, seed data for unsupervised training of a first learning network. Training data that includes a collection of words having typographical errors for the first learning network can be obtained. The process can determine, using the first learning network and based on the seed data and the training data, one or more output words having a probability distribution corresponding to a probability distribution of the training data. The one or more output words can include typographical errors. The process can generate, based on the determined one or more output words, a data set for supervised training of a second learning network. The second learning network can provide one or more typographical error suggestions.","['G06F40/232', 'G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01']"
CN111126386B,Adversarial Learning-Based Sequential Domain Adaptation in Scene Text Recognition,"The invention belongs to the technical field of artificial intelligence, and particularly relates to a field adaptation method based on a text recognition task of a machine vision scene. The method comprises the following steps: constructing a CNN-LSTM network and an attention network; combining the two into a scene text recognition network; inputting scene images of a source domain and a target domain into a scene text recognition network, extracting image features from the input scene images by CNN-LSTM, recoding the image features by an attention network, extracting corresponding features of each character, and realizing segmentation of text information in the images into character level information; and finally, constructing a domain classification network by using a transfer learning technology based on countermeasure learning, and forming a countermeasure generation network together with a scene text recognition network, so that the model can be effectively adapted to a target domain. According to the invention, a small amount of target domain calibration samples are fully utilized, the problem of sample scarcity frequently occurring in an actual scene text recognition task is solved, and the recognition effect is improved.","['G06V20/63', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V30/10', 'Y02T10/40']"
US11829879B2,Detecting adversarial attacks through decoy training,"Decoy data is generated from regular data. A deep neural network, which has been trained with the regular data, is trained with the decoy data. The trained deep neural network, responsive to a client request comprising input data, is operated on the input data. Post-processing is performed using at least an output of the operated trained deep neural network to determine whether the input data is regular data or decoy data. One or more actions are performed based on a result of the performed post-processing.","['G06F18/214', 'G06N3/08', 'G06F17/10', 'G06F21/56', 'G06F21/566', 'G06N3/04', 'G06N3/045', 'G06N3/0499', 'G06N3/09', 'H04L63/1416', 'H04L63/1466', 'G06T2207/20081']"
US11762391B2,Systems and methods for training predictive models for autonomous devices,Systems and methods for training machine-learned models are provided. A method can include receiving a rasterized image associated with a training object and generating a predicted trajectory of the training object by inputting the rasterized image into a first machine-learned model. The method can include converting the predicted trajectory into a rasterized trajectory that spatially corresponds to the rasterized image. The method can include utilizing a second machine-learned model to determine an accuracy of the predicted trajectory based on the rasterized trajectory. The method can include determining an overall loss for the first machine-learned model based on the accuracy of the predictive trajectory as determined by the second machine-learned model. The method can include training the first machine-learned model by minimizing the overall loss for the first machine-learned model.,"['G05D1/0221', 'B60W60/0011', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G05D2201/0213']"
CN113379764B,Pathological image segmentation method based on domain antagonism self-supervision learning,"The invention relates to a pathological image segmentation method based on domain antagonism self-supervision learning. Comprising the following steps: acquiring a pathology image and establishing a pathology image self-supervision data set; establishing a domain countermeasure self-supervision model; deep learning training is carried out on the domain countermeasure self-supervision model by using the pathology image self-supervision data set; establishing a pathological image segmentation model; initializing a pathological image segmentation model by using a domain countermeasure self-supervision model after deep learning; performing pixel level labeling on a focus area in a pathological image to establish a pathological image segmentation data set; performing deep learning training on the pathological image segmentation model by using the pathological image segmentation data set; and segmenting the unknown focus area of the pathological image by using the pathological image segmentation model after the deep learning training. The method adopts a domain countermeasure self-supervision learning method, effectively relieves the dependence of the segmentation model on a large number of manual labels and solves the problem of the segmentation performance fluctuation of the model on different domains.","['G06F18/214', 'G06F17/16', 'G06T3/60', 'G06T5/70', 'G06T7/11', 'G06T7/62', 'Y02T10/40']"
US11010637B2,Generative adversarial network employed for decentralized and confidential AI training,"A computer-implemented method is presented for constructing a trained model for a plurality of edge classifiers in a network having a federated classifier, a generator, and a discriminator. The method includes obtaining edge trained models from the plurality of edge devices, each edge trained model being trained independently with data from private data of each edge, training the generator model and discriminator model by employing the edge trained models and an unlabeled set of data by employing a generative adversarial training procedure, generating data samples by the trained generator model, training the federated classifier with the data samples from the generator model, and deploying the trained model back to the plurality of edge devices.","['G06N3/088', 'G06K9/6256', 'G06F18/214', 'G06F18/2431', 'G06K9/628', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06N3/098', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US11605156B2,Iterative image inpainting with confidence feedback,"Methods and systems are provided for accurately filling holes, regions, and/or portions of images using iterative image inpainting. In particular, iterative inpainting utilize a confidence analysis of predicted pixels determined during the iterations of inpainting. For instance, a confidence analysis can provide information that can be used as feedback to progressively fill undefined pixels that comprise the holes, regions, and/or portions of an image where information for those respective pixels is not known. To allow for accurate image inpainting, one or more neural networks can be used. For instance, a coarse result neural network (e.g., a GAN comprised of a generator and a discriminator) and a fine result neural network (e.g., a GAN comprised of a generator and two discriminators). The image inpainting system can use such networks to predict an inpainting image result that fills the hole, region, and/or portion of the image using predicted pixels and generates a corresponding confidence map of the predicted pixels.","['G06T5/005', 'G06T5/77', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
US11443133B2,Computer vision system for industrial equipment gauge digitization and alarms,"A system for analog gauge monitoring uses a machine learning model for computer vision that is trained using synthetic training data generated based on one or a few images of the gauge being monitored and a geometric model describing the scale and the indicator of the gauge. In some embodiments, the synthetic training data is generated using an image model implemented as a generative adversarial network (GAN) type neural network and trained to modify an image of a given gauge such that the gauge face is preserved while the gauge indicator is added to or removed from the image of the given gauge for any given gauge.","['G06N3/088', 'G06K9/623', 'G06F18/2113', 'G06F18/2155', 'G06K9/6259', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V10/98', 'G06V2201/02']"
US11636375B2,Adversarial learning of driving behavior,"Embodiments described herein disclose methods and systems for adversarial learning in autonomous vehicle path modeling. The systems and methods collect states of the vehicle in the environment to predict a path. The predicted path is compared for variance from an actual path. The variance between the paths, in light of other data, is used to modify the driving models, to create more accurate representations of expert driving in autonomous vehicle path generation.","['G06N20/00', 'B60W30/0956', 'B60W60/001', 'B60W60/0015', 'G05D1/0088', 'G05D1/0221', 'G08G1/0112', 'G08G1/0129', 'B60W2556/10']"
US10165259B2,Generating novel views of a three-dimensional object based on a single two-dimensional image,"Embodiments are directed towards providing a target view, from a target viewpoint, of a 3D object. A source image, from a source viewpoint and including a common portion of the object, is encoded in 2D data. An intermediate image that includes an intermediate view of the object is generated based on the data. The intermediate view is from the target viewpoint and includes the common portion of the object and a disoccluded portion of the object not visible in the source image. The intermediate image includes a common region and a disoccluded region corresponding to the disoccluded portion of the object. The disoccluded region is updated to include a visual representation of a prediction of the disoccluded portion of the object. The prediction is based on a trained image completion model. The target view is based on the common region and the updated disoccluded region of the intermediate image.","['G06V10/82', 'G06F18/214', 'G06K9/6256', 'G06T11/00', 'G06T15/205', 'G06T7/194', 'G06T7/70', 'G06T7/97', 'G06V10/7715', 'H04N13/0048', 'H04N13/0275', 'H04N13/0282', 'H04N13/161', 'H04N13/275', 'H04N13/282', 'G06T2207/10012', 'H04N13/111']"
US20200034948A1,Ml-based methods for pseudo-ct and hr mr image estimation,The present disclosure describes a computer-implemented method of transforming a low-resolution MR image to a high-resolution MR image using a deep CNN-based MRI SR network and a computer-implemented method of transforming an MR image to a pseudo-CT (sCT) image using a deep CNN-based sCT network. The present disclosure further describes a MR image-guided radiation treatment system that includes a computing device to implement the MRI SR and CT networks and to produce a radiation plan based in the resulting high resolution MR images and sCT images.,"['A61N5/1049', 'A61B6/5258', 'A61N5/1067', 'G06F17/18', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06T3/4053', 'G06T5/002', 'G06T5/70', 'A61B6/032', 'A61B6/5247', 'A61N2005/1055', 'A61N5/1039', 'G06N20/10', 'G06N5/01', 'G06N5/025', 'G06N7/01', 'G06T2207/10088']"
US11482320B2,Transformation of digital pathology images,"The invention relates to a method of identifying a biomarker in a tissue sample. The method comprises receiving an acquired image depicting a tissue sample, the pixel intensity values of the acquired image correlating with an autofluorescence signal or of an X-ray induced signal or a signal of a non-biomarker specific stain or a signal of a first biomarker specific stain adapted to selectively stain a first biomarker. The acquired image is input into a trained machine learning logic—MLL which automatically transforms the acquired image into an output image highlighting tissue regions predicted to comprise a second biomarker.","['G06T7/0012', 'G06V10/22', 'G16H30/40', 'G06T2207/10064', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30024', 'G06T2207/30204', 'G06V2201/031']"
US12248796B2,Modifying digital images utilizing a language guided image editing model,"This disclosure describes one or more implementations of systems, non-transitory computer-readable media, and methods that perform language guided digital image editing utilizing a cycle-augmentation generative-adversarial neural network (CAGAN) that is augmented using a cross-modal cyclic mechanism. For example, the disclosed systems generate an editing description network that generates language embeddings which represent image transformations applied between a digital image and a modified digital image. The disclosed systems can further train a GAN to generate modified images by providing an input image and natural language embeddings generated by the editing description network (representing various modifications to the digital image from a ground truth modified image). In some instances, the disclosed systems also utilize an image request attention approach with the GAN to generate images that include adaptive edits in different spatial locations of the image.","['G06F9/453', 'G06F40/30', 'G06F40/166', 'G06F40/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06T11/60', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084']"
US11238877B2,Generative adversarial network-based speech bandwidth extender and extension method,"Proposed are a generative adversarial network-based speech bandwidth extender and extension method. A generative adversarial network-based speech bandwidth extension method, according to an embodiment, comprises the steps of: extracting feature vectors from a narrowband (NB) signal and a wideband (WB) signal of a speech; estimating the feature vector of the wideband signal from the feature vector of the narrowband signal; and learning a deep neural network classification model for discriminating the estimated feature vector of the wideband signal from the actually extracted feature vector of the wideband signal and the actually extracted feature vector of the narrowband signal.","['G10L19/038', 'G06N3/084', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G10L21/038', 'G10L25/30', 'G06N3/045', 'G06N3/047', 'G06N3/088']"
US11551394B2,Audio-speech driven animated talking face generation using a cascaded generative adversarial network,"Conventional state-of-the-art methods are limited in their ability to generate realistic animation from audio on any unknown faces and cannot be easily generalized to different facial characteristics and voice accents. Further, these methods fail to produce realistic facial animation for subjects which are quite different than that of distribution of facial characteristics network has seen during training. Embodiments of the present disclosure provide systems and methods that generate audio-speech driven animated talking face using a cascaded generative adversarial network (CGAN), wherein a first GAN is used to transfer lip motion from canonical face to person-specific face. A second GAN based texture generator network is conditioned on person-specific landmark to generate high-fidelity face corresponding to the motion. Texture generator GAN is made more flexible using meta learning to adapt to unknown subject's traits and orientation of face during inference. Finally, eye-blinks are induced in the final animation face being generated.","['G06T13/40', 'G06T13/205', 'G06F18/214', 'G06K9/6256', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06V40/171', 'G10L15/02', 'G10L21/10', 'G10L25/30']"
US20240160978A1,Rf signal classification device incorporating quantum computing with game theoretic optimization and related methods,"A radio frequency (RF) signal classification device may include an RF receiver configured to receive RF signals, a quantum computing circuit configured to perform quantum subset summing, and a processor. The processor may be configured to generate a game theory reward matrix for a plurality of different deep learning models, cooperate with the quantum computing circuit to perform quantum subset summing of the game theory reward matrix, select a deep learning model from the plurality thereof based upon the quantum subset summing of the game theory reward matrix, and process the RF signals using the selected deep learning model for RF signal classification.","['G06N3/08', 'G06N10/20', 'G06N3/0455', 'G06N3/044', 'G06N3/045']"
US12346809B2,"Method, device, and storage medium for deep learning based domain adaptation with data fusion for aerial image data analysis","Embodiments of the present disclosure provide a method, a device, and a storage medium for domain adaptation for efficient learning fusion (DAELF). The method includes acquiring data from a plurality of data sources of a plurality of sensors; for each of the plurality of sensors, training an auxiliary classifier generative adversarial network (AC-GAN) by a hardware processor with data from each data source of the plurality of data sources, thereby obtaining a trained feature extraction network and a trained label prediction network for each data source; forming a decision-level fusion network or a feature-level fusion network; and training the decision-level fusion network or the feature-level fusion network with a source-only mode or a generate to adapt (GTA) mode; and applying the trained decision-level fusion network or the trained feature-level fusion network to detect a target of interest.","['G06N3/08', 'G06N3/088', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/82', 'G06V20/00', 'G06N3/084']"
WO2022007581A1,Deep learning network intrusion detection,"One or more computer processors intercept one or more network inputs entering or existing an internal network; synthesize one or more network input images from a random noise vector sampled from a normal distribution of textually embedded network inputs utilizing a trained generative adversarial network; classify one or more synthesized network input images by identifying contained objects utilizing a trained convolutional neural network with rectified linear units, wherein the objects include patterns, sequences, trends, and signatures; predict a security profile of the one or more classified network input images and associated one or more network inputs, wherein the security profiles includes a set of rules and associated mitigation actions, analogous historical network traffic, a probability of infection, a probability of signature match with historical malicious network inputs, and a harm factor; apply one or more mitigation actions based on the predicted security profile.","['H04L63/20', 'G06N3/088', 'G06N3/045', 'G06N3/047', 'H04L63/102', 'H04L63/1416', 'H04L63/1425', 'H04L63/1441', 'G06N3/048', 'G06N3/084']"
US11790492B1,Method of and system for customized image denoising with model interpretations,"There is provided a method and a system for customized image denoising with interpretability. A deep neural network (NN) is trained to denoise an image on a training dataset including pairs of noisy and corresponding clean images acquired from an imaging apparatus, where during the training a structured covariance score (SCS) indicative of a performance of the deep NN in recovering content of corresponding clean images relative to the denoised image is determined based on sparse conditional correlations. A test noisy image is received and denoised by the deep NN. A user feedback score indicative of user satisfaction of the denoising is obtained. A quality parameter is obtained based on the SCS and a quality metric indicative of denoised image quality is obtained from a pretrained NN, and compared with the user feedback score. If the SCS is above the user feedback score, the deep NN is provided for denoising.","['G06T5/70', 'G06T5/002', 'G06N3/0464', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/048', 'G06N3/0495', 'G06N3/08', 'G06N3/094', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06T7/80', 'G06T2207/10028', 'G06T2207/10044', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/30168']"
US11559738B2,Machine learned virtual gaming environment,"Virtual game worlds for computer games can be provided using machine learning. The use of machine learning enables the virtual game worlds to be generated at run time by standard consumer hardware devices. Machine learning agents are trained in advance to the characteristics of the particular game world. Then, these suitably trained machine learning agents can be used to generate a relevant portion of a virtual game world, such as a portion of the virtual game world that is proximate to a play's position. Advantageously, the virtual game world can be provided in high resolution and is able to cover a substantially larger region than conventional practical.","['A63F13/52', 'G06T17/00', 'A63F13/50', 'A63F13/5378', 'A63F13/69', 'A63F13/80', 'G06F18/2148', 'G06F18/2413', 'G06K9/6257', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06T17/05', 'G06V10/764', 'G06V10/82', 'G06V20/13', 'A63F2300/66', 'A63F2300/8082']"
US11087025B2,Differential privacy processing of IoT streaming data using generative adversarial networks,"Streaming data is received that is derived from at least one sensor (e.g., IoT sensors, etc.). At least one differential privacy algorithm is subsequently used to anonymize the received streaming data. The modified streaming data can then be provided (e.g., made available, stored, transmitted over a network, etc.) to at least one consuming computing device. Related apparatus, systems, techniques and articles are also described.","['H04W4/38', 'G06F21/6254', 'G06F21/6263', 'G06F9/542', 'G06N3/02', 'G06N3/0442', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'H04L65/602', 'H04L65/607', 'H04L65/70', 'H04L65/762', 'H04L65/765', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H04L67/12', 'H04W4/70']"
CN117175588B,Electricity load forecasting method and device based on spatiotemporal correlation,"The invention provides a power consumption load prediction method and device based on space-time correlation, and belongs to the technical field of load prediction. The method comprises the following steps: performing space-time modeling based on historical electricity load data and historical environment data to obtain a multi-layer space-time model; each layer of model is a directed graph, and represents the space causal relation of fixed time, and directed edges between each layer of models represent the time causal relation; performing feature extraction and priori knowledge fusion on the multi-layer space-time model based on the interpretable space-time attention converter to obtain power consumption load space-time features; wherein the interpretable spatiotemporal attention converter includes a spatial causal attention network, a temporal attention network, and a spatial dependency comparison module; based on the power consumption load space-time characteristics, the real-time power consumption load data and the real-time environment data of the target power consumption node, a trained STEF-DHNet model is adopted for prediction, and the predicted power consumption load data of the target power consumption node is obtained. The invention can improve the prediction accuracy and the model applicability.","['G06F18/213', 'G06F18/214', 'G06F18/25', 'G06N3/0442', 'G06Q50/06', 'H02J3/00', 'Y04S10/50']"
CN110008554B,Method for optimizing technological parameters and welding tool structure of friction stir welding seam forming prediction based on numerical simulation and deep learning,"The invention provides a method for optimizing technological parameters and a welding tool structure of friction stir welding seam forming prediction based on numerical simulation and deep learning, and belongs to the technical field of friction stir welding. The method comprises the following steps: setting three times of simulation tests as a data test set; step two, calculating the distribution conditions of the material flow field and the temperature field in the welding process; step three, calculating the fracture failure condition of the friction stir welding tool under different parameters, and calculating the forming quality of a welding line and the defect distribution condition under different parameters; and fourthly, traversing all process parameters and the welding seam forming result of the welding tool structure by utilizing the generated countermeasure network deep learning model to obtain the welding seam forming optimization result on the premise of ensuring the reliable work of the welding tool. The method aims to provide an effective universal prediction method for the optimized friction stir welding process in production, and has the advantages of time consumption reduction, material cost reduction, high prediction accuracy and the like.","['G06F30/17', 'G06F30/23', 'G06F2111/06', 'G06F2111/10']"
CN109816589B,Method and apparatus for generating manga style transfer model,"The embodiment of the disclosure discloses a method and a device for generating a cartoon style conversion model. One embodiment of the method comprises: acquiring a training sample set; acquiring a pre-established generation countermeasure network; by using a machine learning method, a sample image included in a training sample set is used as an input of a generation network, a sample cartoon style image corresponding to the input sample image is used as an expected output of the generation network, a cartoon style image actually output by the generation network and a sample cartoon style image corresponding to the input sample image are used as inputs of a discrimination network, the generation network and the discrimination network are trained, and the trained generation network is determined as a cartoon style conversion model. According to the embodiment, the problems of image edge sawtooth, image outline deformation and the like of the generated cartoon style image relative to the original image can be reduced, and the display effect of the generated cartoon style image is improved.","['G06N3/0464', 'G06N3/04', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/00']"
US11763168B2,Progressive modification of generative adversarial neural networks,"A generative adversarial neural network (GAN) learns a particular task by being shown many examples. In one scenario, a GAN may be trained to generate new images including specific objects, such as human faces, bicycles, etc. Rather than training a complex GAN having a predetermined topology of features and interconnections between the features to learn the task, the topology of the GAN is modified as the GAN is trained for the task. The topology of the GAN may be simple in the beginning and become more complex as the GAN learns during the training, eventually evolving to match the predetermined topology of the complex GAN. In the beginning the GAN learns large-scale details for the task (bicycles have two wheels) and later, as the GAN becomes more complex, learns smaller details (the wheels have spokes).","['G06N3/088', 'G06N3/02', 'G06N3/045', 'G06N3/04', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/094', 'G06V10/82']"
US11676025B2,"Method, apparatus and computer program for generating robust automatic learning systems and testing trained automatic learning systems",A method for training an automated learning system includes processing training input with a first neural network and processing the output of the first neural network with a second neural network. The input layer of the second neural network corresponding to the output layer of the first neural network. The output layer of the second neural network corresponding to the input layer of the first neural network. An objective function is determined using the output of the second neural network and a predetermined modification magnitude. The objective function is approximated using random Cauchy projections which are propagated through the second neural network.,"['G05B13/042', 'G06N3/084', 'G05B13/027', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06N3/088']"
US11663489B2,Machine learning systems and methods for improved localization of image forgery,A system for improved localization of image forgery. The system generates a variational information bottleneck objective function and works with input image patches to implement an encoder-decoder architecture. The encoder-decoder architecture controls an information flow between the input image patches and a representation layer. The system utilizes information bottleneck to learn useful residual noise patterns and ignore semantic content present in each input image patch. The system trains a neural network to learn a representation indicative of a statistical fingerprint of a source camera model from each input image patch while excluding semantic content thereof. The system can determine a splicing manipulation localization by the trained neural network.,"['G06N3/088', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T5/005', 'G06T5/77', 'G06T7/0002', 'G06V10/7557', 'G06V10/82']"
US10964084B2,Generating realistic animations for digital animation characters utilizing a generative adversarial network and a hip motion prediction network,"The present disclosure relates to systems, methods, and non-transitory computer readable media for generating a digital animation of a digital animation character by utilizing a generative adversarial network and a hip motion prediction network. For example, the disclosed systems can utilize an unconditional generative adversarial network to generate a sequence of local poses of a digital animation character based on an input of a random code vector. The disclosed systems can also utilize a conditional generative adversarial network to generate a sequence of local poses based on an input of a set of keyframes. Based on the sequence of local poses, the disclosed systems can utilize a hip motion prediction network to generate a sequence of global poses based on hip velocities. In addition, the disclosed systems can generate an animation of a digital animation character based on the sequence of global poses.","['G06T13/80', 'G06N3/084', 'G06F17/16', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T13/40']"
US11093707B2,Adversarial training data augmentation data for text classifiers,"An intelligent computer platform to introduce adversarial training to natural language processing (NLP). An initial training set is modified with synthetic training data to create an adversarial training set. The modification includes use of natural language understanding (NLU) to parse the initial training set into components and identify component categories. One or more paraphrase terms are identified with respect to the components and component categories, and function as replacement terms. The synthetic training data is effectively a merging of the initial training set with the replacement terms. As input is presented, a classifier leverages the adversarial training set to identify the intent of the input and to output a classification label to generate accurate and reflective response data.","['G06F40/30', 'G06F16/3344', 'G06F16/35', 'G06F18/214', 'G06F40/205', 'G06F40/42', 'G06K9/6256', 'G06V10/95', 'G06V30/1988', 'G06F40/279', 'G06N3/088']"
US20210081804A1,Tensor network machine learning system,"The invention is machine learning based method of, or system configured for, identifying candidate, small, drug-like molecules, in which a tensor network representation of molecular quantum states of a dataset of small, drug-like molecules is provided as an input to a machine learning system, such as a neural network system. The machine learning method or system may is itself configured as a tensor network. A training dataset may be used to train the machine learning system, and the training dataset is a tensor network representation of the molecular quantum states of small drug-like molecules.","['G06N3/088', 'G06N10/00', 'G06N3/045', 'G06N3/0454', 'G16B15/30', 'G16B40/30', 'G16B5/20', 'G06N3/044']"
US10593023B2,Deep-learning-based automatic skin retouching,"Embodiments disclosed herein involve techniques for automatically retouching photos. A neural network is trained to generate a skin quality map from an input photo. The input photo is separated into high and low frequency layers which are separately processed. A high frequency path automatically retouches the high frequency layer using a neural network that accepts the skin quality map as an input. A low frequency path automatically retouches the low frequency layer using a color transformation generated by a second neural network and the skin quality map. The retouched high and low frequency layers are combined to generate the final output. In some embodiments, a training set for any or all of the networks is enhanced by applying a modification to an original image from a pair of retouched photos in the training set to improve the resulting performance of trained networks over different input conditions.","['G06T5/005', 'G06N3/08', 'G06F18/2185', 'G06K9/6264', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06T5/007', 'G06T5/77', 'G06T5/90', 'G06V10/56', 'G06V10/993', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11189269B2,Adversarial training data augmentation for generating related responses,"An intelligent computer platform to introduce adversarial training to natural language processing (NLP). An initial training set is modified with synthetic training data to create an adversarial training set. The modification includes use of natural language understanding (NLU) to parse the initial training set into components and identify component categories. As input is presented, a classifier evaluates the input and leverages the adversarial training set to identify the intent of the input. An identified classification model generates accurate and reflective response data based on the received input.","['G10L15/1815', 'G06F40/205', 'G06F16/24', 'G06F40/30', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G10L15/063', 'G10L15/22', 'G10L15/1822', 'G10L2015/223']"
US12174729B2,Systems with software engines configured for detection of high impact scenarios with machine learning-based simulation and methods of use thereof,"Systems and methods for scenario planning include using specially programmed software engines to simulate and detect particular feature variations leading to particular outcomes based on modeling with machine learning techniques. The systems and methods improve model debugging, simulation efficiency and accuracy, model explainability, identification of high risk or high reward scenarios, among other improvements and combinations thereof. The systems and methods implement computerized optimization techniques applied via variation generation across a dataset of test input records to optimize for feature variation along with outcome variation. Moreover, the systems and methods may provide and/or realize a minimized variation to input data that correspond to a point of transition from one state to another state in an outcome that results from the input data, where the transition to another state is termed a “significant” variation to the output data.","['G06F11/3664', 'G06N3/08', 'G06F11/3698', 'G06N20/00', 'G06N5/01', 'G06N3/04']"
US12228629B2,Deep learning methods for noise suppression in medical imaging,"Techniques for denoising a magnetic resonance (MR) image are provided, including: obtaining a noisy MR image; denoising the noisy MR image of the subject using a denoising neural network model, and outputting a denoised MR image. The denoising neural network model is trained by: generating first training data for training a first neural network model to denoise MR images by generating a first plurality of noisy MR images using clean MR data associated with a source domain and first MR noise data associated with the target domain; training the first neural network model using the first training data; generating training data for training the denoising neural network model by applying the first neural network model to a second plurality of noisy MR images and generating a plurality of denoised MR images; and training the denoising neural network model using the training data for training the denoising neural network model.","['G01R33/56', 'G01R33/5608', 'G01R33/565', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T5/60', 'G06T5/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
US11922656B2,Partial deformation maps for reconstructing motion-affected treatment dose using machine learning,"A method comprises inputting a treatment planning image of a target subject into a machine learning system. The method further comprises determining, by the machine learning system, a first target-subject-specific model of the treatment planning image. The method further comprises applying, by a processing device, the first target-subject-specific model to the treatment planning image to generate a transformed treatment planning image corresponding to a first position of a plurality of positions of the target subject. The method further comprises comparing the transformed treatment planning image to a reference image. The method further comprises, based on the comparing, modifying one or more parameters of the first target-subject-specific model to generate a second target-subject-specific model corresponding to a second position of the plurality of positions. The method further comprises controlling a treatment device based on the second target-subject-specific model to deliver a treatment to the target subject.","['G06T7/74', 'A61N5/103', 'A61N5/1031', 'A61N5/1037', 'A61N5/1039', 'A61N5/1049', 'A61N5/1082', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06T7/246', 'G06T7/344', 'G06T7/75', 'A61N2005/1051', 'A61N5/1083', 'G06N3/047', 'G06N5/01', 'G06T2200/04', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/10124', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096']"
US20210374947A1,Contextual image translation using neural networks,"Apparatuses, systems, and techniques to facilitate generation of one medical image from another medical image using one or more neural networks trained using a generative adversarial network (GAN) that utilizes a bidirectional encoder representations from transformers (BERT) as a discriminator. In at least one embodiment, one or more neural networks trained using a GAN comprising a BERT discriminator generate a positron emission tomography (PET) image from a magnetic resonance imaging (MRI) image.","['G06N3/088', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06T7/0012', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G16H30/20', 'G16H30/40', 'G06T2207/10088', 'G06V2201/03']"
US20220108134A1,Unsupervised domain adaptation with neural networks,"Approaches presented herein provide for unsupervised domain transfer learning. In particular, three neural networks can be trained together using at least labeled data from a first domain and unlabeled data from a second domain. Features of the data are extracted using a feature extraction network. A first classifier network uses these features to classify the data, while a second classifier network uses these features to determine the relevant domain. A combined loss function is used to optimize the networks, with a goal of the feature extraction network extracting features that the first classifier network is able to use to accurately classify the data, but prevent the second classifier from determining the domain for the image. Such optimization enables object classification to be performed with high accuracy for either domain, even though there may have been little to no labeled training data for the second domain.","['G06N3/08', 'G06F18/2148', 'G06K9/6257', 'G06F18/2155', 'G06F18/217', 'G06F18/22', 'G06F18/2321', 'G06F18/24', 'G06F18/241', 'G06K9/46', 'G06K9/6262', 'G06K9/6268', 'G06N3/045', 'G06N3/0454', 'G06V10/40', 'G06V10/761', 'G06V10/762', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V10/96', 'G06F18/2415', 'G06N3/048']"
US11537901B2,System and method for unsupervised domain adaptation with mixup training,"A system and method for domain adaptation involves a first domain and a second domain. A machine learning system is trained with first sensor data and first label data of the first domain. Second sensor data of a second domain is obtained. Second label data is generated via the machine learning system based on the second sensor data. Inter-domain sensor data is generated by interpolating the first sensor data of the first domain with respect to the second sensor data of the second domain. Inter-domain label data is generated by interpolating first label data of the first domain with respect to second label data of the second domain. The machine learning system is operable to generate inter-domain output data in response to the inter-domain sensor data. Inter-domain loss data is generated based on the inter-domain output data with respect to the inter-domain label data. Parameters of the machine learning system are updated upon optimizing final loss data that includes at least the inter-domain loss data. After domain adaptation, the machine learning system, which is operable in the first domain, is adapted to generate current label data that identifies current sensor data of the second domain.","['G06N20/20', 'G06N3/088', 'G06N20/00', 'G06F18/214', 'G06F18/241', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/049', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/044']"
US11704552B2,Task detection in communications using domain adaptation,"Generally discussed herein are devices, systems, and methods for task classification. A method can include modifying a representation of a source sentence of a source sample from a source corpus to more closely resemble a representation of target sentences of target samples from a target corpus, operating, using a machine learning model trained using the modified representation of the source sentence, with the target sample to generate a task label, the task label indicating whether the target sample includes a task, and causing a personal information manager (PIM) to generate a reminder, based on whether the target sample includes the task.","['G06Q10/06311', 'G06N3/08', 'G06N3/0442', 'G06N3/0455', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'H04L51/224']"
CN113643278B,Adversarial example generation method for UAV image target detection,"The invention discloses an anti-sample generation method for unmanned aerial vehicle image target detection, which comprises the following steps: a control point on a vehicle vertically shot by the unmanned aerial vehicle is used as a reference control point, and the shape of the mask is marked in the range of the reference control point; generating a mask according to the mask coordinates, and initializing a general countermeasure patch by using the mask; calculating a projection matrix by utilizing the corresponding relation between control points in the original image and the target image, and carrying out projection transformation on the universal countermeasure patch and a mask thereof; repositioning the universal countermeasure patch and the mask to a specified area of the vehicle by using projection transformation to obtain a countermeasure image; inputting the contrast image into a target detection model, calculating a loss value by using an attack loss function, and optimizing the universal contrast patch by using a back propagation algorithm. The invention can attack the one-stage and two-stage target detection models, can interfere most samples, and relocates the countermeasure patch by using the projection transformation model, thereby ensuring the effectiveness of the countermeasure patch after projection transformation.","['G06T7/0002', 'G06F18/214', 'G06N3/045', 'G06N3/084', 'G06T3/06', 'G06T7/70', 'G06T2207/20081', 'Y02T10/40']"
US11037531B2,Neural reconstruction of sequential frames,"In one embodiment, a computing system configured to generate a current frame may access a current sample dataset having incomplete pixel information of a current frame in a sequence of frames. The system may access a previous frame in the sequence of frames with complete pixel information. The system may further access a motion representation indicating pixel relationships between the current frame and the previous frame. The previous frame may then be transformed according to the motion representation. The system may generate the current frame having complete pixel information by processing the current sample dataset and the transformed previous frame using a first machine-learning model.","['G09G5/37', 'G06F3/147', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G09G5/363', 'G09G5/391', 'G06N7/01', 'G09G2310/0232', 'G09G2320/0686', 'G09G2320/10', 'G09G2340/0407', 'G09G2340/16']"
CN112633306B,Adversarial image generation method and device,"The application discloses a method and a device for generating a countermeasure image, and belongs to the field of machine learning. The method comprises the following steps: inputting an initial image into a disturbance generation model to obtain an antagonistic disturbance output by the disturbance generation model; and adding the countermeasure disturbance to the initial image to obtain a countermeasure image. The structural similarity index of the initial image and the contrast image is larger than the structural similarity index threshold, and the characteristic similarity index of the contrast image and the target image is larger than the characteristic similarity index threshold, so that the image quality of the contrast image can be improved on the premise of ensuring that the success rate of the contrast image for the contrast image to the image recognition model is higher.","['G06F18/22', 'G06F18/214']"
US11818165B2,Malware detection using machine learning,"Synthetic training sets for machine learning are created by identifying and modifying functional features of code in an existing malware training set. By filtering the resulting synthetic code to measure malware impact and novelty, training sets can be created that predict novel malware and to seek to preemptively exhaust the space of new malware. These synthesized training sets can be used in turn to improve training of machine learning models. Furthermore, by repeating the process of new code generation, filtering and training, an iterative machine learning process may be created that continuously narrows the window of vulnerabilities to new malicious actions.","['H04L63/145', 'G06F21/56', 'G06N20/00', 'H04L63/14', 'H04L63/1416']"
CN114282437B,A physically realizable laser radar 3D point cloud adversarial sample generation method and system,"The invention discloses a method and a system for generating a physical-realizable laser radar 3D point cloud countermeasure sample, and belongs to the technical field of countermeasure machine learning. Modeling according to a physical rule of the laser radar point cloud by acquiring original 3D point cloud data containing a target area; randomly injecting a preset number of countermeasure points in the spherical coordinate range of the target area; the method comprises the steps of designing a target hidden attack loss function and a target creation attack loss function, substituting the target hidden attack loss function and the target creation attack loss function into a cloud countermeasure sample simulation model, optimizing coordinate information of a countermeasure point which is injected randomly, and taking the optimal output of the point cloud countermeasure sample simulation model as a finally generated 3D point cloud countermeasure sample. The invention utilizes the vulnerability of the existing 3D point cloud target detector to creatively model the physical law met by the laser radar acquisition point cloud data so as to construct two different types of 3D point cloud countermeasure samples which can be realized physically, and provides new guidance for machine learning safety analysis and protection.",[]
US10812499B2,Detection of adversary lateral movement in multi-domain IIOT environments,"Implementations are directed to methods for detecting and identifying advanced persistent threats (APTs) in networks, including receiving first domain activity data from a first network domain and second domain activity data from a second network domain, including multiple alerts from the respective first and second network domains and where each alert of the multiple alerts results from one or more detected events in the respective first or second network domains. A classification determined for each alert of the multiple alerts with respect to a cyber kill chain. A dependency is then determined for each of one or more pairs of alerts and a graphical visualization of the multiple alerts is generated, where the graphical visualization includes multiple nodes and edges between the nodes, each node corresponding to the cyber kill chain and representing at least one alert, and each edge representing a dependency between alerts.","['H04L63/1416', 'G06F21/552', 'G06F21/556', 'G06N20/00', 'G06N7/005', 'G06N7/01', 'H04L41/0631', 'H04L41/147', 'H04L41/22', 'H04L63/0227', 'H04L63/1425', 'H04L63/1433', 'H04L67/10']"
WO2022037258A1,"Image authenticity detection method and apparatus, computer device and storage medium","An image authenticity detection method, executed by a computer device. The method comprises: collecting an image to be detected (S202); inputting said image to a generator of a generative adversarial network, and outputting a pseudo image map corresponding to said image by means of the generator, the pseudo image map being used for representing the difference between said image and a true image, wherein at the training stage, the generative adversarial network further comprises a discriminator; at the training stage, the generator is used for outputting a predictive pseudo image map corresponding to a sample image, and generating a fitting image on the basis of the predictive pseudo image map; and the discriminator is used for performing authenticity identification on the fitting image to assist the generator in learning a difference feature between a false image and the true image (S204); and determining the authenticity detection result of said image on the basis of pseudo image information in the pseudo image map (S206).","['G06V20/95', 'G06V40/40', 'G06V40/161', 'G06F18/214', 'G06F18/241', 'G06V10/26', 'G06V10/751', 'G06V10/774', 'G06V10/82', 'G06V20/49', 'G06V40/168', 'G06V40/172', 'G06V40/16']"
US11188789B2,Detecting poisoning attacks on neural networks by activation clustering,"One embodiment provides a method comprising receiving a training set comprising a plurality of data points, where a neural network is trained as a classifier based on the training set. The method further comprises, for each data point of the training set, classifying the data point with one of a plurality of classification labels using the trained neural network, and recording neuronal activations of a portion of the trained neural network in response to the data point. The method further comprises, for each classification label that a portion of the training set has been classified with, clustering a portion of all recorded neuronal activations that are in response to the portion of the training set, and detecting one or more poisonous data points in the portion of the training set based on the clustering.","['G06K9/6256', 'G06N3/084', 'G06F18/214', 'G06F18/2433', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06V10/82', 'G06V30/19173', 'G06N3/04', 'G06V30/10']"
US11922569B2,Generating realistic point clouds,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating realistic full-scene point clouds. One of the methods includes obtaining an initial scene point cloud characterizing an initial scene in an environment; obtaining, for each of one or more objects, an object point cloud that characterizes the object; and processing a first input comprising the initial scene point cloud and the one or more object point clouds using a first neural network that is configured to process the first input to generate a final scene point cloud that characterizes a transformed scene that has the one or more objects added to the initial scene.","['G06T19/20', 'G06T17/00', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V20/10', 'G06V20/56', 'G06T2210/56', 'G06V2201/12']"
EP3757905A1,Deep neural network training method and apparatus,"The present invention relates to artificial intelligence, and proposes a cooperative adversarial network. A loss function is set at a lower layer of the cooperative adversarial network, and is used to learn a domain discriminating feature. In addition, a cooperative adversarial target function includes the loss function and a domain invariant loss function that is set at a last layer (that is, a higher layer) of the cooperative adversarial network, to learn both the domain discriminating feature and a domain-invariant feature. Further, an enhanced collaborative adversarial network is proposed. Based on the collaborative adversarial network, target domain data is added to training of the collaborative adversarial network, an adaptive threshold is set based on precision of a task model, to select a target domain training sample, network confidence is discriminated based on a domain, and a weight of the target domain training sample is set. Prediction precision applied to the target domain can be improved by using the task model trained by using the collaborative adversarial network.","['G06N3/084', 'G06F18/211', 'G06F18/214', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096']"
US12211277B2,Interactive video surveillance as an edge service using unsupervised feature queries,"A method for querying data obtained from a distributed sensor network, comprising: receiving sensor data representing an aspect of an environment with a sensor of the distributed sensor network; communicating a representation of the sensor data to a fog node through an automated communication network; determining, by the fog node, a correspondence of a query received through the automated communication network to characteristics of the representation of the sensor data; and selectively communicating, in response to the query, at least one of: the sensor data having the determined characteristics corresponding to the query, an identification of the sensor data having the determined characteristics corresponding to the query, and the data representing the sensor data having the determined characteristics corresponding to the query.","['G06V20/46', 'G06F16/785', 'G06F16/7854', 'G06F16/786', 'G06F16/7867', 'G06V10/95', 'G06V20/41', 'G06V20/52', 'G06V40/103']"
WO2023070696A1,Feature manipulation-based attack and defense method for continuous learning ability system,"The present invention relates to the technical fields of mode recognition, machine learning, multi-task learning, and adversarial attack, and specifically relates to a feature manipulation-based attack and defense method for a continuous learning ability system, aimed at solving the problem that an existing continuous learning-based intelligent system is poor in security and robustness. The method of the present invention comprises: obtaining an image clean sample; extracting a feature of the clean sample; obtaining a target sample, and extracting a feature as a target anchor feature; on the basis of the clean sample feature in combination with the target anchor feature, generating an adversarial sample by means of an attack sample generation algorithm; training an image classification model by means of a continuous learning algorithm, and counting a classification accuracy rate corresponding to the clean sample during C-category task classification and learning; adding, according to a ratio of 1:n, a first matrix as a training sample, and performing retraining; and classifying an image on the basis of the trained image classification model. The present invention improves the security and robustness of the existing continuous learning-based intelligent system.","['G06N3/082', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/061']"
CN109145992B,Collaborative Generative Adversarial Networks and Space Spectrum Joint Method for Hyperspectral Image Classification,"The invention discloses a hyperspectral image classification method based on cooperation generation countermeasure network and space spectrum combination, which comprises the following steps: inputting a hyperspectral image; obtaining a sample set; generating a training sample and a test sample; building a multi-scale discriminator; constructing a cooperative relationship; building a collaboration generation countermeasure network; the training sample generates an initial value through a multi-scale discriminator; the generator generates a sample; classifying by a multi-scale discriminator; constructing loss functions of a generator and a multi-scale discriminator; alternately training a generator and a multi-scale discriminator; and classifying the hyperspectral images. The method utilizes the established cooperation to generate the confrontation network, extracts the space-spectrum combined characteristics of the pixels, generates more vivid samples, increases the number of the samples, relieves the problems of network overfitting and low network convergence speed, and improves the accuracy of the hyperspectral image classification.","['G06F18/241', 'G06F18/2135', 'G06N3/045']"
US11164085B2,System and method for training a neural network system,"A computer-implemented method for training a neural network system. The method includes receiving at least a first data vector at a first layer of the neural network system; applying a function to the first data vector to generate at least a second data vector, wherein the function is based on a layer parameter of the first layer that includes at least a weight matrix of the first layer; comparing at least the first data vector and the second data vector to obtain a loss value that represents a difference between the first data vector and the second data vector; updating the layer parameter based on the loss value; and adjusting the layer parameter based on a comparison of the updated layer parameter with a threshold value of the first layer.","['G06N3/084', 'G06N20/10', 'G06N3/04', 'G06N3/0464', 'G06N3/048', 'G06N3/0499', 'G06N3/09', 'G06N3/094', 'G06N3/044', 'G06N3/045']"
US11887582B2,Training and testing utterance-based frameworks,"Systems, methods, and devices for training and testing utterance based frameworks are disclosed. The training and testing can be conducting using synthetic utterance samples in addition to natural utterance samples. The synthetic utterance samples can be generated based on a vector space representation of natural utterances. In one method, a synthetic weight vector associated with a vector space is generated. An average representation of the vector space is added to the synthetic weight vector to form a synthetic feature vector. The synthetic feature vector is used to generate a synthetic voice sample. The synthetic voice sample is provided to the utterance-based framework as at least one of a testing or training sample.","['G10L15/063', 'G06F7/582', 'G10L13/02', 'G10L15/07', 'G10L2015/0635']"
US20200294284A1,Posterior image sampling using statistical learning model,"Image reconstruction can include using a statistical or machine learning, MAP estimator, or other reconstruction technique to produce a reconstructed image from acquired imaging data. A Conditional Generative Adversarial Network (CGAN) technique can be used to train a Generator, using a Discriminator, to generate posterior distribution sampled images that can be displayed or further processed such as to help provide uncertainty information about a mean reconstruction image. Such uncertainty information can be useful to help understand or even visually modify the mean reconstruction image. Similar techniques can be used in a segmentation use-case, instead of a reconstruction use case. The uncertainty information can also be useful for other post-processing techniques.","['G06T11/006', 'G06T11/008', 'G06T7/10', 'G06T2207/20076', 'G06T2207/20081', 'G06T2211/424', 'G06T2211/441']"
CN112241790B,Method and device for generating small adversarial patches,"The small countermeasure patch generation method and the small countermeasure patch generation device are used for randomly initializing the countermeasure patch image, adding the initialized countermeasure patch image to a selected pasting area on a target object in training data and making a countermeasure sample; the countermeasure samples are input into a deep learning model for countermeasure feature extraction, and benign samples without added countermeasure patch images are input into the deep learning model for benign feature extraction; inputting the confrontation characteristic and the benign characteristic into a characteristic enhancement loss function together for loss calculation to obtain a loss result; adding the loss result into a model loss function, and updating the pixel value of the countermeasure patch through an optimizer after back propagation; after the iteration of the preset times, the counterpatch enables the deep learning model to output an error result, and the counterpatch processing process is finished. The invention can make the size of the confrontation patch in the physical world smaller, reduce the manufacturing cost, reduce the identifiability of the confrontation patch and more easily break through the defense method based on detection.","['G06N3/084', 'G06N3/045', 'G06V10/40']"
US11334971B2,Digital image completion by learning generation and patch matching jointly,"Digital image completion by learning generation and patch matching jointly is described. Initially, a digital image having at least one hole is received. This holey digital image is provided as input to an image completer formed with a dual-stage framework that combines a coarse image neural network and an image refinement network. The coarse image neural network generates a coarse prediction of imagery for filling the holes of the holey digital image. The image refinement network receives the coarse prediction as input, refines the coarse prediction, and outputs a filled digital image having refined imagery that fills these holes. The image refinement network generates refined imagery using a patch matching technique, which includes leveraging information corresponding to patches of known pixels for filtering patches generated based on the coarse prediction. Based on this, the image completer outputs the filled digital image with the refined imagery.","['G06T5/77', 'G06T5/005', 'G06K9/6202', 'G06V10/7715', 'G06V10/82', 'G06T2207/20081']"
US20230009814A1,Method for training information recommendation model and related apparatus,"Embodiments of this application provide a for training an information recommendation model. The method includes: obtaining historical user behavior data in a plurality of product domains; generating candidate sample data of one or more target product domains according to the historical user behavior data by using a generative model; performing user-specific authenticity sample discrimination on candidate sample data of the target product domains and actual user click sample data by using a discriminative model, to obtain a discrimination result; and performing adversarial training on the generative model and the discriminative model according to the discrimination result, to obtain a trained generative adversarial network as an information recommendation model for a to-be-expanded product domain in the plurality of product domains. According to the method, the training effect of the generative model may be improved, the accuracy of generating the pseudo sample is improved, thereby further improving the recommendation effect.","['G06F16/9535', 'G06Q30/0631', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06Q30/0201', 'G06Q30/0202']"
US11232558B2,Systems and methods for image generation,"The present disclosure provides a system and method for image generation. The method may include obtaining a first image of a first modality including a complete representation of a subject, obtaining a second image of a second modality including a partial representation of the subject, obtaining a trained machine learning model, generating an synthesized second image including a complete representation of the subject using the trained machine learning model based on the first image and the second image.","['G06T7/0012', 'G16H30/20', 'G06T11/008', 'A61B6/037', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T7/10', 'G16H30/40', 'G16H50/70', 'A61B6/5229', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2211/40', 'Y02D10/00']"
US10962976B1,Motion control method and system for biomimetic robotic fish based on adversarial structured control,"A motion control method and system for a biomimetic robotic fish based on an adversarial structured control, includes: taking the accuracy and speed of motion to the target point as a reward term, and taking a power sum of servomotors as a loss term to construct an optimization objective function; optimizing parameters of a central pattern generator model that generates a global control quantity of a servomotor, after curing its parameters, optimizing the parameters of the servomotor compensation control model; iteratively optimizing the parameters of the model; obtaining the global control signal and compensation control signal of the biomimetic robotic fish through the trained model, and using the linear combination of the two sets of output signals as the control signal of the servomotor of the robotic fish to realize the motion control of the fish.","['G05D1/0088', 'B63G8/14', 'B63G8/001', 'G05D1/10', 'G06N3/008', 'G06N3/0499', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N3/126', 'B63G2008/004', 'B63H1/36', 'G06N3/045']"
US11551337B2,Boundary-aware object removal and content fill,Systems and methods for removing objects from images are disclosed. An image processing application identifies a boundary of each object of a set of objects in an image. The image processing application identifies a completed boundary for each object of the set of objects by providing the object to a trained model. The image processing application determines a set of masks. Each mask corresponds to an object of the set of objects and represents a region of the image defined by an intersection of the boundary of the object and the boundary of a target object to be removed from the image. The image processing application updates each mask by separately performing content filling on the corresponding region. The image processing application creates an output image by merging each of the updated masks with portions of the image.,"['G06T5/004', 'G06T5/77', 'G06T5/00', 'G06T5/75', 'G06T5/50', 'G06T5/60', 'G06T5/94', 'G06T7/11', 'G06T7/13', 'G06T7/194', 'H04N23/80', 'G06F18/00', 'G06T11/40', 'G06T2200/21', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20221', 'G06T2207/20224', 'G06V10/44']"
CN117892251B,Rigging forging process parameter monitoring and early warning method and device based on artificial intelligence,"The invention provides a method and a device for monitoring and early warning of a forging technological parameter of a rigging based on artificial intelligence, which relate to the technical field of data processing. The parameter monitoring model is constructed based on a classifier model constructed by a method of determining anchor points, a feature extraction model constructed by a neural network algorithm based on multi-direction communication simulation particle swarm optimization is used for carrying out feature extraction on a training sample set of a training classifier model, and a data dimension reduction model is used for carrying out dimension reduction on the training sample set. The invention can effectively process and analyze a large number of complex forging process parameters, improves the efficiency and accuracy of data processing, so as to more accurately predict potential risks and anomalies and ensure the safety and efficiency of the forging process.","['G06F18/2433', 'G06F18/213', 'G06N3/006', 'G06N3/04', 'G06N3/08']"
CA3104652C,Detection and replacement of transient obstructions from high elevation digital images,Implementations relate to detecting/replacing transient obstructions from high-elevation digital images. A digital image of a geographic area includes pixels that align spatially with respective geographic units of the geographic area. Analysis of the digital image may uncover obscured pixel(s) that align spatially with geographic unit(s) of the geographic area that are obscured by transient obstruction(s). Domain fingerprint(s) of the obscured geographic unit(s) may be determined across pixels of a corpus of digital images that align spatially with the one or more obscured geographic units. Unobscured pixel(s) of the same/different digital image may be identified that align spatially with unobscured geographic unit(s) of the geographic area. The unobscured geographic unit(s) also may have domain fingerprint(s) that match the domain fingerprint(s) of the obscured geographic unit(s). Replacement pixel data may be calculated based on the unobscured pixels and used to generate a transient-obstruction-free version of the digital image.,"['G06T5/77', 'G06F18/214', 'G06F18/241', 'G06T5/50', 'G06T7/337', 'G06T7/344', 'G06V20/188', 'G06T2207/10036', 'G06T2207/10041', 'G06T2207/20081', 'G06T2207/30181', 'G06T2207/30188']"
US20210012093A1,Method and apparatus for generating face rotation image,"This application provides a method and an apparatus for generating a face rotation image. The method includes: performing pose encoding on an obtained face image based on two or more landmarks in the face image, to obtain pose encoded images; obtaining a plurality of training images each including a face from a training data set, where presented rotation angles of the faces included in the plurality of training images are the same; performing pose encoding on a target face image based on two or more landmarks in the target face image in the foregoing similar manner, to obtain pose encoded images, where the target face image is obtained based on the plurality of training images; generating a to-be-input signal based on the face image and the foregoing two types of pose encoded images; and inputting the to-be-input signal into an face rotation image generative model to obtain a face rotation image.","['G06K9/00281', 'G06T3/18', 'G06F18/214', 'G06K9/00248', 'G06K9/00288', 'G06K9/6256', 'G06T3/60', 'G06T5/002', 'G06T5/70', 'G06T9/00', 'G06T9/002', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/161', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US20220284584A1,Computerised tomography image processing,"Methods for training an algorithm to identify structural anatomical features, for example of a blood vessel, in a non-contrast computed tomography (NCT) image are described herein. The algorithm may comprise an image segmentation algorithm, a random forest classifier, or a generative adversarial network in examples described herein. In one embodiment, a method comprises receiving a labelled training set for a machine learning image segmentation algorithm. The labelled training set comprising a plurality of NCT images, each NCT image of the plurality of NCT images showing a targeted region of a subject, the targeted region including at least one blood vessel. The labelled training set further comprises a corresponding plurality of segmentation masks, each segmentation mask labelling at least one structural feature of a blood vessel in a corresponding NCT image of the plurality of NCT images. The method further comprises training a machine learning image segmentation algorithm, using the plurality of NCT images and the corresponding plurality of segmentation masks, to learn features of the NCT images that correspond to structural features of the blood vessels labelled in the segmentation masks, and output a trained image segmentation model. The method further comprises outputting the trained image segmentation model usable for identifying structural features of a blood vessel in an NCT image. Further methods are described herein for identifying anatomical features from an NCT image, and for establishing training sets. Computing apparatuses and computer readable media are also described herein.","['G06T7/11', 'G06T7/0012', 'A61B6/504', 'G06T3/40', 'G06T7/174', 'G06T7/30', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G16H30/40', 'G06T2207/10081', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30084', 'G06T2207/30092', 'G06T2207/30101']"
US11550011B2,Systems and methods for magnetic resonance imaging standardization using deep learning,"A computer-implemented method for transforming magnetic resonance (MR) imaging across multiple vendors is provided. The method comprises: obtaining a training dataset, wherein the training dataset comprises a paired dataset and an un-paired dataset, and wherein the training dataset comprises image data acquired using two or more MR imaging devices; training a deep network model using the training dataset; obtaining an input MR image; and transforming the input MR image to a target image style using the deep network model.","['G06N3/088', 'G01R33/54', 'G01R33/5608', 'G06F18/2413', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06V2201/03']"
US20240161017A1,Connectome Ensemble Transfer Learning,"The present disclosure describes a method of Connectome Ensemble Transfer Learning (CETL), which makes connectome-based predictive models useful for precision mental healthcare. CETL comprises a novel transfer learning process that incrementally trains Connectome Ensemble Predictive Models (CEPMs) by leveraging information from source domains to improve predictive performance in target domains. The disclosed methods broadly comprise selecting target and source domains, obtaining network connectivity data from individual persons, sampling source ensemble representations of connectome “views” from the obtained network connectivity data of said persons in the source domain, reducing the dimensionality of the sampled connectome “views”, and transferring the distilled representations to the target domain to train more robust, generalizable, and clinically deployable CEPMs that predict diverse target mental health phenotypes. Implemented through massively parallel distributed computing, a system of synchronized computer hardware implementing this method is also disclosed.","['G06N20/20', 'G06N3/096', 'G06N3/042', 'G06N3/045', 'G06N3/09', 'G06N5/01', 'G06N5/02', 'G06N7/01', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06N3/0895']"
US20190279075A1,Multi-modal image translation using neural networks,"A source image is processed using an encoder network to determine a content code representative of a visual aspect of the source object represented in the source image. A target class is determined, which can correspond to an entire population of objects of a particular type. The user may specify specific objects within the target class, or a sampling can be done to select objects within the target class to use for the translation. Style codes for the selected target objects are determined that are representative of the appearance of those target objects. The target style codes are provided with the source content code as input to a translation network, which can use the codes to infer a set of images including representations of the selected target objects having the visual aspect determined from the source image.","['G06N3/0454', 'G06N3/088', 'G06N3/045', 'G06F17/18', 'G06N3/047', 'G06N3/0472', 'G06N3/084', 'G06N5/04', 'G06T11/00', 'G06T3/0006', 'G06T3/02', 'G06N20/10', 'G06N3/048', 'G06N3/082']"
US12088616B2,Deep cyber vulnerability mitigation system,"A method, system, or apparatus for mitigating computer and network security deficiencies is provided in which, the method, system, or apparatus scans computer system components for finding a vulnerability, generates a Vulnerability Priority Scoring System (VPSS) score for the vulnerability based on the vulnerability, develops a vulnerability mitigation policy based on a system state comprising the VPSS score, wherein the vulnerability mitigation policy provides a best action for mitigating the vulnerability selected among one or more trained possible actions by a deep neural network, and performs the vulnerability mitigation policy based on the best action. Other aspects, embodiments, and features are also claimed and described.","['G06F21/57', 'G06F21/577', 'G06N3/02', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N7/01', 'H04L41/0894', 'H04L41/145', 'H04L41/16', 'H04L63/1433', 'G06F2221/034', 'H04L41/046', 'H04L63/107']"
US11335062B2,Automated apparel design using machine learning,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media facilitating automated apparel design using deep learning techniques. For example, user instructions may be received as text data (or converted to text data from audio data representing user speech), and natural language processing (NLP) may be performed on the text data to interpret the user instructions. An apparel design may be generated in real-time/substantially real-time based on the user instructions. For example, the interpreted user instructions may be provided as input to at least one machine learning (ML) model that is configured to determine one or more visual apparel elements based on the user instructions and to generate the apparel design based on the visual apparel elements. One or more operations may be initiated based on the apparel design.","['G06T17/20', 'G06T19/20', 'A41D1/00', 'G06F3/167', 'G06F40/30', 'G06F40/35', 'G06N20/00', 'G06N3/006', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G10L15/1822', 'G10L15/22', 'G10L15/26', 'G06F40/216', 'G06F40/289', 'G06F40/295', 'G06T2210/16', 'G06T2219/2004', 'G10L2015/223']"
TWI791889B,"Method of calibrating a plurality of metrology apparatuses, method of determining a parameter of interest, and metrology apparatus","Methods for calibrating metrology apparatuses and determining a parameter of interest are disclosed. In one arrangement, training data is provided that comprises detected representations of scattered radiation detected by each of plural metrology apparatuses. An encoder encodes each detected representation to provide an encoded representation, and a decoder generates a synthetic detected representation from the respective encoded representation. A classifier estimates from which metrology apparatus originates each encoded representation or each synthetic detected representation. The training data is used to simultaneously perform, in an adversarial relationship relative to each other, a first machine learning process involving the encoder or decoder and a second machine learning process involving the classifier.","['G03F7/70525', 'G03F7/70516', 'G03F7/705', 'G03F7/70625', 'G03F7/70633', 'G05B13/027', 'H01L22/12', 'G06V2201/06']"
CN109214973B,Adversarial security vector generation method for steganalysis neural network,"The invention discloses a method for generating a confrontation safety carrier aiming at a steganalysis neural network, which utilizes a gradient back propagation technology to enable the steganalysis neural network to modify an input image to generate a confrontation sample, adds a regular term into a distortion function to prevent excessive modification, uses random noise to simulate steganalysis information and enables the network to learn the modification position and amplitude for confronting the noise, and generates a stable confrontation sample by adopting a cycle of iterative modification, periodic quantization and effect evaluation. By using the method disclosed in the invention, a given neural network or networks for steganalysis can lose the ability to detect the secret carrier with a great probability.","['G06T1/0021', 'G06N3/02']"
US11544530B2,Self-attentive attributed network embedding,"Methods and systems for determining a network embedding include training a network embedding model using training data that includes topology information for networks and attribute information relating to vertices of the networks. An embedded representation is generated using the trained network embedding model to represent an input network, with associated attribute information, in a network topology space. A machine learning task is performed using the embedded representation as input to a machine learning model.","['G06N3/0454', 'G06N3/084', 'G06F18/21355', 'G06F18/22', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01']"
US20220012890A1,Model-Based Deep Learning for Globally Optimal Surface Segmentation,An automated method for segmentation includes steps of receiving at a computing device an input image representing at least one surface and performing by the computing device image segmentation on the input image based on a graph surface segmentation model with deep learning. The deep learning may be used to parameterize the graph surface segmentation model.,"['G06T7/11', 'G06T7/12', 'G06T7/0012', 'G06T7/162', 'G06T2207/10072', 'G06T2207/10101', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30101']"
US20240348663A1,Ai-enhanced simulation and modeling experimentation and control,"An artificial intelligence-driven simulation and decision platform for reducing epistemic uncertainty in complex systems. The system integrates advanced techniques from artificial intelligence, simulation, and uncertainty quantification to generate and run scenarios, monitor progress, and adjust parameters in real-time to achieve user-defined goals. The simulation and decision platform comprises an AI system that employs natural language processing, reinforcement learning, and multi-objective optimization; a continuous and scalable simulation environment; scenario generation and guidance that provides human-readable scenario guides and contextual explanations; and an uncertainty quantification and reduction that employs entropy-based methods and Bayesian inference. The system allows users to define goals and objectives for their simulations, and the AI component generates and optimizes scenarios to achieve these goals while reducing epistemic uncertainty. The simulation and decision platform is designed to be flexible and adaptable to various domains and applications, providing a comprehensive and user-friendly solution for managing complex systems under uncertainty.","['H04L63/104', 'G06F16/2477', 'G06F16/951', 'H04L63/1425', 'H04L63/1441', 'H04L63/20', 'H04L67/10', 'H04L67/535', 'H04L67/55', 'H04L67/566', 'H04L67/02', 'H04L67/125']"
US10783875B2,Unsupervised non-parallel speech domain adaptation using a multi-discriminator adversarial network,A system for domain adaptation includes a domain adaptation model configured to adapt a representation of a signal in a first domain to a second domain to generate an adapted presentation and a plurality of discriminators corresponding to a plurality of bands of values of a domain variable. Each of the plurality of discriminators is configured to discriminate between the adapted representation and representations of one or more other signals in the second domain.,"['G10L15/07', 'G10L15/065', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06N3/096', 'G10L15/063', 'G10L15/16', 'G10L15/22', 'G10L21/003', 'G06N3/044', 'G06N3/082', 'G10L2015/0635']"
US11514694B2,Teaching GAN (generative adversarial networks) to generate per-pixel annotation,"A method and apparatus for joint image and per-pixel annotation synthesis with a generative adversarial network (GAN) are provided. The method includes: by inputting data to a generative adversarial network (GAN), obtaining a first image from the GAN; inputting, to a decoder, a first feature value that is obtained from at least one intermediate layer of the GAN according to the inputting of the data to the GAN; and obtaining a first semantic segmentation mask from the decoder according to the inputting of the first feature value to the decoder.","['G06N3/088', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/10', 'G06V10/40', 'G06V10/82', 'G06V20/70', 'G06V30/19147', 'G06V30/19173', 'G06V30/274', 'G06N3/082', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084']"
US11232573B2,Artificially intelligent systems to manage virtual dental models using dental images,"Methods and apparatuses (including systems and devices) for modifying a three-dimensional (3D) model of a subject's oral cavity to determine individual components such as teeth, gingiva, tongue, palate, etc. In some implementations one or more automated machine learning agents may modify one or more subsets of 3D models of the subject's oral cavity using height map data to identify, segment and/or modify to mesh regions of a 3D model constructed from a plurality of 2D images of the subject's dental cavity.","['G06T7/11', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T15/04', 'G06T17/205', 'G06T19/20', 'G06T7/0012', 'G16H30/20', 'G16H30/40', 'G16H50/50', 'G06T2200/04', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06T2210/41', 'G06T2219/2012']"
US11900565B2,Deep feature generative adversarial neural networks,A data item is identified on a device. A neural network that includes an adversarial transformation subnetwork is applied to the data item to generate a modified data item. Output indicative of the modified data item is caused to be presented on the device. The neural network further comprises an encoder and a decoder. The neural network is trained in at least two stages. At least one of the encoder and the decoder is trained in a first stage and the adversarial transformation subnetwork is trained in a second stage.,"['G06T5/001', 'H04L51/10', 'G06T11/60', 'G06T5/10', 'G06T2200/16', 'G06T2200/24', 'G06T2207/10004', 'G06T2207/20048', 'G06T2207/20081', 'G06T2207/30196', 'H04L51/214', 'H04L51/52']"
US10839208B2,System and method for detecting fraudulent documents,"A system and method to detect fraudulent documents is disclosed. The system uses a generative adversarial network to generate synthetic document data including new fraud patterns. The synthetic document data is used to train a fraud classifier to detect potentially fraudulent documents as part of a document validation workflow. The method includes extracting document features from sample data corresponding to target regions of the documents, such as logo regions and watermark regions. The method may include updating a cost function of the generators to reduce the tendency of the system to generate repeated fraud patterns.","['G06K9/00483', 'G06N3/08', 'G06F40/30', 'G06K9/00463', 'G06K9/036', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/086', 'G06N3/0895', 'G06N3/094', 'G06V10/82', 'G06V20/95', 'G06V30/19173', 'G06V30/40', 'G06V30/414', 'G06V30/418', 'G06K2209/01', 'G06V2201/09']"
US20220309203A1,Artificial intelligence-based automatic generation method for urban road network,"The present invention discloses an artificial intelligence (AI)-based automatic generation method for an urban road network. According to the method, an anchor point distribution model is constructed by means of machine learning. Anchor points are distributed within a planning range where a boundary is a secondary trunk road. A road center line layout scheme set is generated by means of rectangular expansion. A feasible scheme set is screened out based on a rule base translated from specifications related to urban planning road, a road network scheme set is further automatically generated, and finally, a scheme is outputted to a two-dimensional interaction display device for simulated display. The present invention realizes a road network design by using a combination of machine learning and rules of the urban planning field. The present invention provides a simple and efficient automatic generation method for an urban road network. By means of the present invention, a plurality of schemes can be generated within a short time, which provide an efficient and visualized reference for the design and the practice of AI urban planning.","['G06F30/18', 'G06F30/13', 'G06Q50/26', 'G01C21/34', 'G06F16/29', 'G06F30/27', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06V20/17', 'G06V20/182', 'G06N5/022']"
US11562510B2,Real-time context based emoticon generation system and method thereof,"A method for generating a real-time context-based emoticon may include receiving conversation information associated with a conversation between a set of users. The method may include identifying an attribute associated with the conversation. The method may include generating a base emoticon. The method may include generating an output shape based on a fiducial point of the base emoticon. The method may include transforming the output shape of the base emoticon with an accessory. The method may include generating the real-time context-based emoticon for the conversation, based on transforming the output shape of the base emoticon with the accessory.","['G06T11/00', 'G06F40/205', 'G06F40/284', 'G06F40/30', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T2210/44']"
US10518162B2,"Mission-based, game implemented cyber training system and method","A mission-based cyber training platform allows both offensive and defensive oriented participants to test their skills in a game-based virtual environment against a live or virtual opponent. The system builds realistic virtual environments to perform the training in an isolated and controlled setting. Dynamic configuration supports unique missions using a combination of real and/or virtual machines, software resources, tools, and network components. Game engine behaves in a manner that will vary if participant attempts to replay a scenario based upon alternate options available to the engine. Scoring and leader boards are used to identify skill gaps/strengths and measure performance for each training participant. A detailed assessment of a player's performance is provided at the end of the mission and is stored in a user profile/training record.","['A63B71/0622', 'A63F13/85', 'A63F9/24', 'G06N3/006', 'G09B5/12', 'G09B7/00', 'G09B9/003', 'A63F13/75', 'A63F2300/8094', 'G06N3/042']"
CN111860677B,A rolling bearing transfer learning fault diagnosis method based on partial domain adversarial,"The invention discloses a rolling bearing migration learning fault diagnosis method based on partial domain countermeasure, which comprises the following steps: constructing a rolling bearing fault data sample library, and dividing fault data of a source domain and a target domain; extracting implicit characteristics of fault data of a source domain and a target domain; constructing a label predictor; constructing a weighted domain classifier to obtain the probability and weight of the sample feature from the source domain distribution; sending the weighted source domain sample characteristics and the unweighted target domain sample characteristics into another domain classifier, judging whether the sample characteristics come from the source domain or the target domain, and constructing a gradient inversion layer; optimizing a model; the test data is input into a feature extractor to obtain sample features, the obtained sample features are input into a label predictor to obtain a prediction label, and the classification accuracy is calculated. The invention integrates the countermeasure idea into a part of migration network, proposes a strategy of carrying out domain classification after weighting the source domain samples, improves the self-adaptive capacity of the sample domain, and solves the problem of carrying out unsupervised label prediction in the target domain.","['G06F18/2415', 'G01M13/04', 'G06F18/2431', 'G06N20/00', 'G06N3/045']"
US20230385085A1,"Determining sequences of interactions, process extraction, and robot generation using generative artificial intelligence / machine learning models","Use of generative artificial intelligence (AI)/machine learning (ML) models is disclosed to determine sequences of user interactions with computing systems, extract common processes, and generate robotic process automation (RPA) robots. The generative AI/ML model may be trained to recognize matching n-grams of user interactions and/or a beneficial end state. Recorded real user interactions may be analyzed, and matching sequences may be implemented as corresponding activities in an RPA workflow.","['G06F9/451', 'G06F17/18', 'G06N20/00', 'G06N3/006', 'G06N3/04', 'G06N3/084', 'G06N3/09', 'G06N7/01']"
US11475277B2,Accurate and interpretable classification with hard attention,"Generally, the present disclosure is directed to novel machine-learned classification models that operate with hard attention to make discrete attention actions. The present disclosure also provides a self-supervised pre-training procedure that initializes the model to a state with more frequent rewards. Given only the ground truth classification labels for a set of training inputs (e.g., images), the proposed models are able to learn a policy over discrete attention locations that identifies certain portions of the input (e.g., patches of the images) that are relevant to the classification. In such fashion, the models are able to provide high accuracy classifications while also providing an explicit and interpretable basis for the decision.","['G06F18/2415', 'G06N3/084', 'G06N3/0454', 'G06F18/214', 'G06F18/22', 'G06F18/2413', 'G06F18/285', 'G06K9/6215', 'G06K9/6256', 'G06K9/627', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N7/005', 'G06N7/01', 'G06V10/454', 'G06V10/774', 'G06V10/776', 'G06V10/87', 'G06V20/10', 'G06V20/70']"
US12039456B2,Electronic device and controlling method thereof,"An electronic device and a controlling method thereof are provided. A controlling method of an electronic device according to the disclosure includes: performing first learning for a neural network model for acquiring a video sequence including a talking head of a random user based on a plurality of learning video sequences including talking heads of a plurality of users, performing second learning for fine-tuning the neural network model based on at least one image including a talking head of a first user different from the plurality of users and first landmark information included in the at least one image, and acquiring a first video sequence including the talking head of the first user based on the at least one image and pre-stored second landmark information using the neural network model for which the first learning and the second learning were performed.","['G06N3/088', 'G06F16/70', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V40/00', 'G06V40/168', 'G06V40/169', 'G06V40/172', 'G06V40/179', 'G06V40/20', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US10783622B2,Training and utilizing an image exposure transformation neural network to generate a long-exposure image from a single short-exposure image,"The present disclosure relates to training and utilizing an image exposure transformation network to generate a long-exposure image from a single short-exposure image (e.g., still image). In various embodiments, the image exposure transformation network is trained using adversarial learning, long-exposure ground truth images, and a multi-term loss function. In some embodiments, the image exposure transformation network includes an optical flow prediction network and/or an appearance guided attention network. Trained embodiments of the image exposure transformation network generate realistic long-exposure images from single short-exposure images without additional information.","['G06T5/50', 'G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06N3/048', 'G06N3/084', 'G06T2200/21', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20201']"
US11580383B2,"Neural network learning device, method, and program","A large amount of training data is typically required to perform deep network leaning, making it difficult to achieve using a few pieces of data. In order to solve this problem, the neural network device according to the present invention is provided with: a feature extraction unit which extracts features from training data using a learning neural network; an adversarial feature generation unit which generates an adversarial feature from the extracted features using the learning neural network; a pattern recognition unit which calculates a neural network recognition result using the training data and the adversarial feature; and a network learning unit which performs neural network learning so that the recognition result approaches a desired output.","['G06N3/084', 'G06F18/2132', 'G06F18/241', 'G06K9/6234', 'G06K9/6268', 'G06N20/00', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/776']"
TWI773888B,Training a neural network for defect detection in low resolution images,"Methods and systems for training a neural network for defect detection in low resolution images are provided. One system includes an inspection tool that includes high and low resolution imaging subsystems and one or more components that include a high resolution neural network and a low resolution neural network. Computer subsystem(s) of the system are configured for generating a training set of defect images. At least one of the defect images is generated synthetically by the high resolution neural network using an image generated by the high resolution imaging subsystem. The computer subsystem(s) are also configured for training the low resolution neural network using the training set of defect images as input. In addition, the computer subsystem(s) are configured for detecting defects on another specimen by inputting the images generated for the other specimen by the low resolution imaging subsystem into the trained low resolution neural network.","['G06T7/0004', 'G06N3/08', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V30/1916', 'G06V30/19173', 'G06V30/2504', 'H01L22/12', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148', 'G06V2201/06']"
US11062179B2,Method and device for generative adversarial network training,"An electronic device for neural network training includes at least one processor and one or more memories configured to provide or train: a generative adversarial network (GAN) using a generator and a discriminator for: receiving a plurality of training cases; and training the generative adversarial network, based on the plurality of training cases, to classify the training cases; wherein the generator generates hard negative examples for the discriminator.","['G06K9/6257', 'G06N3/08', 'G06F16/532', 'G06F18/2148', 'G06F18/217', 'G06F18/24', 'G06K9/6262', 'G06K9/6267', 'G06K9/726', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06V10/82', 'G06V30/19173', 'G06V30/274', 'G06N20/10', 'G06N3/042', 'G06N3/044', 'G06N3/048']"
US12132750B2,"Systems, methods, and computer-readable media for data security","Systems and methods are provided for data security. A server system provides data security using one or more processor devices, one or more communication interfaces, and one or more memory devices including computer-executable instructions. Those instructions cause the one or more processor devices to: monitor one or more requests or activities of a computing device; compare the monitored one or more requests or activities with a database of predetermined characteristics to determine whether the monitored one or more requests or activities indicates that the computing device downloaded or attempted to download more than a threshold number of data files or objects; and determine that the one or more requests or activities is suspicious when the comparing determines that the one or more requests or activities indicates that the computing device downloaded or attempted to download more than the threshold number of data files or objects, which causes a response to hinder the monitored one or more requests or activities.","['H04L63/1425', 'G06F16/13', 'G06F16/951', 'G06F21/554', 'H04L63/1416', 'H04L63/1441']"
US20240288550A1,"Method, system and computer readable medium for evaluating influence of an action performed by an external entity","The present disclosure provides a non-transitory computer readable medium having instructions tangibly stored thereon, wherein when executed by a processing entity, the instructions cause the processing entity to carry out a method of evaluating influence of an action performed by an external entity, the method comprising: receiving sensor data; determining a signal reliability factor for the received sensor data, wherein the signal reliability factor represents a statistical quality indication between the received sensor data and an expected value or an expected range of values; and associating the signal reliability factor with the received sensor data. There is also provided a system configured to communicate with an autonomous driving system.","['G01S17/10', 'G01S7/4817', 'G01S17/894', 'B60W60/00', 'G01S17/36', 'G01S17/86', 'G01S17/931', 'G01S7/4811', 'G01S7/4815', 'G01S7/4816', 'G01S7/484', 'G01S7/4863', 'G01S7/4865', 'G01S7/4914', 'G01S7/497', 'H04N25/773', 'H05B47/105', 'H05B47/11', 'H05B47/16', 'B60W2420/20', 'B60W2420/24', 'B60W2420/40', 'B60W2420/50', 'B60W2420/506', 'H10F39/182', 'H10F39/184', 'H10F39/191']"
US10043261B2,Generating simulated output for a specimen,"Methods and systems for generating simulated output for a specimen are provided. One method includes acquiring information for a specimen with one or more computer systems. The information includes at least one of an actual optical image of the specimen, an actual electron beam image of the specimen, and design data for the specimen. The method also includes inputting the information for the specimen into a learning based model. The learning based model is included in one or more components executed by the one or more computer systems. The learning based model is configured for mapping a triangular relationship between optical images, electron beam images, and design data, and the learning based model applies the triangular relationship to the input to thereby generate simulated images for the specimen.","['G06T7/0006', 'H01L22/12', 'G03F1/84', 'G03F1/86', 'G03F7/7065', 'G06T7/0004', 'G06T7/001', 'H01L21/67242', 'H01L22/14', 'H01L22/24', 'H01L22/34', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/30148']"
CN110363215B,A method for converting SAR image to optical image based on generative adversarial network,"The invention discloses a method for converting an SAR image into an optical image based on a generating countermeasure network, which utilizes a deep learning and image processing method to complete the technology of converting the SAR image into the optical image, and completes the task of converting a large-size SAR image into an optical image which is convenient to understand through segmentation and re-splicing. The method can greatly reduce the workload of manual intervention, completes the automatic conversion of the SAR image according to the characteristics of the scene to be processed, has better processing effect of the detail part of the image, keeps the conversion result image consistent with the SAR image in the aspect of keeping the space structure information of the ground objects, and has the effect of being very close to the target image in the aspects of texture, hue, spectrum and the like.","['G06F18/214', 'G06F18/241', 'G06V20/13', 'G06V20/20']"
CN110222668B,Multi-pose facial expression recognition method based on generative adversarial network,"The invention discloses a multi-pose facial expression recognition method based on a generation countermeasure network. The invention relates to a multi-pose facial expression recognition method based on a generated confrontation network, which comprises the following steps: the expression recognition system under the multiple facial gestures adds a front face synthesis module in the expression recognition process, and simultaneously inputs the face detected by the system and the synthesized front face into a recognition network, so that the recognition performance under the large-gesture deflection of the face is improved, and the expression recognition under the multiple facial deflection gestures is realized. The invention has the beneficial effects that: the multi-face gesture expression recognition system based on the front face synthesis module constructed by the presented generation countermeasure network mainly has the following advantages: 1. the front face synthesis module based on the generation countermeasure network can synthesize the front face of the original image through the input human face with any angle, so that the front face information is provided for the expression recognition system, and the expression information is guaranteed to be correctly recognized when the human face deflects in a large posture.","['G06F18/214', 'G06F18/251', 'G06V40/168', 'G06V40/174']"
US11699080B2,Communication efficient machine learning of data across multiple sites,"In one embodiment, a service receives machine learning-based generative models from a plurality of distributed sites. Each generative model is trained locally at a site using unlabeled data observed at that site to generate synthetic unlabeled data that mimics the unlabeled data used to train the generative model. The service receives, from each of the distributed sites, a subset of labeled data observed at that site. The service uses the generative models to generate synthetic unlabeled data. The service trains a global machine learning-based model using the received subsets of labeled data received from the distributed sites and the synthetic unlabeled data generated by the generative models.","['G06F18/2155', 'G06F18/253', 'G06F9/48', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/091', 'G06N3/094', 'G06N3/098', 'G06N5/01', 'H04Q9/00']"
US11315343B1,Adversarial optimization method for training process of generative adversarial network,"The invention relates to an adversarial optimization method for the training process of generative adversarial network. According to the adversarial optimization method for the training process of generative adversarial network, the optimal transmission problem is transformed into solving the elliptic Monge-Ampere partial differential equation (MAPDE) in the generator G. To solve MAPDE of n (n>3) dimensions, the Neumann boundary conditions are improved and the discretization of MAPDE is extended to obtain the optimal mapping between a generator and a discriminator, which constitutes the adversarial network MAGAN. In the process of training the defence network, by overcoming the loss function of the optimal mapping, the defence network can obtain a maximum distance between the two measurements and obtain filtered security samples. The effective attack method of GANs is successfully established, with the precision improved by 5.3%. In addition, the MAGAN can be stably trained without adjusting hyper-parameters, so that the accuracy of target classification and recognition system for unmanned vehicle can be well improved.","['G06N3/08', 'G06F17/13', 'G06F18/214', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06V10/774', 'G06V20/56', 'Y02T10/40']"
US11431300B2,Machine learning based digital pre-distortion for power amplifiers,"Example embodiments relate to machine learning based digital pre-distortion for power amplifiers. A device may amplify a signal with a power amplifier and transmit the signal. The signal may be received by an internal feedback receiver of the device. The device may further comprise a first machine learning model configured to emulate an external feedback receiver and to generate an emulated feedback signal based on the internal feedback signal. The device may further comprise a second machine learning model configured to determine digital pre-distortion parameters for the power amplifier based on the emulated feedback signal. Apparatuses, methods, and computer programs are disclosed.","['H03F1/3247', 'H03F1/32', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'H03F3/19', 'H03F3/24', 'H03F3/245', 'H04B1/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H03F1/3258', 'H03F2200/451', 'H03F2201/3227', 'H03F2201/3231', 'H03F2201/3233', 'H04B2001/0425']"
US10832091B2,Machine learning to process Monte Carlo rendered images,A method of rendering an image includes Monte Carlo rendering a scene to produce a noisy image. The noisy image is processed to render an output image. The processing applies a machine learning model that utilizes colors and/or features from the rendering system for denoising the noisy image and/or to for adaptively placing samples during rendering.,"['G06N3/084', 'G06K9/6256', 'G06F18/214', 'G06N7/005', 'G06N7/01', 'G06T15/06', 'G06T15/50', 'G06T5/002', 'G06T5/60', 'G06T5/70', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US12045705B2,Dynamic and intuitive aggregation of a training dataset,"A system receives information associated with an interaction with an individual in a context. Then, the system analyzes the information to extract features associated with one or more attributes of the individual. Moreover, the system generates, based at least in part on the extracted features, a group of behavioral agents in a multi-layer hierarchy that automatically mimics the one or more attributes. Next, the system calculates one or more performance metrics associated with the group of behavioral agents and the one or more attributes. Furthermore, the system determines, based at least in part on the one or more performance metrics, one or more deficiencies in the extracted features. Additionally, the system selectively acquires second information associated with additional interaction with the individual in the context based at least in part on the one or more deficiencies to at least in part correct for the one or more deficiencies.","['G06F11/008', 'G06F11/3024', 'G06F11/3409', 'G06F11/3447', 'G06F11/3452', 'G06N20/00', 'G06N3/004', 'G06N3/006', 'G06N3/008', 'G06N3/02', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06T11/001', 'G06T13/40', 'G06F2201/815', 'G06N3/044', 'G06T17/20']"
CN111753908B,Image classification method and device and style transfer model training method and device,"The embodiment of the application discloses an image classification method and device and a style migration model training method and device, and relates to the fields of deep learning, cloud computing and computer vision in artificial intelligence. The specific implementation scheme is as follows: inputting the first style image into a style migration model to obtain a second style image corresponding to the first style image; inputting the second style image into an image classification model to obtain a classification result of the second style image; the style migration model is obtained based on training of a first style sample image and a second style sample image; the image classification model is trained based on the second style of sample images. The embodiment of the application can improve the accuracy of image classification. The embodiment of the application can be applied to fundus screening.","['G06F18/24', 'G06F18/2413', 'G06V10/82', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/50', 'G06V10/507', 'G06V10/56', 'G06V10/765', 'G16H10/40', 'G16H30/40', 'G16H50/20', 'G06V10/774', 'G06V2201/03']"
WO2022097932A1,"Apparatus for reconstructing, based on deep learning, three-dimensional model from two-dimensional image and method therefor","Provided are an apparatus for reconstructing, based on deep learning, a three-dimensional model from a two-dimensional image and a method therefor. The apparatus for reconstructing a three-dimensional model according to some embodiments of the present disclosure may comprise: a memory that stores one or more instructions; and a processor that acquires a two-dimensional input image of a target object by executing the stored one or more instructions, and reconstructs, via a deep learning network, a three-dimensional voxel model of the target object from the input image. The apparatus for reconstructing a three-dimensional model can improve the accuracy of three-dimensional model reconstruction by using the deep learning network.","['G06T15/08', 'G06N3/08', 'G06T15/10', 'G06T5/00', 'G06T7/13', 'G06T2207/20081', 'G06T2207/20084']"
CN111598762B,A generative robust image steganography method,"The invention provides a generating type robust image steganography method, which comprises the following steps: constructing an image data set, and preprocessing the image data set; constructing and initializing a deep learning network architecture; training a deep learning network architecture by adopting a joint-fine tuning method to obtain a network architecture model; and generating a secret pseudo-graph by using the network architecture model, and carrying out secret communication to complete the image steganography process. The image steganography method provided by the invention integrates the embedding process of secret information into the generating process of the image by utilizing the generating countering network StyleGAN, and constructs a generating image steganography framework which can bear secret information with larger capacity and has certain robustness, so that the obtained generating image steganography method has the advantages of larger embedding capacity, good generated image quality, strong carrying image statistics undetectability, high practicability and the like, and solves the problems of poor carrying image quality, low embedding capacity, low information extraction accuracy and the like of the traditional generating image steganography.","['G06T1/005', 'G06N3/045', 'G06N3/088']"
CN108268638B,Distributed implementation method for generating countermeasure network based on Spark framework,"A distributed realization method for generating a countermeasure network based on a Spark framework adopts the following steps: the main node randomly initializes the network configuration and generates a parameter set; directly uploading the data file to a distributed file system; constructing a flexible distributed data set of Spark; for each training data subset RDD, the master node transmits the parameters, configuration, update state of the network to all slave nodes; each slave node trains partial data and updates parameters; and (4) parallelly training in a data parallel mode to generate an antagonistic network model until Nash equilibrium is reached, and finishing training. The method is distributed training for generating a confrontation network model when facing mass data. Meanwhile, the advantage that Spark is based on a memory computing frame and is suitable for recursive computation is fully utilized, training for generating a confrontation network model can be accelerated, efficiency is improved, and better expandability is achieved.","['G06F16/182', 'G06N3/045', 'G06N3/084']"
US12182940B2,Self-supervised single-view 3D reconstruction via semantic consistency,"Apparatuses, systems, and techniques to identify a shape or camera pose of a three-dimensional object from a two-dimensional image of the object. In at least one embodiment, objects are identified in an image using one or more neural networks that have been trained on objects of a similar category and a three-dimensional mesh template.","['G06T17/20', 'G06F18/217', 'G06T17/00', 'G06T7/40', 'G06T7/50', 'G06T7/74', 'G06V10/26', 'G06V10/776', 'G06V10/82', 'G06V20/64', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
US11836852B2,Neural network-based millimeter-wave imaging system,"A method includes receiving data including a plurality of data items, each data item of the plurality of data items including a three-dimensional (3D) radar heat map of an object and a corresponding two-dimensional (2D) image of the object captured by a stereo camera, inputting the training dataset into a machine learning model including a neural network (NN) that generates, from the 3D radar heat map, a 2D depth map for the object and outputs a probability that the 2D depth map is the corresponding 2D image of the object, and training the machine learning model based on a training dataset to generate a trained machine learning model that iteratively learns to generate an updated 2D depth map that approximates the corresponding 2D image. The training dataset includes the plurality of data items, the 2D depth map and the probability.","['G06T17/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T15/04', 'G06T15/06', 'G06T7/55', 'G06T7/593', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06V20/64', 'G06V20/647', 'G06T2207/10012', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US11768866B2,Dark web content analysis and identification,"In some examples, dark web content analysis and identification may include ascertaining data that includes text and images, and analyzing the data by performing deep learning based text and image processing to extract text embedded in the images, and deep embedded clustering to generate clusters. Clusters that are to be monitored may be ascertained from the generated clusters. A determination may be made as to whether the ascertained data is sufficient for classification. If so, a deep convolutional generative adversarial networks (DCGAN) based detector may be utilized to analyze further data with respect to the ascertained clusters, and alternatively, a convolutional neural network (CNN) based detector may be utilized to analyze the further data with respect to the ascertained clusters. Based on the analysis of the further data, an operation associated with a website related to the further data may be controlled.","['G06F16/355', 'G06F16/951', 'G06F18/2321', 'G06N3/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/30', 'G06V10/454', 'G06V10/763', 'G06V10/82', 'G06V20/62', 'G06V30/19127', 'G06V30/413', 'H04L63/1425', 'H04L67/02']"
US11625812B2,Recovering occluded image data using machine learning,"Examples disclosed herein are related to using a machine learning model to generate image data. One example provides a system, comprising one or more processors, and storage comprising instructions executable by the one or more processors to obtain image data comprising an image with unoccluded features, apply a mask to the unoccluded features in the image to form partial observation training data comprising a masked region that obscures at least a portion of the unoccluded features, and train a machine learning model comprising a generator and a discriminator at least in part by generating image data for the masked region and comparing the image data generated for the masked region to the image with unoccluded features.","['G06T5/77', 'G06T5/005', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06T5/60', 'G06V10/273', 'G06V10/774', 'G06V10/82', 'G06V20/13', 'G01S13/9021', 'G06T2207/10024', 'G06T2207/10036', 'G06T2207/10044', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30181', 'G06V20/194']"
US20210073630A1,Training a class-conditional generative adversarial network,"A computer-implemented method and system are described for training a class-conditional generative adversarial network (GAN). The discriminator is trained using a classification loss function while omitting using an adversarial loss function. Instead, if the training data has C classes, the classification loss function is formulated as a 2C-class classification problem, by which the discriminator is trained to distinguish 2 times C classes. Such trained discriminator provides an informative training signal for the generator to learn the class-conditional data synthesis by the generator. A data synthesis system and computer-implemented method are also described for synthesizing data using the generative part of the trained generative adversarial network.","['G06F18/2155', 'G06N3/084', 'B60W60/00', 'G06F18/24', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06V20/56', 'G06V20/58']"
US11416745B1,Adversarial training of neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for adversarial training of a neural network. One of the methods includes obtaining a plurality of training inputs; and training the neural network on each of the training inputs, comprising, for each of the training inputs: processing the training input using the neural network to determine a neural network output for the training input; applying a perturbation to the training input to generate an adversarial perturbation of the training input; processing the adversarial perturbation of the training input using the neural network to determine a neural network output for the adversarial perturbation; and adjusting the current values of the parameters of the neural network by performing an iteration of a neural network training procedure to optimize an adversarial objective function.","['G06N3/08', 'G06N3/088', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/044']"
US11886989B2,System for measuring information leakage of deep learning models,"Using a deep learning inference system, respective similarities are measured for each of a set of intermediate representations to input information used as an input to the deep learning inference system. The deep learning inference system includes multiple layers, each layer producing one or more associated intermediate representations. Selection is made of a subset of the set of intermediate representations that are most similar to the input information. Using the selected subset of intermediate representations, a partitioning point is determined in the multiple layers used to partition the multiple layers into two partitions defined so that information leakage for the two partitions will meet a privacy parameter when a first of the two partitions is prevented from leaking information. The partitioning point is output for use in partitioning the multiple layers of the deep learning inference system into the two partitions.","['G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/048']"
US11534136B2,Three-dimensional segmentation from two-dimensional intracardiac echocardiography imaging,"For three-dimensional segmentation from two-dimensional intracardiac echocardiography imaging, the three-dimension segmentation is output by a machine-learnt multi-task generator. The machine-learnt multi-task generator is trained from 3D information, such as a sparse ICE volume assembled from the 2D ICE images. The machine-learnt multi-task generator is trained to output both the 3D segmentation and a complete volume. The 3D segmentation may be used to project to 2D as an input with an ICE image to another network trained to output a 2D segmentation for the ICE image. Display of the 3D segmentation and/or 2D segmentation may guide ablation of tissue in the patient.","['A61B8/483', 'A61B5/0044', 'A61B5/06', 'A61B5/1128', 'A61B6/12', 'A61B8/0883', 'A61B8/12', 'A61B8/13', 'A61B8/145', 'A61B8/5207', 'A61B8/5215', 'A61B8/5261', 'A61B90/36', 'A61B90/37', 'G06T15/205', 'G06T7/12', 'A61B18/1492', 'A61B2018/00357', 'A61B2018/00577', 'A61B2034/105', 'A61B2034/2051', 'A61B2034/2063', 'A61B2090/363', 'A61B2090/367', 'A61B2090/374', 'A61B2090/3762', 'A61B2090/378', 'A61B2090/3784', 'A61B2090/3966', 'A61B5/055', 'A61B5/7264', 'A61B8/0891', 'A61B8/4245', 'A61B8/4254', 'A61B8/4483', 'A61B8/466', 'G06T13/20', 'G06T2200/08', 'G06T2207/10132', 'G06T2207/10136', 'G06T2207/20004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T7/344']"
US11290483B1,Platform for developing high efficacy detection content,"Described are platforms, systems, and methods for providing a threat scenario rule to detect a specified threat scenario use case. In one aspect, a method comprises: receiving, from an interface, a set of threat detection parameters; determining a set of recommended threat identifier use cases from a plurality of threat identifier use cases based on the set of threat detection parameters; providing, to the interface, the set of recommended threat identifier use cases; receiving, from the interface, a threat scenario use case comprising a selection of the set of recommended threat identifier use cases; determining a threat scenario rule comprising logic to detect the threat scenario use case; and providing the threat scenario rule to the interface.","['H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1466']"
US11030485B2,"Systems and methods for feature transformation, correction and regeneration for robust sensing, transmission, computer vision, recognition and classification",Embodiments of a deep learning enabled generative sensing and feature regeneration framework which integrates low-end sensors/low quality data with computational intelligence to attain a high recognition accuracy on par with that attained with high-end sensors/high quality data or to optimize a performance measure for a desired task are disclosed.,"['G06K9/6257', 'G06N3/084', 'G06F18/2132', 'G06F18/2134', 'G06F18/2148', 'G06F18/217', 'G06F18/22', 'G06F18/2413', 'G06F18/2431', 'G06F18/251', 'G06K9/6215', 'G06K9/6234', 'G06K9/6262', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T5/002', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/803', 'G06V10/993', 'G06V20/00', 'G06N20/10', 'G06V10/143']"
US20230396638A1,Adaptive system for network and security management,"Systems and methods are described for identifying computer risk. A system may receive a set of input signals from third party sources. The system may characterize the input signals to derive an attack graph. The system may then emulate a threat or attack based on the attack graph. After emulation, the system may determine a risk score based on the attack graph.","['G06F21/554', 'H04L63/1425', 'G06F16/285', 'H04L63/1408', 'H04L63/1416', 'H04L63/1433', 'H04L63/1466', 'H04L63/20']"
US11468262B2,Deep network embedding with adversarial regularization,"Methods and systems for embedding a network in a latent space include generating a representation of an input network graph in the latent space using an autoencoder model and generating a representation of a set of noise samples in the latent space using a generator model. A discriminator model discriminates between the representation of the input network graph and the representation of the set of noise samples. The autoencoder model, the generator model, and the discriminator model are jointly trained by minimizing a joint loss function that includes parameters for each model. A final representation of the input network graph is generated using the trained autoencoder model.","['G06K9/6252', 'G06N3/084', 'G06F18/2137', 'G06F18/21375', 'G06F18/22', 'G06F18/2413', 'G06K9/6215', 'G06K9/6251', 'G06K9/627', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/094', 'G06V10/454']"
US10726555B2,Joint registration and segmentation of images using deep learning,A system for registering and segmenting images includes an image scanner configured to acquire an image pair including a first image at a first time and a second image at a second time that is after the first time. A joint registration and segmentation server receives the image pair from the image scanner and simultaneously performs joint registration and segmentation on the image pair using a single deep learning framework. A computer vision processor receives an output of the joint registration and segmentation server and characterizes how a condition has progressed from the first time to the second time therefrom. A user terminal presents the characterization to a user.,"['G06T7/0016', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/086', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/10', 'G06T7/174', 'G06T7/30', 'G06T7/33', 'G06T7/337', 'G06T7/38', 'G06N3/048', 'G06T2207/10008', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
US10936910B2,Systems and methods for joint adversarial training by incorporating both spatial and pixel attacks,"Described herein are embodiments for joint adversarial training methods that incorporate both spatial transformation-based and pixel-value based attacks for improving image model robustness. Embodiments of a spatial transformation-based attack with an explicit notion of budgets are disclosed and embodiments of a practical methodology for efficient spatial attack generation are also disclosed. Furthermore, both pixel and spatial attacks are integrated into embodiments of a generation model and the complementary strengths of each other are leveraged for improving the overall model robustness. Extensive experimental results on several benchmark datasets compared with state-of-the-art methods verified the effectiveness of the presented method.","['G06N20/00', 'G06F18/214', 'G06K9/6257', 'G06F18/2148', 'G06F18/24', 'G06K9/6232', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06N3/084']"
US11645356B2,Deep learning for partial differential equation (PDE) based models,"Embodiments for deep learning for partial differential equation (PDE)-based models by a processor. A trained forecasting model and consistency constraints may be generated using a PDE-based model, a discretization of the PDE-based model, historical inputs the of the PDE-based model, and a representation of consistency constraints to generate a predictive output.","['G06F17/13', 'G06F18/214', 'G06F18/2413', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06F2218/12', 'G06N3/044']"
EP3964998A1,Text processing method and model training method and apparatus,"This application relates to the field of artificial intelligence, and provides a text processing method, a model training method, and an apparatus. The method includes: obtaining target knowledge data, where the target knowledge data includes a first named entity, a second named entity, and an association between the first named entity and the second named entity; processing the target knowledge data to obtain a target knowledge vector; processing to-be-processed text to obtain a target text vector, where the to-be-processed text includes the first named entity; fusing the target text vector and the target knowledge vector based on a target fusion model, to obtain a fused target text vector and a fused target knowledge vector; and processing the fused target text vector and/or the fused target knowledge vector based on a target processing model, to obtain a processing result corresponding to a target task. The foregoing technical solution can improve accuracy of a result of processing a target task by the target processing model.","['G06N3/084', 'G06F18/214', 'G06F40/205', 'G06F40/211', 'G06F40/216', 'G06F40/295', 'G06F40/30', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06F40/237', 'G06F40/279', 'G06F40/284']"
US20210064858A1,Transformation of hand-drawn sketches to digital images,"Techniques are disclosed for generating a vector image from a raster image, where the raster image is, for instance, a photographed or scanned version of a hand-drawn sketch. While drawing a sketch, an artist may perform multiple strokes to draw a line, and the resultant raster image may have adjacent or partially overlapping salient and non-salient lines, where the salient lines are representative of the artist's intent, and the non-salient (or auxiliary) lines are formed due to the redundant strokes or otherwise as artefacts of the creation process. The raster image may also include other auxiliary features, such as blemishes, non-white background (e.g., reflecting the canvas on which the hand-sketch was made), and/or uneven lighting. In an example, the vector image is generated to include the salient lines, but not the non-salient lines or other auxiliary features. Thus, the generated vector image is a cleaner version of the raster image.","['G06K9/00409', 'G06T9/00', 'G06F18/214', 'G06K9/4671', 'G06K9/6256', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T11/203', 'G06T9/20', 'G06V10/462', 'G06V30/19147', 'G06V30/333', 'G06N3/048']"
CN108665058B,A Generative Adversarial Network Method Based on Segmentation Loss,"A method for generating a countermeasure network based on segment loss comprises the following steps: 1. initializing parameters: setting the batch size m to be 100 and the super parameter k to be 1, initializing parameters by using an Xavier method, determining a maximum iteration number and a loss switching iteration number parameter T, and enabling the iteration number epoch to be 0; 2. training discriminator parameters: let i equal to 1, i be a cyclic variable; 3. training generator parameters; and (3) judging whether the epoch is greater than the maximum iteration number or not, if so, repeating the steps 2 and 3, and if so, ending the training. The method can realize that the generator adopts loss functions of different forms at different training stages, make up for the deficiency of the GAN theory under the single loss form to a certain extent, and make the network training more stable; by introducing the loss of the characteristic level between the real sample and the generated sample, the characteristics extracted by the discriminator are more robust.","['G06N3/045', 'G06V40/50']"
US20240297900A1,Phishing url detection using transformers,"The technology described herein can identify phishing URLs using transformers. The technology tokenizes useful features from the subject URL. The useful features can include the text of the URL and other data associated with the URL, such as certificate data for the subject URL, a referrer URL, an IP address, etc. The technology may build a joint Byte Pair Encoding for the features. The token encoding may be processed through a transformer, resulting in a transformer output. The transformer output, which may be described as a token embedding, may be input to a classifier to determine whether the URL is a phishing URL. Additional or improved URL training data may be generated by permuting token order, by simulating a homoglyph attack, and by simulating a compound word attack.","['H04L63/168', 'G06F21/554', 'G06F21/56', 'G06F21/566', 'G06F40/284', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06N3/096', 'H04L63/1466', 'H04L63/1483', 'G06F2221/2119']"
CN111507888B,Method and device for generating synthetic images using generative adversarial neural networks,"The invention provides a method for generating a synthetic image which can not judge whether to synthesize by fusion of heterogeneous sensors by utilizing a generative countermeasure neural network comprising a generating neural network and a discriminating neural network in order to enable a monitoring system to more accurately identify surrounding conditions and detect rare events such as dangerous conditions. The method of the invention comprises the following steps: a step in which a computing device generates a position candidate group of a rare object in a background image, and selects a specific position candidate group among the position candidate groups of the rare object as an optimal position of the rare object with reference to a candidate group number; inserting a rare object image into the optimal position to generate an initial composite image; and a step of adjusting color values corresponding to the respective pixels included in the initial synthesized image to generate the synthesized image for which whether the synthesis is impossible is determined. In addition, the invention can also be used for pedestrian auxiliary systems and path setting by utilizing 3D maps, GPS, smart phones, V2X communication and the like.","['G06N3/088', 'G06T3/04', 'G06F17/153', 'G06F18/24143', 'G06F18/25', 'G06F18/254', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/809', 'G06V10/82', 'G06V20/41', 'G06V20/52', 'G06V20/44']"
US10346740B2,Systems and methods incorporating a neural network and a forward physical model for semiconductor applications,"Methods and systems for training a neural network are provided. One system includes one or more components executed by one or more computer subsystems. The one or more components include a neural network configured for determining inverted features of input images in a training set for a specimen input to the neural network, a forward physical model configured for reconstructing the input images from the inverted features thereby generating a set of output images corresponding to the input images in the training set, and a residue layer configured for determining differences between the input images in the training set and their corresponding output images in the set. The one or more computer subsystems are configured for altering one or more parameters of the neural network based on the determined differences thereby training the neural network.","['G06V10/82', 'G06N3/0499', 'G06F18/24143', 'G06K9/6274', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06V10/764']"
US11461963B2,Systems and methods for generating synthetic light detection and ranging data via machine learning,"The present disclosure provides systems and methods that combine physics-based systems with machine learning to generate synthetic LiDAR data that accurately mimics a real-world LiDAR sensor system. In particular, aspects of the present disclosure combine physics-based rendering with machine-learned models such as deep neural networks to simulate both the geometry and intensity of the LiDAR sensor. As one example, a physics-based ray casting approach can be used on a three-dimensional map of an environment to generate an initial three-dimensional point cloud that mimics LiDAR data. According to an aspect of the present disclosure, a machine-learned geometry model can predict one or more adjusted depths for one or more of the points in the initial three-dimensional point cloud, thereby generating an adjusted three-dimensional point cloud which more realistically simulates real-world LiDAR data.","['G06T17/05', 'G01S17/931', 'G01S17/89', 'G05D1/0231', 'G05D1/249', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T15/06', 'G07C5/02', 'G05D2201/0213', 'G06N3/084']"
EP4244718A1,Methods and systems for trusted unknown malware detection and classification in linux cloud environments,"A method for detection of unknown malware in Linux cloud environment, the method including: within a hypervisor, acquiring a raw data set comprising one or more volatile memory dumps of a Linux cloud server, wherein the volatile memory dumps are associated with a current state of the virtual machine's volatile memory, extracting one or more features from the raw data set (either by utilizing knowledge based features or by utilizing Deep Learning CNN architectures), and classifying, using at least one classifier, the one or more features, to determine if one or more of the features are associated with a malware, thereby detecting malware in a Linux cloud environment and distinguishing between a benign or malicious state of the server.","['G06F21/566', 'G06F21/56', 'G06F21/53', 'G06F9/45533', 'G06F9/45558', 'G06N3/0464', 'G06F2009/45587', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06N5/01', 'G06N7/01']"
EP3404586A1,Novelty detection using discriminator of generative adversarial network,An example apparatus for detecting novel data includes a discriminator trained using a generator to receive data to be classified. The discriminator may also be trained to classify the received data as novel data in response to detecting that the received data does not correspond to known categories of data.,"['G06F18/241', 'G06N3/088', 'G06F18/214', 'G06F18/2433', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06V30/194', 'H04L43/04', 'G06F18/24']"
US12293007B2,Object authentication using digital blueprints and physical fingerprints,"A method of object authentication based on digital blueprints and physical fingerprints comprising the steps of acquiring a set of training blueprints and fingerprints, training, object enrollment and object authentication. The method uses a pair of a mapper realized as an encoder and a decoder and a set of multi-metric scores originating from the decomposition of mutual information and applied to both the output of the encoder and decoder and producing a feature vector for a one-class classifier. The method is trained only on the original physical objects and does not use any fakes for reliable authentication.","['G06V20/80', 'G06F21/64', 'G06F18/2135', 'G06F18/214', 'G06F18/217', 'G06F18/22', 'G06F18/24133', 'G06F18/2433', 'G06N20/10', 'G06N20/20']"
US11514948B1,Model-based dubbing to translate spoken audio in a video,Model-based dubbing techniques are implemented to generate a translated version of a source video. Spoken audio portions of a source video may be extracted and semantic graphs generated that represent the spoken audio portions. The semantic graphs may be used to produce translations of the spoken portions. A machine learning model may be implemented to generate replacement audio for the spoken portions using the translation of the spoken portion. A machine learning model may be implemented to generate modifications to facial image data for a speaker of the replacement audio.,"['G11B27/036', 'G06F16/2365', 'G06F16/7834', 'G06F40/30', 'G06F40/58', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'G10L13/00', 'G10L17/00', 'G11B27/10', 'H04N21/2343', 'H04N21/234336', 'H04N21/23439', 'H04N7/155', 'G06N3/04', 'G10L13/033']"
US20210092161A1,Collaborative database and reputation management in adversarial information environments,"A system and method for the contextualization and management of collaborative databases in an adversarial information environment. The system and method feature the ability to scan for, ingest and process, and then use relational, wide column, and graph stores for capturing entity data, their relationships, and actions associated with them. Furthermore, meta-data is gathered and linked to the ingested data, which provides a broader contextual view of the environment leading up to and during an event of interest. The gathered data and meta-data is used to manage the reputation of the contributing data sources. The system links each successive data set, algorithm, or meta-data which might pertain to its unique identification and to its ultimate reputation, utility, or fitness for purpose.","['H04L63/20', 'G06F16/951', 'G06F16/2477', 'G06F21/6218', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L67/1097']"
CN113449783B,"Countermeasure sample generation method, system, computer device and storage medium","The invention provides a method, a system, computer equipment and a storage medium for generating a countermeasure sample, which are used for solving the problem that the importance degree of gradient information is not distinguished in the prior art, increasing the concealment of the countermeasure sample while generating a uniform distribution disturbance defect in areas with different image information entropies and improving the attack effect of the countermeasure sample.","['G06F18/214', 'G06N3/08']"
AU2020101836A4,A method for generating femoral x-ray films based on deep learning and digital reconstruction of radiological image,"The invention provides a method for generating femoral X-ray films based on deep learning and digital reconstruction of radiological images, which comprises the following steps: performing deep multi-task regression through a three-dimensional convolution neural network model, automatically extracting CT slices containing trochanter and femoral medial and lateral condyles, segmenting images of femoral trochanter medial and lateral condyles by using a conditional generation antagonistic neural network, performing three-dimensional surface reconstruction on the two areas, calculating the vertices of trochanter and femoral medial and lateral condyles by calculating Gaussian curvature, After calculating the angle between the plane of three points and the horizontal plane, the final angle that needs to be rotated and corrected is obtained. By digitally reconstructing the radiological image, the X ray film analog image at the best position is obtained, replacing the film image used by the traditional CT analog positioning machine. According to the problems that the femoral position in the digital reconstruction radiological image can only be manually calibrated by doctors, the intelligent level is not high, the calibration stability is poor, and the actual needs cannot be met, the computer-aided method is used for correcting the femoral CT film and simulating the X-ray film, which can promote the intelligentization of medical equipment. -2/7 Image M qsands lice marking of femom1CT samples Constding 3D CNN fir keyslie recognition Segmerdaton oflesse tre andmedial and latemlfemoml based onCGAN Three-dimensioalreconstnrtionoftrcr terandfeamoml e surface Surface Gaussian curvature calculationand vertex solution Three-dimensimlreconstndion ofthe sudsce ofthe less trhter and femml co e DigitalreconstdionofradL imags Gerration of femx x-ray fim Fig. 2","['A61B5/004', 'A61B5/0073', 'A61B6/03', 'A61B6/505', 'A61B6/5223', 'G06N3/02', 'G06T11/003', 'G06T19/20', 'G06T7/0012', 'G06T7/10', 'G16H30/40', 'A61B2576/02', 'A61B34/10', 'A61B5/7267', 'G06T2207/10072', 'G06T2207/10124', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2211/40', 'G06T2219/004', 'G06T2219/2016']"
US11689021B2,Power grid reactive voltage control model training method and system,"A power grid reactive voltage control model training method. The method comprises: establishing a power grid simulation model; establishing a reactive voltage optimization model, according to a power grid reactive voltage control target; building interactive training environment based on Adversarial Markov Decision Process, in combination with the power grid simulation model and the reactive voltage optimization model; training the power grid reactive voltage control model through a joint adversarial training algorithm; and transferring the trained power grid reactive voltage control model to an online system. The power grid reactive voltage control model trained by using the method according to the present disclosure has transferability as compared with the traditional method, and may be directly used for online power grid reactive voltage control.","['G06F30/27', 'H02J3/18', 'G06F30/20', 'G06N3/045', 'G06N3/08', 'G06Q50/06', 'G09B9/00', 'H02J13/00001', 'H02J3/001', 'G06F2113/04', 'H02J2203/20', 'Y02E40/30', 'Y02E40/70', 'Y02E60/00', 'Y04S10/40', 'Y04S10/50', 'Y04S40/20']"
US11615505B2,"Apparatus and method for image processing, and system for training neural network","The present disclosure generally relates to the field of deep learning technologies. An apparatus for generating a plurality of correlation images may include a feature extracting unit configured to receive a training image and extracting at least one or more of feature from the training image to generate a first feature image based on the training image; a normalizer configured to normalize the first feature image and generate a second feature image; and a shift correlating unit configured to perform a plurality of translational shifts on the second feature image to generate a plurality of shifted images, correlate each of the plurality of shifted images with the second feature image to generate the plurality of correlation images.","['G06T3/4053', 'G06F17/16', 'G06F18/00', 'G06F18/2148', 'G06F18/241', 'G06K9/6232', 'G06K9/6257', 'G06K9/6268', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/20', 'G06T3/40', 'G06T3/4007', 'G06T3/4046', 'G06T3/4076', 'G06T5/002', 'G06T5/007', 'G06T5/50', 'G06T5/70', 'G06T5/90', 'G06V10/42', 'G06V10/454', 'G06V10/751', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212']"
US11948314B2,Systems and methods for image processing,"The present disclosure is related to systems and methods for image processing. The method includes obtaining a first image of a first modality. The method includes generating a second image of a second modality by processing, based on a trained machine learning model, the first image. The second modality may be different from the first modality.","['G06T7/30', 'G06T5/77', 'G06T5/60', 'G06T7/55', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US10783455B2,Bot-based data collection for detecting phone solicitations,"One embodiment provides a method comprising answering one or more incoming phone calls received at one or more pre-specified phone numbers utilizing a bot. The bot is configured to engage in a conversation with a caller initiating an incoming phone call utilizing a voice recording that impersonates a human being. The method further comprises recording each conversation the bot engages in, and classifying each recorded conversation as one of poison data or truthful training data based on content of the recorded conversation and one or more learned detection models for detecting poisoned data.","['H04M3/436', 'G06N20/00', 'G10L15/1822', 'G10L15/26', 'G10L15/265', 'G10L17/00', 'G10L17/005', 'G10L17/06', 'G10L25/48', 'H04M2201/41', 'H04M2203/6027']"
US10380983B2,Machine learning to generate music from text,"The present disclosure provides systems and methods that leverage one or more machine-learned models to generate music from text. In particular, a computing system can include a music generation model that is operable to extract one or more structural features from an input text. The one or more structural features can be indicative of a structure associated with the input text. The music generation model can generate a musical composition from the input text based at least in part on the one or more structural features. For example, the music generation model can generate a musical composition that exhibits a musical structure that mimics or otherwise corresponds to the structure associated with the input text. For example, the music generation model can include a machine-learned audio generation model. In such fashion, the systems and methods of the present disclosure can generate music that exhibits a globally consistent theme and/or structure.","['G10H1/0025', 'G06F17/241', 'G06F17/2785', 'G06F40/169', 'G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G10H2210/111', 'G10H2240/085', 'G10H2250/311', 'G10L25/30']"
US10839262B2,Machine learning a feature detector using synthetic training data,Synthetic training information/data of a second probe style is generated based on first probe information/data of a first probe style using a style transfer model. First probe information/data is defined. An instance of first probe information/data comprises labels and first probe style sensor information/data. A style transfer model generates training information/data based on at least a portion of the first probe information/data. An instance of training information/data corresponds to an instance of first probe information/data and comprises second probe style sensor information/data. The first and second probe styles are different. A second probe style model is trained using machine learning and the training information/data. The second probe style model is used to analyze second probe style second probe information/data to extract map information/data from the second probe information/data. Each instance of second probe data is captured by one or more second probe sensors of a second probe apparatus.,"['G06K9/6256', 'G06V10/82', 'G01C21/3602', 'G01C21/3841', 'G01C21/3881', 'G06F18/214', 'G06K9/66', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T17/05', 'G06V10/774', 'G06V20/56', 'G06N3/084', 'G06T17/20']"
CN112924749B,Unsupervised adversarial learning method for abnormal signal detection in electromagnetic spectrum,"The invention discloses an unsupervised pairThe learning-resistant electromagnetic spectrum abnormal signal detection method comprises the following steps: preprocessing the acquired power spectrum data to obtain power spectrum density estimation; constructing an electromagnetic spectrum anomaly detection model based on deep learning through the power spectral density estimation; determining reconstruction error L for any power spectrum data through the electromagnetic spectrum anomaly detection modelrSum decider loss Ld(ii) a According to the reconstruction error LrSum decider loss LdDetermining abnormal result AresultAnd by exception result AresultIt is determined whether an anomaly exists in the electromagnetic spectrum data. The invention combines the local characteristics of power spectrum data, uses the convolution neural network to replace the full-connection network in the traditional mode, and reduces the scale of the network; adopt and fight from the encoder, introduce the electromagnetic spectrum abnormal signal detection with fighting the thought, can learn more effective characteristic, compare that traditional ordinary codec model has better detectability.","['G01R23/16', 'G06N3/045', 'G06N3/084']"
US11367239B2,Textured neural avatars,"The present invention relates generally to the field of computer vision and computer graphics to produce full body renderings of a person for varying person pose and camera positions and, in particular, to a system and method for synthesizing 2-D image of a person. The method for synthesizing 2-D image of a person comprises: receiving (S101) 3D coordinates of body joint positions of the person defined in a camera coordinate frame, wherein the 3D coordinates of the body joint positions define a pose of the person and a viewpoint of the 2-D image; predicting (S102), using a trained machine learning predictor, a map stack of body part assignments and a map stack of body part coordinates based on the 3D coordinates of the body joint positions, wherein the map stack of body part coordinates defines texture coordinates of pixels of the body parts of the person, the map stack of body part assignments defines weights, each weight indicating a probability of particular pixel to belong to a particular body part of the person; retrieving (S103), from a memory, a map stack of textures for the body parts of the person previously initialized, wherein the map stack of textures comprises values of the pixels of the body parts of the person; and reconstructing (S104) the 2-D image of the person as a weighted combination of the values of the pixels by using the map stack of body part assignments, the map stack of body part coordinates and the map stack of textures. The system for synthesizing 2-D image of a person implements the method for synthesizing 2-D image of a person.","['G06N3/006', 'G06T15/04', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/001', 'G06T13/40', 'G06T15/205', 'G06T17/10', 'G06V40/103', 'G06N3/047']"
US11157773B2,Image editing by a generative adversarial network using keypoints or segmentation masks constraints,"Images can be edited to include features similar to a different target image. An unconditional generative adversarial network (GAN) is employed to edit features of an initial image based on a constraint determined from a target image. The constraint used by the GAN is determined from keypoints or segmentation masks of the target image, and edits are made to features of the initial image based on keypoints or segmentation masks of the initial image corresponding to those of the constraint from the target image. The GAN modifies the initial image based on a loss function having a variable for the constraint. The result of this optimization process is a modified initial image having features similar to the target image subject to the constraint determined from the identified keypoints or segmentation masks.","['G06T11/60', 'G06K9/6257', 'G06F18/2148', 'G06F18/217', 'G06F18/2413', 'G06K9/00268', 'G06K9/00302', 'G06K9/4604', 'G06K9/4652', 'G06K9/6262', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'G06V10/44', 'G06V10/764', 'G06V10/82', 'G06V40/168', 'G06V40/174', 'G06N3/08']"
CN111325115B,Adversarial cross-modal person re-identification method and system with triple constraint loss,"The invention provides a countermeasures cross-modal pedestrian re-identification method and a countermeasures cross-modal pedestrian re-identification system with triple constraint loss, wherein a training set and a test set to be identified are divided and preprocessed; constructing a countermeasure two-way network framework comprising a generator network structure and a discriminator network structure; respectively inputting the data of the visible light image and the thermal sensing image in the training set into a visible light branch and a thermal sensing branch in a generator to obtain specific pedestrian features of different modes; projecting the modal-specific pedestrian features into a common feature representation space; according to the pedestrian characteristics of the visible light picture and the thermal sensitive picture in the public characteristic representation space, a learning generator performs triple constraint and learns a discriminator; carrying out countermeasure training on the generator and the discriminator, and optimizing a public expression space to obtain a final network model; and performing cross-mode pedestrian re-identification on the test set by using the final network model to obtain an identification result. The accuracy rate of cross-modal pedestrian re-identification can be greatly improved.","['G06V40/10', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/08']"
AU2020355181B2,High fidelity speech synthesis with adversarial networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating output audio examples using a generative neural network. One of the methods includes obtaining a training conditioning text input; processing a training generative input comprising the training conditioning text input using a feedforward generative neural network to generate a training audio output; processing the training audio output using each of a plurality of discriminators, wherein the plurality of discriminators comprises one or more conditional discriminators and one or more unconditional discriminators; determining a first combined prediction by combining the respective predictions of the plurality of discriminators; and determining an update to current values of a plurality of generative parameters of the feedforward generative neural network to increase a first error in the first combined prediction.","['G06N3/08', 'G06N3/084', 'G10L13/02', 'G06F18/2115', 'G06F18/214', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G10L13/047', 'G10L25/30', 'G10L25/45']"
CN113450561B,A traffic speed prediction method based on spatiotemporal graph convolution-generative adversarial network,"A traffic speed prediction method based on a space-time graph convolution-generation countermeasure network comprises the steps of firstly, according to an urban road network structure, taking road sections in a road network as graph nodes, and taking intersections as edges connecting the nodes to construct a traffic graph network; then, acquiring sampled and collected vehicle flow speed data through a vehicle flow speed detector in an urban road network, constructing a characteristic matrix, then, using a constructed space-time graph convolutional network (STGCN) as a generator for generating a countermeasure network and a fully-connected neural network as a discriminator to generate traffic speed data through countermeasure, and performing mutual game training and lifting together to finally obtain an optimal traffic speed prediction model. The final generator for generating the confrontation network is utilized to generate a traffic state data predicted value closest to the real data, and the purpose of predicting the road network state data is achieved. The invention can realize more accurate traffic speed prediction.","['G08G1/0104', 'G06N3/045', 'G06N3/08', 'G08G1/0125', 'G08G1/0129', 'G08G1/052']"
CN110705406B,Face Beauty Prediction Method and Device Based on Adversarial Transfer Learning,"The invention discloses a method and a device for predicting facial beauty based on anti-migration learning, which implement the following steps that the method comprises the steps of screening the auxiliary tasks with highest relevance from a plurality of facial factor recognition tasks through similarity measurement, and constructing a first facial beauty prediction model according to the auxiliary tasks; migrating the general characteristic parameters formed after the confrontation network is pre-trained to a second face beauty prediction model; and inputting the face image to be detected to realize identification. The training cost of pre-training is reduced, and negative migration caused by auxiliary tasks with irrelevant factors is reduced; the amount of calculation of retraining the second face beauty prediction model is reduced through resisting transfer learning, and the effect of obtaining a more accurate model by using fewer training images is achieved.","['G06V40/161', 'G06N3/08', 'G06V40/168', 'G06V40/172']"
US11797863B2,Systems and methods for synthesizing data for training statistical models on different imaging modalities including polarized images,"A method of generating synthetic images of virtual scenes includes: placing, by a synthetic data generator implemented by a processor and memory, three-dimensional (3-D) models of objects in a 3-D virtual scene; adding, by the synthetic data generator, lighting to the 3-D virtual scene, the lighting including one or more illumination sources; applying, by the synthetic data generator, imaging modality-specific materials to the 3-D models of objects in the 3-D virtual scene in accordance with a selected multimodal imaging modality, each of the imaging modality-specific materials including an empirical model; setting a scene background in accordance with the selected multimodal imaging modality; and rendering, by the synthetic data generator, a two-dimensional image of the 3-D virtual scene based on the selected multimodal imaging modality to generate a synthetic image in accordance with the selected multimodal imaging modality.","['G06T17/00', 'G06N3/088', 'G06T15/00', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T15/04', 'G06T15/20', 'G06T17/20', 'G06T19/20', 'G06T2207/20081', 'G06T2219/2021', 'G06T2219/2024']"
CN109600956B,Data center server placement position optimization algorithm and system,"The application provides an optimization algorithm and a system for placement positions of data center servers, a machine room refrigeration model is built through a deep neural network, energy consumption of a machine room is evaluated, a generative countermeasure network is used for building a server power curve, a genetic algorithm is adopted for solving the problem of multi-objective optimization of temperature and power, the optimal deployment positions of the data center servers are calculated, the problem of optimal deployment of enterprise data center server equipment is solved, local high-temperature hot spots of the machine room are effectively reduced, the power utilization rate of a cabinet is improved, the purposes of saving energy and optimizing power distribution are achieved, and a better basis is provided for dynamic energy consumption, resource distribution and scheduling of an enterprise data center.","['H05K7/1498', 'G06N3/02', 'G06N3/126', 'Y02E40/70', 'Y04S10/50']"
CN110796080B,A Multi-pose Pedestrian Image Synthesis Algorithm Based on Generative Adversarial Network,"The invention discloses a multi-pose pedestrian image synthesis algorithm based on a generated countermeasure network, which comprises the following steps: s1: acquiring a training data set and a test data set from a pedestrian re-identification task data set mark-1501; s2: constructing and generating an countermeasure network model through a training data set according to a preset method; s3: adding an attitude information latent code into the generated countermeasure network model input by adopting a preset method; s4: constructing and generating an objective function of the countermeasure network model based on the gesture information latent codes, and synthesizing a multi-gesture pedestrian image by utilizing the generated countermeasure network model with the objective function; s5: and analyzing an experimental result according to the synthesized multi-pose pedestrian image. The beneficial effects are that: the invention effectively reduces the solution space of the generator, so that the generation of the countermeasure network training is more stable, and high-quality multi-pose pedestrian pictures can be generated.","['G06V40/10', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06T3/04', 'Y02T10/40']"
US20210150701A1,Method for training a deep learning model to obtain histopathological information from images,A method and a system for training a deep learning model to obtain histopathological information from images.,"['G06V10/7753', 'G01N1/30', 'G06K9/3216', 'G06T7/0012', 'G06T7/33', 'G06V20/698', 'G06K2209/05', 'G06T2207/20081', 'G06T2207/30024', 'G06V2201/03']"
US11386496B2,Generative network based probabilistic portfolio management,"A deep-learning neural network can be trained to model a probability distribution of the asset-price trends for a future time period using a training data set, which can include asset-price trends of a plurality of assets over a past time period and a latent vector sampled from a prior distribution associated with the asset-price trends of a plurality of assets. The training data set can represent a time series data. A portfolio optimization can be executed on the modeled probability distribution to estimate expected risks and returns for different portfolio diversification options.","['G06Q40/06', 'G06F16/904', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094']"
GB2596383A,Techniques to use a neural network to expand an image,"Apparatuses, systems, and techniques for texture synthesis from small input textures in images using convolutional neural networks. In at least one embodiment, one or more convolutional layers are used in conjunction with one or more transposed convolution operations to generate a large textured output image 314 from a small input textured image 304 while preserving global features and texture, according to various novel techniques described herein. The invention claimed may have application to autonomous vehicles.","['G06T7/529', 'G06T3/4038', 'G06T11/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T1/20', 'G06T11/001', 'G06T3/4046', 'G06T5/50', 'G06T7/40', 'G06V10/454', 'G06V10/54', 'G06V10/776', 'G06V10/82', 'G06N3/049', 'G06N3/063', 'G06T2207/20081', 'G06T2207/20084']"
US10911471B1,Systems and methods for network-based intrusion detection,"Systems and methods for network-based intrusion detection are provided. An anti-adversarial Hidden Markov Model can be used to effectively detect evasion patterns for network-based intrusion detection, using dynamic window and threshold techniques to achieve adaptive, anti-adversarial, and online learning abilities. The concepts of pattern entropy, pattern entropy reduction, window width, local optimal window width, and dynamic window can be used in the model.","['H04L63/1416', 'G06N20/00', 'G06N20/20', 'G06N7/005', 'G06N7/01', 'H04L63/0272', 'H04L63/1425']"
CN111931591B,"Methods, devices, electronic devices and readable storage media for building key point learning models","The embodiment of the application discloses a method, a device, electronic equipment and a computer-readable storage medium for constructing a key point learning model, and relates to the technical fields of image processing, image labeling, artificial intelligence and machine learning. One embodiment of the method comprises the following steps: acquiring marked data of marked human body key points and unmarked data of unmarked human body key points; then, training the marked data through an initial prediction model and an initial discriminant according to a supervised training mode to obtain a first prediction model and a first discriminant; then, training the unlabeled data through the first prediction model and the first discriminator in an unsupervised training mode to obtain a second prediction model and a second discriminator; and finally, constructing a key point learning model according to the second prediction model and the second discriminator. The implementation mode fully utilizes a large amount of unlabeled data, and reduces the threshold and difficulty of constructing and obtaining the key point learning model.","['G06V40/20', 'G06N3/088', 'G06F18/2155', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06V10/44', 'G06V10/462', 'G06V10/764', 'G06V40/10', 'G06N3/044']"
US11941868B2,"Inference apparatus, inference method, and computer-readable storage medium storing an inference program","An inference apparatus provides target data to multiple inference models to cause the inference models each derived from local learning data obtained in a different environment to perform predetermined inference to obtain an inference result from each of the inference models. The inference apparatus determines the value of each combining parameter using environment data, weights the inference result from each of the inference models using the determined value of each combining parameter, and combines the weighted inference result from each inference model together to generate an inference result in a target environment.","['G06T7/0004', 'G06V10/774', 'G06N20/00', 'G06N20/20', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/0002', 'G06V10/82', 'G06V20/56', 'G06N3/047', 'G06T2207/20081', 'G06T2207/20084']"
US20220035961A1,System and method for artifact reduction of computed tomography reconstruction leveraging artificial intelligence and a priori known model for the object of interest,"Nondestructive evaluation (NDE) of objects can elucidate impacts of various process parameters and qualification of the object. Computed tomography (CT) enables rapid NDE and characterization of objects. However, CT presents challenges because of artifacts produced by standard reconstruction algorithms. Beam-hardening artifacts especially complicate and adversely impact the process of detecting defects. By leveraging computer-aided design (CAD) models, CT simulations, and a deep-neutral network high-quality CT reconstructions that are affected by noise and beam-hardening can be simulated and used to improve reconstructions. The systems and methods of the present disclosure can significantly improve the reconstruction quality, thereby enabling better detection of defects compared with the state of the art.","['G06F30/10', 'G06T11/008', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T19/20', 'G06T7/0002', 'G06N3/048', 'G06T2207/10081', 'G06T2211/441', 'G06T2211/448', 'G06T2211/452']"
US20230085827A1,Single-shot autofocusing of microscopy images using deep learning,"A deep learning-based offline autofocusing method and system is disclosed herein, termed a Deep-R trained neural network, that is trained to rapidly and blindly autofocus a single-shot microscopy image of a sample or specimen that is acquired at an arbitrary out-of-focus plane. The efficacy of Deep-R is illustrated using various tissue sections that were imaged using fluorescence and brightfield microscopy modalities and demonstrate single snapshot autofocusing under different scenarios, such as a uniform axial defocus as well as a sample tilt within the field-of-view. Deep-R is significantly faster when compared with standard online algorithmic autofocusing methods. This deep learning-based blind autofocusing framework opens up new opportunities for rapid microscopic imaging of large sample areas, also reducing the photon dose on the sample.","['H04N5/23212', 'G06V10/25', 'G02B21/367', 'G06N3/08', 'G06T5/003', 'G06T5/60', 'G06T5/73', 'G06V10/40', 'G06V10/751', 'H04N23/67', 'H04N23/80', 'H04N23/951', 'H04N23/959', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06V10/467', 'G06V2201/06']"
US11158121B1,Systems and methods for generating accurate and realistic clothing models with wrinkles,"In one embodiment, a computing system may be configured to generate accurate and realistic computer-generated clothing for a given body pose. For example, the system may access a data representation of a body pose and generate, based on the data representation, a 3D clothing model for the body pose using a statistical model. The system may generate a first normal map, such as a low-resolution normal map, based on the 3D clothing model. The system may generate a second normal map, such as a high-resolution normal map, by processing the first normal map using a machine-learning model that is trained to generate normal maps with higher levels of detail from normal maps with relatively lower levels of detail. The system may then render clothing for the body pose based on the 3D clothing model and the second normal map.","['G06T17/205', 'G06T17/20', 'G06F17/18', 'G06F30/20', 'G06F30/27', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N7/00', 'G06T13/40', 'G06T15/04', 'G06F2113/12', 'G06Q30/0643', 'G06T17/00', 'G06T19/20', 'G06T2207/10028', 'G06T2210/16', 'G06T2210/36', 'G06T2215/16']"
US12282851B2,Mutual information adversarial autoencoder,A method for generating an object includes: providing a dataset having object data and condition data; processing the object data to obtain latent object data and latent object-condition data; processing the condition data to obtain latent condition data and latent condition-object data; processing the latent object data and the latent object-condition data to obtain generated object data; processing the latent condition data and latent condition-object data to obtain generated condition data; comparing the latent object-condition data to the latent condition-object data to determine a difference; processing the latent object data and latent condition data and one of the latent object-condition data or latent condition-object data to obtain a discriminator value; and selecting a selected object based on the generated object data.,"['G06N3/08', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G10L19/24', 'G16B40/20', 'G16C20/50', 'G16C20/70', 'G06N3/044']"
US11599744B2,Image processing arrangements,"Aspects of the detailed technologies concern training and use of neural networks for fine-grained classification of large numbers of items, e.g., as may be encountered in a supermarket. Mitigating false positive errors is an exemplary area of emphasis. Novel network topologies are also detailed—some employing recognition technologies in addition to neural networks. A great number of other features and arrangements are also detailed.","['G06Q30/0641', 'G06K9/6256', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06K9/6201', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/17', 'G06V10/462', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G06F16/906', 'G06N3/04', 'G06N3/08', 'G06V2201/09']"
US12061985B2,Automated construction of neural network architecture with Bayesian graph exploration,"A system for automated construction of an artificial neural network architecture is provided. The system includes a set of interfaces and data links configured to receive and send signals, wherein the signals include datasets of training data, validation data and testing data, wherein the signals include a set of random number factors in multi-dimensional signals X, wherein part of the random number factors are associated with task labels Y to identify, and nuisance variations S. The system further includes a set of memory banks to store a set of reconfigurable deep neural network (DNN) blocks, hyperparameters, trainable variables, intermediate neuron signals, and temporary computation values including forward-pass signals and backward-pass gradients. The system further includes at least one processor, in connection with the interface and the memory banks, configured to submit the signals and the datasets into the reconfigurable DNN blocks, wherein the at least one processor is configured to execute a Bayesian graph exploration using the Bayes-Ball algorithm to reconfigure the DNN blocks such that redundant links are pruned to be compact by modifying the hyperparameters in the memory banks. The system realizes nuisance-robust variational Bayesian inference to be transferable to new datasets in semi-supervised settings.","['G06N3/045', 'G06N3/04', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N7/01']"
CN108334848B,Tiny face recognition method based on generation countermeasure network,"The invention provides a tiny face recognition method based on a generation countermeasure network. The invention is proposed to solve the defect that the face detection technology at the present stage can not capture the tiny face under the complex background, and the detection rate is seriously reduced when the face detection is carried out based on the distorted image, and the method comprises the following steps: predicting the face position of each picture in a training database by using an existing face detector, and intercepting and storing real face images and non-face images; obtaining a corresponding low-resolution image according to the face image and the non-face image; constructing a generation countermeasure network, wherein the generation countermeasure network comprises a generator and a discriminator; generating a confrontation network by using the high-resolution face and non-face image and the corresponding low-resolution face and non-face image for training; the position of the face is marked in the input picture according to the scores of the discriminator on the face candidate regions obtained from the existing face detector. The invention is suitable for the recognition and detection of human faces.","['G06V40/161', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T3/4007', 'G06T3/4076', 'G06V40/172', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11491348B2,Real-time patient motion monitoring using a magnetic resonance linear accelerator (MRLINAC),"Systems and techniques may be used to estimate a real-time patient state during a radiotherapy treatment using a magnetic resonance linear accelerator (MR-Linac). For example, a method may include generating a dictionary of expanded potential patient measurements and corresponding potential patient states using a preliminary motion model. The method may include training, using a machine learning technique, a correspondence motion model relating an input patient measurement to an output patient state using the dictionary. The method may include estimating, using a processor, the patient state corresponding to a 2D MR image using the correspondence motion model. The method may include directing radiation therapy, using the MR-Linac, to a target according to the patient state.","['A61N5/1048', 'A61N5/1049', 'A61N5/1037', 'A61N5/1067', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N7/08', 'G06T7/0014', 'G06T7/20', 'G06T7/30', 'A61N2005/1055', 'G06T2207/10016', 'G06T2207/10072', 'G06T2207/10076', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30096']"
US20200335086A1,Speech data augmentation,"Data augmentation is used for speech emotion recognition tasks where certain emotional labels, e.g., sadness, are significantly underrepresented in a training dataset. This is typical for data collected in real-life applications. We propose conditioned data augmentation using Generative Adversarial Networks (GANs), in order to generate samples for underrepresented emotions. We propose a conditional GAN architecture to generate synthetic spectrograms for the minority class. For comparison purposes, we implement a series of signal-based data augmentation methods. Results on the speech emotion recognition task show that the proposed data augmentation method significantly improves classification performance as compared to traditional speech data augmentation methods.","['G10L15/063', 'G06N3/088', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G10L15/16', 'G10L25/30', 'G10L25/63']"
US10614287B2,Virtual staining of cells in digital holographic microscopy images using general adversarial networks,"A cell visualization system includes a digital holographic microscopy (DHM) device, a training device, and a virtual staining device. The DHM device produces DHM images of cells and the virtual staining device colorizes the DHM images based on an algorithm generated by the training device using generative adversarial networks and unpaired training data. A computer-implemented method for producing a virtually stained DHM image includes acquiring an image conversion algorithm which was trained using the generative adversarial networks, receiving a DHM image with depictions of one or more cells and virtually staining the DHM image by processing the DHM image using the image conversion algorithm. The virtually stained DHM image includes digital colorization of the one or more cells to imitate the appearance of a corresponding actually stained cell.","['G06K9/00147', 'G01N15/1429', 'G01N15/1433', 'G01N15/1468', 'G01N15/1475', 'G03H1/0005', 'G03H1/0443', 'G03H1/0866', 'G06F18/241', 'G06F18/2411', 'G06K9/00127', 'G06K9/4604', 'G06K9/6268', 'G06K9/6269', 'G06T7/0012', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G06V20/69', 'G06V20/698', 'G01N2015/1454', 'G03H2001/005', 'G06K2209/05', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06V2201/03']"
CN112329348B,An intelligent decision-making method for military confrontation games under imperfect information conditions,"The invention discloses an intelligent decision method for military countermeasure game under the condition of incomplete information, which comprises the following steps: constructing a military countermeasure game decision-making dynamics basic model; based on deep learning and self-game, establishing an intelligent learning model of military countermeasure game and determining model parameters thereof; analyzing and predicting the incomplete information battlefield situation under the countermeasure environment by utilizing the basic model, the intelligent learning model and the parameters thereof; based on the analysis prediction result and the intelligent optimization decision mode of decision-feedback-dynamic optimization, the intelligent optimization decision in the uncertain countermeasure environment is obtained. The invention converts the incomplete information condition into the complete information condition by identifying and predicting the incomplete information in the military countermeasure game scene, thereby obtaining the military countermeasure decision, and solving the technical problem that the military countermeasure decision which is beneficial to the military countermeasure decision cannot be obtained due to the incomplete information in the military countermeasure game environment.","['G06F30/27', 'G06N3/045', 'G06N3/08', 'G06Q10/04', 'G06Q50/26', 'G06F2119/14']"
US20200387797A1,Unsupervised outlier detection in time-series data,"Systems and methods for detecting patterns in data from a time-series and for detecting outliers in network data in an unsupervised manner are provided. In one implementation, a method includes the steps of obtaining network data from a network to be monitored and creating a window from the obtained network data. The method also includes the step of detecting outliers of the obtained data with respect to the window using an unsupervised deep learning process (e.g., using a Generalized Adversarial Network (GAN) learning technique and/or a Bidirectional GAN (BiGAN) learning technique) for enabling the learning of a data distribution. The unsupervised process, for example, does not require manual intervention.","['G06F17/18', 'G06F11/0754', 'G06F11/3006', 'G06F11/3013', 'G06F11/3058', 'G06F11/3409', 'G06F11/3447', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/084', 'G06N3/088', 'G06F2201/835']"
US20200394459A1,Cell image synthesis using one or more neural networks,"Apparatuses, systems, and techniques to generate synthesized images including digital representations of groups of cells blended realistically with appropriate background images. In at least one embodiment, background image data and gene expression data are fused together to generate such a synthesized image using one or more neural networks.","['G06T11/001', 'G06K9/6256', 'G06T7/11', 'G06F18/214', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06T7/0012', 'G06T7/194', 'G16B25/00', 'G16B40/00', 'G16B45/00', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30061', 'G06T2210/41']"
US11494595B2,"Method , apparatus, and storage medium for annotating image","The present disclosure describes a method, apparatus, and storage medium for annotating image. The method includes extracting, by a device, a visual feature of an image through a generative adversarial network model, and sequentially inputting M pieces of random noise into the generative adversarial network model. In response to each of the M pieces of random noise being inputted into the generative adversarial network model, the method includes performing a determinantal point process (DPP) on the visual feature of the image and the each random noise through the generative adversarial network model to obtain N tag subsets, and selecting a distinct tag subset from the N tag subsets through the generative adversarial network model. The method also includes outputting M distinct tag subsets through the generative adversarial network model after the M pieces of random noise are inputted into the generative adversarial network model.","['G06F18/214', 'G06K9/627', 'G06V10/764', 'G06F18/217', 'G06F18/2413', 'G06K9/46', 'G06K9/6256', 'G06K9/6262', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06V10/40', 'G06V10/82', 'G06V20/38', 'G06V20/70']"
US10614826B2,System and method for voice-to-voice conversion,"A method of building a speech conversion system uses target information from a target voice and source speech data. The method receives the source speech data and the target timbre data, which is within a timbre space. A generator produces first candidate data as a function of the source speech data and the target timbre data. A discriminator compares the first candidate data to the target timbre data with reference to timbre data of a plurality of different voices. The discriminator determines inconsistencies between the first candidate data and the target timbre data. The discriminator produces an inconsistency message containing information relating to the inconsistencies. The inconsistency message is fed back to the generator, and the generator produces a second candidate data. The target timbre data in the timbre space is refined using information produced by the generator and/or discriminator as a result of the feeding back.","['G10L21/013', 'G10L13/033', 'G10L15/02', 'G10L15/063', 'G10L15/22', 'G10L19/018', 'G10L2015/025', 'G10L2021/0135', 'G10L25/30']"
US11676022B2,Systems and methods for learning for domain adaptation,"A method for training parameters of a first domain adaptation model. The method includes evaluating a cycle consistency objective using a first task specific model associated with a first domain and a second task specific model associated with a second domain, and evaluating one or more first discriminator models to generate a first discriminator objective using the second task specific model. The one or more first discriminator models include a plurality of discriminators corresponding to a plurality of bands that corresponds domain variable ranges of the first and second domains respectively. The method further includes updating, based on the cycle consistency objective and the first discriminator objective, one or more parameters of the first domain adaptation model for adapting representations from the first domain to the second domain.","['G06N3/084', 'G05B13/027', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G10L21/003', 'G06F18/2178', 'G10L15/065', 'G10L15/075']"
US11636332B2,Systems and methods for defense against adversarial attacks using feature scattering-based adversarial training,"Described herein are embodiments for a feature-scattering-based adversarial training approach for improving model robustness against adversarial attacks. Conventional adversarial training approaches leverage a supervised scheme, either targeted or non-targeted in generating attacks for training, which typically suffer from issues such as label leaking as noted in recent works. Embodiments of the disclosed approach generate adversarial images for training through feature scattering in the latent space, which is unsupervised in nature and avoids label leaking. More importantly, the presented approaches generate perturbed images in a collaborative fashion, taking the inter-sample relationships into consideration. Extensive experiments on different datasets compared with state-of-the-art approaches demonstrate the effectiveness of the presented embodiments.","['G06F21/57', 'G06F18/2415', 'G06F18/21', 'G06F18/214', 'G06F18/2413', 'G06K9/6256', 'G06K9/627', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/70', 'G06V10/764', 'G06V10/82', 'G06F2221/033', 'G06F2221/034', 'G06N7/01']"
US12387430B2,Generating images of virtual environments using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to generate one or more images based, at least in part, upon one or more semantic features projected from a three-dimensional environment.","['G06T11/00', 'A63F13/52', 'A63F13/67', 'G06T15/00', 'G06T15/10', 'G06T17/05', 'G06T17/20', 'G06T7/12', 'G06V20/647', 'G06V20/70', 'G06T2207/20084', 'G06T2219/2004']"
WO2022121160A1,Method for enhancing quality and resolution of ct images based on deep learning,"Disclosed in the present invention is a method for enhancing the quality and resolution of CT images based on deep learning, comprising the following steps: S1: pre-processing collected clinical data to obtain a data set; S2: building a deep learning model comprising a generative network, a decider network, and a cognitive network; S3: building a loss function; S4: using the data set and the loss function to update the parameters of the iterative generative network in order to obtain a trained deep learning model; and S5: inputting a low-quality low-resolution image into the trained deep learning model to obtain a high-quality high-resolution image. The present invention builds a deep learning model based on deep learning and pre-processes clinical data to obtain a data set, reducing the impact of spatial misalignment of data collected at different times due to movement of the patient or other reasons; by means of the deep learning model combined with the loss function, end-to-end processing of the two tasks of enhancing CT image quality and super-resolution can be implemented to directly obtain final results.","['G06T11/003', 'G06T7/0012', 'G06T3/4046', 'G06N3/045', 'G06N3/08', 'G06T3/4053', 'G06T3/60', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06T2207/10081', 'G06T2207/20132', 'G06T2211/424']"
CN110892477B,Method and computer system for gradient direction data segmentation of neural networks,"The system and method improves the performance of an already converged network by segmenting the training data such that the gradient and all partial derivatives of the network are zero (or near zero) such that on each subset of the segmented training data, some nodes or arcs (i.e., the connections between the nodes and the previous or subsequent layers of the network) have individual partial derivative values that differ from zero on the segmented data subset, although their partial derivative averages over the entire training data set are near zero. The present system and method may create a new network by segmenting candidate nodes or arcs emanating from zero and then training the resulting network with each selected node trained on the corresponding data cluster.","['G06N3/08', 'G06N3/084', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/048', 'G06N3/0499', 'G06N3/082', 'G06N3/09']"
US11210561B2,Device and method for electromagnetic field simulation,"A device and a method for electromagnetic field simulation are provided. The image processing device is to obtain, with a first resolution, a first electromagnetic field simulation result of a simulation region, and to derive a second electromagnetic field simulation result with a second resolution, according to the first electromagnetic field simulation result, using a model trained based on a deep learning method. The second resolution is higher than the first resolution.","['G06N3/08', 'G06K9/6256', 'G06F30/23', 'G06F18/214', 'G06F30/27', 'G06T3/4046', 'Y02E60/00']"
US11886542B2,Model compression using cycle generative adversarial network knowledge distillation,"Systems and processes for prediction using generative adversarial network and distillation technology are provided. For example, an input is received at a first portion of a language model. A first output distribution is obtained, based on the input, from the first portion of the language model. Using a first training model, the language model is adjusted based on the first output distribution. The first output distribution is received at a second portion of the language model. A first representation of the input is obtained, based on the first output distribution, from the second portion of the language model. The language model is adjusted, using a second training model, based on the first representation of the input. Using the adjusted language model, an output is provided based on a received user input.","['G06F18/2148', 'G06F18/22', 'G06F18/2413', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V30/194']"
US12094082B2,"Image processing apparatus, image processing method and computer-readable medium","An image processing apparatus includes: an obtaining unit configured to obtain a first medical image of an object under examination; an image quality improving unit configured to generate, from the obtained first medical image, a second medical image with image quality higher than image quality of the obtained first medical image using a learned model; a comparing unit configured to compare an analysis result obtained by analyzing the obtained first medical image and an analysis result obtained by analyzing the generated second medical image; and a display controlling unit configured to cause a comparison result obtained by the comparing unit to be displayed on a display unit.","['G06T5/00', 'G16H15/00', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/001', 'G06T11/008', 'G06T11/60', 'G06T7/0014', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G06T2200/24', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30168', 'G06T2210/41', 'G06T2211/441', 'G06T2211/456']"
US11886968B2,Methods and devices for detecting objects and calculating a time to contact in autonomous driving systems,"A method for calculating a time to contact of an autonomous vehicle, the method comprising: obtaining a plurality of event data an image, wherein the event data is associated with a pixel associated with a change in light intensity; determining a reference signal frequency associated with a transmitted light; identifying a select event data from the plurality of event data, wherein the light frequency associated with the select event data is substantially the same as the reference signal frequency; determining an object based on the select event data, wherein the object is fully enclosed by a bounding box comprising coordinates of a rectangular border; calculating a distance between a set of coordinates of the bounding box closest to the autonomous vehicle and the autonomous vehicle; and calculating the time to contact between the set of coordinates of the bounding box and the autonomous vehicle.","['B60W50/00', 'G06N20/20', 'B60W30/095', 'B60W30/0956', 'B60W60/001', 'B60W60/0016', 'B60W60/0059', 'G06N3/04', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N5/01', 'G06N7/01', 'G06V10/141', 'G06V10/147', 'G06V10/764', 'G06V20/56', 'B60W2050/0005', 'B60W2050/0052', 'B60W2420/403', 'B60W2420/408', 'B60W2420/52']"
US11092966B2,Building an artificial-intelligence system for an autonomous vehicle,An apparatus for building an artificial-intelligence system is provided. The apparatus accesses images of a real-world scene and generates an image of a simulated object corresponding to a real-world object using a first generative adversarial network (GAN). The apparatus inserts the image of the simulated object into the images of the real-world scene to produce images of the real-world scene including the simulated object. The apparatus applies the images of the real-world scene including the simulated object to a second GAN to remove visual artifacts thereby producing a training set of images of the real-world scene including the simulated object. The apparatus trains an artificial-intelligence algorithm using the training set of images to build the artificial-intelligence system to detect the real-world object in further images of the real-world scene and outputs the artificial-intelligence system for deployment on an autonomous vehicle.,"['G05D1/0221', 'G06V20/58', 'G05D1/0246', 'G06F18/2155', 'G06K9/00805', 'G06K9/6259', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/7747', 'G06V10/82', 'G05D2201/0213']"
US20200167914A1,Methods of analyzing microscopy images using machine learning,Disclosed herein are methods of utilizing machine learning methods to analyze microscope images of populations of cells.,"['G16B20/00', 'G06N20/00', 'G06T7/0012', 'G16B40/20', 'G16B40/30', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
US12249065B2,Quality assessment in video endoscopy,"An analysis apparatus analyses a video image signal comprising successive frames of imaging an endoscopy procedure. A machine learning block analyses the video image signal using a machine learning technique that classifies regions of the frames as belonging to one of plural classes corresponding to respective types of image artefact. The classes include a motion blur class corresponding to motion blur of the image, at least one erroneous exposure class corresponding to a type of erroneous exposure of the image, and at least one noise artefact class corresponding to a type of image artefact that is noise. A quality score block derives quality scores representing image quality of the successive frames based on the classified regions.","['G06T5/70', 'G06T5/00', 'G06T5/60', 'G06T5/73', 'G06T5/77', 'G06T5/90', 'G06T7/0012', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084']"
US20240160937A1,Training image-to-image translation neural networks,"A method includes obtaining a source training dataset that includes a plurality of source training images and obtaining a target training dataset that includes a plurality of target training images. For each source training image, the method includes translating, using the forward generator neural network G, the source training image to a respective translated target image according to current values of forward generator parameters. For each target training image, the method includes translating, using a backward generator neural network F, the target training image to a respective translated source image according to current values of backward generator parameters. The method also includes training the forward generator neural network G jointly with the backward generator neural network F by adjusting the current values of the forward generator parameters and the backward generator parameters to optimize an objective function.","['G06N3/084', 'G06F18/21347', 'G06F18/214', 'G06F18/2148', 'G06F18/2193', 'G06F18/22', 'G06F18/2413', 'G06N3/045', 'G06N3/047', 'G06V10/761', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US11080918B2,Method and system for predicting garment attributes using deep learning,"There is provided a computer implemented method for predicting garment or accessory attributes using deep learning techniques, comprising the steps of: (i) receiving and storing one or more digital image datasets including images of garments or accessories; (ii) training a deep model for garment or accessory attribute identification, using the stored one or more digital image datasets, by configuring a deep neural network model to predict (a) multiple-class discrete attributes; (b) binary discrete attributes, and (c) continuous attributes, (iii) receiving one or more digital images of a garment or an accessory, and (iv) extracting attributes of the garment or the accessory from the one or more received digital images using the trained deep model for garment or accessory attribute identification. A related system is also provided.","['G06V10/454', 'G06F16/535', 'G06F16/538', 'G06F16/5838', 'G06F16/5862', 'G06F18/214', 'G06F18/24', 'G06F40/20', 'G06K9/6256', 'G06K9/6267', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T15/005', 'G06T15/04', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G06V40/10', 'G06V2201/12']"
US11321847B2,Foreground-aware image inpainting,"In some embodiments, an image manipulation application receives an incomplete image that includes a hole area lacking image content. The image manipulation application applies a contour detection operation to the incomplete image to detect an incomplete contour of a foreground object in the incomplete image. The hole area prevents the contour detection operation from detecting a completed contour of the foreground object. The image manipulation application further applies a contour completion model to the incomplete contour and the incomplete image to generate the completed contour for the foreground object. Based on the completed contour and the incomplete image, the image manipulation application generates image content for the hole area to generate a completed image.","['G06T5/77', 'G06T7/149', 'G06T5/005', 'G06T5/60', 'G06T7/13', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084']"
US12210965B2,Interpretable autonomous driving system and method thereof,"In some examples, a dynamic system, including a vehicle, may be represented using a graph-based representation. One or more nodes in the graph-based representation may correspond to one or more agents in the dynamic system, and one or more edges between the nodes in the graph-based representation may correspond to one or more interactions between the agents in the dynamic system. The interactions may be defined based on human domain knowledge of the dynamic system. The dynamic system may be modeled using a respective machine learning model that includes a reward decoder that operates on the graph-based representation and evaluates one or more reward functions for the dynamic system. The one or more reward functions may be defined based on the human domain knowledge of the dynamic system. Autonomous operation of the vehicle may be controlled based on the modeling of the dynamic system.","['G06N3/006', 'G06N3/08', 'B60W50/06', 'B60W60/001', 'G01C21/3407', 'G06N3/045', 'G06N3/0455', 'G06N3/088', 'G06N3/092', 'G06N3/094', 'G06N5/04']"
EP3726439A1,Edge learning,"Systems and methods are provided for training a model on a large number of devices where, for example, each device acquires a local set of training data without sharing data sets across the devices. The devices train the model on the respective device's set of training data. The devices communicate a parameter vector from the trained model asynchronously with a parameter server. The parameter server updates a master parameter vector and transmits the master parameter vector to the respective device. The update rate of the devices is decoupled from the size of the data that is available to the devices and the computational power of the devices by over or under sampling the local training data.","['H04L67/12', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06V10/774', 'G06V10/776', 'G06V10/95', 'G06V20/56', 'H04L67/10', 'H04W4/38', 'H04W4/70']"
US11181926B2,Trajectory selection for an autonomous vehicle,A navigation system for a host vehicle may include at least one processor programmed to receive images representative of an environment of the host vehicle. The processor may analyze the images to identify navigational state information associated with the host vehicle; determine a plurality of potential trajectories for the host vehicle based on the navigational state information; perform a preliminary analysis to select a subset of the plurality of potential trajectories; perform a secondary analysis to select one of the subset of the plurality of potential trajectories as a planned trajectory for the host vehicle; determine one or more navigational actions for the host vehicle based on the planned trajectory; and cause at least one adjustment of a navigational actuator of the host vehicle to implement the one or more navigational actions for the host vehicle.,"['G05D1/0251', 'B60W60/0011', 'B60W60/00276', 'G01C21/3415', 'G01C21/3492', 'G05D1/0214', 'G06K9/00791', 'G06V20/56', 'B60W2420/403', 'B60W2420/408', 'B60W2552/05', 'B60W2552/15', 'B60W2552/30', 'B60W2552/53', 'B60W2554/20', 'B60W2554/4026', 'B60W2554/4029', 'B60W2554/802', 'B60W2554/804', 'B60W2556/40', 'B60W2556/45', 'B60W2754/20', 'B60W2754/30', 'G05D1/0221', 'G05D2201/0213']"
US11886579B2,Machine learning model validation and authentication,"The present disclosure is directed to methods and apparatus for validating and authenticating use of machine learning models. For example, various techniques are described herein to limit the vulnerability of machine learning models to attack and/or exploitation of the model for malicious use, and for detecting when such attack/exploitation has occurred. Additionally, various embodiments described herein promote the protection of sensitive and/or valuable data, for example by ensuring only licensed use is permissible. Moreover, techniques are described for version tracking, usage tracking, permission tracking, and evolution of machine learning models.","['G06F21/554', 'G06F21/606', 'H04L9/008', 'G06F2221/034']"
US11741693B2,System and method for semi-supervised conditional generative modeling using adversarial networks,"One embodiment facilitates generating synthetic data objects using a semi-supervised GAN. During operation, a generator module synthesizes a data object derived from a noise vector and an attribute label. The system passes, to an unsupervised discriminator module, the data object and a set of training objects which are obtained from a training data set. The unsupervised discriminator module calculates: a value indicating a probability that the data object is real; and a latent feature representation of the data object. The system passes the latent feature representation and the attribute label to a supervised discriminator module. The supervised discriminator module calculates a value indicating a probability that the attribute label given the data object is real. The system performs the aforementioned steps iteratively until the generator module produces data objects with a given attribute label which the unsupervised and supervised discriminator modules can no longer identify as fake.","['G06V10/82', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06V10/451', 'G06V10/764']"
US11604984B2,Systems and methods for machine learning based modeling,"A system comprising a first computing apparatus in communication with multiple second computing apparatuses. The first computing apparatus may obtain a plurality of first trained machine learning models for a task from the multiple second computing apparatuses. At least a portion of parameter values of the plurality of first trained machine learning models may be different from each other. The first computing apparatus may also obtain a plurality of training samples. The first computing apparatus may further determine, based on the plurality of training samples, a second trained machine learning model by learning from the plurality of first trained machine learning models.","['G06N20/00', 'G06N20/20', 'G06N3/08', 'G06F18/214', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/045', 'G06N7/01']"
US10698063B2,Motion artifact reduction of magnetic resonance images with an adversarial trained network,Systems and methods are provided for correcting motion artifacts in magnetic resonance images. An image-to-image neural network is used to generate motion corrected magnetic resonance data given motion corrupted magnetic resonance data. The image-to-image neural network is coupled within an adversarial network to help refine the generated magnetic resonance data. The adversarial network includes a generator network (the image-to-image neural network) and a discriminator network. The generator network is trained to minimize a loss function based on a Wasserstein distance when generating MR data. The discriminator network is trained to differentiate the motion corrected MR data from motion artifact free MR data.,"['G01R33/56509', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/046', 'G06T5/003', 'G06T5/60', 'G06T5/73', 'G06T7/20', 'G06N3/048', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
US11631162B2,"Machine learning training method, system, and device","Fill techniques as implemented by a computing device are described to perform hole filling of a digital image. In one example, deeply learned features of a digital image using machine learning are used by a computing device as a basis to search a digital image repository to locate the guidance digital image. Once located, machine learning techniques are then used to align the guidance digital image with the hole to be filled in the digital image. Once aligned, the guidance digital image is then used to guide generation of fill for the hole in the digital image. Machine learning techniques are used to determine which parts of the guidance digital image are to be blended to fill the hole in the digital image and which parts of the hole are to receive new content that is synthesized by the computing device.","['G06T5/77', 'G06T5/005', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T11/40', 'G06T3/0006', 'G06T3/02', 'G06T5/002', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T7/337', 'G06T7/344', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084']"
US20190147296A1,Creating an image utilizing a map representing different classes of pixels,"A method, computer readable medium, and system are disclosed for creating an image utilizing a map representing different classes of specific pixels within a scene. One or more computing systems use the map to create a preliminary image. This preliminary image is then compared to an original image that was used to create the map. A determination is made whether the preliminary image matches the original image, and results of the determination are used to adjust the computing systems that created the preliminary image, which improves a performance of such computing systems. The adjusted computing systems are then used to create images based on different input maps representing various object classes of specific pixels within a scene.","['G06K9/6257', 'G06V10/454', 'G06F18/2148', 'G06F18/24133', 'G06K9/6857', 'G06K9/726', 'G06T1/20', 'G06T11/001', 'G06V10/82', 'G06V30/19173', 'G06V30/2504', 'G06V30/274']"
US20220101972A1,Machine learning systems for automated pharmaceutical molecule identification,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media that leverage artificial intelligence and machine learning to identify molecules or compounds for use in pharmaceuticals. In aspects, one or more machine learning (ML) models may be trained to identify molecules based on pharmaceutical data that indicates properties of previously-identified pharmaceutical molecules, such as physiochemical structure, side effects, toxicity, solubility, and the like. The ML models may include generative models, such as generative adversarial networks or variational autoencoders. The trained ML models may be used to identify new (e.g., previously-unidentified) molecules, or the trained ML models may be provided to client devices for use in molecule identification (e.g., drug discovery).","['G16C20/50', 'G06N20/00', 'G16C20/70', 'G16H20/10', 'G16H70/40']"
US20180247227A1,Machine learning systems and methods for data augmentation,"Aspects relate to systems and methods for improving the operation of computer-implemented neural networks. Some aspects relate to training a neural network using a compressed representation of the inputs either through efficient discretization of the inputs, or choice of compression. This approach allows a multiscale approach where the input discretization is adaptively changed during the learning process, or the loss of the compression is changed during the training. Once a network has been trained, the approach allows for efficient predictions and classifications using compressed inputs. One approach can generate a larger more diverse training dataset based on both simulations from physical models, as well as incorporating domain expertise and other available information. One approach can automatically match the documents to the list, while still allowing a user to input information to update and correct the matching process.","['G06N99/005', 'G06N20/00', 'G06F16/2365', 'G06F17/30371', 'G06F17/5009', 'G06F18/22', 'G06F18/2411', 'G06F18/28', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N7/01', 'G06T9/002', 'G06V30/1914', 'G06V30/2504', 'H04N19/60', 'G06F30/20', 'G06N20/10', 'G06N5/01', 'H04N19/96']"
US20230196117A1,"Training method for semi-supervised learning model, image processing method, and device","Embodiments of this application disclose a training method for a semi-supervised learning model which can be applied to computer vision in the field of artificial intelligence. The method includes: first predicting classification categories of some unlabeled samples by using a trained first semi-supervised learning model, to obtain a prediction label; and determining whether each prediction label is correct in a one-bit labeling manner, and if prediction is correct, obtaining a correct label (a positive label) of the sample, or if prediction is incorrect, excluding an incorrect label (a negative label) of the sample. Then, in a next training phase, a training set (a first training set) is reconstructed based on the information, and an initial semi-supervised learning model is retrained based on the first training set, to improve prediction accuracy of the model. In one-bit labeling, an annotator only needs to answer “yes” or “no” for the prediction label.","['G06F18/214', 'G06N3/0895', 'G06F18/24', 'G06N20/00', 'G06N3/08', 'G06V10/771', 'G06V10/7753', 'G06V10/82']"
CA3043621C,Method and system for color representation generation,"There is provided a system and method for color representation generation. In an aspect, the method includes: receiving three base colors; receiving a patchwork parameter; and generating a color representation having each of the three base colors at a vertex of a triangular face, the triangular face having a color distribution therein, the color distribution discretized into discrete portions, the amount of discretization based on the patchwork parameter, each discrete portion having an interpolated color determined to be a combination of the base colors at respective coordinates of such discrete portion. In further aspects, one or more color representations are generated based on an input image and can be used to modify colors of a reconstructed image.","['G06T11/001', 'G06T11/40', 'G06T15/503']"
US11275830B2,System and method for video backdoor attack,"Systems and methods for video backdoor attack include a trigger generation module for generating a universal adversarial trigger pattern specific to a task, an adversarial perturbation module for producing videos with manipulated features; and a poisoning and inference module for injecting the generated trigger into perturbed videos as poisoned samples for training; wherein the trigger pattern is patched and optimized on videos from all non-target classes but relabeled to a target class, and the trigger pattern is a universal adversarial trigger pattern generated by minimizing the cross-entropy loss.","['G06N3/08', 'G06F21/55', 'G06F18/214', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N7/005', 'G06N7/01', 'G06V20/40', 'G06F2221/034', 'G06N3/048', 'Y02T10/40']"
US11929085B2,Method and apparatus for controlling enhancement of low-bitrate coded audio,"Described herein is a method of low-bitrate coding of audio data and generating enhancement metadata for controlling audio enhancement of the low-bitrate coded audio data at a decoder side, including the steps of: (a) core encoding original audio data at a low bitrate to obtain encoded audio data; (b) generating enhancement metadata to be used for controlling a type and/or amount of audio enhancement at the decoder side after core decoding the encoded audio data; and (c) outputting the encoded audio data and the enhancement metadata. Described is further an encoder configured to perform said method. Described is moreover a method for generating enhanced audio data from low-bitrate coded audio data based on enhancement metadata and a decoder configured to perform said method.","['G10L19/24', 'G10L21/0364', 'G10L25/30']"
US12236616B2,Method and system for automatic extraction of virtual on-body inertial measurement units,"An exemplary virtual IMU extraction system and method are disclosed for human activity recognition (HAR) or classifier system that can estimate inertial measurement units (IMU) of a person in video data extracted from public repositories of video data having weakly labeled video content. The exemplary virtual IMU extraction system and method of the human activity recognition (HAR) or classifier system employ an automated processing pipeline (also referred to herein as “IMUTube”) that integrates computer vision and signal processing operations to convert video data of human activity into virtual streams of IMU data that represents accelerometer, gyroscope, or other inertial measurement unit estimation that can measure acceleration, inertia, motion, orientation, force, velocity, etc. at a different location on the body. In other embodiments, the automated processing pipeline can be used to generate high-quality virtual accelerometer data from a camera sensor.","['G06T7/251', 'G06T7/20', 'G06V10/80', 'G06V20/41', 'G06V30/194', 'G06V40/23', 'G06T2207/30196']"
WO2022195285A1,Image processing using machine learning,"A method of processing image data, comprises receiving one or more target images and at least one reference source. The method processes the at least one reference source and the one or more target images to extract features using a convolutional neural network. In addition the method processes the features of the one or more target images and the at least one reference source using a transformer network to provide an attention output. The attention output is provided as an input to a convolutional neural network decoder. In addition skip connections are provided from the convolutional neural network encoder to provide features of the one or more target images to the convolutional neural network decoder at one or more decoder layers. Finally, the extracted features of the one or more target images and the attention output are processed using the convolutional neural network decoder to produce one or more output images. The output images take the style of the reference source. In one example, this style is by taking colourisation from the reference source. In another example interpolation is provided between two images and the reference source itself comprises two images.","['G06T5/77', 'G06T11/00', 'G06N3/045', 'G06N3/084', 'G06T5/50', 'G06T11/001', 'G06T2207/20084']"
US11334973B2,Image colorizing method and device,"An image colorizing method and device are provided, which relate to the field of image processing technology. The method includes acquiring a grayscale image to be colorized, classifying the grayscale image to determine the grayscale image is a human face image or a human image, providing the grayscale image to a neural network based image colorizing model corresponding to the type of the grayscale image to obtain color information for respective pixels in the grayscale image. The image colorizing model is a human face image colorizing model if the grayscale image is a human face image, the image colorizing model is a human image colorizing model if the grayscale image is a human image. The method further includes synthesizing the grayscale image and the color information to obtain a color image.","['G06T11/001', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06V10/56', 'G06V10/764', 'G06V10/82', 'G06V40/10', 'G06V40/172', 'H04N1/465', 'H04N1/62', 'G06T2207/20212', 'G06T2207/30242', 'G06V40/161']"
US10395356B2,Generating simulated images from input images for semiconductor applications,Methods and systems for generating a simulated image from an input image are provided. One system includes one or more computer subsystems and one or more components executed by the one or more computer subsystems. The one or more components include a neural network that includes two or more encoder layers configured for determining features of an image for a specimen. The neural network also includes two or more decoder layers configured for generating one or more simulated images from the determined features. The neural network does not include a fully connected layer thereby eliminating constraints on size of the image input to the two or more encoder layers.,"['G01N21/9501', 'G06T7/0004', 'G06F18/24133', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G01N2021/8883', 'G01N21/956', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US20230370490A1,System and method for cyber exploitation path analysis and task plan optimization,"A system and method for cyber exploitation path analysis and task plan optimization to minimize network exposure and maximize network resilience. The system and method involve gathering network entity information, establishing baseline behaviors for each entity, and monitoring each entity for behavioral anomalies that might indicate cybersecurity concerns. Further, the system and method involve incorporating network topology information into the analysis by generating a model of the network, annotating the model with risk and criticality information for each entity in the model and with a vulnerability level between entities, and using the model to evaluate cybersecurity risks to the network. Lastly, network attack path analysis and automated task planning for minimizing network exposure and maximizing resiliency is performed with machine learning, generative adversarial networks, hierarchical task networks, and Monte Carlo search trees.","['H04L63/1433', 'G06N3/0475', 'G06N3/094', 'G06N3/098', 'G06N5/01', 'H04L63/102', 'H04L63/1416', 'H04L63/1425', 'H04L63/20', 'G06N20/00', 'G06N3/084']"
CN108256561B,Multi-source domain adaptive migration method and system based on counterstudy,"The invention discloses a multi-source domain adaptive migration method and system based on antagonistic learning, wherein the method comprises the following steps: the method comprises the following steps that firstly, source domain data are used for pre-training, and a representation network and a classifier of a target model are initialized; step two, multi-path countermeasure is carried out by using the multi-source domain data and the target domain data, and the representation network and the multi-path discriminator of the target model are updated; step three, calculating the confrontation score between each source domain and each target domain; classifying the target domain based on the classifier and the confrontation score of each source domain; selecting a high-confidence target domain pseudo sample to finely adjust a representation network and a classifier of the target model; and step six, returning to the step two, performing the step two-five, and stopping training until the model converges or the maximum iteration times is reached.","['G06F18/24', 'G06F18/2148']"
US20220139070A1,"Learning apparatus, estimation apparatus, data generation apparatus, learning method, and computer-readable storage medium storing a learning program","A learning apparatus according to one or more embodiments executes, with respect to each learning data set, a first training step of training a second encoder and a second metadata identifier such that the identification result by the second metadata identifier matches the metadata, a second training step of training encoders and an estimator such that the result of estimation performed by the estimator matches correct answer data, a third training step of training a first metadata identifier such that the result of identification performed by the first metadata identifier matches the metadata, and a fourth training step of training a first encoder such that the result of identification performed by the first metadata identifier does not match the metadata. The third training step and the fourth training step are alternatingly and repeatedly executed.","['G06V10/774', 'G06N3/084', 'G06N20/00', 'G06N3/045', 'G06V20/54', 'G08G1/0112', 'G08G1/0116', 'G08G1/0129', 'G08G1/0141']"
CN109255831B,A method for single-view face 3D reconstruction and texture generation based on multi-task learning,"The invention discloses a method for single-view face three-dimensional reconstruction and texture generation based on multi-task learning, and belongs to the field of computer vision. The method comprises the following steps: selecting a special viewpoint rendered by the human face three-dimensional model; generating a depth map and a texture map as truth value data under a special viewpoint; designing an integrated learning coding network shared by depth information and texture information characteristics; designing a branch decoding network for recovering the depth map from the shared characteristics, and recovering the depth map; designing a mutual information maximization generation countermeasure network with shared characteristics as latent variables, and recovering a texture expansion diagram; adjusting the proportion of each task loss function, and training a model; and (4) carrying out interpolation processing on the depth map output by the network, and recovering the human face three-dimensional grid model with texture details by combining the texture map. The method utilizes multi-task learning-based single-view face three-dimensional reconstruction, texture generation and style migration, and has the advantages of high speed, low cost and the like.","['G06T17/00', 'G06T7/50', 'G06T7/80', 'G06T2207/30201']"
US11727275B2,Model training method and apparatus,"A model training method and apparatus is disclosed, where the model training method acquires a recognition result of a teacher model and a recognition result of a student model for an input sequence and trains the student model such that the recognition result of the teacher model and the recognition result of the student model are not distinguished from each other.","['G10L15/063', 'G06N3/08', 'G06N3/088', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G10L25/30', 'G06N3/084', 'G10L2015/0631']"
CN112446423B,A Transfer Learning-Based Approach to Fast Hybrid High-Order Attention Domain Adversarial Networks,"The invention relates to a method for fast mixing a high-order attention domain confrontation network based on transfer learning, which comprises the following steps: designing a fast-mix higher-order attention and domain impedance adaptive network for the image dataset to be processed; preprocessing a source domain and a target domain; sequentially introducing the preprocessed source domain and target domain in batches into a designed network, obtaining weighted feature maps through a fast mixing high-order attention network, inputting the weighted fine feature maps into a domain-impedance self-adaptive network for training, and finally performing probability operation through a full-connection layer; respectively calculating the average image classification accuracy of the source domain and the target domain; and (3) performing countermeasure training by taking the inverse gradient direction of the gradient inversion layer in back propagation, performing iterative training, and directly applying the training result to a target domain to perform image classification by using a fast mixed high-order attention and domain countermeasure adaptive network trained on a source domain. The invention improves the recognition rate and the migration capability of the unsupervised domain self-adaptive network in the migration learning.","['G06F18/214', 'G06N3/084']"
US11762998B2,System and method for protection and detection of adversarial attacks against a classifier,"A system and a method of prevention and/or detection of adversarial attacks against a classifier may include for example: using a classifier adapted to classify data elements of a specific category; receiving a first data element; applying the classifier on the first data element, to produce a first classification of the data element; using an autoencoder to generate a reconstructed, second data element based on the first data element; applying the classifier on the second data element, to produce a second classification of the data element; and analyzing the first and second classifications to detect and/or prevent an adversarial attack on the classifier.","['G06F21/566', 'G06F18/2148', 'G06F18/2185', 'G06F21/577', 'G06F21/645', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'H04L63/1416', 'H04L63/1433', 'G06N3/048']"
CN109086658B,Sensor data generation method and system based on generation countermeasure network,"The invention relates to a sensor data generation method based on generation of a countermeasure network, which comprises the following steps: a model construction step, namely constructing a generated countermeasure network model through a neural network model by using real data, wherein the generated countermeasure network model comprises a generator and a discriminator; a model training step, training the generator and the discriminator by a countermeasure game mechanism, and iterating until the data obtained from the generator meets the evaluation standard; and a data generation step, wherein the generator generates synthetic data through the countermeasure network model.","['G06V40/20', 'G06F18/214', 'G06F18/2431', 'G06F18/251']"
US12400753B2,Collaborative feature ensembling adaptation for domain adaptation in unsupervised optic disc and cup segmentation,Embodiments of the present disclosure are directed to training a neural network for ocular cup (OC) or ocular disc (OD) detection. One such method comprises initiating training of a first network to learn detection of OC/OD regions within a labeled source sample from a source domain; sharing training weights of the first network with a second network; initiating training of the second network to learn detection of OC/OD regions within an unlabeled sample from a target domain; transferring average training weights of the second network to a third network; initiating training of the third network to learn detection of OC/OD regions within an unlabeled sample from the target domain; computing a mean square error loss between the third network and the second network for a same target sample; and adjusting training weights of the second network based on the mean square error loss computation.,"['G16H30/40', 'A61B3/0025', 'A61B3/12', 'G06F18/2414', 'G06V10/82', 'G06V40/197', 'G16H50/20']"
US10963756B2,Emotion classification based on expression variations associated with same or similar emotions,"Techniques are described that facilitate automatically distinguishing between different expressions of a same or similar emotion. In one embodiment, a computer-implemented is provided that comprises partitioning, by a device operatively coupled to a processor, a data set comprising facial expression data into different clusters of the facial expression data based on one or more distinguishing features respectively associated with the different clusters, wherein the facial expression data reflects facial expressions respectively expressed by people. The computer-implemented method can further comprise performing, by the device, a multi-task learning process to determine a final number of the different clusters for the data set using a multi-task learning process that is dependent on an output of an emotion classification model that classifies emotion types respectively associated with the facial expressions.","['G06K9/628', 'G06N3/08', 'G06F16/285', 'G06F18/2431', 'G06K9/00268', 'G06K9/00302', 'G06K9/622', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06V10/763', 'G06V10/764', 'G06V40/168', 'G06V40/174']"
US12271832B2,Artificial intelligence engine for directed hypothesis generation and ranking,"An artificial intelligence engine for directed hypothesis generation and ranking uses multiple heterogeneous knowledge graphs integrating disease-specific multi-omic data specific to a patient or cohort of patients. The engine also uses a knowledge graph representation of ‘what the world knows’ in the relevant bio-medical subspace. The engine applies a hypothesis generation module, a semantic search analysis component to allow fast acquiring and construction of cohorts, as well as aggregating, summarizing, visualizing and returning ranked multi-omic alterations in terms of clinical actionability and degree of surprise for individual samples and cohorts. The engine also applies a moderator module that ranks and filters hypotheses, where the most promising hypothesis can be presented to domain experts (e.g., physicians, oncologists, pathologists, radiologists and researchers) for feedback. The engine also uses a continuous integration module that iteratively refines and updates entities and relationships and their representations to yield higher quality of hypothesis generation over time.","['G06N5/041', 'G06F16/24578', 'G06F16/284', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/02']"
US12229676B2,"System to detect, assess and counter disinformation","A computer-readable medium for the identification, measurement, and combatting of the influence of large-scale creation and distribution of disinformation is herein disclosed. An embodiment of this invention is comprised of one or more repositories of data which involve online comments and articles and attributes derived from them, one or more technical targeting systems, a content analysis system, a cost and influence estimation system, a dialog system, a performance management system, a bot design and test system, a security system, a multimedia content generator, one or more machine learning components, a data collection mechanism, separate consumer and human operator applications, and a mechanism for the creation and management of bots across multiple channels.","['G06N3/08', 'G06N5/046', 'G06F16/951', 'G06N3/04', 'G06Q50/01', 'G06F16/90332', 'G06F40/186', 'G06F40/20', 'G06F40/205', 'G06F40/279', 'G06N20/00', 'G06N5/025', 'H04L63/302']"
US20240386015A1,Composite symbolic and non-symbolic artificial intelligence system for advanced reasoning and semantic search,"A semantic search system integrates with an AI platform to provide advanced search capabilities by leveraging automatically generated ontologies and knowledge graphs. The system employs natural language processing, machine learning, and large language models to create, update, and align ontologies from diverse data sources. It supports context-aware query interpretation, personalized results, and complex reasoning by incorporating user context, feedback, and domain knowledge. The system optimizes search performance and efficiency through indexing techniques, distributed computing, and continuous learning. With a modular architecture and scalable infrastructure, the semantic search system enables users to retrieve relevant, meaningful, and context-specific information from vast amounts of structured and unstructured data. The integration of the semantic search system with the AI platform's components, such as knowledge graphs and model blending, enhances the platform's overall reasoning, decision-making, and problem-solving capabilities, empowering users with intelligent and intuitive search experiences across various domains and applications.","['G06F40/30', 'G06F16/245', 'G06F16/248', 'G06F16/9024', 'G06N5/022', 'G06N5/04']"
US11501532B2,Audiovisual source separation and localization using generative adversarial networks,"A method (and structure and computer product) for an audiovisual source separation processing includes receiving video data showing images of a plurality of sound sources into a video encoder, while concurrently receiving into the video encoder optical flow data of the video data, the optical flow data indicating motions of pixels between frames of the video data. The video encoder encodes the received video data into video localization data comprising information associating pixels in the frames of video data with different channels of sound and encodes the received optical flow data into video separation data comprising information associating motion information in the frames of video data with the different channels of sound.","['G06T9/00', 'G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T9/001', 'G06T9/002', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/48', 'H04N19/42', 'H04N19/51', 'H04N19/85', 'G06N3/084']"
US20210103814A1,Information Robust Dirichlet Networks for Predictive Uncertainty Estimation,"A method for an application provides weights for a neural network configured to dynamically generate a training for the neural network to detect uncertainty with regards to data input to the neural network. A training loss is determined for the neural network to minimize an expected Lp norm of a prediction error, wherein prediction probabilities follow a Dirichlet distribution. A closed-form approximation to the training loss is derived. The neural network is trained to infer parameters of the Dirichlet distribution, wherein the neural network learns distributions over class probability vectors. The Dirichlet distribution is regularized via an information divergence. A maximum entropy penalty is applied to an adversarial example to maximize uncertainty near an edge of the Dirichlet distribution.","['G06N3/08', 'G06N3/084', 'G06N3/045', 'G06N3/082', 'G06N5/04']"
TWI845781B,"Method and system of semiconductor defect detection and classification, and computer-readable storage medium",A rendered image is aligned with a scanning electron microscope (SEM) image to produce an aligned rendered image. A reference image is aligned with the SEM image to produce an aligned reference image. A threshold probability map also is generated. Dynamic compensation of the SEM image and aligned reference image can produce a corrected SEM image and corrected reference image. A thresholded defect map can be generated and the defects of the thresholded probability map and the signal-to-noise-ratio defects of the thresholded defect map are filtered using a broadband-plasma-based property to produce defect-of-interest clusters.,"['G06F17/18', 'G06F18/23', 'G06F18/241', 'G06F18/2413', 'G06F18/2415', 'G06N20/00', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06T7/0002', 'G06T7/001', 'G06T7/337', 'G06V10/762', 'G06V10/764', 'G06V10/82', 'G06V20/69', 'H01J37/222', 'H01J37/28', 'G06T2207/10061', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148', 'G06V2201/06', 'H01J2237/221']"
US10878566B2,Automatic teeth whitening using teeth region detection and individual tooth location,"An automatic teeth whitening system analyzes digital content and detects at least one teeth region in the digital content. A teeth region refers to a region or portion of the digital content that includes teeth (e.g., human teeth), and the teeth region detection includes identifying each pixel that displays part of the teeth using instance segmentation. The automatic teeth whitening system also finds the visual structure of each tooth in the teeth region using instance contours specific to the tooth. After finding the teeth region and the visual structure of each tooth in the teeth region, a whitening process is applied to the teeth to whiten them. The whitening of the teeth is performed automatically—manual steps by the user of selecting teeth regions and coloring the teeth in those regions are avoided.","['G06T7/11', 'G06T5/50', 'G06T5/60', 'G06T7/0012', 'G06T7/12', 'G06T7/13', 'G06T7/136', 'G06T7/143', 'G06T7/174', 'A61C19/066', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20216', 'G06T2207/30036', 'G06T2207/30201']"
US11232556B2,Surgical simulator providing labeled data,"A surgical simulator for simulating a surgical scenario comprises a display system, a user interface, and a controller. The controller includes one or more processors coupled to memory that stores instructions that when executed cause the system to perform operations. The operations include generating simulated surgical videos, each representative of the surgical scenario. The operations further include associating simulated ground truth data from the simulation with the simulated surgical videos. The ground truth data corresponds to context information of at least one of a simulated surgical instrument, a simulated anatomical region, a simulated surgical task, or a simulated action. The operations further include annotating features of the simulated surgical videos based, at least in part, on the simulated ground truth data for training a machine learning model.","['G09B23/28', 'G06F18/24143', 'G06K9/00718', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0012', 'G06V10/454', 'G06V10/751', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06V20/41', 'A61B2034/101', 'A61B2034/2055', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/03', 'G06V2201/034']"
US11210468B2,System and method for comparing plurality of documents,"Disclosed is a system for comparing a plurality of documents, wherein each of the plurality of documents comprise one or more sentences the system comprises a lexicon ontology represented into multi-dimensional hierarchical space communicably coupled with a server arrangement. The server arrangement is configured to obtain the documents, tokenize, using a tokenizer module, the sentences in each of the documents to obtain a plurality of tokens for each of the documents, determine token coordinates of each of the tokens in the multi-dimensional hierarchical space representing the lexicon ontology, determine sentence coordinates for each of the sentences in the documents using a transmutation module, generate similarity scores for each of the sentences in the documents using a comparison module, and determine a measure of similarity between the documents based on the similarity scores of the sentences in the documents.","['G06N5/022', 'G06F16/313', 'G06F18/214', 'G06F18/22', 'G06F18/29', 'G06F40/284', 'G06K9/6215', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06V30/418', 'G06N5/01', 'G06N7/01']"
CN111738172B,Cross-domain object re-identification method based on feature adversarial learning and self-similarity clustering,"The invention belongs to the field of computer vision and pattern recognition, and particularly relates to a cross-domain target re-recognition method, a system and a device based on feature countermeasure learning and self-similarity clustering, aiming at solving the problem that the existing target re-recognition method limits the discrimination of feature expression due to unfixed number of clustering centers and causes poor robustness of recognition results. The system method comprises the following steps: acquiring an image to be identified as an input image; extracting the characteristics of the input image through a pre-trained characteristic extraction network to serve as first characteristics; and calculating the Euclidean distance between the first feature and the corresponding feature of each image in the image library, sequencing the first feature and the corresponding feature of each image in the image library, and outputting a sequencing result. The invention improves the robustness of cross-domain target re-identification.","['G06V20/20', 'G06F18/214', 'G06F18/22', 'G06F18/23213', 'G06N3/045', 'G06N3/08']"
US20210374756A1,Methods and systems for generating rules for unseen fraud and credit risks using artificial intelligence,"Embodiments provide methods and systems for detecting frauds in payment transactions made by payment instrument using spend patterns of multiple payment instruments associated with user. The method performed by server system includes accessing payment transaction data associated with a plurality of customers from a transaction database. The method includes training a first generative adversarial network (GAN) model based on the payment transaction data and a plurality of probable fraud risk conditions. The first GAN model is trained to generate simulated customer fraud behaviors. The method includes filtering, by the server system, the simulated customer fraud behaviors based on a predetermined filtering criteria. The method includes generating, by the server system, fraud risk scores for the simulated customer fraud behaviors based on a fraud risk model. The method includes extracting fraud risk rules based on a set of simulated customer fraud behaviors from the simulated customer fraud behaviors.","['G06Q20/4016', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N5/01', 'G06Q20/20', 'G06N3/042', 'G06N3/044', 'G06N5/025', 'G06Q20/34', 'G06Q20/403']"
EP4150880A1,Method and system for virtual 3d communications,"Systems, methods, and non-transitory computer readable media for 3D video conference and/or video related. Specifically a system for receiving direction of gaze information regarding a direction of gaze of each participant within a representation of a virtual 3D video conference environment that is associated with the participant and updating the 3D participant representation information within the virtual 3D video conference environment, that reflects the direction of gaze of the participant.","['H04N7/157', 'H04N7/147', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T13/40', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/20', 'G06T7/11', 'G06T7/251', 'G06T7/70', 'G06T7/73', 'H04N7/144', 'H04N7/152', 'G06N3/044', 'G06T19/00', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30196', 'G06T2207/30201', 'G06T2219/2004']"
US20230322208A1,Steering limiters for vehicle navigation,"Systems and methods are provided for navigating a host vehicle. In one implementation, a system may include at least one processor configured to receive at least one image acquired by an image capture device, the at least one image being representative of an environment of the host vehicle; analyze the at least one image to identify at least one characteristic associated with the environment of the host vehicle; determine a navigational action for the host vehicle based on: the at least one characteristic associated with the environment of the host vehicle, and a steering limit corresponding to a maximum allowable lateral acceleration for the host vehicle; and cause one or more actuators associated with the host vehicle to implement the determined navigational action.","['B60W60/0013', 'B60W30/045', 'B60W50/085', 'B60W10/20', 'B60W30/18163', 'B60W40/072', 'B60W2420/403', 'B60W2420/408', 'B60W2420/52', 'B60W2520/125', 'B60W2520/26', 'B60W2530/10', 'B60W2540/049', 'B60W2552/30', 'B60W2552/35', 'B60W2552/40', 'B60W2554/402', 'B60W2554/404', 'B60W2554/801', 'B60W2554/802', 'B60W2710/20', 'B60W2710/207', 'B60W2720/125', 'B60W60/0015']"
KR102192211B1,Efficient Generative Adversarial Networks using Depthwise Separable and Channel Attention for Image to Image Translation,"Provided are an image translation method of efficient generative adversarial networks (GANs) using a depthwise separable convolution and channel attention, and an apparatus thereof. According to the present invention, the image translation method of efficient generative adversarial networks (GANs) using a depthwise separable convolution and channel attention comprises the steps of: applying a depthwise separable convolution to reduce the number of parameters; and applying channel attention to balance the quality of an output image and computational cost by compensating for information loss that occurs by applying the depthwise separable convolution.","['G06T3/4046', 'G06N3/08', 'G06T3/4053', 'G06T2207/20084']"
US20220083807A1,Generating labels for synthetic images using one or more neural networks,"Apparatuses, systems, and techniques to determine pixel-level labels of a synthetic image. In at least one embodiment, the synthetic image is generated by one or more generative networks and the pixel-level labels are generated using a combination of data output by a plurality of layers of the generative networks.","['G06N3/084', 'G06F18/2431', 'G06F18/214', 'G06K9/628', 'G06K9/6232', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/088', 'G06T11/60', 'G06V10/774', 'G06N3/063', 'G06T2200/24']"
US20190286938A1,Real-to-synthetic image domain transfer,"Systems, methods, and machine-readable media for deterministically generating labeled data for training or validating machine learning models for image analysis, and for using such machine learning models to determine the contents of real-domain images by using a domain transfer to synthetic-appearing images are described.","['G06K9/6256', 'G06V10/774', 'G06F18/214', 'G06N20/00', 'G06N3/08', 'G06T11/001', 'G06T15/08', 'G06T17/20', 'G06V10/82']"
US11050770B2,Network defense system and method thereof,A network defense system can include a sensor alert ingestion framework adapted to monitor network activity and alert detected or suspected anomalies. A network analyzer may be coupled to the sensor alert ingestion framework to analyze the anomalies. A course of action (CoA) simulator may be coupled to the network analyzer adapted to generate a list of decision including courses of action to address the anomalies. There may be a training and feedback unit coupled to the CoA simulator to train the system to improve responses in addressing future anomalies.,"['H04L63/1425', 'G06N20/00', 'G06N20/20', 'G06N3/006', 'G06N5/025', 'G06N5/046', 'G06N7/01', 'H04L63/0263', 'H04L63/1433', 'H04L63/20']"
US11354564B2,Tuning of loop orders in blocked dense basic linear algebra subroutines,"An example includes a sequence generator to generate a plurality of sequence pairs, a first one of the sequence pairs including: (i) a first input sequence representing first accesses to first tensors in a first loop nest of a first computer program, and (ii) a first output sequence representing a first tuned loop nest corresponding to the first accesses to the first tensors in the first loop nest; a model trainer to train a recurrent neural network based on the sequence pairs as training data, the recurrent neural network to be trained to tune loop ordering of a second computer program based on a second input sequence representing second accesses to a second tensor in a second loop nest of the second computer program; and a memory interface to store, in memory, a trained model corresponding to the recurrent neural network.","['G06F8/4442', 'G06N3/0418', 'G06F12/0877', 'G06F17/16', 'G06F8/445', 'G06F9/30065', 'G06F9/45516', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06F2212/1021', 'G06N3/047']"
US11508102B2,Systems and methods for image processing,"The present disclosure is related to systems and methods for image processing. The method may include obtaining an image including at least one of a first type of artifact or a second type of artifact. The method may include determining, based on a trained machine learning model, at least one of first information associated with the first type of artifact or second information associated with the second type of artifact in the image. The trained machine learning model may include a first trained model and a second trained model. The first trained model may be configured to determine the first information. The second trained model may be configured to determine the second information. The method may include generating a target image based on at least part of the first information and the second information.","['G06N20/00', 'G06T5/70', 'A61B5/055', 'A61B5/7267', 'A61B6/03', 'A61B6/032', 'A61B6/037', 'A61B6/5258', 'A61B8/5269', 'G06T11/008', 'G06T5/003', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'G06T7/0014', 'A61B5/7203', 'A61B6/501', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30016', 'G06T2207/30048', 'G06T2207/30092', 'G06T2207/30101', 'G06T2211/441', 'G06T2211/448']"
US20220029902A1,Network Anomaly Detection,"A cloud network is a complex environment in which hundreds and thousands of users or entities can each host, create, modify, and develop multiple virtual machines. Each virtual machine can have complex behavior unknown to the provider or maintainer of the cloud. Technologies disclosed include methods, systems, and apparatuses to monitor the complex environment to detect network anomalies using machine learning techniques. In addition, techniques to modify and adapt to user feedback are provided allowing the developed models to be tuned for specific use cases, virtual machine types, and users.","['H04L43/0817', 'H04L41/16', 'G06F18/214', 'G06F21/57', 'G06F21/577', 'G06F9/45558', 'G06K9/6256', 'G06N20/20', 'H04L41/0627', 'H04L41/0686', 'H04L41/142', 'H04L43/065', 'H04L63/1425', 'H04L63/20', 'G06F2009/45575', 'G06F2009/45595', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H04L41/0631', 'H04L41/145', 'H04L41/40', 'H04L43/0829', 'H04L43/0852', 'H04L43/0888', 'H04L63/0263']"
US11159789B2,Generative adversarial network based intra prediction for video coding,"Systems and methods which provide Generative Adversarial Network (GAN) based intra prediction for video coding are described. GAN based intra prediction as implemented according to embodiments may be modeled as an inpainting task. For example, intra prediction may be formulated as a learning based inpainting task, wherein a latent variable is designed to control different generation modes. GAN based intra prediction provided according to embodiments of the invention may be implemented alone or in combination with one or more other video compression technique, such as a direction intra prediction technique. The intra prediction module of such a HEVC encoder/decoder may be redesigned to also apply GAN based inpainting in intra prediction, wherein Rate-Distortion Optimization (RDO) may be performed to select the best intra prediction mode between the intra prediction approaches.","['H04N19/11', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'H04N19/132', 'H04N19/593', 'H04N19/70']"
US12395722B2,Removing distracting objects from digital images,"The present disclosure relates to systems, methods, and non-transitory computer-readable media that modify digital images via scene-based editing using image understanding facilitated by artificial intelligence. For instance, in one or more embodiments, the disclosed systems provide, for display within a graphical user interface of a client device, a digital image displaying a plurality of objects, the plurality of objects comprising a plurality of different types of objects. The disclosed systems generate, utilizing a segmentation neural network and without user input, an object mask for objects of the plurality of objects. The disclosed systems determine, utilizing a distractor detection neural network, a classification for the objects of the plurality of objects. The disclosed systems remove at least one object from the digital image, based on classifying the at least one object as a distracting object, by deleting the object mask for the at least one object.","['G06T11/60', 'G06N3/04', 'G06V10/273', 'G06V10/764', 'G06V10/82', 'G06V10/945', 'H04N23/611', 'H04N23/617', 'H04N23/631', 'H04N23/632', 'H04N23/633', 'H04N23/80', 'H04N5/2628']"
EP3757789A1,Managed edge learning in heterogeneous environments,"Systems and methods are provided for managing machine learning processes within distributed and heterogeneous environments. The distributed and heterogeneous environments may include different types of devices that include different specifications, security, and privacy concerns. The devices participate in complex machine learning tasks while maintaining both privacy and autonomy. The systems and methods manage the lifecycle of how machine learning workloads are distributed.","['G06F9/5072', 'G06F18/214', 'G06F21/6245', 'G06N20/00', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06N7/01']"
US10572679B2,Privacy-guided disclosure of crowd-based scores computed based on measurements of affective response,"Some aspects of this disclosure include systems, methods, and/or computer programs that may be used to filter measurements of affective response collected using sensors that measure physiological signals and/or behavioral cues of users. A bias may be tendency, attitude, and/or inclination, which may influence the affective response a user has to an experience. Some embodiments described herein involve learning a model of biases of the user from measurements of affective response of the user and descriptions of events to which the measurements correspond. The model may be used to filter measurements of the user, which may be provided to other entities, if the model indicates that the measurements are likely to contain a certain level and/or type of bias (e.g., bias to certain factors). Such a filtration process can help make results generated based on the measurements more accurate and also may help protect the privacy of the user.","['G06F21/6245', 'G06F16/24578', 'G06F16/00']"
US20220084055A1,Software agents and smart contracts to control disclosure of crowd-based results calculated based on measurements of affective response,"Software agents and smart contracts may assist users to control how their measurements of affective response are used and how they are compensated for providing their measurements. In one embodiment, a computer receives a measurement of affective response of a user to an experience, and also receives a request indicative of compensation to be provided to the user for a disclosure of a score for the experience. The score is to be calculated based on the measurement of the user and additional measurements of affective response of other users to the experience. The computer calculates a risk to privacy of the user due to a disclosure of the score. Responsive to the risk being below a first threshold and the compensation reaching a second threshold, the computer signs on behalf of the user, a smart contract that facilitates the disclosure of the score and a transfer of the compensation.","['G06Q30/0203', 'G06F16/24578', 'G06F21/6245', 'G06Q2220/00']"
US20240012965A1,Steady flow prediction method in plane cascade based on generative adversarial network,"A steady flow prediction method in a plane cascade based on a generative adversarial network is provided. Firstly, CFD simulation experimental data in the plane cascade are preprocessed, and a test dataset and a training dataset are divided from the simulation experimental data. Then, an Encoding-Forecasting network module, a deep convolutional network module and a generative adversarial network prediction model are constructed successively. Finally, prediction is conducted on test set data: the test set data is preprocessed in the same manner, and data dimensions are adjusted according to input requirements of a saved optimal prediction model; and flow field images in the plane cascade at an inlet attack angle of 10° are obtained through the prediction model. The present invention can effectively avoid the problem of limited measurement range of sensors in an axial flow compressor, and the prediction result is highly consistent with the calculation result of CFD.","['G06F30/27', 'G06F30/17', 'G06F30/28', 'G06N3/04', 'G06N3/08', 'G06F2111/08', 'G06F2113/08', 'G06F2119/14', 'Y02T90/00']"
US11687623B2,Anti-piracy framework for deep neural networks,"Systems, methods, apparatuses, and computer program products for providing an anti-piracy framework for Deep Neural Networks (DNN). A method may include receiving authorized raw input at a protective transform module. The method may also include receiving unauthorized raw input at a restrictive deep neural network. The method may further include processing the authorized raw input at the protective transform module to generate a processed input. In addition, the method may include feeding the processed input into the restrictive deep neural network. The method may also include generating a result based on the processed input and the unauthorized raw input. Further, the result may include a different learning performance between the authorized raw input and the unauthorized raw input.","['G06F21/10', 'G06F21/60', 'G06F21/604', 'G06F21/62', 'G06F21/74', 'G06N3/04', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/09', 'G06N3/045', 'G06N3/082']"
US12348552B2,Automated prediction of cyber-security attack techniques using knowledge mesh,"Implementations include a computer-implemented method for reducing cyber-security risk, comprising: selecting one or more modules for inclusion in a knowledge mesh, wherein each module is associated with a respective aspect and maintains a knowledge graph specific to the respective aspect, wherein each knowledge graph is generated using data from one or more cyber-security repositories and includes nodes and connections between the nodes; receiving a query corresponding to a first node of a first knowledge graph included in the knowledge mesh; generating a response to the query by identifying connections between the first node of the first knowledge graph and at least one node of at least one other knowledge graph included in the knowledge mesh; and identifying, based on the response to the query, one or more actions to reduce cyber-security risk.","['H04L63/1433', 'G06N20/00', 'G06N5/022', 'G06N5/04', 'H04L41/024', 'H04L41/16', 'H04L41/145', 'H04L41/147', 'H04L41/22']"
US10176405B1,"Vehicle re-identification techniques using neural networks for image analysis, viewpoint-aware pattern recognition, and generation of multi- view vehicle representations",This disclosure relates to improved vehicle re-identification techniques. The techniques described herein utilize artificial intelligence (AI) and machine learning functions to re-identify vehicles across multiple cameras. Vehicle re-identification can be performed using an image of the vehicle that is captured from any single viewpoint. Attention maps may be generated that identify regions of the vehicle that include visual patterns that overlap between the viewpoint of the captured image and one or more additional viewpoints. The attention maps are used to generate a multi-view representation of the vehicle that provides a global view of the vehicle across multiple viewpoints. The multi-view representation of the vehicle can then be compared to previously captured image data to perform vehicle re-identification.,"['H04N7/181', 'G06V10/462', 'G06K9/6269', 'G06F18/214', 'G06F18/22', 'G06F18/23', 'G06F18/2411', 'G06K9/00718', 'G06K9/00771', 'G06K9/00785', 'G06K9/6201', 'G06K9/6218', 'G06K9/6256', 'G06T7/246', 'G06T7/73', 'G06V10/761', 'G06V10/764', 'G06V10/82', 'G06V20/30', 'G06V20/41', 'G06V20/52', 'G06V20/54', 'G06V20/63', 'G06K2209/23', 'G06N3/0464', 'G06T19/00', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/08']"
US11973780B2,Deobfuscating and decloaking web-based malware with abstract execution,"Techniques for deobfuscating and decloaking web-based malware with abstract execution is disclosed. In some embodiments, a system/process/computer program product for deobfuscating and decloaking web-based malware with abstract execution includes receiving a sample; performing an abstract execution of a script included in the sample; identifying the sample as malware based on the abstract execution of the script included in the sample; and generating a log of results from the abstract execution of the script included in the sample.","['H04L63/1425', 'G06F21/53', 'G06F21/566', 'H04L63/0263', 'H04L63/1483']"
CN110930295B,"Image style migration method, system, device and storage medium","The invention discloses an image style migration method, an image style migration system, an image style migration device and a storage medium, wherein the method comprises the following steps: acquiring a content picture; inputting the content picture into a pre-trained image style migration model for style migration treatment, and outputting a target picture with a specific style and retaining the original content; the image conversion network and the discrimination network form a generating type countermeasure network (GAN), and are updated alternately in the model training process. According to the invention, the network is continuously updated and optimized through the sensing counterloss function until the loss is minimized, and the image style migration model with better effect is obtained, so that an output picture which is closer to a content picture and a style picture can be obtained, the problem of picture background distortion is effectively avoided, and the method can be widely applied to the field of data image processing.","['G06T3/04', 'G06N3/045', 'G06N3/08']"
CN111709470B,"Image generation methods, devices, equipment and media","The application discloses an image generation method, device, equipment and medium, and relates to the field of artificial intelligence deep learning and image processing. The specific implementation scheme is as follows: acquiring a first random vector set; determining, based on the trained classifier, an image class to which at least one random vector in the first set of random vectors belongs; the random vectors belonging to the image categories are input to a trained image generator, generating virtual images belonging to the image categories. By the technical scheme, a large number of images with clear classification can be automatically generated, the diversity of the images is improved, and the image classification cost is reduced.","['G06T11/00', 'G06F18/2411', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/774', 'G06V10/82', 'G06V40/172', 'G06T2207/20081', 'G06T2207/20084']"
US10346974B2,Apparatus and method for medical image processing,"There is provided an apparatus comprising processing circuitry configured to: receive first medical image data obtained using a first type of imaging procedure, wherein the first medical image data is representative of an anatomical region of a subject; and apply a simulator to perform a simulation process on the first medical image data to obtain simulated second medical image data, the simulated second medical image data having properties so as to simulate image data that is obtained using a second type of imaging procedure. The simulator comprises an image synthesizer that is trained in combination with a discriminator in an adversarial fashion by repeatedly alternating an image synthesizer training process in which the image synthesizer is trained to produce simulated medical image data, and a discriminator training process in which the discriminator is trained to distinguish between real medical image data and simulated medical image data.","['G06T7/0012', 'G06T7/30', 'G01R33/5602', 'G01R33/5608', 'G06T11/008', 'G01R33/4812', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084']"
US11847245B2,Privacy preserving data labeling,"Systems as described herein may label data to preserve privacy. An annotation server may receive a document comprising a collection of text representing a plurality of confidential data from a first computing device. The annotation server may convert the document to a plurality of text embeddings. The annotation server may input the text embeddings into a machine learning model to generate a plurality of synthetic images, and receive a label for each of the plurality of synthetic images from a third-party labeler. Accordingly, the annotation server may send the confidential data and the corresponding labels to a second computing device.","['G06N3/084', 'G06F21/6245', 'G06F18/2132', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V20/62', 'G06V30/274']"
US11183051B2,"Deep learning methods for estimating density and/or flow of objects, and related methods and software","Methods and software utilizing artificial neural networks (ANNs) to estimate density and/or flow (speed) of objects in one or more scenes each captured in one or more images. In some embodiments, the ANNs and their training configured to provide reliable estimates despite one or more challenges that include but are not limited to, low-resolution images, low framerate image acquisition, high rates of object occlusions, large camera perspective, widely varying lighting conditions, and widely varying weather conditions. In some embodiments, fully convolutional networks (FCNs) are used in the ANNs. In some embodiments, a long short-term memory network (LSTM) is used with an FCN. In such embodiments, the LSTM can be connected to the FCN in a residual learning manner or in a direct connected manner. Also disclosed are methods of generating training images for training an ANN-based estimating algorithm that make training of the estimating algorithm less costly.","['G08G1/0116', 'G06F18/211', 'G06K9/00785', 'G06K9/6228', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V20/54', 'G06V20/653', 'G08G1/0129', 'G08G1/04']"
US11843777B2,"Image encoding and decoding, video encoding and decoding: methods, systems and training methods","Lossy or lossless compression and transmission, comprising the steps of: (i) receiving an input image; (ii) encoding it to produce a y latent representation; (iii) encoding the y latent representation to produce a z hyperlatent representation; (iv) quantizing the z hyperlatent representation to produce a quantized z hyperlatent representation; (v) entropy encoding the quantized z hyperlatent representation into a first bitstream, (vi) processing the quantized z hyperlatent representation to obtain a location entropy parameter μy, an entropy scale parameter σy, and a context matrix Ay of the y latent representation; (vii) processing the y latent representation, the location entropy parameter μy and the context matrix Ay, to obtain quantized latent residuals; (viii) entropy encoding the quantized latent residuals into a second bitstream; and (ix) transmitting the bitstreams.","['H04N19/13', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T9/002', 'G06V10/422', 'H04N19/124', 'H04N19/184', 'H04N19/19', 'H04N19/42', 'H04N19/59', 'H04N19/88', 'H04N19/91', 'G06T2207/20084']"
US11188783B2,Reverse neural network for object re-identification,"The invention relates to a method comprising receiving, by a neural network, a first image comprising at least one target object; receiving, by the neural network, a second image comprising at least one query object; and determining, by the neural network, whether the query object corresponds to the target object, wherein the neural network comprises a discriminator neural network of a generative adversarial network (GAN). The invention further relates to an apparatus and a computer program product that perform the method.","['G06K9/6215', 'G06V10/82', 'G06F18/22', 'G06F18/2413', 'G06F18/2415', 'G06F18/28', 'G06K9/00624', 'G06K9/00744', 'G06K9/4628', 'G06K9/6255', 'G06K9/627', 'G06K9/6277', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/454', 'G06V10/764', 'G06V10/772', 'G06V20/00', 'G06V20/46', 'G06F18/2148', 'G06K9/00281', 'G06K9/00288', 'G06K9/6257', 'G06V40/171', 'G06V40/172']"
US12141052B2,Resilient estimation for grid situational awareness,"According to some embodiments, a system, method and non-transitory computer-readable medium are provided to protect a cyber-physical system having a plurality of monitoring nodes comprising: a normal space data source storing, for each of the plurality of monitoring nodes, a series of normal monitoring node values over time that represent normal operation of the cyber-physical system; a situational awareness module including an abnormal data generation platform, wherein the abnormal data generation platform is operative to generate abnormal data to represent abnormal operation of the cyber-physical system using values in the normal space data source and a generative model; a memory for storing program instructions; and a situational awareness processor, coupled to the memory, and in communication with the situational awareness module and operative to execute the program instructions to: receive a data signal, wherein the received data signal is an aggregation of data signals received from one or more of the plurality of monitoring nodes, wherein the data signal includes at least one real-time stream of data source signal values that represent a current operation of the cyber-physical system; determine, via a trained classifier, whether the received data signal is a normal signal or an abnormal signal, wherein the trained classifier is trained with the generated abnormal data and normal data; localize an origin of an anomaly when it is determined the received data signal is the abnormal signal; receive the determination and localization at a resilient estimator module; execute the resilient estimator module to generate a state estimation for the cyber-physical system. Numerous other aspects are provided.","['G06F11/3684', 'G06F11/263', 'G06F18/213', 'G06F18/214', 'G06F18/24', 'G06F18/2411', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'H04L41/0677', 'H04L41/16', 'H04L43/12', 'H04L63/1425', 'H04L63/1441', 'H04L63/1466', 'H04W12/128', 'G06N3/0418', 'Y04S40/00', 'Y04S40/20']"
US10692185B2,Generative methods of super resolution,"A method for training an algorithm to process at least a section of received visual data using a training dataset and reference dataset. The method comprises an iterative method with iterations comprising: generating a set of training data using the algorithm; comparing one or more characteristics of the training data to one or more characteristics of at least a section of the reference dataset; and modifying one or more parameters of the algorithm to optimise processed visual data based on the comparison between the characteristic of the training data and the characteristic of the reference dataset. The algorithm may output the processed visual data with the same content as the at least a section of received visual data. Some aspects and/or implementations provide for improved super-resolution of lower quality images to produce super-resolution images with improved characteristics (e.g. less blur, less undesired smoothing) compared to other super-resolution techniques.","['H04N19/59', 'G06T3/4076', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06N20/10', 'G06N20/20', 'G06N3/048', 'G06N5/01', 'G06T2207/20081']"
US12067690B2,"Image processing method and apparatus, device, and storage medium","An image processing method is provided. The method includes: encoding an input image based on an attention mechanism to obtain an encoding tensor set and an attention map set of the input image; obtaining an encoding result of the input image according to the encoding tensor set and the attention map set, the encoding result of the input image recording an identity feature of a human face in the input image; encoding an expression image to obtain an encoding result of the expression image, the encoding result of the expression image recording an expression feature of a human face in the expression image; and generating an output image according to the encoding result of the input image and the encoding result of the expression image, the output image having the identity feature of the input image and the expression feature of the expression image.","['G06T3/04', 'G06N3/08', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T11/00', 'G06T9/00', 'G06V10/82', 'G06V10/95', 'G06V40/168', 'G06V40/174']"
US11354792B2,System and methods for modeling creation workflows,"Technologies for image processing based on a creation workflow for creating a type of images are provided. Both multi-stage image generation as well as multi-stage image editing of an existing image are supported. To accomplish this, one system models the sequential creation stages of the creation workflow. In the backward direction, inference networks can backward transform an image into various intermediate stages. In the forward direction, generation networks can forward transform an earlier-stage image into a later-stage image based on stage-specific operations. Advantageously, this technical solution overcomes the limitations of the single-stage generation strategy with a multi-stage framework to model different types of variation at various creation stages. Resultantly, both novices and seasoned artists can use these technologies to efficiently perform complex artwork creation or editing tasks.","['G06T11/60', 'G06T5/50', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06N5/01', 'G06N5/046', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084']"
WO2022008677A1,Method for detecting and mitigating bias and weakness in artificial intelligence training data and models,"An exemplary embodiment may present methods for detecting bias both globally and locally by harnessing the white-box nature of the eXplainable artificial intelligence, eXplainable Neural Nets, Interpretable Neural Nets, eXplainable Transducer Transformers, eXplainable Spiking Nets, eXplainable Memory Net and eXplainable Reinforcement Learning models. Methods for detecting bias, strength, and weakness of data sets and the resulting models may be described. A first exemplary method presents a global bias detection which utilizes the coefficients of the explainable model to identify, minimize, and/or correct any potential bias within a desired error tolerance. A second exemplary method makes use of local feature importance extracted from the rule-based model coefficients to identify any potential bias locally. A third exemplary method aggregates the feature importance over the results/explanations of multiple samples. A fourth exemplary method presents a method for detecting bias in multi-dimensional data such as images. Further, a backmap reverse indexing mechanism may be implemented. A number of mitigation methods are also presented to eliminate bias from the affected models.","['G06N3/082', 'G06N5/045', 'G06F17/18', 'G06F18/10', 'G06F18/213', 'G06F18/2178', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'G06N5/022', 'G06V10/751', 'G06N3/048']"
US20220090215A1,Methods and compositions for imputing or predicting genotype or phenotype,"Methods and compositions to impute or predict genotype, haplotype, molecular phenotype, agronomic phenotypes, and/or coancestry are provided. Methods and compositions provided include using latent space to generate latent space representations or latent vectors that are independent of underlying genotypic or phenotypic data. The methods may include generating a universal latent space representation by encoding discrete or continuous variables derived from genotypic or phenotypic data into latent vectors through a machine learning-based encoder framework. Provided herein are universal methods of parametrically representing genotypic or phenotypic data obtained from one or more populations or sample sets to impute or predict a genotype or phenotype of interest.","['G16B40/00', 'G16B20/20', 'C12Q1/6895', 'G06N3/045', 'G06N3/0475', 'G06N3/094', 'G16B20/00', 'G16B25/10', 'G16B40/30', 'C12Q2600/13', 'C12Q2600/154', 'C12Q2600/156', 'C12Q2600/172']"
CN109255364B,A scene recognition method based on deep convolutional generative adversarial network,"The invention relates to a scene recognition method for generating a countermeasure network based on deep convolution. The existing method for scene recognition by utilizing deep learning is to train through a sample and a label carried by a training set picture and then utilize the trained model to extract the features of the picture, but most pictures have no label in practice, and even if manual marking can be utilized, great time and cost are required. According to the method, firstly, a depth convolution is constructed by using a label-free picture to generate a confrontation network model, then, a generator which is learned to the scene data set distribution is used for reverse training to obtain a convolution neural network to extract the characteristics of the image, the problem that the image data set needs labels is solved, and the characteristic vector which can represent the image better than the traditional characteristics is extracted, so that the identification accuracy in the scene identification task is improved.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/088']"
US10692002B1,Learning method and learning device of pedestrian detector for robust surveillance based on image analysis by using GAN and testing method and testing device using the same,"A method for learning a pedestrian detector to be used for robust surveillance or military purposes based on image analysis is provided for a solution to a lack of labeled images and for a reduction of annotation costs. The method can be also performed by using generative adversarial networks (GANs). The method includes steps of: a learning device generating an image patch by cropping each of regions on a training image, and instructing an adversarial style transformer to generate a transformed image patch by converting each of pedestrians into transformed pedestrians capable of impeding a detection; and generating a transformed training image by replacing each of the regions with the transformed image patch, instructing the pedestrian detector to detecting the transformed pedestrians, and learning parameters of the pedestrian detector to minimize losses. This learning, as a self-evolving system, is robust to adversarial patterns by generating training data including hard examples.","['G06V10/454', 'G06V40/103', 'G06F18/214', 'G06F18/241', 'G06K9/00362', 'G06K9/6256', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/00', 'G06T3/40', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G06V20/58', 'G06V40/10', 'G06V40/25', 'G06T2207/20081', 'G06T2207/30196', 'G06T2210/12']"
CN118658128B,AI multidimensional teaching behavior analysis method and system based on classroom video,"The invention provides an AI multidimensional teaching behavior analysis method and system based on classroom video, which relate to the technical field of image processing and comprise the following steps: acquiring a classroom teaching video, extracting video frames and audio frames, performing self-adaptive segmentation, performing image super-resolution reconstruction, and performing self-adaptive noise reduction to obtain a standard classroom teaching video; adding the three-dimensional key point coordinates into a target detection model and a single-target tracking model to perform target recognition to obtain a target boundary box, tracking to obtain a space-time behavior track, extracting three-dimensional key point coordinates to obtain gesture characteristic information, performing speaker separation on the audio track, learning to obtain a voice characteristic vector, and modeling sight line movement to obtain gaze point distribution information; and constructing a teaching behavior analysis chart based on the heterogeneous graph neural network, carrying out time sequence iteration update, determining internal association, generating time sequence semantic characterization, constructing a multi-layer condition generation type countermeasure network, generating an optimal teaching mode, comparing and carrying out microscopic deconstructing to obtain a teaching behavior analysis report.","['G06V20/53', 'G06N3/042', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06T3/4053', 'G06T7/246', 'G06T7/73', 'G06V10/22', 'G06V10/44', 'G06V10/82', 'G06V20/41', 'G10L25/03', 'G10L25/30', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30232', 'G06T2207/30241', 'Y02T10/40']"
AU2020437435B2,"Adversarial image generation method, apparatus, device, and readable storage medium","Disclosed are a method and device for generating an adversarial image, equipment, and a readable storage medium. The method comprises: generating, on the basis of a target classification model, a reference model equivalent in terms of classification with the target classification model; acquiring a target image, generating an original noise with respect to the target image on the basis of the reference model; inputting a first noise and the original noise into an adversarial model and, when the adversarial model satisfies a convergence criterion, outputting a second noise corresponding to the first noise; the second noise being a noise enhancing the information entropy of the original noise; and generating, on the basis of the second noise and of the target image, an enhanced noise image corresponding to the target image; the classification accuracy of the enhanced noise image in the target classification model being less than the classification accuracy of the target image in the target classification model. The employment of the present application safeguards the enhanced noise image from being recognized by a malicious target classification model, thus increasing the security of the enhanced noise image.","['G06F18/2413', 'G06F21/36', 'G06F21/577', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/772', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V30/18057', 'G06V30/1914', 'G06V30/19147', 'G06F2221/033', 'G06V10/454', 'G06V30/226']"
CN109978762B,A Super-resolution Reconstruction Method Based on Conditional Generative Adversarial Networks,"The invention discloses a super-resolution reconstruction method based on a condition generation countermeasure network, which specifically comprises the following steps: using the disclosed super-resolution image dataset to make a low-resolution image and a corresponding high-resolution image training set; constructing a condition generation countermeasure network model, using a dense residual block in a generator network, and realizing super-resolution image reconstruction at the tail end of the generator network model by using a sub-pixel up-sampling method; inputting the training image set into a condition generation countermeasure network for model training, and converging the training model through a perception loss function; performing downsampling processing on the image test set to obtain a low-resolution test image; the low-resolution test image is input into the conditional countermeasure network model, and a high-quality high-resolution image is obtained. The method can well solve the problems that the super-resolution image generated by the conventional generation countermeasure network looks clear and has extremely low evaluation index, and simultaneously, the problems of gradient elimination and high-frequency information loss are relieved through the dense residual error network.","['G06T3/4053', 'Y02T10/40']"
US20200279105A1,Deep learning engine and methods for content and context aware data classification,"Methods, systems and deep learning engines for content and context aware data classification by business category and confidentiality level are provided. The deep learning engine includes a feature extraction module and a classification and labelling module. The feature extraction module extracts both context features and document features from documents and the classification and labelling module is configured for content and context aware data classification of the documents by business category and confidentiality level using neural networks.","['G06K9/00442', 'G06N3/08', 'G06F18/24', 'G06F18/24155', 'G06F18/2431', 'G06K9/6278', 'G06K9/628', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N20/20', 'G06N7/01']"
US12026845B2,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate augmented images. In at least one embodiment, one or more neural networks are used to modify one or more first objects in an image based at least in part upon a modification to be made to one or more second objects in the image.","['G06T19/20', 'G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06T19/006', 'G06T7/0002', 'G06T7/70', 'G06N3/048', 'G06N3/063', 'G06N5/046', 'G06T2207/20081', 'G06T2207/20084']"
US11944385B2,Systems and methods for medical image analysis,"A surgical planning and assessment system is disclosed. The system may include a computing system having a processor, a data store, a patient specific planning and analysis module, and a display. The system may be configured to access a database storing a plurality of possible surgical plans. The computing system may store a target surgical plan including a plurality of patient specific inputs including at least one preoperative medical image of a spine of a target patient and analyze the target surgical plan to determine a predicted alignment of the spine of the target patient. The computing system may develop a plurality of predictive models including a predicted alignment of the spine of the target patient based on the target surgical plan and suggest at least one alternative surgical plan with respect to the target surgical plan.","['A61B17/7032', 'A61B34/10', 'A61B17/7077', 'A61B34/20', 'A61B34/25', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G16H10/20', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H70/20', 'A61B17/7082', 'A61B2034/102', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'A61B2034/108', 'A61B2034/2048', 'A61B2034/254', 'A61B2034/256', 'A61B2090/376', 'A61B2090/3762', 'G06N20/00']"
US11308291B2,Methods and apparatus for radio frequency sensing in diverse environments,"A system may sense the contents of a closed container, by analyzing a wireless signal that reflects from an RFID tag on the outside of the container. The frequency response of the tag's antenna may be affected by the relative permittivity of the contents and by the tag's environment. The frequency response may be measured in a line-of-sight environment and in a multipath environment. Channel estimates may be calculated, based on the measurements. Channel ratios may be calculated by dividing line-of-sight channel estimates by multipath channel estimates. The resulting channel ratios may be fed into a variational autoencoder, which in turn generates synthetic data that contains information about multipath environments but not the contents. The output of the variational autoencoder may be converted into synthetic channel estimates, which may in turn be employed for anomaly detection, or to train a classifier to classify contents of the container.","['G06K19/07771', 'G06K7/0008', 'G06K17/0022', 'G06K19/0723', 'G06K7/10009']"
WO2022105308A1,Method for augmenting image on the basis of generative adversarial cascaded network,"Disclosed in the present invention is a method for augmenting an image on the basis of a generative adversarial cascaded network. The method comprises: determining a region of interest from an original image I ori and cutting same to obtain a cut image I cut ; obtaining an augmented data set S cut by pre-processing the I cut ; training an Ⅰ-level generative adversarial network by using the data set S cut ; loading the trained I-level generator, inputting random noise to infer an image, and performing up-sampling processing on the generated image to form a new data set S I ; using the data set S I and the I cut as the training data sets of an II-level generative adversarial network, and training the II-level generative adversarial network; loading the trained II-level generator, and inputting the data set S I into the II-level generator to infer a required augmented image I des . The present invention solves the problems of small difference and low resolution of generated images in the I-level generative adversarial network when image augmentation is performed, thereby improving the generalization performance of the network while performing image augmentation.","['G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T3/4023', 'G06T5/40', 'G06T5/90', 'G06T7/11', 'G06V10/25', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30008']"
AU2020220153B2,Robust warping via multi-scale patch adversarial loss for virtual try-on,"Generating a synthesized image of a person wearing clothing is described. A two-dimensional reference image depicting a person wearing an article of clothing and a two-dimensional image of target clothing in which the person is to be depicted as wearing are received. To generate the synthesized image, a warped image of the target clothing is generated via a geometric matching module, which implements a machine learning model trained to recognize similarities between warped and non-warped clothing images using multi-scale patch adversarial loss. The multi-scale patch adversarial loss is determined by sampling patches of different sizes from corresponding locations of warped and non-warped clothing images. The synthesized image is generated on a per-person basis, such that the target clothing fits the particular body shape, pose, and unique characteristics of the person.","['G06T3/18', 'G06F18/22', 'G06F18/24', 'G06F18/25', 'G06N3/045', 'G06N3/08', 'G06T11/60', 'G06T7/40', 'G06T2207/20081', 'G06T2207/30196', 'G06T2210/16']"
WO2019228317A1,"Face recognition method and device, and computer readable medium","A face recognition method and device, and a computer readable medium. The method comprises: inputting n image frames comprised in first video data to a feature extraction network for facial feature extraction to obtain n facial feature matrices in one-to-one correspondence to the n image frames; fusing the n facial feature matrices to obtain a target facial feature matrix of the face to be recognized; and performing face recognition on the face to be recognized by means of the target facial feature matrix to obtain a face recognition result, wherein 2≤n. By performing face recognition by means of a facial feature obtained by fusing multiple facial features extracted from video data, the accuracy of face recognition can be increased.",['G06F18/00']
CN110992934B,Defense method and defense device for black box attack model of voice recognition system,"The invention discloses a defense method and a defense device for a black box attack model of a voice recognition system. The defense method comprises the steps of adding simulated environmental noise to original audio, simulating a voice input condition in a real scene, forming a primary countermeasure sample after random noise addition, optimizing the countermeasure sample through a genetic algorithm and gradient estimation to obtain an accurate countermeasure sample, mixing an original audio file and the countermeasure sample to serve as a training data set for countermeasure training, training a model, and improving the identification accuracy of the model on the countermeasure sample, so that the robustness of the model on the countermeasure attack is improved.","['G10L15/063', 'G06N3/086', 'G10L15/26', 'H04L9/002', 'G10L2015/0635']"
US11106903B1,Object detection in image data,Techniques are generally described for object detection in image data. A first frame of image data associated with a first domain is received by a detector executing on at least one computing device. The detector generates a first feature data in the first domain. The first feature data is transformed from the first domain into a second feature data in a second domain. The detector may be effective to detect objects in the second domain. A location of an object in the first frame of image data is determined based at least in part on the second feature data.,"['G06K9/00369', 'G06V20/64', 'G06F18/2132', 'G06F18/217', 'G06K9/4642', 'G06K9/4652', 'G06K9/6234', 'G06K9/6262', 'G06V10/143', 'G06V10/56', 'G06V10/82', 'G06V40/103', 'G06V10/58']"
US20200401835A1,Generating scene graphs from digital images using external knowledge and image reconstruction,"Methods, systems, and non-transitory computer readable storage media are disclosed for generating semantic scene graphs for digital images using an external knowledgebase for feature refinement. For example, the disclosed system can determine object proposals and subgraph proposals for a digital image to indicate candidate relationships between objects in the digital image. The disclosed system can then extract relationships from an external knowledgebase for refining features of the object proposals and the subgraph proposals. Additionally, the disclosed system can generate a semantic scene graph for the digital image based on the refined features of the object/subgraph proposals. Furthermore, the disclosed system can update/train a semantic scene graph generation network based on the generated semantic scene graph. The disclosed system can also reconstruct the image using object labels based on the refined features to further update/train the semantic scene graph generation network.","['G06K9/34', 'G06N5/022', 'G06F18/2413', 'G06F18/24323', 'G06K9/469', 'G06K9/6282', 'G06N3/042', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06V10/255', 'G06V10/426', 'G06V10/764', 'G06V10/82']"
US11598880B2,Detecting fault states of an aircraft,"An apparatus for detecting a fault state of an aircraft is provided. The apparatus accesses a training set of flight data for the aircraft. The training set includes observations of the flight data, each observation of the flight data includes measurements of properties selected and transformed into a set of features. The apparatus builds a generative adversarial network including a generative model and a discriminative model using the training set and the set of features, and builds an anomaly detection model to predict the fault state of the aircraft. The anomaly detection model is trained using the training set of flight data, simulated flight data generated by the generative model, and a subset of features from the set of features. The apparatus deploys the anomaly detection model to predict the fault state of the aircraft using additional observations of the flight data.","['G01S19/20', 'G05B23/024', 'G05B23/0221', 'G05B23/0224', 'G05B23/0243', 'B64D2045/0085', 'B64F5/60', 'G05B2219/2637']"
US11651526B2,Frontal face synthesis from low-resolution images,"An apparatus and corresponding method for frontal face synthesis. The apparatus comprises a decoder that synthesizes a high-resolution (HR) frontal-view (FV) image of a face from received features of a low-resolution (LR) non-frontal-view (NFV) image of the face. The HR FV image is of a higher resolution relative to a lower resolution of the LR NFV image. The decoder includes a main path and an auxiliary path. The auxiliary path produces auxiliary-path features from the received features and feeds the auxiliary-path features produced into the main path for synthesizing the HR FV image. The auxiliary-path features represent a HR NFV image of the face at the higher resolution. As such, an HR identity-preserved frontal face can be synthesized from one or many LR faces with various poses and may be used in types of commercial applications, such as video surveillance.","['G06T11/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V40/161', 'G06V40/168']"
US11429862B2,Dynamic adaptation of deep neural networks,"Techniques are disclosed for training a deep neural network (DNN) for reduced computational resource requirements. A computing system includes a memory for storing a set of weights of the DNN. The DNN includes a plurality of layers. For each layer of the plurality of layers, the set of weights includes weights of the layer and a set of bit precision values includes a bit precision value of the layer. The weights of the layer are represented in the memory using values having bit precisions equal to the bit precision value of the layer. The weights of the layer are associated with inputs to neurons of the layer. Additionally, the computing system includes processing circuitry for executing a machine learning system configured to train the DNN. Training the DNN comprises optimizing the set of weights and the set of bit precision values.","['G06N3/084', 'G06N3/006', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/065', 'G06N3/088', 'G06N3/09', 'G06N3/0985', 'G06N3/10', 'G06N3/048', 'G06N3/082', 'G06N5/045']"
US11061650B2,Methods and apparatus to automatically generate code for graphical user interfaces,Methods and apparatus to automatically generate code for graphical user interfaces are disclosed. An example apparatus includes a textual description analyzer to encode a user-provided textual description of a GUI design using a first neural network. The example apparatus further includes a DSL statement generator to generate a DSL statement with a second neural network. The DSL statement is to define a visual element of the GUI design. The DSL statement is generated based on at least one of the encoded textual description or a user-provided image representative of the GUI design. The example apparatus further includes a rendering tool to render a mockup of the GUI design based on the DSL statement.,"['G06F40/143', 'G06F40/00', 'G06F40/20', 'G06F8/10', 'G06F8/20', 'G06F8/38', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/168', 'G06F9/451', 'G06N5/04']"
CN109147010B,"Method, device and system for generating face image with attribute and readable storage medium","The invention discloses a face image generation method with attributes, which comprises the following steps: receiving a face feature description text and a partial occlusion image; inputting the descriptive text into a text encoder network to obtain a text encoding vector; carrying out channel cascade on the text coding vector and the partial shielding image to generate semantic feature data; inputting semantic feature data into a face image generation model to perform face feature restoration to obtain a face image with attributes; the face image generation model is a deep learning network obtained through training and optimizing according to a text data set and a training set image. The image generation method can generate a face image conforming to the attribute described by the text according to the text detail description. The invention also discloses a device, a system and a computer-readable storage medium for generating the face image with the attribute, which have the beneficial effects.","['G06T11/60', 'G06T2207/20081', 'G06T2207/30201', 'Y02T10/40']"
US11288546B2,Apparatus and method for training facial locality super resolution deep neural network,"Provided is an apparatus for training a facial-locality super resolution deep neural network, the apparatus including a generator configured to receive a low-resolution image and convert the received low-resolution image into a fake high-resolution image similar to an original high-resolution image, a discriminator configured to compare the fake high-resolution image output from the generator with the original high-resolution image to determine authenticity, and a facial-locality loss term configured to calculate a loss that is to be minimized by the generator according to the authenticity output from the discriminator, wherein the generator is an artificial neural network learning model that learns while adjusting a weight to minimize the loss, and the facial-locality loss term calculates the loss of the generator by reflecting pixel information about a feature region of a face.","['G06K9/6262', 'G06N3/084', 'G06F18/2148', 'G06F18/217', 'G06K9/6257', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06V40/16', 'G06V40/161', 'G06T2207/20084']"
US11562382B2,System and method for providing data science as a service,"The invention relates to a computer-implemented system and method for providing data science as a service (DSaaS) using a real time data prediction contest. Participants in the real time data prediction contest are permitted to execute and submit algorithms, utilize third party data sources, and utilize sub-contests to generate data predictions for the data prediction contest. The participants in the data prediction contest may be humans or software robots. A category of sponsor confidential information related to the data prediction is defined and maintained as confidential by the sponsor, while various methods are implemented to obtain relevant algorithms and data for the data prediction. The sponsor receives data predictions from the participants on a real time or near real time basis, calculates a score for the data predictions, and compensates participants according to their score.","['G06Q30/0202', 'G06F16/25', 'G06F17/11', 'G06N5/04', 'H04L65/403', 'H04L65/70']"
US11250252B2,Simulated handwriting image generator,"Techniques are provided for generating a digital image of simulated handwriting using an encoder-decoder neural network trained on images of natural handwriting samples. The simulated handwriting image can be generated based on a style of a handwriting sample and a variable length coded text input. The style represents visually distinctive characteristics of the handwriting sample, such as the shape, size, slope, and spacing of the letters, characters, or other markings in the handwriting sample. The resulting simulated handwriting image can include the text input rendered in the style of the handwriting sample. The distinctive visual appearance of the letters or words in the simulated handwriting image mimics the visual appearance of the letters or words in the handwriting sample image, whether the letters or words in the simulated handwriting image are the same as in the handwriting sample image or different from those in the handwriting sample image.","['G06F3/04883', 'G06K9/00416', 'G06K9/00859', 'G06K9/00879', 'G06K9/224', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/454', 'G06V10/82', 'G06V30/2264', 'G06V30/2276', 'G06V30/228', 'G06V30/347', 'G06N3/044', 'G06N3/048']"
US20220108177A1,"Concepts for federated learning, client classification and training data similarity measurement","A concept for Federated Learning which is more efficient and/or robust is presented. Beyond this, concepts for specifying clients and/or measuring training data similarities in a manner more suitable for being applied in Federated Learning environments, are described.","['G06N3/084', 'G06N3/08', 'G06N3/045', 'G06N3/098', 'G06N3/047']"
CN117009876B,Motion state quantity evaluation method based on artificial intelligence,"An artificial intelligence based exercise state quantity evaluation method belongs to the field of health data processing, and comprises the following steps: (1) The motion state quantity evaluation data are collected and then marked as five grades; (2) Data preprocessing, including missing value processing, data standardization, outlier processing and outlier detection; (3) training data augmentation; (4) Data feature extraction, including initialization, calculation loss and gradient, potential barrier establishment, calculation of tunnel loss probability, probability tunnel decision, interlayer information exchange, weight update and iteration; (5) Training a classifier, namely initializing honey sources, searching parameters, dynamically adjusting KELM learning rate, carrying out weight sparsification, and training a kernel extreme learning machine; and (6) estimating the motion state quantity. The method and the device enable the generated data to be closer to the actual application, and improve the generalization capability of the model; the problem of local optimization in the neural network training process is effectively avoided, and meanwhile, the accuracy and the robustness of the classifier are improved.","['G06F18/241', 'G06F18/214', 'G06N3/0475', 'G06N3/094', 'G16H50/30']"
US10621764B2,Colorizing vector graphic objects,"There is disclosed a system and method for colorizing vector graphic objects in a digital medium environment. The system comprises a processing unit and a deep neural network of the processing unit, in which the deep neural network includes a generator. The processing unit receives a non-colorized vector image and converts the non-colorized vector image to a non-colorized raster image. The deep neural network generates a colorized raster image from the non-colorized raster image. The generator processes the non-colorized raster image using an extended number of convolutional layers and residual blocks to add skip connections between at least two of the convolutional layers. The processing unit converts the colorized raster image to a colorized vector image.","['G06T11/40', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06T11/001', 'G06N3/048', 'G06T2207/20081']"
EP4425493A2,Compressing audio waveforms using neural networks and vector quantizers,"Methods, systems and apparatus, including computer programs encoded on computer storage media. One of the methods includes receiving an audio waveform that includes a respective audio sample for each of a plurality of time steps, processing the audio waveform using an encoder neural network to generate a plurality of feature vectors representing the audio waveform, generating a respective coded representation of each of the plurality of feature vectors using a plurality of vector quantizers that are each associated with a respective codebook of code vectors, wherein the respective coded representation of each feature vector identifies a plurality of code vectors, including a respective code vector from the codebook of each vector quantizer, that define a quantized representation of the feature vector, and generating a compressed representation of the audio waveform by compressing the respective coded representation of each of the plurality of feature vectors.","['G10L19/00', 'G10L19/038', 'G06N3/045', 'G06N3/08', 'G10L19/0017', 'G10L25/30', 'H03M7/3082', 'H03M7/6029', 'G10L2019/0002', 'G10L2019/0005']"
US11705226B2,Data based cancer research and treatment systems and methods,"A method and system for storing user application programs and micro-service programs, for each of multiple patients that have cancerous cells and receive treatment, includes obtaining clinical records data in original forms, storing it in a semi-structured first database, generating sequencing data for the patient's cancerous and normal cells using a next generation genomic sequencer, storing the sequencing data in the first database, shaping at least some of the first database data to generate system structured data optimized for searching and including clinical record data, storing the structured data in a second database, for each user application program, selecting an application-specific subset of data from the second database and storing it in a structure optimized for application program interfacing in a third database, wherein an orchestration manager operatively connected to one or more micro-service programs receives status messages and initiates a respective micro-service program when program prerequisites are satisfied.","['G16H10/40', 'G16H10/60', 'G16B20/00', 'G16B30/00', 'G16B40/00', 'G16B40/20', 'G16H15/00', 'G16H20/10', 'G16H20/40', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'G16B25/00', 'G16H30/40']"
US11222138B2,Privacy-preserving machine learning in the three-server model,"Methods and systems according to embodiments of the invention provide for a framework for privacy-preserving machine learning which can be used to obtain solutions for training linear regression, logistic regression and neural network models. Embodiments of the invention are in a three-server model, wherein data owners secret-share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Embodiments of the invention provide for efficient conversions between arithmetic, binary, and Yao 3PC, as well as techniques for fixed-point multiplication and truncation of shared decimal values. Embodiments also provide customized protocols for evaluating polynomial piecewise functions and a three-party oblivious transfer protocol.","['G06N3/082', 'A63B21/023', 'A63B21/0435', 'A63B21/222', 'A63B69/34', 'A63B71/023', 'G06F21/6245', 'G06N20/00', 'G06N3/063', 'G06N3/084', 'A63B2071/0063', 'A63B2071/026', 'A63B21/0552', 'A63B21/0628', 'A63B2225/093', 'A63B2244/10']"
US20220092216A1,Privacy-preserving machine learning in the three-server model,"Methods and systems according to embodiments of the invention provide for a framework for privacy-preserving machine learning which can be used to obtain solutions for training linear regression, logistic regression and neural network models. Embodiments of the invention are in a three-server model, wherein data owners secret-share their data among three servers who train and evaluate models on the joint data using three-party computation (3PC). Embodiments of the invention provide for efficient conversions between arithmetic, binary, and Yao 3PC, as well as techniques for fixed-point multiplication and truncation of shared decimal values. Embodiments also provide customized protocols for evaluating polynomial piecewise functions and a three-party oblivious transfer protocol.","['G06N3/084', 'G06F21/6245', 'G06N20/00', 'G06N3/063', 'H04L9/085', 'H04L2209/46']"
US20250217418A1,Enhanced searching using fine-tuned machine learning models,"An advanced search system leverages a pre-trained large language model to enhance user query responses. The system, equipped with hardware processors, a search query via an interface and accesses a pre-trained large language model designed to respond to the search query. The system fine-tunes the model to generate a task-specific generative model. The system employs the task-specific generative model to generate a search result to the search query and analyzes the search result based on a performance metric associated with the task-specific generative model. The system refines the task-specific generative model based on the analyzing of the search result.","['G06F16/24575', 'G06F16/248', 'G06F16/345', 'G06F16/90328', 'G06F16/93', 'G06F16/9538', 'G06F16/9558']"
US11651302B2,Method and device for generating synthetic training data for an artificial-intelligence machine for assisting with landing an aircraft,"A computer-implemented method for generating synthetic training data for an artificial-intelligence machine, the method includes at least steps of: defining parameters for at least one approach scenario of an aircraft approaching a runway; using the parameters of the at least one scenario in a flight simulator to generate simulated flight data, the flight simulator being configured to simulate the aircraft in the phase of approach toward the runway and to simulate an associated automatic pilot; using the simulated flight data to generate a plurality of ground-truth images, the ground-truth images corresponding to various visibility conditions; and generating, from each ground-truth image, a plurality of simulated sensor images.","['G06Q10/04', 'G05D1/0088', 'G05D1/101', 'G06F18/214', 'G06F18/217', 'G06F30/27', 'G06N20/00', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06Q50/40']"
WO2021179839A1,Method and apparatus for constructing user classification system for protecting user privacy,"Provided is a method for constructing a user classification system for protecting user privacy. The method comprises: first, inputting original user data that comprises original sensitive data into a feature encoder based on differential privacy, so as to obtain corresponding feature representations; then, inputting the feature representations into a user classifier, so as to obtain a classification result, and in conjunction with a classification label corresponding to the original user data, determining a first loss, which is used for training the user classifier; inputting the feature representations into a first decoder, so as to obtain restored sensitive data that simulates the original sensitive data; on the basis of the restored sensitive data and the original sensitive data, determining a second loss, and training the first decoder by means of taking the minimization of the second loss as a goal; next, training the feature encoder by means of taking the minimization of the first loss and the maximization of the second loss as goals; and finally, constructing the trained feature encoder and user classifier to form a user classification system.","['G06F21/6245', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06V10/30']"
US11193790B2,Method and system for detecting changes in road-layout information,"A method for detecting changes in road information includes converting a captured road image and a projected road-layout map into first intermediate data and second intermediate data of a same feature space, respectively, and calculating the similarity between the captured road image and the projected road-layout map based on the first intermediate data and the second intermediate data Thereafter, the presence or the absence of changes in road information on the projected road-layout map is detected based on the calculated similarity.","['G01C21/30', 'G01C21/3859', 'G01C21/3819', 'G01C11/04', 'G01C21/3667', 'G01C21/3815', 'G01C21/3874', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G08G1/0112', 'G08G1/0129', 'G08G1/04', 'G08G1/096716', 'G08G1/096844']"
US11455515B2,Efficient black box adversarial attacks exploiting input data structure,"Markov random field parameters are identified to use for covariance modeling of correlation between gradient terms of a loss function of the classifier. A subset of images are sampled, from a dataset of images, according to a normal distribution to estimate the gradient terms. Black-box gradient estimation is used to infer values of the parameters of the Markov random field according to the sampling. Fourier basis vectors are generated from the inferred values. An original image is perturbed using the Fourier basis vectors to obtain loss function values. An estimate of a gradient is obtained from the loss function values. An image perturbation is created using the estimated gradient. The image perturbation is added to an original input to generate a candidate adversarial input that maximizes loss in identifying the image by the classifier. The neural network classifier is queried to determine a classifier prediction for the candidate adversarial input.","['G06F18/241', 'G06N3/0454', 'G06N3/08', 'G06F18/295', 'G06N3/045', 'G06N3/0464', 'G06N7/01', 'G06T7/0002', 'G06V10/431', 'G06V10/764', 'G06V10/82', 'G06V10/85', 'G06T2207/20084']"
CN111386462B,Automatic noninvasive determination of fertility of poultry eggs,"There is shown herein a method of automatically noninvasively determining fertility of an avian egg (14), comprising the steps of: delivering a plurality of eggs (14) to an NMR apparatus (18) sequentially or in parallel; subjecting the avian eggs (14) to NMR measurements so as to generate a 3-D NMR image of at least a portion of each of the eggs (14), the 3-D NMR image having a spatial resolution of 1.0mm or less, preferably 0.50mm or less, in at least one dimension, wherein the portion of the avian eggs (14) comprises a blastoderm of the respective avian egg (14), the prediction of fertility being determined according to at least one of two procedures: (i) Deriving at least one feature from each of the 3-D NMR images and using the at least one feature in a feature-based classifier to determine a prediction of fertility, and (ii) using a deep learning algorithm, in particular a deep learning algorithm based on a convolutional neural network, a generative antagonism network, a recurrent neural network or a long-term short-term memory network.","['A01K43/04', 'G01N24/085', 'B07C5/344', 'G01N33/08', 'G01R33/307', 'G01R33/3415', 'G01R33/483', 'G01R33/4835', 'G01R33/5608', 'G01R33/561', 'G01R33/5611']"
US11631029B2,Generating combined feature embedding for minority class upsampling in training machine learning models with imbalanced samples,"Systems, methods, and non-transitory computer-readable media are disclosed for generating combined feature embeddings for minority class upsampling in training machine learning models with imbalanced training samples. For example, the disclosed systems can select training sample values from a set of training samples and a combination ratio value from a continuous probability distribution. Additionally, the disclosed systems can generate a combined synthetic training sample value by modifying the selected training sample values using the combination ratio value and combining the modified training sample values. Moreover, the disclosed systems can generate a combined synthetic ground truth label based on the combination ratio value. In addition, the disclosed systems can utilize the combined synthetic training sample value and the combined synthetic ground truth label to generate a combined synthetic training sample and utilize the combined synthetic training sample to train a machine learning model.","['G06N20/00', 'G06N3/084', 'G06N5/04']"
US10880299B2,Machine learning for document authentication,"Computer systems and methods are provided for using a machine learning system to analyze authentication information. First authentication information for a first transaction includes at least a first image that corresponds to a first identification document is received. First validation information that corresponds to a first validation fault is received from a validation system. Data storage of a machine learning system stores the first validation information. Second authentication information for a second transaction includes a second image that corresponds to a second image is received. The machine learning system determines a first validation value that corresponds to a probability that the second image includes the first validation fault. The first validation value is used to determine whether fault review criteria are met. In accordance with a determination that the fault review criteria are met, the second image is transmitted to the validation system.","['G06V30/40', 'G06K9/00483', 'G06N20/00', 'G06V30/19133', 'G06V30/418', 'H04L63/0861']"
US12008591B2,Machine learning based user targeting,"Apparatuses, methods, program products, and systems are disclosed for machine learning based user targeting. An apparatus includes one or more memory devices in communication with one or more processing devices. An apparatus includes a subject module that receives subject data associated with a subject. Subject data includes data that describes a subject. An apparatus includes an affinity module that determines, using a machine learning model, an affinity level of each of one or more entities in relation to a subject. Subject data is provided as input to a machine learning model. An apparatus includes a campaign module that generates one or more promotional campaign strategies for a subject based at least in part on an affinity level of each of one or more entities in relation to a subject. One or more promotional campaign strategies target a subject to one or more entities.","['G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06Q30/0201', 'G06Q30/0204', 'G06Q30/0276', 'G06N3/044']"
US11880943B2,Photogrammetry of building using machine learning based inference,"The data set receiving unit 13 of the information processing apparatus 1 of an aspect example receives a data set that includes at least BIM data. The route setting processor 151 sets a route, which is arranged inside and/or outside a virtual building represented by the BIM data, based on the data set received. The virtual image set generating processor 152 generates a virtual image set of the virtual building along the route, based on the received data set and the set route. The inference model creating processor 153 creates an inference model by applying machine learning with training data that includes at least the generated virtual image set to a neural network. The inference model created is used to identify data of a building material from data acquired by measuring a building.","['G06T19/003', 'G06F18/214', 'G06T2210/04']"
US11544411B2,Machine learning model validation and authentication,"The present disclosure is directed to methods and apparatus for validating and authenticating use of machine learning models. For example, various techniques are described herein to limit the vulnerability of machine learning models to attack and/or exploitation of the model for malicious use, and for detecting when such attack/exploitation has occurred. Additionally, various embodiments described herein promote the protection of sensitive and/or valuable data, for example by ensuring only licensed use is permissible. Moreover, techniques are described for version tracking, usage tracking, permission tracking, and evolution of machine learning models.","['G06N3/08', 'G06F21/64', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/082', 'G06N3/044', 'G06N3/047']"
US10397266B1,Verifying that the influence of a user data point has been removed from a machine learning classifier,"Verifying that influence of a user data point has been removed from a machine learning classifier. In some embodiments, a method may include training a machine learning classifier using a training set of data points that includes a user data point, calculating a first loss of the machine learning classifier, updating the machine learning classifier by updating parameters of the machine learning classifier to remove influence of the user data point, calculating a second loss of the machine learning classifier, calculating an expected difference in loss of the machine learning classifier, and verifying that the influence of the user data point has been removed from the machine learning classifier by determining that the difference between the first loss and the second loss is within a threshold of the expected difference in loss.","['H04L63/1433', 'G06F21/577', 'G06F21/6245', 'G06F21/6254', 'G06N20/00', 'G06N20/10', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06F2221/033', 'G06N5/048']"
US10867404B2,Distance estimation using machine learning,"A method receives a captured image depicting image content including an object, the captured image being captured by an image sensor located at a sensor position; generates, using a trained first machine learning logic, a lighting-corrected image from an imitative simulation image depicting at least a portion of the image content of the captured image in a simulation style associated with an environment simulator; generates, using a trained second machine learning logic, a depth estimation image from the lighting-corrected image, the depth estimation image indicating a relative distance between the object depicted in the captured image and the sensor position of the image sensor; and determines an object position of the object depicted in the captured image based on the depth estimation image.","['G06T5/94', 'G06F18/217', 'G06F18/2413', 'G06K9/00791', 'G06K9/6262', 'G06T5/008', 'G06T5/60', 'G06T7/50', 'G06T7/74', 'G06V10/764', 'G06V10/82', 'G06V20/54', 'G06V20/56', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30256', 'G06T2207/30261']"
US11423282B2,Autoencoder-based generative adversarial networks for text generation,"In accordance to embodiments, an encoder neural network is configured to receive a one-hot representation of a real text and output a latent representation of the real text generated from the one-hot representation of the real text. A decoder neural network is configured to receive the latent representation of the real text, and output a reconstructed softmax representation of the real text from the latent representation of the real text, the reconstructed softmax representation of the real text is a soft-text. A generator neural network is configured to generate artificial text based on random noise data. A discriminator neural network is configured to receive the soft-text and receive a softmax representation of the artificial text, and output a probability indicating whether the softmax representation of the artificial text received by the discriminator neural network is not from the generator neural network.","['G06N3/02', 'G06N3/088', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N7/005', 'G06N7/01']"
US11354602B2,System and methods to mitigate poisoning attacks within machine learning systems,Embodiments of the present invention provide a system and methods to mitigate poisoning attacks within machine learning systems. The invention includes an improved data analysis approach to train an ensemble of machine learning models to analyze received data and label the data in a non-binary fashion to indicate likelihood that certain data has been injected abnormally and should not be used for training purposes. The resulting dataset from the ensemble is assessed to determine convergence of model labeling and to detect outlier data labeling among models in the ensemble. Confidence scores for clustered interaction data may be performed on varied sets of training data populations and using a number of models. Output from the various training/model mixes are fed to a machine learning model to compare ensemble accuracy between different model sets and select the most accurate ensemble combination.,"['G06F21/554', 'G06N20/20', 'G06F21/562', 'H04L61/1511', 'H04L61/4511', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1466']"
US12347419B2,Unsupervised federated learning of machine learning model layers,"Implementations disclosed herein are directed to unsupervised federated training of global machine learning (“ML”) model layers that, after the federated training, can be combined with additional layer(s), thereby resulting in a combined ML model. Processor(s) can: detect audio data that captures a spoken utterance of a user of a client device; process, using a local ML model, the audio data to generate predicted output(s); generate, using unsupervised learning locally at the client device, a gradient based on the predicted output(s); transmit the gradient to a remote system; update weight(s) of the global ML model layers based on the gradient; subsequent to updating the weight(s), train, using supervised learning remotely at the remote system, a combined ML model that includes the updated global ML model layers and additional layer(s); transmit the combined ML model to the client device; and use the combined ML model to make prediction(s) at the client device.","['G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G10L15/063', 'G10L15/16', 'G10L15/187', 'G10L15/22', 'G10L15/30', 'G10L2015/0635']"
US11651497B2,InSeGAN: a generative approach to instance segmentation in depth images,"System and method for generating verisimilar images from real depth images. Train a generative adversarial neural network (GAN) by accessing test depth images having identical instances as instances of a real depth image. Input the test depth images in the generator to generate estimated depth images representing an implicit three-dimensional model of the object. Input, each estimated depth image into a discriminator to obtain a loss and into a pose encoder to obtain a matching loss. Iteratively repeat processes until the losses are minimized to a threshold, to end training. Identify the instances in the real image using the trained GAN pose encoder, to produce a pose transformation matrix for each instance in the real image. Identify pixels in the depth images corresponding to the instances of the real image and merge the pixels for the depth images to form an instance segmentation map for the real depth image.","['G06T7/11', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/094', 'G06T7/50', 'G06T7/75', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30128']"
US20240303487A1,Multimodal machine learning model for data including examples with missing modalities,"Multimodal training data comprising samples of a prediction target is received. Each sample includes at least a subset of the full set of a plurality of modalities, and the samples collectively include instances of each modality. An attention-based encoder receives sets of training vectors for the samples in fixed-dimensional input vector format, and generates a fixed-dimensional vector representation template for the prediction target. The number of dimensions in the template is constant and is independent of the number of modalities represented by the training vectors. The attention-based encoder uses the samples and the fixed-dimensional vector representation template to generate, from the training vectors for the samples, a latent distribution. The samples in fixed-dimensional input vector format and the latent distribution are used as input to a second attention-based neural network to generate an attention-based decoder that can predict from samples with missing modalities.","['G06N3/0455', 'G06N3/045', 'G06N3/08']"
US20220083068A1,Detection of hazardous driving using machine learning,"An autonomous driving system could create or exacerbate a hazardous driving situation due to incorrect machine learning, algorithm design, sensor limitations, environmental conditions or other factors. This technology presents solutions that use machine learning to detect when the autonomous driving system is in this state e.g., erratic or reckless driving and other behavior, in order to take remedial action to prevent a hazard such as a collision.","['G05D1/0221', 'G06V10/82', 'G05D1/0088', 'G05D1/0214', 'G06F18/24133', 'G06K9/00791', 'G06K9/6271', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/764', 'G06V20/56', 'G05D2201/0213']"
US11537506B1,System for visually diagnosing machine learning models,"Computer systems and associated methods are disclosed to implement a model development environment (MDE) that allows a team of users to perform iterative model experiments to develop machine learning (ML) media models. In embodiments, the MDE implements a media data management interface that allows users to annotate and manage training data for models. In embodiments, the MDE implements a model experimentation interface that allows users to configure and run model experiments, which include a training run and a test run of a model. In embodiments, the MDE implements a model diagnosis interface that displays the model's performance metrics and allows users to visually inspect media samples that were used during the model experiment to determine corrective actions to improve model performance for later iterations of experiments. In embodiments, the MDE allows different types of users to collaborate on a series of model experiments to build an optimal media model.","['G06V10/776', 'G06F11/366', 'G06F11/1476', 'G06F11/34', 'G06F11/3495', 'G06F11/3664', 'G06F11/3698', 'G06F18/2431', 'G06F18/40', 'G06K9/628', 'G06N20/00', 'G06N3/091', 'G06N3/0985', 'G06N3/10', 'G06N20/10', 'G06N20/20', 'G06N3/0464', 'G06N3/094', 'G06N5/01']"
US10719301B1,Development environment for machine learning media models,"Computer systems and associated methods are disclosed to implement a model development environment (MDE) that allows a team of users to perform iterative model experiments to develop machine learning (ML) media models. In embodiments, the MDE implements a media data management interface that allows users to annotate and manage training data for models. In embodiments, the MDE implements a model experimentation interface that allows users to configure and run model experiments, which include a training run and a test run of a model. In embodiments, the MDE implements a model diagnosis interface that displays the model's performance metrics and allows users to visually inspect media samples that were used during the model experiment to determine corrective actions to improve model performance for later iterations of experiments. In embodiments, the MDE allows different types of users to collaborate on a series of model experiments to build an optimal media model.","['G06F8/33', 'G06F11/3688', 'G06F18/23213', 'G06F18/24', 'G06F18/40', 'G06F8/34', 'G06K9/6223', 'G06K9/6267', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/0985', 'G06N5/04', 'G06V10/774', 'G06V10/7784', 'G06V10/7788', 'G06F11/3447', 'G06N20/00']"
US12182227B2,User interface for visual diagnosis of image misclassification by machine learning,"Computer systems and associated methods are disclosed to implement a model development environment (MDE) that allows a team of users to perform iterative model experiments to develop machine learning (ML) media models. In embodiments, the MDE implements a media data management interface that allows users to annotate and manage training data for models. In embodiments, the MDE implements a model experimentation interface that allows users to configure and run model experiments, which include a training run and a test run of a model. In embodiments, the MDE implements a model diagnosis interface that displays the model's performance metrics and allows users to visually inspect media samples that were used during the model experiment to determine corrective actions to improve model performance for later iterations of experiments. In embodiments, the MDE allows different types of users to collaborate on a series of model experiments to build an optimal media model.","['G06F18/2178', 'G06F16/58', 'G06F18/23213', 'G06F18/24', 'G06N20/00', 'G06N3/08', 'G06N5/04', 'G06V10/70']"
US11657269B2,Systems and methods for verification of discriminative models,"Verification of discriminative models includes receiving an input; receiving a prediction from a discriminative model for the input; encoding, using an encoder, a latent variable based on the input; decoding, using a decoder, a reconstructed input based on the prediction and the latent variable; and determining, using an anomaly detection module, whether the prediction is reliable based on the input, the reconstructed input, and the latent variable. The encoder and the decoder are jointly trained to maximize an evidence lower bound of the encoder and the decoder. In some embodiments, the encoder and the decoder are further trained using a disentanglement constraint between the prediction and the latent variable. In some embodiments, the encoder and the decoder are further trained without using inputs that are out of a distribution of inputs used to train the discriminative model or that are adversarial to the discriminative model.","['G06N3/08', 'G06N3/088', 'G06F17/18', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'H03M7/6005', 'H03M7/6011', 'G06N3/084', 'H03M7/3059', 'H03M7/3071']"
WO2020209591A1,Novelty detection using deep learning neural network,"The disclosed technology generally relates to novelty detection and more particularly to novelty detection methods, apparatuses, and non-transitory computer-readable media. In one aspect, a method comprises: generating a first intermediate encoded input from one of encoder layers prior to generating a first encoded input by feeding a first input comprising a sensor data into an encoder; generating a second intermediate encoded input from one of the encoder layers by feeding a first reconstructed output as a second input into the encoder; and computing a novelty score of the first input using the first intermediate encoded input and the second intermediate encoded input.","['G06N3/082', 'G06N3/088', 'G06F18/2411', 'G06N3/045', 'G06N3/047']"
CN110490802B,Super-resolution-based satellite image airplane target model identification method,"The invention discloses a satellite image airplane target model identification method based on super-resolution, which comprises the following steps: performing super-resolution reconstruction on the acquired satellite image to obtain a super-resolution reconstruction image; performing regional screening network processing on the super-resolution reconstructed image to obtain a candidate frame image; inputting the candidate frame images into a pre-trained super-resolution reconstruction target recognition network for target recognition to obtain a target recognition result; the super-resolution reconstruction target recognition network is obtained by alternately training a super-resolution countermeasure generation network and a classification recognition network and continuously optimizing by using an incremental learning method. The super-resolution countermeasure generation network and the classification recognition network are alternately trained, and the incremental learning thought is utilized to continuously optimize the recognition model, so that the target recognition network with strong generalization capability is obtained, and the application range and the recognition accuracy of the recognition network are improved.","['G06F18/241', 'G06T3/4053', 'G06V20/13']"
US20240375682A1,Method of making highly humanoid safe driving decision for automated driving commercial vehicle,"A method of making a highly humanoid safe driving decision for an automated driving commercial vehicle, includes: collecting synchronously multi-source information on driving behaviors in typical traffic scenarios, constructing an expert trajectory data set representing driving behaviors of excellent drivers; simulating the driving behaviors of excellent drivers by utilizing a generative adversarial imitation learning (GAIL) algorithm, in a comprehensive consideration of influences of factors such as a forward collision, a backward collision, a transverse collision, a vehicle roll stability and a driving smoothness on a driving safety, constructing a generator and a discriminator by utilizing a proximal policy optimization algorithm and a deep neural network respectively, and establishing a safe driving decision-making model with highly humanoid level; and training the safe driving decision-making model to obtain safe driving policies under different driving conditions and to implement an output of an advanced decision-making for the automated driving commercial vehicle.","['B60W60/0015', 'B60W50/0098', 'G06F30/27', 'G06N3/08', 'B60W2050/0088', 'B60W2540/30', 'B60W2556/05']"
US12293284B2,Meta cooperative training paradigms,"Generative adversarial models have several benefits; however, due to mode collapse, these generators face a quality-diversity trade-off (i.e., the generator models sacrifice generation diversity for increased generation quality). Presented herein are embodiments that improve the performance of adversarial content generation by decelerating mode collapse. In one or more embodiments, a cooperative training paradigm is employed where a second model is cooperatively trained with the generator and helps efficiently shape the data distribution of the generator against mode collapse. Moreover, embodiments of a meta learning mechanism may be used, where the cooperative update to the generator serves as a high-level meta task and which helps ensures the generator parameters after the adversarial update stay resistant against mode collapse. In experiments, tested employments demonstrated efficient slowdown of mode collapse for the adversarial text generators. Overall, embodiments outperformed the baseline approaches with significant margins in terms of both generation quality and diversity.","['G06N3/088', 'G06N3/08', 'G06N3/0442', 'G06N3/045', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/0985']"
US10733292B2,Defending against model inversion attacks on neural networks,"Mechanisms are provided for protecting a neural network model against model inversion attacks. The mechanisms generate a decoy dataset comprising decoy data for each class recognized by a neural network model. The mechanisms further configure the neural network model to generate a modified output based on the decoy dataset that directs a gradient of the modified output to the decoy dataset. The neural network model receives and process input data to generate an actual output. The neural network model modifies one or more actual elements of the actual output to be one or more corresponding modified elements of the modified output, and returns the one or more corresponding modified elements, instead of the one or more actual elements, to the source computing device.","['G06F21/554', 'G06F21/57', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04L63/1491', 'G06F2221/034']"
TWI772805B,"Method for training generative adversarial network, method for generating image, and computer-readable storage medium","The invention provides a method for training a generative adversarial network (GAN), a method for generating an image by using the GAN, and a computer-readable storage medium. The method can use the available training samples belonging to the first type category to train the first generator of the GAN, and share the knowledge learned by the first generator to the second generator. Therefore, even if no training data is available during training the second generator, the second generator can still learn to generate (fake) images belonging to the second type category.","['G06N3/088', 'G06N3/045', 'G06F17/18', 'G06F18/24', 'G06F18/2413', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/60', 'G06T7/90', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN109615582B,A Face Image Super-resolution Reconstruction Method Based on Attribute Description Generative Adversarial Network,"A super-resolution reconstruction method for generating face images of an countermeasure network based on attribute description belongs to the field of digital image/video signal processing. The method is characterized in that: training phase: the method comprises three parts of training sample preparation, network structure design and network training; the network structure design adopts a generating countermeasure network frame, and consists of a generating network and a judging network; the generating network comprises a face attribute encoding and decoding module and a super-resolution reconstruction module; the judging network comprises an attribute classifying module, a countermeasure module and a perception module; the network training process is carried out by adopting a mode of generating a network for generating an countermeasure network frame and judging the alternate countermeasure training of the network; reconstruction stage: LR face images and attribute description information are used as input, and image coding, attribute adding, image decoding and image reconstruction are realized through a trained generation network. The technology of the invention not only can complete the enhancement of the facial information of the low-resolution facial image, but also can improve the accuracy of the low-resolution facial recognition.","['G06V40/161', 'G06N3/045', 'G06N3/08', 'G06T11/00', 'G06T3/4053', 'G06V40/168', 'Y02T10/40']"
US20230359903A1,Mitigation for Prompt Injection in A.I. Models Capable of Accepting Text Input,"A system for use with an artificial intelligence (AI) model configured to accept text input, such as generative pre-trained transformer (GPT), that detects and tags trusted instructions and nontrusted instructions of an input provided by a user responsive to an AI model prompt. The system uses reinforcement learning (RL) and a set of rules to remove the untrusted instructions from the input and provide only trusted instructions to the AI model. The input is represented as tokens, wherein the trusted instructions and the untrusted instructions are represented using incompatible token sets.","['G06N3/0475', 'G06N3/092', 'G06F40/279', 'G06F40/30', 'G06F40/40', 'G06N3/0455', 'G06N3/091']"
US20200356675A1,Systems and methods for predicting which software vulnerabilities will be exploited by malicious hackers to prioritize for patching,Various embodiments for predicting which software vulnerabilities will be exploited by malicious hackers and hence prioritized by patching are disclosed.,"['G06F11/00', 'G06F11/008', 'G06F12/16', 'G06F18/2148', 'G06F18/24', 'G06F21/54', 'G06F21/552', 'G06F21/577', 'G06K9/6257', 'G06K9/6267']"
US11514925B2,Using a predictive model to automatically enhance audio having various audio quality issues,"Operations of a method include receiving a request to enhance a new source audio. Responsive to the request, the new source audio is input into a prediction model that was previously trained. Training the prediction model includes providing a generative adversarial network including the prediction model and a discriminator. Training data is obtained including tuples of source audios and target audios, each tuple including a source audio and a corresponding target audio. During training, the prediction model generates predicted audios based on the source audios. Training further includes applying a loss function to the predicted audios and the target audios, where the loss function incorporates a combination of a spectrogram loss and an adversarial loss. The prediction model is updated to optimize that loss function. After training, based on the new source audio, the prediction model generates a new predicted audio as an enhanced version of the new source audio.","['G10L21/02', 'G10L21/0364', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G10L25/18', 'G10L25/30', 'G10L2021/02082', 'G10L21/0208']"
EP3889836A1,"Image description information generation method and device, and electronic device","An image description information generation method and device, and an electronic device. The method comprises: acquiring a target image to be processed (S202); inputting the target image to a target-image description information generation network, wherein the target-image description information generation network is acquired after adversarial training is performed by using multiple sample images, and is for generating image description information (S204), the adversarial training being performed alternately on an initialized image description information generation network and an initialized determination network, the determination network being used to determine an output result of an image description information generation network; and generating, according to an output result of the target-image description information generation network, target-image description information used to describe the target image (S206). The method solves the technical problem of poor quality of information generated by an image description information generation method provided in the prior art.","['G06N3/088', 'G06F18/2132', 'G06F18/214', 'G06F18/22', 'G06F18/24', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06N3/006', 'Y02T10/40']"
US11875488B2,Method and device for parallel processing of retinal images,A method for parallel processing of retinal images includes: optimizing an objective function with a chaotic supply-demand algorithm to enhance a real retinal image; synthesizing a virtual retinal image by a hybrid image generation method; establishing a parallel multi-layer decomposed interval type-2 intuitionistic fuzzy convolutional neural network model based on the virtual retinal image and the enhanced real retinal image; and integrating outputs from a plurality of parallel multi-layer decomposed interval type-2 intuitionistic fuzzy convolutional neural network models as a final classification result.,"['G06F18/24', 'G06N3/08', 'G06T5/50', 'G06F18/214', 'G06N3/006', 'G06N3/043', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T3/60', 'G06V10/82', 'G06V20/20', 'G06V40/18', 'G06T2207/20084', 'G06T2207/30041', 'Y02T10/40']"
US12254064B2,"Image generation method, neural network compression method, and related apparatus and device","The present application discloses an image generation method, a neural network compression method, and a related apparatus and device in the field of artificial intelligence. The image generation method includes: inputting a first matrix into an initial image generator to obtain a generated image; inputting the generated image into a preset discriminator to obtain a determining result, where the preset discriminator is obtained through training based on a real image and a category corresponding to the real image; updating the initial image generator based on the determining result to obtain a target image generator; and further inputting a second matrix into the target image generator to obtain a sample image. Further, a neural network compression method is disclosed, to compress the preset discriminator based on the sample image obtained by using the foregoing image generation method.","['G06F18/2148', 'G06F18/243', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/088', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V30/19', 'G06V40/16', 'G06V40/174', 'G06V40/178', 'G06N3/048']"
CN108875935B,Natural image target material visual characteristic mapping method based on generation countermeasure network,"The invention provides a natural image target material visual characteristic mapping method based on a generation countermeasure network, which is characterized in that a deep unsupervised learning mode is used for learning the material visual characteristics of an unmarked natural image target to obtain high-order expression of an image target material visual characteristic space, a mapping network related to the material visual characteristic space between a source domain image and a target domain image is learned and established, the material visual characteristics of the source domain image are mapped to the material visual characteristics of a target domain, so that the target domain image has the material visual characteristic information of the source domain image, and finally, an image after the material visual characteristic mapping is obtained. The invention provides a task target for obtaining material visual characteristic information from a natural image without annotation and mapping the material visual characteristic between different images, and provides a corresponding solution for the task target, thereby obtaining a good result and having important theoretical significance and practical value.","['G06N3/088', 'G06N3/045', 'G06T7/194', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084']"
CN109190684B,SAR image sample generation method based on sketch and structure generative adversarial network,"The invention provides an SAR image sample generation method based on a sketch and structure generation countermeasure network, which mainly solves the problem of sample imbalance in SAR image semantic segmentation, and comprises the following implementation steps: (1) the SAR image is subjected to sketch to obtain a sketch map; (2) extracting a small extremely inhomogeneous region according to a regional map of the SAR image; (3) constructing a paired data set in the shape of a sketch block-SAR image block; (4) selecting samples in the data set to form a training set and a testing set; (5) constructing a generation countermeasure network based on sketch information and structural constraints; (6) alternately training the sketch fitting network, the judging network and the generating network in sequence through sketch line loss, confrontation loss and generator loss; (7) inputting a test sketch block to a trained generation network to obtain a generated SAR image block; the SAR image sample inosculated with the ground object structure of the original SAR image can be generated according to the sketch map, and the problem of sample imbalance of classification of extremely uneven regions of the SAR image can be solved.","['G06F18/214', 'G06N3/045']"
US11580646B2,Medical image segmentation method based on U-Net,"A medical image segmentation method based on a U-Net, including: sending real segmentation image and original image to a generative adversarial network for data enhancement to generate a composite image with a label; then putting the composite image into original data set to obtain an expanded data set, and sending the expanded data set to improved multi-feature fusion segmentation network for training. A Dilated Convolution Module is added between the shallow and deep feature skip connections of the segmentation network to obtain receptive fields with different sizes, which enhances the fusion of detail information and deep semantics, improves the adaptability to the size of the segmentation target, and improves the medical image segmentation accuracy. The over-fitting problem that occurs when training the segmentation network is alleviated by using the expanded data set of the generative adversarial network.","['G06T7/11', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/40', 'G16H30/40', 'G06N3/048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/30004', 'G06T2207/30101']"
AU2021399965B2,Explainable transducer transformers,"An explainable transducer transformer (XTT) may be a finite state transducer, together with an Explainable Transformer. Variants of the XTT may include an explainable Transformer-Encoder and an explainable Transformer-Decoder. An exemplary Explainable Transducer may be used as a partial replacement in trained Explainable Neural Network (XNN) architectures or logically equivalent architectures. An Explainable Transformer may replace black-box model components of a Transformer with white-box model equivalents, in both the sub-layers of the encoder and decoder layers of the Transformer. XTTs may utilize an Explanation and Interpretation Generation System (EIGS), to generate explanations and filter such explanations to produce an interpretation of the answer, explanation, and its justification.","['G06N3/065', 'G06F40/40', 'G06N3/04', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/049', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/086', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06N3/10', 'G06N5/01', 'G06N5/025', 'G06N5/042', 'G06N5/045', 'G06N3/047', 'G06N5/022']"
US12361221B2,Grammar transfer using one or more neural networks,"Apparatuses, systems, and techniques to transfer grammar between sentences. In at least one embodiment, one or more first sentences are translated into one or more second sentences having different grammar using one or more neural networks.","['G06F40/30', 'G06F18/241', 'G06F40/253', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G10L15/063', 'G10L15/16', 'G10L15/1815', 'G10L15/22', 'G06N20/10', 'G06N3/02', 'G06N3/044', 'G06N3/047', 'G06N3/088']"
US20210049441A1,Method of news evaluation in social media networks,"A method of news evaluation in social media networks having a plurality of socially related users, the method comprising the steps of determining a social graph at least with respect to users and their social relations; determining a news message to be evaluated; determining a propagation behaviour of the news message in the social graph; evaluating the news message in view of its determined propagation behaviour in the social graph.","['G06F17/11', 'G06F16/9024', 'G06F17/16', 'G06F17/18', 'G06F18/20', 'G06N3/04', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N5/022', 'G06Q50/01', 'G06N3/126']"
US20230352164A1,Method for generating prediction result for predicting occurrence of fatal symptoms of subject in advance and device using same,"The present invention relates to a method for generating a prediction result for predicting an occurrence of fatal symptoms of a subject in advance, a method for performing data classification by using data augmentation in mechanical learning for the same, and a computing device using the same. Particularly, the computing device according to the present invention acquires vital signs of the subject, converts the same into individuated data, generates analysis information from the individuated data on the basis of a machine learning model, generates a prediction result by referring to the analysis information, and provides the prediction result to an external entity.","['G16H40/63', 'A61B5/00', 'G06F18/217', 'G06F18/241', 'G06F18/2413', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G16H50/20', 'G16H50/30', 'G06F2218/12', 'G06N3/048']"
US12166777B2,Method and system for analyzing cybersecurity threats and improving defensive intelligence,"Disclosed is a cyber threat intelligence platform configured to: a) designate a virtual machine as an attacker machine; b) designate a virtual machine as a victim machine; c) receive cyberattack data representative of a cyberattack executed by the attacker machine against the victim machine; e) receive defense action data representative of a defense action executed by the victim machine against the cyberattack; f) mark a first point in time when the cyberattack is executed, and mark a second point in time when the defense action is initiated; g) compare the first point in time with the second point in time to ascertain an attack-defense time lapse as a performance measure for computer system threat management of cyberattacks or defense actions, and h) view or analyze cyberattack and defense actions for effectiveness, including perspectives derived from the relative timing of the actions as indicated on the time lapse.","['G06F21/57', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06F21/577', 'G06F3/0482', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'H04L63/14', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/145', 'H04L63/1458', 'H04L63/1466', 'H04L63/1483', 'H04L63/20', 'G06F2221/034', 'G06N7/01']"
US20210241120A1,Systems and methods for identifying synthetic identities,"Systems and methods are provided for implementing machine learning techniques to distinguish a real identity, such as a set of identity information representing a real person, from a synthetic identity that may include portions of real identity information. Attributes regarding a target identity derived from a variety of retrieved data records may be provided as input to multiple machine learning models that generate scores associated with the potential of the target identity being synthetic. The scores may be combined and compared to a threshold to generate a determination of whether the target identity is a synthetic identity.","['G06F16/906', 'A61L29/06', 'A61L29/106', 'A61L29/16', 'G06F16/9035', 'G06F21/31', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06Q30/0185', 'G06Q30/0609', 'G06Q40/02', 'A61L2300/102', 'A61L2300/104', 'A61L2300/404', 'G06F2221/2133', 'G06N20/10', 'G06N7/01']"
US10652565B1,Image compression and decompression using embeddings,"A processing device receives a representation of an image, wherein the image has a first size and the representation has a second size that is smaller than the first size, the representation having been generated from the image by a first portion of a first trained machine learning model. The processing device processes the representation of the image using a second portion of the trained machine learning model to generate a reconstruction of the image and then outputs the reconstruction of the image.","['H04N19/463', 'G06N3/088', 'G06K9/6232', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06T9/002', 'G06V10/764', 'G06V10/82', 'H04N19/115', 'G06N7/01']"
US20230289604A1,Systems and methods for securing artificial intelligence systems for edge computing systems,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media that support security-aware compression of machine learning (ML) and/or artificial intelligence (AI) models, such as for use by edge computing systems. Aspects described herein leverage cybersecurity threat models, particularly models of ML/AI-based threats, during iterative pruning to improve security of compressed ML models. To illustrate, iterative pruning may be performed on a pre-trained ML model until stop criteria are satisfied. This iterative pruning may include pruning an input ML model based on pruning heuristic(s) to generate a candidate ML model, testing the candidate ML model based on attack model(s) to generate risk assessment metrics, and updating the heuristic(s) based on the risk assessment metrics. If the risk assessment metrics fail to satisfy the stop criteria, the candidate ML model may be provided as input to a next iteration of the iterative pruning.","['G06F21/577', 'G06N3/0495', 'G06N3/082', 'G06N3/094', 'H04L63/08', 'G06N3/048']"
US12254964B2,Quantum circuit based system configured to model physical or chemical systems,"There is provided a quantum circuit based system configured to model infinite-size systems, in which one or more quantum circuits are configured as an infinite tensor network representation of quantum states of effectively infinite physical or chemical systems.","['G16C10/00', 'G06N10/00', 'G06N10/20', 'G06N10/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N5/01', 'G16C20/30', 'G16C20/70', 'G06N3/044', 'G06N3/084', 'G06N3/088', 'G06N7/01']"
US11468350B2,"Behavioral prediction and boundary settings, control and safety assurance of ML and AI systems","Typical autonomous systems implement black-box models for tasks such as motion detection and triaging failure events, and as a result are unable to provide an explanation for its input features. An explainable framework may utilize one or more explainable white-box architectures. Explainable models allow for a new set of capabilities in industrial, commercial, and non-commercial applications, such as behavioral prediction and boundary settings, and therefore may provide additional safety mechanisms to be a part of the control loop of automated machinery, apparatus, and systems. An embodiment may provide a practical solution for the safe operation of automated machinery and systems based on the anticipation and prediction of consequences. The ability to guarantee a safe mode of operation in an autonomous system which may include machinery and robots which interact with human beings is a major unresolved problem which may be solved by an exemplary explainable framework.","['G06N5/045', 'G06N20/00', 'G06N5/01', 'G06N5/048']"
US11948594B2,Automated conversation content items from natural language,"A conversation augmentation system can automatically augment a conversation with content items based on natural language from the conversation. The conversation augmentation system can select content items to add to the conversation based on determined user “intents” generated using machine learning models. The conversation augmentation system can generate intents for natural language from various sources, such as video chats, audio conversations, textual conversations, virtual reality environments, etc. The conversation augmentation system can identify constraints for mapping the intents to content items or context signals for selecting appropriate content items. In various implementations, the conversation augmentation system can add selected content items to a storyline the conversation describes or can augment a platform in which an unstructured conversation is occurring.","['G10L15/183', 'G10L21/10', 'G06N20/00', 'G06Q30/0251', 'G06Q30/0282', 'G06Q30/0631', 'G06Q30/0639', 'G10L15/197', 'G10L15/26', 'H04M11/025', 'H04M11/10', 'G06Q50/00', 'G06Q50/01', 'G10L2015/228']"
US11887288B2,"Image processing apparatus, image processing method, and storage medium","An image processing apparatus includes display control means for displaying, on display means, a blend image obtained by performing blend processing at a variable transmissivity in accordance with an instruction of an operator using an optical coherence tomography (OCT) image and an OCT angiography (OCTA) image of mutually corresponding regions in a subject that are acquired by an OCT, setting means for setting a region of interest in the displayed blend image, and execution means for executing processing on the set region of interest in at least one image of the OCT image and the OCTA image.","['G06T11/60', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06T5/001', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T5/90', 'G06T7/0012', 'G06T7/11', 'G16H30/40', 'G16H50/20', 'G06N3/048', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30041', 'G06T2207/30101', 'G06T2210/41']"
US10223547B2,Method for differentially private aggregation in a star topology under a realistic adversarial model,"One embodiment provides a system for noise addition to enforce data privacy protection in a star network. In operation, participants may add a noise component to a dataset. An aggregator may receive the noise components from the plurality of participants, compute an overall noise term based on the received noise components, and aggregate values using the noise components and overall noise term.","['G06F21/6245', 'G06F21/602', 'H04L9/008', 'H04L9/085', 'H04L2209/08', 'H04L2209/16']"
CN107464210B,An Image Style Transfer Method Based on Generative Adversarial Networks,"An image style migration method based on a generative confrontation network comprises the following steps: (1) generating a random input; (2) constructing a generating network; (3) constructing a discrimination network; (4) inputting a style image and a content image; (5) learning the representation of styles and contents; (6) confrontation training; (7) and outputting the composite image. The invention has the following beneficial effects: the countertraining of the generation network and the discrimination network combines the advantages of the generation algorithm and the discrimination algorithm, and the alternate optimization of the generation network and the discrimination network not only improves the extraction capability of the model to the high-level features, but also makes the generated samples more vivid. The method has the advantages of no need of manual design of features, low cost, high efficiency, good quality of generated samples and easy popularization.","['G06T3/04', 'G06N3/08']"
CN111563841B,A High-Resolution Image Generation Method Based on Generative Adversarial Networks,"The invention discloses a high-resolution image generation method based on a generation countermeasure network, which comprises the steps of firstly preprocessing a data set image to be learned to obtain a training set; then constructing a generating countermeasure network comprising a generating network and a judging network, pre-training the generating countermeasure network, and obtaining pre-trained model parameters as initializing parameters of the generating countermeasure network: then, respectively inputting the training set and the images generated by the generating network into a judging network, wherein the output of the judging network reacts to the generating network, the generating countermeasure network is subjected to countermeasure training, the network parameters of the generating network and the judging network are optimized, and when the loss function converges, the training is ended, so that the trained generating countermeasure network is obtained; and finally, inputting the random data distribution into a trained generation network to realize high-resolution image generation. The method has the advantages that the generated images are clearer, the training process is stable, and the network is converged faster.","['G06T3/4053', 'G06N3/045', 'G06N3/084', 'G06T3/4007', 'Y02T10/40']"
CN111788476B,"Inspection method of component mounting state, printed circuit board inspection device, and computer-readable recording medium","The printed circuit board inspection apparatus may generate the component-related depth information using pattern light reflected from the component mounted on the printed circuit board, which is received by means of the image sensor, generate the component-related two-dimensional image data using at least one of light of a first wavelength, light of a second wavelength, light of a third wavelength, and light of a fourth wavelength, which is reflected from the component, which is received by means of the first image sensor, input the depth information and the component-related two-dimensional image data to a machine learning-based model, obtain noise-reduced depth information from the machine learning-based model, and inspect the mounting state of the component using the noise-reduced depth information.","['H05K13/0817', 'G06T7/0004', 'G01B11/22', 'G01B11/24', 'G01B11/2509', 'G01N21/8851', 'G01N21/956', 'G01N21/95684', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T5/70', 'G06T7/521', 'G06T7/586', 'H04N23/56', 'H04N23/90', 'H05K13/08', 'H05K13/0815', 'G01N2021/95638', 'G06N3/045', 'G06N3/047', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10152', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30141', 'H05K13/081']"
US20230039729A1,Autonomous vehicle neural network optimization,"Methods and apparatus relating to autonomous vehicle neural network optimization techniques are described. In an embodiment, the difference between a first training dataset to be used for a neural network and a second training dataset to be used for the neural network is detected. The second training dataset is authenticated in response to the detection of the difference. The neural network is used to assist in an autonomous vehicle/driving. Other embodiments are also disclosed and claimed.","['G05B13/027', 'G05B13/0285', 'G05D1/0088', 'G06N20/00', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/084', 'G06N5/047', 'H03M7/30', 'G06N3/063', 'G06N3/08', 'H04B1/66']"
US11011275B2,System and method for diagnosing gastrointestinal neoplasm,A system and method of diagnosing gastrointestinal neoplasm or pathologies in an endoscopy system including an endoscopy system display for displaying an image enhanced endoscopy (IEE) image. The method includes randomly generating training image samples with or without cancer region(s) by an adversarial network (AN) including collecting endoscopic training images (T1) and automatically generating a realistic IEE image as a new training image sample (T2) using a generator network in the AN from a generated segmentation map; using a prediction network (L1PN) to learn a level 1 prediction result being a cancerous probability of an IEE image from the collected T1 and T2; using a prediction network (L2PN) to learn a level 2 prediction result being detected cancerous region(s) of an IEE image; and predicting the level 1 result and the level 2 result for an IEE image using the L1PN and the L2PN and without using the AN.,"['G16H50/20', 'A61B1/000096', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G09B23/285', 'G16H30/40', 'A61B1/00009', 'A61B1/2736', 'G06T2207/10068', 'G06T2207/30028']"
WO2020248492A1,Method and device for denoising oct image based on cyclic generative adversarial network,"The present invention relates to the technical field of artificial intelligence. Disclosed are a method and device for denoising an OCT image based on a cyclic generative adversarial network. The method for denoising an OCT image comprises: acquiring an OCT image to be denoised; inputting said OCT image to a cyclic generative adversarial network model obtained from training; and outputting a denoised OCT image by means of the cyclic generative adversarial network model. The present invention employs a cyclic generative adversarial network model to perform denoising processing on an OCT image, such that a high-noise OCT image can be effectively converted to a clear OCT image for examination by a doctor or analysis by software. The invention eliminates the limitation in the prior art in which the application of deep learning in denoising requires pairing of training data, thereby facilitating acquisition of a large amount of data for training, and accordingly improving denoising performance of a model.","['G06N3/045', 'G06N3/08', 'G06T5/70', 'G06T2207/10101', 'G06T2207/20081', 'G06T2207/20084']"
US20250086458A1,Automatic xai (autoxai) with evolutionary nas techniques and model discovery and refinement,"An exemplary model search may provide optimal explainable models based on a dataset. An exemplary embodiment may identify features from a training dataset, and may map feature costs to the identified features. The search space may be sampled to generate initial or seed candidates, which may be chosen based on one or more objectives and/or constraints. The candidates may be iteratively optimized until an exit condition is met. The optimization may be performed by an external optimizer. The external optimizer may iteratively apply constraints to the candidates to quantify a fitness level of each of the seed candidates. The fitness level may be based on the constraints and objectives. The candidates may be a set of data, or may be trained to form explainable models. The external optimizer may optimize the explainable models until the exit conditions are met.","['G06N3/08', 'G06N3/126', 'G06F18/2163', 'G06F18/217', 'G06F18/22', 'G06N5/025', 'G06N3/006', 'G06N3/045', 'G06N3/048', 'G06N3/049', 'G06N3/084', 'G06N5/045', 'G06N7/01']"
US11620202B2,System and method for unsupervised anomaly prediction,Some embodiments are associated with a system and method for deep learning unsupervised anomaly prediction in Internet of Things (IoT) sensor networks or manufacturing execution systems. The system and method use an unsupervised predictive GAN model with multi-layer perceptrons (MLP) as generator and discriminator.,"['G06N3/088', 'G06F11/008', 'G06F11/0757', 'G06F11/0772', 'G06F11/3006', 'G06F11/3072', 'G06F11/3089', 'G06F18/214', 'G06K9/6256', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/094', 'G06F11/327', 'G06F2218/12']"
CN112614077B,Unsupervised low-illumination image enhancement method based on generation countermeasure network,"The invention discloses an unsupervised low-illumination image enhancement method based on a generated confrontation network, which belongs to the field of image processing. According to the method, the model can be trained by using the unsupervised image data, so that the problems of small amount of supervised data and difficulty in acquisition are solved; meanwhile, the method can try to solve the problem of overexposure after image enhancement through attention designed based on image gradient and brightness.","['G06T5/90', 'G06F18/214', 'G06N20/00', 'G06T2207/20081']"
US12026977B2,"Model training method and apparatus, face recognition method and apparatus, device, and storage medium","A face recognition method includes: extracting a first identity feature of a first face image by using a feature extraction module, and extracting a second identity feature of a second face image by using the feature extraction module, wherein the feature extraction module is implemented by using a neural network, and pre-trained in a manner such that a correlation coefficient of training batch data is obtained based on an identity feature and an age feature of a sample face image in the training batch data, and decorrelated training of the identity feature and the age feature is performed on the feature extraction module based on the correlation coefficient; and performing a face recognition based on determining a similarity between faces in the first face image and the second face image according to the first identity feature and the second identity feature.","['G06V40/161', 'G06F18/214', 'G06F18/217', 'G06F18/22', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V40/168', 'G06V40/172', 'G06V40/178']"
CN111652267B,"Method, device, electronic device, and storage medium for generating an adversarial example","The embodiment of the invention provides a method and a device for generating a countermeasure sample, electronic equipment and a storage medium, wherein an original text is obtained; determining a candidate set of replacement words of each word in the original text; and searching a sample of the attack target model from a discrete space formed by the combination of the candidate sets of the replacement words based on a particle swarm optimization algorithm to generate a countersample. The embodiment of the invention searches the antagonistic sample by using the particle swarm optimization algorithm, and the particle swarm optimization is more efficient than the genetic algorithm as a metaheuristic group evolution calculation method, so that the search speed can be increased and the attack success rate can be increased when the antagonistic sample is searched by using the algorithm. Aiming at different natural language processing models, the embodiment of the invention can quickly and efficiently generate a large amount of high-quality countermeasure samples, successfully deceive the target model, further expose the vulnerability of the target model and has good practicability.","['G06F18/214', 'G06F40/247', 'G06F40/289', 'G06N3/006']"
US20220166955A1,Generating an avatar of a participant of a three dimensional (3d) video conference,"A method for generating an avatar of a participant of a three dimensional (3D) video conference, the method may include acquiring visual information, by a camera of a participant; generating an avatar of the participant as seen from a point of view of a virtual camera that is virtually located at a physical location of the camera; comparing between the avatar and the visual information to provide a comparison result; and amending the avatar or at least one building block of the avatar to compensate for one or more differences between the avatar and the visual information when the comparison results is indicative of the one or more differences.","['H04N7/157', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/024', 'G06T2219/2004', 'G06T2219/2012']"
US10607114B2,Trained generative network for lung segmentation in medical imaging,"A generative network is used for lung lobe segmentation or lung fissure localization, or for training a machine network for lobar segmentation or localization. For segmentation, deep learning is used to better deal with a sparse sampling of training data. To increase the amount of training data available, an image-to-image or generative network localizes fissures in at least some of the samples. The deep-learnt network, fissure localization, or other segmentation may benefit from generative localization of fissures.","['G06K9/6256', 'G06V10/82', 'A61B6/032', 'A61B6/5211', 'A61B8/5207', 'G06F18/2113', 'G06F18/214', 'G06K9/623', 'G06K9/66', 'G06T11/003', 'G06T5/002', 'G06T5/70', 'G06T7/10', 'G06T7/11', 'G06T7/187', 'G06V30/19173', 'G16H50/20', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20116', 'G06T2207/20152', 'G06T2207/30061', 'G06T2207/30101', 'G06V2201/031']"
US10713821B1,Context aware text-to-image synthesis,Techniques are generally described for context aware text-to-image synthesis. First text data comprising a description of an object may be received. A recurrent neural network may determine a first semantic representation data representing the first text data. A generator trained using a first generative adversarial network (GAN) may determine first image data representing the object using the first semantic representation. An encoder of a second GAN may generate a first feature representation of the first image data. The first feature representation may be combined with a projection of the first semantic representation data. A decoder of the second GAN may generate second image data representing the first text data.,"['G06F40/30', 'G06T11/001', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T11/20']"
CN108805188B,An Image Classification Method Based on Feature Recalibration Generative Adversarial Networks,"An image classification method for generating a confrontation network based on feature recalibration is suitable for the field of machine learning. Inputting image data to be classified into a confrontation network model for network training; a generator and a discriminator formed by a convolution network; initializing random noise, and inputting the random noise into a generator; carrying out multilayer deconvolution operation on random noise by using a convolution network in a generator to finally obtain a generated sample; inputting the generated sample and the real sample into a discriminator; performing convolution and pooling operation on input samples by using a convolution network in a discriminator to obtain a feature map, introducing a compression activation SENet module in an intermediate layer of the convolution network to calibrate the feature map to obtain a calibrated feature map, and finally classifying output image data by using global average pooling. A SENet module is introduced into the middle layer of the discriminator, the importance degree of each characteristic channel is automatically learned, and useful characteristics related to the task are extracted to inhibit characteristics unrelated to the task, so that semi-supervised learning performance is improved.","['G06F18/24133', 'G06N3/045', 'G06N3/08']"
US11037025B2,Systems and methods for adversarially robust object detection,"Described herein are embodiments for an approach to improve the robustness of an object detector against adversarial attacks. Existing attacks for object detectors and the impacts of individual task component on model robustness are systematically analyzed from a multi-task view of object detection. In one or more embodiments, a multi-task learning perspective of object detection is introduced and an asymmetric role of task losses is identified. One or more embodiments of an adversarial training method for robust object detection are presented to leverage the multiple sources of attacks for improving the robustness of object detection models.","['G06V40/40', 'G06K9/6256', 'G06V10/82', 'G06F18/214', 'G06F18/2185', 'G06F18/2411', 'G06F18/2431', 'G06K9/00805', 'G06K9/6264', 'G06K9/6269', 'G06V10/764', 'G06V10/774', 'G06V20/58']"
US11151382B2,Opportunity to view an object in image processing,"Image processing of an image is used to determine the opportunity to view an object. Rather than relying on simple numbers passing an object, the opportunity to view the object is weighted based on attention, which is derived from other objects competing for attention. For the processor to more accurately determine opportunity to view as compared to using geometric information alone, a machine-learned network is used. To deal with changes in obstructions, another machine-learned network may extract obstructions from camera images. Trace data is used to allow for daily variation in base counts of viewers, allowing greater temporal resolution and determination based on information more recently acquired than counts.","['G06K9/00671', 'G06Q30/0201', 'G06K9/00637', 'G06N20/00', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06V10/255', 'G06V10/764', 'G06V10/82', 'G06V20/176', 'G06V20/20', 'G06V20/56', 'G06N3/044', 'G06N3/045', 'G06N7/01']"
US12198224B2,Retrieval-based text-to-image generation with visual-semantic contrastive representation,Systems and methods for image generation are described. Embodiments of the present disclosure receive a text phrase that describes a target image to be generated; generate text features based on the text phrase; retrieve a search image based on the text phrase; and generate the target image using an image generation network based on the text features and the search image.,"['G06T11/00', 'G06F16/53', 'G06N20/00', 'G06N3/0475', 'G06N3/0895', 'G06N3/044', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084']"
CN110568442B,A Radar Echo Extrapolation Method Based on Adversarial Extrapolation Neural Network,"The invention provides a radar echo Extrapolation method based on an Antagonistic Extrapolation Neural Network (AENN), which comprises the following steps: AENN offline training: obtaining a training and testing sample set by data preprocessing on a given radar data set, initializing an AENN network and training parameters, carrying out forward propagation by using the training sample set, and training the AENN by adopting a antagonism strategy; AENN online prediction: and testing the trained condition generator by using the test sample set to obtain a predicted radar echo image.","['G01S13/958', 'G01S7/417', 'G01S7/418', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'Y02A90/10']"
CN109816593B,An Attention Mechanism-Based Generative Adversarial Network for Super-Resolution Image Reconstruction,"The invention discloses a super-resolution image reconstruction method for generating a countermeasure network based on an attention mechanism, which comprises the following steps: preprocessing an ImageNet data set, and making training data sets corresponding to high-resolution and low-resolution images; constructing a generation confrontation network model for training, and introducing an attention mechanism into the model; sequentially inputting the obtained training data sets into a generated countermeasure network for model training; and inputting the image to be processed into the trained generation network model to obtain a reconstructed high-resolution image. According to the method, the attention mechanism is added into the perception network to extract the saliency region of the target, the generated image is closer to a real high-resolution image by using a mode of combining local information and global information, the perception loss is introduced to improve the generation effect, the edge and detail information of the reconstructed image are clearer, and the reconstruction effect is better.",[]
US10997690B2,Method and system for end-to-end image processing,"A method of processing an input image comprises receiving the input image, storing the image in a memory, and accessing, by an image processor, a computer readable medium storing a trained deep learning network. A first part of the deep learning network has convolutional layers providing low-level features extracted from the input image, and convolutional layers providing a residual image. A second part of the deep learning network has convolutional layers for receiving the low-level features and extracting high-level features based on the low-level features. The method feeds the input image to the trained deep learning network, and applies a transformation to the residual image based on the extracted high-level features.","['G06T5/70', 'G06T3/4015', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06T5/002', 'G06T5/60', 'G06N3/048', 'G06T2207/20084']"
US12005922B2,Toward simulation of driver behavior in driving automation,"In some examples, one or more characteristics of one or more driving scenes may be obtained. Based at least on the one or more characteristics, one or more behaviors of a simulated driver may be simulated via a machine learning model. An operation associated with one or more advanced driving assistance system (ADAS) functions may be performed based at least on the simulated one or more behaviors.","['B60W60/001', 'B60W50/06', 'G06F30/27', 'G06F30/15']"
CN111767979B,"Training method, image processing method and image processing device for neural network","A training method, an image processing method and an image processing device for a neural network are provided. The training method comprises the following steps: training the discrimination network based on the generation network; training the generating network based on the discriminating network; and alternately executing the training process to obtain a target network based on the trained generation network; the target network is used for carrying out style migration processing on the input image to obtain an output image, and the resolution of the output image is higher than that of the input image. The training method combines the generated type countermeasure network, the super-resolution technology and the style migration technology, and the target network obtained through training by the training method can generate high-quality high-resolution images with target styles based on input images, so that the effects of image style migration and image fusion are improved, and the method has better and wider application prospects.","['G06N3/044', 'G06N3/0475', 'G06F18/24', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06N3/09', 'G06N3/094']"
US11538143B2,Fully convolutional transformer based generative adversarial networks,Systems and methods for detecting anomaly in video data are provided. The system includes a generator that receives past video frames and extracts spatio-temporal features of the past video frames and generates frames. The generator includes fully convolutional transformer based generative adversarial networks (FCT-GANs). The system includes an image discriminator that discriminates generated frames and real frames. The system also includes a video discriminator that discriminates generated video and real video. The generator trains a fully convolutional transformer network (FCTN) model and determines an anomaly score of at least one test video based on a prediction residual map from the FCTN model.,"['G06N3/08', 'G06F18/22', 'G06F18/2433', 'G06K9/6215', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06N5/046', 'G06T7/0002', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'G06T2207/20081', 'G06T2207/20084']"
US11580410B2,3-D convolutional autoencoder for low-dose CT via transfer learning from a 2-D trained network,"A 3-D convolutional autoencoder for low-dose CT via transfer learning from a 2-D trained network is described, A machine learning method for low dose computed tomography (LDCT) image correction is provided. The method includes training, by a training circuitry, a neural network (NN) based, at least in part, on two-dimensional (2-D) training data. The 2-D training data includes a plurality of 2-D training image pairs. Each 2-D image pair includes one training input image and one corresponding target output image. The training includes adjusting at least one of a plurality of 2-D weights based, at least in part, on an objective function. The method further includes refining, by the training circuitry, the NN based, at least in part, on three-dimensional (3-D) training data. The 3-D training data includes a plurality of 3-D training image pairs. Each 3-D training image pair includes a plurality of adjacent 2-D training input images and at least one corresponding target output image. The refining includes adjusting at least one of a plurality of 3-D weights based, at least in part, on the plurality of 2-D weights and based, at least in part, on the objective function. The plurality of 2-D weights includes the at least one adjusted 2-D weight.","['G06V10/82', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T11/00', 'G06T11/006', 'G06T5/002', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'A61B6/032', 'A61B6/5258', 'A61B6/542', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
US11157782B2,Anomaly detection in multidimensional time series data,"A method, computer system, and computer program product to detect anomalies in a multivariate or multidimensional time series data set. The time series data set is retrieved from a monitored device. A pair of neural networks are trained simultaneously using the retrieved time series data set by implementing an adversarial training process, to generate a generative neural network and a discriminative neural network. The anomalies in the time series data set of the monitored device are detected by implementing one or both of the generative neural network and the discriminative neural network to monitor the time series data set.","['G06N3/084', 'G06K9/6284', 'G05B23/024', 'G06F17/153', 'G06F18/2433', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06F17/175', 'G06F18/24317', 'G06F2218/12', 'G06K9/00536', 'G06K9/6281', 'G06N3/082']"
US11556581B2,Sketch-based image retrieval techniques using generative domain migration hashing,"This disclosure relates to improved sketch-based image retrieval (SBIR) techniques. The SBIR techniques utilize a neural network architecture to train a domain migration function and a hashing function. The domain migration function is configured to transform sketches into synthetic images, and the hashing function is configured to generate hash codes from synthetic images and authentic images in a manner that preserves semantic consistency across the sketch and image domains. The hash codes generated from the synthetic images can be used for accurately identifying and retrieving authentic images corresponding to sketch queries, or vice versa.","['G06F16/532', 'G06F16/137', 'G06F16/152', 'G06F16/51', 'G06F16/583', 'G06F16/5854', 'G06F18/217', 'G06F18/22', 'G06K9/6215', 'G06K9/6262', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06V30/1916', 'G06V30/422', 'G06N3/02', 'G06T2207/20084', 'G06T2210/36']"
US10430946B1,Medical image segmentation and severity grading using neural network architectures with semi-supervised learning techniques,"This disclosure relates to improved techniques for performing computer vision functions on medical images, including object segmentation functions for identifying medical objects in the medical images and grading functions for determining severity labels for medical conditions exhibited in the medical images. The techniques described herein utilize a neural network architecture to perform these and other functions. The neural network architecture can be trained, at least in part, using semi-supervised learning techniques that enable the neural network architecture to accurately perform the object segmentation and grading functions despite limited availability of pixel-level annotation information.","['A61B5/02007', 'A61B5/7267', 'A61B5/7282', 'G06F18/2148', 'G06F18/2155', 'G06F18/2178', 'G06F18/2431', 'G06F18/2453', 'G06F18/41', 'G06K9/6257', 'G06K9/6259', 'G06K9/6263', 'G06K9/628', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06T7/11', 'G06V10/26', 'G06V10/454', 'G06V10/462', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V20/695', 'G16H30/40', 'G16H50/20', 'A61B2576/00', 'A61B5/02028', 'A61B5/026', 'A61B5/055', 'A61B5/4064', 'A61B5/4504', 'A61B5/7275', 'G06K2209/05', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30008', 'G06T2207/30041', 'G06T2207/30048', 'G06T2207/30096', 'G06V2201/03']"
TWI753325B,Computing device and method for generating machine translation model and machine-translation device,"A device and a method for generating a machine translation model and a machine translation device are disclosed. The device inputs a source training sentence of a source language and a dictionary data to a generator network so that the generator network outputs a target training sentence of a target language according to the source training sentence and the dictionary data. Then, the device inputs the target training sentence and a correct translation of the source training sentence to a discriminator network so as to calculate an error between the target training sentence and the correct translation according to the output of the discriminator network, and trains the generator network and the discriminator network respectively. The trained generator network is the machine translation model.","['G06F40/44', 'G06F40/58', 'G06F40/242', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094']"
US11037336B2,Method for processing unmatched low-dose X-ray computed tomography image using neural network and apparatus therefor,A method for processing an unmatched low-dose X-ray computed tomography (CT) image using a neural network and an apparatus therefor are provided. The method includes receiving a low-dose X-ray CT image and removing noise from the low-dose X-ray CT image using a unsupervised learning based neural network learned using unmatched data to reconstruct a routine-dose X-ray CT image corresponding to the low-dose X-ray CT image.,"['G06T5/70', 'A61B6/5205', 'G06T11/003', 'A61B6/032', 'G06N3/045', 'G06N3/0895', 'G06T11/008', 'G06T5/002', 'G06T5/60', 'G06T7/0012', 'G16H30/40', 'G16H50/20', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/412', 'G06T2211/441']"
CN107622104B,A method and system for text image recognition and annotation,"The invention discloses a character image identification and annotation method and a system, wherein the method or the system firstly obtains an original character image and a database containing a plurality of character image annotation samples; secondly, establishing a Laplace additional information antagonistic neural network model, and generating an artificially synthesized character image according to the original character image and the Laplace additional information antagonistic neural network model; and classifying the artificially synthesized character images according to image categories to obtain characteristic images, matching the characteristic images by utilizing a database containing a plurality of character image annotation samples, and adding the annotation information of the character image annotation sample with the highest matching degree with the characteristic images to the characteristic images, so that the automatic identification and annotation of the original character images are realized, and the character image identification and annotation efficiency is improved.",[]
WO2023035015A1,Systems and methods for token management in social media environments,Systems and techniques to enable token-related functionality within social media platforms are illustrated. One embodiment include a method for accessing tokens. The method derives characteristics of one or more tokens owned by a first account on a platform. The method reviews one or more external accounts on the platform for compatible tokens that share at least one of the characteristics. The method confirms a compatible token is owned by a second account of the one or more external accounts. The method accesses the compatible token.,"['G06Q20/3678', 'H04L9/50', 'G06Q20/3823', 'H04L9/3213', 'H04L9/3231', 'H04L9/3247', 'G06Q2220/00', 'G06Q50/01']"
CN109947086B,Mechanical fault migration diagnosis method and system based on counterstudy,"The invention discloses a mechanical fault migration diagnosis method and system based on countermeasure learning, wherein the method comprises the following steps: acquiring original signals of mechanical faults under different working conditions, and analyzing to generate a source domain training data set with a label, a source domain training data set without a label and a target domain testing data set under different working conditions; training a deep convolutional neural network model according to a source domain training data set with a label and a back propagation algorithm to generate a fault diagnosis model; training a fault diagnosis model according to the source domain training data set without the label and the target domain testing data set; fine-tuning the trained fault diagnosis model according to the source domain training data set with the label and a back propagation algorithm; inputting the target domain test data set without the label into the fault diagnosis model after fine adjustment, and outputting the fault category of the sample to be tested. The method obtains the domain invariant feature through the counterstudy method, realizes the migration before different domains, and realizes the intelligent diagnosis of the variable working condition mechanical fault.",[]
US11205251B2,Method of image completion,"A method of image completion comprises: constructing the image repair model and constructing a plurality of conditional generative adversarial networks according to a plurality of object types; inputting the training image corresponding to the plurality of objective types such that the plurality of conditional generative adversarial networks respectively conduct a corruption feature training; inputting the image in need of repair and respectively conducting an image repair through the plurality of conditional generative adversarial networks to generate a plurality of repaired images; and judging a reasonable probability of the plurality of repaired images through a probability analyzer, choosing an accomplished image and outputting the accomplished image through an output interface.","['G06T5/005', 'G06T5/77', 'G06F18/2148', 'G06K9/6257', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/60', 'G06T5/60', 'G06V10/764', 'G06V10/82', 'G06N7/01', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T5/20']"
US11615546B2,Systems and methods for depth estimation using generative models,"Systems and methods for depth estimation in accordance with embodiments of the invention are illustrated. One embodiment includes a method for estimating depth from images. The method includes steps for receiving a plurality of source images captured from a plurality of different viewpoints using a processing system configured by an image processing application, generating a target image from a target viewpoint that is different to the viewpoints of the plurality of source images based upon a set of generative model parameters using the processing system configured by the image processing application, and identifying depth information of at least one output image based on the predicted target image using the processing system configured by the image processing application.","['G06T7/55', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/70', 'G06T2207/20084']"
US11704804B2,Domain adaptation using post-processing model correction,"Techniques are described for domain adaptation of image processing models using post-processing model correction According to an embodiment, a method comprises training, by a system operatively coupled to a processor, a post-processing model to correct an image-based inference output of a source image processing model that results from application of the source image processing model to a target image from a target domain that differs from a source domain, wherein the source image processing model was trained on source images from the source domain. In one or more implementations, the source imaging processing model comprises an organ segmentation model and the post-processing model can comprise a shape-autoencoder. The method further comprises applying, by the system, the source image processing model and the post-processing model to target images from the target domain to generate optimized image-based inference outputs for the target images.","['G06T7/11', 'G06F18/214', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T11/003', 'G06T7/0012', 'G06T7/10', 'G06V10/7753', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06V2201/03']"
US11158090B2,Enhanced video shot matching using generative adversarial networks,"This disclosure involves training generative adversarial networks to shot-match two unmatched images in a context-sensitive manner. For example, aspects of the present disclosure include accessing a trained generative adversarial network including a trained generator model and a trained discriminator model. A source image and a reference image may be inputted into the generator model to generate a modified source image. The modified source image and the reference image may be inputted into the discriminator model to determine a likelihood that the modified source image is color-matched with the reference image. The modified source image may be outputted as a shot-match with the reference image in response to determining, using the discriminator model, that the modified source image and the reference image are color-matched.","['G06T7/90', 'G06F18/214', 'G06K9/00744', 'G06K9/00758', 'G06K9/622', 'G06K9/6256', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/46', 'G06V20/48', 'H04N1/6052', 'H04N23/84', 'H04N9/64', 'H04N9/74', 'G06T2207/10016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'H04N1/6086']"
WO2020108358A1,"Image inpainting method and apparatus, computer device, and storage medium","Disclosed in embodiments of the present application are an image inpainting method and apparatus, and a storage medium. According to the embodiments of the present application, after an image to be inpainted is obtained, an area to be inpainted and a non-inpainting area are determined from the image; feature extraction is performed on the non-inpainting area on the basis of different receptive fields and spatial resolutions, then textures of the area to be inpainted are generated according to the extracted feature information of multiple scales, and the area to be inpainted in the image is filled with the generated textures to obtain an inpainted image.","['G06T3/4053', 'G06T5/00', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06T11/40', 'G06T3/4007', 'G06T5/60', 'G06T5/77', 'G06V10/764', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104']"
US12223435B2,System and method for molecular reconstruction from molecular probability distributions,"A system and method comprising a transmoler that identifies common substructures of a given 3D conformer and predicts its structural information. First, based on contrastive learning, substructure embeddings are learned in an unsupervised manner. Secondly, a novel oriented 3D object regressor predicts the dimensions and directions of each substructure in a conformer as well as its fingerprint embedding which are used to create differentiable junction tree molecular graphs. Lastly, using the junction tree graphs, molecular representations such as DeepSMILES are generated which represent new and novel molecules. The system may also generate conformers directly from a pocket. A pocket may be input to the model and the model learns to generate structures which can fit that pocket by conditioning the generative system. Furthermore, structure-based contrastive embeddings generated for transmoler can be recycled in structure-based generative modelling.","['G06N3/088', 'G06F16/951', 'G06F18/22', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/022', 'G06V10/751', 'G06V10/82', 'G16B15/00', 'G16B40/00', 'G16B45/00', 'G16B50/10', 'G16C20/50', 'G16C20/70', 'G06N3/044', 'G06N3/048', 'G06N3/084', 'G16C20/30', 'G16C20/90']"
US10849585B1,Anomaly detection using parametrized X-ray images,"For anomaly detection based on topogram predication from surface data, a sensor captures the outside surface of a patient. A generative adversarial network (GAN) generates a topogram representing an interior anatomy based on the outside surface of the patient. An X-ray image of the patient is acquired and compared to the generated topogram. By quantifying the difference between the real X-ray image and the predicted one, anatomical anomalies may be detected.","['A61B5/7267', 'A61B5/0515', 'A61B6/463', 'A61B6/5205', 'A61B6/5217', 'G06N20/00', 'G06N3/0445', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/003', 'G06T7/0014', 'G06T7/514', 'G06V10/764', 'G06V10/82', 'A61B5/0033', 'A61B5/0037', 'A61B5/055', 'A61B6/545', 'G06F18/217', 'G06F18/24143', 'G06K2209/055', 'G06K9/6262', 'G06K9/6274', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/084', 'G06N7/01', 'G06T2207/10028', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064', 'G06T7/70', 'G06V2201/03', 'G06V2201/033']"
US11805157B2,Sharing content during a virtual 3D video conference,"A method for sharing content during a virtual 3D video conference, the method may include inviting multiple participants to join a virtual 3D video conference; creating a shared folder dedicated for storing shared content items, wherein the shared content is accessible during at least during the virtual 3D video conference; enabling access, to the multiple participants, to the shared folder; wherein the access is governed by one or more access control rule; and conducting the virtual 3D video conference; wherein the conducting comprises sharing at least one of the content items.","['H04L65/4015', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04L12/1818', 'H04L12/1822', 'H04L63/101', 'H04L63/102', 'H04L63/108', 'H04L65/1089', 'H04L65/1093', 'H04L65/403', 'H04L65/80', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'H04N7/157', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/2004']"
US11610098B2,Data augmentation in transaction classification using a neural network,"Systems and methods for data augmentation in a neural network system includes performing a first training process, using a first training dataset on a neural network system including an autoencoder including an encoder and a decoder to generate a trained autoencoder. A trained encoder is configured to receive a first plurality of input data in an N-dimensional data space and generate a first plurality of latent variables in an M-dimensional latent space, wherein M is an integer less than N. A sampling process is performed on the first plurality of latent variables to generate a first plurality of latent variable samples. A trained decoder is used to generate a second training dataset using the first plurality of latent variable samples. The second training dataset is used to train a first classifier including a first classifier neural network model to generate a trained classifier for providing transaction classification.","['G06N3/088', 'G06N3/0454', 'G06F18/214', 'G06F18/241', 'G06F18/2413', 'G06K9/6256', 'G06K9/6268', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N7/005', 'G06Q20/4016', 'G06V10/82', 'G06N7/01']"
US11291919B2,Development of virtual character in a learning game,"Technologies for executing a virtual character development application using machine learning are described herein. In typical simulation applications, a user may be enabled to create a virtual character and navigate a virtual world. A typical simulation application may accept inputs from the user, determine actions initiated by the user based on the inputs, determine subsequent outcomes of the user-initiated actions, and mold the simulation according to the outcomes. However, most outcomes may be predetermined and predictable by design. In contrast, some embodiments may include a server configured to execute a virtual character development application in conjunction with one or more client devices. A user may utilize a client device to create and develop a virtual character within the application. The user may be enabled to provide inputs to the virtual character development application, and the artificial component may process the input and extract information associated with the virtual character.","['A63F13/355', 'A63F13/825', 'A63F13/211', 'A63F13/213', 'A63F13/2145', 'A63F13/215', 'A63F13/424', 'A63F13/58', 'A63F13/63', 'A63F13/655', 'A63F13/67', 'A63F13/822', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/04', 'G06T19/003', 'G06T19/006', 'A63F2300/65', 'A63F2300/8082']"
CN113627504B,Multimodal and multiscale feature fusion target detection method based on generative adversarial network,"The invention discloses a multi-mode multi-scale feature fusion target detection method based on a generated countermeasure network, which is characterized in that images generated by visible light camera equipment and infrared light camera equipment are respectively transmitted into a parallel pre-training Darknet53 network, deep feature data in the respective images are extracted as far as possible, three feature maps with different scales are extracted from the last three residual error networks, and the two-mode multi-scale feature maps are transmitted to a feature fusion module; using a generator pre-trained in a countermeasure network generated based on conditions to perform deep fusion on the multi-mode and multi-scale characteristic diagram, so that more target characteristic information is injected into the characteristic diagram of the original visible light mode; and finally, sequentially cascading the generated multi-scale multi-modal fusion feature maps and transmitting the multi-scale multi-modal fusion feature maps to each YOLO layer to complete a target detection task. The invention can generate the fusion characteristic vector which is close to the real condition to the maximum extent, thereby improving the detection effect of the target detection model in the night environment.","['G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08']"
CN114612836B,Anomaly detection method for surveillance videos based on memory-enhanced future video frame prediction,"The invention provides a monitoring video anomaly detection method based on memory-enhanced future video frame prediction, and belongs to the technical field of video anomaly detection. Firstly, constructing and optimizing a learning anomaly detection model, wherein the anomaly detection model comprises a generator network and a discriminator network; the generator network comprises an encoder, a memory module and a decoder, and generates a video frame at the next moment, namely a future video frame; the discriminator network uses the anomaly score as a criterion for judging whether the future video frame is anomalous or not by calculating the anomaly score of the future video frame; optimizing and learning the built abnormal detection model through strength loss, gradient loss, optical flow loss, contrast loss and cross entropy loss; then detecting an abnormal event in the monitoring video; the method can remarkably improve the abnormality detection precision in the monitoring video; the generator network has higher universality and robustness, can be embedded into most of anomaly detection methods, and improves the anomaly detection performance.","['G06F18/214', 'G06N3/045', 'G06N3/084', 'H04N17/00', 'Y02T10/40']"
US12197640B2,"Image gaze correction method, apparatus, electronic device, computer-readable storage medium, and computer program product","An image gaze correction method, apparatus, electronic device, computer-readable storage medium, and computer program product related to the field of artificial intelligence technologies are provided. The image gaze correction method includes: acquiring an eye image from an image; performing feature extraction processing on the eye image to obtain feature information of the eye image; performing, based on the feature information and a target gaze direction, gaze correction processing on the eye image to obtain an initially corrected eye image and an eye contour mask; performing, by using the eye contour mask, adjustment processing on the initially corrected eye image to obtain a corrected eye image; and generating a gaze corrected image based on the corrected eye image.","['G06T11/60', 'G06F3/013', 'G06F18/214', 'G06F18/25', 'G06V10/46', 'G06V10/761', 'G06V10/803', 'G06V40/165', 'G06V40/171', 'G06V40/18', 'G06V40/19', 'G06V40/193']"
CN107194872B,Super-resolution reconstruction method of remote sensing images based on content-aware deep learning network,"The invention discloses a kind of Remote sensed image super-resolution reconstruction methods based on perception of content deep learning network, the invention proposes the comprehensive measurement indexs and calculation method of picture material complexity, based on this, sample image is classified by content complexity, the deep layer GAN network model of building and the high, medium and low three kinds of complexity of training not etc., then it according to the content complexity of the input picture to oversubscription, chooses corresponding network and is rebuild.In order to improve the learning performance of GAN network, the present invention gives a kind of loss function definition of optimization simultaneously.The present invention overcomes the contradictions of over-fitting generally existing in the super-resolution rebuilding based on machine learning and poor fitting, effectively improve the super-resolution rebuilding precision of remote sensing image.",['G06T3/4053']
WO2022199143A1,Medical image segmentation method based on u-shaped network,"Disclosed in the present invention is a medical image segmentation method based on a U-shaped network. Firstly, a real segmented image and an original image are sent into a generative adversarial network for data enhancement, and a synthesized picture with a label is generated; and then, the synthesized picture is put into an original data set, so as to obtain an expanded data set, and the expanded data set is sent to an improved multi-feature fused segmentation network for training. According to the present invention, a dilated convolution module for acquiring receptive fields of different sizes is added between skip connections of shallow layer and deep layer features of a segmentation network, such that the fusion of detailed information and deep-layer semantics is enhanced, the adaptability to the size of a segmentation target is improved, and the accuracy of medical image segmentation is also improved. By means of the present invention, the problem of overfitting occurring when a segmentation network is trained is alleviated by means of using a generative adversarial network to expand a data set, and the problem of a traditional U-shaped network losing the capability to capture detailed information and incompletely capturing deep layer and shallow layer information features are compensated for from the perspective of a multi-scale feature connection, thereby improving a final segmentation result.","['G06T7/10', 'G06F18/253', 'G06F21/6245', 'G06N3/045', 'G06N3/08', 'G06T5/70', 'G06T2207/30004']"
US12182308B2,Removal of sensitive data from documents for use as training sets,"Systems and methods relating to the replacement or removal of sensitive data in images of documents. An initial image of a document with sensitive data is received at an execution module and changes are made based on the execution module's training. The changes include replacing or effectively removing the sensitive data from the image of the document. The resulting sanitized image is then sent to a user for validation of the changes. The feedback from the user is then used in training the execution module to refine its behaviour when applying changes to other initial images of documents. To train the execution module, training data sets of document images with sensitive data manually tagged by users are used. The execution module thus learns to identify sensitive data and its submodules replace that sensitive data with suitable replacement data. The feedback from the user works to improve the resulting sanitized images from the execution module.","['G06F21/6209', 'G06F18/214', 'G06F18/2178', 'G06F18/24137', 'G06F21/6245', 'G06F21/6254', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T5/77', 'G06V10/82', 'G06V30/19167', 'G06V30/19173', 'G06V30/414', 'G06V30/416', 'G06F2221/2143', 'G06T2207/20084', 'G06T2207/30176']"
US11543830B2,Unsupervised real-to-virtual domain unification for end-to-end highway driving,"An unsupervised real to virtual domain unification model for highway driving, or DU-drive, employs a conditional generative adversarial network to transform driving images in a real domain to their canonical representations in the virtual domain, from which vehicle control commands are predicted. In the case where there are multiple real datasets, a real-to-virtual generator may be independently trained for each real domain and a global predictor could be trained with data from multiple real domains. Qualitative experiment results show this model can effectively transform real images to the virtual domain while only keeping the minimal sufficient information, and quantitative results verify that such canonical representation can eliminate domain shift and boost the performance of control command prediction task.","['G06V10/82', 'G05D1/0246', 'G05D1/0088', 'G06F18/2185', 'G06F18/24', 'G06K9/6264', 'G06K9/6267', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T11/60', 'G06T3/0012', 'G06T3/04', 'G06T9/002', 'G06V10/764', 'G06V20/58', 'G06V20/588', 'G05D2201/0213']"
US11449733B2,Neural network learning method and device for recognizing class,"The present disclosure provides a neural network training device for recognizing a class of an object included in an image based on an artificial intelligence (AI) system and an application thereof, the neural network training method including: acquiring, by using a first learning network model trained based on source training images respectively included in at least one class, feature information of a query image included in a class different from the at least one class; obtaining a generated image from the feature information of the query image by using a second learning network model acquiring feature information of the obtained generated image by using the first learning network model; and updating weights of layers respectively included in the first and second learning network models, based on a difference between the feature information of the query image and the feature information of the generated image and on a difference between the query image and the generated image.","['G06N3/08', 'G06N3/0454', 'G06N3/088', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/098', 'G06T7/136', 'G06V10/774', 'G06V10/776', 'G06T2207/20081', 'G06T2207/20084']"
NL2022758B1,Image Super-resolution Reconstruction Method Based on Multi-scale Generative Adversarial Network,"The present invention discloses an image super-resolution reconstruction method based on a multi-scale generative adversarial network. A multi-scale SENet module is used as a generator, and finally, the multi-scale generative adversarial network is constructed. Then, an objective loss function is determined, a pre-training process of the generator is completed, and the convergence rate of the multi-scale generative adversarial network is improved. The feature extraction of high-frequency information of an LR input image is realized by the constructed multi-scale generative adversarial network, and then an HR image is reconstructed with the input result of bicubic interpolation. The discriminator is used to identify the authenticity of the reconstructed input and weight the reconstructed mean square error loss and the adversarial loss as the final adjustment objective function. After the output HR image is adjusted by the objective function, the whole reconstruction process of the image is completed. The present invention can extract more high-frequency information details of the LR input image, thereby generating an HR image with better display effect after the image super-resolution reconstruction.","['G06N3/082', 'G06T3/4076', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T3/4007', 'G06T2207/20081', 'G06T2207/20084']"
CN111027439B,SAR Target Recognition Method Based on Auxiliary Classification Generative Adversarial Network,"The invention relates to a novel method for generating an anti-network SAR image synthesis and SAR target recognition based on auxiliary classification, which generates an anti-network by utilizing the auxiliary classification of a generator based on a deconvolution neural network, and expands a training sample library in the process of generating a high-resolution SAR image; the discrimination network for generating the countermeasure network in the auxiliary classification mode can not only identify the true and false of the SAR image and obtain the class label of the corresponding SAR image, but also generate a large number of high-resolution SAR image samples containing the class label on the basis of improving the network identification rate in the process of the countermeasure training.","['G06V20/13', 'G06F18/214', 'G06F18/22', 'G06F18/241']"
US11437034B2,Remote control method and apparatus for an imaging apparatus,"Disclosed are a method and apparatus for remotely controlling an imaging apparatus. A method of controlling a remote control apparatus includes converting a spoken utterance of a user into an utterance text or receiving the utterance text, applying a generative model-based first learning model to the utterance text and generating an image having attributes corresponding to a context of the utterance text, and externally transmitting the image and the utterance text. In addition, a method of controlling an imaging apparatus includes receiving a first input including text or speech data and a second input including a first image, capturing at least one second image based on the first input, comparing the first image and the second image, and transmitting the second image in response to a comparison result of the first image and the second image.","['H04L67/125', 'H04N23/661', 'G06F18/22', 'G06F3/167', 'G06F40/00', 'G06F40/216', 'G06F40/284', 'G06F40/289', 'G06F40/30', 'G06F40/44', 'G06K9/6215', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G10L15/16', 'G10L15/1815', 'G10L15/22', 'G10L15/24', 'G10L15/26', 'G10L15/30', 'G10L2015/223', 'H04L67/10']"
CN118378912B,Emergency scene intelligent analysis and decision support method based on AI large model,"The invention provides an intelligent analysis and decision support method for an emergency scene based on an AI large model, which comprises six parts: multisource data integration and preprocessing, dynamic scenario modeling, decision perspective and behavior analysis, real-time data processing and feedback, adaptive decision support, and knowledge-driven learning and optimization. The method integrates the Bayesian network fusion depth belief network to preprocess the multi-source data, so that the information reliability and consistency are improved; by combining a dynamic scene modeling with a self-adaptive deep learning network and a graph neural network, the adaptability and generalization capability of the model are improved; the real-time data processing architecture ensures low delay of data processing, so that the system can rapidly respond to emergency; the self-adaptive decision support mechanism combines reinforcement learning, so that the flexibility and accuracy of decision making are improved. The invention provides scientific, strict and efficient support for emergency management, obviously enhances the capability of coping with emergency situations, and ensures the real-time performance and accuracy of decision making.","['G06Q10/0637', 'G06F18/213', 'G06F18/2411', 'G06F18/24155', 'G06F18/2431', 'G06N3/0442', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/094', 'G06Q10/06313', 'G06Q50/26']"
US11875551B2,Collecting and processing data from vehicles,"In one embodiment, a method includes obtaining candidate data generated by a vehicle. The candidate data comprises a subset of sensor data identified based on a set of neural network models executing on the vehicle. The method also includes determining whether the candidate data can be associated with one or more categories of a set of categories for training data based on a set of categorization models. The method further includes associating the candidate data with the first category in response to determining that the candidate data can be associated with at a first category of the set of categories. The method further includes determining whether the candidate data can be associated with a second category. The set of categories lacks the second category. The method further includes including the second category in the set of categories in response to determining that the candidate data can be associated with the second category. The method further includes associating the candidate data with the second category.","['G06V10/764', 'G06F16/9024', 'G06F16/9035', 'G06F18/214', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06V10/945', 'G06V20/56']"
US20230252754A1,Systems and methods for modeling and controlling physical dynamical systems using artificial intelligence,"The present disclosure provides systems, methods, and computer program products for controlling an object. An example method can comprise (a) obtaining video data of the object and (b) performing motion analysis on the video data to generate modified video data. The method can further comprise (c) using artificial intelligence (AI) to identify a set of features in the modified video data. The set of features may be indicative of a predicted state of the object. The AI may be been trained offline on historical training data. The method can further comprise (d) using the predicted state to determine a control signal and (e) transmitting, in real-time, the control signal to the object to adjust or maintain a state of the object in relation to the predicted state. Operations (a) to (d) can be performed without contacting the object.","['G06V10/255', 'G06T7/0004', 'G06T7/13', 'G06T7/90', 'G06V10/25', 'G06V10/82', 'G06V20/44', 'G06V20/46', 'G06V20/52', 'G01H1/003', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20182']"
CN111105352B,"Super-resolution image reconstruction method, system, computer equipment and storage medium","The invention discloses a super-resolution image reconstruction method, a super-resolution image reconstruction system, computer equipment and a storage medium, wherein the super-resolution image reconstruction method comprises the following steps: removing batch normalization layers in an inverted residual block of the lightweight network, wherein the inverted residual block comprises an expansion convolution layer, a depth separable convolution layer and a compression convolution layer by using a Swish function as an activation function; constructing a generator network according to the processed inverted residual block and a sub-pixel convolution layer based on an efficient sub-pixel convolution neural network; constructing a discriminator network according to the dense network; constructing and generating an antagonistic neural network according to the generator network and the discriminator network; training the generated antagonistic neural network by using a training set; and performing super-resolution image reconstruction on the image to be processed by utilizing the trained generation antagonistic neural network. The method can solve the problems of serious delay, large occupied space of the model and the like caused by adding the super-resolution image reconstruction technology based on the generation countermeasure neural network into the real-time detection algorithm.","['G06T3/4053', 'G06N3/045', 'G06N3/08']"
US11734319B2,Question answering method and apparatus,"A question answering method includes obtaining target question information; determining a candidate question and answer pair based on the target question information; calculating a confidence of answer information in the candidate question and answer pair, where the confidence is used to indicate a probability that question information in the candidate question and answer pair belongs to an answer database or an adversarial database; determining whether the confidence is less than a first preset threshold; and when the confidence is less than the first preset threshold, outputting information indicating incapable of answering.","['G06F18/22', 'G06F16/3329', 'G06F18/251', 'G06N5/00', 'G10L15/063', 'G10L15/197', 'G10L15/22', 'G10L2015/0636', 'G10L2015/225']"
CN111967571B,Abnormality detection method and device based on MHMA,"The application relates to the technical field of artificial intelligence, in particular to an abnormal detection method and equipment based on MHMA, which are used for solving the technical problem of low abnormal data detection accuracy in an industrial control system in the prior art. The method comprises the following steps: acquiring equipment data in an industrial control system, inputting the equipment data into a multi-head memory self-encoder which is trained and comprises a memory module for memory enhancement, and obtaining reconstruction data corresponding to the equipment data; and calculating a reconstruction error between the equipment data and the reconstruction data, and determining that the industrial control system is abnormal when the reconstruction error exceeds a preset abnormal threshold value. Therefore, the multi-head memory self-encoder is adopted to detect abnormal data in the system, and the accuracy of system abnormal detection is effectively improved.","['G06N3/045', 'G05B23/024', 'G05B19/4184', 'G06F18/213', 'G06F18/22', 'G06F18/23213', 'G06F18/24', 'G06N3/084', 'Y02P90/02']"
CN113826051B,Generate digital twins of the interactions between parts of a physical system,"A method includes receiving, via a first component in a production environment, sensor measurements corresponding to a second component in the production environment. A first digital twinning corresponding to a first component is identified, and a perception algorithm is applied to identify a component type associated with a second component. A second digital twin is selected based on the component type, and a third digital twin modeling interactions between the first digital twin and the second digital twin is selected. The third digital twinning is used to generate instructions of the first component that allow the first component to interact with the second component. The instructions may then be sent to the first component.","['G06N3/006', 'B25J9/163', 'B25J9/1671', 'G05B19/41885', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/092', 'G06N3/094', 'G05B17/02', 'G05B2219/32017', 'G06F2119/18', 'G06F30/17', 'G06F30/20', 'G06F30/27', 'G06N3/008', 'G06N7/01']"
CN108830209B,Remote sensing image road extraction method based on generation countermeasure network,"The invention provides a remote sensing image road extraction method based on a generation countermeasure network, which solves the problems of low road extraction accuracy and poor road continuity of remote sensing images. The method comprises the following implementation steps: selecting a sample set from the existing remote sensing database and dividing a test sample and a training sample; setting a generation countermeasure network structure, including a generation network and a discrimination network; setting a generation countermeasure network loss function for road extraction, including traditional generation countermeasure network loss and Euclidean distance loss aiming at road extraction; training and generating a confrontation network by using a self-adaptive moment estimation method to obtain network parameters; the trained model carries out road extraction on the test sample; and outputting a remote sensing image with the road network and the background information. The invention improves the road extraction accuracy, and the extracted road network is more complete, the road continuity is better, and the accuracy, the recall ratio, the precision ratio and the F are improved1Score is significantly elevated for road extraction of remote sensing images.","['G06V20/182', 'G06N3/045', 'G06N3/08']"
US11580203B2,Method and apparatus for authenticating a user of a computing device,"A system for authenticating a user attempting to access a computing device or a software application executing thereon. A data storage device stores one or more digital images or frames of video of face(s) of authorized user(s) of the device. The system subsequently receives from a first video camera one or more digital images or frames of video of a face of the user attempting to access the device and compares the image of the face of the user attempting to access the device with the stored image of the face of the authorized user of the device. To ensure the received video of the face of the user attempting to access the device is a real-time video of that user, and not a forgery, the system further receives a first photoplethysmogram (PPG) obtained from a first body part (e.g., a face) of the user attempting to access the device, receives a second PPG obtained from a second body part (e.g., a fingertip) of the user attempting to access the device, and compares the first PPG with the second PPG. The system authenticates the user attempting to access the device based on a successful comparison of (e.g., correlation between, consistency of) the first PPG and the second PPG and based on a successful comparison of the image of the face of the user attempting to access the device with the stored image of the face of the authorized user of the device.","['G06F21/32', 'G06F18/22', 'G06F18/24143', 'G06F21/83', 'G06K9/6201', 'G06V10/30', 'G06V10/56', 'G06V10/764', 'G06V10/82', 'G06V40/161', 'G06V40/168', 'G06V40/172', 'G06V40/20', 'G06V40/45', 'G06V40/70', 'H04N23/56', 'H04N23/611', 'H04N23/90', 'H04N5/2256', 'H04N5/247', 'G06V40/15']"
US11615878B2,Systems and methods for integrating neural network image analyses into medical image viewing applications,"Systems for delivering one or more studies, where each of the one or more studies has a series of digital images associated with only one person and generated by an imaging modality, is disclosed. The systems include a syncing application that is configured to execute within a local area network and that is in data communication with imaging modalities and/or computing devices configured to display images generated by each of the imaging modalities. The systems also include a server adapted to be external to the local area network and in data communication with the syncing application and a client-side viewing application installed on one or more of the computing devices. The client-side viewing application is configured to acquire the studies, including unrendered data representative of the digital images of the series, locally render the unrendered data, and enable a user to manipulate the digital images.","['G16H30/20', 'G06F16/27', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06T11/008', 'G06T7/0002', 'G06T7/0012', 'G16H30/40', 'G16H40/20', 'H04L67/1095', 'H04L67/1097', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'G06T2200/16', 'G06T2200/24', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G16H50/20', 'G16H80/00']"
US10733287B2,Resiliency of machine learning models,"One embodiment provides a method, including: deploying a machine learning model, wherein the deployed machine learning model is used in responding to queries from users; receiving, at the deployed machine learning model, input from a user; identifying a type of machine learning model attack corresponding to the received input; computing, responsive to receiving the input, a resiliency score of the machine learning model, wherein the resiliency score indicates resistance of the machine learning model against the identified type of attack; and performing an action responsive to the computed resiliency score.","['G06F21/125', 'G06F16/903', 'G06F18/2178', 'G06F21/52', 'G06F21/55', 'G06F21/577', 'G06K9/62', 'G06N20/00']"
US11182979B2,Augmented reality remote authoring and social media platform and system,"Frontend and backend systems and processes. Technical foundations on which an Augmented Reality (AR) platform, such as an AR Social Media Platform. Systems and methods are used to construct and manage an AR Cloud backend and frontend environment facilitation: persistent 3-Dimensional and 2-Dimensional geo-located content that can be created, viewed, changed, and interacted with by users in the same or different sessions; ephemeral content; local creation and posting of content; remote creation and posting of content; remote visualization, altering, and placing content on a 3D map; filtering and management of content in the camera view based on a visibility layer/similar theme and content priority based on preferences, categorization, and ownership; automated creation and posting; lighting of content and digital environments; linking of point clouds with real-world geo-coordinates for accurate map construction; and the security of property and content rights and ownership via smart contracts on a blockchain.","['A63F13/213', 'G06T19/20', 'A63F13/216', 'A63F13/63', 'A63F13/65', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06T15/06', 'G06T15/50', 'G06T19/006', 'H04L9/0637', 'H04L9/0894', 'H04L9/3239', 'H04L9/3297', 'H04L9/50', 'G06T2200/08', 'G06T2210/56', 'G06T2215/12', 'G06T2219/2004', 'H04L2209/38', 'H04L63/102']"
US11624795B2,Systems and methods for improving low dose volumetric contrast-enhanced MRI,"Methods and systems are provided for improving model robustness and generalizability. The method may comprise: acquiring, using a medical imaging apparatus, a medical image of a subject; reformatting the medical image of the subject in multiple scanning orientations; applying a deep network model to the medical image to improve the quality of the medical image; and outputting an improved quality image of the subject for analysis by a physician.","['G06T7/0014', 'G01R33/5608', 'A61B5/0033', 'A61B5/055', 'G01R33/5601', 'G06T11/005', 'G06T11/008', 'G06T19/20', 'G06T3/60', 'G06T5/50', 'G06T5/60', 'G06T5/90', 'G06T7/337', 'G06T7/62', 'G06T2207/10088', 'G06T2207/20084', 'G06T2207/20216', 'G06T2207/30004', 'G06T2207/30016', 'G06T2207/30096', 'G06T2219/2016']"
CN109948693B,Hyperspectral image classification method based on superpixel sample expansion and generation countermeasure network,"The invention provides a hyperspectral image classification method based on superpixel sample expansion and generation confrontation network, and aims to solve the problem of low classification accuracy caused by overfitting of the network when the number of labeled training samples is small. The implementation is as follows: constructing an initial training set and a test set, and expanding to obtain an expanded training set and a candidate test set; constructing a generation countermeasure network consisting of a generator and a discriminator; generating a false sample by using a generator, and acquiring a false sample and a true and false prediction label and a category prediction label of an extended training set by using a discriminator; constructing loss functions of a generator and a discriminator, and alternately training the generator and the discriminator; training a support vector machine; passing the candidate test set through a trained discriminator and a support vector machine to obtain a candidate label set; a maximum voting algorithm is used on the candidate set of tags to determine the category tags of the test set. The method effectively extracts the spatial features of the hyperspectral images, alleviates the over-fitting problem, improves the classification accuracy, and can be used for classifying the ground objects of the hyperspectral images.",[]
US12008478B2,Systems and methods for training generative models using summary statistics and other constraints,"Systems and methods for training and utilizing constrained generative models in accordance with embodiments of the invention are illustrated. One embodiment includes a method for training a constrained generative model. The method includes steps for receiving a set of data samples from a first distribution, identifying a set of constraints from a second distribution, and training a generative model based on the set of data samples and the set of constraints.","['G06N3/088', 'G06F18/211', 'G06F18/24133', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/094', 'G06N7/08', 'G06N5/046', 'G06N7/01']"
US11645497B2,System and method for augmented reality using conditional cycle-consistent generative image-to-image translation models,"Systems and methods relate to a network model to apply an effect to an image such as an augmented reality effect (e.g. makeup, hair, nail, etc.). The network model uses a conditional cycle-consistent generative image-to-image translation model to translate images from a first domain space where the effect is not applied and to a second continuous domain space where the effect is applied. In order to render arbitrary effects (e.g. lipsticks) not seen at training time, the effect's space is represented as a continuous domain (e.g. a conditional variable vector) learned by encoding simple swatch images of the effect, such as are available as product swatches, as well as a null effect. The model is trained end-to-end in an unsupervised fashion. To condition a generator of the model, convolutional conditional batch normalization (CCBN) is used to apply the vector encoding the reference swatch images that represent the makeup properties.","['G06N3/045', 'G06F3/011', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T11/60', 'G06T19/006', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084']"
CN112465718B,A Two-Stage Image Inpainting Method Based on Generative Adversarial Networks,"The invention provides a two-stage image restoration method based on a generation countermeasure network, and relates to the technical field of computer vision. According to the method, the two-stage generation confrontation network model is constructed, the accurate repair of large-area damaged images is realized through the edge-first and integral repair method, the generation confrontation network is utilized, the problem is simplified into end-to-end model training, the traditional convolutional layer is replaced by adding the Ghost module, and the SE module is intermittently inserted, so that the network performance is improved, the network parameters and the calculated amount are obviously reduced, meanwhile, the mixed precision training is used in the training, the convergence speed of the network is improved, and the network performance is improved.","['G06T5/77', 'G06F18/214', 'G06N3/045', 'G06N3/08']"
US10713569B2,System and method for generating improved synthetic images,"System, methods, and other embodiments described herein relate to improving the generation of realistic images. In one embodiment, a method includes acquiring a synthetic image including identified labels of simulated components within the synthetic image. The synthetic image is a simulated visualization and the identified labels distinguish between the components within the synthetic image. The method includes computing, from the simulated components, translated components that visually approximate real instances of the simulated components by using a generative module comprised of neural networks that are configured to separately generate the translated components. The method includes blending the translated components together to produce a new image from the simulated components of the synthetic image.","['G06N3/088', 'G06N3/084', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US11501001B2,Techniques to detect perturbation attacks with an actor-critic framework,"Embodiments discussed herein may be generally directed to systems and techniques to generate a quality score based on an observation and an action caused by an actor agent during a testing phase. Embodiments also include determining a temporal difference between the quality score and a previous quality score based on a previous observation and a previous action, determining whether the temporal difference exceeds a threshold value, and generating an attack indication in response to determining the temporal difference exceeds the threshold value.","['G06F21/577', 'G06F21/552', 'G06F21/566', 'G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/08', 'G06N3/092', 'G06N5/043', 'G06F2221/034']"
US11354764B2,System and method for monitoring electronic communications,"A method for monitoring mobile communication and generating alerts associated with targeted content. A monitored user's mobile communication device forwards an incoming or outgoing communication to a monitoring user's mobile communication device. The monitored user's or monitoring user's mobile communication device generates an alert if it is determined that the incoming or outgoing communication contains targeted content, and an alert is provided on the monitoring user's mobile communication device.","['G06Q50/265', 'H04L51/21', 'H04L67/535', 'H04W4/00', 'H04W4/16', 'H04W4/12', 'H04W4/14', 'H04W4/21']"
AU2019202063B2,Synthesizing new font glyphs from partial observations,"OF THE DISCLOSURE Techniques are disclosed for the synthesis of a full set of slotted content, based upon only partial observations of the slotted content. With respect to a font, the slots may comprise particular letters or symbols or glyphs in an alphabet. Based upon partial observations of a subset of glyphs from a font, a full set of the glyphs corresponding to the font may be synthesized and may further be ornamented. 1/18 en sGlyphShape Subse 104 JointlySynthesize All G G phhape r Test/Inference 106 Jointly Perform Ornamentation All Glyph Shapes 108 FIG.la","['G06T11/203', 'G06F40/109', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/40', 'G06T11/60']"
WO2021113881A1,Secure computing hardware apparatus,"A secure computing hardware apparatus includes at least a secret generator module, the at least a secret generator module configured to generate a module-specific secret, and a device identifier circuit communicatively connected to the at least a secret generator, the device identifier circuit configured to produce at least an output comprising a secure proof of the module-specific secret. Secret generator module may implement one or more physically unclonable functions to generate the module-specific secret.","['H04L9/3218', 'G06F21/62', 'G06F21/73', 'G06F21/75', 'H04L9/085', 'H04L9/0866', 'H04L9/3247', 'H04L9/3278', 'G06F2221/2143', 'H04L2209/42', 'H04L2209/46']"
US20210342977A1,"Method And Apparatus For Image Restoration, Storage Medium And Terminal","The present disclosure provides an method and apparatus for image restoration, a storage medium and a terminal. The method includes: acquiring a to-be-processed image including biometric information; inputting the to-be-processed image into a generator, wherein the generator comprises a neural network model with a plurality of convolutional layers, and a weight of a convolutional kernel of the generator is determined at least according to a quality of an image historically restored by the generator; and restoring the to-be-processed image by the generator to acquire a restored image. The present disclosure can effectively improve a restoration quality when performing image restoration based on machine learning.","['G06T5/77', 'G06V40/1347', 'G06T5/001', 'G06K9/6298', 'G06N3/045', 'G06N3/08', 'G06T5/006', 'G06T5/009', 'G06T5/60', 'G06T5/80', 'G06T5/92', 'G06V10/82', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088', 'G06T2207/30168', 'G06T2207/30196']"
US11574199B2,Generative adversarial network device and training method thereof,"A generative adversarial network device and a training method thereof. The generative adversarial network device includes a generator and a discriminator. The generator is configured to generate a first sample according to an input data; the discriminator is coupled to the generator, and is configured to receive the first sample and be trained based on the first sample; the generator includes a first memristor array serving as a first weight array. The generative adversarial network device can omit a process of adding noise to fake samples generated by the generator, thereby saving training time, reducing resource consumption and improving training speed of the generative adversarial network.","['G06N3/088', 'G06N3/084', 'G06N3/061', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/065', 'G06N3/094']"
CN108537743B,A Facial Image Enhancement Method Based on Generative Adversarial Networks,"The invention discloses a face image enhancement method based on a generation countermeasure network, which comprises the following steps: 1. preprocessing the face images of multiple postures by using a 3D dense face alignment method; 2. the design is based on a face enhancement network that generates a countermeasure network, two steps of which generate the countermeasure network. 3. Designing an objective function 4 corresponding to Step-I and Step-II according to task needs, pre-training an identification model by using MS-1-celeb, and pre-training a TS-GAN model by using amplification data; 5. and (5) using the Multi-PIE as a training set, and training the TS-GAN model parameters which are subjected to pre-training in the step (4) by using a back propagation algorithm until convergence. And obtaining a front face image corresponding to the input image by using the finally trained TS-GAN model, and simultaneously keeping original illumination and real visual degree of the image and original identity information.","['G06T5/73', 'G06T7/33', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US20230041233A1,"Image recognition method and apparatus, computing device, and computer-readable storage medium","An image recognition method includes: obtaining a to-be-recognized image; determining whether the image is a forged image by recognizing the image through a trained generative adversarial network, the generative adversarial network including a generator and a classifier. Training the classifier includes: obtaining an original image group having a plurality of original images, and a category label of each original image. Each of the plurality of original images includes a real image and a forged image corresponding to the real image. The method includes obtaining using the classifier, for a respective original image of the plurality of original images, first-type noise corresponding to the respective original image; inputting the respective original image into the generator to obtain an output of the generator, and obtaining second-type noise corresponding to the respective original image as the output; and training the classifier using the respective original image, the first-type noise, and the second-type noise.","['G06V40/40', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'G06V10/774', 'G06V10/82', 'G06V40/172', 'Y02T10/40']"
WO2020029356A1,Method employing generative adversarial network for predicting face change,"A method employing generative adversarial network for predicting a face change, comprising: S1 of acquiring face data samples; S2 of constructing a generative adversarial network model consisting of a generator and a discriminator, designing a loss function, and performing iterative training on the generator and the discriminator; and S3 of inputting a target young face image to be processed into the trained generative adversarial network model, and outputting a target aged face image corresponding to the target young face image. The method is adopted to construct a unique generative adversarial network model and loss function, provides robustness for aging, and accounts for change information including the forehead, hair, and the like, thereby improving the accuracy and uniqueness of prediction.","['G06V40/161', 'G06V40/168']"
US10210631B1,Generating synthetic image data,"According to an aspect, a method comprises: generating a 2D projection from a 3D representation of an object, generating, based on the 2D projection, a simulated image of the object, wherein the simulated image appears as though the object has been scanned by a detection device, combining the simulated object with a background image to form a synthesized image, wherein the background image was captured by a detection device, and outputting the synthesized image.","['G06T11/003', 'G01V5/00', 'G06T15/503', 'G06T17/30', 'G06T7/12', 'G06T9/002']"
US11507822B2,Scalable artificial intelligence model generation systems and methods for healthcare,"Systems and methods to generate artificial intelligence models with synthetic data are disclosed. An example system includes a deep neural network (DNN) generator to generate a first DNN model using first real data. The example system includes a synthetic data generator to generate first synthetic data from the first real data, the first synthetic data to be used by the DNN generator to generate a second DNN model. The example system includes an evaluator to evaluate performance of the first and second DNN models to determine whether to generate second synthetic data. The example system includes a synthetic data aggregator to aggregate third synthetic data and fourth synthetic data from a plurality of sites to form a synthetic data set. The example system includes an artificial intelligence model deployment processor to deploy an artificial intelligence model trained and tested using the synthetic data set.","['G06T7/0012', 'G06N3/084', 'G06F11/3447', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06T7/0002', 'G16H30/20', 'G16H50/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US20230320642A1,"Systems and methods for techniques to process, analyze and model interactive verbal data for multiple individuals","Disclosed are methods, systems, and other implementations for processing, analyzing, and modelling psychotherapy data. The implementations include a method for analyzing psychotherapy data that includes obtaining transcript data representative of spoken dialog in one or more psychotherapy sessions conducted between a patient and a therapist, extracting speech segments from the transcript data related to one or more of the patient or the therapist, applying a trained machine learning topic model process to the extracted speech segments to determine weighted topic labels representative of semantic psychiatric content of the extracted speech segments, and processing the weighted topic labels to derive a psychiatric assessment for the patient.","['A61B5/165', 'A61B5/4803', 'A61B5/7267', 'G06F40/279', 'G06F40/30', 'G10L15/063', 'G10L15/26', 'G10L17/02', 'G10L17/04', 'G10L17/14', 'G10L17/18', 'G10L17/22', 'G10L21/028', 'G10L25/66', 'G16H10/20', 'G16H20/70', 'G16H50/20', 'G10L21/0272']"
US12056605B2,System and method for improved neural network training,"A system, electronic device and method for improved neural network training are provided. The electronic device includes: a processor, a memory storing a Generative adversarial network (GAN) to learn from unlabeled data by engaging a generative model in an adversarial game with a discriminator; and one or more programs stored in the memory and configured to be executed by the one or more processors, the one or more programs including instructions for training the Generative adversarial network using a regularizer to encourage the discriminator to properly use its capacity and hidden representations of the discriminator to have high entropy.","['G06N3/08', 'G06F18/2148', 'G06F18/217', 'G06F18/24133', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/0895', 'G06N3/094', 'G06N7/01', 'G06V10/764', 'G06V10/776', 'G06V10/82']"
US20220245775A1,Tone mapping method and electronic device,"A tone mapping method is provided. This method includes: obtaining one or a plurality of high dynamic range images, and determining a storage format of each high dynamic range image; performing an image decomposition on the high dynamic range image to obtain a first component, a second component and a third component, when the storage format of the high dynamic range image is determined as a predetermined storage format; inputting the first component and the second component into a predetermined deep neural network, and using the deep neural network to perform mapping on the first component and the second component respectively to obtain a first mapped component and a second mapped component; and fusing the first mapped component and the second mapped component with the third component to obtain a fused low dynamic range image corresponding to the high dynamic range image.","['G06T5/009', 'G06T3/04', 'G06T5/92', 'G06N3/045', 'G06N3/0454', 'G06T5/50', 'G06T5/60', 'G06N3/088', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208', 'G06T2207/20221']"
CN110930367B,Multimodal ultrasound image classification method and breast cancer diagnosis device,"The invention provides a multi-modal ultrasound image classification method and a breast cancer diagnosis device, comprising the following steps: s1, segmenting an interested area image from an original gray-scale ultrasonic-elastography image pair, and obtaining a pure elastography image according to the segmented interested area image; s2, extracting the single-mode image characteristics of the gray-scale ultrasonic image and the elastic imaging image by using a DenseNet network; s3, constructing a resistance loss function and an orthogonality constraint function, and extracting shared characteristics between the gray-scale ultrasonic image and the elastic imaging image; and S4, constructing a multi-task learning framework, splicing the inter-modal shared features obtained in the S3 and the single-modal features obtained in the S2, inputting the inter-modal shared features and the single-modal shared features into a plurality of classifiers together, and classifying the good and the bad respectively. The invention can simultaneously classify the quality and the malignancy of the gray-scale ultrasonic image, the elasticity imaging image and the two mode images, and has the excellent performances of high accuracy and wide application range.","['G06T7/0012', 'G06T7/11', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068']"
US11146463B2,Predicting network states for answering what-if scenario outcomes,"In one embodiment, a device constructs a set of controlled what-if input parameters for evaluating a what-if scenario in a network. The device uses the set of controlled what-if input parameters and state data indicative of a current state of the network as input to a network state model. The network state model predicts values for the state data conditioned on the what-if input parameters. The device predicts a key performance indicator (KPI) in the network by using the predicted values for the state data from the network state model as input to a machine learning-based KPI prediction model. The device initiates a routing change in the network based in part on the predicted KPI.","['H04L41/5009', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'H04L12/4633', 'H04L12/4641', 'H04L41/0663', 'H04L41/147', 'H04L41/16', 'H04L41/5025', 'H04L45/08', 'H04L45/22', 'H04L45/28', 'H04L45/64', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N7/01', 'H04L41/40', 'H04L43/0817', 'H04L43/0852']"
US10970829B2,Synthesizing and segmenting cross-domain medical images,Systems and methods for generating synthesized images are provided. An input medical image of a patient in a first domain is received. A synthesized image in a second domain is generated from the input medical image of the patient in the first domain using a first generator. The first generator is trained based on a comparison between segmentation results of a training image in the first domain from a first segmentor and segmentation results of a synthesized training image in the second domain from a second segmentor. The synthesized training image in the second domain is generated by the first generator from the training image in the first domain. The synthesized image in the second domain is output.,"['G06V10/774', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/006', 'G06T5/50', 'G06T5/80', 'G06T7/11', 'G06T7/174', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'A61B6/032', 'A61B6/5247', 'A61B6/563', 'A61B8/5261', 'G06K2209/05', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20212', 'G06T2207/30004', 'G06V2201/03']"
CN112801900B,Video blurring removal method for generating countermeasure network based on bidirectional circular convolution,"The invention discloses a video blur removal method for generating an countermeasure network based on bidirectional circular convolution, which comprises the following steps: step one: generating a high-quality blur-removed restored video by using a clear video generation network; step two: classifying and judging the restored video and the reference clear video by utilizing a judging network; step three: constructing a loss function to train two networks, namely a clear video generation network and a discrimination network; and (3) outputting: and processing the blurred video by using the trained clear video generation network. The method takes the generated countermeasure network as a basic framework, and utilizes the time sequence relationship contained in the two paths of circulating neural network sequences for transmitting information along different directions; a fusion reconstruction module is introduced to reconstruct the current frame, and the global residual error connection is utilized to improve the network expression capacity and the convergence rate; the network is trained with content loss and countermeasures loss. The invention can be combined with various image and video application systems, helps to improve the quality of the shot video, and has wide market prospect and application value.","['G06T5/73', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'Y02T10/40']"
US20200410399A1,"Method and system for determining policies, rules, and agent characteristics, for automating agents, and protection","A method of automatically configuring an action determination model includes determining an environment model, determining an action determination model that indicates an action option, determining whether the action determination model indicates a next action option, and if so, determining an action based on the action determination model, simulating execution of the action across the environment model, obtaining a simulated result, adjusting the action determination model. Then, until environment or an agent reach an end state, the following are repeated: determining whether the action determination model indicates the next action option, and if so, determining the action based on the action determination model, simulating the execution of the action across the environment model, obtaining the simulated result, and adjusting the action determination model.","['G06N3/006', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'G06N5/025', 'G06N5/04', 'G06N7/005', 'G06N7/01']"
EP3579196A1,"Human clothing transfer method, system and device","There is provided a method and system comprising determining in a first image a person and a first 3D human pose and body shape fitting model, wherein the person has a first pose and a first clothing, determining in a second image a person and a second 3D human pose and body shape fitting model, wherein the person has a second pose and a second clothing, and generating, by use of the first 3D human pose and body shape fitting model and by use of the second 3D human pose and body shape fitting model, an image comprising the person of the first image in the first pose and with the second clothing and/or generating, by use of the first 3D human pose and body shape fitting model and by use of the second 3D human pose and body shape fitting model, an image comprising the person of the second image in the second pose and with the first clothing.","['G06T19/00', 'G06F18/214', 'G06T13/40', 'G06T17/20', 'G06T19/20', 'G06T7/11', 'G06V40/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2210/16', 'G06T2219/2012']"
US11494661B2,Intelligent time-series analytic engine,"Implementations include receiving two or more time-series data sequences representative of a target process executed within a physical environment, executing automated time-series process segmentation to provide a plurality of subsequence segments for each of the two or more time-series data sequences, each subsequence segment corresponding to a phase of the target process, processing the two or more subsequence segments using at least one time-series transformation to provide a feature data set for each subsequence segment, applying each feature data set to provide time-series models for anomaly detection and forecasting, respectively, each time-series model being provided as one of a recurrent neural network (RNN), a convolution neural network (CNN), and a generative adversarial network (GAN), determining anomaly scores based on the time-series models, and selectively providing an alert to one or more users, each alert indicating at least one anomaly and a respective probability.","['G06N3/088', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985']"
US11804074B2,Method for recognizing facial expressions based on adversarial elimination,"The present disclosure relates to a method for recognizing facial expressions based on adversarial elimination. First, a facial expression recognition network is built based on a deep convolutional neural network. On a natural facial expression data set, the facial expression recognition network is trained through a loss function to make facial expression features easier to distinguish. Then some key features of input images are actively eliminated by using an improved confrontation elimination method to generate a new data set to train new networks with different weight distributions and feature extraction capabilities, forcing the network to perform expression classification discrimination based on more features, which reduces the influence of interference factors such as occlusion on the network recognition accuracy rate, and improving the robustness of the facial expression recognition network. Finally, the final expression classification predicted results are obtained by using network integration and a relative majority voting method.","['G06V10/809', 'G06V40/174', 'G06F18/2148', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T3/4007', 'G06V10/817', 'G06V10/82', 'G06V40/168', 'G06V40/169', 'G06V40/172']"
US11734565B2,Systems and methods of training neural networks against adversarial attacks,"Embodiments disclosed herein describe systems, methods, and products that generate trained neural networks that are robust against adversarial attacks. During a training phase, an illustrative computer may iteratively optimize a loss function that may include a penalty for ill-conditioned weight matrices in addition to a penalty for classification errors. Therefore, after the training phase, the trained neural network may include one or more well-conditioned weight matrices. The one or more well-conditioned weight matrices may minimize the effect of perturbations within an adversarial input thereby increasing the accuracy of classification of the adversarial input. By contrast, conventional training approaches may merely reduce the classification errors using backpropagation, and, as a result, any perturbation in an input is prone to generate a large effect on the output.","['G06F21/57', 'G06N3/08', 'G06F18/214', 'G06F18/24', 'G06F21/577', 'G06N3/0464', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N5/046', 'G06V10/82']"
US12137230B2,"Method and apparatus for applying deep learning techniques in video coding, restoration and video quality analysis (VQA)","Video quality analysis may be used in many multimedia transmission and communication applications, such as encoder optimization, stream selection, and/or video reconstruction. An objective VQA metric that accurately reflects the quality of processed video relative to a source unprocessed video may take into account both spatial measures and temporal, motion-based measures when evaluating the processed video. Temporal measures may include differential motion metrics indicating a difference between a frame difference of a plurality of frames of the processed video relative to that of a corresponding plurality of frames of the source video. In addition, neural networks and deep learning techniques can be used to develop additional improved VQA metrics that take into account both spatial and temporal aspects of the processed and unprocessed videos.","['H04N19/154', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G06T3/4046', 'G06T5/00', 'G06T7/0002', 'G06T7/254', 'G06T9/002', 'H04N19/103', 'H04N19/107', 'H04N19/124', 'H04N19/172', 'H04N19/174', 'H04N19/176', 'H04N19/19', 'H04N19/567', 'H04N21/23418', 'H04N21/2343', 'H04N21/236', 'G06N3/044', 'G06N5/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30168']"
US12033374B2,"Image processing method, apparatus, and device, and storage medium","An image processing method is provided. The image processing method includes: acquiring first second input images; extracting a content feature of the first input image; extracting an attribute feature of the second input image; performing feature fusion and mapping processing on the content feature of the first input image and the attribute feature of the second input image by using a feature transformation network to obtain a target image feature, the target image feature having the content feature of the first input image and the attribute feature of the second input image; and generating an output image based on the target image feature.","['G06V10/7747', 'G06V10/462', 'G06F18/213', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06V10/761', 'G06V10/7715', 'G06V10/776', 'G06V10/806', 'G06V10/82']"
CN109035142B,A satellite image super-resolution method based on adversarial network combined with aerial image priors,"The invention discloses a satellite image super-resolution method combining an antagonistic network with aerial image prior, which comprises the steps of firstly training a denoising model by using an image pair formed by a 16-level noise-containing image and a corresponding 16-level noise-free image, and then training the image super-resolution model by using clear aerial data. Because the satellite image and the aerial image do not exist in the condition of being paired, when the generated super-resolution image is subjected to image post-processing, the clear aerial image is adopted to construct the external prior dictionary of the GMM model, and the satellite image with unclear interior is guided to be reconstructed. And after reconstruction, in order to further improve the image quality, sharpening the image by using a Gaussian filtering mode. And finally, obtaining a high-resolution image of the original satellite image, and realizing the improvement of the image visual quality on the basis of the original satellite image. The effectiveness of the scheme can be seen from the experimental links. An effective idea is provided for solving the problems of satellite image super-resolution and image quality improvement under the condition of conditional limitation in reality.",['G06T3/4053']
US10430685B2,Deep multi-scale video prediction,"In one embodiment, a method includes receiving a plurality of input frames of a video sequence associated with a time t, training a convolutional network to predict one or more future frames of the video sequence from the plurality of input frames based on a generative model, and outputting a first future frame of the video sequence associated with a time t+1 as predicted by the generative model. The training may comprise using an adversarial model and an image gradient difference loss model. In addition, the training may comprise randomly selecting temporal sequences of a n×m grid of pixels from the plurality of input frames exhibiting a threshold of optical flow.","['G06K9/6212', 'G06N3/084', 'G06F18/21', 'G06K9/00718', 'G06K9/4628', 'G06K9/6217', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06N7/005', 'G06N7/01', 'G06V10/454', 'G06V10/758', 'G06V10/82', 'G06V20/41', 'G06K2009/00738', 'G06N3/048', 'G06Q50/01', 'G06V20/44']"
US20230104945A1,Systems and methods for image processing,Systems and methods for image processing are provided. The systems may include obtaining an initial image relating to a blood vessel. The system may include determining a centerline of the blood vessel based on the initial image. The system may also include determining one or more images to be segmented of the blood vessel based on the centerline and the initial image. The system may also include determining a boundary of the lumen of the blood vessel and a boundary of the wall of the blood vessel in the each image for each of the one or more images. The system may further include analyzing the blood vessel based on the one or more boundaries of the lumen and the one or more boundaries of the wall.,"['G06T7/0012', 'G06T7/12', 'A61B6/504', 'G06T2207/10072', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20084', 'G06T2207/30101', 'G06T2207/30172']"
US11270476B2,Method and system for providing photorealistic changes for digital image,"Disclosed is a computer-implemented method for providing photorealistic changes for a digital image. The method includes receiving a digital image of dressable model, receiving digital cutout garment textures that are indexed according to an outfitting layering order and aligned with body shape and pose of the dressable model, receiving binary silhouettes of the digital cutout garment textures, generating a garment layer index mask by compositing the binary silhouettes of the digital cutout garment textures indexed according to the outfitting layering order, receiving a composite image obtained by overlaying the digital cutout garment textures according to the indexed outfitting layering order on the digital image of the dressable model, inputting the composite image and the garment layer index mask into a machine learning system for providing photorealistic changes, and receiving from the machine learning system a digital file including photorealistic changes for application to the composite image.","['G06T11/00', 'G06T15/50', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06Q30/0643', 'G06T11/001', 'G06T15/60', 'G06T3/0093', 'G06T3/18', 'G06T7/11', 'G06T7/194', 'G06T2207/20081', 'G06T2210/16']"
CN113228194B,A multi-omics search engine for integrated analysis of cancer genomic and clinical data,"Methods for tumor profiling using multiple sets of mathematical data indices are provided. The method may include storing a plurality of multiple-set of chemical data indices, wherein each of the plurality of multiple-set of chemical data indices includes cancer-specific tokenization data; ingest additional sets of mathematical data, and any annotations associated with the additional sets of mathematical data, the additional sets of mathematical data being related to one or more indices; indexing the ingested additional sets of chemical data and annotations while preserving in a particular index the sets of chemical mapping between gene names, gene variant names, and different data streams for the same patient to produce tokenized ingested additional sets of chemical data; receiving a user query; selecting one or more related multiple-study data indices based on the user query; ranking the selected one or more multiple sets of mathematical data indices based on at least one of clinical operability, pathogenicity, feature weight, or frequency; and returning the ranked one or more multiple-study data indices to the user.","['G16H50/70', 'G16H50/20', 'G06F16/2272', 'G06F16/24578', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G16B40/20', 'G16H30/40', 'G16H70/60', 'Y02A90/10']"
US11640704B2,Generating and using synthetic training data for plant disease detection,"Implementations are described herein for automatically generating synthetic training images that are usable, for instance, as training data for training machine learning models to detect and/or classify various types of plant diseases at various stages in digital images. In various implementations, one or more environmental features associated with an agricultural area may be retrieved. One or more synthetic plant models may be generated to visually simulate one or more stages of a progressive plant disease, taking into account the one or more environmental features associated with the agricultural area. The one or more synthetic plant models may be graphically incorporated into a synthetic training image that depicts the agricultural area.","['G06V10/774', 'G06F18/214', 'G06K9/6256', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T7/0012', 'G06V10/82', 'G06V20/188', 'G06V20/20', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30188']"
TWI782597B,"Systems, products, and methods for adjusting a patterning process","Generating a control output for a patterning process is described. A control input is received. The control input is for controlling the patterning process. The control input comprises one or more parameters used in the patterning process. The control output is generated with a trained machine learning model based on the control input. The machine learning model is trained with training data generated from simulation of the patterning process and/or actual process data. The training data comprises 1) a plurality of training control inputs corresponding to a plurality of operational conditions of the patterning process, where the plurality of operational conditions of the patterning process are associated with operational condition specific behavior of the patterning process over time, and 2) training control outputs generated using a physical model based on the training control inputs.","['G03F7/705', 'G03F7/70508', 'G03F7/70525', 'G03F7/70633', 'G03F7/7065', 'G03F7/706837', 'G03F7/706841', 'G03F7/70875', 'G06N3/02']"
US12363253B2,Realistic personalized style transfer in image processing,"Computerized systems are provided for applying data indicative of a personal style to a feature of a user represented in one or more images based on determining or estimating the personal style. In operation, embodiments can receive a first image of a first user that indicates the personal style of the first user. The first image can then be fed to one or more machine learning models in order to learn and capture the personal style of the first user. Subsequently, some embodiments capture the first user in another image or set of images. Some embodiments can then detect one or more features of the first user in these other images and based on the determining of the user's personal style in the first image, can apply data indicative of the personal style of the first user to the one or more features of the user in these other images.","['G06T11/00', 'H04N5/272', 'G06F18/211', 'G06N20/00', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/73', 'G06T2207/20084', 'H04N2005/2726']"
US12299385B2,Machine content generation,"Computerized systems and methods are disclosed to generate a document from one or more first and second text prompts, generating one or more context-sensitive text suggestions using a transformer with an encoder on the text prompts and a decoder that produces a text expansion to provide the context-sensitive text suggestions based on the one or more first and second text prompts by applying generative artificial intelligence with token biased weights for zero-shot, one-shot or some-shot generation of the artificial intelligence context-sensitive text suggestions from the one or more first and second text prompts.","['G06F21/1015', 'G06F21/32', 'G06F40/137', 'G06F40/169', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'G06F21/105', 'G06F40/30']"
US11719821B2,Method for object avoidance during autonomous navigation,"A method for autonomous navigation of an autonomous vehicle includes: accessing a first scan image containing data captured by a sensor on the autonomous vehicle at a first time; identifying a first group of points in the first scan image representing an object in a field proximal the autonomous vehicle; characterizing a first motion of the object at the first time based on the first group of points; characterizing an uncertainty of the first motion of the object at the first time; calculating a predicted second uncertainty of a second motion of the object at a second time based on the first motion of the object and motion of the autonomous vehicle at the first time; and, in response to the predicted second uncertainty falling below the uncertainty, muting the object from braking consideration for object avoidance by the autonomous vehicle at the second time.","['G01S17/89', 'B60W10/18', 'B60W30/09', 'B60W30/0956', 'B60W30/146', 'B60W30/181', 'B60W40/068', 'B60W40/105', 'B60W60/0011', 'G01S17/58', 'G01S17/931', 'G06V10/25', 'G06V20/58', 'G06V20/64', 'G08G1/04', 'G08G1/165', 'G08G1/166', 'B60W2420/408', 'B60W2420/52', 'B60W2552/40', 'B60W2554/4041', 'B60W2554/4042', 'B60W2554/4043', 'B60W2554/80', 'B60Y2300/0954', 'G06V2201/12']"
CN111798400B,Reference-free low-light image enhancement method and system based on generative adversarial network,"The invention relates to a generation countermeasure network-based no-reference low-illumination image enhancement method and a system, wherein the method comprises the following steps: respectively preprocessing a low-illumination image and a normal-illumination image with original resolution to obtain an unpaired low-illumination image block and a normal-illumination image block for training; constructing a generator network for low-light enhancement and a discriminator network for countermeasure training; alternately training a generator network and a discriminator network to converge to Nash balance by using the low-illumination image blocks and the normal-illumination image blocks; the original low-light image for testing is input into a trained generator network to predict its enhanced image. The method and the system are beneficial to improving the quality of low-illumination image enhancement.","['G06T5/92', 'G06N3/045', 'G06N3/084', 'G06T7/90']"
US10121104B1,System and method for anomaly detection via a multi-prediction-model architecture,"In some embodiments, anomaly detection may be facilitated via a multi-neural-network architecture. In some embodiments, a first neural network may be configured to generate hidden representations of data items corresponding to a concept. A second neural network may be configured to generate reconstructions of the data items from the hidden representations. The first neural network may be configured to assess the reconstructions against the data items and update configurations of the first neural network based on the assessment of the reconstructions. Subsequent to the update of the first neural network, the first neural network may generate a hidden representation of a first data item from the first data item. The second neural network may generate a reconstruction of the first data item from the hidden representation. An anomaly in the first data item may be detected based on differences between the first data item and the reconstruction.","['G06N3/08', 'G06N3/084', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0475', 'G06N3/0499', 'G06N3/09', 'G06N3/094']"
CN112673378B,"Device for generating estimator, monitoring device, method for generating estimator, and program for generating estimator","The present invention provides a technique for generating an estimator capable of estimating the state of a subject person with higher accuracy. An estimator generating apparatus according to an aspect of the present invention trains a first estimator having an encoder common to each other and a second estimator to derive a state of a subject from face image data, and trains a second estimator to reproduce physiological data from the face image data. By means of this machine learning, the parameters of the common encoder are made to approach a local solution with higher accuracy in estimating the state of the subject person, thereby generating an estimator capable of estimating the state of the subject person with higher accuracy.","['B60W40/09', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V20/597', 'G06V40/174', 'G06V40/70', 'B60W2040/0872', 'B60W2540/22', 'G06N3/047', 'G06V40/15']"
CN113378906B,A feature-adaptive alignment method for unsupervised domain-adaptive remote sensing image semantic segmentation,"The invention provides a deep learning unsupervised domain adaptive remote sensing image semantic segmentation method based on an antagonistic learning framework. The method generally comprises a semantic Segmentation model (Segmentation model) and a Domain discriminator (Domain discriminator), a Pythrch deep learning framework is adopted for training, and the Domain discriminator is used for completing the alignment of target Domain features extracted by the Segmentation model to source Domain features in an output space, so that the Segmentation performance of the Segmentation model on a target Domain image can be improved. According to the characteristics of different types and severe change of different regions of the remote sensing image, a class-specific module (CCM) and an entropy-based region attention module (ERAM) are added into a domain discriminator. Both enable features of different classes, different regions to be adaptively aligned together in an appropriate manner in the output space to the feature distribution of the source domain.","['G06F18/2415', 'G06F18/217', 'G06N3/08']"
US10852379B2,Artifact reduction by image-to-image network in magnetic resonance imaging,"For artifact reduction in a magnetic resonance imaging system, deep learning trains an image-to-image neural network to generate an image with reduced artifact from input, artifacted MR data. For application, the image-to-image network may be applied in real time with a lower computational burden than typical post-processing methods. To handle a range of different imaging situations, the image-to-image network may (a) use an auxiliary map as an input with the MR data from the patient, (b) use sequence metadata as a controller of the encoder of the image-to-image network, and/or (c) be trained to generate contrast invariant features in the encoder using a discriminator that receives encoder features.","['G01R33/5608', 'G01R33/565', 'G01R33/4818', 'G01R33/56509', 'G06T11/008', 'G01R33/56518', 'G06T2210/41']"
US20210224997A1,"Image processing apparatus, image processing method and computer-readable medium","An image processing apparatus is provided that includes: an obtaining unit configured to obtain a first medical image of a subject; and an image quality improving unit configured to generate a second medical image with image quality higher than image quality of different regions including a first region and a second region that is different from the first region in the obtained first image, using the obtained first image as input data that is input into a learned model.","['G06T7/0012', 'A61B3/0025', 'A61B3/0033', 'A61B3/005', 'A61B3/102', 'G06T5/001', 'G06T5/50', 'G06T5/60', 'G06T5/90', 'G06T7/0014', 'G06T7/12', 'G06T2200/04', 'G06T2207/10101', 'G06T2207/20032', 'G06T2207/20056', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/30041', 'G06T2207/30168']"
CN110189253B,Image super-resolution reconstruction method based on improved generation countermeasure network,"An image super-resolution reconstruction method based on an improved generation countermeasure network comprises the following steps: 1) Collecting a large number of 2k pixel high-quality pictures, intercepting a large number of HR blocks from the pictures, and obtaining corresponding LR blocks in a 4-time downsampling mode to construct a training data set. 2) And establishing a generated confrontation network model, wherein a generator network G adopts a residual error network, and a condition discriminator D also adopts the residual error network. 3) And improving a training loss function for generating the confrontation network by using a concept of a relative discriminator, adding content loss in the generator loss function, adding a gradient penalty item based on false data in the discriminator loss function, and then using a processed training data set and adopting an Adam optimizer to carry out confrontation training on the network until the network converges. 4) And completing 4-time super-resolution reconstruction of the low-pixel image by a trained generator network.","['G06T3/4023', 'G06T3/4053', 'G06T2207/20081', 'G06T2207/20084']"
US20200394825A1,Virtual staining for tissue slide images,"A machine learning predictor model is trained to generate a prediction of the appearance of a tissue sample stained with a special stain such as an IHC stain from an input image that is either unstained or stained with H&E. Training data takes the form of thousands of pairs of precisely aligned images, one of which is an image of a tissue specimen stained with H&E or unstained, and the other of which is an image of the tissue specimen stained with the special stain. The model can be trained to predict special stain images for a multitude of different tissue types and special stain types, in use, an input image, e.g., an H&E image of a given tissue specimen at a particular magnification level is provided to the model and the model generates a prediction of the appearance of the tissue specimen as if it were stained with the special stain. The predicted image is provided to a user and displayed, e.g., on a pathology workstation.","['G06V20/69', 'G01N1/30', 'G06F18/214', 'G06K9/00127', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06T11/001', 'G06T7/0012', 'G06V10/774', 'G06V10/82', 'G06V20/695', 'G16H30/40', 'G01N2001/302', 'G06K2209/05', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2210/41', 'G06V2201/03']"
US11308657B1,Methods and systems for image processing using a learning engine,"Systems and methods are disclosed configured to train an autoencoder. A data training set is generated comprising images of different faces. A first autoencoder configuration is generated, comprising a first encoder, and a first decoder. The first autoencoder configuration is trained using dataset images, wherein weights associated with the first encoder and weights associated with the first decoder are modified. A second autoencoder configuration is generated comprising the first encoder and a second decoder. The second decoder is trained using a plurality of images of a first target face. First encoder weights are substantially maintained, and weights associated with the second decoder are modified. An autoencoder comprising the trained first encoder and the trained second decoder is used to generate an output using a source image of a first face having a facial expression, where the facial expression of the first face from the source image is applied to the first specific target face.","['G06T11/00', 'G06N3/084', 'G06F18/214', 'G06K9/00302', 'G06K9/6256', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06T5/50', 'G06T5/60', 'G06T5/77', 'G06V40/174', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30196', 'G06T2207/30201', 'G10L2021/0135', 'G10L21/013', 'G10L25/18', 'G10L25/30']"
CN113795834B,Techniques for modifying query images,"Described herein are computer-implemented techniques for performing an image-based search that allows a user to create a custom query image that expresses the user's search intent. The technique generates a query image based on one or more input images and/or one or more information items describing at least one desired characteristic of the query image. The technique then submits the query image to a search engine, and in response, receives a set of candidate images that match the query image. In one implementation, the technique constructs a query image using a decoder neural network that operates on mixed latent variable vectors. In one approach, the technique uses a Generated Antagonism Network (GAN) to generate a decoder neural network.","['G06F16/532', 'G06F16/54', 'G06F16/56', 'G06F16/583', 'G06F16/5846', 'G06F16/5862', 'G06F3/04855', 'G06N20/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094']"
US20200187841A1,System and Method for Measuring Perceptual Experiences,"There is provided a method for determining perceptual experiences. The method comprises obtaining a plurality of signals acquired by a measurement device comprising a plurality of sensors positioned to measure brain activity of users being measured by the measurement device; providing the plurality of signals, without pre-processing, to a processing system comprising at least one deep learning module, the at least one deep learning module being configured to process the signals to generate at least one capability, wherein combinations of one or more of the at least one capability form the perceptual experiences; and providing an output corresponding to a combination of one or more of the at least one capability to an application utilizing the corresponding perceptual experience.","['G16H50/20', 'A61B5/165', 'A61B5/0022', 'A61B5/04842', 'A61B5/04845', 'A61B5/11', 'A61B5/377', 'A61B5/378', 'A61B5/38', 'A61B5/4806', 'A61B5/6803', 'A61B5/7267', 'G06F3/015', 'G06F3/017', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G16H20/70', 'H04L67/12', 'A61B5/16', 'A61B5/369', 'G06F2203/011']"
US12101329B2,Network architecture providing device identification and redirection using whitelisting traffic classification,"Systems and methods include monitoring packets, by a network edge device, from one or more endpoint devices where the packets are destined for corresponding application services in a network; classifying the one or more endpoint devices based on the monitoring into a corresponding trust level of a plurality of trust levels; and, responsive to a first endpoint device of the one or more endpoint devices being untrusted, steering the packets from the first endpoint device into a restricted zone.","['G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'H04L63/101', 'H04L63/105', 'H04L63/1416', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
US10970854B2,Visual target tracking method and apparatus based on deep adversarial training,"A visual target tracking method and apparatus based on deep adversarial training. The method includes: dividing each video frame of video data into several search regions; for each of the search regions, inputting a target template and the search region into a response graph regression network, and outputting a response graph corresponding to a target; for each of the search regions, inputting the target template, the search region, and the response graph into a discrimination network, and outputting a score of the search region; and using positioning information corresponding to a search region with the highest score as positioning information of the target in the video frame. The method can track a target by constructing a plurality of search regions, and can effectively track the target having a change in length-width ratio. End-to-end processing can be achieved by combining the response graph regression network with the discrimination network.","['G06T7/74', 'G06F18/214', 'G06T11/20', 'G06T7/11', 'G06T7/246', 'G06T7/248', 'G06T7/97', 'G06V10/454', 'G06T2207/10016', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
CN109460015B,Unsupervised learning agents for autonomous driving applications,"Systems and methods for controlling a vehicle are provided. In one embodiment, a computer-implemented method is provided that includes training an autonomous driving agent, the method including the steps of: extracting, by a processor, information from the demonstration of the driving behavior using a neural network; transmitting the extracted information to a generator module; transmitting a real environment state associated with the demonstration of the driving behavior to the evaluator module; generating, by the processor, an environmental state interpretation from the extracted information using the generator module; training, by the processor, the discriminator module to better determine whether the generated interpretation of the environmental state corresponds to a real environmental state, while training, by the processor, the generator module to generate an improved interpretation of the environmental state for which the discriminator determines to correspond to a real environmental state; and the reward graph is recovered by the processor using the environmental state interpretation generated from the trained generator module.","['G05D1/0236', 'G05D1/0088', 'G05D1/021', 'G05D1/0221', 'G05D1/0223', 'G05D1/024', 'G05D1/0253', 'G05D1/0255', 'G05D1/0257', 'G05D1/0259', 'G05D1/0278', 'G05D1/0285', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/092', 'G06N3/094', 'G06N7/01']"
US20210334645A1,Notifications determined using one or more neural networks,"Apparatuses, systems, and techniques are presented to determine actions to be taken for data anomalies. In at least one embodiment, audio and video data captured for an environment of a user can be analyzed to detect one or more data anomalies and determine whether to notify this user depending on whether the anomalies are applicable to this user.","['G06N3/045', 'B60K35/00', 'B60K35/10', 'B60K35/213', 'B60K35/28', 'G06F18/00', 'G06K9/00718', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/08', 'G06T1/00', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06V20/41', 'G08B1/08', 'G08B21/02', 'G10L15/08', 'G10L15/16', 'G10L15/183', 'G10L15/22', 'G10L25/51', 'B60K2360/148', 'B60K2360/175', 'B60K2360/176', 'B60K2360/178', 'B60K2360/179', 'B60K2360/21', 'B60K35/22', 'B60K35/80', 'G06K2009/00738', 'G06N3/044', 'G06V20/44', 'G10L15/26']"
US10474929B2,Cyclic generative adversarial network for unsupervised cross-domain image generation,A system is provided for unsupervised cross-domain image generation relative to a first and second image domain that each include real images. A first generator generates synthetic images similar to real images in the second domain while including a semantic content of real images in the first domain. A second generator generates synthetic images similar to real images in the first domain while including a semantic content of real images in the second domain. A first discriminator discriminates real images in the first domain against synthetic images generated by the second generator. A second discriminator discriminates real images in the second domain against synthetic images generated by the first generator. The discriminators and generators are deep neural networks and respectively form a generative network and a discriminative network in a cyclic GAN framework configured to increase an error rate of the discriminative network to improve synthetic image quality.,"['G06K9/6259', 'G06N3/08', 'G06F18/2155', 'G06F18/22', 'G06K9/03', 'G06K9/6201', 'G06K9/66', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/094', 'G06N3/096', 'G06T11/001', 'G06T11/60', 'G06V10/7753', 'G06V10/82']"
US10997970B1,Methods and systems implementing language-trainable computer-assisted hearing aids,"A hearing aid system presents a hearing impaired user with customized enhanced intelligibility sound in a preferred language. The system includes a model trained with a set of source speech data representing sampling from a speech population relevant to the user. The model is also trained with a set of corresponding alternative articulation of source data, pre-defined or algorithmically constructed during an interactive session with the user. The model creates a set of selected target speech training data from the set of alternative articulation data that is preferred by the user as being satisfactorily intelligible and clear. The system includes a machine learning model, trained to shift incoming source speech data to a preferred variant of the target data that the hearing aid system presents to the user.","['G10L15/063', 'H04R25/70', 'G06N3/08', 'G10L17/00', 'G10L21/013', 'H04R25/507', 'G10L13/00', 'G10L21/003', 'G10L25/30', 'H04R2225/43']"
US10839269B1,System for fast and accurate visual domain adaptation,"In the field of computer vision, without sufficient labeled images, it is challenging to train an accurate model. But through visual adaptation from source to target domains, a relevant labeled dataset can help solve such problem. Many methods apply adversarial learning to diminish cross-domain distribution difference. They are able to greatly enhance the performance on target classification tasks. GAN (Generative Adversarial Networks) loss is widely used in adversarial adaptation learning methods to reduce a across-domain distribution difference. However, it becomes difficult to decline such distribution difference if generator or discriminator in GAN fails to work as expected and degrades its performance. To solve such cross-domain classification problems, an adaptation algorithm and system called as Generative Adversarial Distribution Matching (GADM) is implemented. In GADM, the objective function is improved by taking cross-domain discrepancy distance into consideration, and further minimize the difference through the competition between the generator and discriminator, thereby greatly decreasing the cross-domain distribution difference. Even when the performance of its generator or discriminator degrades, GADM is capable of decreasing the cross-domain distribution difference. The GADM algorithm and system employs a single GAN framework so as to achieve faster domain adaption with less computation resource. Specially, GADM transfers target data distribution to source one to keep accurate label dependence information, which ensures high accuracy and stability of source classifier and thus achieves better classification performance on target data.","['G06V10/82', 'G06K9/6263', 'G06F18/2178', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V20/00', 'G06V30/19167', 'G06V30/19173', 'G06N3/047', 'G06N3/088', 'G06V30/10']"
CN110992275B,A Refinement Single Image Rain Removal Method Based on Generative Adversarial Network,"The invention relates to a method for removing rain from a refined single image based on a generated countermeasure network, which comprises the steps of inputting a rain-containing image into a rain-grain estimation network to obtain an estimated rain-grain image, connecting the estimated rain-grain image with an input image to form a multi-channel image, inputting the multi-channel image into a generation model, inputting a rain-free image generated by the generation model into a discriminator for judgment, optimizing a generator according to the judgment result to finally obtain a generator network with stronger rain removing capability, taking the output of the generation model as the input of the image refinement network, and further processing the image to obtain a final rain-free image. The algorithm of the invention is an end-to-end algorithm and does not need any additional pretreatment or post-treatment. Compared with other work of generating a countermeasure network to carry out a single image area, the invention provides two auxiliary networks, which can further improve the image rain removing effect without remarkably increasing the calculation amount.","['G06T5/00', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/10']"
US12182878B2,Safe state to safe state navigation,"Systems and methods are provided for navigating a host vehicle. In one implementation, a system may include a processing device configured to receive an image acquired by an image capture device; determine a planned navigational action for accomplishing a navigational goal of the host vehicle; analyze the at least one image to identify a first target vehicle ahead of the host vehicle and a second target vehicle ahead of the first target vehicle; determine a next-state distance between the host vehicle and the second target vehicle that would result if the planned navigational action was taken; determine a stopping distance for the host vehicle based on a maximum braking capability of the host vehicle and a current speed of the host vehicle; and cause the vehicle to implement the planned navigational action if the stopping distance is less than the determined next-state distance.","['B60W30/095', 'B60W10/04', 'B60W10/18', 'B60W10/20', 'B60W30/08', 'B60W30/09', 'B60W30/0953', 'B60W30/0956', 'B60W30/18163', 'B60W40/02', 'B60W40/105', 'B60W60/0016', 'B60W60/0027', 'B60W60/00276', 'B62D15/025', 'B62D15/0265', 'G01C21/3407', 'G01C21/3415', 'G01C21/3446', 'G01C21/3602', 'G01S19/45', 'G05D1/0088', 'G05D1/0214', 'G05D1/0223', 'G05D1/0246', 'G06Q10/00', 'G06Q40/08', 'G07C5/006', 'G07C5/02', 'G07C5/08', 'G08G1/163', 'G08G1/166', 'B60W2050/0005', 'B60W2050/009', 'B60W2400/00', 'B60W2420/403', 'B60W2420/408', 'B60W2520/10', 'B60W2552/50', 'B60W2552/53', 'B60W2554/00', 'B60W2554/20', 'B60W2554/4023', 'B60W2554/4026', 'B60W2554/4029', 'B60W2554/4046', 'B60W2554/60', 'B60W2554/801', 'B60W2554/802', 'B60W2554/804', 'B60W2555/60', 'B60W2710/18']"
US11586865B2,"Apparatus, system and method for fusing sensor data to do sensor translation","Technologies and techniques for operating a sensor system including an image sensor and a light detection and ranging (LiDAR) sensor. Image data associated with an image scene of a landscape is received from the image sensor, and LiDAR data associated with a LiDAR scene of the landscape is received from the LiDAR sensor, wherein the LiDAR scene and image scene of the landscape substantially overlap. A machine-learning model is applied to (i) the image data to identify image points of interest in the image data, and (ii) the LiDAR data to identify LiDAR features of interest in the LiDAR data. The LiDAR features of interest and the image points of interest are fused, utilizing an attention mechanism, and generating an output, wherein new LiDAR data is produced, based on the fusing output.","['G01S17/931', 'G06K9/629', 'G06F18/253', 'G01B11/22', 'G01S17/86', 'G01S17/89', 'G01S7/417', 'G06F18/214', 'G06F18/2178', 'G06F18/251', 'G06K9/6256', 'G06K9/6263', 'G06K9/6289', 'G06T7/50', 'G06V10/803', 'G06V10/82', 'G06V20/56', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
US11776180B2,Controlled style-content image generation based on disentangling content and style,"Embodiments of the present disclosure are directed towards improved models trained using unsupervised domain adaptation. In particular, a style-content adaptation system provides improved translation during unsupervised domain adaptation by controlling the alignment of conditional distributions of a model during training such that content (e.g., a class) from a target domain is correctly mapped to content (e.g., the same class) in a source domain. The style-content adaptation system improves unsupervised domain adaptation using independent control over content (e.g., related to a class) as well as style (e.g., related to a domain) to control alignment when translating between the source and target domain. This independent control over content and style can also allow for images to be generated using the style-content adaptation system that contain desired content and/or style.","['G06T11/60', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/00', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2210/36']"
US12130938B2,Data product release method or system,"A computer implemented data product release method or system. The data product release is derived from a sensitive dataset using a privacy protection system such as a differentially private system. The privacy protection parameters, such as noise addition magnitude, are configurable as part of the data product release method or system to alter the balance between maintaining privacy of the sensitive dataset and making the data product release useful.","['G06F17/12', 'G06F17/18', 'G06F21/577', 'G06F21/6227', 'G06F21/6245', 'G06F9/547', 'G06F21/6254']"
US11743294B2,Retrospective learning of communication patterns by machine learning models for discovering abnormal behavior,"Conventional email filtering services are not suitable for recognizing sophisticated malicious emails, and therefore may allow sophisticated malicious emails to reach inboxes by mistake. Introduced here are threat detection platforms designed to take an integrative approach to detecting security threats. For example, after receiving input indicative of an approval from an individual to access past email received by employees of an enterprise, a threat detection platform can download past emails to build a machine learning (ML) model that understands the norms of communication with internal contacts (e.g., other employees) and/or external contacts (e.g., vendors). By applying the ML model to incoming email, the threat detection platform can identify security threats in real time in a targeted manner.","['H04L63/20', 'G06N20/00', 'G06N20/20', 'G06N3/0464', 'G06N3/09', 'G06N3/098', 'H04L63/102', 'H04L63/1416', 'H04L63/1433', 'H04L63/1441', 'G06N3/08', 'G06N5/01', 'G06N7/01']"
US11550914B2,System and method for detecting backdoor attacks in convolutional neural networks,"Described is a system for detecting backdoor attacks in deep convolutional neural networks (CNNs). The system compiles specifications of a pretrained CNN into an executable model, resulting in a compiled model. A set of Universal Litmus Patterns (ULPs) are fed through the compiled model, resulting in a set of model outputs. The set of model outputs are classified and used to determine presence of a backdoor attack in the pretrained CNN. The system performs a response based on the presence of the backdoor attack.","['G06N3/084', 'G06F18/24', 'G06F18/2433', 'G06F21/566', 'G06F21/577', 'G06F8/41', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06F2221/033', 'G06V20/582']"
US11842164B2,"Method and apparatus for training dialog generation model, dialog generation method and apparatus, and medium","The disclosure discloses a method and an apparatus for training a dialog generation model, and a dialog generation method and apparatus, and relates to the field of artificial intelligence. The method includes: encoding a context sample to obtain a first latent variable, and recognizing the first latent variable to obtain a prior latent variable; encoding a response sample to obtain a second latent variable; encoding a response similar sample to obtain a third latent variable; performing recognition according to a Gaussian mixture distribution of the first latent variable, the second latent variable, and the third latent variable to obtain a posterior latent variable; and matching the prior latent variable with the posterior latent variable, and performing adversarial training on a dialog generation model.","['G06F16/3329', 'G06F40/35', 'G06F16/3343', 'G06F18/22', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/048', 'G06N7/01']"
CN110008680B,Verification code generation system and method based on adversarial samples,"The invention discloses a verification code generation system and method based on a confrontation sample. The verification code acquisition layer transmits the collected verification code data set into the preprocessing layer, the preprocessing layer converts the verification code pictures into a plurality of black and white character pictures through graying, binaryzation, drying character segmentation and the like, and the constructed neural network and the confrontation sample algorithm are randomly selected from the confrontation sample generation layer to directionally generate the confrontation samples. The sample splicing layer carries out reverse pretreatment on the verification codes with different lengths of the single countermeasure sample splicing layer through the hybrid layer, the verification codes are reduced into colors, and the verification codes aeCAPTCHA based on the countermeasure samples are generated. The invention has the characteristics of low cost, small deployment difficulty and strong attack resistance. The method not only can enable the website to resist network attack more effectively without replacing the existing verification code system.","['G06F18/214', 'G06F21/36', 'G06F21/45', 'G06N3/04', 'G06T3/60', 'G06T5/70', 'G06F2221/2133']"
US11556794B2,Facilitating neural networks,"Techniques for improved neural network modeling are provided. In one embodiment, a system comprises a memory that stores computer-executable components and a processor that executes the components. The computer-executable components can comprise a loss function logic component that determines a penalty based on a training term, the training term being a function of a relationship between an output scalar value of a first neuron of a plurality of neurons of a neural network model, a plurality of input values from the first neuron, and one or more tunable weights of connections between the plurality of neurons; an optimizer component that receives the penalty from the loss function component, and changes one or more of the tunable weights based on the penalty; and an output component that generates one or more output values indicating whether a defined pattern is detected in unprocessed input values received at the neural network evaluation component.","['G06N3/082', 'G06F17/16', 'G06F17/18', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/049', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/084', 'G06N5/003', 'G06N5/01', 'G06N7/005', 'G06N7/01']"
CN109800811B,Small sample image identification method based on deep learning,"The invention relates to a small sample image recognition method based on deep learning, which comprises the following steps: firstly, dividing a training set; secondly, generating a noise image; thirdly, pre-training a prototype space discrimination network; fourthly, training a deception image generation network; fifthly, training a prototype space discrimination network; sixthly, repeating the fourth step and the fifth step to carry out cross iterative training until the preset iteration times or accuracy is reached and is not improved any more; and seventhly, identifying image categories. On the premise of not changing the trained model, the method identifies new classes which are never seen in the training process by generalizing the rare classes by means of a few labeled samples of each class without additional training, and has high image identification accuracy.",[]
CN109544442B,Image Local Style Transfer Method Based on Generative Adversarial Network Based on Dual Adversarial,"The invention discloses a method for migrating local styles of images of a generated type countermeasure network based on double countermeasures, which comprises the following steps: s1, acquiring two types of images; s2, preprocessing the two acquired images; s3, constructing a double countermeasure network with a self-attention mechanism, respectively inputting the preprocessed two types of images into a minimized loss function of the double countermeasure network, and training the double countermeasure network; s4, taking the generator in the trained double countermeasure network as a tool for local style migration of the two types of images, and applying the tool to actual measurement. According to the technical scheme, the self-attention generation type countermeasure network based on double countermeasures can enable the graph-to-graph conversion of local features to be focused on the local features, and the method is excellent in use effect.","['G06T3/18', 'G06N3/08', 'Y02T10/40']"
US10460234B2,Private deep neural network training,"Systems and methods for private deep neural network training are disclosed. Method includes storing first private values at first machine and second private values at second machine; providing, to third machine, first share of first private values and first share of second private values; providing, to fourth machine, second share of first private values and second share of second private values; computing, at third machine, third machine-value based on first share of first private values and first share of second private values; computing, at fourth machine, fourth machine-value based on second share of first private values and second share of second private values; providing, to first machine and second machine, third machine-value and fourth machine-value; and computing, at first machine, a mathematical function of first private values and second private values, mathematical function being computed based on first private values stored at first machine, third machine-value, and fourth machine-value.","['G06N3/08', 'G06N3/084', 'G06F1/02', 'G06F17/13', 'G06F17/16', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/09', 'G06N3/098']"
US11620527B2,Domain adaption learning system,"Described is a system for adapting a deep convolutional neural network (CNN). A deep CNN is first trained on an annotated source image domain. The deep CNN is adapted to a new target image domain without requiring new annotations by determining domain agnostic features that map from the annotated source image domain and a target image domain to a joint latent space, and using the domain agnostic features to map the joint latent space to annotations for the target image domain.","['G06N3/08', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0002', 'G06V10/764', 'G06V10/7753', 'G06V10/82', 'G06V20/56', 'G06T2207/20081', 'G06T2207/20084']"
US20200395117A1,Adaptive image processing method and system in assisted reproductive technologies,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['G16H30/20', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G16H10/60', 'G16H20/10', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B10/0012', 'A61B8/5223', 'G06N3/082', 'Y02A90/10']"
US11406899B2,Virtual character generation from image or video data,"Systems and methods for generating a customized virtual character are disclosed. A system may obtain video data or other media depicting a real person, and then may provide the obtained media to one or more machine learning models configured to learn visual appearance and behavior information regarding the particular person depicted in the video or other media. The system may then generate a custom visual appearance model and a custom behavior model corresponding to the real person, which may subsequently be used to render, within a virtual environment of a video game, a virtual character that resembles the real person in appearance and in-game behavior.","['A63F13/655', 'G06T13/40', 'A63F13/213', 'A63F13/40', 'A63F13/63', 'A63F13/67', 'G06N20/20', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06T15/005', 'G06T15/04', 'G06T17/205', 'G06T19/00', 'G06V20/20', 'G06V40/10', 'A63F13/428', 'A63F2300/5553', 'A63F2300/695', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06T17/20', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/16', 'G06V40/20']"
US11455527B2,Classification of sparsely labeled text documents while preserving semantics,"A method of training a neural network includes receiving a text corpus containing a labeled portion and an unlabeled portion, extracting local n-gram features and a sequence of the local n-gram features from the text corpus, processing the text corpus, using convolutional layers, according to the local n-gram features to determine capsule parameters of capsules configured to preserve the sequence of the local n-gram features, performing a forward-oriented dynamic routing between the capsules using the capsule parameters to extract global characteristics of the text corpus, and processing the text corpus according to the global characteristics using a long short-term memory layer to extract global sequential text dependencies from the text corpus, wherein parameters of the neural network are updated according to the local n-gram features, the capsule parameters, global characteristics, and global sequential text dependencies.","['G06F16/35', 'G06N3/08', 'G06F40/216', 'G06F17/15', 'G06F40/284', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/049', 'G06N3/0895', 'G06N3/09', 'G06N3/094']"
EP4465208A2,Network for detecting edge cases for use in training autonomous control systems,"Embodiments relate to the detection of edge cases through application of a neural network to predict future vehicle environment data and identifying an edge case when the prediction error exceeds a given threshold. This allows edge cases to be identified based on unexpected vehicle environmental conditions or conditions that otherwise cause the neural network to make inaccurate predictions. These edge cases can then be utilised to better train machine learning systems, for instance, to train autonomous vehicle control systems. Alternatively, the identification of an edge case can highlight the need for remedial action, and can therefore trigger an alert to a vehicle control system to take remedial action. Further methods and systems described herein improve environmental sensing by providing a computationally efficient and accurate means for fusing sensor data and using this fused data to control sensors to focus on areas that would most reduce the uncertainty in the sensing system.","['G06N3/04', 'B60W50/06', 'B60W40/09', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/0495', 'G06N3/088', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'B60W2050/0075', 'B60W2050/0088', 'B60W2050/065', 'B60W2556/10', 'B60W2556/35', 'B60W2556/45', 'B60W2756/10', 'G05B13/027']"
US11763541B2,"Target detection method and apparatus, model training method and apparatus, device, and storage medium","The disclosure provides a target detection method and apparatus, a model training method and apparatus, a device, and a storage medium. The target detection method includes: obtaining a first image; obtaining a second image corresponding to the first image, the second image belonging to a second domain; and obtaining a detection result corresponding to the second image through a cross-domain image detection model, the detection result including target localization information and target class information of a target object, the cross-domain image detection model including a first network model configured to convert an image from a first domain into an image in the second domain, and the second network model configured to perform region localization on the image in the second domain.","['G06V10/255', 'G06V10/764', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06V10/82', 'G06V20/58']"
US20230252224A1,Systems and methods for machine content generation,"Computerized systems and methods are disclosed to generate a document with a transformer by prompt-engineering the transformer with a title and a summary to generate a description of the document; displaying a set of claims and allowing user editing of the set of claims; receiving one or more figures; receiving a part list with a plurality of element names for each figure; generating an expanded description of each element name through prompt engineering based on prior text in the document; selecting one or more boilerplate texts for major sections of the document; and organizing the document with the title, a background, the summary, a brief description of the drawings, and a detailed description.","['G06F40/151', 'G06F3/0482', 'G06F3/04845', 'G06F40/166', 'G06F40/40', 'G06F40/56', 'G06Q10/10', 'G06Q50/184']"
CA2997579C,Crowdsourcing and deep learning based segmenting and karyotyping of chromosomes,The most challenging problems in karyotyping are segmentation and classification of overlapping chromosomes in metaphase spread images. Often chromosomes are bent in different directions with varying degrees of bend. Tediousness and time consuming nature of the effort for ground truth creation makes it difficult to scale the ground truth for training phase. The present disclosure provides an end-to-end solution that reduces the cognitive burden of segmenting and karyotyping chromosomes. Dependency on experts is reduced by employing crowdsourcing while simultaneously addressing the issues associated with crowdsourcing. Identified segments through crowdsourcing are pre-processed to improve classification achieved by employing deep convolutional network (CNN).,"['G06T7/155', 'G06V10/82', 'G06F18/217', 'G06F18/241', 'G06F18/24133', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/0012', 'G06T7/60', 'G06V10/764', 'G06V20/695', 'G06V20/698', 'G16B10/00', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G16B40/20', 'G16H30/40']"
US12093297B2,"Summary generation model training method and apparatus, device and storage medium","The present disclosure provides a summary generation model training method and apparatus, a device and a storage medium, and relates to the field of computer technologies, and in particular, to the field of artificial intelligence such as natural language processing and deep learning. The summary generation model training method includes: acquiring a document representation corresponding to a document sample; constructing, based on the document representation, a summary representation corresponding to the document representation, the summary representation including a positive summary representation and a negative summary representation; and constructing a total contrastive loss function based on the document representation, the positive summary representation and the negative summary representation, and training a summary generation model based on the total contrastive loss function. The present disclosure may improve accuracy of the summary generation model.","['G06F40/279', 'G06F16/345', 'G06F40/30', 'G06F40/51', 'G06F40/56']"
EP4230385A1,"Systems, methods and media for artificial intelligence feedback control in additive manufacturing","An additive manufacturing system (100) comprises a print head (140) to print an object layer by layer, an illumination source (130) for illuminating a printed layer of the object and an image sensor (120) configured to capture an image of the printed layer. The system further comprises at least one hardware processor (110,160) configured to: receive a captured image, obtain one or more desired mechanical properties for the object, generate a three-dimensional topographical image of the printed layer, identify an anomaly using an A1 algorithm, determine a correlation between the identified anomaly and one/more print parameters using a second A1 algorithm, adjust a value for the one or more print parameters to be used by the print head to print a subsequent layer, and cause the print head (140) to print the subsequent layer using the value for the one or more print parameters to substantially achieve the one or more desired mechanical properties,","['B29C64/393', 'B33Y50/02', 'B29C64/386', 'B22F10/10', 'B22F10/20', 'B22F10/85', 'B22F12/90', 'B29C64/106', 'B29C64/209', 'B33Y10/00', 'B33Y30/00', 'B33Y50/00', 'G01B11/24', 'G01N21/8851', 'G06F18/2411', 'G06F18/295', 'G06N20/00', 'G06N20/10', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/094', 'G06V10/764', 'G06V20/64', 'B22F2203/03', 'B22F2999/00', 'G01N2021/8438', 'G01N2021/8883', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'G06V2201/06', 'G06V2201/121']"
US11062490B2,Reinforcement learning for online sampling trajectory optimization for magnetic resonance imaging,"A magnetic resonance imaging scan performs an MRI acquisition using an undersampling pattern to produce undersampled k-space data; adds the undersampled k-space data to aggregate undersampled k-space data for the scan; reconstructs an image from the aggregate undersampled k-space data; updates the undersampling pattern from the reconstructed image and aggregate undersampled k-space data using a deep reinforcement learning technique defined by an environment, reward, and agent, where the environment comprises an MRI reconstruction technique, where the reward comprises an image quality metric, and where the agent comprises a deep convolutional neural network and fully connected layers; and repeats these steps to produce a final reconstructed MRI image for the scan.","['G01R33/5608', 'G06T11/006', 'A61B5/055', 'G01R33/4818', 'G01R33/561', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N7/01', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
US20230244965A1,Predicted forecast offset from remote location sensor,"A computing system configured to execute a predictive program is provided. The predictive program, in a run-time phase, receives a current value for a remotely sourced forecast as run-time input into an artificial intelligence model. The artificial intelligence model has been trained on training data including a time series of locally sourced measurements for a parameter and a time series of remotely sourced forecast data for the parameter. The predictive program outputs a predicted forecast offset between the current value of a remotely sourced forecast and a future locally sourced measurement for the parameter. The predictive program outputs from the artificial intelligence model a predicted forecast offset based on the run-time input.","['G06N3/088', 'G06N5/04', 'G01W1/10', 'G06N20/00', 'G06N3/044', 'G06N3/045']"
US20190306526A1,Inter-prediction method and apparatus using reference frame generated based on deep learning,"Disclosed herein are an inter-prediction method and apparatus using a reference frame generated based on deep learning. In the inter-prediction method and apparatus, a reference frame is selected, and a virtual reference frame is generated based on the selected reference frame. A reference picture list is configured to include the generated virtual reference frame, and inter prediction for a target block is performed based on the virtual reference frame. The virtual reference frame may be generated based on a deep-learning network architecture, and may be generated based on video interpolation and/or video extrapolation that use the selected reference frame.","['H04N19/513', 'H04N19/105', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'H04N19/109', 'H04N19/132', 'H04N19/176', 'G06N3/048', 'H04N19/129']"
CN112786030B,A meta-learning-based adversarial sampling training method and device,"The invention discloses a countersampling training method and a device based on meta-learning, wherein the method comprises the following steps: outputting K-dimensional probability vectors from a large task set T consisting of K languages according to a policy network
Wherein the content of the first and second substances,
selecting the language with the maximum previous M probabilities according to the sampling probability for the sampling probability corresponding to the ith language task set, sampling one task according to each language in the language with the maximum previous M probabilities to form a training task set, and dividing the training task set into a support set and a query set; the support set carries out gradient descent on the initialization parameter theta of the voice recognition model to obtain an updated parameter
The query set updates the parameters according to the query
To obtain a query loss vector
The query loss vector
And optimizing the initialization parameter theta to obtain an optimal model parameter. Based on a multilingual meta-learning speech recognition framework, a strategy network is introduced to form confrontation training, so that the problem of unbalanced low-resource language recognition is solved, and the training effect is improved.","['G10L15/16', 'G06N3/045', 'G06N3/049', 'G06N3/08']"
CN107480772B,License plate super-resolution processing method and system based on deep learning,"The invention discloses a license plate super-resolution processing method and a system based on deep learning, which comprises the steps of acquiring a series of images containing license plate information from an original compressed monitoring video; then tracking the interest target therein; selecting a plurality of interest points, intercepting images, and registering the images; and acquiring corresponding depth network weights by using a depth learning training library, and performing super-resolution processing on the registered multi-frame images by using the depth network weights to obtain a clear high-resolution license plate I. The method uses a strategy of carrying out common optimization by using a super-resolution depth network model and a gradient guide network model to learn the internal relation between the degraded characters and the clear characters in the high-compression monitoring video, realizes the effects of super-resolution and block removal effect through a common depth network, improves the resolution of the degraded characters, removes the block effect and solves the problem that the license plate characters in the high-compression monitoring video cannot be seen clearly.","['G06N3/045', 'G06N3/08', 'G06T5/20', 'G06T7/269', 'G06T7/30', 'G06V10/23', 'H04N19/42', 'H04N19/44', 'G06V2201/07', 'Y02T10/40']"
US20240161165A1,Cross-domain recommendation via contrastive learning of user behaviors in attentive sequence models,"The technology involves a personalized recommender system that can be used with an e-commerce platform. It employs a contrastive learning based cross-domain recommendation approach. The approach balances the learning of user behaviors within each domain, as well as user behaviors across multiple domains. To achieve robust user representations and to improve knowledge transfer between the source and target domains, multi-task intra-domain contrastive regularizations may be employed along with multiple branches of sequential attentive encoders in a model for cross-domain sequential recommendation. Different data augmentation approaches can be used to generate augmented data for contrastive learning. For instance, different data augmentation methods may be combined with recommendation optimization in a multi-task learning paradigm. An optimized sequence representation may be fine-tuned in a next-value prediction task for recommendation in a target domain.","['G06Q30/0631', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/084', 'G06N3/0895']"
CN110555458B,Multi-band image feature level fusion method for generating countermeasure network based on attention mechanism,"The invention relates to an image fusion method, in particular to a multiband image fusion method, and specifically relates to a multiband image feature level fusion method for generating a countermeasure network based on an attention mechanism. The method comprises the following steps: designing and constructing a generation confrontation network, wherein a generator comprises a feature enhancement module of a mixed attention mechanism, and a generation model is obtained through dynamic balance training of the generator and a discriminator; the method realizes the end-to-end neural network fusion of the multiband images and obviously improves the detail quality of the fused images.",['G06F18/253']
US12229681B2,"Trusted graph data node classification method, system, computer device and application","A trusted graph data node classification method includes: (1) inputting a topological graph and node features, and calculating a discrete Ricci curvature of the discrete topological graph; (2) preprocessing the curvature and the node features; (3) mapping the curvature, reconstructing original features, and performing a semi-supervised training on graph data containing adversarial examples; and (4) performing a classification on unlabeled nodes. The new method uses a discrete curvature to extract topological information, and uses a residual network to reconstruct node feature vectors without knowing the technical details of the adversarial examples, and without using a large number of adversarial examples for adversarial training. Hence, the system effectively defends against attacks from adversarial examples on the graph data, outperforms the existing mainstream models in terms of accuracy when used in data without adversarial examples, and is thus a trusted node classification system.","['G06F18/241', 'G06N3/084', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06N3/0895', 'G06N5/01']"
US11681924B2,Training neural networks using a variational information bottleneck,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes receiving training data; training a neural network on the training data, wherein the neural network is configured to: receive a network input, convert the network input into a latent representation of the network input, and process the latent representation to generate a network output from the network input, and wherein training the neural network on the training data comprises training the neural network on a variational information bottleneck objective that encourages, for each training input, the latent representation generated for the training input to have low mutual information with the training input while the network output generated for the training input has high mutual information with the target output for the training input.","['G06N3/084', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0499', 'G06N3/09']"
US11854160B2,"CT super-resolution GAN constrained by the identical, residual and cycle learning ensemble (GAN-circle)","A system for generating a high resolution (HR) computed tomography (CT) image from a low resolution (LR) CT image is described. The system includes a first generative adversarial network (GAN) and a second GAN. The first GAN includes a first generative neural network (G) configured to receive a training LR image dataset and to generate a corresponding estimated HR image dataset, and a first discriminative neural network (DY) configured to compare a training HR image dataset and the estimated HR image dataset. The second GAN includes a second generative neural network (F) configured to receive the training HR image dataset and to generate a corresponding estimated LR image dataset, and a second discriminative neural network (DX) configured to compare the training LR image dataset and the estimated LR image dataset. The system further includes an optimization module configured to determine an optimization function based, at least in part, on at least one of the estimated HR image dataset and/or the estimated LR image dataset. The optimization function contains at least one loss function. The optimization module is further configured to adjust a plurality of neural network parameters associated with at least one of the first GAN and/or the second GAN, to optimize the optimization function.","['G06T3/4053', 'G06T3/4076', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06N3/082']"
US10957031B1,Intelligent defect detection from image data,"Implementations include receiving image data representative of images of items within a physical environment and depicting defects in at least one item, providing one or more of a set of augmented images using image augmentation based on the image data and a set of synthetic images using ML-based image synthesis based on the image data, processing one of the set of augmented images and the set of synthetic images using an ML model to provide a set of defect characteristics representative of defects in the at least one item, providing one or more root causes of each of the one or more defects by processing the set of defect characteristics and ancillary data, the ancillary data representative of the physical environment, and generating one or more alerts based on the one or more root causes for remediation of at least one root cause of the one or more defects.","['G06T7/0004', 'G06N20/00', 'G06N3/006', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N7/01', 'G06T3/0006', 'G06T3/02', 'G06T7/11', 'G06T7/174', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US11079738B2,Framework for rapid additive design with generative techniques,"According to some embodiments, a system may include a design experience data store containing electronic records associated with prior industrial asset item designs. A deep learning model platform, coupled to the design experience data store, may include a communication port to receive constraint and load information from a designer device. The deep learning platform may further include a computer processor adapted to automatically and generatively create boundaries and geometries, using a deep learning model associated with an additive manufacturing process, for an industrial asset item based on the prior industrial asset item designs and the received constraint and load information. According to some embodiments, the deep learning model computer processor is further to receive design adjustments from the designer device. The received design adjustments might be for example, used to execute an optimization process and/or be fed back to continually re-train the deep learning model.","['G05B19/4099', 'G06F30/27', 'G06F30/17', 'G06N20/00', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N5/025', 'G06N7/005', 'G06N7/01', 'B33Y50/00', 'G05B2219/49023', 'G06N3/08', 'G06N5/027']"
US10984558B2,Learning-based sampling for image matting,"Techniques are disclosed for image matting. In particular, embodiments decompose the matting problem of estimating foreground opacity into the targeted subproblems of estimating a background using a first trained neural network, estimating a foreground using a second neural network and the estimated background as one of the inputs into the second neural network, and estimating an alpha matte using a third neural network and the estimated background and foreground as two of the inputs into the third neural network. Such a decomposition is in contrast to traditional sampling-based matting approaches that estimated foreground and background color pairs together directly for each pixel. By decomposing the matting problem into subproblems that are easier for a neural network to learn compared to traditional data-driven techniques for image matting, embodiments disclosed herein can produce better opacity estimates than such data-driven techniques as well as sampling-based and affinity-based matting approaches.","['G06T7/11', 'G06T7/90', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/001', 'G06T11/60', 'G06T3/40', 'G06T7/194', 'H04N5/272', 'H04N5/275', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
CN111080645B,Semi-supervised semantic segmentation method for remote sensing images based on generative adversarial network,"The application discloses a remote sensing image semi-supervised semantic segmentation method based on a generated type countermeasure network, which comprises the steps of constructing an initial generated type countermeasure segmentation network, constructing a training data set, training the initial generated type countermeasure segmentation network according to the training data set to obtain an optimized generated type countermeasure segmentation network, inputting an image to be detected into the optimized generated type countermeasure segmentation network to carry out semantic segmentation so as to extract features of different scales, fusing local and global features, and guiding data without labels by the generated countermeasure network to carry out semantic segmentation, thereby carrying out semi-supervised semantic segmentation and improving the precision of the semantic segmentation.","['G06T7/10', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'Y02T10/40']"
CN110363183B,A privacy protection method for service robot visual image based on generative adversarial network,"The invention discloses a service robot visual image privacy protection method based on a generating type confrontation network, which is characterized by comprising the following steps: the privacy identification and protection comprises functions of data preprocessing, privacy identification, picture conversion and the like, data acquired by a visual data acquisition end are firstly subjected to data preprocessing, then a privacy identification module judges whether privacy exists in the input preprocessed data, if the input preprocessed data are judged to be pictures related to the privacy, the pictures are converted, and the converted pictures are converted into picture data not related to the privacy and stored; the training data growth and feature learning are used for updating a training data set, and a feature model is obtained through an improved Cycle-GAN algorithm based on the training data set and is used for the image conversion. The invention can ensure that the picture data does not relate to the privacy content from the source, and has the characteristics of short training time and strong generalization capability of the privacy picture conversion.","['G06N3/045', 'G06N3/088', 'G06T3/04', 'G06V20/10', 'G06V40/166']"
US12019718B2,"Identity verification method and apparatus, computer device and storage medium","An identity authentication method is provided, including: acquiring a raw feature of a user; calling an identity authentication model to extract a primary attribute feature vector in the raw feature, the primary attribute feature vector being an unbiased feature representation for selectively decoupling m−1 domain discrepancy features in the raw feature, and m being an integer greater than 2; and performing unbiased identity authentication based on the primary attribute feature vector to obtain an identity authentication result.","['G06F21/31', 'G06F18/214', 'G06F21/32', 'G06N3/004', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/168', 'G06V40/172', 'G06N3/047', 'G06N3/048', 'G06V40/1365', 'G06V40/197']"
US11403737B2,Segmenting and denoising depth images for recognition applications using generative adversarial neural networks,"A method of removing noise from a depth image includes presenting real-world depth images in real-time to a first generative adversarial neural network (GAN), the first GAN being trained by synthetic images generated from computer assisted design (CAD) information of at least one object to be recognized in the real-world depth image. The first GAN subtracts the background in the real-world depth image and segments the foreground in the real-world depth image to produce a cleaned real-world depth image. Using the cleaned image, an object of interest in the real-world depth image can be identified via the first GAN trained with synthetic images and the cleaned real-world depth image. In an embodiment the cleaned real-world depth image from the first GAN is provided to a second GAN that provides additional noise cancellation and recovery of features removed by the first GAN.","['G06T5/002', 'G06T5/70', 'G06F18/2413', 'G06F30/23', 'G06F30/27', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/11', 'G06T7/194', 'G06T7/55', 'G06V10/30', 'G06V10/764', 'G06V10/82', 'G06T2207/10028']"
US11983625B2,Robust multimodal sensor fusion for autonomous driving vehicles,"Techniques are disclosed for using neural network architectures to estimate predictive uncertainty measures, which quantify how much trust should be placed in the deep neural network (DNN) results. The techniques include measuring reliable uncertainty scores for a neural network, which are widely used in perception and decision-making tasks in automated driving. The uncertainty measurements are made with respect to both model uncertainty and data uncertainty, and may implement Bayesian neural networks or other types of neural networks.","['G06N3/08', 'G05B23/0221', 'G05B13/026', 'G05B13/027', 'G06F18/2431', 'G06F18/25', 'G06F18/251', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/0499', 'G06N3/09', 'G06N3/091', 'G06N5/046', 'G06N7/01']"
US10482575B2,Super-resolution apparatus and method for virtual and mixed reality,"An apparatus and method for efficiently improving virtual/real interactions in augmented reality. For example, one embodiment of a method comprises: capturing a raw image including depth data; identifying one or more regions of interest based on a detected spatial proximity of one or more virtual objects and one or more real objects; generating a super-resolution map of the one or more regions of interest using machine-learning techniques or results thereof; detecting interactions between the virtual objects and the real objects using the super-resolution map; and performing one or more graphics processing or general purpose processing operations based on the detected interactions.","['G06T3/4053', 'G06F3/011', 'G06N3/047', 'G06N3/0475', 'G06N3/063', 'G06N3/09', 'G06N3/094', 'G06T19/006', 'G06T7/70', 'G06T7/97', 'G06N20/00', 'G06T2207/10028', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/30244']"
US11537873B2,"Processing method and system for convolutional neural network, and storage medium","Provided are a processing method and system for a convolutional neural network, and a computer-readable medium, the processing method includes training a generator and training a discriminator, wherein training a generator includes: extracting a low-resolution color image from a high-resolution color image; training parameters of a generator network, by using the low-resolution color image and a noise image as an input image, based on parameters of a discriminator network, and reducing a generator cost function; training a discriminator includes: inputting an output image of the trained generator network and the high-resolution color image to the discriminator network, respectively; training parameters of the discriminator network by reducing a discriminator cost function (S204) the generator cost function and the discriminator cost function represent a degree in which the output image of the generator network corresponds to the high-resolution color image.","['G06N3/08', 'G06F18/25', 'G06K9/6232', 'G06K9/6288', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/776', 'G06V10/82']"
CN111126218B,Human behavior recognition method based on zero sample learning,"The human behavior recognition method based on zero sample learning improves the classification performance and accuracy of the trained classifier and promotes the realization of automatic labeling targets of human behavior categories. The method comprises the following steps: (1) Constructing a knowledge graph based on action classes and action-related objects, and dynamically updating the relationship of the knowledge graph through a graph rolling network AMGCN based on an attention mechanism, so as to better describe the relationship of nodes in the graph; (2) Learning generation of the antagonism network WGAN-GCC based on gradient penalty and loop consistency constraint, so that the learned generator can better generate unknown class features; (3) The graph convolution network and the generation countermeasure network are combined into a double-flow deep neural network, so that the trained classifier is more discriminant.","['G06V40/20', 'G06F18/2155', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V40/10']"
US12148119B2,Utilizing a generative neural network to interactively create and modify digital images based on natural language feedback,"The present disclosure relates to systems, non-transitory computer-readable media, and methods that implement a neural network framework for interactive multi-round image generation from natural language inputs. Specifically, the disclosed systems provide an intelligent framework (i.e., a text-based interactive image generation model) that facilitates a multi-round image generation and editing workflow that comports with arbitrary input text and synchronous interaction. In particular embodiments, the disclosed systems utilize natural language feedback for conditioning a generative neural network that performs text-to-image generation and text-guided image modification. For example, the disclosed systems utilize a trained model to inject textual features from natural language feedback into a unified joint embedding space for generating text-informed style vectors. In turn, the disclosed systems can generate an image with semantically meaningful features that map to the natural language feedback. Moreover, the disclosed systems can persist these semantically meaningful features throughout a refinement process and across generated images.","['G06T3/10', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T11/00', 'G06T11/60', 'G10L15/22', 'G10L15/26', 'G06F3/167', 'G10L2015/223']"
US11765332B2,Virtual 3D communications with participant viewpoint adjustment,"A method for conducting a three dimensional (3D) video conference between multiple participants, the method may include receiving second participant metadata and first viewpoint metadata by a first unit that is associated with a first participant, wherein the second participant metadata is indicative of a pose of a second participant and an expression of the second participant, wherein the first viewpoint metadata is indicative of a virtual position from which the first participant requests to view an avatar of the second participant; generating, by the first unit, and based on the second participant metadata and the first viewpoint metadata, a second participant representation information; wherein the second participant representation information comprises a compact 3D model of the second participant and a second participant texture map; and determining, for the first participant and during the 3D video conference, a representation of virtual 3D video conference environment, wherein the determining is based on the second participant representation information.","['H04N13/111', 'G06T19/006', 'H04N7/157']"
US11158069B2,Unsupervised deformable registration for multi-modal images,"In order to reduce computation time and provide more accurate solutions for bi-directional, multi-modal image registration, a learning-based unsupervised multi-modal deformable image registration method that does not require any aligned image pairs or anatomical landmarks is provided. A bi-directional registration function is learned based on disentangled shape representation by optimizing a similarity criterion defined on both latent space and image space.","['G06T7/30', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10132', 'G06T2207/10136', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30068']"
CN111814707B,Crop leaf area index inversion method and device,"The invention discloses a crop leaf area index inversion method and a device, which are used for acquiring remote sensing image data; carrying out data preprocessing on the remote sensing image data to obtain hyperspectral data; the method comprises the steps of inputting hyperspectral data into a pre-generated target-based inversion model to obtain a leaf area index output by the target-based inversion model, wherein the target-based inversion model is obtained by optimizing the target inversion model through a target training sample, and the target training sample is obtained by performing data enhancement on an initial training sample by using a generative confrontation network of dual learning. The problem of quantity demand of a neural network on training samples is solved by performing data enhancement on the actually-collected hyperspectral data and the leaf area indexes, so that the leaf area indexes can be inverted through the hyperspectral data by utilizing a neural network method, and high-precision leaf area index inversion based on the actually-collected small sample data is realized.","['G06T7/0004', 'G06V20/188', 'G01N21/25', 'G06F18/213', 'G06F18/214', 'G06N3/045', 'G06T11/60', 'G01N2021/1797', 'G06T2207/10036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30188', 'G06V20/194']"
CN111133756B,Neural network method and apparatus for video coding,"The application provides a video coding and decoding method and device for performing video coding and decoding on a video encoder or a video decoder by using a Neural Network (NN). According to one method, input data or a video bitstream is received for a block in one or more images, which includes one or more color components. Deriving residual data, prediction data, reconstruction data, filtered reconstruction data, or a combination thereof for one or more blocks of the one or more pictures. A target signal corresponding to one or more signal types is processed using a neural network, and an input of the neural network or an output of the neural network includes two or more color components. According to another method, a target signal corresponding to one or more approximate signal types is processed using a neural network, and an input to the neural network or an output from the neural network includes two or more color components.","['H04N19/117', 'G06T9/002', 'H04N19/107', 'H04N19/176', 'H04N19/186', 'H04N19/33', 'H04N19/82', 'H04N19/86', 'H04N19/46', 'H04N19/70']"
US12160579B2,"Image compression and decoding, video compression and decoding: methods and systems","There is disclosed a computer-implemented method for lossy image or video compression, transmission and decoding, the method including the steps of: (i) receiving an input image at a first computer system; (ii) encoding the input image using a first trained neural network, using the first computer system, to produce a latent representation; (iii) quantizing the latent representation using the first computer system to produce a quantized latent; (iv) entropy encoding the quantized latent into a bitstream, using the first computer system; (v) transmitting the bitstream to a second computer system; (vi) the second computer system entropy decoding the bitstream to produce the quantized latent; (vii) the second computer system using a second trained neural network to produce an output image from the quantized latent, wherein the output image is an approximation of the input image. Related computer-implemented methods, systems, computer-implemented training methods and computer program products are disclosed.","['G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/0985', 'G06T3/4046', 'G06T9/002', 'G06V10/774', 'H04N19/126', 'H04N19/13', 'H04N19/503', 'H04N19/91', 'G06N3/044', 'G06N3/088']"
CN112800906B,Improved YOLOv 3-based cross-domain target detection method for automatic driving automobile,"The invention belongs to the technical field of computer vision and environment perception of an automatic driving automobile, and particularly relates to a cross-domain target detection method of the automatic driving automobile based on improved YOLOv 3. The method is based on an improved single-stage YOLOv3 detection algorithm framework, adopts a generated confrontation network model to obtain training set data, and carries out cross-domain target detection aiming at the problem that the training set and the test set respectively come from different distributed data domains. Meanwhile, the accuracy of single-stage target detection is improved by improving the YOLOv3 algorithm, the application of the generated countermeasure network reduces the re-labeling of multi-class targets between different data fields, and the difficult problem of cross-domain target detection of the automatic driving automobile is solved to a certain extent.","['G06V20/56', 'G06F18/214', 'G06F18/23213', 'G06N3/045', 'G06N3/088', 'Y02T10/40']"
US11586860B2,Method for preventing the extraction of a machine learning model,"A method and data processing system for detecting tampering of a machine learning model is provided. The method includes training a machine learning model. During a training operating period, a plurality of input values is provided to the machine learning model. In response to a predetermined invalid input value, the machine learning model is trained that a predetermined output value will be expected. The model is verified that it has not been tampered with by inputting the predetermined invalid input value during an inference operating period. If the expected output value is provided by the machine learning model in response to the predetermined input value, then the machine learning model has not been tampered with. If the expected output value is not provided, then the machine learning model has been tampered with. The method may be implemented using the data processing system.","['G06K9/6269', 'G06N20/00', 'G06F18/2411', 'G06N3/09', 'G06N5/04', 'G06V10/764', 'G06V10/82', 'G06N3/08']"
WO2022007438A1,"Emotional voice data conversion method, apparatus, computer device, and storage medium","An emotional voice data conversion method and a related device, able to be used in the fields of smart governance or smart medicine, and comprising: acquiring source emotional voice data, and on the basis of a pre-set vocoder, extracting a first fundamental frequency, non-periodic data, and a first Mel-frequency cepstrum coefficient from the source emotional voice data (S201); by means of a linear transform, converting the first fundamental frequency into a second fundamental frequency, and on the basis of a pre-set conversion model, converting the first Mel-frequency cepstrum coefficient into a second Mel-frequency cepstrum coefficient, the pre-set conversion model being of a variational autoencoder generative adversarial network structure; and on the basis of the vocoder, performing a Fourier transform and adaptive interpolation processing on the second fundamental frequency, the second Mel-frequency cepstrum coefficient, and the non-periodic data, to obtain target emotional data (S203).","['G10L19/18', 'G10L21/013', 'G10L25/24', 'G10L25/63', 'G10L2021/0135']"
US11610115B2,Learning to generate synthetic datasets for training neural networks,"In various examples, a generative model is used to synthesize datasets for use in training a downstream machine learning model to perform an associated task. The synthesized datasets may be generated by sampling a scene graph from a scene grammar—such as a probabilistic grammar—and applying the scene graph to the generative model to compute updated scene graphs more representative of object attribute distributions of real-world datasets. The downstream machine learning model may be validated against a real-world validation dataset, and the performance of the model on the real-world validation dataset may be used as an additional factor in further training or fine-tuning the generative model for generating the synthesized datasets specific to the task of the downstream machine learning model.","['G06N3/08', 'G06F16/9024', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/0985', 'G06T11/00', 'G06T11/60', 'G06V10/426', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N5/01', 'G06N7/01', 'G06T2210/61']"
US12217828B2,"Method, apparatus, and computer-readable medium for efficiently optimizing a phenotype with a combination of a generative and a predictive model","A method, apparatus, and computer-readable medium for efficiently optimizing a phenotype with a combination of a generative and a predictive model, training a phenotype prediction model based on experiential genotype vectors, training a genotype generation model based on sample genotype vectors, generating new genotype vectors, applying the phenotype prediction model to the new genotype vectors to generate scores, determining result genotypes based on a ranking of the available genotypes according to the scores, and generating a result based on the result genotypes, the result indicating one or more genetic constructs for testing.","['G16B20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G16B40/00', 'G16B40/20', 'G06N3/044']"
US11668853B2,Petrophysical inversion with machine learning-based geologic priors,"A method and system for modeling a subsurface region include applying a trained machine learning network to an initial petrophysical parameter estimate to predict a geologic prior model; and performing a petrophysical inversion with the geologic prior model, geophysical data, and geophysical parameters to generate a rock type probability model and an updated petrophysical parameter estimate. Embodiments include managing hydrocarbons with the rock type probability model. Embodiments include checking for convergence of the updated petrophysical parameter estimate; and iteratively: applying the trained machine learning network to the updated petrophysical parameter estimate of a preceding iteration to predict an updated rock type probability model and another geologic prior model; performing a petrophysical inversion with the updated geologic prior model, geophysical seismic data, and geophysical elastic parameters to generate another rock type probability model and another updated petrophysical parameter estimate; and checking for convergence of the updated petrophysical parameter estimate.","['G01V99/005', 'G01V20/00', 'G01V1/282', 'E21B49/00', 'G01V1/306', 'G01V11/00', 'G06F30/27', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'E21B2200/20', 'G01V2210/614', 'G01V2210/6242', 'G01V2210/6244', 'G01V2210/667']"
US11972572B2,Intraoral scanning system with excess material removal based on machine learning,"A system includes an intraoral scanner and a computing device. The intraoral scanner generates an intraoral scan of a dental site. The computing device processes an input comprising data from the intraoral scan using a trained machine learning model that has been trained to classify regions of dental sites, wherein the trained machine learning model generates an output comprising, for each point in the intraoral scan, an indication as to whether the point belongs to a first dental class that represents excess material. The computing device determines, based on the output, one or more points in the intraoral scan that are classified as excess material. The computing device then hides or removes, from at least one of the intraoral scan or a virtual three-dimensional (3D) model generated using the intraoral scan, data for the one or more points that are classified as excess material.","['G06T7/11', 'A61C13/34', 'A61C9/0053', 'G06F18/2431', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T17/00', 'G06T19/20', 'G06T7/0012', 'G06T7/33', 'G06V10/454', 'G06V10/82', 'G06N3/047', 'G06N3/084', 'G06T2200/04', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30036', 'G06T2207/30052', 'G06T2210/41', 'G06T2219/008', 'G06T2219/2021', 'G06V20/653', 'G06V2201/03']"
US12211592B2,Machine learning based methods of analysing drug-like molecules,"There is provided a method for a machine learning based method of analysing drug-like molecules by representing the molecular quantum states of each drug-like molecule as a quantum graph, and then feeding that quantum graph as an input to a machine learning system.","['G16B15/00', 'G06N10/20', 'G06N10/60', 'G06N3/02', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N5/022', 'G16B40/20', 'G16B40/30', 'G16C10/00', 'G16C20/50', 'G16C20/70', 'G06N20/20', 'G06N3/006', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'G06N7/023']"
US20240013462A1,Audio-driven facial animation with emotion support using machine learning,"A deep neural network can be trained to output motion or deformation information for a character that is representative of the character uttering speech contained in audio input, which is accurate for an emotional state of the character. The character can have different facial components or regions (e.g., head, skin, eyes, tongue) modeled separately, such that the network can output motion or deformation information for each of these different facial components. During training, the network can be provided with emotion and/or style vectors that indicate information to be used in generating realistic animation for input speech, as may relate to one or more emotions to be exhibited by the character, a relative weighting of those emotions, and any style or adjustments to be made to how the character expresses that emotional state. The network output can be provided to a renderer to generate audio-driven facial animation that is emotion-accurate.","['G10L21/10', 'G06T13/205', 'G06T13/40', 'G06T17/20', 'G10L15/16', 'G10L25/63', 'G10L2021/105']"
CN110147797B,A method and device for sketch completion and recognition based on generative adversarial network,"The invention discloses a sketch complementing and identifying method and device based on a generating type confrontation network. The invention comprises the following steps: (1) based on the conditional generation type antagonistic neural network, aiming at the characteristic that the sketch is sparse relative to the semantic information of the color picture, the conditional generation type antagonistic neural network is improved by utilizing a cascading strategy; (2) the category universality of the sketch completion network is expanded, a sketch identification task is set as an auxiliary task, and meanwhile, a sketch identification auxiliary network is added in a network structure; (3) applying a sketch completion method to a recognition task of a incomplete sketch, an image retrieval task based on the incomplete sketch and a sketch scene editing task; (6) the integrated sketch completion method forms a sketch completion application platform, supports application functions including interactive sketch completion, sketch completion and recognition, sketch scene segmentation and completion, interactive sketch completion assistance and the like, and can be applied to various devices and terminals such as a PC (personal computer), a mobile phone, a tablet computer, an electronic whiteboard and the like.","['G06F18/214', 'G06F18/24', 'G06T7/13', 'G06V10/457', 'G06T2207/20081', 'G06T2207/20084']"
US11881010B2,Machine learning for video analysis and feedback,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for machine learning for video analysis and feedback. In some implementations, a machine learning model is trained to classify videos into performance level classifications based on characteristics of image data and audio data in the videos. Video data captured by a device of a user following a prompt that the device provides to the user is received. A set of feature values that describe audio and video characteristics of the video data are determined. The set of feature values are provided as input to the trained machine learning model to generate output that classifies the video data with respect to the performance level classifications. A user interface of the device is updated based on the performance level classification for the video data.","['G06V10/764', 'G06V10/454', 'G06V10/82']"
US20240169579A1,Prediction of structures in surgical data using machine learning,"A location of an anatomical structure in image(s) from a surgical procedure is predicted using machine learning. An image/video capture device such as an endoscope, a wearable camera, a stationary camera, etc., can be used to capture the image(s). A confidence score of the prediction of the machine learning is determined. A surgeon can be provided an augmented visualization of the surgical procedure by displaying one or more graphical overlays based on the findings of the machine learning to enhance the surgeon-s information.","['A61B34/25', 'G06T7/70', 'A61B34/20', 'A61B90/36', 'A61B90/37', 'G06F18/24133', 'G06T11/00', 'G06T11/001', 'G06T7/0012', 'G06T7/11', 'G06T7/20', 'G06T7/50', 'G06T7/74', 'G06V10/26', 'G06V10/774', 'G06V20/41', 'G06V20/50', 'G16H20/40', 'G16H30/40', 'G16H40/20', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/20', 'A61B2017/00026', 'A61B2017/00119', 'A61B2034/107', 'A61B2034/2065', 'A61B2034/252', 'A61B2090/364', 'A61B2090/365', 'A61B2090/371', 'A61B2090/372', 'G06T2207/10016', 'G06T2207/10068', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2210/41', 'G06V2201/03', 'G06V2201/031', 'G06V2201/034']"
US11689944B2,Traffic flow classification using machine learning,"Methods, systems, and apparatus, including computer programs encoded on computer-storage media, for traffic flow classification using machine learning. In some implementations, a communication device includes an anomaly detector comprising a machine learning model trained to predict whether data traffic patterns differ from a set of observed traffic patterns present in a set of training data. The communication device includes a traffic classifier comprising a machine learning model trained to predict a quality of service (QoS) class for network connections or data flows. The communication device is configured to evaluate network connections or data flows using the anomaly detector. The communication device may (i) use the traffic classifier to predict QoS classes for traffic that the anomaly detector predicts to be similar to the observed traffic patterns, and (ii) store data traffic that the anomaly detector predicts to be different from the observed traffic patterns.","['H04L41/147', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/09', 'H04L41/145', 'H04L43/026', 'H04L47/127', 'H04L47/2441', 'H04L47/83', 'H04W24/08', 'H04W24/10', 'H04W28/24', 'G06N3/044', 'H04L43/04']"
US11790596B2,Bayesian machine learning system for adaptive ray-tracing,"Various techniques for adaptive rendering of images with noise reduction are described. More specifically, the present disclosure relates to approaches for rendering and denoising images—such as ray-traced images—in an iterative process that distributes computational efforts to pixels where denoised output is predicted with higher uncertainty. In some embodiments, an input image may be fed into a deep neural network (DNN) to jointly predict a denoised image and an uncertainty map. The uncertainty map may be used to create a distribution of additional samples (e.g., for one or more samples per pixel on average), and the additional samples may be used with the input image to adaptively render a higher quality image. This process may be repeated in a loop, until some criterion is satisfied, for example, when the denoised image converges to a designated quality, a time or sampling budget is satisfied, or otherwise.","['G06T15/06', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06T5/50', 'G06N20/10', 'G06N3/044', 'G06N5/01', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084']"
US11216950B2,Method and system for automatically segmenting blood vessel in medical image by using machine learning and image processing algorithm,A method for automatically segmenting three-dimensional blood vessel data from three-dimensional medical image data of a patient through the use of a computer is provided. The method includes: receiving the three-dimensional medical image data of the patient; generating three-dimensional shape machine-learning blood vessel data from the received three-dimensional medical image data through the use of a machine-learned segmentation program so as to generate three-dimensional blood vessel data; and generating corrected three-dimensional shape blood vessel data from the received three-dimensional medical image data and the generated three-dimensional shape machine-learning blood vessel data through the use of an image processing program.,"['G06T19/20', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T15/08', 'G06T3/40', 'G06T5/00', 'G06T5/002', 'G06T5/70', 'G06T7/0014', 'G06T7/11', 'G06T7/187', 'G06N20/00', 'G06N3/048', 'G06N5/01', 'G06T2207/10028', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10136', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/30101', 'G06T2210/41', 'G06T2219/2021']"
US11264128B2,Machine-learning framework for coordinating and optimizing healthcare resource utilization and delivery of healthcare services across an integrated healthcare system,"Techniques are described optimizing operations of an integrated healthcare system in real-time using a machine learning framework. In one embodiment, a method comprises monitoring, by a system operatively coupled to a processor, activity of healthcare workers of a healthcare system over a defined timeframe in association with operation of the healthcare system, including monitoring performance of healthcare tasks scheduled for performance over the defined timeframe. The method further comprises determining, by the system based on the monitoring, a timeslot within the defined timeframe in which a healthcare worker of the healthcare workers is not performing, anticipated to perform, or scheduled to perform a healthcare task of the healthcare tasks, and determining, by the system, a supplemental healthcare task for performance by the healthcare worker during the timeslot.","['G06Q10/063114', 'G16H40/20', 'G06N20/00', 'G16H50/20', 'G06F16/24']"
EP3786835A1,"Traffic image recognition method and apparatus, and computer device and medium","Disclosed in embodiments of the present disclosure are a traffic image recognition method and apparatus, and a computer device and a medium. The method comprises: obtaining a video stream acquired by a vehicle and extracting each image frame in the video stream as a first image; inputting the first image to an interference removal autoencoder for preprocessing to filter the interference in the first image and output a second image, wherein the interference removal autoencoder is obtained by training by using at least two types of interference sample sets, and disturbance modes added to different types of interference sample sets comprise at least two of the following: noise, affine change, filter blurring, brightness change, and monochromation; and inputting the second image to a traffic sign recognition model for recognition processing. The embodiments of the present disclosure provide an approach for correctly identifying the traffic sign after an adversarial sample attacks the traffic sign recognition model, and can reduce the interference on the adversarial sample in a traffic image, improve the recognition accuracy of the image, and improve the safety of unmanned driving or intelligent driving.","['G06V10/30', 'G06F18/214', 'G06N3/04', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/582', 'G06T2207/20081', 'G06T2207/20084']"
US11399060B2,System and method for continuous AI management and learning,"A method, computer program product, and computer system for applying deductive artificial intelligence (AI) attribution and auditability to data inputs, wherein the deductive AI may account for ontologies and competing system information, and wherein the deductive AI attribution and auditability may be applied to the data inputs by vendor workflow. The data inputs applied with the deductive AI attribution and auditability may be processed via a feedback loop to align a sense-understand-decide-act (SUDA) understanding with an inductive AI understanding. The inductive AI may be automated via the feedback loop based upon, at least in part, an AI expert system processing of the data inputs. One or more policy based rules may be developed for user automation authorization based upon, at least in part, the feedback loop.","['H04W56/001', 'H04L67/1095', 'G06F16/901', 'G06N5/022', 'G06N5/025', 'G06N5/045', 'H04L41/0213', 'H04L41/0226', 'H04L41/142', 'H04L41/16', 'H04L41/22', 'H04L43/04', 'H04L43/065', 'H04L63/0263', 'H04L63/1425', 'H04L63/1433', 'H04L63/302', 'H04L67/12', 'H04L67/565', 'H04W12/009', 'H04W12/12', 'G06N20/00', 'H04L67/02', 'H04L67/10', 'H04L67/535', 'H04L69/12', 'H04W84/18']"
US20210287071A1,Method and Apparatus for Augmented Data Anomaly Detection,"A data anomaly detection method and apparatus in which a deep neural network is trained on baseline data. Sequences of statistics of each layer of the deep neural network are saved, processed and used to train an LSTM autoencoder across a variety of reconstruction error thresholds, and a preferred threshold is selected for an optimized autoencoder. In an Inference mode, a data sample is presented to the autoencoder; the reconstruction error is calculated and compared to the threshold. If it is above the threshold, then the data sample is an out-of-distribution sample, and the sample is tagged as anomalous.","['G06N3/0454', 'G06N3/088', 'G06F18/24', 'G06F18/24133', 'G06K9/6267', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'H04L63/1425']"
AU2019202799B2,A method to automatically predict handle locations for skinningtransformations using deep learning,"Systems and techniques are described for determining image handle locations. An image is provided to a neural network as input, and the neural network translates the input image to an output image that includes clusters of pixels against a background that have intensities greater than an intensity of the background and that indicate candidate handle locations. Intensities of clusters of pixels in an output image are compared to a threshold intensity level to determine a set of the clusters of pixels satisfying an intensity constraint. The threshold intensity level can be user-selectable, so that a user can control a density of handles. A handle location for each cluster of the set of clusters is determined from a centroid of each cluster. Handle locations include a coordinate for the handle location and an attribute classifying a degree of freedom for a handle at the handle location. 1/12 100 102 104 106-1 0 10 106-2 106-3 106-5 106-6 FIG. 1","['G06T13/40', 'G06T13/00', 'G06N3/088', 'G06F18/214', 'G06F18/23', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T13/80', 'G06T3/18', 'G06T7/66', 'G06V10/763', 'G06V10/82', 'G06V40/10', 'G06T2200/24']"
CN111460494B,Multi-mode deep learning-oriented privacy protection method and system,"The invention discloses a privacy protection method and a privacy protection system for multi-modal deep learning, wherein the method can be used in the field of emotion recognition and mainly comprises the following steps: acquiring audio data to be processed, image data to be processed and text data to be processed; carrying out corresponding privacy protection processing on the audio data to be processed, the image data to be processed and the text data to be processed to obtain data to be identified; inputting data to be identified into an emotion classification model to obtain classification results of various modes; automatically distributing the weights of different modal categories and different emotion category combinations by using a weight self-selection algorithm of a dynamic routing protocol to obtain weight coefficients; obtaining an emotion recognition result according to the weight coefficient and the classification result of each mode; according to the method and the device, corresponding privacy protection processing can be adopted according to the data type, so that user information leakage is prevented, and user experience is improved.","['G06F21/6245', 'G06F18/241', 'G06F21/32', 'G06V40/172', 'Y02D10/00']"
US20220374720A1,Systems and methods for sample generation for identifying manufacturing defects,"Systems and methods for classifying products are disclosed. A first data sample having a first portion and a second portion is identified from a training dataset. A first mask is generated based on the first data sample, where the first mask is associated with the first portion of the first data sample. A second data sample is generated based on a noise input. The first mask is applied to the second data sample for outputting a third portion of the second data sample. The third portion of the second data sample is combined with the second portion of the first data sample for generating a first combined data sample. Confidence and classification of the first combined data sample are predicted. The first combined data sample is added to the training dataset in response to predicting the confidence and the classification.","['G06T7/0008', 'G06V10/774', 'G06N3/088', 'G06F18/2113', 'G06F18/214', 'G06F18/217', 'G06K9/623', 'G06K9/6256', 'G06K9/6262', 'G06K9/746', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/063', 'G06T7/0004', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V10/898', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'G06T2207/30121', 'G06V2201/06']"
CN111292264B,A high dynamic range image reconstruction method based on deep learning,"The invention discloses an image high dynamic range reconstruction method based on deep learning, and belongs to the field of computational photography and digital image processing. The invention establishes a mapping network from a single LDR image to an HDR image by adopting a method based on deep learning. The method first sequentially generates LDR training data, HDR sample labels with aligned brightness units and mask images of high brightness areas from the collected HDR data set. The neural network is then constructed and trained to obtain a network model with an LDR to HDR mapping relationship. And finally, directly inputting the LDR image into the network model by utilizing the generated network model obtained by training, and outputting the reconstructed HDR image. The method can effectively reconstruct the dynamic range of the real scene from a single common digital image, and can be used for HDR simulation effect display of the common digital image or providing more realistic rendering effect for the image illumination technology.","['G06T5/90', 'G06N3/045', 'G06N3/08', 'G06T2207/20208', 'Y02T10/40']"
US11069069B2,System for predicting movements of an object of interest with an autoencoder,"Described is a system for implicitly predicting movement of an object. In an aspect, the system includes one or more processors and a memory, the memory being a non-transitory computer-readable medium having executable instructions encoded thereon, such that upon execution of the instructions, the one or more processors perform operations of providing an image of a first trajectory to a predictive autoencoder, and using the predictive autoencoder, generating a predicted tactical response that comprises a second trajectory based on images of previous tactical responses that were used to train the predictive autoencoder, and controlling a device based on the predicted tactical response.","['G06T7/246', 'G06K9/00724', 'G06K9/4628', 'G06T7/20', 'G06V10/454', 'G06V10/82', 'G06V20/42', 'H04N19/537', 'G06F18/2135', 'G06K9/6247', 'G06T2207/20081', 'G06T2207/30221', 'G06T2207/30241']"
US11399288B2,Method for HTTP-based access point fingerprint and classification using machine learning,"A method for HyperText Transfer Protocol (HTTP) based fingerprint and classification. The method includes training a HTTP-based machine-learning model, using machine-learning training techniques and a historical dataset of labelled Access Point HTTP service response features collected. The method is useful to detect benign or malicious classes, to assess the potential trustworthiness, to detect any type of bad behavior of an HTTP server, and any other threats that modify or implement an AP HTTP server or webpage. The method takes advantage of the captive portal detection packet exchange between a station and an Access Point (AP) to passively classify the AP.","['H04L63/1483', 'G06N20/20', 'H04L63/1433', 'H04L63/1466', 'H04W12/122', 'H04W12/66', 'H04W12/79', 'H04L63/123']"
US11908233B2,Normalization of facial images using deep neural networks,"A system, method, and apparatus for generating a normalization of a single two-dimensional image of an unconstrained human face. The system receives the single two-dimensional image of the unconstrained human face, generates an undistorted face based on the unconstrained human face by removing perspective distortion from the unconstrained human face via a perspective undistortion network, generates an evenly lit face based on the undistorted face by normalizing lighting of the undistorted face via a lighting translation network, and generates a frontalized and neutralized expression face based on the evenly lit face via an expression neutralization network.","['G06V40/169', 'G06V40/161', 'G06T5/006', 'G06T5/60', 'G06T5/80', 'G06T5/94', 'G06V10/764', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30201']"
US10922793B2,Guided hallucination for missing image content using a neural network,"Missing image content is generated using a neural network. In an embodiment, a high resolution image and associated high resolution semantic label map are generated from a low resolution image and associated low resolution semantic label map. The input image/map pair (low resolution image and associated low resolution semantic label map) lacks detail and is therefore missing content. Rather than simply enhancing the input image/map pair, data missing in the input image/map pair is improvised or hallucinated by a neural network, creating plausible content while maintaining spatio-temporal consistency. Missing content is hallucinated to generate a detailed zoomed in portion of an image. Missing content is hallucinated to generate different variations of an image, such as different seasons or weather conditions for a driving video.","['G06T5/77', 'G06T5/005', 'G06F18/214', 'G06K9/6256', 'G06K9/726', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T5/50', 'G06T5/60', 'G06V30/274', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
US20200160176A1,System and method for generative model for stochastic point processes,"A variational auto-encoder model is trained to generate probabilities of action categories and probabilities of inter-arrival times of next action from a sequence of past actions by generating a concatenated representation of each action and associated time, encoding the concatenated representations, determining a conditional prior distribution for a next action, determining a conditional posterior distribution for the current action, sampling a latent variable from the conditional prior distribution, generating a probability distribution over a current action category, and generating a probability distribution over inter-arrival times for the current action category.","['G06N3/08', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/048']"
US11544928B2,Athlete style recognition system and method,"A system and method leverages understanding of complex dribbling video clips by representing a video sequence with a single Dribble Energy Image (DEI) that is informative for dribbling styles recognition. To overcome the shortage of labelled data, a dataset of soccer video clips employs Mask-RCNN to segment out dribbling players and OpenPose to obtain joints information of dribbling players. To solve issues caused by camera motions in highlight soccer videos, the system registers a video sequence to generate a single image representation DEI and dribbling styles classification.","['G06N3/088', 'A63B67/002', 'A63B69/002', 'G06F18/24', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V20/42', 'G06V40/23', 'G06V40/25']"
US11568109B2,Experience learning in virtual world,A computer-implemented method of machine-learning is described that includes obtaining a dataset of virtual scenes. The dataset of virtual scenes belongs to a first domain. The method further includes obtaining a test dataset of real scenes. The test dataset belongs to a second domain. The method further includes determining a third domain. The third domain is closer to the second domain than the first domain in terms of data distributions. The method further includes learning a domain-adaptive neural network based on the third domain. The domain-adaptive neural network is a neural network configured for inference of spatially reconfigurable objects in a real scene. Such a method constitutes an improved method of machine learning with a dataset of scenes including spatially reconfigurable objects.,"['G06F30/27', 'G06F30/17', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/04', 'G06F2111/00', 'G06F2111/18', 'G06F30/12', 'G06N3/008', 'G06N3/0454', 'G06N3/047', 'G06N3/0472']"
US10650245B2,"Generating digital video summaries utilizing aesthetics, relevancy, and generative neural networks","The present disclosure relates to systems, methods, and non-transitory computer readable media for generating digital video summaries based on analyzing a digital video utilizing a relevancy neural network, an aesthetic neural network, and/or a generative neural network. For example, the disclosed systems can utilize an aesthetics neural network to determine aesthetics scores for frames of a digital video and a relevancy neural network to generate importance scores for frames of the digital video. Utilizing the aesthetic scores and relevancy scores, the disclosed systems can select a subset of frames and apply a generative reconstructor neural network to create a digital video reconstruction. By comparing the digital video reconstruction and the original digital video, the disclosed systems can accurately identify representative frames and flexibly generate a variety of different digital video summaries.","['G06K9/00751', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/47', 'G11B27/031', 'H04N21/23418', 'H04N21/8456', 'G06N3/047', 'H04N21/8549']"
US20200364571A1,Machine learning-based data processing method and related device,"A machine learning-based data processing method and a related device, to resolve a prior-art problem that service experience is affected due to an increase in an exchange latency are disclosed. The method in the embodiments of this application includes: receiving, by a first network element, installation information of an algorithm model from a second network element, where the first network element is a user plane network element UPF or a base station, and the second network element is configured to train the algorithm model; installing, by the first network element, the algorithm model based on the installation information of the algorithm model; and collecting, by the first network element, data after the algorithm model is successfully installed, and performing prediction based on the data by using the algorithm model.","['G06N20/20', 'G06F18/214', 'G06F18/2411', 'G06F18/24323', 'G06F18/27', 'G06N3/0481', 'G06N3/08', 'G06N3/084', 'G06N5/01', 'G06N7/01', 'H04L41/16', 'H04W24/04', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'H04W88/08']"
CN114493991B,"Style transfer system, method, and device based on attention recurrent adversarial network","The invention discloses a style migration system, a method and a device based on an attention cycle countermeasure network, wherein the method firstly selects A and B images of two different styles of images to be input into the network; A, randomly nested cutting a plurality of small blocks of an image A, inputting the small blocks into a multi-scale block transducer encoder for learning features, merging low-dimensional global information layer by layer through deconvolution and up-sampling, finally merging high-dimensional global information subjected to dynamic filtering to generate migration results, simultaneously training the mapping of A2B and B2A in a cyclic countermeasure mode, introducing a block-based discriminator and content loss function training convergence, and finally completing the mutual migration of styles of A and B. The invention provides a zero-order learning style migration method based on a cyclic countermeasure network for the first time, and a real and reasonable migration effect can be generated by utilizing the relation characteristics between the interior of a small excavation block and the blocks of a nested cutting small excavation block. The method is superior to the existing method, and has the advantages of strong universality, small data dependence, strong individuation of style generation and the like.","['G06T3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T9/002']"
US11756567B2,Autocreation of conversational image representation,"In an approach to generating conversational image representations, one or more computer processors detect one or more utterances by a user, wherein utterances are either textual or acoustic. The one or more computer processors generate one or more image representations of the one or more detected utterances utilizing a generative adversarial network restricted by one or more user privacy parameters, wherein the generative adversarial network is fed with an extracted sentiment, a generated avatar, an identified topic, an extracted location, and one or more user preferences. The one or more computer processors display the generated one or more image representations on one or more devices associated with respective one or more recipients of the one or more utterances.","['G10L21/10', 'G06Q50/01', 'G06F21/32', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/049', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T13/205', 'G06T13/40', 'G06N3/044', 'G10L25/63']"
US11842517B2,Using iterative 3D-model fitting for domain adaptation of a hand-pose-estimation neural network,"Described is a solution for an unlabeled target domain dataset challenge using a domain adaptation technique to train a neural network using an iterative 3D model fitting algorithm to generate refined target domain labels. The neural network supports the convergence of the 3D model fitting algorithm and the 3D model fitting algorithm provides refined labels that are used for training of the neural network. During real-time inference, only the trained neural network is required. A convolutional neural network (CNN) is trained using labeled synthetic frames (source domain) with unlabeled real depth frames (target domain). The CNN initializes an offline iterative 3D model fitting algorithm capable of accurately labeling the hand pose in real depth frames. The labeled real depth frames are used to continue training the CNN thereby improving accuracy beyond that achievable by using only unlabeled real depth frames for domain adaptation.","['G06T7/75', 'G06F18/2111', 'G06F18/2155', 'G06F18/217', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/126', 'G06V10/426', 'G06V10/764', 'G06V10/82', 'G06V20/653', 'G06V40/11', 'G06V40/28', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
CN110111236B,Multi-object sketch image generation based on progressive adversarial generative networks,"The invention provides a method for generating an image based on a multi-target sketch of a progressive confrontation generation network, which is used for facilitating generation of texture and color of an example and generation of a whole image relation by decoupling the generation processes of the example and the whole image. And the judgment sketch augmentation technology is used, and the sketch information of the judgment area is obtained, so that the image generation process has more accurate structural constraint. The method provided by the invention solves the problem that the existing network ignores the distribution of the example part in the image due to learning the distribution of the whole image and generates the same texture and color on different examples, and obtains a higher inclusion Score and a lower Fre' chemotherapy initiation distance in the MS-COCO data set, namely the method of the invention obtains good results on the quality and diversity of the generated data.","['G06T3/04', 'G06T7/13', 'G06T2207/20081', 'G06T2207/20084']"
US10699055B2,Generative adversarial networks for generating physical design layout patterns,"A method for generating physical design layout patterns includes selecting as training data a set of physical design layout patterns of features in a given layer of a given patterned structure and converting the physical design layout patterns into two-dimensional (2D) arrays comprising entries for different locations in the given layer of the given patterned structure with values representing presence of the features at the different locations. The method also includes training, utilizing the 2D arrays, a generative adversarial network (GAN) comprising a discriminator neural network and a generator neural network. The method further includes generating one or more synthetic 2D arrays utilizing the trained generator neural network of the GAN, a given synthetic 2D array comprising entries for different locations in the given layer of a new physical design layout pattern with values representing presence of the features at the different locations of the new physical design layout pattern.","['G06N3/08', 'G06F30/27', 'G06F30/398', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06F2111/20', 'G06F2119/18', 'G06N3/044', 'G06N3/048', 'Y02P90/02']"
CN110660038B,A Fusion Method of Multispectral Image and Panchromatic Image Based on Generative Adversarial Network,"The invention discloses a multispectral image and full-color image fusion method based on a generated countermeasure network. The method comprises the following steps: firstly, collecting multispectral image and panchromatic image data sets, registering the images, and dividing the data sets into a training set and a testing set; then constructing a feature extraction network, and inputting the feature extraction network into a full-color image; and secondly, constructing and generating an countermeasure network, optimizing a discriminator by using the Wassertein distance, inputting a multispectral image, outputting a fused high-resolution multispectral image, finally training and generating the countermeasure network, and testing by using a test set. In particular, the method does not need extra processing flow and is a method for realizing multi-spectrum image fusion end to end. In addition, the method takes a large amount of data as a fusion mapping relation for driving learning, and for most images of different data sets, the method can enable the fused image to better maintain the spectrum information of the original multispectral image while injecting space detail information.","['G06T5/50', 'G06T3/4053', 'G06T7/30', 'G06T2207/10036', 'G06T2207/10041', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'Y02T10/40']"
US10862926B2,Cybersecurity threat detection and mitigation system,"Apparatus and methods are provided for graphically defining a real-world cybersecurity protocol of an entity. The graphical platform includes searchable, manipulatable, graphs mapping cybersecurity threats. Manipulating nodes and relationships within the graphs translates into real-time modification of a cybersecurity protocol in effect for the entity. An ability to map known cybersecurity threats and analyze them (even according to known frameworks) may streamline and integrate efforts of cybersecurity defense teams. Graphical representation of a security protocol facilitates proactive threat hunting as well as expediting incident response activities by providing evidence-based pathways to inform impact analysis and source event analysis.","['H04L63/20', 'G06F21/577', 'G06F16/951', 'H04L63/1416', 'H04L63/1441', 'G06F2221/2101', 'G06F2221/2111']"
US11900940B2,Processing speech signals of a user to generate a visual representation of the user,"A computing system for generating image data representing a speaker's face includes a detection device configured to route data representing a voice signal to one or more processors and a data processing device comprising the one or more processors configured to generate a representation of a speaker that generated the voice signal in response to receiving the voice signal. The data processing device executes a voice embedding function to generate a feature vector from the voice signal representing one or more signal features of the voice signal, maps a signal feature of the feature vector to a visual feature of the speaker by a modality transfer function specifying a relationship between the visual feature of the speaker and the signal feature of the feature vector; and generates a visual representation of at least a portion of the speaker based on the mapping, the visual representation comprising the visual feature.","['G10L21/10', 'G10L15/22', 'G06T11/60', 'G10L13/00', 'G10L15/02', 'G10L15/26', 'G10L2021/105']"
US11586841B2,Method and system for generating user driven adaptive object visualizations using generative adversarial network models,"A method and system for generating user driven adaptive object visualizations using Generative Adversarial Network (GAN) models is disclosed. The method includes the steps of generating a first set of object vectors for an object based on at least one input received from a user. The first set of vectors corresponds to a first set of visualizations for the object The method further includes capturing at least one tacit reaction type of the user in response to user interaction with each of the first set of visualizations, computing a score for each portion of each of the first set of visualizations, identifying a plurality of portions from at least one of the first set of object visualizations, generating a second set of object vectors, and processing the second set of object vectors sequentially through a plurality of GAN models to generate a final object visualization of the object.","['G06F16/26', 'G06K9/6253', 'G06F18/214', 'G06F18/217', 'G06F18/40', 'G06K9/6256', 'G06K9/6262', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T15/00', 'G06T19/20', 'G06V10/454', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V10/945', 'G06T2200/24', 'G06T2210/16', 'G06T2219/2024']"
US11501415B2,Method and system for high-resolution image inpainting,"Methods and systems for high-resolution image inpainting are disclosed. An original high-resolution image to be inpainted is obtained, as well as an inpainting mask indicating an inside-mask area to be inpainted. The original high-resolution image is down-sampled to obtain a low-resolution image to be inpainted. Using a trained inpainting generator, a low-resolution inpainted image and a set of attention scores are generated from the low-resolution image. The attention scores represent the similarity between inside-mask regions and outside-mask regions. A high-frequency residual image is computed from the original high-resolution image. An aggregated high-frequency residual image is generated using the attention scores, including high-frequency residual information for the inside-mask area. A high-resolution inpainted image is outputted by combining the aggregated high-frequency residual image and a low-frequency inpainted image generated from the low-resolution inpainted image.","['G06T5/77', 'G06T5/005', 'G06F18/22', 'G06K9/6215', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06T5/60', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US11961233B2,"Method and apparatus for training image segmentation model, computer device, and storage medium","This application provides a method and apparatus for training an image segmentation model, a device, and a storage medium. The method includes: training an initial image segmentation model by using source domain samples, to obtain a pre-trained image segmentation model; extracting a predicted segmentation result of a source domain image and a predicted segmentation result of a target domain image by using the pre-trained image segmentation model; training a first discriminator by using the predicted segmentation result of the source domain image and the predicted segmentation result of the target domain image; training a second discriminator by using the predicted segmentation result of the source domain image and a standard segmentation result of the source domain image; and iteratively training the pre-trained image segmentation model according to a loss function of the pre-trained image segmentation model, an adversarial loss function of the first discriminator, and an adversarial loss function of the second discriminator, until convergence, to obtain a trained image segmentation model.","['G06T7/0012', 'G06F18/241', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/11', 'G06T7/162', 'G06T7/174', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/048', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/031']"
US11244671B2,Model training method and apparatus,"A model training method and apparatus is disclosed, where the model training method acquires first output data of a student model for first input data and second output data of a teacher model for second input data and trains the student model such that the first output data and the second output data are not distinguished from each other. The student model and the teacher model have different structures.","['G06N3/088', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06N3/096', 'G10L15/063', 'G10L15/16', 'G10L15/183', 'G06N3/084']"
US10839578B2,"Artificial-intelligence enhanced visualization of non-invasive, minimally-invasive and surgical aesthetic medical procedures","A method includes obtaining, by a processor, an image of a patient using an imaging device, presenting the image of the patient on a display, and selecting one or more medical procedures to apply to the patient. The method further includes generating a modified image of the patient by applying the one or more medical procedures and the image of the patient as input to a machine learning model trained to output the modified image of the patient. The modified image of the patient includes one or more body region representations of the patient that are modified due to application of the one or more medical procedures to the image of the patient. The method also includes presenting the modified image of the patient on the display.","['G06T11/60', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06N3/044', 'G06N3/047', 'G06T2200/21', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/30196', 'G06T2210/41', 'G06T7/70']"
US11856021B2,Detecting and mitigating poison attacks using data provenance,"Computer-implemented methods, program products, and systems for provenance-based defense against poison attacks are disclosed. In one approach, a method includes: receiving observations and corresponding provenance data from data sources; determining whether the observations are poisoned based on the corresponding provenance data; and removing the poisoned observation(s) from a final training dataset used to train a final prediction model. Another implementation involves provenance-based defense against poison attacks in a fully untrusted data environment. Untrusted data points are grouped according to provenance signature, and the groups are used to train learning algorithms and generate complete and filtered prediction models. The results of applying the prediction models to an evaluation dataset are compared, and poisoned data points identified where the performance of the filtered prediction model exceeds the performance of the complete prediction model. Poisoned data points are removed from the set to generate a final prediction model.","['H04L63/1466', 'G06F18/10', 'G06F18/2113', 'G06F18/214', 'G06F18/217', 'G06F21/55', 'G06N20/00', 'H04L63/123', 'H04L63/1441', 'H04L2463/145']"
US12198416B2,Systems and methods for identifying and segmenting objects from images,"Systems and methods for identifying and segmenting objects from images include a preprocessing module configured to adjust a size of a source image; a region-proposal module configured to propose one or more regions of interest in the size-adjusted source image; and a prediction module configured to predict a classification, bounding box coordinates, and mask. Such systems and methods may utilize end-to-end training of the modules using adversarial loss, facilitating the use of a small training set, and can be configured to process historical documents, such as large images comprising text. The preprocessing module within the systems and methods can utilize a conventional image scaler in tandem with a custom image scaler to provide a resized image suitable for GPU processing, and the region-proposal module can utilize a region-proposal network from a single-stage detection model in tandem with a two-stage detection model paradigm to capture substantially all particles in an image.","['G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T7/11', 'G06V10/32', 'G06V10/82', 'G06V30/19173', 'G06V30/414', 'G06N3/08', 'G06T2207/20021', 'G06T2207/20024']"
US12039647B1,Systems and methods for synthetic image generation,"A system includes memory devices storing instructions, and one or more processors configured to execute instructions performing method steps. The method may include training a generator, encoder, and discriminator of a synthetic image generation system to enable creation of synthetic images that comply with one or more image classification requirements. A generator and discriminator may be trained in an adversarial relationship. Training may be completed when the generator outputs a synthetic image that matches a target image beyond a first predetermined threshold of accuracy and the encoder outputs a latent feature vector that matches an input latent feature vector beyond a second predetermined threshold of accuracy. After training the system may be configured to generate synthetic images that comply with one or more image classification requirements.","['G06T11/60', 'G06F18/2178', 'G06F18/2433', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06V10/774', 'G06V10/82', 'G06T2200/24', 'G06V20/56']"
CN111191835B,IES Incomplete Data Load Forecasting Method and System Based on C-GAN Migration Learning,"The invention provides an IES incomplete data load prediction method and system based on C-GAN transfer learning. Firstly, original sample data are collected and normalized, then the sample data after normalization are extracted by adopting a depth variation self-coding network, the extracted sample features are input into a first constructed C-GAN generator, incomplete sample data are expanded when the Nash equilibrium is achieved by the generator and the discriminator game, an expanded sample data set is input into a second constructed conditional C-GAN generator, electric, gas and heat loads are predicted in parallel when the Nash equilibrium is achieved by the generator and the discriminator game, prediction precision is judged by the discriminator based on the C-GAN, and the prediction precision of comprehensive energy load prediction is continuously corrected and improved in the Nash equilibrium process is achieved by the generator and the discriminator game.","['G06Q10/04', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'Y04S10/50']"
CN117879970B,Network security protection method and system,"The invention discloses a network security protection method and system, which relate to the technical field of network security and comprise the steps of collecting multi-mode data in real time; converting the raw data into a standardized format for machine learning using a multimodal data fusion algorithm; updating a threat identification model in real time by adopting a streaming data processing and dynamic incremental learning algorithm, and optimizing a learning process and a threat library through active learning and crowdsourcing safety strategies; simulating potential attack paths and strategies by adopting sandbox technology and virtual network environment, and monitoring and analyzing conventional network behaviors to identify anomalies and potential threats; an automated response and repair mechanism is introduced to respond and process the detected threat in real time. According to the invention, by deploying the intelligent acquisition agent at the key network node and combining with the network topology analysis optimized by artificial intelligence, targeted and efficient data coverage can be realized, and the comprehensive acquisition of key information is ensured.","['H04L63/20', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L9/40']"
CN113538664B,"Vehicle de-illumination three-dimensional reconstruction method and device, electronic equipment and storage medium","The application provides a vehicle de-illumination three-dimensional reconstruction method and device. The method comprises the following steps: acquiring a textured vehicle three-dimensional model, and rendering the vehicle three-dimensional model under different viewing angles and different illumination conditions to obtain original data; the method comprises the steps that original data comprise an original picture and camera internal and external parameters corresponding to the original picture; building a generative confrontation neural network, and training the generative confrontation neural network according to original data; acquiring RGB (red, green and blue) pictures of vehicles on a road by a color camera based on target camera parameters, taking the acquired RGB pictures as an input part of a trained generative confrontation neural network, rendering from multiple angles to acquire density distribution of a reconstructed scene, and selecting points with density values meeting preset conditions as reconstructed point clouds; and after point cloud noise points are removed, a Poisson reconstruction algorithm is adopted to obtain a surface grid model of the vehicle, and the surface grid model is simplified to obtain a three-dimensional model of the vehicle containing the information of the light removal color textures and the material quality.","['G06T17/00', 'G06N3/045', 'G06N3/08', 'G06T2200/04']"
US10885531B2,Artificial intelligence counterfeit detection,"A counterfeit detection system provides an artificial intelligence (AI) platform that implements a Generative Adversarial Network (GAN) to classify an image as one of a fake or genuine item and integrates a Classification Activation Module (CAM) to refine counterfeit detection. The GAN may include a generator that generates simulated counterfeit images for a discriminator. The discriminator may be trained to identify faked items by learning from the simulated counterfeit images and/or images of actual faked items. The discriminator may implement a deep neural network of convolutional layers that each analyze a region of an image and produce a weighted output that contributes to the classification based on the analyzed region. The CAM may identify the regions and weights relied upon by the discriminator, provide corresponding heatmaps to subject matter experts, receive annotations from the subject matter experts, and use the annotations as feedback to refine the classifier of the discriminator.","['G06Q30/0185', 'G06F18/2413', 'G06K9/00577', 'G06T3/4076', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/66', 'G06V20/95', 'G06K2009/0059', 'G06T2207/20081', 'G06V20/80', 'G06V30/10']"
US11894012B2,Neural-network-based approach for speech denoising,"Disclosed are methods, systems, device, and other implementations, including a method that includes receiving an audio signal representation, detecting in the received audio signal representation, using a first learning model, one or more silent intervals with reduced foreground sound levels, determining based on the detected one or more silent intervals an estimated full noise profile corresponding to the audio signal representation, and generating with a second learning model, based on the received audio signal representation and on the determined estimated full noise profile, a resultant audio signal representation with a reduced noise level.","['G10L21/0208', 'G10L21/0232', 'G10L25/30', 'G10L25/84', 'G10L2021/02168', 'G10L21/0308', 'G10L25/18']"
US20240142342A1,Cross-domain mechanical fault diagnosis method based on multi-channel feature fusion of cbam and use thereof,"The present invention belongs to the technical field of mechanical fault data recognition, and discloses a cross-domain mechanical fault diagnosis method based on multi-channel feature fusion of an improved CBAM and use thereof, wherein the method comprises: conducting preliminary feature extraction in a grey-scale graph formed by original signals with convolutional neural network, obtaining high-level features, and compressing the high-level features with a full-connection layer module; conducting deep-level multi-sensor feature extraction with an improved convolutional block attention module (CBAM); conducting fusion for multi-sensor features extracted with an improved convolutional block attention module and obtaining multi-sensor fusion features; and inputting the multi-sensor fusion features into a tag assignor for fault diagnosis results. In the present invention, the latest multi-channel domain adaptation fault diagnosis method is used to realize efficiently intelligent fault diagnosis tasks of bearings in different working states.","['G06N3/08', 'G01M13/028', 'G01M13/045', 'G06F18/253']"
CN111967477B,"RGB-D image saliency target detection method, device, equipment and storage medium","The invention discloses a RGB-D image saliency target detection method, a device, equipment and a computer readable storage medium, wherein the RGB-D image saliency target detection method avoids the introduction of useless or redundant information in the modal characteristics by adopting an attention mechanism instead of directly using and fusing the layered RGB modal characteristics and the layered depth modal characteristics, and improves the performance of saliency target detection; the multi-stage cross-modal feature fusion is carried out by designing a cross-modal guiding strategy, so that the effectiveness and complementarity among cross-modal multi-features can be fully utilized, and more accurate cross-modal remarkable feature expression is formed while the influence of depth images with poor quality is reduced; through designing a bidirectional fusion structure, the multi-level cross-modal fusion features are subjected to multi-scale fusion, so that high-level features and low-level features in multiple levels can be effectively aggregated, and the detection performance of a salient target and the robustness of a detection algorithm are further improved.","['G06V10/462', 'G06T5/50', 'G06T7/30', 'G06T7/50', 'G06T7/90', 'G06T2207/20221', 'G06V2201/07']"
CN113468521B,Data protection method for federal learning intrusion detection based on GAN,"The invention belongs to the technical field of intrusion detection, and particularly relates to a data protection method for GAN-based federal learning intrusion detection. The invention combines the loose differential privacy protection technology with the confrontation generation neural network, reduces the communication loss of each terminal in the federal learning framework, improves the learning efficiency, can well solve the condition of lower calculation force of each terminal in the federal, and improves the utilization efficiency of the machine. The dynamic fuzzy data generated by the anti-generation neural network used by the invention can expand the local training data set while the attacker can not judge the successful attack condition, thereby solving the possible problem of small samples. The invention can effectively reduce the communication loss in the federal learning framework, can effectively improve the training efficiency, simultaneously solves the problems of susceptibility to reasoning attack and small sample data and non-independent and same distributed data of the intrusion detection terminal in the federate learning, and can realize the federate learning intrusion detection for resisting the reasoning attack.","['G06F21/55', 'G06F18/214', 'G06F21/602', 'G06F21/6245', 'G06N3/043', 'G06N3/08']"
CN114707227B,Dam safety early warning and alarm eliminating method and system based on digital twinning,"The invention discloses a dam safety early warning and alarm eliminating method and system based on digital twinning, comprising the following steps: constructing a digital twin dam with the same safety state as an objective physical dam, consistent influence factors, equivalent measurable response and fidelity of a multidimensional scene through a self-adaptive numerical simulation, a comprehensive evaluation model, a dynamic recursion data driving model, an online data assimilation model, an abnormality diagnosis reasoning model, a behavior understanding model, a live-action and XR model and a data and mechanism mixed driving control model; the objective physical dam is subjected to information sensing and optimization, information abnormality diagnosis, structural safety and system working state online evaluation, dam safety state accurate prediction, effective early warning of failure results, reasonable regulation and control of dam safety states and targeted recommendation of follow-up measures through the digital twin dam. The invention has complete system, innovation and outstanding practicability and has good popularization and application values.","['G06F30/13', 'G06F30/23', 'G06F30/27', 'G06F2119/02', 'Y02A10/40']"
US10581894B2,Assessing effectiveness of cybersecurity technologies,"A method for assessing effectiveness of one or more cybersecurity technologies in a computer network includes testing each of two or more component stages of an attack model at a first computer network element twice. A first one of the tests is conducted with a first one of the cybersecurity technologies operable to protect the first computer network element, and a second one of the tests is conducted with the first cybersecurity technology not operable to protect the first computer network element. For each one of the twice-tested component stages, comparing results from the first test and the second test, wherein the comparison yields or leads to information helpful in assessing effectiveness of the first cybersecurity technology on each respective one of the twice-tested component stages at the computer network element.","['H04L63/1433', 'H04L63/20']"
US12380318B2,Semi-supervised hyperspectral data quantitative analysis method based on generative adversarial network,"Disclosed is a hyperspectral data analysis method based on a semi-supervised learning strategy, which includes: hyperspectral sample data is acquired; a sample training set and a prediction set are constructed, herein an unlabeled prediction set sample is used; a regression network based on a generative adversarial network is constructed, including a generator network that generates a sample, and a discriminator/regressor network that has functions of judging the authenticity of the sample and outputting a quantitative analysis value at the same time; a loss function of the generative adversarial network is constructed, including a loss function of the discriminator, a loss function of the regressor, and a loss function of the generator with a sample distribution matching function. The generative adversarial network is used to generate a sample. A sample distribution matching strategy is used to supplement an existing unlabeled sample set. So, the accuracy of hyperspectral quantitative analysis is improved.","['G01N21/25', 'G06F18/2135', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G01N21/359']"
US20210118136A1,Artificial intelligence for personalized oncology,"Techniques performed by a data processing system for operating a personalized oncology system herein include accessing a first histopathological image of a histopathological slide of a sample taken from a first patient; analyzing the first histopathological image using a first machine learning model configured to extract first features from the first histopathological image; searching a histological database that includes a plurality of second histopathological images and corresponding clinical data for a plurality of second patients to generate search results; analyzing the plurality of third histopathological images and the corresponding clinical data associated with the plurality of third histopathological images using statistical analysis techniques to generate associated statistics and metrics associated with mortality, morbidity, time-to-event, or a combination thereof for the plurality of third patients associated with the third histopathological images; and presenting an interactive visual representation of the associated statistics and metrics including information for the personalized therapeutic plan for treating the first patient.","['G16H50/70', 'G02B21/365', 'G06F16/535', 'G06T7/0012', 'G06T7/0014', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/698', 'G16B20/20', 'G16B40/00', 'G16B50/00', 'G16H20/40', 'G16H50/20', 'G16H50/30', 'G02B21/34', 'G06F18/214', 'G06K9/00147', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G16H10/60', 'G16H30/20', 'G16H30/40']"
CN111652827B,Front face synthesis method and system based on generation countermeasure network,"The invention provides a front face synthesis method and a system based on a generation countermeasure network, which are used for detecting and segmenting a face part from an input image, and aligning the face to acquire a face image to be synthesized; estimating the head pose of the human face according to the key points of the human face, and dividing the human face data set into a front human face set and a non-front human face set according to the rotational freedom of the head; extracting the identity characteristics of an input face image by using a pre-training model of a face recognition deep neural network to train a supervision network; and synthesizing corresponding front face images based on the generation countermeasure network according to the input side face images. The face symmetry constraint and the identity feature constraint make the synthesized face more natural and better maintain the identity feature.","['G06T7/11', 'G06N3/045', 'G06N3/084', 'G06T3/60', 'G06T5/50', 'G06T7/194', 'G06T7/50', 'G06V40/171', 'G06T2207/20221', 'Y02T10/40']"
US11301996B2,Training neural networks of an automatic clinical workflow that recognizes and analyzes 2D and doppler modality echocardiogram images,"A method for training neural networks of an automated workflow performed by a software component executing on a server in communication with remote computers at respective laboratories includes downloading and installing a client and a set of neural networks to a first remote computer of a first laboratory, the client accessing the echocardiogram image files of the first laboratory to train the set of neural networks and to upload a first trained set of neural networks to the server. The process continues until the client and the second trained set of neural networks is downloaded and installed to a last remote computer of a last laboratory, the client accessing the echocardiogram image files of the last laboratory to continue to train the second trained set of neural networks and to upload a final trained set of neural networks to the server.","['G16H30/20', 'G06T7/0012', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06T7/11', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048']"
US11379685B2,Machine learning classification system,"A computing device classifies unclassified observations. A first batch of unclassified observation vectors and a first batch of classified observation vectors are selected. A prior regularization error value and a decoder reconstruction error value are computed. A first batch of noise observation vectors is generated. An evidence lower bound (ELBO) value is computed. A gradient of an encoder neural network model is computed, and the ELBO value is updated. A decoder neural network model and an encoder neural network model are updated. The decoder neural network model is trained. The target variable value is determined for each observation vector of the unclassified observation vectors based on an output of the trained decoder neural network model. The target variable value is output.","['G06N3/08', 'G06K9/6223', 'G06F18/2155', 'G06F18/23213', 'G06K9/6259', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06V10/7753', 'G06V10/82']"
WO2023201552A1,County-wide photovoltaic prediction method based on cluster division and data enhancement,"The present invention discloses a county-wide distributed photovoltaic prediction method based on cluster division and data enhancement. The prediction method is as follows: selecting a typical power curve in a sunny day from the photovoltaic (PV) output history database of the entire county, and standardizing the output with the maximum power of the station. Pearson correlation coefficient is used as the distance measure, and the Density-Based Spatial Clustering of Applications with Noise (DBSCAN) is used to cluster photovoltaic stations to form a cluster division. The outliers are divided into nearest clusters using k-nearest neighbor search method. An enhanced Generative Adversarial Networks (GAN) is used to augment the historical data; the original data and the generated data are jointly used to train the deep convolutional network prediction model. The present invention learns the original data distribution through the training process of the enhanced GAN and then generates correspondingly distributed data to enhance the entire county photovoltaic historical database. Finally the invention trains the deep convolutional neural network through the enhanced training set to improve the accuracy of prediction.","['G06N20/20', 'G06N3/045', 'G06Q10/04', 'G06Q50/06']"
US11740618B2,Systems and methods for global cyber-attack or fault detection model,"An industrial asset may have monitoring nodes that generate current monitoring node values representing a current operation of the industrial asset. An abnormality detection computer may detect when a monitoring node is currently being attacked or experiencing a fault based on a current feature vector, calculated in accordance with current monitoring node values, and a detection model that includes a decision boundary. A model updater (e.g., a continuous learning model updater) may determine an update time-frame (e.g., short-term, mid-term, long-term, etc.) associated with the system based on trigger occurrence detection (e.g., associated with a time-based trigger, a performance-based trigger, an event-based trigger, etc.). The model updater may then update the detection model in accordance with the determined update time-frame (and, in some embodiments, continuous learning).","['G05B23/024', 'G05B19/0428', 'G05B23/0221', 'G05B23/027', 'G06F21/552', 'G06N3/006', 'G06N3/045', 'G06N3/0475', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096']"
CN113375941B,Open-collector fault diagnosis method for high-speed EMU bearings,"The disclosure discloses a method for diagnosing an open-set fault of a high-speed motor train unit bearing, which comprises the following steps: collecting vibration signals of bearings of the running high-speed motor train unit through an acceleration sensor; aiming at an open set diagnosis scene under a constant working condition, training data with labels is input to train the one-dimensional convolutional neural network; aiming at an open set diagnosis scene of working condition change, inputting labeled source domain data and unlabeled target domain data to train a bilateral weighted countermeasure network; and establishing an extremum theoretical model by utilizing the characteristics of training data or source domain data, inputting the characteristics of the test sample or the target domain sample into the established extremum theoretical model, outputting the probability that the test sample or the target domain sample belongs to an unknown fault type, if the probability is larger than a threshold value, the test sample or the target domain sample belongs to the unknown fault type, otherwise, the test sample or the target domain sample belongs to the known fault type, and determining the class of the test sample or the target domain sample according to a label predicted value so as to realize fault diagnosis of the high-speed train bearing.","['G01M13/045', 'G01M17/10', 'G06N3/045', 'G06N3/08', 'G06N3/096', 'G06N3/0464', 'Y02T90/00']"
US20200204822A1,System and method for content and motion controlled action video generation,"A method, computer readable medium, and system are disclosed for action video generation. The method includes the steps of generating, by a recurrent neural network, a sequence of motion vectors from a first set of random variables and receiving, by a generator neural network, the sequence of motion vectors and a content vector sample. The sequence of motion vectors and the content vector sample are sampled by the generator neural network to produce a video clip.","['H04N19/521', 'G06N3/08', 'G06K9/00201', 'G06K9/00281', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06T13/40', 'G06V20/64', 'G06V40/171', 'G06T2207/20081', 'G06T2207/30196']"
US10949525B2,Generating a challenge-response for authentication using relations among objects,"Aspects described herein may allow for the application of generating captcha images using relations among objects. The objects in ground-truth images may be clustered based on the probabilities of co-occurrence. Further aspects described herein may provide for generating a first captcha image comprising a first object and a second object, and generating a second captcha image based on the first captcha image by replacing the first object with the third object. Finally, the first and second captcha images may be presented as security challenges and user access requests may be granted or denied based on responses to the security challenges.","['H04L63/08', 'G06F16/285', 'G06F21/36', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N3/094', 'H04L63/102', 'G06F2221/2103', 'G06F2221/2133', 'G06N3/044']"
US11416772B2,Integrated bottom-up segmentation for semi-supervised image segmentation,"Embodiments of the present disclosure include a computer-implemented method, a system, and a computer program product for integrating bottom-up segmentation techniques into a semi-supervised image segmentation machine learning model. The computer implemented method includes training a machine learning model with a labeled dataset. The labeled dataset includes ground truth segmentation labels for each sample in the labeled dataset. The computer implemented method also includes generating a pseudo labeled dataset by applying an unlabeled dataset to the machine learning model using a top-down segmentation grouping rule. The computer implemented method further includes evaluating the pseudo labeled dataset using a bottom-up segmentation grouping rule to produce evaluation results, combining the pseudo labeled dataset with the second pseudo labeled dataset into a training dataset, and then retraining the machine learning model with the training dataset.","['G06N3/08', 'G06F18/214', 'G06F18/231', 'G06K9/6256', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06T7/10', 'G06V10/40', 'G06V10/7625', 'G06V10/774', 'G06V20/70', 'G06V30/274', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
CN109522857B,A population estimation method based on generative adversarial network model,"The invention relates to a people number estimation method based on a Generative confrontation network model, which relates to a characteristic automatic extraction technology and a multiple regression model in deep learning, fully utilizes the characteristic representation capability of the Generative confrontation network model (GANs, general adaptive Nets), takes a density graph indicating local crowd density as a second supervision signal, takes the number of people in an image as a first supervision signal, trains a network by using a back propagation algorithm, and then initializes the network by using the obtained network parameters to predict the number of people in an unknown image.","['G06V20/53', 'G06F18/214', 'G06N3/045', 'G06N3/084']"
US12299962B2,Diffusion-based generative modeling for synthetic data generation systems and applications,"Systems and methods described relate to the synthesis of content using generative models. In at least one embodiment, a score-based generative model can use a stochastic differential equation with critically-damped Langevin diffusion to learn to synthesize content. During a forward diffusion process, noise can be introduced into a set of auxiliary (e.g., “velocity”) values for an input image to learn a score function. This score function can be used with the stochastic differential equation during a reverse diffusion denoising process to remove noise from the image to generate a reconstructed version of the input image. A score matching objective for the critically-damped Langevin diffusion process can require only the conditional distribution learned from the velocity data. A stochastic differential equation based integrator can then allow for efficient sampling from these critically-damped Langevin diffusion models.","['G06T5/70', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/096', 'G06T5/60', 'G06T7/277', 'G06V10/772', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06V10/774']"
US10733721B2,Automated material characterization system including conditional generative adversarial networks,"A material characterization system includes an imaging unit, a material characterization controller, and an imaging unit controller. The electronic imaging unit generates a test image of a specimen composed of a material. The electronic material characterization controller determines values of a plurality of parameters and maps the parameters to corresponding ground truth labeled outputs. The mapped parameters are applied to at least one test image to predict a presence of at least one target attribute of the specimen in response to applying the learned parameters. The test image is convert to a selected output image format so as to generate a synthetic image including the predicted at least one attribute. The electronic imaging unit controller performs a material characterization analysis that characterizes the material of the specimen based on the predicted at least one attribute included in the synthetic image.","['G06V10/82', 'G06F18/217', 'G06F18/24133', 'G06F18/251', 'G06K9/342', 'G06K9/6202', 'G06K9/6262', 'G06K9/6271', 'G06K9/6289', 'G06T7/0004', 'G06T7/0006', 'G06T7/001', 'G06T7/12', 'G06T7/13', 'G06T7/174', 'G06V10/267', 'G06V10/764', 'G06V10/776', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20152', 'G06T2207/20221', 'G06T2207/30136', 'G06T2207/30164', 'G06T2207/30242']"
US12283350B2,Computer implemented method and system for small molecule drug discovery,"In a small molecule drug discovery method, a transition state for a specific enzyme is modelled using quantum mechanics and molecular dynamics based simulation of the enzyme and substrate reaction; data defining the transition state (a ‘quantum pharmacophore’) is fed to a machine learning engine configured to generate transition state analogues, such as enzyme inhibitors.","['G16B5/00', 'G16B15/30', 'G16B40/20']"
US10319076B2,Producing higher-quality samples of natural images,"In one embodiment, a method includes accessing a plurality of generative adversarial networks (GANs) that are each applied to a particular level k of a Laplacian pyramid. Each GAN may comprise a generative model Gk and a discriminative model Dk. At each level k, the generative model Gk may take as input a noise vector zk and may output a generated image {tilde over (h)}k. At each level k, the discriminative model Dk may take as input either the generated image {tilde over (h)}k or a real image hk, and may output a probability that the input was the real image hk. The method may further include generating a sample image Ĩk from the generated images {tilde over (h)}k, wherein the sample image is based on the probabilities outputted by each of the discriminative models Dk and the generated images {tilde over (h)}k. The method may further include providing the sample image Ĩk for display.","['G06T5/00', 'G06T5/60', 'G06T2207/20016', 'G06T2207/20084']"
US11610289B2,"Image processing method and apparatus, storage medium, and terminal","The present disclosure provides an image processing method and apparatus, a storage medium and a terminal. The image processing method includes: acquiring a to-be-processed blurred image, wherein the to-be-processed blurred image is obtained by an under-screen camera through a device screen; inputting the to-be-processed blurred image to a trained generative adversarial network model to obtain a processed clear image, wherein the generative adversarial network model is trained using a preset training sample, the preset training sample includes a clear image sample and a blurred image sample corresponding to each other; and outputting the processed clear image. Embodiments of the present disclosure can improve image quality of an image captured by the under-screen camera.","['G06T5/73', 'G06T5/003', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06T5/60', 'G06V10/34', 'G06V10/82', 'G06V10/993', 'G06V30/142', 'G06V40/16', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'G06V40/172']"
US12067659B2,Generating animated digital videos utilizing a character animation neural network informed by pose and motion embeddings,"The present disclosure relates to systems, non-transitory computer-readable media, and method that utilize a character animation neural network informed by motion and pose signatures to generate a digital video through person-specific appearance modeling and motion retargeting. In particular embodiments, the disclosed systems implement a character animation neural network that includes a pose embedding model to encode a pose signature into spatial pose features. The character animation neural network further includes a motion embedding model to encode a motion signature into motion features. In some embodiments, the disclosed systems utilize the motion features to refine per-frame pose features and improve temporal coherency. In certain implementations, the disclosed systems also utilize the motion features to demodulate neural network weights used to generate an image frame of a character in motion based on the refined pose features.","['G06T13/40', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06T7/20', 'G06T7/73', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11521009B2,Automatically generating training data for a lidar using simulated vehicles in virtual space,"Automated training dataset generators that generate feature training datasets for use in real-world autonomous driving applications based on virtual environments are disclosed herein. The feature training datasets may be associated with training a machine learning model to control real-world autonomous vehicles. In some embodiments, an occupancy grid generator is used to generate an occupancy grid indicative of an environment of an autonomous vehicle from an imaging scene that depicts the environment. The occupancy grid is used to control the vehicle as the vehicle moves through the environment. In further embodiments, a sensor parameter optimizer may determine parameter settings for use by real-world sensors in autonomous driving applications. The sensor parameter optimizer may determine, based on operation of the autonomous vehicle, an optimal parameter setting of the parameter setting where the optimal parameter setting may be applied to a real-world sensor associated with real-world autonomous driving applications.","['G06K9/6256', 'G06F13/28', 'G01C21/28', 'G01S17/931', 'G01S7/4808', 'G01S7/497', 'G05D1/0088', 'G05D1/0231', 'G05D1/0257', 'G05D1/0278', 'G06F18/214', 'G06F18/2148', 'G06F18/2411', 'G06F18/2413', 'G06K9/6257', 'G06K9/6269', 'G06N3/006', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N5/04', 'G06T11/00', 'G06T7/246', 'G06T7/50', 'G06V10/764', 'G06V10/774', 'G06V20/56', 'G08G1/0962', 'G01S17/87', 'G05D2201/0213', 'G06F2213/28', 'G06F9/451', 'G06N20/00', 'G06N3/045', 'G06N3/088', 'G06T11/60', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241', 'G06T2207/30256', 'G06V20/588']"
US20250053817A1,Adversarially generated communications,"Methods, systems, and apparatus, including computer programs encoded on computer-storage media, for adversarially generated communication. In some implementations, first information is used as input for a generator machine-learning network. Information is taken from both the generator machine-learning network and target information that includes sample signals or other data. The information is sent to a discriminator machine-learning network which produces decision information including whether the information originated from the generator machine-learning network or the target information. An optimizer takes the decision information and performs one or more iterative optimization techniques which help determine updates to the generator machine-learning network or the discriminator machine-learning network. One or more rounds of updating the generator machine-learning network or the discriminator machine-learning network can allow the generator machine-learning network to produce information that is similar to the target information.","['G06N3/088', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
US10607065B2,Generation of parameterized avatars,"Generation of parameterized avatars is described. An avatar generation system uses a trained machine-learning model to generate a parameterized avatar, from which digital visual content (e.g., images, videos, augmented and/or virtual reality (AR/VR) content) can be generated. The machine-learning model is trained to identify cartoon features of a particular style—from a library of these cartoon features—that correspond to features of a person depicted in a digital photograph. The parameterized avatar is data (e.g., a feature vector) that indicates the cartoon features identified from the library by the trained machine-learning model for the depicted person. This parameterization enables the avatar to be animated. The parameterization also enables the avatar generation system to generate avatars in non-photorealistic (relatively cartoony) styles such that, despite the style, the avatars preserve identities and expressions of persons depicted in input digital photographs.","['G06K9/00268', 'G06T15/02', 'G06N20/00', 'G06N3/006', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T13/40', 'G06T13/80', 'G06T19/006', 'G06V10/82', 'G06V40/168', 'H04L51/10']"
US10746843B2,Method and system for learned communications signal shaping,"Methods and systems including computer programs encoded on computer storage media, for training and deploying machine-learned communication over radio frequency (RF) channels. One of the methods includes: determining first information; generating a first RF signal by processing using an encoder machine-learning network; determining a second RF signal that represents the first RF signal altered by transmission through a communication channel; determining a first property of the first signal or the second RF signal; calculating a first measure of distance between a target value of the first property and an actual value of the first or second RF signal; generating second information as a reconstruction of the first information using a decoder machine-learning network; calculating a second measure of distance between the first information and the second information; and updating at least one of the encoder machine-learning network or the decoder machine-learning network based on the first and second measures.","['H04B1/0003', 'G01S11/06', 'G01S5/021', 'G01S5/0215', 'G01S5/0268', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N20/00']"
US11386986B2,"System and method for identifying complex patients, forecasting outcomes and planning for post discharge care","Techniques are described for identifying complex patients and forecasting patient outcomes based on a variety of factors including medical, socio-economic, mental and behavioral. According to an embodiment, a method can include employing one or more machine learning models to identify complex patients and predict patient outcomes like length of stay, potential discharge trajectories with likelihoods, discharge destinations, readmission likelihood and safety. These models are applied to respective patients that are currently admitted to a hospital and expected to be placed after discharge from the hospital, wherein the one or more discharge forecasting machine learning models predict the discharge destinations based on clinical data points and non-clinical data points collected for the respective patients. The method can further include providing discharge information identifying the discharge destinations predicted for the respective patients to one or more care providers to facilitate managing and coordinating inpatient and post-discharge care for the respective patients.","['G16H10/60', 'G06N20/00', 'G16H20/00', 'G16H40/20', 'G16H50/30']"
US20210097691A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate or manipulate digital images. In at least one embodiment, a network is trained to generate modified images including user-selected features.","['G06T11/001', 'G06F18/214', 'G06F18/24133', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06T11/60', 'G06T3/4053', 'G06T7/11', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US12265897B2,Systems and methods for automated content curation using signature analysis,"Systems and methods are described herein for curating content that follows a narrative structure. A narrative structure comprises narrative portions that have a defined order. Signature analysis of known content that follows the narrative structure is used to train machine learning models for the narrative structure and the narrative portions that make up the narrative structure. Signature analysis of candidate content segments, along with machine learning models for the narrative portions, are used to identify candidate content segments that match the respective narrative portions. A candidate playlist is generated of the identified candidate content segments in the defined order. In one embodiment, the machine learning model for the narrative structure is used to validate the generated playlist.","['G06N3/088', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'H04N21/44008', 'H04N21/4663', 'H04N21/4666', 'H04N21/4668', 'G06N20/00', 'G06N7/01']"
US11589924B2,Non-invasive assessment and therapy guidance for coronary artery disease in diffuse and tandem lesions,"A method and system for non-invasive assessment and therapy planning for coronary artery disease from medical image data of a patient is disclosed. Geometric features representing at least a portion of a coronary artery tree of the patient are extracted from medical image data. Lesions are detected in coronary artery tree of the patient and a hemodynamic quantity of interest is computed at a plurality of points along the coronary artery tree including multiple points within the lesions based on the extracted geometric features using a machine learning model, resulting in an estimated pullback curve for the hemodynamic quantity of interest. Post-treatment values for the hemodynamic quantity of interest are predicted at the plurality of points along the coronary artery tree including the multiple points within the lesions for each of one or more candidate treatment options for the patient, resulting in a respective predicted post-treatment pullback curve for the hemodynamic quantity of interest for each of the one or more candidate treatment options. A visualization of a treatment prediction for at least one of the candidate treatment options is displayed.","['A61B34/10', 'A61B5/0036', 'A61B5/026', 'A61B5/4887', 'A61B5/7267', 'A61B5/7278', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/0012', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096', 'G06T2207/30101', 'G06T2207/30104', 'Y02A90/10']"
US11398223B2,Electronic device for modulating user voice using artificial intelligence model and control method thereof,"The present disclosure relates to an artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning, etc. and an application thereof. In particular, a controlling method of an electronic apparatus includes obtaining a user voice of a first user, converting the voice of the first user into a first spectrogram, obtaining a second spectrogram by inputting the first spectrogram to a trained model through an artificial intelligence algorithm, converting the second spectrogram into a voice of a second user, and outputting the converted second user voice. Here, the trained model is a model trained to obtain a spectrogram of a style of the second user voice by inputting a spectrogram of a style of the first user voice. In particular, at least part of the controlling method of the electronic apparatus uses an artificial intelligence model trained according to at least one of machine learning, a neural network or a deep learning algorithm.","['G10L15/063', 'G10L21/003', 'G10L13/033', 'G06F3/16', 'G06F3/167', 'G10L25/30', 'G10L2021/0135', 'G10L25/18']"
US12254413B2,Systems and methods for contrastive learning of visual representations,"Systems, methods, and computer program products for performing semi-supervised contrastive learning of visual representations are provided. For example, the present disclosure provides systems and methods that leverage particular data augmentation schemes and a learnable nonlinear transformation between the representation and the contrastive loss to provide improved visual representations. Further, the present disclosure also provides improvements for semi-supervised contrastive learning. For example, computer-implemented method may include performing semi-supervised contrastive learning based on a set of one or more unlabeled training data, generating an image classification model based on a portion of a plurality of layers in a projection head neural network used in performing the contrastive learning, performing fine-tuning of the image classification model based on a set of one or more labeled training data, and after performing the fine-tuning, distilling the image classification model to a student model comprising a relatively smaller number of parameters than the image classification model.","['G06N3/084', 'G06F18/2155', 'G06F18/2178', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06V10/764', 'G06V10/7753', 'G06V10/7788', 'G06T2207/20081']"
US11631032B2,Failure feedback system for enhancing machine learning accuracy by synthetic data generation,"An exemplary system, method, and computer-accessible medium can include, for example, (a) receiving a dataset(s), (b) determining if a misclassification(s) is generated during a training of a model(s) on the dataset(s), (c) generating a synthetic dataset(s) based on the misclassification(s), and (d) determining if the misclassification(s) is generated during the training of the model(s) on the synthetic dataset(s). The dataset(s) can include a plurality of data types. The misclassification(s) can be determined by determining if one of the data types is misclassified. The dataset(s) can include an identification of each of the data types in the dataset(s).","['G06N20/10', 'G06F18/214', 'G06F18/217', 'G06F18/24', 'G06K9/6256', 'G06K9/6267', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N20/20', 'G06N5/01']"
US20200228880A1,On-demand generation and personalization of video content,"Various embodiments for dynamically generating an advertisement in a video stream are disclosed. In one embodiment, video stream content associated with a video stream for a user device is received. Video analytics data is obtained for the video stream content, which indicates a scene recognized in the video stream content. An advertisement to be generated and inserted into the video stream content is then selected based on the scene recognized in the video stream content, and an advertisement template for generating the selected advertisement is obtained. Video advertisement content corresponding to the advertisement is then generated based on the advertisement template and the video analytics data. The video advertisement content is then inserted into the video stream content, and the modified video stream content is transmitted to the user device.","['H04N21/812', 'H04N21/23418', 'H04N21/235', 'H04N21/251', 'H04N21/64715', 'H04N21/8133', 'H04N21/23424']"
US10800430B2,Driving intervention in vehicles,"A method for providing an alert signal to a control unit of a vehicle for controlling driver intervention. The method comprises determining a set of present driving behavior data indicative of a present driving behavior in a present driving situation and retrieving a driving model indicative of expected driving behavior for the present driving situation. Further, a plurality of expected near future paths for the vehicle are predicted and an actual path is additionally determined. The set of present driving behavior data is mapped with the driving model. When a predetermined degree of deviation in the set of present driving behavior data compared to the driving model is found and the actual path deviates from the predicted expected paths, the alert signal is provided.","['B60W50/14', 'B60W30/095', 'B60W40/09', 'B60W50/0097', 'G06F16/2455', 'G06N3/088', 'G08G1/167', 'B60W2050/007', 'B60W2050/0075', 'B60W2050/0089', 'B60W2050/143', 'B60W2400/00', 'B60W2520/10', 'B60W2520/14', 'B60W2540/00', 'B60W2540/30', 'B60W2554/00', 'B60W2556/10', 'B60W2556/50', 'B60W2556/55', 'B60W2900/00']"
US20250044412A1,Method for quality detection of tunnel lining through ground-penetrating radar based on self-supervised learning,"A method for a quality detection of tunnel lining through ground-penetrating radar based on self-supervised learning. In the method, a grayscale image of the tunnel to be detected is obtained, the grayscale image is then input into a trained feature recognition model, to obtain a feature atlas is corresponding to the grayscale image, and then a quality recognition result of the tunnel to be detected is determined according to the feature atlas. In the present application, the feature recognition model is obtained by means of the self-supervised learning according to an unlabeled image set and a labeled image set, and the unlabeled image set is directly utilized to train the recognition model, which not only improves the efficiency of training the tunnel recognition model, but also improves the accuracy of tunnel quality detection results.","['G06T7/0004', 'G01S13/885', 'G01S13/89', 'G01S7/417', 'G06N3/045', 'G06N3/088', 'G06T7/0002', 'G06T2207/10044', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/30']"
US11442992B1,Conversational reasoning with knowledge graph paths for assistant systems,"In one embodiment, a method includes receiving a query from a user from a client system associated with the user, accessing a knowledge graph comprising a plurality of nodes and edges connecting the nodes, wherein each node corresponds to an entity and each edge corresponds to a relationship between the entities corresponding to the connected nodes, determining one or more initial entities associated with the query based on the query, selecting one or more candidate nodes by a conversational reasoning model from the knowledge graph corresponding to one or more candidate entities, respectively, wherein each candidate node is selected based on the nodes corresponding to the initial entities, dialog states associated with the query, and a context associated with the query, generating a response based on the initial entities and the candidate entities, and sending instructions for presenting the response to the client system in response to the query.","['G06Q50/01', 'G06F16/90332', 'G06F16/9024', 'G06N20/00', 'G06N3/0442', 'G06N3/049', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/022', 'G06N5/045', 'G06N3/044', 'G06N3/045', 'G06N3/08']"
KR102271740B1,Method and apparatus for anomaly detection,"The present disclosure relates to an anomaly detection method and an apparatus therefor. In accordance with one embodiment of the present disclosure, the anomaly detection method includes the following steps of: performing restoration learning with respect to at least one piece of data through an autoencoder including an encoder network and a decoder network; acquiring first output data by inputting first input data into the autoencoder, wherein the first output data includes a latent vector outputted through the encoder network and restoration data outputted through the decoder network; inputting the first input data and the first output data as second input data of a preset anomaly detection learning model; calculating an anomaly score based on the second output data outputted by the anomaly detection learning model; and determining whether the first input data is an anomaly by threshold-processing the calculated anomaly score. Therefore, the present disclosure is capable of creating a more robust learning model and increasing the stability of the learning model.",['G06N20/00']
US20210165937A1,System and Method for Simulating Reservoir Models,"A method, computer program product, and computing system are provided for defining one or more injector completions and one or more producer completions in one or more reservoir models. One or more edges between the one or more injector completions and the one or more producer completions in the one or more reservoir models may be defined. The one or more edges between the one or more injector completions and the one or more producer completions may define a graph network representative of the one or more reservoir models. The one or more reservoir models may be simulated along the one or more edges between the one or more injector completions and the one or more producer completions.","['G06F30/27', 'G06N3/084', 'E21B43/00', 'E21B43/20', 'E21B49/00', 'G01V20/00', 'G01V99/005', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'E21B2200/22', 'G01V2210/663']"
US11709922B2,Password-less software system user authentication,"Data is received as part of an authentication procedure to identify a user. Such data characterizes a user-generated biometric sequence that is generated by the user interacting with at least one input device according to a desired biometric sequence. Thereafter, using the received data and at least one machine learning model trained using empirically derived historical data generated by a plurality of user-generated biometric sequences (e.g., historical user-generated biometric sequences according to the desired biometric sequence, etc.), the user is authenticated if an output of the at least one machine learning model is above a threshold. Data can be provided that characterizes the authenticating. Related apparatus, systems, techniques and articles are also described.","['H04L9/3231', 'G06F18/24155', 'G06F21/32', 'G06F21/40', 'G06K9/6278', 'G06N5/022', 'H04L63/0815', 'H04L63/0861', 'G06F21/36', 'H04L2463/062', 'H04L63/083', 'H04W12/68']"
US12147880B2,Autonomous detection of incongruous behaviors,"Behavioral characteristics of at least a first machine component are monitored. A model that represents machine-to-machine interactions between at least the first machine component and at least a further machine component is generated. Using the monitored behavioral characteristics and the generated model, an incongruity of a behavior of at least the first machine component and the machine-to-machine interactions is computed, where the incongruity is predicted based on determining a discordance between an expectation of the system and the behavior and the machine-to-machine interactions, and wherein the predicting is performed without using a previously built normative rule of behavior and machine-to-machine interactions.","['G06N20/00', 'G06N5/02', 'H04L41/142', 'H04L41/147', 'H04L63/1425', 'G06F21/552']"
WO2021031480A1,Text generation method and device,"A text generation method and device. The method comprises: selecting, from a knowledge graph set, a target knowledge graph of a target entity (S102); determining, on the basis of the target knowledge graph, an entity vector, an attribute vector, and an attribute value vector of the target entity (S104); and generating, according to the entity vector, the attribute vector, and the attribute value vector, text matching the target entity (S106).","['G06F16/35', 'G06F16/367', 'G06N3/045', 'G06N3/08']"
CN111738003B,"Named entity recognition model training method, named entity recognition method and medium","The embodiment of the invention provides a named entity recognition model training method, a named entity recognition method and a medium.","['G06F40/295', 'G06N3/045', 'G06N3/08']"
US20220225126A1,Data processing method and device in wireless communication network,"The disclosure relates to a pre-5th generation (5G) or 5G communication system to be provided for supporting higher data rates beyond 4th generation (4G) communication system such as long term evolution (LTE). A method for data processing in a wireless communication network is provided. The method includes obtaining, by a first node, data, and generating, by the first node, information for self optimization according to the data.","['H04W24/02', 'G06N3/08', 'G06N3/063', 'H04W92/20']"
WO2020101246A1,Joint unsupervised object segmentation and inpainting,"The invention relates to implementation of image processing functions associated with finding the boundaries of objects, removing objects from an image, inserting objects into an image, creating new images from a combination of existing images. Proposed is a method for automated image processing and a computing system for performing automated image processing, comprising: first neural network for forming a coarse image z by segmenting an object O from an original image x containing the object O and background B x by a segmentation mask, and, using the mask, cutting off the segmented object O from the image x and pasting it onto an image y containing only background B y, second neural network for constructing an enhanced version of an image (Image I) with pasted segmented object O by enhancing coarse image z based on the original images x and y and the mask m; third neural network, for restoring the background-only image (Image II) without removed segmented object O by inpainting image obtained by zeroing out pixels of image x using the mask m; wherein the first, second and third neural networks are combined into common architecture of neural network for sequential performing segmentation, enhancing and inpainting and for simultaneously learning, wherein the common architecture of neural network accepts the images and outputs processed images of the same dimensions.","['G06T7/11', 'G06F18/2185', 'G06F18/2193', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06T11/60', 'G06T5/50', 'G06T5/60', 'G06T5/77', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084']"
AU2018100325A4,A New Method For Fast Images And Videos Coloring By Using Conditional Generative Adversarial Networks,"Abstract This new invention presents a method for coloring black-and-white films and photos in real time by using conditional Generative Adversarial Network(cGAN). Using the YUV channel instead of RGB channel to train the network makes the training more effective. The cGAN which is made up of a ""U-Net""-based architecture for generator and a convolutional ""PatchGAN"" classifier avoids shortages of traditional encoder-decoder models. Move clips Software written in Mat Lab Python C atu lredan jit iigues Py tha-on) half-colore images (Dneata es OuInput (Initciiaton parme e poch ma epoch? r'i Yesnn pocs BW image Fiur 1",[]
US9996694B2,Unsupervised detection of anomalous processes using hardware features,"Disclosed are devices, systems, apparatus, methods, products, media and other implementations, including a method that includes obtaining current hardware performance data, including hardware performance counter data, for a hardware device executing a first process associated with pre-recorded hardware performance data representative of the first process' normal behavior, and determining whether a malicious process is affecting performance of the first process based on a determination of an extent of deviation of the obtained current hardware performance data corresponding to the first process from the pre-recorded hardware performance data representative of the normal behavior of the first process.","['G06F21/566', 'G06F21/52', 'G06F21/552', 'G06N20/00', 'G06N99/005', 'H04L63/0428', 'H04L9/3239', 'G06F2221/034']"
US11819363B2,Systems and methods to improve resolution of ultrasound images with a neural network,"The current disclosure provides for mapping ultrasound images to resolution mapped ultrasound images using generative neural networks, while maintaining clinical quality of the resolution mapped ultrasound image, thereby enabling a clinician to evaluate ultrasound images in a preferred resolution without loss of clinically relevant content. In one embodiment the current disclosure provides for a method comprising, acquiring a ultrasound image of an anatomical region of a subject, wherein the ultrasound image is in a first resolution, selecting a target resolution, wherein the target resolution is distinct from the first resolution, selecting a clinical quality metric, selecting a trained resolution mapping network based on the target resolution and the clinical quality metric, mapping the ultrasound image to a resolution mapped ultrasound image using the trained resolution mapping network, wherein the resolution mapped ultrasound image is in the target resolution, and displaying the resolution mapped ultrasound image via a display device.","['A61B8/5207', 'A61B8/4494', 'A61B8/461', 'A61B8/5215', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06N3/047', 'G06T2207/20081', 'G06T2207/20084']"
EP3940592A1,"Sample generation method and apparatus, and computer device and storage medium","A sample generation method, comprising: acquiring a real category feature vector extracted from each real sample respectively; splicing the real category feature vector with a real category label vector of the corresponding real sample; inputting each spliced vector, obtained by means of the splicing, into the current sample generation network, and performing mapping to obtain various pseudo-samples; determining mutual information between each pseudo-sample and the corresponding spliced vector; inputting the various real samples and the various pseudo-samples into the current sample determination network, performing, in conjunction with the mutual information, iterative adversarial training on the sample generation network and the sample determination network, and during the process of adversarial training, iteratively maximizing the mutual information until an iteration stop condition is satisfied; and inputting the various spliced vectors into a sample generation network when iteration stops, and outputting a pseudo-sample set.","['G06N3/08', 'G06F18/211', 'G06F18/213', 'G06F18/214', 'G06F18/2155', 'G06F18/25', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06V2201/03']"
US11719811B2,Method and device to improve radar data using reference data,"A method with radio detection and ranging (radar) data processing may include: obtaining, by a radar sensor, input radar data; and generating, using a resolution increase model, output radar data from the input radar data and reference data, wherein the output radar data has a resolution greater than a resolution of the input radar data.","['G01S13/874', 'G01S13/931', 'G01S13/42', 'G01S13/87', 'G01S13/872', 'G01S13/89', 'G01S7/04', 'G01S7/417', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G01S13/865', 'G01S13/867', 'G01S7/4004', 'G06N20/00', 'G06N3/08']"
US11625576B2,Systems and methods for image style transformation,"A method for image processing may include: obtaining an original image of a first style, the original image being generated by a first imaging device; obtaining a target transformation model; and generating a transferred image of a second style by transferring the first style of the original image using the target transformation model. The second style may be substantially similar to a target style of one or more other images generated by a second imaging device. The second style may be different from the first style.","['G06T11/00', 'G06N3/0454', 'G06T3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06T7/30', 'G06T2207/20081', 'G06T2207/20084']"
CN111693534B,"Surface defect detection methods, model training methods, devices, equipment and media","The embodiment of the application discloses a surface defect detection method, a model training device, equipment and a medium, relates to the fields of artificial intelligent computer vision, deep learning and cloud computing, and particularly relates to an image recognition technology. The specific implementation scheme is as follows: inputting the surface image of the object to be detected into a defect detection model to detect defects, and obtaining a defect detection result output by the defect detection model; inputting the surface image of the defective object determined to have the defect into an image judging model according to the defect detection result so as to judge whether the surface image of the defective object has the defect or not; the image discrimination model is a trained generation countermeasure network model, and the generation countermeasure network model is obtained by training a surface image of a non-defective good product; and adjusting a defect detection result of the surface image of the defective article according to the judging result of the image judging model. The embodiment of the application can effectively reduce the over-killing rate of the surface image of the object to be tested.","['G06V10/82', 'G01N21/8851', 'G06F18/2148', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/0004', 'G06V10/776', 'G06V20/60', 'G01N2021/8883', 'G01N2021/8887', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'G06T2207/30124', 'Y02P90/30']"
US20220374630A1,Person re-identification system and method integrating multi-scale gan and label learning,"A person re-identification system and a person re-identification method integrating multi-scale GAN and label learning are provided. The occluded blocks with different sizes are added to an original image for data restoration and enhancement, multi-scale discrimination branches are introduced, multi-scale features are fused, and feature matching losses on different scales are calculated respectively to improve the quality of generative images. Further, an online label learning method based on semi-supervised learning is provided to label a generative image and reduce the interference of label noise on an identification model.","['G06K9/00362', 'G06V20/52', 'G06V40/10', 'G06F18/214', 'G06F18/253', 'G06K9/6232', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06V10/82', 'Y02T10/40']"
US11628566B2,Manipulating fracturable and deformable materials using articulated manipulators,"In an embodiment, a method and system use various sensors to determine a shape of a collection of materials (e.g., foodstuffs). A controller can determine a trajectory which achieves the desired end-state, possibly chosen from a set of feasible, collision-free trajectories to execute, and a robot executes that trajectory. The robot, executing that trajectory, scoops, grabs, or otherwise acquires the desired amount of material from the collection of materials at a desired location. The robot then deposits the collected material in the desired receptacle at a specific location and orientation.","['B25J9/1666', 'A47J44/00', 'B25J11/0045', 'B25J13/003', 'B25J13/085', 'B25J13/088', 'B25J15/0052', 'B25J15/0408', 'B25J19/0083', 'B25J19/023', 'B25J9/0009', 'B25J9/16', 'B25J9/161', 'B25J9/1633', 'B25J9/1653', 'B25J9/1664', 'B25J9/1674', 'B25J9/1676', 'B25J9/1682', 'B25J9/1687', 'B25J9/1697', 'B65G1/137', 'G05D1/02', 'G06N3/0464', 'G06N3/08', 'G06Q10/06316', 'G06V40/28', 'G10L15/22', 'G05B19/4061', 'G05B2219/32335', 'G05B2219/39001', 'G05B2219/39091', 'G05B2219/39319', 'G05B2219/39342', 'G05B2219/39468', 'G05B2219/40201', 'G05B2219/40202', 'G05B2219/40411', 'G05B2219/40497', 'G05B2219/45111', 'G05B2219/49157', 'G05B2219/50391', 'H04L67/12']"
US10824909B2,Systems and methods for conditional image translation,"System, methods, and other embodiments described herein relate to conditionally generating custom images by sampling latent space of a generator. In one embodiment, a method includes, in response to receiving a request to generate a custom image, generating a component instruction by translating a description about requested characteristics for the object instance into a vector that identifies a portion of a latent space within a respective generator. The method includes computing the object instance by controlling the respective one of the generators according to the component instruction to produce the object instance. The respective one of the generators being configured to generate objects within a semantic object class. The method includes generating the custom image from at least the object instance to produce the custom image from the description as a photorealistic image approximating a real image corresponding to the description.","['G06N3/088', 'G06K9/6257', 'G06F18/2148', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/774', 'G06V10/82']"
US11358063B2,Generation of audience appropriate content,Multimedia content to be played on a multimedia player device can be received. Whether the multimedia content contains audience-inappropriate content can be determined. Replacement content corresponding to the audience-inappropriate content can be generated. The generated replacement content can be caused to play on the multimedia player device in lieu of the audience-inappropriate content.,"['A63F13/67', 'A63F13/73', 'A63F13/75', 'A63F13/79', 'G06F16/435', 'G06F16/48', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'H04N21/234336', 'H04N21/26603', 'H04N21/4318', 'H04N21/44008', 'H04N21/440236', 'H04N21/4532', 'H04N21/4542', 'H04N21/4627', 'H04N21/4662', 'H04N21/4756', 'H04N21/4781', 'H04N21/8456', 'A63F2300/201', 'A63F2300/5546']"
CN112288658B,Underwater image enhancement method based on multi-residual joint learning,"The invention relates to an underwater image enhancement method based on multi-residual joint learning, and belongs to the technical field of deep learning. Comprising the following steps: 1) Randomly cutting pictures with different resolutions in an underwater image dataset containing degraded images and corresponding reference images into images with the same resolution, and establishing a training set of an underwater image enhancement model; 2) The degraded images cut in the training set are respectively processed by adopting a plurality of preprocessing methods, and each preprocessing method correspondingly obtains a preprocessed image; 3) Taking the reference image as a label of the degraded image, inputting an original image of the degraded image and the preprocessed degraded image into a multi-branch convolutional neural network for multi-residual joint learning for training, and obtaining an image enhancement model; 4) And inputting the image to be enhanced into the image enhancement model to obtain the processed enhanced image.","['G06T5/94', 'G06N3/045', 'G06T7/10', 'G06T2207/20021', 'G06T2207/20081']"
US12058213B2,Device-free human identification and device-free gesture recognition,"A system can include multiple WiFi-enabled commercial off the shelf (COTS) Internet of Things (IoT) devices disposed within an environment and configured to be a transmitter (TX) or a received (RX) to send or receive data over a WiFi radio frequency communication link. A server can be configured to receive and parse the CSI data transmitted from the RX, store the CSI data with a corresponding human identity label collected for training, train a human identification classifier using a Convex Clustered Concurrent Shapelet Learning (C3SL) method, and estimate an identification of a user based on the CSI data and the C3SL method. The server can be configured to receive and parse the CSI data transmitted from the RX, transfer the CSI data into real-time CSI frames, store the real-time CSI frames in a database, store the real-time CSI frames with a corresponding gesture label collected in an original environment, and estimate and identify the gesture performed by user using a trained target encoder and source classifier.","['H04B1/38', 'H04L67/12', 'H04L63/0861', 'H04W12/06', 'H04W84/18']"
US11501473B2,Systems and methods for image correction in positron emission tomography,"System for image correction in PET is provided. The system may acquire a PET image and a CT image of a subject. The system may generate, based on the PET image and the CT image, an attenuation-corrected PET image of the subject by application of an attenuation correction model. The attenuation correction model may be a trained cascaded neural network including a trained first model and at least one trained second model downstream to the trained first model. During the application of the attenuation correction model, an input of each of the at least one trained second model may include the PET image, the CT image, and an output image of a previous trained model that is upstream and connected to the trained second model.","['G06T11/005', 'G06N3/084', 'G06T11/003', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/008', 'G06T2211/428', 'G06T2211/441', 'G06T2211/464']"
CN110751098B,A Face Recognition Method Based on Illumination and Gesture Generative Adversarial Networks,"The invention discloses a face recognition method for generating an confrontation network based on illumination and posture, which comprises the following steps: (1) acquiring face images of various illumination and angles as sample data; (2) generating a confrontation network through end-to-end training to obtain an optimal illumination generator; (3) generating a countermeasure network through end-to-end training to obtain an optimal posture generator; (4) and setting target illumination and posture, and performing face illumination and posture conversion. The method can effectively transform the given face image to the specified illumination condition and the specified posture by utilizing the method for generating the confrontation network and various loss functions, and introduces a two-way attention mechanism in the posture transformation network to separate the face information and the key point information, so that the illumination information in the original image can be well kept while posture transformation is carried out. The invention has the characteristics of small parameter quantity and high speed.","['G06V40/161', 'G06N3/045', 'G06N3/08', 'G06V40/172']"
CN110490946B,A text-to-image method based on cross-modal similarity and generative adversarial networks,"The invention relates to a method for generating an image based on cross-modal similarity and text of a generated countermeasure network, which comprises the following steps: step S1: training a global consistency model, a local consistency model and a relationship consistency model by using matched and unmatched data, wherein the three models are respectively used for obtaining global representation, local representation and relationship representation of a text and an image; step S2: obtaining global representation, local representation and relation representation of the text to be processed by using the trained global consistency model, the trained local consistency model and the trained relation consistency model; step S3: the global representation, the local representation and the relation representation of the text to be processed are connected in series to obtain the text representation of the text to be processed; step S4: by F ca The text representation of the text to be processed by the condition enhancement module is converted into a condition vector; step S5: the condition vector is input to a generator to obtain a generated image. Compared with the prior art, the inventionThe invention has the advantages of considering local and relation information and the like.","['G06F18/22', 'G06N3/045', 'G06T11/001', 'Y02D10/00']"
US11651247B2,Method for verifying lack of bias of deep learning AI systems,"A method including receiving an unknown vector including a data structure populated with unknown features describing a user. The method also includes executing a primary machine learning model (MLM) trained using a prediction data set to predict a score representing a prediction regarding the user. The prediction data set includes the unknown vector stripped of a biased data set including markers set that directly indicate that the user belongs to a cohort against which bias is to be avoided. The method also includes executing a supervisory MLM trained using the prediction data set to predict whether the user belongs to the cohort. The method also includes performing, using an industry tool, a computer-implemented action using the score after executing the primary MLM and the supervisory MLM.","['G06N5/04', 'G06N20/00', 'G06Q40/03', 'G06N5/022']"
US20200372618A1,"Video deblurring method and apparatus, storage medium, and electronic apparatus","A method of video deblurring by an electronic device is described. The processing circuitry of the electronic device acquires N continuous image frames from a video clip the N being a positive integer, and the N continuous image frames including a blurry image frame to be processed. The processing circuitry of the electronic device performs three-dimensional (3D) convolution processing on the N continuous image frames with a generative adversarial network model, to acquire spatio-temporal information corresponding to the blurry image frame. The spatio-temporal information includes spatial feature information of the blurry image frame, and temporal feature information between the blurry image frame and a neighboring image frame of the N continuous image frames The processing circuitry of the electronic device performs deblurring processing on the blurry image frame by using the spatio-temporal information corresponding to the blurry image frame through the generative adversarial network model, to output a sharp image frame.","['G06T5/003', 'G06T5/73', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T5/50', 'G06T5/60', 'G06V10/454', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/20201', 'G06T2207/20221']"
CN113610787B,"Training method, device and computer equipment for image defect detection model","The application relates to a training method, a training device, computer equipment and a storage medium of an image defect detection model. The method comprises the following steps: a plurality of unlabeled generated images belonging to the target domain may be generated by a first generator in the trained feature enhancement model. In this way, a generated image with greatly enhanced characteristics can be obtained, and then clustering processing is carried out on the generated image to obtain the category corresponding to each generated image; constructing each class of countermeasure models, and obtaining each class of countermeasure models after training based on the generated images of the same class; the random variable data and the noise data are acquired and input to a second generator in each class countermeasure model in a superposition mode, class feature images of each class are generated greatly, the condition of insufficient sample size is relieved greatly, the condition of fitting is avoided, a trained defect detection model with improved generalization capability is obtained based on each class feature image, and then accuracy and recall rate of micron-level defect detection are improved greatly.","['G06T7/0004', 'G06F18/214', 'G06F18/23', 'G06F18/23213', 'G06N3/045', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US11373064B2,Cross-modality automatic target recognition,"Discussed herein are systems, devices, and methods for automatic target recognition based on a non-visible input image. A method can include providing, as input to a first machine learning (ML) model for object classification, pixel data of a non-visible image, the first ML model including an encoder from a second ML model, the second ML model trained to generate a visible image representation of an input non-visible image, and receiving, from the first ML model, data indicating one or more objects present in the non-visible image.","['G06K9/6267', 'G06V10/764', 'G06F18/214', 'G06F18/24', 'G06F18/251', 'G06K9/6256', 'G06K9/6289', 'G06V10/7753', 'G06V10/803', 'G06V10/82', 'G01S13/9027', 'G01S15/89']"
EP3951654A1,"Image classification model training method, and image processing method and device","Disclosed is an image classification model training method, comprising: obtaining an image to be trained; when a first model parameter of an offset network to be trained is fixed, obtaining first prediction category marking information of said image by means of an image classification network to be trained; determining a second model parameter using a classification loss function according to image content category information and the first prediction category marking information; when a second model parameter of said image classification network is fixed, obtaining second prediction category marking information of said image by means of said offset network; determining a third model parameter using the classification loss function according to the image content category information and the second prediction category marking information; and obtaining an image semantic segmentation network model according to the second model parameter and the third model parameter. The present application implements pixel-level marking and model training by means of AI, and manual marking is not needed, so that the manual marking cost is lowered, and the model training efficiency is improved.","['G06N3/088', 'G06F18/214', 'G06F18/2415', 'G06F18/2431', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US11716338B2,System and method for determining a file-access pattern and detecting ransomware attacks in at least one computer network,"Systems and methods of determining file-access patterns in at least one computer network, the network comprising a file-access server, including training a first machine learning (ML) algorithm with a first training dataset comprising vectors representing network traffic such that the first ML algorithm learns to determine network characteristics associated with file-access traffic, determining, using the first ML algorithm, network characteristics based on highest interaction of traffic with the file-access server compared to other interactions in the at least one computer network, and determining file-access patterns in the at least one computer network based on the network characteristics associated with file-access traffic.","['H04L63/1416', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'H04L63/1425', 'H04L67/1097']"
US11178170B2,Systems and methods for detecting anomalous behavior within computing sessions,"The disclosed computer-implemented method for detecting anomalous behavior within computing sessions may include (i) identifying, by the computing device, a set of execution events that correspond to a computing session, (ii) providing, by the computing device, the set of execution events as input to an autoencoder, (iii) receiving, by the computing device and from the autoencoder, a reconstruction error associated with autoencoding the set of execution events, (iv) detecting, by the computing device and based on the reconstruction error, an anomaly within the computing session, and (v) performing, by the computing device, a security action to address the anomaly within the computing session. Various other methods, systems, and computer-readable media are also disclosed.","['H04L63/1425', 'H04L63/1441', 'G06F21/552', 'G06F21/554', 'G06F21/6218', 'G06F9/542', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06N7/005', 'G06N7/01', 'H04L63/1416', 'H04L63/20', 'G06N3/084']"
US11181598B2,Multi-contrast MRI image reconstruction using machine learning,"A computer-implemented method for reconstructing a MRI image, including: receiving a plurality of MRI measurement data sets ƒ1 to ƒN, wherein each data set is acquired from an examination object based on a different MRI protocol of an MRI system; receiving MRI images u10 to uN0 corresponding to the MRI measurement data sets ƒ1 to ƒN; applying, in at least a first step GD1, trained functions to the MRI images u10 to uN0, using a neural network and a forward-sampling operator, wherein at least one output MRI image uT is generated; and providing the at least one output MRI image uT, wherein the forward-sampling operator determines an agreement between at least one MRI image u10 to uN0 and the corresponding MRI measurement data set ƒ1 to ƒN.","['G01R33/5611', 'A61B5/055', 'A61B5/7207', 'A61B5/7267', 'G01R33/3607', 'G01R33/4818', 'G01R33/5602', 'G01R33/5608']"
US12008115B2,System and method for privacy-aware analysis of video streams,"A method and system for privacy-aware movement tracking includes receiving a series of images of a field of view, such as captured by a camera. The images containing movement of an unidentified person within the field of view. A body region corresponding to the person is detected within the images. A movement dataset for the unidentified person is generated based on tracking movement of the body region over the fired of view within the images is generated. A characterizing feature set is determined for the unidentified person. The set is associated within the movement dataset to form a first track entry. Anonymizing of the body region can be applied to remove identifying features while or prior to determining the characterizing feature set. A second track entry can be generated from a second series of images and match between the track entries can be determined. A method and system for privacy-aware operation and learning of a computer-implemented classification module is also contemplated.","['G06F21/60', 'G06F16/73', 'G06F16/784', 'G06F21/6254', 'G06Q30/0201', 'G06V20/48', 'G06V20/52', 'G06V40/167', 'H04N7/181', 'H04W12/02', 'H04W4/029', 'G06V10/22']"
US20250124570A1,Methods for identifying cross-modal features from spatially resolved data sets,"Disclosed are methods of identifying a cross-modal feature from two or more spatially resolved data sets, the method including: (a) registering the two or more spatially resolved data sets to produce an aligned feature image including the spatially aligned two or more spatially resolved data sets; and (b) extracting the cross-modal feature from the aligned feature image.","['G06T7/0012', 'G06T7/30', 'G06T7/33', 'G06V10/12', 'G06V10/24', 'G06V10/25', 'G06V10/26', 'G06V10/762', 'G06V10/764', 'G06V10/77', 'G06V10/7715', 'G06V10/80', 'G06V10/82', 'G06V20/69', 'G06V20/695', 'G06V20/698', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/30024', 'G06V2201/03']"
US20220188918A1,System and method for network security based on a user's computer network activity data,Systems and methods for implementing network security are disclosed. These systems and methods may identify anomalous computer network activity in an online networked environment based on computer network data associated with a user's activity.,"['G06Q40/02', 'G06Q20/4016']"
EP3515037A1,Dynamic concurrent learning method to neutralize cyber attacks and faults for industrial asset monitoring nodes,"Input signals 510 may be received from monitoring nodes 110 of the industrial asset, each input signal comprising time series data representing current operation. A neutralization engine 530 may transform the input signals 510 into feature vectors in feature space, each feature vector being associated with one of a plurality of overlapping batches of received input signals 510. A dynamic decision boundary 750 may be generated based on the set of feature vectors, and an abnormal state of the asset may be detected based on the set of feature vectors and a predetermined static decision boundary 720. An estimated neutralized value for each abnormal feature value may be calculated based on the dynamic decision boundary 750 and the static decision boundary 720 such that a future set of feature vectors will be moved with respect to the static decision boundary 720. An inverse transform of each estimated neutralized value may be performed to generate neutralized signals comprising time series data that are output 540.","['H04L63/1466', 'G05B23/0297', 'G06N20/00', 'H04L63/14', 'H04L63/1416', 'G06F21/50', 'Y04S40/20']"
CN110021051B,A Generative Adversarial Network-based Human Image Generation Method Guided by Text,"The invention discloses a human image generation method based on generation of confrontation network through text guidance, and belongs to the field of computer vision. The method specifically comprises the following steps: acquiring a figure image data set for training, and defining an algorithm target; acquiring attitude information of all images in a character image data set, and acquiring basic attitudes from all the attitude information through a clustering algorithm; learning from characters to predicted postures by using a posture predictor based on the generated countermeasure network; predicting the corresponding character posture from the text by using a posture predictor obtained by learning in S2-S3; and performing learning of character picture generation conforming to text description by using a character picture generator for generating the countermeasure network, and simultaneously establishing a mapping relation between the picture sub-region and the text by using multi-modal errors. The human image generation method based on the generation countermeasure network and guided by the text has good application value in scenes such as image generation, image editing, pedestrian re-identification and the like.","['G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T11/00']"
CN112906644B,Intelligent diagnosis method of mechanical fault based on deep transfer learning,"The invention relates to a mechanical fault intelligent diagnosis method based on deep migration learning, and belongs to the technical field of mechanical equipment fault diagnosis. The method comprises the following steps: s1: collecting vibration signals of various faults of mechanical equipment under different working conditions, and preprocessing the vibration signals; s2: gaussian noises with different signal-to-noise ratios are added into the divided sample sets to simulate various noise environments; s3: constructing a CAE-DTLN network by using a correlation alignment and domain confrontation transfer learning method; s4: inputting the training set into a CAE-DTLN, and performing iterative update training on the CAE-DTLN by using the classification error of the source domain labeled sample, the CORAL index and the domain classifier discrimination error; s6: and inputting the test set into a trained CAE-DTLN network, and carrying out migration fault diagnosis on the mechanical equipment under different noises and working conditions. The method can realize anti-noise migration diagnosis, and has good migration diagnosis effect and strong robustness and generalization capability.","['G06F2218/04', 'G01M13/00', 'G01M13/021', 'G01M13/028', 'G06F18/2155', 'G06F18/24', 'G06N3/045', 'G06N3/048', 'G06N3/088', 'G06F2218/12']"
US12033277B2,Normalized three-dimensional avatar synthesis and perceptual refinement,"A system, method, and apparatus for generating a normalized three-dimensional model of a human face from a single unconstrained two-dimensional image of the human face. The system includes a processor that executes instructions including receiving the single unconstrained two-dimensional image of the human face, using an inference network to determine an inferred normalized three-dimensional model of the human face based on the single unconstrained two-dimensional image of the human face, and using a refinement network to iteratively determine the normalized three-dimensional model of the human face with a neutral expression and unshaded albedo textures under diffuse lighting conditions based on the inferred normalized three-dimensional model of the human face.","['G06V10/82', 'G06N3/045', 'G06T15/506', 'G06T17/00', 'G06V40/168', 'G06V40/175']"
US11030487B2,Noise-robust neural networks and methods thereof,"The exemplified methods and systems facilitate the training of a noise-robust deep learning network that is sufficiently robust in the recognition of objects in images having extremely noisy elements such that the noise-robust network can match, or exceed, the performance of human counterparts. The extremely noisy elements may correspond to extremely noisy viewing conditions, e.g., that often manifests themselves in the real-world as poor weather or environment conditions, sub-optimal lighting conditions, sub-optimal image acquisition or capture, etc. The noise-robust deep learning network is trained both (i) with noisy training images with low signal-to-combined-signal-and-noise ratio (SSNR) and (ii) either with noiseless, or generally noiseless, training images or a second set of noisy training images having a SSNR value greater than that of the low-SSNR noisy training images.","['G06K9/6257', 'G06T5/70', 'G06F18/2148', 'G06F18/2411', 'G06K9/6203', 'G06K9/6269', 'G06T5/002', 'G06T5/60', 'G06T7/0016', 'G06V10/30', 'G06V10/7515', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
KR101936302B1,Diagnosis method and apparatus for neurodegenerative diseases based on deep learning network,"According to the present invention, disclosed is a diagnostic method for neurodegenerative diseases based on deep learning network comprising: a step of converting user voice data into image data; a step of inputting the image data into a learned nerve network; and a step of deciding a diagnosis result of a user based on an output value from the nerve network. The nerve network is a deep learning model learned in advance in order to output the progression of the neurodegenerative disease of the user on a basis of a feature value from the image data obtained by converting the user voice data.","['G16H50/20', 'A61B5/4803', 'G06N3/042', 'G06N3/0427', 'G06N3/08']"
US20250124285A1,Data handling and machine learning,A method implemented by a software for a multimodal evaluation engine stored on a memory is provided herein. The software is executable by a processor coupled to the memory to cause the method. The method includes receiving multimodal signatures of an object of interest from inspection elements and processing the multimodal signatures to transform the multimodal signatures into formats. The method also includes generating data representations of the formats and detecting whether anomalies are present within the object of interest based on the data representations.,"['G06F21/71', 'G06N3/08', 'G06F21/562', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G01N2021/8845', 'G01N2021/8883', 'G01N2021/95638', 'G01N2201/1296', 'G01R31/281', 'G01R31/2837', 'G01R31/2846']"
US9411955B2,Server-side malware detection and classification,"A server-side system that detects and classifies malware and other types of undesirable processes and events operating on network connected devices through the analysis of information collected from said network connected devices. The system receives information over a network connection and collects information that is identified as being anomalous. The collected information is analyzed by system process that can group data based on optimally suited cluster analysis methods. Upon clustering the information, the system can correlate an anomalous event to device status, interaction, and various elements that constitute environmental data in order to identify a pattern of behavior associated with a known or unknown strain of malware. The system further interprets the clustered information to extrapolate propagation characteristics of the strain of malware and determine a potential response action.","['G06F21/55', 'G06F21/566', 'H04L63/14']"
US11276216B2,Virtual animal character generation from image or video data,"Systems and methods for generating a customized virtual animal character are disclosed. A system may obtain video data or other media depicting a real animal, and then may provide the obtained media to one or more machine learning models configured to learn visual appearance and behavior information regarding the particular animal depicted in the video or other media. The system may then generate a custom visual appearance model and a custom behavior model corresponding to the real animal, which may subsequently be used to render, within a virtual environment of a video game, a virtual animal character that resembles the real animal in appearance and in-game behavior.","['G06T13/40', 'A63F13/213', 'A63F13/52', 'A63F13/65', 'A63F13/655', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06T19/20', 'A63F2300/5553', 'A63F2300/66', 'A63F2300/69']"
CN110334805B,A Generative Adversarial Network-Based Method and System for Image Steganography in JPEG Domain,"The invention discloses a JPEG domain image steganography method based on a generation confrontation network, which comprises the steps of generating a tampering probability matrix corresponding to a DCT coefficient matrix of a carrier image through the generation network, generating a corresponding secret-carrying image according to the tampering probability matrix by utilizing an analog coding embedding module and a transferable gradient JPEG conversion module, distinguishing the carrier image from the secret-carrying image through a discrimination network, and carrying out confrontation training on the generation network and the discrimination network by taking a classification error as a loss function to finally obtain a generation network model capable of generating a self-adaptive steganography cost value. By combining the model with a traditional information coding module, secret information is embedded into a carrier image to obtain a carrier image. Compared with the traditional JPEG domain image steganography method, the method has the characteristics of simple design, easy realization, strong detection resistance and the like. The invention also discloses a JPEG domain image steganography system which comprises a network generation module, an information coding module and a JPEG conversion module, wherein the network generation module is obtained based on the JPEG domain image steganography method for generating the confrontation network.","['G06N3/084', 'G06T9/002', 'H04N19/625']"
US10871576B2,Error mitigation in doppler based satellite positioning system measurements,"Disclosed embodiments facilitate accuracy and decrease error in terrestrial positioning systems, including errors induced by multipath (e.g. ground reflections) in doppler based measurements of SVs. In some embodiments, one or more Global Navigation Satellite System (GNSS) doppler measurements and one or more corresponding GNSS pseudorange measurements for one or more satellites may be obtained. One or more GNSS doppler estimates corresponding to the one or more GNSS doppler measurements may be determined, wherein for a GNSS doppler measurement, the corresponding GNSS doppler estimate may be determined based, in part, on the GNSS doppler measurement and a GNSS pseudorange measurement corresponding to the GNSS doppler measurement. A speed of the UE may be determined based, in part, on the one or more GNSS doppler estimates.","['G01S19/52', 'G01S19/22', 'G01S19/254', 'G01S19/29', 'G01S19/40', 'G01S19/47', 'G01S19/49']"
US11720727B2,Method and system for increasing the resolution of physical gridded data,"Apparatuses, methods, and systems for increasing a spatial resolution of gridded spatial-temporal data on weather and climate-related physical variables are disclosed. One method includes obtaining weather and climate data including at least a coarse resolution and a fine resolution, or observational data that includes physical data, pre-processing the weather and climate data, training one or more probabilistic downscaling mapping functions of the at least one of the gridded numeric simulation data or the observational data comprising applying interpolation filters to successively interpolate the pre-processed weather and climate data to generate output data having a resolution that is equal to the fine resolution, and generating high-resolution physical parameters for at least one of a plurality of applications utilizing the trained probabilistic downscaling mapping functions receiving different weather and climate input data that has different times or locations than the pre-processed weather and climate data used in the training.","['G06F30/27', 'G06F30/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/086', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06F2111/04', 'G06F2111/08', 'G06F2111/10', 'G06N3/044', 'G06N3/084', 'Y02A90/10']"
US11423310B2,Deep learning based adaptive arithmetic coding and codelength regularization,"A deep learning based compression (DLBC) system applies trained models to compress binary code of an input image to a target codelength. For a set of binary codes representing the quantized coefficents of an input image, the DLBC system applies a first model that is trained to predict feature probabilities based on the context of each bit of the binary codes. The DLBC system compresses the binary code via adaptive arithmetic coding based on the determined probability of each bit. The compressed binary code represents a balance between a reconstruction quality of a reconstruction of the input image and a target compression ratio of the compressed binary code.","['G06N3/084', 'G06N20/00', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'G06V20/52', 'G06V30/18057', 'G06V30/19147', 'G06V30/19167', 'G06V30/19173', 'G06V40/172', 'G06F18/214', 'G06F18/2178', 'G06F18/24143', 'G06K9/6232', 'G06K9/6256', 'G06K9/6263', 'G06K9/6274', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06T5/002', 'G06T5/70', 'G06V10/449', 'G06V10/454', 'G06V10/758', 'G06V20/46', 'G06V30/10', 'G06V30/194', 'H04N19/126', 'H04N19/13', 'H04N19/149', 'H04N19/154', 'H04N19/167', 'H04N19/172', 'H04N19/18', 'H04N19/197', 'H04N19/33', 'H04N19/44', 'H04N19/48', 'H04N19/91']"
US11593468B2,System and method for identifying user,"A method may include acquiring first physiological data relating to a first subject, extracting at least one first physiological feature from the first physiological data relating to the first subject, determining a first model relating to at least one first reference physiological feature, generating, based on the first model and the at least one first physiological feature, a second model, the second model relating to at least one second reference physiological feature corresponding to the second model, and determining, based on the second model and the at least one first physiological feature, at least one identification physiological feature relating to the first subject. In some embodiments, the at least one identification physiological feature may correspond to the at least one second reference physiological feature.","['G06F21/32', 'A61B5/0006', 'G06N20/10', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V40/70', 'G06V40/15']"
US11790489B2,Systems and method of training networks for real-world super resolution with unknown degradations,"A method and apparatus are provided. The method includes generating a dataset for real-world super resolution (SR), training a first generative adversarial network (GAN), training a second GAN, and fusing an output of the first GAN and an output of the second GAN.","['G06T3/4046', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/4053', 'G06T2207/20084']"
US20230222314A1,"System and Method for Capturing, Preserving, and Representing Human Experiences and Personality Through a Digital Interface","A system and method to capture and interact with a comprehensive digital record of an individual's biographical history and produce a synthetic model of their personality. The captured biographical history is a detailed record of this individual's actions, interactions, and experiences over a period which may span decades of their lifetime. The biographical history is indexed by areas of data variability and neural network confidence variability to identify points of likely human interest. A synthetic personality model is generated as a representation of the individual's personality structure, biases, sentiments, and traits. The synthetic personality can be interacted with through a digital interface and demonstrates the interaction patterns, triggers, and habits of the original individual. The functioning and the performance of the system over an individual's lifespan are optimized through data synthesis and disposition.","['G06F16/2219', 'A61B5/167', 'G06F16/2477', 'G06F16/285', 'G06F16/287', 'G06N3/006', 'G06N3/094', 'G06T13/40', 'G06V10/764', 'G06V40/174', 'G06V40/20', 'G10L25/63', 'G06N3/045', 'G06N3/08']"
US11531885B2,Training data generation for visual search model training,"Systems, device and techniques are disclosed for training data generation for visual search model training. A catalog including catalog entries which may include images of an item and data about the item may be received. Labels may be applied to the images of the items based on the data about the items. The images of the items may be sorted into clusters using cluster analysis on the labels. Each cluster may include labels as categories of the cluster. Additional images may be received based on searching for the categories. Generative adversarial network (GAN) training data sets may be generated from the images of the items, the additional images, and the categories. GANs may be trained with the GAN training data sets. The GANs may generate images including images of generated items, which may be replaced with images of items from the catalog entries to create feature model training images.","['G06N3/084', 'G06F18/214', 'G06F18/23', 'G06K9/6218', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T3/40', 'G06V10/762', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US10810745B2,Method and apparatus with image segmentation,"A processor-implemented learning method for an image segmentation includes training first duplicate layers, as duplications of trained first layers of a pre-trained model, so that a second feature extracted from a target image by the trained first duplicate layers is matched to a first feature extracted from a training image by the trained first layers; regularizing the trained first duplicate layers so that a similarity between the first feature and a third feature extracted from the training image by the regularized first duplicate layers meets a threshold; and training second duplicate layers, as duplications of trained second layers of the pre-trained model, to be configured to segment the target image based on the regularized first duplicate layers, the trained second layer being configured to segment the training image.","['G06T7/10', 'G06N3/084', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/136', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V30/274', 'G06N20/10', 'G06T2207/20081', 'G06T2207/20084']"
CN116458103B,A neural network training method and related device,"A training method of a neural network and a related device are provided, wherein the method comprises the steps that a first device receives first channel sample information from a second device, the first device determines the first neural network, the first neural network is trained according to the first channel sample information, and the first neural network is used for reasoning to obtain second channel sample information according to the first channel sample information. By the method, the overhead of the air interface signaling can be effectively reduced, the channel environment can be adapted, and the communication performance is improved.","['G06N3/0455', 'H04L25/0224', 'H04L25/0254', 'G06N3/045', 'H04B7/0626', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'H04B7/0619', 'H04L27/2626', 'H04L27/2647', 'H04L5/0048', 'H04L5/0051', 'H04L5/0057']"
US20210003699A1,"Method and apparatus for sar image data enhancement, and storage medium","Disclosed are a method and apparatus for SAR image data enhancement, and a storage medium. The method includes: processing an SAR target image by electromagnetic simulation to acquire an SAR electromagnetic simulation image; and processing the SAR electromagnetic simulation image and the SAR target image by a generative adversarial network to obtain a set of virtual samples of the SAR target image.","['G06T5/90', 'G06T5/50', 'G01S13/9027', 'G01S7/417', 'G06T5/60', 'G06T2207/10041', 'G06T2207/10044', 'G06T2207/20081', 'G06T2207/20084']"
CN112184577B,Single image defogging method based on multiscale self-attention generation countermeasure network,"According to the single image defogging method based on the multiscale self-attention generated countermeasure network, a generated countermeasure network model constructed by carrying out downsampling on an image twice is trained through a training set formed by normalizing the image, a trained generated countermeasure network model is obtained, a defogging result is optimized through a loss function in the training process, and finally a foggy image is input into the generated countermeasure network model, so that a defogging image is obtained. The defogging method for the single image solves the problem of poor defogging image quality in the prior art.","['G06T5/73', 'G06T2207/20081', 'G06T2207/20084']"
US11252169B2,Intelligent data augmentation for supervised anomaly detection associated with a cyber-physical system,"A Cyber-Physical System (“CPS”) may have monitoring nodes that generate a series of current monitoring node values representing current operation of the CPS. A normal space data source may store, for each monitoring node, a series of normal monitoring node values representing normal operation of the CPS. An abnormal data generation platform may utilize information in the normal space data source and a generative model to create generated abnormal to represent abnormal operation of the CPS. An abnormality detection model creation computer may receive the normal monitoring node values (and generate normal feature vectors) and automatically calculate and output an abnormality detection model including information about a decision boundary created via supervised learning based on the normal feature vectors and the generated abnormal data.","['H04L63/1425', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N20/10', 'Y04S40/20']"
US11900052B2,Automatic generation of transformations of formatted templates using deep learning modeling,"The present disclosure applies trained artificial intelligence (AI) processing adapted to automatically generating transformations of formatted templates. Pre-existing formatted templates (e.g., slide-based presentation templates) are leveraged by the trained AI processing to automatically generate a plurality of high-quality template transformations. In transforming a formatted template, the trained AI processing not only generates feature transformation of objects thereof but may also provide style transformations where attributes associated with a presentation theme may be modified for a formatted template or set of formatted templates. The trained AI processing is novel in that it is tailored for analysis of feature data of a specific type of formatted template. The trained AI processing converts a formatted template into a feature vector and utilizes conditioned generative modeling to generate one or more transformed templates using a representation of the feature data and feature data from one or more other formatted templates.","['G06F16/4393', 'G06F40/186', 'G06F40/103', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06V10/40', 'G06N3/042', 'G06N3/08', 'G06N5/047']"
US10762298B2,Method and device for automatic data correction using context and semantic aware learning techniques,A method and device for automatic data correction using context and semantic aware learning techniques is disclosed. The method includes extracting data within a document as machine readable text in a predefined format. The method further includes encoding each word of each line in the machine readable text to a multi-dimension word vector. The method includes generating a context word vector for each word in each line based on multi-dimension vectors associated with words succeeding and preceding the word in a line comprising the word. The method further includes decoding the context word vector associated with each word in each line to generate a corrected context word vector for each word. The method includes validating the corrected context word vector associated with each word in each line.,"['G06F40/30', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09']"
US11954578B2,Denoising magnetic resonance images using unsupervised deep convolutional neural networks,"Systems and methods for denoising a magnetic resonance (MR) image utilize an unsupervised deep convolutional neural network (U-DCNN). Magnetic resonance (MR) image data of an area of interest of a subject can be acquired, which can include noisy input images that comprise noise data and noise free image data. For each of the noisy input images, iterations can be run of a converging sequence in an unsupervised deep convolutional neural network. In each iteration, parameter settings are updated; the parameter settings are used in calculating a series of image feature sets with the U-DCNN. The image feature sets predict an output image. The converging sequence of the U-DCNN is terminated before the feature sets predict a respective output image that replicates all of the noise data from the noisy input image. Based on a selected feature set, a denoised MR image of the area of interest of the subject can be output.","['G06N3/045', 'G06T5/70', 'A61B5/055', 'G01R33/5608', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/088', 'G06T5/002', 'A61B5/7203', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/10092', 'G06T2207/30016']"
AU2018328515C1,Method and apparatus for detecting model security and electronic device,"Disclosed in the embodiments of the present description are a method and apparatus for detecting model security and an electronic device. The method comprises: using a generative adversarial nets (GAN) frame, a model to be detected and sample training to obtain a discriminator; by means of the discriminator, making a determination for data of an intermediate result and/or output result calculated by the model to be detected for current input data so as to detect whether the model to be detected is currently secure.","['G06F21/52', 'G06F21/53', 'G06F21/57', 'G06F11/3692', 'G06F21/577', 'G06F21/6218', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
US10235523B1,Avionics protection apparatus and method,"An apparatus for a network of electrical and/or electronic devices coupled to a data bus comprises a sensor coupled to the data bus and configured to capture information content communicated through the data bus in a form of electromagnetic emissions being at least one of differential mode electromagnetic emissions, common mode electromagnetic emissions, coupled radiated electromagnetic emissions, and data bit streams; one or more processors or logic devices, and a non-transitory computational medium comprising executable instructions. The apparatus measure a feature value in at least one region of a time domain or a frequency domain of the captured electromagnetic emissions, calculates a difference value between the measured feature value and one or more baseline feature values, and determines, based on the calculated value, a presence or an absence of anomalies indicative of at least one of cyber intrusion attempt, cyber attack, cyber-physical attacks, malware, etc.","['G06F21/564', 'G06F13/4282', 'G06F21/556', 'G06F21/577']"
US11696714B2,System and method for brain modelling,"Brain modelling includes receiving time-coded bio-signal data associated with a user; receiving time-coded stimulus event data; projecting the time-coded bio-signal data into a lower dimensioned feature space; extracting features from the lower dimensioned feature space that correspond to time codes of the time-coded stimulus event data to identify a brain response; generating a training data set for the brain response using the features; training a brain model using the training set, the brain model unique to the user; generating a brain state prediction for the user output from the trained brain model, and automatically computing similarity metrics of the brain model as compared to other user data; and inputting the brain state prediction to a feedback model to determine a feedback stimulus for the user, wherein the feedback model is associated with a target brain state.","['A61B5/4064', 'A61B5/246', 'A61B5/02055', 'A61B5/375', 'A61B5/377', 'A61B5/7267', 'A61B5/7275', 'G16H20/00', 'G16H40/67', 'G16H50/20', 'G16H50/50', 'G16H50/70']"
GB2596901A,Content-aware style encoding using neural networks,"Neural Networks are used to apply feature(s) (e.g. styles, optionally from objects in the first image) from a first image to objects in a second image based on the object(s)’s location within the second image. The Neural Networks may be untrained. A styled output image (218) may be generated by neural network(s) (216) based on a style contained in a style image (214) and content of a content image (212) where the neural network(s) has not been trained by a training framework on the style. The NNs may transform the object(s) within the second image to comprise visual attribute(s) of the feature(s) from the first image. Application to medical and autonomous vehicle fields are disclosed, as well as hardware implementations of the invention.","['G06N3/04', 'G06T11/60', 'G06T3/04', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06T11/40', 'G06T5/50', 'G06T7/174', 'G06T7/73', 'G06T9/002', 'G06V10/764', 'G06T2207/20084']"
WO2022047625A1,"Image processing method and system, and computer storage medium","An image processing method and system, and a computer storage medium. The method comprises a generator training step: inputting a noise image to train network parameters by means of a loss function, so as to reduce the difference between an output image and a noiseless image (S10); a discriminator training step: respectively inputting the output image and the noiseless image of a trained generator network into a discriminator network to train network parameters by reducing a loss function, so that an output indicates whether an input is the output image or the noiseless image of the trained generator network (S20); and repeating the generator and discriminator training steps by using different noise images so as to obtain the final parameters of the generator and discriminator networks by minimizing the loss function (S30). The method has the effects of accelerating image processing and optimizing image edge information.",['G06N3/04']
US11676411B2,Systems and methods for neuronal visual-linguistic data retrieval from an imaged document,Systems and methods for automatic information retrieval from imaged documents. Deep network architectures retrieve information from imaged documents using a neuronal visual-linguistic mechanism including a geometrically trained neuronal network. An expense management platform uses the neuronal visual-linguistic mechanism to determine geometric-semantic information of the imaged document.,"['G06F16/532', 'G06V30/412', 'G06N20/00', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06Q30/04']"
US11810374B2,Training text recognition systems,"In implementations of recognizing text in images, text recognition systems are trained using noisy images that have nuisance factors applied, and corresponding clean images (e.g., without nuisance factors). Clean images serve as supervision at both feature and pixel levels, so that text recognition systems are trained to be feature invariant (e.g., by requiring features extracted from a noisy image to match features extracted from a clean image), and feature complete (e.g., by requiring that features extracted from a noisy image be sufficient to generate a clean image). Accordingly, text recognition systems generalize to text not included in training images, and are robust to nuisance factors. Furthermore, since clean images are provided as supervision at feature and pixel levels, training requires fewer training images than text recognition systems that are not trained with a supervisory clean image, thus saving time and resources.","['G06V20/62', 'G06F18/214', 'G06F18/2413', 'G06V10/764', 'G06V20/63', 'G06V30/153', 'G06V2201/01']"
US20220207680A1,Image Processing Method and Apparatus,"An image processing method includes obtaining a plurality of frames of raw images. After preprocessing such as image alignment, channel splitting or pixel rearrangement is performed on the obtained plurality of frames of raw images, detail restoration is performed on an image based on a deep learning network, and luminance enhancement and color enhancement are performed on an image output by the deep learning network. A plurality of types of processing related to detail restoration are integrated into a same deep learning network.","['G06T5/70', 'G06N3/045', 'G06T3/4015', 'G06T3/4053', 'G06T5/002', 'G06T5/003', 'G06T5/007', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'G06T5/90', 'G06T7/90', 'G06N3/08', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'H04N23/12', 'H04N23/843', 'H04N25/131', 'H04N25/134', 'H04N25/135']"
US10943349B2,Positron emission tomography system and image reconstruction method using the same,Disclosed are a positron emission tomography system and an image reconstructing method using the same and the positron emission tomography system includes: a collection unit collecting a positron emission tomography sinogram (PET sinogram); an image generation unit applying the positron emission tomography sinogram to an MLAA with TOF and generating a first emission image and a first attenuation image; and a control unit selecting at least one of the first emission image and the first attenuation image generated by the image generation unit as an input image and generating and providing a final attenuation image by applying the input image to the learned deep learning algorithm.,"['A61B6/037', 'A61B6/5247', 'A61B5/055', 'A61B5/7221', 'A61B5/7267', 'A61B6/032', 'G01T1/161', 'G01T1/2985', 'G06K9/6232', 'G06T11/005', 'G06T11/008', 'G06T5/60', 'G06T5/70', 'G06T7/0016', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'A61B6/5258', 'G06T2207/10104', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30016', 'G06T2211/424', 'G06T2211/428', 'G06T2211/441']"
US12190483B2,Deep generative modeling of smooth image manifolds for multidimensional imaging,A method for visualization of dynamic objects using a generative manifold includes steps of: acquiring a set of measurements associated with the dynamic objects using sensors; estimating parameters of a generator using the set of measurements and estimating latent variables using the set of measurements; modeling using a computing device the dynamic objects as a smooth non-linear function of the latent variables using the generator such that points in a latent subspace are mapped to a manifold in a generative manifold model; and generating a visualization of the dynamic objects using the generative manifold model. The set of measurements may include multi-slice data. The generative manifold model may provide for modeling deformations.,"['G06T5/70', 'G06N3/084', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/0895', 'G06T5/50', 'G06T2207/10076', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/30048', 'G06T2207/30061']"
US20210334665A1,"Text-based event detection method and apparatus, computer device, and storage medium","A training method includes obtaining a first data set and a second data set, each of the first data set and the second data set including event instances, the event instances include text and events corresponding to the text. The training method also includes training an adversarial network using the first data set and the second data set, the adversarial network includes processing circuitry configured as a generator and a discriminator. The discriminator is configured to output first reliable probabilities of the event instances in the first data set, and second reliable probabilities of the event instances inputted by the generator. A loss function of the adversarial network is used to adjust a parameter of the adversarial network, to maximize the first reliable probabilities and minimize the second reliable probabilities. The method further includes obtaining, by the trained adversarial network, a reliable event instance in the second data set.","['G06N3/088', 'G06N3/08', 'G06F16/3346', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047']"
US11295168B2,Depth estimation and color correction method for monocular underwater images based on deep neural network,"The invention discloses a depth estimation and color correction method for monocular underwater images based on deep neural network, which belongs to the field of image processing and computer vision. The framework consists of two parts: style transfer subnetwork and task subnetwork. The style transfer subnetwork is constructed based on generative adversarial network, which is used to transfer the apparent information of underwater images to land images and obtain abundant and effective synthetic labeled data, while the task subnetwork combines the underwater depth estimation and color correction tasks with the stack network structure, carries out collaborative learning to improve their respective accuracies, and reduces the gap between the synthetic underwater image and the real underwater image through the domain adaptation strategy, so as to improve the network's ability to process the real underwater image.","['G06K9/6256', 'H04N1/60', 'G06F18/214', 'G06K9/6232', 'G06T3/04', 'G06T5/90', 'G06T7/50', 'G06T7/55', 'G06V10/82', 'G06V20/05', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
US11190535B2,Methods and systems for inferring behavior and vulnerabilities from process models,"Systems and methods for process models to determine systems behavior and vulnerabilities are provided. In one embodiment, a method comprises collecting event logs from monitoring systems communicatively coupled to a computing device, each event log indicating an event occurring at a given time at a given activity within a process, measuring transition times between activities of the process from the event logs, calculating, from the measured transition times, a capacity of an activity of the activities, inferring behavior and vulnerabilities of the process based on one or more of the measured transition times and the capacity, and generating natural language output indicating the inferred behavior and vulnerabilities of the process. Further, simulations of the process are performed with statistical data regarding the event logs as input. In this way, aspects of a process such as an operational process in need of attention or vulnerable to external attacks may be rapidly identified and actions for resolution may be automatically recommended.","['H04L63/1425', 'G06F17/18', 'G06N5/04', 'G06N7/01', 'H04L63/1416', 'H04L63/1433']"
US11222242B2,Contrastive explanations for images with monotonic attribute functions,"In an embodiment, a method for generating contrastive information for a classifier prediction comprises receiving image data representative of an input image, using a deep learning classifier model to predict a first classification for the input image, evaluating the input image using a plurality of classifier functions corresponding to respective high-level features to identify one or more of the high-level features absent from the input image, and identifying, from among the high-level features absent from the input image, a pertinent-negative feature that, if added to the input image, will result in the deep learning classifier model predicting a second classification for the modified input image, the second classification being different from the first classification. In an embodiment, the method includes creating a pertinent-positive image that is a modified version of the input image that has the first classification and fewer than all superpixels of the input image.","['G06N3/08', 'G06K9/6262', 'G06N3/045', 'G06F18/2148', 'G06F18/217', 'G06F18/22', 'G06F18/24', 'G06F18/2431', 'G06K9/6201', 'G06K9/6257', 'G06K9/628', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G16H30/00', 'G16H50/50', 'G06N3/047', 'G06V2201/03', 'G06V2201/05']"
CN109523018B,Image classification method based on deep migration learning,"The invention requests to protect a picture classification method based on deep migration learning, wherein the field is adapted to data at least comprising two fields, namely a source field and a target field, and the source field data is marked sample data; step 4) training phase, carrying out field marking on the source domain and target domain samples, setting a loss function based on sample migration weight, and step 5) predicting phase, predicting the target domain data, and taking the category prediction result as a final result.","['G06N3/045', 'G06F18/00']"
CN111223062B,Image deblurring method based on generation countermeasure network,"The invention discloses an image deblurring method based on a generation countermeasure network, which mainly solves the problems of slow running speed and poor reconstruction effect when a fuzzy kernel needs to be estimated and clear images are obtained through deconvolution iteration in the prior art. The implementation scheme is as follows: 1) Selecting an experimental data set, and determining a training data set and a testing data set related to the experimental data set; 2) Respectively constructing a generation network with a 15-layer structure and a countermeasure network with a 6-layer structure; 3) Constructing a joint loss function according to the confrontation loss, the pixel loss and the characteristic loss; 4) Performing interactive training on the generation network and the countermeasure network through a joint loss function to obtain a generation countermeasure network model; 5) And inputting the test sample into a generated countermeasure network model to obtain a deblurred clear image. The method has the advantages of no need of estimating a blur kernel, high deblurring speed and good deblurring effect, and can be used for deblurring processing of the blurred image shot due to camera shake.","['G06T5/73', 'G06N3/045', 'G06N3/08', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US11176724B1,Identity preserving realistic talking face generation using audio speech of a user,"Speech-driven facial animation is useful for a variety of applications such as telepresence, chatbots, etc. The necessary attributes of having a realistic face animation are: 1) audiovisual synchronization, (2) identity preservation of the target individual, (3) plausible mouth movements, and (4) presence of natural eye blinks. Existing methods mostly address audio-visual lip synchronization, and synthesis of natural facial gestures for overall video realism. However, existing approaches are not accurate. Present disclosure provides system and method that learn motion of facial landmarks as an intermediate step before generating texture. Person-independent facial landmarks are generated from audio for invariance to different voices, accents, etc. Eye blinks are imposed on facial landmarks and the person-independent landmarks are retargeted to person-specific landmarks to preserve identity related facial structure. Facial texture is then generated from person-specific facial landmarks that helps to preserve identity-related texture.","['G06T13/40', 'G06F18/22', 'G06K9/00281', 'G06K9/6215', 'G06T13/205', 'G06V40/16', 'G06V40/171', 'G10L15/02', 'G10L21/10', 'H04N7/15', 'G10L2021/105']"
TWI792292B,Architecture for a hardware based explainable neural network,"Explainable neural networks may be designed to be easily implementable in hardware efficiently, leading to substantial speed and space improvements. An exemplary embodiment extends upon possible hardware embodiments of XNNs, making them suitable for low power applications, smartphones, mobile computing devices, autonomous machines, server accelerators, Internet of Things (IoT) and edge computing applications amongst many other applications. The capability of XNNs to be transformed from one form to another while preserving their logical equivalence is exploited to create efficient, secure hardware implementations that are optimized for the desired application domain and predictable in their behavior.","['G06N3/042', 'G06N3/063', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/098', 'G06N3/044', 'G06N3/088']"
CN110807122B,Image-text cross-modal feature disentanglement method based on depth mutual information constraint,"The invention discloses a method for disentanglement of image-text cross-modal characteristics based on depth mutual information constraint. Firstly, reading a text file and an image file in a specified data mode; next, respectively extracting original features from the text data and the image data by using ResNet and BiGRU; then, under the action of depth mutual information constraint, the original features are mapped to a mixed feature space; and finally, reconstructing the data to different degrees by using the generated countermeasure network, and realizing the de-entanglement of the cross-modal characteristics by controlling the reconstruction process, so that the modal common information and the modal specific information are respectively mapped to different characteristic spaces. The invention can learn the de-entanglement characteristics on large-scale image-text data, and improves the retrieval accuracy and enables the depth characteristics to have better interpretability by only de-entangling the characteristics.",['G06F16/5846']
US11783292B2,Augmented intelligence system impartiality assessment engine,"A method, system and computer-readable storage medium for performing a cognitive information processing operation. The cognitive information processing operation includes: receiving data from a plurality of data sources; processing the data from the plurality of data sources to provide cognitively processed insights via an augmented intelligence system, the augmented intelligence system executing on a hardware processor of an information processing system, the augmented intelligence system and the information processing system providing a cognitive computing function; performing an impartiality assessment operation via an impartiality assessment engine, the impartiality assessment operation detecting a presence of bias in an outcome of the cognitive computing function; and, providing the cognitively processed insights to a destination, the destination comprising a cognitive application, the cognitive application enabling a user to interact with the cognitive insights.","['G06Q10/10', 'G06F16/9535', 'G06F18/10', 'G06F18/15', 'G06F18/2111', 'G06F18/2132', 'G06F18/2148', 'G06F18/2185', 'G06F18/22', 'G06F18/24', 'G06F18/24147', 'G06F18/245', 'G06N20/00', 'G06N3/12', 'G06N3/126', 'G06N5/02', 'G06N5/04', 'G06N5/043', 'G06N5/045', 'G06N99/007', 'G06T19/006', 'G06V10/757', 'G06V10/7788', 'H04L67/10', 'H04L67/34', 'H04L67/56', 'G06N7/01']"
US20220300618A1,Privacy preserving cooperative learning in untrusted environments,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media that support cooperative training of machine learning (ML) models that preserves privacy in untrusted environments. For example, a server (or cloud-based computing device(s)) may be configured to “split” an initial ML model into various partial ML models, some of which are provided to client devices for training based on client-specific data. Output data generated during the training at the client devices may be provided to the server for use in training corresponding server-side partial ML models. After training of the partial ML models is complete, the server may aggregate the trained partial ML models to construct an aggregate ML model for deployment to the client devices. Because the client data is not shared with other entities, privacy is maintained, and the splitting of the ML models enables offloading of computing resource-intensive training from client devices to the server.","['G06F21/60', 'G06N3/084', 'G06F21/6245', 'G06N3/0454', 'G06N3/08', 'G06N3/082', 'G06N5/01', 'G06N3/045', 'G06N3/063']"
US11727086B2,Multimodality image processing techniques for training image data generation and usage thereof for developing mono-modality image inferencing models,"Techniques are described for generating mono-modality training image data from multi-modality image data and using the mono-modality training image data to train and develop mono-modality image inferencing models. A method embodiment comprises generating, by a system comprising a processor, a synthetic 2D image from a 3D image of a first capture modality, wherein the synthetic 2D image corresponds to a 2D version of the 3D image in a second capture modality, and wherein the 3D image and the synthetic 2D image depict a same anatomical region of a same patient. The method further comprises transferring, by the system, ground truth data for the 3D image to the synthetic 2D image. In some embodiments, the method further comprises employing the synthetic 2D image to facilitate transfer of the ground truth data to a native 2D image captured of the same anatomical region of the same patient using the second capture modality.","['G06F18/214', 'G06T15/10', 'A61B5/055', 'A61B5/7267', 'A61B6/032', 'A61B6/5223', 'G06F18/2178', 'G06F18/22', 'G06F18/28', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06T5/50', 'G06T7/30', 'G06V10/7715', 'G06V10/772', 'G06V10/774', 'G06V20/64', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2200/04', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212', 'G06T2207/30004', 'G06T2210/41', 'G06V2201/03']"
US20230207064A1,Inter-model prediction score recalibration during training,"The technology disclosed relates to a system for inter-model prediction score recalibration. The system includes a first model that generates, based on evolutionary conservation summary statistics of amino acids in a reference protein sequence, a first set of pathogenicity scores with rankings for variants that mutate the reference sequence to alternate protein sequences. The system further includes a second model that generates, based on epistasis expressed by amino acid patterns spanning a multiple sequence alignment aligning the reference sequence to non-target sequences, a second set of pathogenicity scores with rankings for the variants. The system further includes a rank loss determination logic that determines a rank loss parameter by comparing the two sets of rankings, a loss function reconfiguration logic that reconfigures a loss function based on the rank loss parameter, and a training logic that uses the reconfigured loss function to train the first model.","['G16B20/20', 'G16B30/00', 'G16B40/00', 'G06F18/2111', 'G06F18/2148', 'G06F18/2155', 'G06N20/00', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/126', 'G16B10/00', 'G16B20/00', 'G16B20/40', 'G16B30/10', 'G16B40/20', 'G16B40/30', 'G16B50/10', 'Y02A90/10']"
CN110689482B,Face super-resolution method based on supervised pixel-by-pixel generation countermeasure network,"The invention relates to a face super-resolution method based on supervised pixel-by-pixel generation countermeasure network, which comprises the steps of firstly reading an original face picture data set; then carrying out preprocessing work such as data cutting and cleaning; thirdly, reading the high-resolution face image, and performing bicubic interpolation downsampling to obtain a high-resolution face image-low-resolution face image pair; fourthly, inputting the low-resolution face image into a generator network to generate a super-resolution face image; and fifthly, respectively inputting the high-resolution face image and the super-resolution image into a pixel-by-pixel discriminator network, calculating a supervised pixel-by-pixel countermeasure loss function by using a pixel-by-pixel discrimination matrix output by the pixel-by-pixel discriminator network, and training a generator network by using error back propagation.","['G06T3/4053', 'G06N3/045', 'G06N3/084']"
WO2023050746A1,Method for enhancing sar image data for ship target detection,"Disclosed in the present invention is a method for enhancing SAR image data for ship target detection, which method has stable training and a robust mode. The method may be implemented by using the following technical solution: taking a ship position as a center, taking a ship position in the form of an image as a constraint condition for SAR image enhancement, after passing through two fully connected layers, reconstructing an obtained high-dimensional feature vector into a conditional feature map, cascading the conditional feature map and a latent variable feature map and then inputting same into a transposed convolutional layer, so as to obtain a comprehensive feature map, performing up-sampling layer by layer to improve the feature resolution, generating a new SAR ship image, correspondingly converting a target box into a label of the generated SAR image, and constructing a data-label pair; a discriminator extracting a feature of the data-label pair by means of a convolutional layer and determining the authenticity of the generated SAR image and the degree of matching between the image and the label, and by means of adversarial learning of a generator and the discriminator, exciting the generator to generate new higher-quality SAR image data; and finally, enhancing the SAR image data by means of collaborative learning of an adversarial network and a target detection network.","['G06T5/00', 'G06N3/045', 'G06N3/08', 'G06T2207/10044', 'G06T2207/20081']"
US20240062530A1,Deep perceptual image enhancement,"A system for training a neural network includes a neural network configured to receive a training input in an image space and produce an enhanced image. The system further includes an error signal generator configured to compare the enhanced image to a ground truth and generate an error signal that is communicated back to the neural network to train the neural network. Additionally, the system includes a neural input enhancer configured to modify the training input in response to receiving at least one of an output from the neural network or the error signal. Modifying the training input improves one of an efficiency or a training result of the neural network beyond the communication of the error signal to only the neural network.","['G06T5/00', 'G06T5/001', 'G06T5/50', 'G06V10/60', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V10/88', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212']"
US12288360B2,3D human pose estimation system,"Methods and systems for providing a dataset of human in-bed poses include simultaneously gathered images of in-bed poses of humans from imaging modalities including red-green-blue (RGB) and one or more of long wavelength infrared (LWIR), depth imaging, and pressure mapping. The images are obtained under a lighting condition and a cover condition. The dataset can be used to train a model of estimating human in-bed poses and for methods of estimating human in-bed poses. Methods and systems of estimating three-dimensional human poses from two-dimensional input images are provided.","['G06T7/80', 'G06T7/50', 'G06T7/74', 'G06T7/75', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30204', 'G06T2207/30232']"
CN111242238B,RGB-D image saliency target acquisition method,"The invention provides a method for acquiring an RGB-D image saliency target, which provides an interweaving fusion network for mutually guiding the joint extraction of RGB-D characteristics and densely integrating cross-modal complementary information through a network shallow layer structure and a deep layer structure, so that potential useful information can be automatically and fully acquired, and interference caused by the inconsistency of cross-modal data is reduced. Compared with the integration mode of independently extracting the RGB-D characteristics, the interactive guidance of the RGB-D characteristics is beneficial to promoting the complementation fusion of the cross-mode information and relieving the inconsistent problem in different modes; negative effects due to low quality depth maps caused by the imaging environment or equipment can also be reduced. By introducing an anti-loss term during the construction of the loss function, global semantic constraint is provided for RGB-D saliency target detection, so that a detection result focuses on pixel-level saliency attribute and can capture global semantic features of an object level to generate a saliency map with a complete structure and clear boundaries.","['G06F18/253', 'G06V2201/07']"
US12165034B2,Controlling a neural network through intermediate latent spaces,"A generative neural network control system controls a generative neural network by modifying the intermediate latent space in the generative neural network. The generative neural network includes multiple layers each generating a set of activation values. An initial layer (and optionally additional layers) receives an input latent vector, and a final layer outputs an image generated based on the input latent vector. The data that is input to each layer (other than the initial layer) is referred to as data in an intermediate latent space. The data in the intermediate latent space includes activation values (e.g., generated by the previous layer or modified using various techniques) and optionally a latent vector. The generative neural network control system modifies the intermediate latent space to achieve various different effects when generating a new image.","['G06T5/00', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06T3/00', 'G06N3/045', 'G06N3/063', 'G06N3/105', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20172', 'G06T2207/20221']"
WO2022110611A1,Pedestrian road-crossing behavior prediction method for plane intersection,"A pedestrian road-crossing behavior prediction method for a plane intersection, comprising the following steps: step 1: designing an instant reward function; step 2: establishing a fully convolutional neural network-long-short term memory (FCN-LSTM) model to predict an action reward function; step 3: training the (FCN-LSTM) model on the basis of reinforcement learning; and step 4: predicting pedestrian crossing behavior and carrying out a danger early warning. In the technical solution, a complex pedestrian motion model does not need to be established, and a large number of labeled data sets do not need to be prepared. Autonomous learning of pedestrian road-crossing behavior features at a plane intersection is achieved, and behavior such as walking, stopping and fast running are predicted. In particular, pedestrian road-crossing behavior when dangers such as human-vehicle collisions and scrapes are induced are predicted in real time. Therefore, a danger early warning is carried out on pedestrians crossing the road and passing vehicles, which is beneficial for reducing the traffic accident rate of key road sections such as plane intersections, and ensures the safety of the pedestrians in a traffic environment.","['G08G1/166', 'G06V40/25', 'G06N3/044', 'G06N3/049', 'G06V10/26', 'G06V10/267', 'G06V10/44', 'G06V10/454', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V20/52', 'G06V20/70', 'G06V40/10', 'G06V40/103', 'G08G1/052', 'Y02T10/40']"
CN110084757B,Infrared depth image enhancement method based on generation countermeasure network,"The invention discloses an infrared depth image enhancement method based on a generation countermeasure network, which comprises the following steps: selecting an image database of a training network; constructing and generating a confrontation network model; preprocessing an image; the training generates a confrontation network. According to the method, the generation countermeasure network in the deep learning algorithm is utilized to enhance the infrared depth image, the training of the generation countermeasure network is realized through the three-dimensional image quality database aiming at the difficulty of acquisition of the infrared depth image, the noise of the depth image with poor quality is removed, the quality of the depth image is improved, the obtained enhanced depth image can be used as a standard image for subsequent image processing, and the conditions of infrared depth image distortion and low quality are improved.","['G06T5/70', 'G06T5/80', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
CN113658051B,An image defogging method and system based on recurrent generative adversarial network,"The application discloses an image defogging method and system based on a circularly generated countermeasure network, comprising the following steps: acquiring a foggy image to be processed; inputting the images to a pre-trained dense connection circulation generation countermeasure network, and outputting a fogless image; the dense connection cyclic generation countermeasure network comprises a generator, the generator comprises an encoder, a converter and a decoder, the encoder comprises a dense connection layer and is used for extracting characteristics of an input image, the converter comprises an overswitching layer and is used for combining the characteristics extracted by the encoder stage, the decoder comprises a dense connection layer and a scaled convolution neural network layer, the dense connection layer is used for restoring original characteristics of the image, the scaled convolution neural network layer is used for removing chequering effects of the restored original characteristics, and a finally output haze-free image is obtained. The advantages are that: image defogging is performed on the basis of the circularly generated countermeasure network, the requirement on paired data sets is eliminated, the utilization rate of the feature map is improved, the network training efficiency is maintained, and the quality of the generated image is improved.","['G06T5/73', 'G06N3/045', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/10']"
CN113763442B,A deformable medical image registration method and system,"The invention relates to a deformable medical image registration method and system. The method comprises the following steps: acquiring a medical image data set, preprocessing the medical image data set, and dividing the medical image data set into a training set and a testing set; constructing a deformable image registration model based on dual-discriminant countermeasure learning, wherein the deformable image registration model comprises a generator and two discriminants; constructing a target loss function, wherein the target loss function comprises a regular term loss, a re-weighted loss, an antagonism loss of a global discriminator and an antagonism loss of a local discriminator respectively; taking an image pair to be registered in a training set as input of a network model, and carrying out iterative training on the network model based on a target loss function to obtain a pre-trained registration model; and inputting the image pairs to be registered in the test set into a pre-trained registration model to obtain a registration image. According to the method and the system, under the condition that the medical image training sample lacks labeling information, the registration accuracy of the medical image can be improved, and the generalization capability of the registration method and the registration system can be enhanced.","['G06T7/33', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'Y02T10/40']"
US11323464B2,Artifact modification and associated abuse detection,"An apparatus comprises at least one processing device comprising a processor coupled to a memory. The processing device is configured to identify artifacts in a plurality of messages of an account of a user, and to replace the identified artifacts in the messages with respective modified artifacts while also maintaining in access-controlled storage at least information related to the identified artifacts. The processing device receives from a requestor a request for a given one of the identified artifacts that has been replaced with a corresponding modified artifact, determines a profile of the requestor based at least in part on the request, makes a security determination based at least in part on the determined profile, and takes at least one automated action based at least in part on the security determination.","['H04L63/1425', 'H04L51/212', 'H04L63/0281', 'H04L63/0428', 'H04L63/08', 'H04L63/102', 'H04L63/1408', 'H04L63/1416', 'H04L63/145', 'H04L63/30', 'H04L51/52', 'H04L63/1483']"
US11423196B2,Systems and methods for predicting responses of a particle to a stimulus,"System, methods, and other embodiments described herein relate to predicting effects of a stimulus on a particle or other material structure. In one embodiment, a method includes receiving a segmented image of a particle that identifies at least semantics of the particle and associated characteristics according to subregions of the particle. The method includes analyzing, using a stimulus model, the segmented image to predict changes in the particle associated with applying the stimulus to the particle. Analyzing the segmented image includes generating a predicted image identifying characteristics, semantics and other properties of the particle according to the changes. The method includes providing the predicted image as an electronic output.","['G06F30/25', 'G06F18/2413', 'G06F30/20', 'G06F30/27', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T7/10', 'G06V10/26', 'G06V10/764', 'G06V20/695', 'G06V20/698', 'G06N3/047', 'G06T2207/20081']"
WO2021214751A1,Algorithm-based methods for predicting and/or detecting a clinical condition related to insertion of a medical instrument toward an internal target,"Provided are computer-implemented methods and systems for generating and/or utilizing data analysis algorithm(s) for predicting and/or detecting a clinical condition related to insertion of a medical instrument toward a target in a body of a patient based, inter alia, on data related to an automated medical device and/or to operation thereof.","['A61B34/25', 'A61B5/7267', 'A61B34/10', 'A61B34/32', 'A61B5/02042', 'A61B5/08', 'A61B5/1073', 'A61B5/489', 'A61B5/7275', 'A61B5/746', 'G06N20/00', 'G06T7/0012', 'G16H20/40', 'G16H30/20', 'G16H40/63', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'A61B2017/00203', 'A61B2034/104', 'A61B2034/107', 'A61B2034/2048', 'A61B2034/2065', 'A61B2034/301', 'A61B2090/365', 'A61B2090/374', 'A61B2090/3762', 'A61B2090/378', 'G06T2207/10', 'G16H20/17', 'G16H30/40', 'G16H70/20']"
US20210058395A1,Protection against phishing of two-factor authentication credentials,"An apparatus comprises at least one processing device comprising a processor coupled to a memory. The processing device is configured to identify artifacts in a plurality of messages of an account of a user, and to replace the identified artifacts in the messages with respective modified artifacts while also maintaining in access-controlled storage at least information related to the identified artifacts. The processing device receives from a requestor a request for a given one of the identified artifacts that has been replaced with a corresponding modified artifact, determines a profile of the requestor based at least in part on the request, makes a security determination based at least in part on the determined profile, and takes at least one automated action based at least in part on the security determination.","['H04L63/102', 'H04L63/0884', 'H04L51/063', 'H04L51/08', 'H04L51/212', 'H04L51/22', 'H04L51/42', 'H04L63/0281', 'H04L63/08', 'H04L63/1408', 'H04L63/1425', 'H04L63/145', 'H04L67/306', 'H04L63/1483']"
US20210273857A1,Method and system for virtual network emulation and self-organizing network control using deep generative models,A computer device may include a memory configured to store instructions and a processor configured to execute the instructions to train a generator neural network to simulate a network entity using a discriminator neural network that discriminates output associated with the network entity from output generated by the generator neural network. The computer device may be further configured to receive a set of input parameters associated with the simulated network entity; use the generator neural network to generate output for the simulated network entity based on the received set of input parameters; and apply the generated output for the simulated network entity to manage a communication network.,"['H04L41/145', 'G06N3/006', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06N3/10', 'H04L41/0894', 'H04L41/147', 'H04L43/08', 'H04L43/20', 'G06N20/10', 'G06N7/01', 'H04L41/0895', 'H04L41/40', 'H04L43/50', 'H04W84/18']"
US12288346B2,Feature pyramid warping for video frame interpolation,"Methods, systems, and storage media are described for motion estimation in video frame interpolation. Disclosed embodiments use feature pyramids as image representations for motion estimation and seamlessly integrates them into a deep neural network for frame interpolation. A feature pyramid is extracted for each of two input frames. These feature pyramids are wrapped together with the input frames to the target temporal position according to the inter-frame motion estimated via optical flow. A frame synthesis network is used to predict interpolation results from the pre-warped feature pyramids and input frames. The feature pyramid extractor and the frame synthesis network are jointly trained for the task of frame interpolation. An extensive quantitative and qualitative evaluation demonstrates that the described embodiments utilizing feature pyramids enables robust, high-quality video frame interpolation. Other embodiments may be described and/or claimed.","['H04N7/014', 'G06T3/4007', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T1/20', 'G06T7/269', 'G06V10/56', 'H04N5/145', 'H04N7/0127', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084']"
US11443559B2,Facial liveness detection with a mobile device,"A system for remote identification of users. The system uses deep learning techniques for authenticating a user from an identification document, using automated verification of identification documents and detection that a live person identified by the document is present. Liveness of a user indicated by the identification document may be determined with a deep learning model trained for identification of facial spoofing attacks. The deep learning model may be trained using training data extracted from facial feature locations of training images.","['G06F21/32', 'B42D25/23', 'B42D25/328', 'G06F18/214', 'G06F21/34', 'G06K9/6256', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/225', 'G06V10/25', 'G06V10/751', 'G06V30/413', 'G06V40/168', 'G06V40/172', 'G06V40/45', 'G06V40/67', 'G07D7/0032', 'G07D7/12', 'G07D7/206', 'G06V10/16']"
CN111260741B,Three-dimensional ultrasonic simulation method and device by utilizing generated countermeasure network,"A three-dimensional ultrasonic simulation method and a device for generating a countermeasure network are used for generating a simulated three-dimensional ultrasonic image and a real ultrasonic image to be highly simulated. The method comprises the following steps: (1) simultaneously inputting the magnetic resonance MR image and the ultrasonic US image into an encoder in a generator in a least squares generative countermeasure network based on spectral regularization; (2) embedding a three-dimensional self-adaptive example normalization layer between an encoder and a decoder of a network, and keeping the mean value and the variance of the MR image characteristics consistent with the mean value and the variance of the US image characteristics; (3) in the design of the network architecture of the generator, designing a Res-U-Net network architecture, wherein a residual block with a bottleneck is designed to replace blocks in an encoder and a decoder in the original U-Net network architecture; (4) combining content loss including modal perception with feature matching loss and antagonistic loss of spectral regularization to construct a new loss function for ultrasonic simulation; (5) a least squares generation dyadic network of spectral regularization is constructed.","['G06T9/002', 'G06N3/045', 'G06N3/08']"
US11645515B2,Automatically determining poisonous attacks on neural networks,"Embodiments relate to a system, program product, and method for automatically determining which activation data points in a neural model have been poisoned to erroneously indicate association with a particular label or labels. A neural network is trained using potentially poisoned training data. Each of the training data points is classified using the network to retain the activations of the last hidden layer, and segment those activations by the label of corresponding training data. Clustering is applied to the retained activations of each segment, and a cluster assessment is conducted for each cluster associated with each label to distinguish clusters with potentially poisoned activations from clusters populated with legitimate activations. The assessment includes executing a set of analyses and integrating the results of the analyses into a determination as to whether a training data set is poisonous based on determining if resultant activation clusters are poisoned.","['G06N3/08', 'G06F18/211', 'G06F18/23', 'G06F18/24', 'G06N20/00', 'G06N3/0499', 'G06N3/09', 'G06N7/01', 'G06V10/762', 'G06V10/771', 'G06V10/776']"
US11785040B2,Systems and methods for cyber security alert triage,"The present disclosure is directed to systems, apparatuses and methods for mitigating cyber-attacks. For example, the method includes receiving, from one or more network devices tracking activity on a network, one or more data streams associated with a respective one of the one or more network devices, identifying a security alert from the one or more data streams, the security alert including metadata context describing the network device from the one or more network devices that originated the security alert, analyzing the metadata context to generate a metadata context score. When the security alert is determined to be a security threat event, classifying a type of the security threat event based on the related activity score and the metadata context, and outputting a recommended mitigation course of action based on the classified type of the security threat event.","['H04L63/1441', 'G06F16/285', 'G06F21/552', 'G06F21/554', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/20']"
US10930263B1,Automatic voice dubbing for media content localization,"This disclosure describes techniques for replicating characteristics of an actor or actresses voice across different languages. The disclosed techniques have the practical application of enabling automatic generation of dubbed video content for multiple languages, with particular speakers in each dubbing having the same voice characteristics as the corresponding speakers in the original version of the video content.","['H04N21/233', 'G10L13/033', 'G06N3/006', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G10L13/00', 'G10L13/027', 'G10L13/086', 'G10L15/005', 'G10L15/16', 'G10L25/30', 'H04N21/234336', 'H04N21/251', 'H04N21/25841', 'H04N21/4856', 'H04N21/8106', 'H04N21/854', 'G06N3/044', 'G10L2013/105']"
CN110706157B,Face super-resolution reconstruction method for generating confrontation network based on identity prior,"The invention relates to a face super-resolution reconstruction method for generating a confrontation network based on identity prior, which comprises the steps of firstly reading an original face picture data set; then extracting a network for training human face features by using the human face image-identity label; thirdly, reading the high-resolution face image, and performing bicubic interpolation downsampling to obtain a high-resolution face image-low-resolution face image pair for model training; fourthly, inputting the low-resolution face image into a generator network to generate a super-resolution face image; then, respectively inputting the high-resolution face image and the super-resolution face image into a trained face feature extraction network, and extracting identity prior features of the high-resolution face image and the super-resolution face image; and then inputting the high-resolution face image, the super-resolution image and the corresponding identity prior features into a discriminator network, calculating a supervised countermeasure loss function by using the output of the discriminator network, and generating a countermeasure network by using error back propagation training.","['G06T3/4053', 'G06F18/22', 'G06N3/04', 'G06N3/08', 'G06V40/168']"
US11019407B2,Systems and methods for providing watermarked content,"A content processing system obtains an identification associated with a device configured to receive content, generates a digital watermark reflecting the receiving device's identification, provides watermarked content by including the digital watermark in the content, and transmits the watermarked content from an edge computing device to the receiving device for the playback. The digital watermark is not visually observable during playback of the watermarked content, and it enables tracking of transmission of the watermarked content.","['H04N1/32149', 'G06F21/1063', 'G06F21/16', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T1/0021', 'G06T1/0028', 'H04L9/0894', 'H04N21/2347', 'H04N21/2393', 'H04N21/2407', 'H04N21/251', 'H04N21/8358', 'G06N3/047', 'G06N3/084', 'G06T2201/0202']"
WO2022068195A1,"Cross-modal data processing method and device, storage medium and electronic device","A cross-modal data processing method and device, a storage medium and an electronic device. The cross-modal data processing method comprises: obtaining query data of a first modal; separately determining a target parameter between the query data of the first modal and retrieval data of each second modal in a retrieval data set of a second modal, to obtain a plurality of target parameters; and determining, according to the plurality of target parameters, the retrieval data of one or more second modals as target data corresponding to the query data of the first modal. The first modal and the second modals are effectively associated by using category annotation data as a bridge, to relieve semantic gaps between different modals. According to the cross-modal data processing method and device, the technical problems in the prior art that cross-modal data processing is difficult to achieve effectively and the performance of the cross-modal data processing method is poor can be solved, and the technical effects of improving the cross-modal data processing efficiency and optimizing the cross-modal data processing performance are achieved.","['G06F16/325', 'G06F16/3331', 'G06F18/214', 'G06F40/30', 'G06N3/045']"
US11190804B2,"Encoder, decoder, encoding method, and decoding method","The encoder includes processing circuitry, and memory. Using the memory, the processing circuitry: generates a predicted image of an input image that is a current image to be encoded, based on generated data output from a generator network in response to a reference image being input to the generator network, the generator network being a neural network; calculates a prediction error by subtracting the predicted image from the input image; and generates an encoded image by at least transforming the prediction error.","['H04N19/61', 'H04N19/107', 'H04N19/154', 'H04N19/176', 'H04N19/192', 'H04N19/196', 'H04N19/503', 'H04N19/593']"
US20210241119A1,"Pre-trained model update device, pre-trained model update method, and program","A pre-trained model update device includes: an alternative example generation unit configured to generate an alternative example and a correct answer label corresponding to the alternative example, based on a generative model representing training data used in generating a pre-trained model; an adversarial example generation unit configured to generate an adversarial example inducing the pre-trained model to misclassify and a correction label corresponding to the adversarial example, based on an attack model and based on the alternative example and the correct answer label generated by the alternative example generation unit; and a model update unit configured to perform additional learning based on a result of generation by the alternative example generation unit and a result of generation by the adversarial example generation unit, and generate an updated model.","['G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/047']"
US11688036B2,Generation of synthetic high-elevation digital images from temporal sequences of high-elevation digital images,"Implementations relate to detecting/replacing transient obstructions from high-elevation digital images, and/or to fusing data from high-elevation digital images having different spatial, temporal, and/or spectral resolutions. In various implementations, first and second temporal sequences of high-elevation digital images capturing a geographic area may be obtained. These temporal sequences may have different spatial, temporal, and/or spectral resolutions (or frequencies). A mapping may be generated of the pixels of the high-elevation digital images of the second temporal sequence to respective sub-pixels of the first temporal sequence. A point in time at which a synthetic high-elevation digital image of the geographic area may be selected. The synthetic high-elevation digital image may be generated for the point in time based on the mapping and other data described herein.","['G06T3/4007', 'A01D41/127', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/023', 'G06Q10/04', 'G06Q50/02', 'G06T5/50', 'G06T7/00', 'G06T7/0016', 'G06T7/143', 'G06V10/82', 'G06V20/13', 'G06V20/188', 'A01B79/005', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10032', 'G06T2207/10048', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30181', 'G06T2207/30188', 'G06T2207/30192', 'G06V20/194', 'Y02A40/10']"
CN111861906B,Pavement crack image virtual augmentation model establishment and image virtual augmentation method,"The application belongs to the field of pavement crack image processing, and discloses a pavement crack image virtual augmentation model establishment and an image virtual augmentation method. The model building method comprises the following steps: step 1: acquiring pavement crack images, and sequentially carrying out data quality improvement and image segmentation on the pavement crack images to obtain a real pavement crack image set; step 2: establishing a DCGAN generation countermeasure network model, wherein the DCGAN generation countermeasure network model comprises a generator network and a discriminator network, and penalty items are arranged behind loss functions of the generator network and the discriminator network; step 3: and (3) acquiring random noise, inputting the random noise and the real pavement crack image set acquired in the step (1) into the DCGAN generated countermeasure network model acquired in the step (2) for training, wherein the trained model is the pavement crack image virtual augmentation model. The application effectively solves the problem of insufficient crack image data sets, and well realizes the increase of the quantity and diversity of the crack image data sets.","['G06T5/70', 'G06N3/045', 'G06N3/084', 'G06T5/90', 'G06T7/0002', 'Y02T10/40']"
CN108564126B,Specific scene generation method fusing semantic control,"The invention provides a specific scene generation method integrating semantic control, which comprises the steps of selecting a plurality of object pictures and a plurality of different specific scene pictures containing the object; manufacturing different attribute labels according to the characteristics of a specific scene in a specific scene picture, and obtaining a training sample after cutting the specific scene picture; constructing a condition generating type countermeasure network consisting of a discriminator and a generator; inputting the item graph and the label into a generator as input, and generating a specific scene graph described by the label; the method comprises the steps that a specific scene graph of an article is used as a target scene graph, the specific scene graph, the target scene graph, the article graph and the label which are described by a label generated by a generator are input into a discriminator together, and the discriminator performs model training through a conditional countermeasure network; inputting the similar object images to be processed and the scene to be obtained into the trained model in a label mode to obtain the corresponding scene image.","['G06F18/214', 'G06F18/25', 'G06F18/29']"
CN111950628B,Robustness assessment and enhancement system of artificial intelligent image classification model,"A robustness assessment and enhancement system for an artificial intelligence image classification model, comprising: the system comprises a white box evaluation module, a black box evaluation module and a defense enhancement module, wherein the white box evaluation module obtains a model to be evaluated and selected evaluation indexes from a user, evaluates the attack resistance of the model from various aspects according to a plurality of different indexes, and calculates the scores of all indexes and the total score of robustness; the black box evaluation module obtains an output result of the model to be evaluated from the user, and the output result is compared with the correct label to obtain an evaluation result. Providing a plurality of black box assessment means, and assessing the robustness of the model from the black box perspective; the defense enhancing module is internally provided with a plurality of robustness improving means. And obtaining the model to be enhanced and the selected defense enhancing method information from the user, and carrying out robustness enhancement on the model uploaded by the user by using a corresponding defense enhancing method. According to the invention, the whole model robustness assessment flow is optimized through various robustness assessment indexes, so that the comparison and assessment between different methods can be more conveniently, accurately and comprehensively carried out, meanwhile, the model is defended through various built-in technologies, and the robustness of the model is improved.",['G06F18/217']
CN112163638B,"Method, device, equipment and medium for defending image classification model back door attack","The application relates to a method, a device, equipment and a medium for defending a back door attack of an image classification model, wherein the method comprises the following steps: acquiring a training image set; filtering the training images of the visible triggers in the training image set to obtain a training sample set; respectively carrying out standard training and countermeasure training on the image classification model by using a training sample set to obtain a first image classification model and a second image classification model; performing diagnosis and comparison on the first image classification model and the second image classification model according to the purity test image to determine whether training images of the first invisible trigger exist in the training image set; and when the training images of the first invisible trigger exist in the training image set, returning to the step of acquiring the training image set to continue training until the training images of the first invisible trigger do not exist in the training image set. The method and the device can improve the capability of the model for resisting the back door attack and enhance the robustness of the model for resisting the attack.","['G06F18/214', 'G06F18/24', 'G06N3/08']"
US11670015B2,Method and apparatus for generating video,"Embodiments of the present disclosure provide a method and apparatus for generating a video. The method may include: acquiring a cartoon face image sequence of a target cartoon character from a received cartoon-style video, and generating a cartoon face contour figure sequence based on the cartoon face image sequence; generating a face image sequence for a real face based on the cartoon face contour figure sequence and a received initial face image of the real face, a face expression in the face image sequence matching a face expression in the cartoon face image sequence; generating a cartoon-style face image sequence for the real face according to the face image sequence; and replacing a face image of the target cartoon character in the cartoon-style video with a cartoon-style face image in a cartoon-style face image sequence, to generate a cartoon-style video corresponding to the real face.","['G06T11/001', 'G06T13/40', 'G06T13/80', 'G06T11/60', 'G06T7/13', 'G06T7/246', 'G06V40/161', 'G06V40/165', 'G06V40/168', 'G06V40/171', 'H04N21/854', 'G06T2207/30201']"
EP3889914A2,Unsupervised learning of scene structure for synthetic data generation,"A rule set or scene grammar can be used to generate a scene graph that represents the structure and visual parameters of objects in a scene. A renderer can take this scene graph as input and, with a library of content for assets identified in the scene graph, can generate a synthetic image of a scene that has the desired scene structure without the need for manual placement of any of the objects in the scene. Images or environments synthesized in this way can be used to, for example, generate training data for real world navigational applications, as well as to generate virtual worlds for games or virtual reality experiences.","['G06N3/088', 'G06T17/00', 'A63F13/52', 'G06F16/51', 'G06F16/54', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N5/025', 'G06T15/00', 'G06T15/205', 'G06V10/25', 'G06V10/774', 'G06V20/20', 'A63F13/60', 'A63F13/67', 'G06F18/2148', 'G06F18/2155', 'G06N20/00', 'G06N3/044', 'G06N3/048', 'G06N7/01', 'G06T2210/61', 'G06V20/40']"
US20200292608A1,Residual-based substation condition monitoring and fault diagnosis,"Briefly, embodiments are directed to a system, method, and article for monitoring and diagnosing a status of one or more assets of a power grid system. Input data measurements and training data measurements from one or more data sources relating to the power grid system may be accessed or received. An offline training phase and an online monitoring and diagnosis phase may be performed. During the offline training phase, first features may be extracted from the training measurement data, one or more residual generation models may be trained using the extracted features as model inputs, and one or more residual-based classifiers may be trained. During the online monitoring and diagnosis phase, second features may be extracted from the input measurement data, one or more residuals may be generated based on the extracted second features, and a status of the one or more assets may be determined based on the one or more residuals, where the one or more residuals may comprise a difference between model predicted values and measured values from the one or more data sources. An output may be generated indicating the status of the one or more assets based on the classification of the status.","['G01R19/2513', 'G05B23/0254', 'G01R31/086', 'G05B15/02', 'G05B23/0208', 'G05B23/0221', 'G05B23/024', 'G05B23/027', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06N5/04', 'H02J13/00', 'H02J13/00002', 'H02J13/00034', 'H02H1/0092', 'H02J13/00001', 'H02J2203/20', 'Y02B90/20', 'Y02E40/70', 'Y02E60/00', 'Y04S10/22', 'Y04S10/30', 'Y04S10/40', 'Y04S10/50', 'Y04S20/00', 'Y04S40/20']"
US10735205B1,Methods and systems for implementing an anonymized attestation chain,"A system for implementing an anonymized attestation chain. The system includes a first device having a first hardware-generated secret and a first verification datum linked to the first hardware-generated secret. The first device is designed and configured to receive an originating signature from an originating device and an originating verification datum. The originating signature includes a secure proof of an originating device secret. The originating signature signs a message referencing the first verification datum, and the originating signature is verified by the originating verification datum. First device generates a first anonymized signature set. The first anonymized signature set includes a modified first verification datum, a modified originating signature, and a modified originating verification datum. First devices delegates the at least a credential to a second verification datum.","['H04L9/3257', 'H04L9/3247', 'H04L9/0637', 'H04L9/3255', 'H04L9/3265', 'H04L2209/42']"
CN111650204B,Method and system for detecting defects of transmission line fittings based on cascade target detection,"The invention discloses a transmission line hardware defect detection method and system based on cascade target detection, comprising the following steps: using a trained first target detection model to detect a connection area of the power transmission line image, and cutting the detected connection area; taking n connecting areas with the area size meeting preset conditions as images to be identified; performing fine hardware defect detection on the image to be identified by using a trained second target detection model, and obtaining coordinates of the fine hardware defect on the image to be identified; according to the method, the defect of the fine hardware fitting is displayed in an original image according to the mapping relation between the coordinates of the image to be identified and the coordinates of the original image, and the method adopts a cascade target detection algorithm to deeply convolve the neural network for identifying the small target of the fine hardware fitting of the power transmission line, and then identifies the connection area in the power transmission line image, and then identifies the defect condition of the fine hardware fitting of the connection area, so that the defect detection precision of the fine hardware fitting is remarkably improved.","['G01N21/8851', 'G01N2021/8861', 'G06F17/15', 'Y04S10/50']"
AU2019421383B2,System and method for deriving high-resolution subsurface reservoir parameters,"A method is described for deriving high-resolution reservoir properties for a subsurface reservoir. The method may include receiving a seismic dataset; inverting the seismic dataset to generate an ensemble of coarse-scale seismic parameters, wherein the inverting may use one of Bayesian models with Markov Chain Monte Carlo (MCMC) sampling, simulated annealing, partial swarm, or analytic Bayes formulations; receiving fine-scale lithotype models; developing deep learning neural networks based on transfer learning using the fine-scale lithotype models to generate a conditional probability distribution of high-resolution reservoir parameters; generating an ensemble of high-resolution reservoir parameters using the deep learning neural network to condition the ensemble of coarse-scale seismic parameters; and displaying, on a user interface, the ensemble of high-resolution reservoir parameters. The method is executed by a computer system.","['G01V1/282', 'G01V1/306', 'G01V1/345', 'G01V1/50', 'G06F30/20', 'G06N20/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N7/01', 'G01V2210/6246', 'G06F2113/08']"
CN110503598B,Generative Adversarial Networks Based on Conditional Loop Consistency for Font Style Transfer,"The invention discloses a font style migration method for generating an confrontation network based on condition cycle consistency, which specifically comprises the following steps: creating a source font and a target font data set, and carrying out normalization processing along with the data sets; building a font style migration network structure, wherein the network consists of a generator for generating an confrontation network and a residual error network based on conditions and a judgment network based on PatchGAN, and inputting a source font and a label picture into the generator to generate a target style font; the discriminator network discriminates the authenticity of the generated target font and the real target font corresponding to the generated target font, optimizes the Chinese character migration network by means of the thought of the confrontation network training, realizes the mutual mapping migration of the two font styles, reduces the manual interference in the font generation process, and improves the automation degree of the generated font.","['G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T3/04']"
CN111598787B,"Biological radar image denoising method and device, electronic equipment and storage medium thereof","The invention discloses a biological radar image denoising method, a device, electronic equipment and a storage medium thereof, wherein the method comprises the steps of acquiring a biological radar image training set; constructing a generated type countermeasure neural network model, and training the generated type countermeasure neural network model according to a biological radar image training set to obtain a trained generated type countermeasure neural network model, wherein a loss function adopted in the training process comprises a conditional triplet loss function; and inputting the test biological radar noise image into the trained generated type anti-neural network model to obtain a denoised image. According to the biological radar image denoising method provided by the invention, as the conditional triplet loss function is adopted in the training process, the generated type anti-neural network model is better converged, and the detail storage of the denoising image obtained by adopting the generated type anti-neural network model is better.","['G06T5/70', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T2207/10044', 'Y02T10/40']"
US11790581B2,Transferring hairstyles between portrait images utilizing deep latent representations,"The disclosure describes one or more embodiments of systems, methods, and non-transitory computer-readable media that generate a transferred hairstyle image that depicts a person from a source image having a hairstyle from a target image. For example, the disclosed systems utilize a face-generative neural network to project the source and target images into latent vectors. In addition, in some embodiments, the disclosed systems quantify (or identify) activation values that control hair features for the projected latent vectors of the target and source image. Furthermore, in some instances, the disclosed systems selectively combine (e.g., via splicing) the projected latent vectors of the target and source image to generate a hairstyle-transfer latent vector by using the quantified activation values. Then, in one or more embodiments, the disclosed systems generate a transferred hairstyle image that depicts the person from the source image having the hairstyle from the target image by synthesizing the hairstyle-transfer latent vector.","['G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06T7/11', 'G06V10/82', 'G06V40/165', 'G06V40/171', 'G06T2207/20084', 'G06T2207/30196']"
CN110580501B,Zero sample image classification method based on variational self-coding countermeasure network,"A zero sample image classification method based on a variation self-coding countermeasure network is characterized in that a visual mode and a semantic mode are constructed, visual features and semantic features are respectively and correspondingly used as the input of the two variation self-encoders to generate pseudo visual features and semantic features, and finally the true and generated visual features and semantic features are input into a discriminator to finish the countermeasure process by a measurement learning method; then starting training a softmax classifier, inputting the visual features of the unseen images into a variable self-encoder of the visual mode, and training the classifier by using the generated pseudo visual features and the corresponding labels; and during testing, inputting the real visual features of the non-seen samples into a classifier to classify, so as to realize the zero-sample image classification task. The invention can realize classification tasks in more real scenes, is beneficial to pushing zero sample learning to be applied to production and living practice, and accelerates the practical development of a deep learning algorithm.","['G06F18/214', 'G06F18/2415']"
US20250005942A1,Detection and identification of defects using artificial intelligence analysis of multi-dimensional information data,"Methods, apparatus and program products for acquiring and analyzing images of a sample. An artificial intelligence (AI) module may be trained to identify, within multi-dimensional image data corresponding to images of objects, wavelength patterns corresponding to one or more defects within the objects. An analysis module is configured to detect one or more defects in the sample using the AI module for analyzing the images of the sample. In some embodiments, the samples are food samples and the defects include one or more pathogens.","['G06V10/14', 'G06T7/0002', 'G06T7/0012', 'G06V10/143', 'G06V10/454', 'G06V10/58', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G06V10/87', 'G06V20/68', 'G06V20/698', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10048', 'G06T2207/10056', 'G06T2207/20016', 'G06T2207/20064', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30024', 'G06T2207/30128']"
EP4207766A1,Entropy encoding/decoding method and device,"This application provides an entropy encoding/decoding method and apparatus; and relates to the field of artificial intelligence (AI)-based video or picture compression technologies, and in particular, to the field of neural network-based video compression technologies. The method includes: obtaining base layer information of a to-be-encoded picture block, where the base layer information corresponds to M samples in the picture block, and M is a positive integer; obtaining K elements corresponding to enhancement layer information of the picture block, where the enhancement layer information corresponds to N samples in the picture block, both K and N are positive integers, and N≥M; inputting the base layer information into a neural network to obtain K groups of probability values, where the K groups of probability values correspond to the K elements, and any group of probability values is for representing probabilities of a plurality of candidate values of a corresponding element; and performing entropy encoding on the K elements based on the K groups of probability values. This application can improve entropy encoding/decoding efficiency.","['H04N19/91', 'G06N3/0455', 'G06N3/047', 'G06N3/088', 'H04N19/13', 'H04N19/132', 'H04N19/172', 'H04N19/176', 'H04N19/30', 'H04N19/42', 'H04N19/50', 'H04N19/70', 'G06N3/044', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/094']"
US10726153B2,Differentially private machine learning using a random forest classifier,"A request from a client is received to generate a differentially private random forest classifier trained using a set of restricted data. The differentially private random forest classifier is generated in response to the request. Generating the differentially private random forest classifier includes determining a number of decision trees and generating the determined number of decision trees. Generating a decision tree includes generating a set of splits based on the restricted data, determining an information gain for each split, selecting a split from the set using an exponential mechanism, and adding the split to the decision tree. The differentially private random forest classifier is provided to the client.","['G06F21/6245', 'G06F16/2455', 'G06F16/248', 'G06F17/18', 'G06F18/24323', 'G06F21/6254', 'G06K9/6282', 'G06N20/00', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G16H10/60', 'G06F17/11', 'G06F18/214', 'G06F2221/2145', 'G06K9/6256', 'G06N20/10']"
US11616804B2,Thwarting model poisoning in federated learning,"A method detects model-poisoning attempts in a federated learning system. The federated learning system includes a server orchestrating with clients to train a machine-learning model. The method includes receiving, by the server, results of a poisoning detection analysis. The poisoning detection analysis includes at least one of an analysis of class-specific misclassification rates or an analysis of activation clustering of a current state of the machine-learning model.","['H04L63/1441', 'G06N20/00', 'G06N3/08', 'G06N3/09', 'G06N3/098', 'G06N5/04']"
WO2020087607A1,Bi-skip-net-based image deblurring method,"The present invention relates to the field of digital image processing, in particular to a Bi-Skip-Net-based image deblurring method for realizing blurred image restoration by means of a Bi-Skip-Net, which aims to solve the problems in existing deep learning deblurring algorithms of high time complexity, inaccurate texture restoration, and a square effect of a restored image, etc. In the disclosure of the present invention, a Bi-Skip-Net serves as a generative network of a GAN (Generative Adversarial Network), which aims to overcome the defects in existing deep learning deblurring algorithms. Comparing the present invention with existing optimal algorithms, the time complexity is improved by 0.1s, and the image restoration performance is improved by 1dB on average.","['G06T5/73', 'G06N3/045']"
CN113014927B,Image compression method and image compression device,"The present disclosure relates to an image compression method and an image compression apparatus, the image compression method including: based on an input image, obtaining hidden variables of the input image by using a coding network, wherein the coding network is a deep learning neural network and comprises at least one downsampling back-projection module; performing entropy encoding based on the hidden variable to obtain a bit stream file of the compressed image; each of the at least one downsampled backprojection module comprised by the encoding network performs the following operations: performing downsampling transformation on the first feature map input to the downsampling back-projection module to obtain a second feature map; performing reconstruction on the second feature map to obtain a third feature map with the same resolution as the first feature map; obtaining a fourth feature map as an optimization result of the second feature map based on a difference value between the first feature map and the third feature map, and obtaining a hidden variable based on the fourth feature map obtained by a last downsampling rear projection module of at least one downsampling rear projection module in the coding network.","['H04N19/91', 'H04N19/42', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06T9/002', 'H04N19/132', 'H04N19/136', 'H04N19/147', 'H04N19/182', 'H04N19/184', 'H04N19/59']"
US10831577B2,"Abnormality detection system, abnormality detection method, abnormality detection program, and method for generating learned model","A method and system that efficiently selects sensors without requiring advanced expertise or extensive experience even in a case of new machines and unknown failures. An abnormality detection system includes a storage unit for storing a latent variable model and a joint probability model, an acquisition unit for acquiring sensor data that is output by a sensor, a measurement unit for measuring the probability of the sensor data acquired by the acquisition unit based on the latent variable model and the joint probability model stored by the storage unit, a determination unit for determining whether the sensor data is normal or abnormal based on the probability of the sensor data measured by the measurement unit, and a learning unit for learning the latent variable model and the joint probability model based on the sensor data output by the sensor.","['G06F11/0703', 'G06F11/07', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0475', 'G06N3/0499', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06N7/00', 'G06N7/005', 'G06N7/01', 'G06K2009/00583', 'G06N3/04', 'G06V20/90']"
US11120585B2,Systems and methods for image reconstruction,"The present disclosure relates to a system. The system may obtain a k-space dataset according to magnetic resonance (MR) signals acquired by a magnetic resonance imaging (MRI) scanner. The system may also generate, based on the k-space dataset using an image reconstruction model that includes a sequence sub-model and a domain translation sub-model, a reconstructed image by: inputting at least a part of the k-space dataset into the sequence sub-model; outputting, from the sequence sub-model, a feature representation of the k-space dataset; inputting the feature representation of the k-space dataset into the domain translation sub-model; and outputting, from the domain translation sub-model, the reconstructed image.","['G06T11/008', 'G06T11/003', 'G01R33/5602', 'G01R33/5608', 'G01R33/561', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06T2207/10088', 'G06T2207/20084', 'G06T2207/30004']"
US11620521B2,Smoothing regularization for a generative neural network,"A style-based generative network architecture enables scale-specific control of synthesized output data, such as images. During training, the style-based generative neural network (generator neural network) includes a mapping network and a synthesis network. During prediction, the mapping network may be omitted, replicated, or evaluated several times. The synthesis network may be used to generate highly varied, high-quality output data with a wide variety of attributes. For example, when used to generate images of people's faces, the attributes that may vary are age, ethnicity, camera viewpoint, pose, face shape, eyeglasses, colors (eyes, hair, etc.), hair style, lighting, background, etc. Depending on the task, generated output data may include images, audio, video, three-dimensional (3D) objects, text, etc.","['G06N3/088', 'G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/044', 'G06N3/063', 'G06N3/084']"
US20220016423A1,Brain interfacing apparatus and method,"Here is disclosed brain interfacing apparatus that provides, when in operation, brain activity monitoring and stimulation of brain of user comprising headwear arrangement to be placed or positioned on head of user wherein headwear arrangement comprises electrode arrangement including plurality of electrodes that makes electrical contact with scalp of user, input/output arrangement that receives electrical signals from plurality of electrodes and delivers brain stimuli using brain stimulation protocol to plurality of electrodes, data processing arrangement that processes detected electrical signals received from input/output arrangement and generates brain stimulation protocol corresponding to received electrical signals, wherein data processing arrangement includes memory module; and power units that supply electrical power to input/output arrangement and data processing arrangement. Data processing arrangement compares received electrical signals with predetermined reference data set to generate analysis of received electrical signals and applies, machine learning algorithm or another computational algorithm to analysis when generating brain stimulation protocol.","['A61B5/369', 'A61N1/36031', 'A61B5/24', 'A61B5/375', 'A61B5/486', 'A61B5/6803', 'A61B5/6814', 'A61B5/7235', 'A61N1/025', 'A61N1/0456', 'A61N1/0476', 'A61N1/0484', 'A61N1/18', 'A61N1/36014', 'A61N1/36025', 'A61N1/37264', 'G06F3/015']"
US12175632B2,"Image processing method and apparatus, device, and video processing method","An image processing method and apparatus, a device, a video processing method and a storage medium are provided. The image processing method includes: receiving an input image; and processing the input image by using the convolutional neural network to obtain an output image. A definition of the output image is higher than a definition of the input image. Processing the input image by using the convolutional neural network to obtain the output image includes: performing feature extraction on the input image; concatenating the input image and the plurality of first images; performing the feature extraction on the first image group; fusing the plurality of second images and the plurality of first images; concatenating the input image and the plurality of third images to obtain a second image group; and performing the feature extraction on the second image group to obtain the output image.","['G06T5/50', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06V10/40', 'G06V10/7747', 'G06V10/776', 'G06V10/803', 'G06V10/806', 'G06V10/82', 'H04N19/42', 'H04N7/015', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30168', 'G06V10/454']"
CN111325236B,Ultrasonic image classification method based on convolutional neural network,"The invention discloses an ultrasonic image classification method based on a convolutional neural network. The method comprises the following steps: defining an interested area from an original image and cutting to obtain a cut image; performing data amplification on the cut image by adopting a Gaussian noise adding method and a histogram equalization method to obtain a data set after data amplification; training for generating a countermeasure network by using the augmented data set, and verifying and testing to obtain a trained generator; loading the trained generator, reasoning out an image through noise, and calibrating a label for the generated image; and expanding the image generated by the generator into a classification data set, retraining the convolutional neural network to classify the ultrasonic image, outputting the accuracy and the recall rate, and evaluating the network performance. When the ultrasonic images are classified, the problem of insufficient training data set in the neural network is solved, and the generalization performance of the network is improved.","['G06F18/24', 'G06F18/214', 'G06N3/045']"
US11184766B1,"Systems and methods for continuous authentication, identity assurance and access control","According to one embodiment, the system maintains and enforces assertions about a user's intent and identity at a point of access (e.g., a computer system being used to access a service, system, cloud, etc.). In one example, the system includes lightweight browser components and mobile and/or desktop agents that communicate in the background with a cloud-based authentication service. The system integrates seamlessly with enterprise applications, cloud services, multi-factor authentication solutions and existing identity management solutions. In one example, the system includes protocols, application programming interfaces, etc. that facilitate integration with standards such as Fast Identity Online (“FIDO”) Universal Authentication and OpenID Connect. In one example, the system includes protocols, application programming interfaces, etc. that facilitate integration with existing widely adopted SMS/Phone call or One Time Passcode (OTP) based multi-factor solutions so such system can be integrated with existing enterprise infrastructure with minimal efforts.","['H04W12/065', 'G06F18/22', 'G06F21/32', 'G06F21/45', 'G06K9/0002', 'G06K9/00087', 'G06K9/00335', 'G06N5/04', 'G06V10/75', 'G06V40/1306', 'G06V40/1365', 'G06V40/20', 'H04W12/06', 'G06K9/66', 'G06N20/00', 'H04L63/0861', 'H04L63/107', 'H04W12/08', 'H04W12/63', 'H04W12/65']"
US20210339772A1,Driving scenarios for autonomous vehicles,"One aspect herein provides a method of analysing driving behaviour in a data processing computer system, the method comprising: receiving at the data processing computer system driving behaviour data to be analysed, wherein the driving behaviour data records vehicle movements within a monitored driving area; analysing the driving behaviour data to determine a normal driving behaviour model for the monitored driving area; using object tracking to determine driving trajectories of vehicles driving in the monitored driving area; comparing the driving trajectories with the normal driving behaviour model to identify at least one abnormal driving trajectory; and extracting a portion of the driving behaviour data corresponding to a time interval associated with the abnormal driving trajectory.","['G08G1/0116', 'B60W40/02', 'B60W40/04', 'B60W50/0097', 'B60W60/0011', 'B60W60/0013', 'B60W60/0015', 'B60W60/0027', 'G05B13/027', 'G05B13/04', 'G06F18/214', 'G06F18/24', 'G06F18/2411', 'G06F18/29', 'G06F18/295', 'G06K9/00785', 'G06K9/6256', 'G06K9/6267', 'G06K9/6297', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N5/045', 'G06N7/01', 'G06T7/20', 'G06V10/84', 'G06V20/54', 'G06V20/56', 'G08G1/0129', 'G08G1/164', 'H02J3/14', 'H04N7/183', 'B60W2050/0002', 'B60W2050/0028', 'B60W2050/005', 'B60W2420/00', 'B60W2540/30', 'B60W2554/00', 'B60W2554/4046', 'B60Y2400/30', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30236', 'G06T2207/30241', 'H02J2310/12', 'Y02B70/3225', 'Y04S20/222']"
CN111460443B,Security defense method for data manipulation attack in federated learning,"The invention discloses a security defense method for data manipulation attack in federated learning, which comprises the following steps: step 1, a central server receives local model parameters uploaded by users, and calculates the similarity of local model parameters uploaded by each user in the current round and the corresponding fusion coefficient of each user; the local model parameters are the local model parameters after the user adopts private training data to train one round; step 2, after receiving the local model parameters of the local users in one period, the central server calculates the weighted average value of the local model parameters of each user according to the fusion coefficient to obtain global model parameters, wherein the one period is the number of updating rounds of the preset local model parameters; and 3, issuing the global model parameters to corresponding users, and updating the local model parameters after the users receive the global model parameters.","['G06F21/554', 'G06F18/22', 'G06F21/604', 'G06N20/00', 'G06N3/08']"
US10536437B2,Performing privacy-preserving multi-party analytics on vertically partitioned local data,"Example computing devices described herein enable computation of a machine learning model on distributed multi-party data that is vertically partitioned, in a privacy preserving fashion. The computing device computes at a party a sum of local data owned by the party, wherein the local data is vertically partitioned into a plurality of data segments, each data segment representing a non-overlapping subset of data features; transforms a cost function of a data analytics task to a gradient descent function, wherein the cost function comprises a summation of a plurality of cost function values; anonymizes aggregated data shards received from a mediator; updating local model parameters based on the aggregated data shards; and performs privacy-preserving multi-party analytics on the vertically partitioned local data based on a learned global analytic model. It leverages a secure-sum protocol that provides strong security guarantees against collusion and prior-knowledge attacks.","['H04L63/0428', 'H04L67/12', 'H04W12/02', 'H04W4/70']"
US11669689B2,Natural language generation using pinned text and multiple discriminators,"A personality model is created for a population and used as an input to a text generation system. Alternative texts are created based upon the emotional effect of the generated text. Certain words or phrases are “pinned” in the output, reducing the variability of the generated text so as to preserve required information content, and a number of tests provide input to a discriminator network so that proposed outputs both match an outside objective regarding the information content, emotional affect, and grammatical acceptability. A feedback loop provides new “ground truth” data points for refining the personality model and associated generated text.","['G06F40/30', 'G06F40/211', 'G06F40/56', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N7/01']"
US10846488B2,Collating information from multiple sources to create actionable categories and associated suggested actions,"A personality model is created for a population and used as an input to a text generation system. Alternative texts are created based upon the emotional effect of the generated text. Certain words or phrases are “pinned” in the output, reducing the variability of the generated text so as to preserve required information content, and a number of tests provide input to a discriminator network so that proposed outputs both match an outside objective regarding the information content, emotional affect, and grammatical acceptability. A feedback loop provides new “ground truth” data points for refining the personality model and associated generated text.","['G06F40/216', 'G06F40/295', 'G06F40/30', 'G06F40/56', 'G06N3/006', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/048', 'G06N7/01', 'G10L19/0212']"
WO2021174935A1,Generative adversarial neural network training method and system,"A generative adversarial neural network training method, comprising the following steps: establishing an initial discrimination neural network and an initial generation neural network so as to form an initial generative adversarial neural network (S100); initializing a parameter of the initial generative adversarial neural network and a boundary vector (S102); acquiring a real sample set and a random variable set, and inputting the random variable set into the initial generation neural network so as to generate a false sample set (S104); inputting the real sample set and the false sample set into the initial discrimination neural network so as to obtain a first discrimination output and a second discrimination output (S106); performing a calculation according to a preset discriminant loss function to obtain a discriminant loss value (S108); performing a calculation according to a preset generation loss function to obtain a generation loss value (S110); and updating the parameter of the initial generative adversarial neural network according to the discriminant loss value and the generation loss value so as to obtain a target generative adversarial neural network (S112). By means of the method, the training speed and stability of a generative adversarial neural network can be improved.","['G06N3/045', 'G06N3/084', 'Y02T10/40']"
US20220318443A1,Ai-based method for generating building block in commercial district,"The present invention discloses an artificial intelligence (AI)-based method for generating a building block in a commercial district, and relates to the field of AI urban design. According to the present invention, geographic information data of a target district and surrounding districts is acquired to construct a three-dimensional space sand table, then design conditions in various planning files and local legal regulations are translated and extracted to generate a three-dimensional building block of the district, and then a training sample library of three-dimensional contour lines of the district is constructed, a machine learning model is loaded to generate three-dimensional building heights of the district and optimize building forms, to generate a plurality of schemes for the building block of the district, and finally simulated display of the schemes and display of scheme indexes are performed by using a holographic display device, and the schemes are outputted. For the problem that a previous generation of AI technology generates a large quantity of invalid schemes, the present invention realizes the AI-based generation of a plurality of valid schemes, resolving the problem that the previous generation of AI requires a long time and large manpower to screen out a valid scheme, and improving the design efficiency for planners.","['G06F30/13', 'G06N3/088', 'G06F18/214', 'G06F30/27', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06T17/00', 'G06V10/44', 'G06N20/00']"
US11514293B2,Future object trajectory predictions for autonomous machine applications,"In various examples, historical trajectory information of objects in an environment may be tracked by an ego-vehicle and encoded into a state feature. The encoded state features for each of the objects observed by the ego-vehicle may be used—e.g., by a bi-directional long short-term memory (LSTM) network—to encode a spatial feature. The encoded spatial feature and the encoded state feature for an object may be used to predict lateral and/or longitudinal maneuvers for the object, and the combination of this information may be used to determine future locations of the object. The future locations may be used by the ego-vehicle to determine a path through the environment, or may be used by a simulation system to control virtual objects—according to trajectories determined from the future locations—through a simulation environment.","['G06N3/0445', 'G06N3/08', 'G06N3/044', 'B60W40/02', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N5/01']"
US12327298B2,Translation of images of stained biological material,"Techniques and systems for translating images of biological samples stained according to a first staining technique into images representing the biological samples stained according to a second staining technique. In various implementations, the first staining technique can include a histopathological staining technique and the second staining technique can include an immunofluorescence staining technique or an immunohistochemistry staining technique.","['G06T11/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/32', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2210/41']"
US20210133590A1,System and method for machine learning architecture with differential privacy,"Differential private dictionary learning privatizes input data by training an autoencoder to learn a dictionary, the autoencoder including an encoder and a decoder, and weights of channels in a layer in the decoder defining dictionary atoms forming the dictionary; inputting the input data to the trained autoencoder; projecting, using the encoder, the input data on the learned dictionary to generate a sparse representation of the input data, the sparse representation including coefficients for each dictionary atom; adding noise to the sparse representation to generate a noisy sparse representation; and mapping, using the decoder, the noisy sparse representation to a reconstructed differentially private output.","['G06F21/6254', 'G06N3/04', 'G06N3/045', 'G06N3/088', 'G06N3/048', 'G06N3/084']"
US11676023B2,Systems and methods for performing direct conversion of image sensor data to image analytics,"Systems and methods for performing direct conversion of image sensor data to image analytics are provided. One such system for directly processing sensor image data includes a sensor configured to capture an image and generate corresponding image data in a raw Bayer format, and a convolution neural network (CNN) coupled to the sensor and configured to generate image analytics directly from the image data in the raw Bayer format. Systems and methods for training the CNN are provided, and may include a generative model that is configured to convert RGB images into estimated images in the raw Bayer format.","['G06N3/084', 'G06F18/2148', 'G06F18/2155', 'G06F18/24', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06V10/147', 'G06V10/454', 'G06V10/82', 'G06V10/98', 'H04N23/84', 'H04N25/13', 'G06N3/047']"
US12284147B2,Techniques for optimizing the display of videos,"The disclosed embodiments disclose techniques for optimizing the display of videos. During operation, a computing device receives a video stream to be displayed. The computing device determines a preferred orientation for the video stream, determines a present orientation for the computing device, and determines a mismatch between the preferred orientation and the present orientation. The computing device adjusts the video stream while displaying the video stream on the display. As the video stream plays, the computing device detects any rotation of the computing device, and if so, re-adjusts how the video stream is displayed.","['H04L51/10', 'G06F1/1626', 'G06F1/1694', 'G06F3/0346', 'G06F3/04845', 'G06F3/04883', 'G06V10/25', 'G06V20/41', 'H04L12/1822', 'H04L65/60', 'H04L65/61', 'G06F2203/04806', 'G06V10/462', 'G06V40/16']"
US11288507B2,Object detection in image based on stochastic optimization,"An electronic device includes circuitry that determines probability map information for a first image, based on application of a neural network model on the first image. The neural network model is trained to detect one or more objects based on a plurality of images associated with the one or more objects. The probability map information indicates a probability value for each pixel in the first image. A region corresponding to the one or more objects is detected in the first image based on the probability map information. A first set of sub-images is determined from the detected region, based on application of a stochastic optimization function on the probability map information. The one or more objects are detected from a second set of sub-images of the first set of sub-images, based on application of the neural network model on the second set of sub-images.","['G06K9/00624', 'G06N3/08', 'G06K9/3258', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V20/00', 'G06V20/63', 'G06K2209/15', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/126', 'G06N5/01', 'G06V20/625']"
CN113112411B,Face image semantic restoration method based on multi-scale feature fusion,"The invention discloses a facial image semantic restoration method based on multi-scale feature fusion, which comprises the following steps: s1, collecting face images to be processed to form a training set, and performing preprocessing size cutting on the face images of the training set to obtain a face image set to be trained; s2, constructing and generating an countermeasure network model, and using parameters of the pre-training model as initialization parameters of the network; s3, inputting the missing face image set to be trained into a generating network G, and judging whether the generating network restores the face image or not through a judging network D; s4, reacting the discrimination result to a generation network, performing countermeasure training, optimizing network parameters of the generation network and the discrimination network, ending training when the loss function converges, and storing model parameters when the training is finished; s5, inputting the face image to be repaired into the trained generated network model, and finishing the face image repair. The invention can reduce the adverse effect of the network initialization parameters on the network training, so that the network training is stable.","['G06T5/77', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'Y02T10/40']"
US11506776B2,Method and device with improved radar resolution,"A method of increasing a resolution of radar data is provided. The method of training a radar resolution increase model comprises generating a high-resolution training ground truth and a low-resolution training input from original raw radar data based on information corresponding to at least one of dimensions defining the original raw radar data, and training the resolution increase model based on the high-resolution training ground truth and the low-resolution training input. A radar data processing device generates high-resolution output data from low-resolution input data based on a trained resolution increase model.","['G01S13/583', 'G01S13/9047', 'G01S13/89', 'B60W30/08', 'G01S13/931', 'G01S7/352', 'G01S7/417', 'G06T3/4053', 'B60W2420/408', 'G01S7/356']"
US11475223B2,Converting tone of digital content,"Techniques are disclosed for generating an output sentence from an input sentence by replacing an input tone of the input sentence with a target tone. For example, an input sentence is parsed to separate semantic meaning of the input sentence from the tone of the input sentence. The input tone is indicative of one or more characteristics of the input sentence, such as politeness, formality, humor, anger, etc. in the input sentence, and thus, a measure of the input tone is a measure of such characteristics of the input sentence. An output sentence is generated based on the semantic meaning of the input sentence and a target tone, such that the output sentence and the input sentence have similar semantic meaning, and the output sentence has the target tone that is different from the input tone of the input sentence. In an example, a neural network for parsing the input sentence and/or generating the output sentence is trained using non-parallel corpora of training data that includes a plurality of input sentences and corresponding plurality of assigned tones.","['G06F40/30', 'G06F40/205', 'G06F40/253', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06N20/00', 'G06N3/084']"
US20240211645A1,Physics-enhanced data-driven method and device for intelligent structural design of shear wall building,"The present application provides a physics-enhanced data-driven method and device for intelligent structural design of shear wall building, and the method includes: obtaining an architectural design image and a basic design condition text to be processed; inputting the architectural design image and the basic design condition text into a structural design model, and obtaining a structural design image; the structural design model being obtained by performing a structural design image generation capability training and a physical performance optimization training for a physics-enhanced data-driven generative adversarial network; and vectorizing the structural design image and the architectural design image to obtain a structural design result of shear wall building. The physics-enhanced data-driven method and device for intelligent structural design of shear wall building provided by the present application improve the efficiency and the reliability of structural design.","['G06F30/13', 'G06F30/00', 'G06F30/27', 'G06N3/047', 'G06N3/08', 'G06F2119/14']"
US11003947B2,Density based confidence measures of neural networks for reliable predictions,"A system and method for learning and associating reliability and confidence corresponding to a model's predictions by examining the support associated with datapoints in the variable phase space in terms of data coverage, and their impact on the weights distribution. The approach disclosed herein examines the impact of minor perturbations on a small fraction of the training exemplars in the variable phase space on the weights to understand whether the weights remain unperturbed or change significantly.","['G06N3/084', 'G06K9/6226', 'G06F17/18', 'G06F18/214', 'G06F18/2321', 'G06F18/2415', 'G06F18/285', 'G06K9/6227', 'G06K9/6256', 'G06K9/6277', 'G06N20/00', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/0985']"
US20230075309A1,"Electroencephalogram signal classification method and apparatus, device, storage medium and program product","An electroencephalogram (EEG) signal classification method and apparatus, a device, a storage medium, and a program product are provided, and relate to the field of signal processing technologies. The method includes: obtaining a first EEG signal; obtaining time-frequency feature maps of at least two electrode signals in the first EEG signal; performing feature extraction based on the time-frequency feature maps of the at least two electrode signals to obtain a first extracted feature map; performing weighting processing based on an attention mechanism on the first extracted feature map to obtain an attention feature map; and obtaining a motor imagery type of the first EEG signal based on the attention feature map.","['G06F3/015', 'A61B5/374', 'A61B5/372', 'A61B5/7267', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'A61B5/1126', 'A61B5/4064', 'A61B5/7207', 'A61B5/7253', 'A61B5/7257', 'G06F3/01']"
CN114767115B,Fatigue driving visual detection method and system based on facial multimodal deep learning,"The invention discloses a fatigue driving visual detection system based on facial multi-mode deep learning, which comprises a controller, wherein the controller is electrically connected with a camera and a mechanical module and is provided with a data processing module, a data storage module and an alarm module; the controller is connected with a camera in a serial port communication mode, the camera shoots pictures of drivers and transmits the pictures to the controller, a data processing module is used for processing shot image frames, fatigue characteristics of heart rate and facial behaviors in facial videos are extracted, and then the heart rate characteristics, variability characteristics and facial behavior characteristics are fused to carry out fatigue state classification judgment; the facial behavior features comprise eye signal features, mouth signal features and head signal features, the eye signal features, the mouth signal features, the head signal features and the heart rate features are respectively subjected to feature extraction, the extracted feature information is subjected to classification fusion, and the fatigue degree of the facial behavior features is comprehensively judged.","['A61B5/165', 'A61B5/0205', 'A61B5/18', 'A61B5/7264', 'B60W40/08', 'G06F18/253', 'G06N3/044', 'G06N3/08', 'A61B2503/22', 'A61B5/024', 'A61B5/0816', 'B60W2040/0827', 'B60W2040/0872', 'Y02T10/40']"
US10694526B2,Adaptive pursuit learning method to mitigate small-cell interference through directionality,"A learning protocol for distributed antenna state selection in directional cognitive small-cell networks is described. Antenna state selection is formulated as a nonstationary multi-armed bandit problem and an effective solution is provided based on the adaptive pursuit method from reinforcement learning. A cognitive small cell testbed, called WARP-TDMAC, provides a useful software-defined radio package to explore the usefulness of compact, electronically reconfigurable antennas in dense small-cell configurations. A practical implementation of the adaptive pursuit method provides a robust distributed antenna state selection protocol for cognitive small-cell networks. Test results confirm that directionality provides significant advantages over omnidirectional transmission which suffers high throughput reduction and complete link outages at above-average jamming or cross-link interference power.","['G06N20/00', 'H04W72/082', 'H04W72/541', 'G06N7/005', 'G06N7/01', 'H04L43/087', 'H04W16/06', 'H04W72/0446', 'H04W74/04', 'G06N3/123', 'H04B7/0617', 'H04B7/086', 'H04L41/16', 'H04W16/26', 'H04W56/001']"
US10839506B1,Detecting surface flaws using computer vision,"A convolutional neural network may be trained to inspect subjects such as carbon fiber propellers for surface flaws or other damage. The convolutional neural network may be trained using images of damaged and undamaged subjects. The damaged subjects may be damaged authentically during operation or artificially by manual or automated means. Additionally, images of undamaged subjects may be synthetically altered to depict damages, and such images may be used to train the convolutional neural network. Images of damaged and undamaged subjects may be captured for training or inspection purposes by an imaging system having cameras aligned substantially perpendicular to subjects and planar light sources aligned to project light upon the subjects in a manner that minimizes shadows and specular reflections. Once the classifier is trained, patches of an image of a subject may be provided to the classifier, which may predict whether such patches depict damage to the subject.","['G06V10/82', 'G01N21/8803', 'G01N21/8806', 'G01N21/8851', 'G01N21/9515', 'G06K9/4604', 'G06K9/66', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/0004', 'G06T7/0008', 'G06T7/194', 'G06V10/44', 'G06V30/19147', 'G06V30/19173', 'H04N23/56', 'H04N5/2256', 'G01N2021/8472', 'G01N2021/8864', 'G01N2021/887', 'G01N2021/888', 'G01N2021/8883', 'G01N2021/8887', 'G06N3/04', 'G06N7/005', 'G06N7/01', 'G06Q10/20', 'G06T2207/10012', 'G06T2207/20084', 'G06T2207/30164', 'G06V2201/06']"
CN108095716B,Electrocardiosignal detection method based on confidence rule base and deep neural network,"The invention provides an electrocardiosignal detection method based on a confidence rule base and a deep neural network, which comprises the following steps: constructing a deep neural network model according to an input signal, selecting a network loss function, and utilizing the network loss function to drive the deep neural network to train according to input data; extracting artificial features by using expert knowledge according to an input signal; combining the features learned by the artificial feature deep neural network as common input to construct a confidence rule base, optimizing parameters of the confidence rule base by adopting an improved covariance matrix adaptive evolution strategy, and reducing rules in the confidence rule base; and performing decision fusion on the decision outputs of the deep neural network model and the confidence rule base by adopting a fusion method. The method gives full play to the advantages of finding complex patterns from a large amount of data based on modeling of expert experience knowledge and deep network learning, and automatically judges potential diseases possibly existing in a tester according to electrocardiosignals of the tester to obtain more robust and accurate judgment.","['A61B5/318', 'A61B5/316', 'A61B5/349', 'A61B5/7235', 'A61B5/7246', 'A61B5/7267']"
CN115018727B,"A multi-scale image restoration method, storage medium and terminal","The invention discloses a multi-scale image restoration method, a storage medium and a terminal, wherein the method comprises the following steps: acquiring an original real image and a corresponding binary defect mask, and constructing an image dataset to be repaired; constructing a multi-scale polarized self-attention generation countermeasure network, and embedding polarized self-attention mechanism modules on different scales of a generator; training and modeling an countermeasure network model by using an image training set to be repaired; testing the multi-scale polarized self-attention generation countermeasure repair model by adopting an image test set to be repaired; the repair performance of the model is evaluated by the evaluation index. The invention further utilizes image characteristics by adding the multi-scale characteristic fusion method on jump connection, and then shares the image characteristics to a back-layer network of the model, and uses a polarized self-attention mechanism with less compressed dimension operation to reduce loss of characteristic data, improve the repair precision of the model to large-scale information missing images, simplify the structural complexity of the model and improve the performance of image repair.","['G06T5/77', 'G06N3/088', 'G06V10/40', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US11526610B2,Peer-to-peer network for blockchain security,"A method and apparatus utilize a peer-to-peer network of security nodes collectively adhering to a protocol for inter-node communication. The system is comprised a plurality of first security nodes, at least one second security node, and at least one third security node. The plurality of first security nodes receive at least one of pre-trained detection models and rules, monitor at least one of a blockchain and connected devices for malicious behavior based on the received at least one of pre-trained detection models and rules, and report the malicious behavior. The at least one second security node creates and communicates the at least one of pre-trained detection models and rules to the plurality of first security nodes. The at least one third security node is informed by the at least one second security node of the reported malicious behavior.","['H04L41/145', 'G06F21/566', 'G06F16/1824', 'G06F16/1834', 'G06F21/552', 'G06F21/554', 'G06N20/00', 'G06N3/09', 'H04L41/0681', 'H04L43/065', 'H04L63/1408', 'H04L63/1433', 'G06N3/045', 'G06N3/08', 'G06N5/022', 'H04L41/16']"
US9736167B2,Enhanced security and safety in telerobotic systems,Methods and systems for securing remotely-operable devices are provided. A security device can receive a plurality of commands to control a remotely-operable device in a remote environment. At least one command in the plurality of commands can include command data that is related to the remotely-operable device. The security device can receive a plurality of responses to the plurality of commands. The security device can process the plurality of commands and the plurality of responses to determine a signature related to an operator that issued the plurality of commands for the remotely-operable device. The security device can determine an identity of the operator based on the signature. The security device can generate an identity report that includes the identity of the operator.,"['H04L63/102', 'B25J13/006', 'B25J9/1689', 'G06F21/316', 'G06F21/552', 'H04L63/126', 'H04L63/1425', 'H04W12/102', 'G06F21/00', 'H04L29/06', 'H04L9/40']"
CN110728654B,Automatic pipeline detection and classification method based on deep residual error neural network,"The invention discloses a method for automatically detecting and classifying pipelines based on a deep residual error neural network, which comprises the steps of expanding an image through a generating type countermeasure network to form an image set, building the deep residual error neural network containing N residual error modules through a M-layer model before migration learning based on the image set.","['G06T7/0004', 'G06F18/241', 'G06T2207/20081', 'G06T2207/20084']"
US11604965B2,Private deep learning,"A method for training parameters of a student model includes receiving one or more teacher models trained using sensitive data. Each teacher model includes one or more intermediate layers and a prediction layer coupled to the one or more intermediate layers. The method includes receiving, from the one or more teacher models, one or more intermediate layer outputs and one or more prediction layer outputs respectively based on public data. Student model training is performed to train parameters of the student model based on the intermediate layer outputs and prediction layer outputs of the one or more teacher models.","['G06N3/0454', 'G06N3/084', 'G06N3/045', 'G06N3/008', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/09', 'G06N3/096']"
CN107220600B,A kind of Picture Generation Method and generation confrontation network based on deep learning,"The present invention discloses a kind of Picture Generation Method based on deep learning and generates confrontation network, described method includes following steps: (1) establishing picture database: collecting several true pictures and classified to it and marked, every picture has unique corresponding class label k；(2) building generates network G: the vector that random noise signal z and class label k are composed is inputted in generating network G, and using the data of generation as the input for differentiating network D；(3) building differentiates network D: differentiating the loss function of network D by for judging the true and false first-loss function of picture and for judging that other second loss function of picture category forms；(4) training network；(5) it generates the picture needed: random noise signal z and class label k input is passed through in step (4) trained generation network G, obtain the picture of specified classification.Through the invention, picture not only can be generated, but also may specify to the picture classification generated.","['G06V40/172', 'G06F18/214', 'G06F18/29', 'G06V40/174']"
US11282205B2,Structure correcting adversarial network for chest x-rays organ segmentation,"Organ segmentation in chest X-rays using convolutional neural networks is disclosed. One embodiment provides a method to train a convolutional segmentation network with chest X-ray images to generate pixel-level predictions of target classes. Another embodiment will also train a critic network with an input mask, wherein the input mask is one of a segmentation network mask and a ground truth annotation, and outputting a probability that the input mask is the ground truth annotation instead of the prediction by the segmentation network, and to provide the probability output by the critic network to the segmentation network to guide the segmentation network to generate masks more consistent with learned higher-order structures.","['G06T7/11', 'A61B5/7267', 'A61B6/50', 'A61B6/5211', 'G06F18/2431', 'G06F18/285', 'G06K9/6227', 'G06K9/628', 'G06K9/6298', 'G06T7/13', 'G06T7/143', 'G06T7/187', 'G06V10/82', 'G16H50/20', 'G06K2209/051', 'G06T2207/10116', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30061', 'G06V2201/031']"
US20240096014A1,Method and system for creating and simulating a realistic 3d virtual world,"A computer implemented method of creating data for a host vehicle simulation, comprising: in each of a plurality of iterations of a host vehicle simulation using at least one processor for: obtaining from an environment simulation engine a semantic-data dataset representing a plurality of scene objects in a geographical area, each one of the plurality of scene objects comprises at least object location coordinates and a plurality of values of semantically described parameters; creating a 3D visual realistic scene emulating the geographical area according to the dataset; applying at least one noise pattern associated with at least one sensor of a vehicle simulated by the host vehicle simulation engine on the virtual 3D visual realistic scene to create sensory ranging data simulation of the geographical area; converting the sensory ranging data simulation to an enhanced dataset emulating the geographical area, the enhanced dataset comprises a plurality of enhanced scene objects.","['G06T17/05', 'G06N3/08', 'G06N3/045', 'G06N3/047', 'G06T19/003', 'G09B9/04', 'G09B9/048', 'B60W2050/0028', 'G06F30/15', 'G06F30/20', 'G06N20/10', 'G06N7/01', 'G09B9/54']"
WO2022142445A1,"Model training method, and image quality evaluation method and apparatus","A model training method, and an image quality evaluation method and apparatus. The training method comprises: acquiring a real image sample set, wherein the real image sample set comprises a plurality of real image samples (101); performing iterative training on a pre-built generative adversarial network by using the real image sample set, and collecting a plurality of pseudo image sample sets that are respectively generated within a plurality of rounds of iteration by a generative network in the generative adversarial network (102); generating a first training sample library composed of the real image sample set and the plurality of pseudo image sample sets, and automatically categorizing and labeling each first training sample of the first training sample library according to a plurality of preset image quality levels to obtain the first training sample library (103); and training a preset multi-classification network by using the first training sample library so as to obtain an image quality evaluation model (104). By using the foregoing method, only a small number of clear real image samples need to be collected to generate a large number of pseudo image samples of different quality levels, and automatic labeling reduces manual costs while improving the quality of data labeling, so that the image quality evaluation model is trained at a lower cost.","['G06T7/0002', 'G06F18/214', 'G06N3/045', 'G06V40/161', 'G06T2207/30168', 'G06T2207/30201']"
US20230113072A1,"Method, system, and medium for affective music recommendation and composition","A method, system, and medium for affective music recommendation and composition. A listener's current affective state and target affective state are identified, and an audio stream, such as a music playlist, is generated with the intent of effecting a controlled trajectory of the listener's affective state from the current state to the target state. The audio stream is generated by a machine learning system trained using data from the listener and/or other users indicating the effectiveness of specific audio segments, or audio segments having specific features, in effecting the desired affective trajectory. The audio stream is presented to the user as an auditory stimulus. The machine learning system may be updated based on the affective state changes induced in the listener after exposure to the auditory stimulus. Over time, the machine learning system gains a robust understanding of the relationship between music and human affect, and thus the machine learning system may also be used to compose, master, and/or adapt music configured to induce specific affective responses in listeners.","['G10H1/0025', 'A61B5/16', 'A61M21/02', 'G06F16/635', 'G10G1/00', 'G10H1/0008', 'G16H20/70', 'A61M2021/0027', 'A61M21/00', 'A61M2205/3303', 'A61M2205/505', 'G10H2210/111', 'G10H2210/125', 'G10H2220/116', 'G10H2220/371', 'G10H2240/085', 'G10H2240/131', 'G10H2250/311']"
US11157010B1,Method and system for deterministic trajectory selection based on uncertainty estimation for an autonomous agent,A system for deterministic trajectory selection based on uncertainty estimation includes a set of one or more computing systems. A method for deterministic trajectory selection includes receiving a set of inputs; determining a set of outputs; determining uncertainty parameters associated with any or all of the set of inputs and/or any or all of the set of outputs; and evaluating the uncertainty parameters and optionally triggering a process and/or action in response.,"['G05D1/0219', 'B60W60/0011', 'G05D1/0088', 'G05D1/0214', 'G05D1/0221', 'G05D1/227', 'G05D1/617', 'G05D1/648', 'G06F18/2155', 'G06F18/217', 'G06K9/6259', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'B60W2556/20']"
US20200051303A1,Real-time avatars using dynamic textures,A system and method for generating real-time facial animation is disclosed. The system relies upon pre-generating a series of key expression images from a single neutral image using a pre-trained generative adversarial neural network. The key expression images are used to generate a set of FACS expressions and associated textures which may be applied to a three-dimensional model to generate facial animation. The FACS expressions and textures may be provided to a mobile device to enable that mobile device to generate convincing three-dimensional avatars in real-time with convincing animation in a processor non-intensive way through a blending process using the pre-determined FACS expressions and textures.,"['G06T13/40', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T15/04', 'G06T17/20', 'G06T5/003', 'G06T2210/44']"
US12093426B2,"Systems and methods for functionally separating heterogeneous data for analytics, artificial intelligence, and machine learning in global data ecosystems","Systems, program storage devices, and methods for improving data privacy/trust/anonymity/pseudonymity and data value, wherein data related to a Data Subject can be used and stored, while minimizing re-identification risk by unauthorized parties and enabling data related to the Data Subject to be disclosed to an authorized party by granting access only to the data relevant to that authorized party's purpose, time, place, and/or other criterion via the obfuscation of specific data values. The techniques described herein maintain this level of privacy/trust/anonymity/pseudonymity, while empowering Data Subjects, e.g., consumers or customers of such authorized parties, by enabling protection of data at the desired level of engagement with various business entities. The techniques described herein also allow Data Controllers to perform General Data Protection Regulation (GDPR) and Schrems II-compliant (and surveillance-proof) data processing, via the functional separation of heterogeneous data (e.g., via the use of “Variant Twins”) from embedded trust and privacy controls.","['G06F21/6254', 'G16H10/60', 'G16H40/67', 'H04L63/0407', 'H04L63/20', 'H04L9/0891', 'H04L9/16', 'H04L9/3239', 'H04L9/3297', 'H04L9/50', 'G06F2221/2115', 'H04L2209/42', 'H04L2209/56', 'H04L63/0414', 'H04L63/068', 'H04L63/08', 'H04L63/101']"
US20240135259A1,Computer implemented method for generating a 3d object,"There is provided a method for a computer implemented method for generating a 3D object. The method comprises training a machine learning system to learn design parameter values that give rise to an optimally performing version of the 3D object; and processing, using the machine learning system, input data relating to the 3D object, in an unsupervised manner such that it can be used for generative purposes, such as the creation of novel geometries or other parameters of the 3D object.","['G06F30/17', 'G06N20/00', 'G06F30/27', 'G06F30/20']"
US10886008B2,Methods and systems for determining the biological age of samples,"The present disclosure provides systems, media, and methods for applying machine learning to determine the biological age of a sample. A method of using a biological age predictor may comprise: (a) providing data of a sample to the biological age predictor; (b) treating the sample with a substance, thereby generating a treated sample; and (c) providing data of the treated sample to the biological age predictor. The biological age predictor may generate the first biological age and/or the second biological age.","['G06V10/764', 'C12Q1/025', 'G01N33/6848', 'G06T7/0012', 'G06V20/69', 'G16B20/00', 'G16B20/40', 'G16B40/00', 'G16B40/20', 'G01N2500/00', 'G01N2800/7042']"
US12062180B2,"Automated, generation of dental features in digital models","In embodiments, a processing device generates a three-dimensional model of a dental site from scan data, the three-dimensional model comprising a representation of a tooth, wherein a portion of the three-dimensional model comprises an interfering surface that obscures a portion of the tooth. The processing device receives or generates an image of the tooth, wherein the image depicts the interfering surface. The processing device processes the image to generate a modified image, wherein the portion of the tooth that was obscured by the interfering surface in the image is shown in the modified image. The processing device updates the three-dimensional model of the dental site by replacing, using the modified image, the portion of the three-dimensional model that comprises the interfering surface that obscures the portion of the tooth, wherein the portion of the tooth that was obscured in the three-dimensional model is shown in an updated three-dimensional model.","['G06T7/12', 'A61C13/0004', 'A61C13/0019', 'A61C13/34', 'A61C9/0053', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/0012', 'G06T7/143', 'G16H30/40', 'G06N3/044', 'G06N3/045', 'G06T2207/10028', 'G06T2207/10081', 'G06T2207/10101', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036']"
US20240371184A1,Live-cell label-free prediction of single-cell omics profiles by microscopy,"Computer-implemented methods, computer program products, and systems determine an omics profiles of a cell using microscopy imaging data. In one aspect, a computer-implemented method determines an omics profiles of a cell using microscopy imaging data by a) receiving microscopy imaging data of a cell or a population of cells; b) determining a targeted expression profile of a set of target genes from the microscopy imaging data using a first machine learning model, the target genes identifying a cell type or cell state of interest; and c) determining a single-cell omics profile for the population of cells using a second machine learning algorithm model. The targeted expression profile and a reference single-cell RNA-seq data set are used as inputs for the second machine learning model. Computer-implemented methods, computer program products, and systems described herein also provide for determining single-cell omics profile from microscopy, such as Raman microscopy, or expression profiles, such as H&E stains.","['G06V20/698', 'G06N20/20', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06N5/01', 'G06V10/774', 'G06V10/82', 'G16B25/10', 'G16B40/20', 'G16H20/10', 'G16H20/60', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70']"
WO2022041307A1,Method and system for constructing semi-supervised image segmentation framework,"A method for constructing a semi-supervised image segmentation framework, the method comprising: constructing a semi-supervised image segmentation framework which comprises a student model, a teacher model and a discriminator (S1); acquiring a marked MRI image and a corresponding gold standard thereof, so as to calculate a supervised segmentation loss; acquiring an original unmarked MRI image and an unmarked MRI noise image that is obtained after combining the original unmarked MRI image with pre-set Gaussian distribution noise, so as to obtain a corresponding student segmentation probability result graph and a corresponding teacher segmentation probability result graph, then respectively covering the original unmarked MRI image with same, and generating a student segmentation area and a teacher segmentation area and transmitting same together to the discriminator for similarity comparison, so as to calculate a consistency loss; and obtaining the total segmentation loss according to the supervised segmentation loss and the consistency loss, and optimizing the semi-supervised image segmentation framework according to the total segmentation loss (S4). By means of implementing the method, a universal semi-supervised segmentation framework capable of being used for 3D medical images is established by means of improving a mean teacher model, and no additional image-level mark is needed.","['G06T7/11', 'G06N3/045', 'G06N3/08', 'G06T7/136', 'G06T7/143', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
CN113378965B,Multi-label image identification method and system based on DCGAN and GCN,"The present disclosure provides a multi-label recognition algorithm based on DCGAN and GCN, including: constructing a DCGAN model based on the GAN model, and generating a similar image based on the DCGAN model; extracting features based on a transferred CNN algorithm, transferring parameters of a neural network of a DCGAN model to the CNN algorithm to extract features of a multi-label image, and generating a class label classifier by using a GCN algorithm through a relation graph among training labels; and generating a countermeasure network generation data pre-training model through deep convolution, and transferring parameters of a convolution neural network of the pre-training model to a target task to fine tune the network so as to obtain a more accurate image recognition effect. Meanwhile, random noise is added when the image is generated, and therefore robustness of the pre-training model can be improved.","['G06F18/241', 'G06F18/214', 'G06F18/22', 'G06N3/045', 'G06N3/084']"
US10783639B2,System and method for N-dimensional image segmentation using convolutional neural networks,Disclosed are systems and methods for image segmentation using convolutional networks. Image data comprising an image hypervolume can be received. The image hypervolume can be provided to a trained convolutional neural network (CNN). The CNN can output a segmentation of the image hypervolume.,"['G06T7/11', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06T2200/04', 'G06T2207/10072', 'G06T2207/10136', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20124']"
US12347156B2,Neural network model for image segmentation,"A computer processing system is configured to train a model for use in semantic image segmentation. The model comprises a refinement neural network, a discriminator neural network. The refinement neural network is configured to receive a predicted label distribution for an image, obtain one or more random values from a random or pseudo-random noise source, use the one or more random values to generate a plurality of predicted segmentation maps from the received predicted label distribution and output the plurality of predicted segmentation maps to the discriminator neural network. The computer processing system is configured to train the refinement neural network using an objective function that is a function of an output of the discriminator neural network and that further includes a term representative of a difference between the predicted label distribution and an average of the plurality of predicted segmentation maps output by the refinement neural network for the predicted label distribution.","['G06V10/25', 'G06F18/24143', 'G06N3/094', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/56']"
US11334833B2,Determining propensities of entities with regard to behaviors,"Propensities of entities, comprising human users and virtual assistants (VAs), for various behaviors can be determined and used to facilitate managing interactions between entities. An interaction management component (IMC) can determine an aggregate propensity metric relating to a propensity of an entity to engage in a behavior based on a cross-correlation of respective propensity metrics relating to respective propensities of the entity to engage in respective behaviors. During an interaction between entities, including the entity, IMC can determine an action to perform to interact with the entity based on the aggregate propensity metric and a context determined for the interaction. The action can be one that is predicted to elicit a defined action by the entity in response to the action. During (or after) the interaction, IMC can update behavior attributes, context, and/or aggregate propensity metric associated with the entity based on actions performed during the interaction.","['G06Q10/06375', 'G06Q30/0202', 'G06Q30/0281', 'G06Q30/0224', 'G06Q30/0255']"
US11688399B2,Computerized intelligent assistant for conferences,"A method for facilitating a remote conference includes receiving a digital video and a computer-readable audio signal. A face recognition machine is operated to recognize a face of a first conference participant in the digital video, and a speech recognition machine is operated to translate the computer-readable audio signal into a first text. An attribution machine attributes the text to the first conference participant. A second computer-readable audio signal is processed similarly, to obtain a second text attributed to a second conference participant. A transcription machine automatically creates a transcript including the first text attributed to the first conference participant and the second text attributed to the second conference participant.","['H04N7/147', 'G10L15/26', 'G06V40/172', 'G10L17/00', 'H04N7/15', 'H04N7/155']"
US12327356B2,Methods of assessing lung disease in chest X-rays,The present system provides methods and systems of detecting lung abnormalities in chest x-ray images using at least two neural networks.,"['A61B6/50', 'A61B6/5217', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/098', 'G06T3/40', 'G06T7/0012', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N20/10', 'G06N3/044', 'G06N5/01', 'G06N5/025', 'G06N7/01', 'G06T2207/10081', 'G06T2207/10116', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06T2207/30096', 'G06T2207/30168', 'G06V2201/032', 'G16H30/20']"
AU2017203008B2,Unstructured security threat information analysis,"A computer-implemented method including receiving, by an analysis system that includes one or more computers, a plurality of unstructured textual datasets that each include information about a respective potential security threat, determining that a first subset of the plurality of unstructured textual datasets and a second, different subset of the plurality of unstructured textual datasets both include information about a particular threat, the second subset being a different subset than the first subset, discarding the first subset in response to determining that the first subset of the plurality of unstructured textual datasets and the second, different subset of the plurality of unstructured textual datasets both include information about the particular threat, for each respective subset in the plurality of unstructured textual datasets that has not been discarded identifying, by the analysis system, one or more keywords in the respective subset, determining, by the analysis system, one or more text patterns of patterns that correspond with the respective subset using the identified one or more keywords by comparing strings from unstructured data in the respective subset with the patterns to determine whether each string matches, or is similar to, one or more of the patterns, identifying, by the analysis system, one or more intelligence types that correspond with the respective subset using the one or more text patterns, and associating, by the analysis system, for each respective intelligence type of the identified one or more intelligence types, the respective subset from the plurality of unstructured textual datasets with the respective intelligence type, determining a rule for a third party that indicates that the third party should receive data associated with a particular intelligence type of the one or more intelligence types, determining that the second subset of the plurality of unstructured textual datasets is associated with the particular intelligence type, and providing the second subset of the plurality of unstructured textual datasets that is associated with the particular intelligence type to the third party. 10% Security News Gov't Unstructured Advisories Websites Websites Datructured 102a 102b 102c Receive T< unstructured 104 data Determine Keywords Determine Patterns Parse T2 Apply Rules unstructured data 104a Intelligence Type X Intelligence Type Y Data Construct m Data Construct n Create T- Intelligence Type X Intelligence Type Y structured 106a 106b constructs Third Party A Third Party B Paty rulhird T4 Rule 1a Rule lb for security Rule 2a 108a 108b threat --8 -- information Data Construct Data Construct Send security m 106a n 106b threat Te*- information to Third PartyA Third Party B Third Parties","['H04L63/1416', 'G06F16/3344', 'G06F16/338', 'G06F21/55', 'H04L63/14', 'H04L67/10', 'H04L67/53', 'H04L67/02']"
US10496833B2,Controlling secure processing of confidential data in untrusted devices,"A number of transmissions of secure data communicated between a secure trusted device and an unsecure untrusted device in a DBMS is controlled. The data is communicated for database transaction processing in the secure trusted device. The number of transmissions may be controlled by receiving, from the untrusted device, an encrypted key value of a key and a representation of an index of a B-tree structure, decrypting, at the trusted device, the key and one or more encrypted index values, and initiating a transmission, a pointer value that identifies a lookup position in the index for the key. The index comprises secure, encrypted index values. Other optimizations for secure processing are also described, including controlling available computation resources on a secure trusted device in a DBMS and controlling transmissions of secure data that is communicated between a secure trusted device and an unsecure untrusted device in a DBMS.","['G06F21/606', 'G06F16/24552', 'G06F21/62', 'G06F21/6218', 'G06F21/6227', 'G06F21/72', 'G06F21/76', 'H04L63/0428', 'H04L63/061', 'H04L9/0637', 'H04L9/0819', 'H04L9/0822', 'H04L9/088', 'G06F16/2228', 'G06F16/2246', 'H04L2463/062']"
US11783062B2,Risk-based access to computing environment secrets,"Technology for risk-based access to secrets utilizes risk metadata tailored to secrets. Secrets include passwords, security tokens, digital certificates, and other items used for identity authentication, authorization, signing, validation, and other cybersecurity processes. A secret's risk metadata may indicate which controls protect the secret, the deployment scope of the secret or the asset it secures, known exposures of the secret, whether the secret secures other secrets, the impact if the secret is misused, the secret's strength, characteristics of the asset the secret secures, the secret's risk history, and other characteristics of secrets that set them apart. Unlike secrets, typical user-generated digital assets like web pages, documents, image files, and so on have value on their own. An enhanced system distinguishes between secrets and non-secrets when modulating access, making it possible to automatically provide consistent, efficient, and effective risk-based control over access to secrets.","['G06F21/6218', 'G06F21/62', 'G06F21/577', 'G06F21/6209', 'G06F2221/034']"
CN111047629B,"Method, device, electronic device and storage medium for multimodal image registration","The application is applicable to the technical field of pattern recognition, and provides a multi-modal image registration method, which comprises the following steps: acquiring a first image of a source modality and a second image of a target modality paired with the first image; correcting the intensity of the first image to obtain a first corrected image, and matching the intensity of the first corrected image with the intensity distribution of the second image; acquiring a deformation field of the first corrected image registered to a target modality according to the first corrected image and the second image; acquiring a registered image of the first image registered to a target modality according to the first image and the deformation field. The influence caused by the image intensity characteristics is reduced, the accuracy reduction caused by overlarge distance difference between the same object of the first image to be corrected and an ideal registration result can be avoided, and therefore the registration accuracy is improved.",['G06T7/33']
US10646156B1,Adaptive image processing in assisted reproductive imaging modalities,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['A61B5/4325', 'A61B8/5223', 'G06K9/00671', 'G06N20/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06T7/0012', 'G06T7/0016', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G16H10/60', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06T2200/28', 'G06T2207/10024', 'G06T2207/10132', 'G06T2207/10136', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03', 'Y02A90/10']"
CN109871902B,SAR small sample identification method based on super-resolution countermeasure generation cascade network,"The invention belongs to the field of radar data processing, and particularly relates to an SAR small sample identification method based on a super-resolution countermeasure generation cascade network. Aiming at the problems that target features are not obvious, the influence of the environment is large and data samples are easy to be confused due to low resolution of an SAR target image, a super-resolution network based on deep learning is provided to amplify a small sample image of the SAR with low resolution. Allowing the classification network to extract more features. Different from the traditional super-resolution method, the characteristics of the image can be effectively extracted by utilizing the image super-resolution of the GAN, and a non-excessively smooth vivid high-resolution image is generated. The model is a GAN super-resolution model aiming at the characteristics of low resolution, fuzzy characteristics and easy sample confusion of the SAR small sample image and the inherent characteristics of the SAR image. The hyper-resolution model with a 4-time magnification factor can magnify the number of pixels of the original image to 16 times. This may provide the classifier with more content and features.",[]
CN112634163B,Method for removing image motion blur based on improved cyclic generation countermeasure network,"The invention discloses an image motion blurring method based on improved cyclic generation and countering network, which comprises the following steps: step 1, constructing a non-paired fuzzy-clear data set; step 2, constructing a generator network consisting of an encoder, a feature converter and a decoder; step 3, constructing a discriminator network for dividing images by receptive fields; step 4, constructing a joint loss function; step 5, constructing two mirror image annular GAN networks to obtain a circularly generated countermeasure network model; step 6, inputting the motion blurred image to be processed into the trained model in the step 5 to obtain a deblurred image; and 7, performing two-dimensional Fourier transform on the preliminary deblurred image obtained in the step 6, and filtering high-frequency bright spot spectrum information to obtain an accurate clear image. The method does not need to estimate the fuzzy core, has few calculation parameters and high deblurring speed, avoids the problems of mode collapse and gradient disappearance, and solves the problem of false clear error identification of a frequency domain.","['G06T5/73', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06T5/10', 'G06T5/20', 'G06T7/246', 'G06T2207/10004', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20201', 'Y02T10/40']"
US12106848B2,Systems and methods for integrity analysis of clinical data,"Disclosed are implementations that include a method for dental data analysis including obtaining dental data for an individual, with the dental data being input radiographic image data of at least one dental object, and treatment data representative of one or more treatment procedures associated with the dental object, analyzing, by machine learning models, the input radiographic image data to identify one or more dental features associated with the dental object, and deriving, based on the treatment data and the identified one or more dental features, one or more integrity scores for the image data and the treatment data, with the one or more integrity scores being representative of potential integrity problems associated with the input radiographic image data and the treatment data. Deriving the integrity scores includes deriving a provider score representative of a potential integrity problem associated with a dental-care provider submitting the treatment data.","['G16H40/20', 'G06T7/11', 'G06T7/0012', 'G06T7/70', 'G16H10/60', 'G16H20/40', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G06T2207/10124', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30036', 'G06T2207/30052', 'G06T2207/30168']"
US10740985B2,Adjusting a digital representation of a head region,"Methods and devices for generating reference data for adjusting a digital representation of a head region, and methods and devices for adjusting the digital representation of a head region are disclosed. In some arrangements, training data are received. A first machine learning algorithm generates first reference data using the training data. A second machine learning algorithm generates second reference data using the same training data and the first reference data generated by the first machine learning algorithm.","['G06T19/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06T7/337', 'G06N20/10', 'G06N3/047', 'G06N5/01', 'G06T2207/20081', 'G06T2219/2004', 'G06T2219/2012', 'G06T2219/2021']"
US11995883B2,Scene graph generation for unlabeled data,"Approaches are presented for training and using scene graph generators for transfer learning. A scene graph generation technique can decompose a domain gap into individual types of discrepancies, such as may relate to appearance, label, and prediction discrepancies. These discrepancies can be reduced, at least in part, by aligning the corresponding latent and output distributions using one or more gradient reversal layers (GRLs). Label discrepancies can be addressed using self-pseudo-statistics collected from target data. Pseudo statistic-based self-learning and adversarial techniques can be used to manage these discrepancies without the need for costly supervision from a real-world dataset.","['G06V10/82', 'G06F18/10', 'G06F18/24', 'G06F18/29', 'G06V10/764', 'G06V10/84', 'G06V20/00', 'G06V20/70', 'G06V20/56']"
US20250131564A1,Systems and methods for processing electronic images to detect contamination in specimen preparations,"Systems and methods are disclosed for receiving one or more digital images associated with a tissue specimen, detecting one or more image regions from a background of the one or more digital images, determining a prediction, using a machine learning system, of whether at least one first image region of the one or more image regions comprises at least one external contaminant, the machine learning system having been trained using a plurality of training images to predict a presence of external contaminants and/or a location of any external contaminants present in the tissue specimen, and determining, based on the prediction of whether a first image region comprises an external contaminant, whether to process the image region using an processing algorithm.","['G06T7/0012', 'G06T7/11', 'G06T7/194', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V10/993', 'G06V20/69', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06V2201/03']"
NL2029854B1,High end imaging radar,"According to various embodiments, a radar device is described comprising a processor configured to generate a scene comprising an object based on a plurality of receive wireless 5 signals, generate a ground truth object parameter of the object and generate a dataset representative of the scene and a radar detector configured to determine an object parameter of the object using a machine learning algorithm and the dataset, determine an error value of the machine learning algorithm using a cost function, the object parameter, and the ground truth object parameter and adjust the machine learning algorithm values to reduce the error value.","['G01S7/354', 'G01S7/417', 'G01S13/34', 'G01S13/4454', 'G01S13/584', 'G01S13/726', 'G01S13/89', 'G01S13/931', 'G01S7/356', 'G01S7/40', 'H01Q21/06', 'G01S7/415', 'H01Q15/02']"
US11963846B2,Systems and methods for integrity analysis of clinical data,"Disclosed are implementations that include a clinical data analysis method including obtaining dental data that includes input radiographic image data for at least one dental object, and identifying, by machine learning models, a first dental feature in the input radiographic image data for the at least one dental object, and at least one other feature in the dental object comprising at least partly a healthy dental structure. The method additionally includes computing at least one dimensioned property representative of physical dimensions of the first dental feature and the at least one other feature, deriving, based on the computed at least one dimensioned property, a ratio indicative of an extent of a dental clinical condition associated with the identified first dental feature, and determining a treatment plan based on a comparison of the at least one dimensioned property ratio to a respective threshold value.","['A61C7/002', 'A61C9/0053', 'G06T7/0012', 'G06T7/0014', 'G06T7/62', 'G16H20/00', 'G16H20/40', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G06T2207/10116', 'G06T2207/10124', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30036', 'G06T2207/30052', 'G06T2207/30168']"
US11468288B2,Method of and system for evaluating consumption of visual information displayed to a user by analyzing user's eye tracking and bioresponse data,"Method of analyzing eye tracking data for estimating user's cognitive and emotional level of consumption of visual information. A training machine learning model is trained using a data set containing gaze information of known training users, their known cognitive levels and their EEG signal measurements. A calibrating machine learning model is trained using a data set of calibrating visual information displayed to a user, calibrating gaze tracks of that user, calibrating actions data of that user, and calibrating session data related to the session environment. The device displays to that user a target visual information and records target eye tracking data of that user in response to consuming the target information. The recorded target eye tracking data is calibrated via the calibrating machine learning model. The calibrated target eye tracking data is fed into the training machine learning model, which estimates the cognitive levels of consumption of the target visual information of that user.","['G06N3/0445', 'G06N3/044', 'G06F16/2379', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06F3/015', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/01', 'G06F2203/011', 'G06F3/14', 'G06N5/003']"
US20230068727A1,Intraoral scanner real time and post scan visualizations,"Embodiments relate to techniques for real-time and post-scan visualization of intraoral scan data, which may include 3D images, 3D scans, 3D surfaces and/or 3D models. In one embodiment, an intraoral scanning system comprises a plurality of image sensors to periodically generate a set of intraoral two-dimensional (2D) images, wherein for each set of intraoral 2D images each image sensor of the plurality of image sensors is to generate an intraoral 2D image, and wherein relative positions and orientations of the plurality of image sensors are known. The intraoral scanning system further comprises a computing device, wherein the computing device is to perform the following for each set of intraoral 2D images: generate a combined intraoral image based on merging the set of intraoral 2D images together during scanning; and output the combined intraoral image to a display.","['A61C9/0073', 'A61C9/0053', 'A61C9/006', 'G06T17/00', 'G06T17/20', 'G06T3/08', 'G06T3/4038', 'G06T5/002', 'G06T5/50', 'G06T5/70', 'G06T7/0012', 'G06T7/70', 'G06T2200/04', 'G06T2207/10028', 'G06T2207/20221', 'G06T2207/30036', 'G06T2210/41']"
EP4142384A1,"Positioning method, communication device, and network device","This application pertains to the communications field, and discloses a positioning method, a communications device, and a network device. The positioning method includes: receiving first information, where the first information includes at least one of first machine learning model information, first preprocessing model information, and first error model information; and determining, based on the first information, information related to a location of a terminal device.","['H04W64/006', 'H04W64/00', 'G01S5/021', 'H04W64/003', 'G01S5/0018', 'G01S5/0236', 'G06N20/00', 'H04W12/03', 'H04W12/04', 'H04W24/08', 'H04W48/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'H04W88/02']"
US20230281955A1,Systems and methods for generalized scene reconstruction,"Various embodiments of the disclosure are directed to a scene reconstruction and machine learning system. In embodiments, the system comprises a storage medium configured to store image data, one or more scene models, one or more relightable matter fields, and information related to a machine learning model. In one or more embodiments, the system comprises an input circuit configured to receive image data characterizing light in a scene. In embodiments the system includes a processor. In embodiments the processor configured to reconstruct a scene model representing the scene using the image data. In embodiments the processor is configured to extract a relightable matter field from the scene model representing the object, store the scene model and the relightable matter field representing the object in the storage medium, apply the relightable matter field as an input to the machine learning model, and generate an output from the machine learning model.","['G06T7/557', 'G06T15/506', 'G06T17/00', 'G06V10/60', 'G06V10/762', 'G06V10/764', 'G06V10/82', 'G06T2207/10024', 'G06T2207/30156', 'G06T2207/30252', 'G06T2210/61']"
US12125125B2,Method and device for text-based image generation,"A method and device for image generation are provided. The method includes: obtaining a text describing a content of an image to be generated; extracting, using a text encoder, a text feature vector from the text; determining a semantic mask as spatial constraints of the image to be generated; and automatically generating the image using a generative adversarial network (GAN) model according to the semantic mask and the text feature vector.","['G06T11/00', 'G06T11/203', 'G06F18/213', 'G06F40/126', 'G06F40/20', 'G06F40/279', 'G06F40/289', 'G06F40/30', 'G06N3/02', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V10/70', 'G06V10/768', 'G06V10/82', 'H04N21/8153', 'G06N3/044', 'G06T2207/20084']"
CN112220562B,Method and system for enhancing surgical tool control during surgery using computer vision,"The present disclosure relates to systems and methods for improving patient safety during surgical procedures using a computer vision processing system. The computer vision processing system may use machine learning techniques to train the machine learning model. The machine learning techniques may be performed to train the machine learning model to identify, classify, and interpret objects within a live video feed. Certain embodiments of the present disclosure may use a trained machine learning model to control (or facilitate control of) surgical tools during a surgical procedure.","['A61F5/0076', 'A61B1/000094', 'A61B1/000096', 'A61B1/00055', 'A61B1/313', 'A61B17/068', 'A61B17/07207', 'A61B17/320016', 'A61B17/320092', 'A61B34/10', 'G05B19/4155', 'G06F18/21', 'G06F18/217', 'G06N20/00', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06V10/70', 'G06V20/41', 'G16H30/40', 'G16H40/60', 'A61B2017/00017', 'A61B2017/00061', 'A61B2017/00119', 'A61B2017/00128', 'A61B2017/00199', 'A61B2017/00207', 'A61B2017/00212', 'A61B2017/320082', 'A61B2017/320095', 'A61B2034/101', 'A61B2034/107', 'A61B2034/2065', 'A61B2090/064', 'A61B2090/371', 'A61B2090/502', 'A61B90/361', 'A61B90/37', 'G05B2219/36414', 'G06N3/045', 'G06N3/088', 'G06V2201/03', 'G06V2201/034', 'G06V2201/07', 'G06V2201/10']"
US20230407404A1,Methods and compositions for analyzing immune infiltration in cancer stroma to predict clinical outcome,"Provided herein are methods for analyzing immune cell infiltration in a cancer stromal region of a biological sample obtained from a subject using machine learning modules. For example, the methods may include (a) identifying a cancerous region or an analyte associated with the cancerous region in the biological sample; (b) identifying a stromal region or an analyte associated with the stromal region in the biological sample; (c) identifying one or more immune cells or an analyte associated with an immune cell in one or more locations in the biological sample; and (d) using (i) the identified cancerous and stromal regions or associated analytes thereof in the biological sample and (ii) the identified one or more immune cells or associated analytes thereof to analyze immune cell infiltration in the cancer stromal region of the biological sample obtained from the subject.","['C12Q1/6886', 'G16H50/20', 'C12Q2600/118', 'C12Q2600/158', 'Y02A90/10']"
US11977137B2,Systems and methods for magnetic resonance imaging,"A method may include obtaining image data of a subject acquired by an imaging device. The method may also include determining one or more characteristics associated with a body part of the subject from the image data. The one or more characteristics of the body part of the subject may include at least one of position information of the body part in the subject, geometric morphology information of the body part, water content information, or fat content information. The method may also include determining, based on one or more characteristics associated with the body part, values of one or more individualized parameters corresponding to the subject. The method may further include causing the imaging device to perform an imaging scan on the subject according to the values of the one or more individualized parameters.","['G01R33/288', 'G01R33/3875', 'G01R33/4828', 'G01R33/543', 'G01R33/5608', 'G01R33/58', 'G01R33/583']"
US11973772B2,Multistage analysis of emails to identify security threats,"Conventional email filtering services are not suitable for recognizing sophisticated malicious emails, and therefore may allow sophisticated malicious emails to reach inboxes by mistake. Introduced here are threat detection platforms designed to take an integrative approach to detecting security threats. For example, after receiving input indicative of an approval from an individual to access past email received by employees of an enterprise, a threat detection platform can download past emails to build a machine learning (ML) model that understands the norms of communication with internal contacts (e.g., other employees) and/or external contacts (e.g., vendors). By applying the ML model to incoming email, the threat detection platform can identify security threats in real time in a targeted manner.","['H04L63/1416', 'G06F16/951', 'G06F16/9558', 'G06F16/986', 'G06N20/00', 'G06N20/20', 'G06N5/01', 'G06Q10/107', 'H04L51/212', 'H04L63/1433', 'H04L63/1483']"
US12257025B2,AI enabled multisensor connected telehealth system,"This invention presents a multisensor-connected, AI-enabled telehealth system for assisting healthcare providers with differential diagnosis and patients with early health concern detection. The system comprises a multi-sensor medical device with at least seven sensors, a secure cloud-based platform, and an interactive telehealth module. The device preprocesses and securely transmits patient information to the cloud platform, where an ensemble of deep learning models analyzes the data to generate ranked potential diagnoses with likelihood scores. The telehealth module facilitates communication between providers, patients, and the cloud platform, presenting visualizations and receiving feedback. The system continuously updates and fine-tunes its models using incremental learning algorithms, adapting to new data while retaining previous knowledge. It also generates alerts for providers and patients when deviations from normal physiological patterns are detected, accompanied by explainable AI visualizations.","['A61B5/0261', 'A61B5/0022', 'A61B5/1171', 'A61B5/7267', 'A61B5/746', 'G06Q10/04', 'G06Q10/06', 'G06Q10/10', 'G06Q30/018', 'G06Q30/0269', 'G06Q30/0271', 'G06Q50/01', 'G06Q50/22', 'G06Q50/265', 'G06V10/82', 'G06V40/14', 'G06V40/18', 'G06V40/197', 'G16H20/00', 'G16H50/20', 'A61B5/7264', 'G06Q2220/00']"
CN108520199B,Human body action open set identification method based on radar image and generation countermeasure model,"The invention relates to the technical field of radar and the field of human body action recognition, and aims to provide a human body action open set recognition method based on a radar image and a generated countermeasure model, which directly distinguishes the known or unknown action types of an input image and outputs the type information of the input image so as to realize end-to-end open set recognition of human body actions. Therefore, the technical scheme adopted by the invention is that the human body action open set identification method based on the radar image and the generated countermeasure model utilizes the characteristic that the micro Doppler image of the radar can reflect the micro motion of the human body, and simultaneously adopts a discriminator in the generated countermeasure model as an open set identifier to directly distinguish the known or unknown action type of the input image and output the type information of the known or unknown action type so as to realize the end-to-end open set identification of the human body action. The invention is mainly applied to the technical field of radars and human body action recognition occasions.","['G06V40/10', 'G01S13/89', 'G06N3/045']"
EP4229560A1,Explanation and interpretation generation system,"An exemplary embodiment provides an explanation and interpretation generation system for creating explanations in different human and machine-readable formats from an explainable and/or interpretable machine learning model. An extensible explanation architecture may allow for seamless third-party integration. Explanation scaffolding may be implemented for generating domain specific explanations, while interpretation scaffolding may facilitate the generation of domain and scenario specific interpretations. An exemplary explanation filter interpretation model may provide an explanation and interpretation generation system optional filtering and interpretation filtering and briefing capabilities. An embodiment may cluster explanations into concepts to incorporate information such as taxonomies, ontologies, causal models, statistical hypotheses, data quality controls, domain specific knowledge and allow for collaborative human knowledge injection. An embodiment may include a flexible presentation layer, user model and a goal-plan-action system to enable practical and useful actionable explanations to be generated.","['G06N5/045', 'G06F16/284', 'G06F17/18', 'G06N3/042', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/098', 'G06N3/0985', 'G16H50/20', 'G06N3/045', 'G06N5/041', 'G06N5/046', 'G06N5/048']"
US20230054446A1,"Systems and methods for functionally separating geospatial information for lawful and trustworthy analytics, artificial intelligence and machine learning","Various systems, computer-readable media, and computer-implemented methods of providing improved data privacy, anonymity and security by enabling subjects to which data pertains to remain “dynamically anonymous,” i.e., anonymous for as long as is desired—and to the extent that is desired—are disclosed herein. Embodiments include systems that create, access, use, store and/or erase data with increased privacy, anonymity, and security—thereby facilitating the availability of more qualified and accurate information. When personal data is authorized by data subjects to be shared with third parties, embodiments described herein may facilitate the sharing of information in a dynamically-controlled manner that also enables the delivery of temporally-, geographically-, and/or purpose-limited information to the receiving party. In one example, the disclosed techniques may be used to functionally separate geospatial information, such that it remains “dynamically anonymous,” i.e., anonymous for as long as is desired—and to the extent or degree that is desired.","['G06F21/6254', 'G16H10/60', 'G16H40/67', 'H04L63/0407', 'H04L63/20', 'H04L9/0891', 'H04L9/0894', 'H04L9/16', 'H04L9/3239', 'H04L9/3297', 'H04L9/50', 'H04W12/02', 'H04W12/75', 'G06F2221/2115', 'H04L2209/42', 'H04L2209/56', 'H04L63/0414', 'H04L63/068', 'H04L63/08', 'H04L63/101']"
US10944996B2,Visual quality optimized video compression,Techniques related to providing high perceptual quality video from highly compressed and decompressed reconstructed video are discussed. Such techniques include applying a pretrained decompression upsampling portion of a generative adversarial network to the decompressed reconstructed video to upsample and improve the perceptual quality of the decompressed reconstructed video to generate output video.,"['H04N19/86', 'H04N19/154', 'G06T3/4046', 'H04N19/117', 'H04N19/132', 'H04N19/17', 'H04N19/172', 'H04N19/176', 'H04N19/184', 'H04N19/30', 'H04N19/59', 'H04N19/80']"
US20230335289A1,Systems and methods for generating health risk assessments,"Provided herein are systems and methods for assessing health risk for a user from a combination of Artificial Intelligence, ECG data available from the user's smart watch or other smart device, and other biometric data and/or medical data provided from the user.","['G16H50/30', 'A61B5/0006', 'A61B5/349', 'A61B5/7267', 'A61B5/7275', 'G16H10/60', 'G16H40/67', 'G16H50/20', 'A61B5/352', 'A61B5/36', 'A61B5/361', 'A61B5/363', 'A61B5/364', 'G16H50/70', 'G16H80/00']"
US12127814B2,Dental diagnostics hub,"A method includes receiving intraoral scan data of an intraoral cavity of a patient; processing the intraoral scan data to determine, for each dental condition of a plurality of dental conditions, whether the dental condition is detected for the patient and a severity of the dental condition; and presenting indications of the plurality of dental conditions together in a graphical user interface (GUI), wherein the indications show, for each dental condition of the plurality of dental conditions, whether the dental condition was detected for the patient and the severity of the dental condition.","['A61B5/0088', 'A61B1/0004', 'A61B5/0035', 'A61B5/0062', 'A61B5/1079', 'A61B5/4547', 'A61B5/4552', 'A61B5/4842', 'A61B5/7267', 'A61B5/742', 'A61B5/743', 'A61B5/7475', 'A61B6/512', 'A61C9/0053', 'G16H20/00', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'A61B1/24', 'A61B5/1032', 'A61B5/1077', 'A61B6/12', 'A61B6/51', 'A61B6/5217', 'A61C19/04', 'A61C7/002']"
US20220157138A1,Facility surveillance systems and methods,"Systems and methods for surveillance of a facility including facility elements. The system includes a central computing unit providing a digital model of the facility providing topological or logical or functional relationships of the facility elements, surveillance sensors adapted for surveillance of a plurality of the facility elements and for generation of surveillance data, communication means for transmitting data from the surveillance sensors to the central computing unit, and state derivation means configured to analyse the surveillance data and derive a state of a respective facility element. The central computing unit is configured to record a state pattern by combining states of at least one facility element based on at least one relationship of the facility element provided by the facility model, provide a state pattern critical-noncritical classification model which considers relationships provided by the facility model, and perform a criticality-classification based on the relationship.","['G08B13/19613', 'G05D1/0094', 'G06F18/2431', 'G06K9/628', 'G06N3/02', 'G06V20/35', 'G06V20/52', 'G08B13/19647', 'G08B13/1965', 'G08B13/1968', 'G08B13/19682', 'G08B29/188', 'G08B29/186']"
US12106552B2,Method and system for digital staining of label-free phase images using deep learning,"A deep learning-based digital staining method and system are disclosed that provides a label-free approach to create a virtually-stained microscopic images from quantitative phase images (QPI) of label-free samples. The methods bypass the standard histochemical staining process, saving time and cost. This method is based on deep learning, and uses a convolutional neural network trained using a generative adversarial network model to transform QPI images of an unlabeled sample into an image that is equivalent to the brightfield image of the chemically stained-version of the same sample. This label-free digital staining method eliminates cumbersome and costly histochemical staining procedures, and would significantly simplify tissue preparation in pathology and histology fields.","['G06V10/82', 'G02B21/14', 'G06F18/2148', 'G06F18/2155', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V10/764', 'G06V20/693', 'G06V20/698']"
US12344897B2,Urinary microbiomic profiling,"Methods and systems for identifying and/or treating urinary disorders are provided. The methods and systems generally operate by obtaining a urine sample from a subject, identifying (such as by using nucleic acid sequencing) an abundance of a first set of one or more microbes (such as one or more bacteria or viruses) in the urine sample, and determining whether the subject suffers from a urinary disorder based on the abundance of the first set of one or more microbes. In some cases, the methods and systems further operate by identifying a second set of microbes to supplement a microbiome in the urinary tract of the subject. In some instances, the methods and systems further operate by treating the urinary disorder using the second set of microbes. In some instances a preservation solution is utilized.","['A61K31/16', 'A61K31/357', 'A61K31/43', 'A61K31/7036', 'A61K31/7048', 'A61K35/741', 'A61K35/742', 'A61K35/744', 'A61K35/747', 'A61K45/06', 'C12Q1/04', 'C12Q1/6806', 'C12Q1/6869', 'C12Q1/689', 'G01N33/57488', 'G16B40/30', 'G16B50/30', 'C12Q1/6883', 'G01N2800/34', 'G01N2800/348']"
CN110647765B,Privacy protection method and system based on knowledge migration under collaborative learning framework,"The disclosure provides a privacy protection method and system based on knowledge migration under a collaborative learning framework, which includes: dividing a local privacy data set into a plurality of mutually disjoint privacy subsets, and training a corresponding privacy model based on each privacy subset; and (3) collaborative learning: submitting the public data to a privacy model, wherein the privacy model uses an aggregation mechanism and utilizes knowledge to migrate to a public data set label; after enough marked data are obtained, the local interaction model is trained, part of parameters are uploaded to the server in each round of training, the server updates and maintains global parameters and provides the latest parameters for all parties to download, and the participants download the latest parameters to optimize the local interaction model. The method can ensure that multiple parameter interactions of simultaneous collaborative learning can still keep higher accuracy after multiple rounds of training even if the interaction model obtains less labeled data.",['G06F21/6245']
US12293155B2,Out-of-domain data augmentation for natural language processing,"A method includes receiving a training set of utterances for training a machine-learning model to identify one or more intents for one or more utterances, and augmenting the training set of utterances with out-of-domain (OOD) examples. The augmenting includes: generating a data set of OOD examples, filtering out OOD examples from the data set of OOD examples, determining a difficulty value for each OOD example remaining within the filtered data set of the OOD examples, and generating augmented batches of utterances including utterances from the training set of utterances and utterances from the filtered data set of the OOD based on the difficulty value for each OOD. Thereafter, the machine-learning model is trained using the augmented batches of utterances in accordance with a curriculum training protocol.","['G06F40/289', 'G06F40/242', 'G06F40/284', 'G06F40/295', 'G06F40/30', 'G06N20/00', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'H04L51/02']"
TWI805784B,A method for enhancing quality of media,"A method for enhancing quality of media uses an AI enhancing model built-in the client device to enhance the quality of video streams. The AI enhance module is pre-trained by using a neural network in the server to analyze differences between the decoded images and the raw images that are generated by the server. Wherein, the AI enhance module enhances decoded images by using algorithms which are defined by analyzing differences between the decoded images and the raw images that are generated by the server. Such that, the enhanced images are visually more similar to the raw images than the decoded images do.","['H04L41/16', 'G06T9/002', 'A63F13/355', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T15/005', 'H04L41/145', 'H04L65/70', 'H04L65/75', 'H04L65/752', 'H04L65/765', 'H04L65/80', 'H04L67/01', 'H04L67/10', 'H04L67/125', 'H04L67/131', 'A63F2300/407', 'A63F2300/538', 'G06N3/048']"
US11367268B2,Cross-domain image processing for object re-identification,"Object re-identification refers to a process by which images that contain an object of interest are retrieved from a set of images captured using disparate cameras or in disparate environments. Object re-identification has many useful applications, particularly as it is applied to people (e.g. person tracking). Current re-identification processes rely on convolutional neural networks (CNNs) that learn re-identification for a particular object class from labeled training data specific to a certain domain (e.g. environment), but that do not apply well in other domains. The present disclosure provides cross-domain disentanglement of id-related and id-unrelated factors. In particular, the disentanglement is performed using a labeled image set and an unlabeled image set, respectively captured from different domains but for a same object class. The identification-related features may then be used to train a neural network to perform re-identification of objects in that object class from images captured from the second domain.","['G06V10/34', 'G06N3/088', 'G06F18/214', 'G06F18/2155', 'G06F18/217', 'G06K9/6256', 'G06K9/6259', 'G06K9/6262', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/40', 'G06V10/82', 'G06V20/46', 'G06V30/19173', 'G06V30/274', 'G06N3/048', 'G06V10/62']"
CN111598761B,Anti-printing shooting image digital watermarking method based on image noise reduction,"According to the image noise reduction-based anti-printing shooting image digital watermarking method, an image noise reduction layer which can resist noise attack possibly existing in the printing shooting process of an image is constructed by adopting a generated countermeasure network, so that the simultaneous attack of various noises can be resisted, a better noise reduction effect is realized, and the image has high fidelity; and the image noise reduction layer is added into the whole watermark embedding and extracting training frame, the image noise reduction layer realizes the function of resisting noise attack, ensures the robustness to a certain extent, and enables the watermark codec to be more focused on improving the visual effect after watermark embedding, the detection accuracy and the embedding capacity of the watermark, thereby realizing the balance of three indexes of the robustness, the visual effect and the embedding capacity.","['G06T1/005', 'G06N3/045', 'G06N3/084', 'G06T5/70']"
US11849196B2,Automatic data extraction and conversion of video/images/sound information from a slide presentation into an editable notetaking resource with optional overlay of the presenter,"A method and system to automatically convert a presentation with slide materials to a digitized notetaking resource, by inputting a media stream from a presentation to a compute server, converting the media stream by segmenting the video into smaller segments, transcribing audio of the presenter's speech into text. Time stamp metadata is associated to elements of the segmented video (and, if available, slide data), audio, and transcribed text, and the elements are time ordered. A user interface is provided displaying elements of the segmented video/slide data and transcribed text. The user interface enables playback of the elements of the segmented video/slide data, audio of the presenter's speech, and transcribed text, wherein playback items are time-matched. Different times can be selected by a user, wherein the selected elements are made prominent in the display, with the audio of the presenter's speech also being time-matched to the selection.","['H04N21/23418', 'H04N21/854', 'G06F3/0425', 'G06F3/048', 'G06F3/04883', 'G06F40/169', 'G10L15/26', 'H04N21/233', 'H04N21/234336', 'H04N21/8456']"
US12017142B2,System and method for real-time calibration of virtual apparel using stateful neural network inferences and interactive body measurements,"An Augmented Reality (AR) and Artificial Intelligence (AI) based interactive virtual try-on solution that facilitates trying on, fitting, and modularizing a virtual apparel in real-time—as if a consumer were wearing the apparel. A user with a mobile device defines retail adjustment operations on the virtual apparel using an AR-based visual interface. The user can interact with the virtual apparel for identifying, defining, and changing the look, fit, and design of the apparel on the user's body. The real-time interaction is with the same virtual apparel. The system defines operations based on user's features, sartorial measurements, intent, gestures, position, pressure values received from a controller operated by the user, and the sensed motion of the user to translate into a set of machine learning inference models that predict a series of states that visually generate the outcome the user anticipates based on the user's interaction with the virtual clothing.","['G06Q30/0643', 'A63F13/53', 'A63F13/31', 'G06F3/011', 'G06F3/016', 'G06F3/017', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/094', 'G06Q30/0621', 'G06Q30/0623', 'G06T17/20', 'G06T19/006', 'G06T2210/16']"
US9628272B2,PUF authentication and key-exchange by substring matching,"Mechanisms for operating a prover device and a verifier device so that the verifier device can verify the authenticity of the prover device. The prover device generates a data string by: (a) submitting a challenge to a physical unclonable function (PUF) to obtain a response string, (b) selecting a substring from the response string, (c) injecting the selected substring into the data string, and (d) injecting random bits into bit positions of the data string not assigned to the selected substring. The verifier: (e) generates an estimated response string by evaluating a computational model of the PUF based on the challenge; (f) performs a search process to identify the selected substring within the data string using the estimated response string; and (g) determines whether the prover device is authentic based on a measure of similarity between the identified substring and a corresponding substring of the estimated response string.","['H04L9/0866', 'G09C1/00', 'H04L9/3271', 'H04L9/3278', 'H04L2209/24']"
CN110992354B,Anomaly region detection method based on introducing automatic memory mechanism against autoencoder,"The invention belongs to the technical field of image processing, and particularly discloses an abnormal region detection method for an anti-self-encoder based on an introduced automatic memory mechanism. The method comprises the following steps: in a training set and a test set of industrial field image division, the training set only contains OK samples, and the test set contains OK and NG samples; designing a confrontation self-encoder model with an automatic memory mechanism; training by using a training set, evaluating by using a test set, and obtaining an optimal model; and constructing a statistical model of the abnormal values of the training set samples to obtain a discrimination threshold value for discriminating OK/NG. Inputting the sample to be detected into the trained network model, reconstructing by the generator to obtain a reconstruction image, obtaining an abnormal value, judging as OK if the value is smaller than the judgment threshold value, otherwise judging as NG, and inputting the input image and the reconstruction image into the comparison module to obtain the position of the abnormal area. The invention only uses the OK sample as the training set, can judge OK/NG and locate the position of an abnormal area, and has higher NG sample recall rate and higher detection speed.","['G06T7/0006', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
WO2021018228A1,Detection of adverserial attacks on graphs and graph subsets,"Method and system for detecting potentially perturbed nodes in a graph that comprises potentially perturbed nodes and clean nodes, comprising: calculating, for each of a plurality of nodes of the graph, a discrepancy value in resp1ect of the node, wherein the discrepancy value for each node indicates a statistical discrepancy for classification probabilities associated with the node and classification probabilities associated with neighbouring nodes; fitting a statistical distribution for the discrepancy values for the clean nodes; determining a detection threshold for potentially perturbed nodes based on the statistical distribution; and identifying nodes having a discrepancy value greater than the detection threshold as potentially perturbed nodes.","['G06F21/55', 'G06F21/554', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06F2221/034']"
US11475246B2,System and method for generating training data for computer vision systems based on image segmentation,"A system and method for training a model using a training dataset. The training dataset can be made up of only real data, only synthetic data, or any combination of synthetic data and real data. The images are segmented to define objects with known labels. The object is pasted onto backgrounds to generated synthetic datasets. The various aspects of the invention include generation of data that is used to supplement or augment real data. Labels or attributes can be automatically added to the data as it is generated. The data can be generated using seed data. The data can be generated using synthetic data. The data can be generated from any source, including the user's thoughts or memory. Using the training dataset, various domain adaptation models can be trained.","['G06K9/6257', 'G06N3/08', 'G06F18/214', 'G06F18/2148', 'G06F18/217', 'G06F18/2185', 'G06K9/6256', 'G06K9/6262', 'G06K9/6264', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06T7/11', 'G06V10/764', 'G06V10/7788', 'G06V10/82']"
US11922550B1,Systems and methods for hierarchical text-conditional image generation,"Disclosed herein are methods, systems, and computer-readable media for generating an image corresponding to a text input. In an embodiment, operations may include accessing a text description and inputting the text description into a text encoder. The operations may include receiving, from the text encoder, a text embedding, and inputting at least one of the text description or the text embedding into a first sub-model configured to generate, based on at least one of the text description or the text embedding, a corresponding image embedding. The operations may include inputting at least one of the text description or the corresponding image embedding, generated by the first sub-model, into a second sub-model configured to generate, based on at least one of the text description or the corresponding image embedding, an output image. The operations may include making the output image, generated by the first second sub-model, accessible to a device.","['G06T11/60', 'G06F40/284', 'G06F40/30', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T11/001', 'G06T9/002']"
US20240045966A1,Anomaly detection in real-time multi-threaded processes on embedded systems and devices using hardware performance counters and/or stack traces,"An aspect of behavior of an embedded system may be determined by (a) determining a baseline behavior of the embedded system from a sequence of patterns in real-time digital measurements extracted from the embedded system; (b) extracting, while the embedded system is operating, real-time digital measurements from the embedded system; (c) extracting features from the real-time digital measurements extracted from the embedded system while the embedded system was operating; and (d) determining the aspect of the behavior of the embedded system by analyzing the extracted features with respect to features of the baseline behavior determined.","['G06F21/57', 'G06F11/006', 'G06F11/0721', 'G06F11/3013', 'G06F11/302', 'G06F11/3419', 'G06F11/3452', 'G06F11/3466', 'G06F11/3612', 'G06F18/214', 'G06F21/52', 'G06F21/71', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/084', 'G06N7/01', 'G06F11/3636', 'G06F2201/86', 'G06F2201/865', 'G06F2221/2129']"
US20200294630A1,Systems and Methods for Determining Molecular Structures with Molecular-Orbital-Based Features,"Systems and methods for determining molecular structures based on molecular-orbital-based (MOB) features are described. MOB features can be utilized in combination with machine-learning methods to predict accurate properties, such as quantum mechanical energy, of molecular systems.","['G16C20/50', 'G06F18/213', 'G06F18/24', 'G06K9/6232', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'G16C10/00', 'G16C20/10', 'G16C20/70', 'G16C20/30', 'G16C20/90']"
US11960568B2,Model and method for multi-source domain adaptation by aligning partial features,"A multi-source domain adaptation model by aligning partial features includes a general feature extraction module, a feature selection module for partial feature extraction with the dedicated loss function, three partial feature alignment losses, and two classifiers for adversarial training, where the three partial feature alignment losses include an intra-class partial feature alignment loss, an inter-domain partial feature alignment loss, and an inter-class partial feature alignment loss. With the partial features extracted by the general feature extraction module and the feature selection module following three different partial feature alignment losses, the model is capable of clustering the samples from the identical categories and isolating samples from distinct classes.","['G06F18/214', 'G06F18/2415', 'G06F18/213', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N3/094', 'G06N3/096', 'G06V10/454', 'G06V10/771', 'G06V10/7715', 'G06V10/774']"
US20230245651A1,Enabling user-centered and contextually relevant interaction,An approach is disclosed for enabling contextually relevant conversational interaction. Environment data is received by an AI System which detects a plurality of physical objects in a physical environment and forms a contextual understanding of the plurality of physical objects and the physical environment and identifies a user relevant to the contextual understanding. A most relevant contextual information to the user is predicted by the AI system and transformed into a textual form. A set of intents and objectives is predicted by the AI system for user-centered interaction. The AI system and the user interact iteratively through the user-centered interaction to determine an understanding of a most relevant intent and a most relevant objective which is validated by the AI system with the user until the user agrees. The validated most relevant intent and the most relevant objective is utilized to facilitate the user-centered and contextually relevant conversational interaction.,"['G06N5/022', 'G06F3/011', 'G06F3/167', 'G06F40/30', 'G10L13/027', 'G10L15/1815', 'G10L15/22', 'G06F2203/011', 'G06F40/35', 'G06N10/60', 'G06N20/10', 'G06N3/045', 'G10L2015/223', 'G10L2015/226', 'G10L25/63']"
WO2021150017A1,Method for interactive segmenting an object on an image and electronic computing device implementing the same,"The present invention relates generally to the fields of computer vision and computer graphics using neural networks, machine learning for interactive segmentation of objects on images, in particular, to a method for interactive segmenting an object on an image and electronic computing device implementing the method. The method comprises: inputting (S101) the image and user inputs, wherein each user input indicates either the object or a background on the image and is defined by coordinates; converting (S102) each user input into a distance map and a tensor representation including coordinates and an indication that the user input indicates either the object or the background; fusing (S103), by a trained artificial intelligence tool, the distance maps with the image into an intermediate representation; extracting (S104), by the trained artificial intelligence tool, features of the image from the intermediate representation; adjusting (S105), by the trained artificial intelligence tool, a scale to 1 and a bias to 0; rescaling (S106), by the trained artificial intelligence tool, the extracted features by using adjusted scale and adjusted bias; predicting (S107), by the trained artificial intelligence tool, a segmentation mask segmenting the object on the image by predicting that the rescaled features belong to the object or the background based on the intermediate representation; estimating (S108), by the trained artificial intelligence tool, whether a discrepancy between predicted segmentation mask and the tensor representation meet a minimum threshold value set by a user in advance; and adjusting (S109), by the trained artificial intelligence tool, the scale and the bias using an iterative optimization procedure to minimize the discrepancy between the predicted segmentation mask and the tensor representation; wherein the steps (S106) to (S109) are repeated until, on the step (S107), the segmentation mask is predicted so that the discrepancy between the predicted segmentation mask and the tensor representation meet the minimum threshold value or a number of repetitions reaches a maximum number set by the user in advance.","['G06T7/11', 'G06F18/24133', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06T7/194', 'G06V10/235', 'G06V10/454', 'G06V10/82', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20041', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20132']"
US12343874B2,Reinforcement and imitation learning for a task,"A neural network control system for controlling an agent to perform a task in a real-world environment, operates based on both image data and proprioceptive data describing the configuration of the agent. The training of the control system includes both imitation learning, using datasets generated from previous performances of the task, and reinforcement learning, based on rewards calculated from control data output by the control system.","['B25J9/163', 'B25J9/161', 'B25J9/1697', 'G06N3/008', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/098']"
US11961197B1,"XR health platform, system and method","A computer-based extended reality health system is adapted for electronically rendering patient sessions within an XR environment incorporating immersive scenes. The XR health system utilizes an XR device adapted for being employed by a patient to visually display the immersive scenes during a patient session within the XR environment. An input device is adapted for electronically interacting with objects, content and features visually displayed in the immersive scenes. A billing module is configured to extract claims data applicable for medical billing claims. The claims data includes billing information associated with the immersive scenes visually rendered to the patient during the patient session within the XR environment.","['G06T19/006', 'G16H40/67', 'G16H10/20', 'G16H10/60', 'G16H15/00', 'G16H20/00', 'G16H20/10', 'G16H20/30', 'G16H20/60', 'G16H20/70', 'G16H40/63', 'G16H50/20', 'G16H80/00', 'G16H10/40', 'G16H30/20', 'G16H30/40']"
US10296761B2,"Database privacy protection devices, methods, and systems","A system for reducing the information content of a data stream according to privacy requirements that vary according to referents of the data while maximizing the utility of the data stream in the aggregate. In embodiments, a receiver of data characterizing multiple referents extracts information such as statistics. A filter may reduce the information content of the data to reduce the probability that the receiver could uniquely identify any single referent from the data, according to privacy requirements that vary by the referent. The filter allows this to be done in a way that allows the utility of the data to be maximized when the permitted probability of identification varies among the referents.","['G06F21/6245', 'G06F16/9535', 'G06F21/6254']"
CN111784602B,Method for generating countermeasure network for image restoration,"The invention discloses an image restoration model PRGAN, which consists of two mutually independent generation confrontation network modules. The image restoration network module PConv-GAN is formed by combining partial convolution and a countermeasure network and is used for restoring irregular masks, and meanwhile, the whole texture structure and the color of the image are closer to the original image according to the feedback of the discriminator. In order to solve the problems of local chromatic aberration and slight boundary artifacts of the image caused by the defect of repairing the network module, the invention designs an image optimization network module. The image optimization network module Res-GAN combines the depth residual error network with the countermeasure network, and trains the image optimization network module by combining the countermeasure loss, the perception loss and the content loss, so that the information of the non-missing area in the image is reserved, the consistency of the texture structure of the image in the non-missing area is maintained, and the purposes of eliminating the local chromatic aberration and solving the false boundary are achieved.","['G06T5/00', 'G06N3/045', 'G06N3/08', 'G06T5/94', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US11983632B2,Generating and utilizing pruned neural networks,"The disclosure describes one or more implementations of a neural network architecture pruning system that automatically and progressively prunes neural networks. For instance, the neural network architecture pruning system can automatically reduce the size of an untrained or previously-trained neural network without reducing the accuracy of the neural network. For example, the neural network architecture pruning system jointly trains portions of a neural network while progressively pruning redundant subsets of the neural network at each training iteration. In many instances, the neural network architecture pruning system increases the accuracy of the neural network by progressively removing excess or redundant portions (e.g., channels or layers) of the neural network. Further, by removing portions of a neural network, the neural network architecture pruning system can increase the efficiency of the neural network.","['G06N3/045', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/044', 'G06N3/047', 'G06N3/084']"
US12255915B2,"Programmatic discovery, retrieval, and analysis of communications to identify abnormal communication activity","Conventional email filtering services are not suitable for recognizing sophisticated malicious emails, and therefore may allow sophisticated malicious emails to reach inboxes by mistake. Introduced here are threat detection platforms designed to take an integrative approach to detecting security threats. For example, after receiving input indicative of an approval from an individual to access past email received by employees of an enterprise, a threat detection platform can download past emails to build a machine learning (ML) model that understands the norms of communication with internal contacts (e.g., other employees) and/or external contacts (e.g., vendors). By applying the ML model to incoming email, the threat detection platform can identify security threats in real time in a targeted manner.","['H04L63/1441', 'G06F16/353', 'G06F16/9017', 'G06Q10/107', 'H04L41/16', 'H04L51/212', 'H04L63/0236', 'H04L63/1425', 'H04L63/20']"
US20240371081A1,Neural Radiance Field Generative Modeling of Object Classes from Single Two-Dimensional Views,"Systems and methods for learning spaces of three-dimensional shape and appearance from datasets of single-view images can be utilized for generating view renderings of a variety of different objects and/or scenes. The systems and methods can be able to learn effectively from unstructured. “in-the-wild” data, without incurring the high cost of a full-image discriminator, and while avoiding problems such as mode-dropping that are inherent to adversarial methods.","['G06T15/08', 'G06T15/20', 'G06T17/00', 'G06T7/596', 'G06V10/774', 'G06V40/168', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11941721B2,Using watermark information and weight information to train an embedded neural network model,"A method and an apparatus for embedding watermark information are disclosed in the present disclosure. The method trains an embedded neural network model using weight information of a target neural network model and target watermark information that is to be embedded into the target neural network model, updates the weight information of the target neural network model according to target watermark embedded data provided by the embedded neural network model, and obtains a target neural network model embedded with the target watermark information. Since the embedded neural network model includes multiple neural network layers, this method increases the complexity of the watermark embedding process, and is able to avoid the problem that watermark information of existing neural network models has poor robustness to watermarking attacks such as overwriting attacks and model compression.","['G06T1/0028', 'G06F21/16', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/094', 'G06T1/005', 'G06T2201/0065', 'G06T2207/20084', 'G06T2207/20221', 'G06T5/50']"
US9998445B2,Authentication system,"A device authentication system for use with an authenticatable device having a physically-unclonable function and constructed to, in response to input, of challenge C, internally generate an output O characteristic to the PUF and the challenge C, and configured to: i) upon receiving challenge C, generate a corresponding commitment value that depends upon a private value r, and ii) upon receiving an authentication query that includes the challenge C and a nonce, return a zero knowledge proof authentication value that corresponds to the commitment value. The system comprises an enrollment server having a working verification set that includes challenge C and corresponding commitment value, wherein: a) the enrollment server is configured to generate an authentication token that corresponds to the authentication value and includes a blinded value depending upon the private value r and a random value decryptable by the authenticatable device; and/or b) the system is configured to pre-process and convey data to the authenticatable device as part of an extended Boyko-Peinado-Venkatesan generation.","['H04L9/3221', 'H04L63/0807', 'G09C1/00', 'H04L63/061', 'H04L63/0853', 'H04L63/123', 'H04L9/3278', 'H04L2209/12', 'H04L2209/34']"
US11900663B2,Computer-assisted or autonomous driving traffic sign recognition method and apparatus,"Apparatuses, methods and storage medium associated with traffic sign recognition, are disclosed herein. In some embodiments, an apparatus includes an orchestrator, disposed in a CA/AD vehicle, to receive a classification and a location of a traffic sign, while the CA/AD vehicle is enroute to a destination. In response, the orchestrator query a remote sign locator service or a local database on the CA/AD vehicle for a reference description of the traffic sign, determine whether the classification is correct, and output a result of the determination. The classification of the traffic sign is generated based at least in part on computer vision, and the orchestrator includes an anomaly detector to detect anomalies between the classification and the reference description, and determine whether the classification is correct based at least in part on an amount of anomalies detected. Other embodiments are also described and claimed.","['G06V10/82', 'G05D1/0088', 'G05D1/228', 'G06F16/532', 'G06F18/24143', 'G06V10/764', 'G06V20/582', 'G06V20/584', 'G07C5/0808', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
US20220206434A1,System and method for deep learning-based color holographic microscopy,A method for performing color image reconstruction of a single super-resolved holographic sample image includes obtaining a plurality of sub-pixel shifted lower resolution hologram images of the sample using an image sensor by simultaneous illumination at multiple color channels. Super-resolved hologram intensity images for each color channel are digitally generated based on the lower resolution hologram images. The super-resolved hologram intensity images for each color channel are back propagated to an object plane with image processing software to generate a real and imaginary input images of the sample for each color channel. A trained deep neural network is provided and is executed by image processing software using one or more processors of a computing device and configured to receive the real input image and the imaginary input image of the sample for each color channel and generate a color output image of the sample.,"['G03H1/0808', 'G03H1/0866', 'G03H1/2645', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G03H1/0443', 'G03H2001/005', 'G03H2001/0447', 'G03H2001/266', 'G03H2210/11', 'G03H2210/12', 'G03H2210/13', 'G03H2222/13', 'G03H2222/18', 'G03H2222/34', 'G03H2227/03', 'G03H2240/56', 'G03H2240/62', 'G06N3/048']"
EP4205046A1,"Behavior modeling, verification, and autonomous actions and triggers of ml and ai systems","An exemplary embodiment may present a behavior modeling architecture that is intended to assist in handling, modelling, predicting and verifying the behavior of machine learning models to assure the safety of such systems meets the required specifications and adapt such architecture according to the execution sequences of the behavioral model. An embodiment may enable conditions in a behavioral model to be integrated in the execution sequence of behavioral modeling in order to monitor the probability likelihoods of certain paths in a system. An embodiment allows for real-time monitoring during training and prediction of machine learning models. Conditions may also be utilized to trigger system-knowledge injection in a white-box model in order to maintain the behavior of a system within defined boundaries. An embodiment further enables additional formal verification constraints to be set on the output or internal parts of white-box models.","['G06N3/08', 'G06F18/214', 'G06F18/2163', 'G06F18/217', 'G06N20/00', 'G06N3/006', 'G06N3/042', 'G06N3/045', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/098', 'G06N7/01']"
US11966670B2,Method and system for predicting wildfire hazard and spread at multiple time scales,"Apparatuses, methods, and systems for generating gridded predictions of a probability of wildfire spread for geographies are disclosed. One method includes sensing observational climate and earth surface data, obtaining historical data on wildfire spread events, obtaining gridded climate data, creating a set of input features, creating a gridded wildfire data set, training a model that learns one or more probabilistic mapping function emulators between the set of input features and the gridded wildfire data set, which predicts a first probability of wildfire occurrence and a rate and extent of wildfire spread within a geographical region and at a specified period of time, and generating gridded wildfire prediction data including a second probability of wildfire occurrence and spread within the geographical region, using the model and a new set of input features over the geographical region but for a different time period.","['G06F30/20', 'G06F18/2113', 'G06F18/214', 'G06F18/2415', 'G06F30/27', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06V10/25', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/13', 'G06F2111/10', 'G06N3/044', 'G06N3/047', 'G06N3/086']"
WO2022072507A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to generate one or more images based, at least in part, upon speech input received from one or more users.","['G06T1/0007', 'G10L15/22', 'G06F40/30', 'G06N3/045', 'G06T11/001', 'G06T7/194', 'G10L15/16', 'G10L15/26', 'G06N3/08', 'G06T2207/20221']"
US10665011B1,Dynamically estimating lighting parameters for positions within augmented-reality scenes based on global and local features,"This disclosure relates to methods, non-transitory computer readable media, and systems that use a local-lighting-estimation-neural network to render a virtual object in a digital scene by using a local-lighting-estimation-neural network to analyze both global and local features of the digital scene and generate location-specific-lighting parameters for a designated position within the digital scene. For example, the disclosed systems extract and combine such global and local features from a digital scene using global network layers and local network layers of the local-lighting-estimation-neural network. In certain implementations, the disclosed systems can generate location-specific-lighting parameters using a neural-network architecture that combines global and local feature vectors to spatially vary lighting for different positions within a digital scene.","['G06T15/50', 'G06T15/80', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T15/005', 'G06T19/006', 'G06N3/048', 'G06T2215/16']"
US20220198245A1,Neuromorphic algorithm for rapid online learning and signal restoration,"A computer-implemented method of training a neural network to recognize sensory patterns includes obtaining input data, preprocessing the input data in one or more preprocessors of the neural network, and applying the preprocessed input data to a core portion of the neural network. The core portion of the neural network includes a plurality of principal neurons and a plurality of interneurons, and is configured to implement a feedback loop from the interneurons to the principal neurons that supports persistent unsupervised differentiation of multiple learned sensory patterns over time. The method further includes obtaining an output from the core portion, and performing at least one automated action based at least in part on the output obtained from the core portion. The neural network may be adaptively expanded to facilitate the persistent unsupervised differentiation of multiple learned sensory patterns over time by incorporating additional interneurons into at least the core portion.","['G06N3/049', 'G06N3/088', 'G06N3/044', 'G06N3/0445', 'G06N3/063']"
US20220114698A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to adjust one or more aspect ratios of one or more objects of one or more images based, at least in part, on input from one or more users.","['G06T3/04', 'G06T3/4046', 'G06T7/11', 'G06T2200/24', 'G06T2207/20084']"
CN110310221B,Multi-domain image style migration method based on generation countermeasure network,"The invention provides a multi-domain image style migration method based on a generation countermeasure network, belongs to the field of computer vision, and is used for realizing the conversion of an image into a plurality of different artistic styles. The invention designs an expert style network, and extracts style characteristic codes containing unique information of respective domains from input images of different target domains through a group of bidirectional reconstruction losses. Meanwhile, a migration network is designed, and by combining with self-adaptive instance standardization, extracted style feature codes and cross-domain shared semantic contents extracted by a content encoder are recombined to generate a new image, so that style migration of the image from a source domain to a plurality of target domains is realized. Experiments show that the model can effectively combine the content of any photo with the styles of a plurality of artworks to generate a new image.","['G06N3/045', 'G06N3/08', 'G06T3/04']"
US12112514B2,"Device for generating prediction image on basis of generator including concentration layer, and control method therefor","According to certain embodiments, an electronic apparatus comprises: a memory storing a generator previously trained to generate a prediction image based on one or more input images; and a processor configured to: acquire feature data from a plurality of image frames input through at least one layer included in the generator, extract feature data corresponding to change over time from the feature data acquired through an attention layer included in the generator, and acquire a prediction image frame by inputting the extracted feature data to at least one other layer included in the generator.","['G06V10/40', 'H04N5/145', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T9/002', 'G06V10/75', 'G06V10/774', 'G06V10/82']"
WO2020186914A1,"Person re-identification method and apparatus, and storage medium","Disclosed is a person re-identification method. The method comprises: acquiring an image to be identified in a target field of vision scene, wherein the image to be identified comprises an object to be identified (11); and carrying out, on the basis of a trained neural network for person re-identification, feature extraction and matching on the image to be identified to obtain an identification result corresponding to the object to be identified, wherein a training sample of the neural network comprises a target domain image obtained after a source domain image in another field of vision scene is shifted to the target field of vision scene, and the category of an object included in the target domain image (12).","['G06V40/10', 'G06F18/214', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084']"
WO2022116977A1,"Action driving method and apparatus for target object, and device, storage medium, and computer program product","An action driving method and apparatus for a target object, and a device, a storage medium, and a computer program product, which relate to the technical field of artificial intelligence. The method comprises: obtaining a source voice, and obtaining a target video, the target video comprising a target object; performing face parameter conversion processing on a voice parameter of the source voice at each moment to obtain a source parameter of the source voice at the corresponding moment; performing parameter extraction processing on the target video to obtain a target parameter of the target video; performing, according to a combination parameter obtained by combining the source parameter and the target parameter, image reconstruction processing on the target object in the target video to obtain a reconstructed image; and generating a synthetic video by means of the reconstructed image, wherein the synthetic video comprises the target object, and an action of the target object corresponds to the source voice.","['G06V40/171', 'G06T15/00', 'H04N21/43072', 'G06F40/205', 'G06N3/044', 'G06N3/045', 'G06V10/82', 'G06V40/176', 'G10L15/02', 'G10L15/063', 'G10L15/16', 'G10L15/25', 'H04N19/132', 'H04N21/2187', 'H04N21/23412', 'H04N21/234336', 'H04N21/2368', 'H04N21/251', 'H04N21/8146', 'H04N7/157']"
US20210224607A1,"Method and apparatus for neutral network training, method and apparatus for image generation, and storage medium","Provided are a method and apparatus for neutral network training and a method and apparatus for image generation. The method includes that: a first random vector is input to a generator to obtain a first generated image; the first generated image and a first real image are input to a discriminator to obtain a first discriminated distribution and a second discriminated distribution; a first network loss of the discriminator is determined based on the first discriminated distribution, the second discriminated distribution, a first target distribution and a second target distribution; a second network loss of the generator is determined based on the first discriminated distribution and the second discriminated distribution; and adversarial training is performed on the generator and the discriminator based on the first network loss and the second network loss.","['G06N3/084', 'G06N3/08', 'G06K9/6262', 'G06F18/2148', 'G06F18/217', 'G06F18/23', 'G06K9/6257', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N7/01', 'G06T7/0002', 'G06T9/002', 'G06V10/762', 'G06V10/7747', 'G06V10/776', 'G06V10/82', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
US11593660B2,Subset conditioning using variational autoencoder with a learnable tensor train induced prior,"The proposed model is a Variational Autoencoder having a learnable prior that is parametrized with a Tensor Train (VAE-TTLP). The VAE-TTLP can be used to generate new objects, such as molecules, that have specific properties and that can have specific biological activity (when a molecule). The VAE-TTLP can be trained in a way with the Tensor Train so that the provided data may omit one or more properties of the object, and still result in an object with a desired property.","['G06N3/006', 'G06F18/2137', 'G06F18/217', 'G06K9/6251', 'G06K9/6262', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06V10/82', 'G06V20/69', 'G06N20/00', 'G06N3/044', 'G06N3/082', 'G06N7/01', 'G06V30/10', 'G16B40/00', 'G16C20/30', 'G16C20/70']"
US11151734B2,Method and system for generating synthetic point cloud data using a generative model,"Methods and systems for generating synthetic point cloud data are described. Projected 2D data grid is generated by projecting a 3D point cloud into a 2D grid, with rotation equivariance. A generative model is learned using the projected 2D data grid, wherein the generative model is implemented using flex-convolution and transpose flex convolution operations, for example in a generative adversarial network. The learned generative model is used to generate synthetic point clouds.","['G06T7/50', 'G06T7/521', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US20210374499A1,Iterative deep graph learning for graph neural networks,"An initial noisy graph topology is obtained and an initial adjacency matrix is generated by a similarity learning component using similarity learning and a similarity metric function. An updated adjacency matrix with node embeddings is produced from the initial adjacency matrix using a graph neural network (GNN). The node embeddings are fed back to revise the similarity learning component. The generating, producing, and feeding back operations are repeated for a plurality of iterations.","['G06V10/82', 'G06N3/0445', 'G06F16/9024', 'G06F17/16', 'G06F18/21375', 'G06F18/22', 'G06F18/23213', 'G06K9/6215', 'G06K9/6223', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06V10/7715']"
US20200185055A1,Methods and Systems for Nucleic Acid Variant Detection and Analysis,"Disclosed herein are methods, systems, and devices for detection of nucleotide variants. In some aspects, the methods, systems, and devices of the present disclosure can be used to detect germline variant or somatic variant in a biological sample, e.g., a sample from a tumor tissue. In other aspects, the methods, systems, and devices of the present disclosure can be used to detect somatic variant in cell-free nucleic acids from a biological sample, such as blood, plasma, serum, saliva, or urine. In some aspects, the methods, systems, and devices of the present disclosure make use of neural networks, such as convolutional neural networks for variant detection.","['G16B40/20', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G16B20/20', 'G16B30/10', 'C12Q1/6869', 'G06N3/047']"
WO2023044979A1,Mechanical fault intelligent diagnosis method under class unbalanced dataset,"A mechanical fault intelligent diagnosis method under a class unbalanced dataset, comprising: step (1), data preprocessing: converting a mechanical vibration signal into a frequency domain, and normalizing an amplitude to a range of [0,1]; step (2), model building: combining an autoencoder and a generative adversarial network to build a data generation model; step (3), model training: using fault data to train the data generation model according to a preset loss function and an optimization algorithm; step (4), data generation: using fault data low-dimensional features learned by the data generation model in training to generate fault data of a corresponding class after multiple interpolations and noise additions, and realizing balance of various classes of data; and step (5), fault diagnosis: using a class balanced dataset to train a preset fault diagnosis model, and using the trained fault diagnosis model to perform intelligent diagnosis on mechanical faults. The mechanical fault diagnosis is realized by combining the autoencoder and the generative adversarial network.","['G06N3/045', 'G06F18/2411', 'G06F18/2414', 'G06F18/24147', 'G06F18/2415', 'G06F18/24323', 'G06N3/047', 'G06N3/048', 'G06N3/084', 'Y02T90/00']"
US20220180199A1,"Neural network model compression method and apparatus, storage medium, and chip","This application provides a neural network model compression method in the field of artificial intelligence. The method includes: obtaining, by a server, a first neural network model and training data of the first neural network that are uploaded by user equipment; obtaining a PU classifier based on the training data of the first neural network and unlabeled data stored in the server; selecting, by using the PU classifier, extended data from the unlabeled data stored in the server, where the extended data has a property and distribution similar to a property and distribution of the training data of the first neural network model; and training a second neural network model by using a knowledge distillation (KD) method based on the extended data, where the first neural network model is used as a teacher network model and the second neural network model is used as a student network model.","['G06N3/084', 'G06N3/063', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454', 'G06V10/82', 'G06F18/214', 'G06F18/2415', 'G06K9/6256', 'G06N3/047']"
CN113221641B,Video person re-identification method based on generative adversarial network and attention mechanism,"The invention discloses a video pedestrian re-recognition method based on a generated countermeasure network and an attention mechanism, which comprises the steps of utilizing the existing disclosed video pedestrian re-recognition data set to realize video frame prediction and pedestrian identity calibration based on the generated countermeasure network, and increasing effective training samples; secondly, feature extraction is carried out on each frame of image and a corresponding optical flow diagram by using a pre-trained ResNet50 model, then the dependency relationship of the features in each pedestrian image sequence is captured through a gating circulation unit (GRU), an attention mechanism is introduced, and the feature representation of the whole image sequence is extracted; and finally, constructing a pedestrian re-identification model by using a twin network, and performing contrast learning by using two output characteristics of the model. According to the technical scheme, in the non-overlapping monitoring system, the problems of insufficient model training samples, illumination change, pedestrian shielding and the like caused by short time under the monitoring camera of the pedestrian can be effectively solved, and the accuracy of pedestrian re-identification can be obviously improved.","['G06F18/214', 'G06N3/045', 'G06T3/4007', 'G06V20/46', 'G06V20/53', 'Y02T10/40']"
US12045925B2,Computing images of head mounted display wearer,"In various examples there is an apparatus for computing an image depicting a face of a wearer of a head mounted display (HMD), as if the wearer was not wearing the HMD. An input image depicts a partial view of the wearer's face captured from at least one face facing capture device in the HMD. A machine learning apparatus is available which has been trained to compute expression parameters from the input image. A 3D face model that has expressions parameters is accessible as well as a photorealiser being a machine learning model trained to map images rendered from the 3D face model to photorealistic images. The apparatus computes expression parameter values from the image using the machine learning apparatus. The apparatus drives the 3D face model with the expression parameter values to produce a 3D model of the face of the wearer and then renders the 3D model from a specified viewpoint to compute a rendered image. The rendered image is upgraded to a photorealistic image using the photorealiser.","['G06T15/04', 'G06F18/2148', 'G06T13/40', 'G06T15/205', 'G06T17/00', 'G06T17/205', 'G06V20/653', 'G06V40/176']"
US11503054B2,Systems and methods for identifying access anomalies using network graphs,"In some instances, the disclosure provides a method for identifying access anomalies using network graphs. The method comprises obtaining access data for an entity, generating a network graph baseline profile based on the plurality of data elements, generating a network graph current profile based on the plurality of data elements, generating comparison data based on comparing the plurality of baseline network graphs with the one or more current network graphs and comparing the plurality of baseline nodes and the plurality of baseline edges with the plurality of current nodes and the plurality of current edges, determining, based on the comparison data, anomaly data comprising one or more flagged network accesses to the enterprise system, and providing the anomaly data indicating the flagged network accesses to an authentication system.","['H04L63/1425', 'G06F18/214', 'G06F18/29', 'G06K9/6256', 'G06N20/00', 'G06N3/09', 'G06N3/094', 'H04L41/069', 'H04L41/12', 'H04L41/142', 'H04L41/22', 'H04L63/08', 'H04L63/102', 'H04L63/1416', 'G06N3/08', 'H04L41/145']"
US20220390964A1,Cloud & hybrid-cloud flight vehicle & robotic control system ai & ml enabled cloud-based software & data system method for the optimization and distribution of flight control & robotic system solutions and capabilities,"A robotic vehicle management system for the control, optimization and distribution of robotic vehicles is presented in which vehicle operational data is recorded and used to model and optimize a vehicle's travel path. A process for receiving data from multiple vehicles is disclosed, wherein the recorded data is used in the optimization of control systems with regards to travel path, fuel savings, safety, and other considerations. The recorded data may be used to improve system operations or operations of individual vehicles. Methods and techniques are also provided for reading data from vehicle sensors, applying analysis techniques to this data, and uploading improved operational processes to one or more vehicles or to a fleet of vehicles. Adaptive controls, learning based controls, navigation system and other capabilities may be included for optimization and distribution by this discloses system and methods.","['G05D1/104', 'G01C21/20', 'B64C39/024', 'G01C21/005', 'G05D1/0016', 'G05D1/0027', 'G05D1/101', 'G05D1/46', 'B64C2201/146', 'B64U2101/30', 'B64U2201/00', 'B64U2201/20', 'G05D2109/20']"
US10931467B2,Authentication system and device including physical unclonable function and threshold cryptography,"A device comprising: a physical unclonable function (PUF) device configured to generate an output value based on hardware characteristics of the PUF device; and a processor connected to the PUF device, the processor configured to: execute a cryptographic operation in a sequence of ordered stages including a first stage and a second stage, the executing comprising: in the first stage: recovering a first secret value based on a first output value obtained from the PUF device; executing a first sub-operation using the first secret value; and removing unobscured values from memory prior to execution of a subsequent stage; in the second stage: recovering a second secret value based on a second output value obtained from the PUF device; and executing a second sub-operation using the second secret value to enable execution of a cryptographic operation encoded with at least the first secret value and the second secret value.","['H04L9/3278', 'H04L9/085', 'H04L9/3026', 'H04L9/3066', 'H04L9/3221']"
US20230412360A1,Distributed platform for computation and trusted validation,"An example operation may include one or more of obtaining data of a simulation, identifying checkpoints within the simulation data, generating a plurality of sequential data structures based on the identified checkpoints, where each data structure identifies an evolving state of the simulation with respect to a previous data structure among the sequential data structures, and transmitting the generated sequential data structures to nodes of a blockchain network for inclusion in one or more data blocks within a hash-linked chain of data blocks.","['G06F21/64', 'H04L9/0637', 'G06F21/57', 'G06F30/20', 'H04L41/145', 'H04L63/12', 'H04L67/104', 'H04L9/0643', 'H04L9/3236', 'G06N20/00', 'H04L9/50']"
US11521016B2,Method and apparatus for generating information assessment model,"Embodiments of the present disclosure provide a method for generating an information assessment model, a method for determining the usefulness of comment information, apparatus, electronic device, and computer-readable medium. The method may include: acquiring training samples, the training samples including first sample comment information with a usefulness label and second sample comment information without a usefulness label; acquiring a predictor model and a discriminator model respectively constructed based on a generative network and a discrimination network in a generative adversarial network, and pre-training the predictor model using the first sample comment information, the predictor model being used to predict a usefulness label of a piece of comment information, the discriminator model being used to discriminate authenticity of a usefulness label; and training the predictor model and the discriminator model by iteratively performing a plurality of times of training operations, using the trained predictor model as an information assessment model.","['G06F16/355', 'G06N3/08', 'G06K9/6259', 'G06F18/211', 'G06F18/2155', 'G06K9/6228', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'Y02P90/30']"
US11658988B2,Dynamic physical watermarking for attack detection in cyber-physical systems,"A cyber-physical system may have a plurality of system nodes including a plurality of monitoring nodes each generating a series of current monitoring node values over time that represent current operation of the cyber-physical system. According to some embodiments, a watermarking computer platform may randomly inject a watermarking signal into an injection subset of the system nodes. The watermarking computer platform may then receive current monitoring node values over time and generate a current watermarking feature vector based on the current monitoring node values. The watermarking computer platform might comprise a dedicated watermarking abnormality detection platform or a unified abnormality detection platform (e.g., that also uses data-drive feature vectors). The injection subset may be associated with a randomly selected subset of the system nodes and/or magnitudes of watermarking signals that are randomly selected.","['H04L63/1416', 'H04L63/123', 'H04L63/1425', 'H04L63/145', 'H04L63/1466', 'H04L63/30', 'H04L43/04']"
US20230181121A1,Systems and methods to predict and manage post-surgical recovery,"The present invention relates to systems and methods to manage and predict post-surgical recovery. More specifically, the disclosure generally relates to systems and methods for post-surgical intervention planning, support, follow-up, patient compliance, recovery prediction and tracking, and potential treatment modifications.","['A61B5/7275', 'A61B5/02', 'A61B5/0205', 'A61B5/265', 'A61B5/726', 'A61B5/7267', 'A61B7/00', 'G16H10/20', 'G16H40/20', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H80/00', 'A61B2505/05', 'A61B2562/0285', 'A61B5/086', 'A61B5/1118', 'A61B5/318', 'A61B5/4561', 'G16H10/60']"
GB2599224A,Object image completion,"One or more neural networks for generating complete depictions of objects based on their partial description are disclosed. An image 114 of a whole object is generated, based on an image 106 of a portion of the object, using an encoder 108 trained using training data 102 produced from the output of a decoder 112. The neural network may comprise a generative model framework, which can be a variational autoencoder, a generative adversarial network (GAN) or a normalising flow. The decoder can be trained on a dataset comprising images of complete objects and excluding images of partial entities. The decoder may output a complete version of an incomplete picture input into the decoder. The decoder parameters may remain unvaried while training the encoder (Fig. 6). Two images may be entered into the encoder, with the resulting output being the first image which is partially occluded by features from the second picture. An associated training technique is also described.","['G06F18/214', 'G06T5/77', 'G06T9/002', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06T5/60', 'G06T7/11', 'G06V10/26', 'G06V10/82', 'G06V20/58', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US11730387B2,Method for detection and diagnosis of lung and pancreatic cancers from imaging scans,"A method of detecting and diagnosing cancers characterized by the presence of at least one nodule/neoplasm from an imaging scan is presented. To detect nodules in an imaging scan, a 3D CNN using a single feed forward pass of a single network is used. After detection, risk stratification is performed using a supervised or an unsupervised deep learning method to assist in characterizing the detected nodule/neoplasm as benign or malignant. The supervised learning method relies on a 3D CNN used with transfer learning and a graph regularized sparse MTL to determine malignancy. The unsupervised learning method uses clustering to generate labels after which label proportions are used with a novel algorithm to classify malignancy. The method assists radiologists in improving detection rates of lung nodules to facilitate early detection and minimizing errors in diagnosis.","['A61B5/055', 'A61B5/7267', 'A61B6/032', 'A61B6/037', 'A61B6/12', 'A61B6/4417', 'A61B6/5217', 'A61B8/481', 'A61B8/5223', 'G06F18/2148', 'G06F18/23', 'G06F18/2411', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06T7/0012', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H70/60', 'A61B8/085', 'G06T2207/10081', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30064', 'G06T2207/30096', 'G06V2201/03', 'G06V2201/032']"
CN107158708B,Multi-player video game match optimization,"Embodiments of the systems presented herein may identify users to be included in a matching plan. A parametric model may be generated to predict retention times for a group of users. A potential user queue, a set of teammates, and/or opponents may be selected from the waiting user queue. User information for the team friend and/or opponent can be provided to the parametric model to generate a predicted retention time. The team friend and/or opponent may be approved if the predicted retention time meets a predetermined threshold. Advantageously, by creating a matching plan based on retention rates, the level of participation and/or retention of multiple users may be increased over existing multi-player matching systems.","['A63F13/73', 'A63F13/795', 'A63F13/79', 'A63F13/48', 'A63F13/822', 'A63F13/75', 'A63F2300/5566']"
US11989634B2,Private federated learning with protection against reconstruction,"Embodiments described herein provide for a non-transitory machine-readable medium storing instructions to cause one or more processors to perform operations comprising receiving a machine learning model from a server at a client device, training the machine learning model using local data at the client device, generating an update for the machine learning model, the update including a weight vector that represents a difference between the received machine learning model and the trained machine learning model, privatizing the update for the machine learning model, and transmitting the privatized update for the machine learning model to the server.","['G06N3/08', 'G06N20/20', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/063', 'G06N3/09', 'G06N3/098', 'G06N5/04', 'G06N3/044', 'G06N3/045', 'G06N7/01']"
US11720994B2,High-resolution portrait stylization frameworks using a hierarchical variational encoder,"Systems and method directed to an inversion-consistent transfer learning framework for generating portrait stylization using only limited exemplars. In examples, an input image is received and encoded using a variational autoencoder to generate a latent vector. The latent vector may be provided to a generative adversarial network (GAN) generator to generate a stylized image. In examples, the variational autoencoder is trained using a plurality of images while keeping the weights of a pre-trained GAN generator fixed, where the pre-trained GAN generator acts as a decoder for the encoder. In other examples, a multi-path attribute aware generator is trained using a plurality of exemplar images and learning transfer using the pre-trained GAN generator.","['G06T3/0012', 'G06N3/088', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06N3/096', 'G06T11/00', 'G06T3/0006', 'G06T3/02', 'G06T3/04', 'G06T5/00', 'G06V10/774', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US20200249936A1,Method and system for a platform for api based user supplied algorithm deployment,"A system for deploying user supplied algorithms that inserts the user supplied algorithms and creates application program interfaces within client or server devices. The user supplied algorithm is analyzed and software dependencies are determined along with computation that influences the systems decision to deploy the algorithm for inference on the device or in a cloud server device. Server type selection is determined based on analyst of the user supplied algorithm by the system and the user supplied algorithm is deployed in a selectable efficient manner. Using the user supplied algorithm, a sample a sample set of software is generated from analyst and deployment through an application program interface. The sample set of software can be used by the user to demonstrate the algorithm function in technologies like TOT devices, Smartphone apps or websites.","['G06F8/656', 'H04L67/34', 'G06F8/30', 'G06F8/433', 'G06F8/60']"
US20230090743A1,Anomaly detection based on an autoencoder and clustering,"An anomaly detection method of objects in a digital image is provided, wherein the image of the object is encoded and decoded by an autoencoder, then a pixel-wise difference is calculated between the input image of the object, and the reconstructed image of the object. Pixels whose pixel-wise difference is above a threshold are considered as dissimilar pixels, and the presence of clusters of dissimilar pixels is tested. A cluster of dissimilar pixel is considered as representing an anomaly.","['G06T7/0002', 'G06T7/0004', 'G06F18/22', 'G06F18/2453', 'G06T7/0008', 'G06T7/10', 'G06T9/00', 'G06V10/26', 'G06V10/454', 'G06V10/761', 'G06V10/762', 'G06V10/763', 'G06V10/764', 'G06V10/776', 'G06V10/7788', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G06V2201/06']"
AU2021201661B2,Systems and methods for determining path confidence for unmanned vehicles,"SYSTEMS AND METHODS FOR DETERMINING PATH CONFIDENCE FOR UNMANNED VEHICLES ABSTRACT Examples implementations relate to determining path confidence for a vehicle. An example method includes receiving a request for a vehicle to navigate a target location. The method further includes determining a navigation path for the vehicle to traverse a first segment of the target location based on a plurality of prior navigation paths previously determined for traversal of segments similar to the first segment of the target location. The method also includes determining a confidence level associated with the navigation path. Based on the determined confidence level, the method additionally includes selecting a navigation mode for the vehicle from a plurality ofnavigation modes corresponding to a plurality of levels of remote assistance. The method further includes causing the vehicle to traverse the first segment of the target location using a level of remote assistance corresponding to the selected navigation mode for the vehicle.","['G06V20/588', 'G05D1/0027', 'B60K31/0008', 'B60W50/082', 'B60W60/001', 'B60W60/0011', 'B62D1/28', 'B62D1/283', 'B62D15/025', 'G01C21/20', 'G01C21/3446', 'G01C21/3484', 'G05D1/00', 'G05D1/0088', 'G05D1/0221', 'G05D1/0242', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/82', 'B60W2420/403', 'B60W2556/45', 'B60W2556/65', 'G08G1/165', 'G08G1/166']"
CN110598554B,Multi-person posture estimation method based on counterstudy,"The invention discloses a multi-person posture estimation method based on antagonistic learning, which comprises the following steps of: using a public data set with a multi-person key point coordinate label as a training set, and carrying out edge information enhancement pretreatment on an image of the training set; preprocessing the coordinate labels of the key points in the training set to manufacture a corresponding key point hot spot diagram and an integral framework hot spot diagram; constructing a double-branch key point feature extraction sub-network; constructing an A-HPose network generator part; constructing an A-HPose network discriminator part; carrying out relay supervision cycle training on the A-HPose network by using a training set to obtain network model parameters; and performing post-processing on the network output hotspot graph, searching and classifying the key points in the key point hotspot graph according to the skeleton hotspot graph to obtain the key point positions of each of multiple persons, and estimating the postures of the multiple persons. The method has the beneficial effect of quickly and accurately detecting the key point characteristics of the human body.","['G06F18/214', 'G06N3/045', 'G06N3/084', 'G06V10/462', 'G06V40/23']"
CN113396428B,"Learning system, computer program product and method for multi-agent applications","The present disclosure relates to learning systems, computer program products, and methods for multi-agent applications. A learning system for multi-agent applications is described. In operation, the system initializes a plurality of learning agents. The learning agents include both tactical agents and strategic agents. The strategic agents observe from the environment and select one or more tactical agents to generate actions for controlling actuators of the platform or simulated movements in the environment to accomplish the task. Alternatively, tactical agents generate actions corresponding to learned low-level behaviors to control actuators of the platform or simulated motions in the environment to accomplish tasks.","['G06N20/00', 'G06N3/006', 'A63F13/67', 'G06N3/0442', 'G06N3/045', 'G06N3/082', 'G06N3/088', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'A63F13/837', 'A63F2300/6623', 'G06N3/044', 'G06N7/01']"
CN108846355B,"Image processing method, face recognition device and computer equipment","The application relates to an image processing method, a face recognition device, a computer device and a readable storage medium, wherein the image processing method comprises the following steps: acquiring a target image with glasses; inputting the target image to a glasses removal model based on the generated confrontation network training; the glasses removal model comprises a plurality of convolution-contraction excitation networks which are connected in sequence; obtaining a characteristic diagram of each characteristic channel of the target image through a convolution layer of a convolution-contraction excitation network, wherein the characteristic diagram is used as the input of a contraction excitation layer in the convolution-contraction excitation network; acquiring global information of each characteristic channel by contracting the excitation layer, and learning the global information to generate the weight of each characteristic channel; respectively carrying out weighting processing on the feature maps of the feature channels according to the weights through a weighting layer of a convolution-contraction excitation network to generate weighted feature maps; and generating a glasses-removed image corresponding to the target image through the glasses-removal model. The method can effectively remove the glasses in the image.","['G06T5/77', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T5/20', 'G06T5/60', 'G06V10/30', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/171', 'G06V40/172', 'G06N3/047', 'G06T2207/20084']"
US10885383B2,Unsupervised cross-domain distance metric adaptation with feature transfer network,"A method for implementing an unsupervised cross-domain distance metric adaptation framework with a feature transfer network for enhancing facial recognition includes recursively training a feature transfer network and automatic labeling of target domain data using a clustering method, and implementing the feature transfer network and the automatic labeling to perform a facial recognition task.","['G06N3/088', 'G06K9/6234', 'G06F18/2132', 'G06F18/231', 'G06F18/2413', 'G06F18/2431', 'G06K9/00221', 'G06K9/6219', 'G06K9/627', 'G06K9/628', 'G06N20/20', 'G06N3/04', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/7625', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V40/16', 'G06V40/168', 'G06V40/172']"
CN112070209B,Stable controllable image generation model training method based on W distance,"The invention provides a stable controllable image generation model training method based on a W distance, which comprises the following steps: a. preprocessing the image data to obtain sample data of a training set; b. constructing a stable controllable image generation model based on the W distance, and c, constructing an integral model according to the loss function of each network; d. training the model by alternately iterating the gradient descent algorithm to ensure normal convergence of the model parameters; e. and after the model parameters are converged, separating the generator network G, the encoder network E and the classifier network C respectively to be used as independent service products. The invention is an end-to-end network model, improves the model in the prior art from two aspects of model structure and distribution measurement standard, solves the problems of unstable model training gradient and unstable model gradient descending direction, can stably and directionally generate image samples, and improves the robustness in the model training process and the controllability of the generated samples.","['G06N3/045', 'G06F18/24', 'G06N3/084']"
US11080707B2,Methods and arrangements to detect fraudulent transactions,"Logic may detect fraudulent transactions. Logic may determine, by a neural network based on the data about a transaction, a deviation of the transaction from a range of purchases predicted for the customer, wherein the neural network is pretrained to predict purchases by the customer based on a purchase history of the customer. Logic may compare the deviation of the transaction from purchases predicted by the customer against a deviation threshold to determine whether the transaction is within the range of purchases predicted by the neural network. Logic may generate a notification in response to a determination that the deviation of the transaction from the range of purchases predicted exceeds a deviation threshold, the notification to identify the transaction as a potentially fraudulent transaction. Logic may train the neural network based on the transaction in response to a determination that transaction is not a fraudulent transaction.","['G06Q20/4016', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N3/044']"
US20220054071A1,"Motor imagery electroencephalogram signal processing method, device, and storage medium","This disclosure discloses a method and apparatus for processing a motor MI-EEG signal and a storage medium. The method includes: inputting a source MI-EEG signal belonging to a source domain and a target MI-EEG signal belonging to a target domain to an initial feature extraction model to obtain first source MI features and first target MI features; inputting the first source MI features to an initial classification model to obtain a first classification result outputted by the initial classification model, the first classification result representing an action predicted to be performed in the source MI-EEG signal; and adjusting a model parameter of the initial feature extraction model and/or a model parameter of the initial classification model when a certain condition (set) is met.","['A61B5/375', 'A61B5/369', 'A61B5/372', 'A61B5/72', 'A61B5/7267', 'G06F18/22', 'G06F18/24143', 'G06K9/46', 'G06K9/6215', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06V10/40', 'G06V10/454', 'G06V40/15', 'G16H40/63', 'G16H50/20', 'A61B2505/09', 'G06F2218/08', 'G06F2218/12', 'G06F3/015', 'G06N3/044']"
US11398026B2,Systems and methods for synthetic medical image generation,"Systems and methods for synthetic medical image generation in accordance with embodiments of the invention are illustrated. One embodiment includes a synthetic medical image generation system, including a processor, and a memory containing an image synthesis application, where the image synthesis application directs the processor to obtain source image data generated by at least one medical imaging device, where the source image data describes a functional medical image taken of a patient administered with a first imaging agent, and synthesize a predicted medical image of the patient that depicts the patient as if they were administered with a second imaging agent, wherein the first imaging agent and the second imaging agent are different imaging agents.","['G16H30/40', 'A61B6/037', 'A61B6/481', 'A61B6/52', 'G06F18/2413', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G16H20/17', 'G16H50/20', 'A61B5/0033', 'A61B5/055', 'A61B5/7267', 'A61B5/7278', 'A61B6/032', 'A61B6/5235', 'G06T2207/10104', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/031']"
US11244500B2,Map feature extraction using overhead view images,"Various embodiments of the present technology can include methods, systems and non-transitory computer readable media and computer programs configured to determine one or more images of a generated overhead view of a geographical area. The generated overhead view is generated from aggregated pixel values determined from correlated pixel values in images of the geographical area. The disclosed approaches identify semantic map features as being present in the images of the overhead perspective of the geographic area. The disclosed approaches extract the semantic map features of the geographical area from the images of the substantially overhead perspective of the geographical area. The disclosed approaches translate the extracted semantic map features to a semantic map layer of a geometric map associated with the geographical area.","['G01C21/3804', 'G01C21/32', 'G01S17/89', 'G01S17/931', 'G06F16/29', 'G06F16/54', 'G06K9/6202', 'G06T17/05', 'G06V20/56']"
US20200304290A1,Distributed ledgers for the management of the lifecycle of data in aeronautics,"Computer-implemented methods and systems for managing the lifecycle of aeronautical data stored in a blockchain, include steps of receiving or sending aeronautical data, and encrypting and/or decrypting these data using a smart contract. The use of a plurality of blockchains, and the facts and rules of management of the lifecycle of the data (e.g. programmed obsolescence, time-dependent quality indicator, etc.) are described. Transactional aspects; the use of oracle services; asymmetric, homomorphic and post-quantum encryption methods; the use of chameleon hash functions, so as to manipulate at least partially redactable blockchains; and machine-learning techniques, are in particular described with respect to a number of embodiments. Software and system aspects are described.","['H04L9/0637', 'G06F21/6245', 'G06Q10/04', 'G06F16/27', 'G06F21/602', 'G06F21/6227', 'G06F21/6254', 'G06F21/645', 'G06Q10/06', 'G06Q10/0631', 'G06Q10/08', 'G06Q10/20', 'G06Q50/40', 'G06Q90/00', 'H04L9/008', 'H04L9/0643', 'H04L9/0825', 'H04L9/0852', 'H04L9/3073', 'H04L9/3239', 'H04L9/50', 'G06F2221/2141', 'G06F2221/2143', 'H04L2209/38', 'H04L2209/56', 'H04L2209/603']"
US11151391B2,Method and apparatus for creating a visual map without dynamic content,"Methods described herein relate to creating a visual map of an environment free of scene clutter. Methods may include: receiving sensor data from at least one image sensor, where the sensor data is representative of a plurality of images, each image representative of a scene at a scene location; processing each image using semantic scene segmentation to identify segments of the image of the scene; classifying the segments of each of the images of the scene into one of static elements or dynamic elements; generating a decluttered image of the scene, where the decluttered image includes only elements classified as static elements; providing for storage of the decluttered image of the scene in a database; and identifying a location of a device as the scene location in response to sensor data from the device corresponding to the decluttered image of the scene.","['G06K9/00791', 'G06V10/82', 'G01C21/3647', 'G05D1/0246', 'G06F18/2115', 'G06F18/2163', 'G06F18/24', 'G06K9/6231', 'G06K9/6261', 'G06K9/6267', 'G06K9/726', 'G06T7/174', 'G06T7/70', 'G06V20/10', 'G06V20/56', 'G06V20/70', 'G06V30/1916', 'G06V30/19173', 'G06V30/274', 'G05D2201/0213', 'G06T2207/20084', 'G06T2207/30252']"
US11528290B2,"Systems and methods for machine learning-based digital content clustering, digital content threat detection, and digital content threat remediation in machine learning-based digital threat mitigation platform","A machine learning-based system and method for content clustering and content threat assessment includes generating embedding values for each piece of content of corpora of content data; implementing unsupervised machine learning models that: receive model input comprising the embeddings values of each piece of content of the corpora of content data; and predict distinct clusters of content data based on the embeddings values of the corpora of content data; assessing the distinct clusters of content data; associating metadata with each piece of content defining a member in each of the distinct clusters of content data based on the assessment, wherein the associating the metadata includes attributing to each piece of content within the clusters of content data a classification label of one of digital abuse/digital fraud and not digital abuse/digital fraud; and identifying members or content clusters having digital fraud/digital abuse based on querying the distinct clusters of content data.","['H04L63/1416', 'H04L63/1425', 'G06F16/217', 'G06F16/2455', 'G06F16/285', 'G06F16/9535', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/04']"
US20200218982A1,Dithered quantization of parameters during training with a machine learning tool,"A machine learning tool uses dithered quantization of parameters during training of a machine learning model such as a neural network. The machine learning tool receives training data and initializes certain parameters of the machine learning model (e.g., weights for connections between nodes of a neural network, biases for nodes). The machine learning tool trains the parameters in one or more iterations based on the training data. In particular, in a given iteration, the machine learning tool applies the machine learning model to at least some of the training data and, based at least in part on the results, determines parameter updates to the parameters. The machine learning tool updates the parameters using the parameter updates and a dithered quantizer function, which can add random values before a rounding or truncation operation.","['G06N3/063', 'G06F7/49963', 'G06N20/00', 'G06N3/084', 'G06N3/048', 'G06N3/082']"
US11554785B2,Driving scenario machine learning network and driving environment simulation,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating a driving scenario machine learning network and providing a simulated driving environment. One of the operations is performed by receiving video data that includes multiple video frames depicting an aerial view of vehicles moving about an area. The video data is processed and driving scenario data is generated which includes information about the dynamic objects identified in the video. A machine learning network is trained using the generated driving scenario data. A 3-dimensional simulated environment is provided which is configured to allow an autonomous vehicle to interact with one or more of the dynamic objects.","['B60W50/06', 'G08G1/012', 'G05B13/027', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06T7/20', 'G06T7/246', 'G06V20/176', 'G06V20/182', 'G06V20/41', 'G08G1/0129', 'G08G1/04', 'G08G5/26', 'G08G5/723', 'B60W2050/0075', 'B60W2556/45', 'G06T2207/10016', 'G06T2207/10032', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232', 'G06T2207/30236', 'G06T2207/30241', 'G06T2207/30252']"
US12346117B2,Guiding vehicles through vehicle maneuvers using machine learning models,"In various examples, a trigger signal may be received that is indicative of a vehicle maneuver to be performed by a vehicle. A recommended vehicle trajectory for the vehicle maneuver may be determined in response to the trigger signal being received. To determine the recommended vehicle trajectory, sensor data may be received that represents a field of view of at least one sensor of the vehicle. A value of a control input and the sensor data may then be applied to a machine learning model(s) and the machine learning model(s) may compute output data that includes vehicle control data that represents the recommended vehicle trajectory for the vehicle through at least a portion of the vehicle maneuver. The vehicle control data may then be sent to a control component of the vehicle to cause the vehicle to be controlled according to the vehicle control data.","['G05D1/0221', 'B60W30/00', 'B60W30/18154', 'B60W60/001', 'B62D15/02', 'B62D15/025', 'B62D15/0255', 'G05D1/0088', 'G05D1/43', 'G05D1/81', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/588', 'B60W2420/403', 'B60W2420/408', 'G05D2101/15']"
US11281975B1,Creating and modifying machine learning models in a model training engine,"A method for creating one or more machine learning models in a model training engine is provided. The method includes providing to a user, via a graphical user interface, a selection of components for a machine learning model, at least one component having a computational layer including one or more coefficients associated with a component attribute. The method also includes displaying, in the graphical user interface, a component selected by the user, including a selected value of the component attribute and executing the machine learning model with a training archive as an input, to obtain an output indicative of a desired feature of the training archive. The method also includes comparing the output with a desirable feature value, and modifying at least one coefficient in the component of the machine learning model based on a difference between the output from the machine learning model and the desirable feature value.","['G06N3/084', 'G06F11/362', 'G06F11/3698', 'G06F3/0482', 'G06F3/0483', 'G06F3/04842', 'G06F3/0486', 'G06F8/34', 'G06N20/00']"
US11983806B1,Systems and methods for image generation with machine learning models,"Disclosed herein are methods, systems, and computer-readable media for regenerating a region of an image with a machine learning model based on a text input. Disclosed embodiments involve accessing a digital input image. Disclosed embodiments involve generating a masked image by removing a masked region from the input image. Disclosed embodiments involve accessing a text input corresponding to an image enhancement prompt. Disclosed embodiments include providing at least one of the input image, the masked region, or the text input to a machine learning model configured to generate an enhanced image. Disclosed embodiments involve generating, with the machine learning model, the enhanced image based on at least one of the input image, the masked region, or the text input.","['G06T5/60', 'G06T11/00', 'G06T11/60', 'G06T5/00', 'G06T5/77', 'G06V10/77', 'G06V10/945', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20221']"
US12382115B2,Machine learning based media content annotation,"Systems and techniques are described herein for annotating media content. For example, a process can include obtaining media content and generate, use one or more machine learning models, a metadata file for at least a portion of the media content. The metadata file includes one or more metadata descriptions. The process can include generating a text description of the media content based on the one or more metadata descriptions of the metadata file. The process can include annotating the media content use the text description.","['H04N21/2353', 'G06N20/00', 'G06V10/70', 'G06V20/47', 'G06V20/70', 'G06V40/172', 'G06V40/174', 'G06V40/20', 'H04N21/26603']"
US20220043838A1,Automated learning of anomalies in media streams with external feed labels,"Methods, computer-readable media, and devices are disclosed for providing a notification of an anomaly in a media content that is associated with an event type. For example, a method may include a processing system including at least one processor for detecting a first anomaly from a first media content, generating a first anomaly signature for the first anomaly, obtaining a notification of a first event, the notification including an event type, time information, and location information of the first event, correlating the first anomaly to the notification of the first event, and labeling the first anomaly signature with the event type. The processing system may further detect a second anomaly from a second media content that matches the first anomaly signature and transmit a notification of a second event of the event type when it is detected that the second anomaly matches the first anomaly signature.","['G06F16/285', 'G06F16/783', 'G06F16/24575', 'G06N20/10', 'G06N3/006', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
US11222061B2,Generating digital media clusters corresponding to predicted distribution classes from a repository of digital media based on network distribution history,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for generating accurate digital media clusters corresponding to predicted distribution classes from a repository of digital media based on network distribution history. For example, a digital media clustering system can apply machine learning models at a remote server (based on network distribution history of a network account of a user) to generate predicted distribution classes for future electronic communications. The remote server can provide the predicted distribution classes to a user client device for secure local analysis of digital media stored at the client device. Based on the predicted distribution classes and the stored digital media, the client device can suggest digital media items to distribute via a networking system. Thus, the disclosed system can surface digital media content without providing any information regarding the digital media items stored at the client device to a remote server.","['H04N21/4668', 'G06F16/432', 'G06F16/435', 'G06F16/45', 'G06F16/90324', 'G06F18/23', 'G06F18/2431', 'G06K9/6218', 'G06K9/628', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N5/022', 'G06Q10/10', 'G06Q50/01', 'G06V20/30', 'H04L67/306', 'H04L67/535', 'H04N21/4788', 'H04N21/4826']"
US20230022550A1,"Image processing method, method for training image processing model devices and storage medium","An image processing method includes: obtaining a first latent code by encoding an image to be edited in a Style (S) space of a Generative Adversarial Network (GAN), in which the GAN is a StyleGAN; encoding the text description information, obtaining a text code of a Contrastive Language-Image Pre-training (CLIP) model, and obtaining a second latent code by mapping the text code on the S space; obtaining a target latent code that satisfies distance requirements by performing distance optimization on the first latent code and the second latent code; and generating a target image based on the target latent code.","['G06T11/001', 'G06T11/60', 'G06N3/045', 'G06N3/08', 'G06T9/002', 'Y02T10/40']"
US11348364B2,Method and system for neural fingerprint enhancement for fingerprint recognition,"Biometrics fingerprint matching has been done with a heavily hand-tuned and designed process of classical computer vision techniques for several decades. This approach has led to accurate solutions for solving crimes today and, as such, little effort has been devoted to using deep learning in this domain. Exemplary embodiments disclosed herein leverage synthetic data generators to train a neural fingerprint enhancer to improve matching accuracy on real fingerprint images.","['G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/0481', 'G06N3/09', 'G06V10/30', 'G06V10/82', 'G06V40/1347', 'G06V40/1353', 'G06V40/1376']"
CN111612708B,Image restoration method based on countermeasure generation network,"The invention relates to an image restoration method based on an countermeasure generation network, which comprises the following steps: s1, constructing an image restoration training network: adding the generated SE-RestNet network into the generated network, and adding the discrimination SE-RestNet network into the discrimination network to obtain an image restoration training network; s2, training: extracting a plurality of original images from a training data set, masking to obtain a plurality of training images, respectively using the SE-RestNet generating network in the generating network to generate training repair images, using the SE-RestNet discriminating network in the discriminating network to discriminate the true and false of the repair images, and taking the trained generating network as an image repair network after the discriminating network reaches an equilibrium state. According to the image restoration method based on the countermeasure generation network, the SE-RestNet network block is added in the countermeasure generation network, so that the restored image ensures the image structure and semantic consistency, the image restoration effect is better, and no restoration trace exists.","['G06T5/77', 'G06N3/045', 'G06N3/08', 'G06T2207/10004', 'G06T2207/20081', 'Y02T10/40']"
US11045271B1,Robotic medical system,"A system includes a camera; an AI visual processor to classify and recognize human anatomical features, and a processor to control robot movement to reach a selected anatomical target.","['G16H40/67', 'A61B34/70', 'A61B18/1492', 'A61B34/30', 'A61B34/32', 'A61B34/37', 'A61B90/361', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G16H20/40', 'G16H40/63', 'G16H50/20', 'G16H50/80', 'A61B2018/00351', 'A61B2018/00482', 'A61B2018/00577', 'A61B2018/126', 'A61B2018/143', 'A61B2034/2065', 'A61B2034/301', 'A61B2034/302', 'A61B2034/303', 'A61B2090/306', 'A61B2090/3612', 'A61B2090/3614', 'A61B2090/365', 'A61B2090/3735', 'A61B2090/378', 'G06N3/008', 'G06N3/047', 'G06N3/08', 'G06N5/022']"
US20200265301A1,Incremental training of machine learning tools,"Technology related to incremental training of machine learning tools is disclosed. In one example of the disclosed technology, a method can include receiving operational parameters of a machine learning tool based on a primary set of training data. The machine learning tool can be a deep neural network. Input data can be applied to the machine learning tool to generate an output of the machine learning tool. A measure of prediction quality can be generated for the output of the machine learning tool. In response to determining the measure of prediction quality is below a threshold, incremental training of the operational parameters can be initiated using the input data as training data for the machine learning tool. Operational parameters of the machine learning tool can be updated based on the incremental training. The updated operational parameters can be stored.","['G06N3/084', 'G06F18/40', 'G06K9/6253', 'G06N3/04', 'G06N3/048', 'G06N3/08', 'G06N5/04', 'G06N3/063']"
US20200125928A1,Real-time supervised machine learning by models configured to classify offensiveness of computer-generated natural-language text,"Provided is a process that includes: receiving a computer generated utterance classified as non-offensive by a machine learning model, wherein the machine learning model is configured to classify input text as offensive or non-offensive; obtaining feedback regarding the computer generated utterance, the feedback being indicative of a reaction by an audience to the computer generated utterance; determining and based on the feedback, whether the computer generated utterance is perceived as offensive by the audience; and causing one or more parameters of the machine learning model to be updated based on the computer generated utterance and a result of the determination of whether the computer generated utterance is perceived as offensive by the audience.","['G06N3/0472', 'G06F40/56', 'G06F17/2785', 'G06F18/214', 'G06F18/24', 'G06F18/24155', 'G06F18/41', 'G06F40/284', 'G06K9/6254', 'G06K9/6256', 'G06K9/6267', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/047', 'G06N3/08', 'G06N5/04', 'G06N7/01', 'G06N99/005', 'G06V30/19147', 'G06V30/2272', 'G06F40/30', 'G06N20/20']"
US12165289B2,Image enhancement via iterative refinement based on machine learning models,"A method includes receiving, by a computing device, training data comprising a plurality of pairs of images, wherein each pair comprises an image and at least one corresponding target version of the image. The method also includes training a neural network based on the training data to predict an enhanced version of an input image, wherein the training of the neural network comprises applying a forward Gaussian diffusion process that adds Gaussian noise to the at least one corresponding target version of each of the plurality of pairs of images to enable iterative denoising of the input image, wherein the iterative denoising is based on a reverse Markov chain associated with the forward Gaussian diffusion process. The method additionally includes outputting the trained neural network.","['G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T3/4007', 'G06T5/50', 'G06T5/60', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
US12140019B2,Methods for characterizing and evaluating well integrity using unsupervised machine learning of acoustic data,"Methods and systems are provided that characterize and evaluate well integrity of a cased well using unsupervised machine learning of acoustic data. Sonic waveform data for acoustic signals received by the receiver array of a sonic logging tool is collected and processed to determine a high-dimensional representation of the sonic waveform data. The high-dimensional representation is input to an unsupervised machine learning system to determine a low-dimensional representation of the sonic waveform data. A clustering method is applied to the low-dimensional representation to identify a set of clusters therein. At least one well integrity property of the depth interval of the cased well is determined based on the set of clusters. In embodiments, the at least one well integrity property can characterize cement condition in an annulus of the cased well as a function of azimuth and depth and can be used to evaluate cement integrity in a depth interval of the cased well.","['E21B47/0025', 'E21B47/005', 'E21B47/107', 'G01V1/40', 'G01V1/48', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06N20/00']"
US20220405522A1,"Method for protecting the intellectual property rights of a trained machine learning network model using digital watermarking by adding, on purpose, an anomaly to the training data","The invention provides a method for marking a machine learning model, said method comprising providing a training dataset, adding at least one anomaly to said training dataset, and training said machine learning model using said training dataset.This can for instance help to protect property rights on trained neural networks.","['G06K9/62', 'G06F18/22', 'G06F21/6209', 'G06K9/6215', 'G06N20/00', 'G06N3/08', 'G06V10/70']"
US20200297444A1,Systems and methods for localization based on machine learning,"Certain aspects relate to systems and techniques for localizing and/or navigating a medical instrument within a luminal network. A medical system can include an elongate body configured to be inserted into the luminal network, as well as an imaging device positioned on a distal portion of the elongate body. The system may include memory and processors configured to receive from the imaging device image data that includes an image captured when the elongate body is within the luminal network. The image can depict one or more branchings of the luminal network. The processor can be configured to access a machine learning model of one or more luminal networks and determine, based on the machine learning model and information regarding the one or more branchings, a location of the distal portion of the elongate body within the luminal network.","['A61B34/20', 'A61B1/00149', 'A61B1/2676', 'A61B34/10', 'A61B34/37', 'A61B34/70', 'A61G13/1235', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'G16H20/40', 'G16H30/00', 'G16H30/40', 'G16H50/00', 'G16H50/20', 'A61B2017/00477', 'A61B2017/00809', 'A61B2034/102', 'A61B2034/105', 'A61B2034/2051', 'A61B2034/2059', 'A61B2034/2061', 'A61B2034/2065', 'A61B2034/301', 'A61B2090/306', 'A61B2090/309', 'A61B2090/3614', 'A61B2090/367', 'A61B2090/376', 'A61G13/04', 'A61G13/06', 'A61G13/101']"
US11324439B2,Methods and apparatus for machine learning to analyze musculo-skeletal rehabilitation from images,"A method can include receiving (1) images of at least one subject and (2) at least one total mass value for the at least one subject. The method can further include executing a first machine learning model to identify joints of the at least one subject. The method can further include executing a second machine learning model to determine limbs of the at least one subject based on the joints and the images. The method can further include generating three-dimensional (3D) representations of a skeleton based on the joints and the limbs. The method can further include determining a torque value for each limb, based on at least one of a mass value and a linear acceleration value, or a torque inertia and an angular acceleration value. The method can further include generating a risk assessment report based on at least one torque value being above a predetermined threshold.","['A61B5/45', 'G16H15/00', 'A61B5/0022', 'A61B5/1071', 'A61B5/1079', 'A61B5/1121', 'A61B5/1128', 'A61B5/4528', 'A61B5/725', 'A61B5/7267', 'A61B5/7275', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N5/01', 'G06T19/20', 'G06T7/277', 'G06T7/70', 'G06V10/25', 'G06V10/62', 'G06V10/82', 'G06V20/647', 'G06V40/103', 'G06V40/23', 'G16H20/30', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'A61B2505/09', 'G06N3/044', 'G06T2207/20044', 'G06T2207/30196']"
US20220188654A1,System and method for clinical trial analysis and predictions using machine learning and edge computing,"A system and method for improving the efficiency of information flow of and during clinical trials and also using edge-based and cloud-based machine learning for analyzing clinical trial data from inception to completion subsequently protecting investments, assets, and human life. The system comprises a pharmaceutical research system that receives, pushes, and facilitates data packets containing clinical trial information across multiple sites and across multiple trial personnel while also using machine learning for a variety of tasks. A mobile application on edge devices uses edge-based machine learning to identify biomarkers and provides sponsors and clinicians with an expedient and secure communication means. The edge devices and the cloud-based machine learning communicate full-duplex and share information and machine learning models leading to an improvement in early adverse effects detection. Biomarkers predicting severe adverse effects trigger the system to send alerts, reports, and potential victims to medical personnel for immediate intervention.","['G06N3/084', 'G06N5/022', 'G06F16/951', 'G06F18/22', 'G06F18/2413', 'G06K9/6215', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06V10/82', 'G06V20/698', 'G16B15/30', 'G16B40/20', 'G16H10/20', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G06N5/02', 'G06V2201/04', 'G16B20/40']"
US10861439B2,"Machine learning model for identifying offensive, computer-generated natural-language text or speech","Provided is a process that includes: obtaining a training set of n-grams labeled as offensive; causing a machine learning model to be trained based on the training set of n-grams, wherein the machine learning model, when trained, is configured to classify natural language text as offensive or non-offensive; obtaining input natural language text expressing a computer-generated utterance; classifying after causing training, the computer-generated utterance as offensive or non-offensive using the machine learning model; and causing an output to be provided to a recipient, the output being based on whether the machine learning model classifies the computer-generated utterance as offensive or non-offensive.","['G06F40/284', 'G10L15/063', 'G06F16/35', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G10L15/1815', 'G06N7/01', 'G10L2015/0631']"
US11957478B2,Methods and apparatus for machine learning to analyze musculo-skeletal rehabilitation from images,"A method can include receiving (1) images of at least one subject and (2) at least one total mass value for the at least one subject. The method can further include executing a first machine learning model to identify joints of the at least one subject. The method can further include executing a second machine learning model to determine limbs of the at least one subject based on the joints and the images. The method can further include generating three-dimensional (3D) representations of a skeleton based on the joints and the limbs. The method can further include determining a torque value for each limb, based on at least one of a mass value and a linear acceleration value, or a torque inertia and an angular acceleration value. The method can further include generating a risk assessment report based on at least one torque value being above a predetermined threshold.","['A61B5/7275', 'A61B5/45', 'A61B5/0077', 'A61B5/1116', 'A61B5/1121', 'A61B5/1128', 'A61B5/4528', 'A61B5/7203', 'A61B5/725', 'A61B5/7267', 'G06N20/20', 'G06T19/20', 'G06T7/277', 'G06T7/70', 'G06V10/25', 'G06V10/34', 'G06V10/82', 'G06V40/23', 'G16H20/30', 'G16H50/30', 'A61B2503/10', 'A61B2505/09', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06T2207/20044', 'G06T2207/20084', 'G06T2207/30196']"
US20200125639A1,Generating training data from a machine learning model to identify offensive language,"Provided is a process that includes: obtaining a corpus of unstructured natural language text statements and corresponding responses by responding users, wherein the corresponding responses are responsive natural language text statements or responding-user-expressed scores; obtaining demographic features associated with the responding users; scoring the corresponding responses based on whether the corresponding responses indicate offense to the unstructured natural language text statements to which the corresponding responses correspond in order to form offensiveness scores; forming a training set at least in part by: labeling the unstructured natural language text statements, or n-grams therein, with labels based on the offensiveness scores; and associating the labels with corresponding demographic features of the responding users; and causing a machine learning model to be trained based on the training set, wherein the machine learning model is configured to at least one of: classify natural language utterances as offensive or non-offensive, or generate utterances.","['G06F40/216', 'G06F17/2785', 'G06F15/18', 'G06F17/2705', 'G06F18/214', 'G06F18/24', 'G06F18/41', 'G06F40/205', 'G06F40/284', 'G06F40/30', 'G06K9/6254', 'G06K9/6256', 'G06K9/6267', 'G06N20/00', 'G06N3/044', 'G06N3/08', 'G06N7/01', 'G10L15/197', 'G06N3/006']"
US11393577B2,Machine-learning and combinatorial optimization framework for managing tasks of a dynamic system with limited resources,"Techniques are described for managing tasks of a dynamic system with limited resources using a machine-learning and combinatorial optimization framework. In one embodiment, a computer-implemented method is provided that comprises employing, by a system operatively coupled to a processor, one or more first machine learning models to determine a total demand for tasks of a dynamic system within a defined time frame based on state information regarding a current state of the dynamic system, wherein the state information comprises task information regarding currently pending tasks of the tasks. The method further comprises, employing, by the system, one or more second machine learning models to determine turnaround times for completing the tasks based on the state information, and determining, by the system, a prioritization order for performing the currently pending tasks based on the total demand and the turnaround times.","['G06Q10/063112', 'G16H40/20', 'G06Q10/0631', 'G06Q10/06311', 'G06Q10/063118', 'G06Q10/06313', 'G06Q10/0633', 'G06Q10/0639', 'G16H50/20']"
US20210287119A1,Systems and methods for mitigation bias in machine learning model output,"Systems and methods for generating machine learning model output from an input data set is provided. The system includes a processor and a memory coupled to the processor. The memory may store processor-executable instructions that, when executed, configure the processor to: obtain a qualitative data set; determine a regularization threshold value based on the qualitative data set for regularizing the machine learning output; determine a quantitative feedback score for the input data set, wherein the quantitative feedback score includes a bias-detection indication value; determine an adjustment parameter based on the quantitative feedback score and the regularization threshold value; and update the machine learning model based on the determined adjustment parameter.","['G06N5/04', 'G06N20/00', 'G06Q10/063', 'G06Q30/0201', 'G06Q40/03', 'G06Q40/08']"
US11777540B1,Machine learning-based nonlinear pre-distortion system,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for correcting distortion of radio signals A transmit radio signal corresponding to an output of a transmitting radio signal processing system is obtained. A pre-distorted radio signal is then generated by processing the transmit radio signal using a nonlinear pre-distortion machine learning model. The nonlinear pre-distortion machine learning model includes model parameters and at least one nonlinear function to correct radio signal distortion or interference. A transmit output radio signal is obtained by processing the pre-distorted radio signal through the transmitting radio signal processing system. The transmit output radio signal is then transmitted to one or more radio receivers.","['H04B1/0475', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'H03F1/3247', 'H03F1/3258', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'H04B2001/0425', 'H04W88/08']"
US11871244B2,Primary signal detection using distributed machine learning in multi-area environment,"Methods and systems for primary signal detection using distributed machine learning in a multi-area environment are disclosed. In an example method, it is determined that a first user equipment (UE) device moved to a first predefined area from a second predefined area. A controller sends, to the first UE device, a first machine learning model configured to detect an anomaly in an RF environment associated with the first area. The first machine learning model may have been determined by a second UE device associated with the first area. The controller receives, from the first UE device, anomaly data indicative of an anomaly detected by the first UE device via the first machine learning model. The controller may optionally determine that a primary signal is present in an RF environment associated with the first area based on the anomaly data from the first UE device.","['H04W16/14', 'G06N20/00', 'H04W24/02', 'H04W4/38', 'H04W4/80', 'H04W24/10', 'H04W84/042', 'H04W88/06']"
US11189106B2,Systems and methods for spatial remodeling in extended reality,"Aspects of the subject disclosure may include, for example, storing, in a database, a decorating style preference of a user; receiving, from user equipment of the user, one or more images (and/or one or more 2D environment models and/or one or more 3D environment models) depicting an environment in which remodeling is desired; generating, via a machine learning process, a first model to present by the user equipment, the generating the first model being based upon the decorating style preference and the one or more images (and/or the one or more 2D environment models and/or the one or more 3D environment models), the first model comprising a first remodeling proposal for the environment; sending, to the user equipment, the first model, the sending of the first model facilitating display by the user equipment of a first depiction of the environment as proposed by the first remodeling proposal; receiving, from the user equipment, feedback information regarding the first remodeling proposal; generating, via the machine learning process, a second model to present by the user equipment, the generating the second model being based upon the decorating style preference, the one or more images (and/or the one or more 2D environment models and/or the one or more 3D environment models), and the feedback information, the second model comprising a second remodeling proposal for the environment; and sending, to the user equipment, the second model, the sending of the second model facilitating display by the user equipment of a second depiction of the environment as proposed by the second remodeling proposal. Other embodiments are disclosed.","['G06Q30/0275', 'G06F18/231', 'G06F30/13', 'G06K9/00671', 'G06N20/00', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06Q30/0643', 'G06T19/20', 'G06T7/75', 'G06V10/7625', 'G06V10/82', 'G06V10/945', 'G06V20/20', 'G06F2111/16', 'G06F2111/18', 'G06N3/045']"
US20230139567A1,Multi-modal methods and systems,"Methods and systems to predict phenotypes for one or more organisms, such as plants, using multi-omics or multi-modal data are provided. In some aspects, two or more types of the same or different multi-omics or multi-modal data are encoded into a universal integrated latent space representation.","['G16B40/20', 'G06N3/09', 'G16B20/00']"
CN111091841B,Identity authentication audio watermarking algorithm based on deep learning,"The invention relates to an identity authentication audio watermarking algorithm based on deep learning, which is characterized in that: the algorithm comprises the following steps: 1) carrying out face segmentation, silence removal and spectrum conversion pretreatment on the data set; 2) the identity watermark generation model of the training design extracts the identity characteristics of the speaker from the audio; 3) the watermark embedding-extracting combined model of the training design is self-adaptive to complete the embedding and extracting of the watermark; 4) selecting proper weight ratio parameters through experiments, and adding robustness of a noise enhancement algorithm; 5) and visually finishing the identity authentication of the speaker. The method generates dynamic identity authentication watermark information from speaker audio based on the generation countermeasure model, completes embedding and extraction of the identity watermark based on the self-encoder, and finally performs identity authentication by a visual dynamic effect self-adaptive embedding and extraction mode different from the traditional static information and manual design scheme, thereby ensuring the safety of the audio information.","['G10L19/018', 'G06F21/16', 'G06F21/32', 'G06V40/172', 'H04L2209/608']"
US10949702B2,System and a method for semantic level image retrieval,A system and method for retrieval of similar images related to query images is provided. The query images are pre-processed for noise removal by selecting filtering technique based on noise variance estimation in each query image with respect to pre-set noise variance threshold value. The pre-processed query images are pre-classified for determining class one image identifier. Image types are generated from pre-processed query images for determining class two image identifier. Features are extracted from pre-classified query images based on class one image identifier and from generated images based on class two image identifier. The images similar to query images are retrieved which have features similar to extracted features of pre-classified query images and generated images. The retrieved similar images are ranked for determining most similar images with respect to query images. Similarity between query images and retrieved similar images is analyzed for re-ranking retrieved similar images.,"['G06N3/088', 'G06K9/4623', 'G06F16/535', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/002', 'G06T5/20', 'G06T5/70', 'G06V20/00', 'G06N20/00', 'G06N7/01']"
US20220270711A1,Machine learning guided polypeptide design,"Systems, apparatuses, software, and methods for engineering amino acid sequences configured to have specific protein functions or properties. Machine learning is implemented by methods to process an input seed sequence and generate as output an optimized sequence having the desired function or property.","['G06N3/02', 'G16B15/00', 'G16B15/20', 'G16B35/10', 'G16B40/30', 'G16B45/00']"
US9806718B2,Authenticatable device with reconfigurable physical unclonable functions,"An authenticatable device according to one embodiment includes a reconfigurable physical unclonable function (‘RPUF’) used with one parameter to recover sensitive values (e.g., a secret or a share of a secret) and a different parameter to encode and store values (e.g., challenge-helper pairs) correlated to the sensitive values. In another embodiment, a pair of RPUFs is used instead of a single PUF, with one RPUF used to recover sensitive values and the other RPUF used to encode and store correlated values. In still another embodiment, the desired expiration of values can be enforced by employing redundant RPUFs; when the device is powered on, one (or more than one, but less than all) of the RPUFs is selected and transitioned to a new configuration, invalidating any correlated values previously constructed using the old configuration, and the RPUF that was not reconfigured is used to recover the sensitive value(s) using the remaining correlated value(s).","['H03K19/17748', 'G06F21/34', 'G06F21/44', 'G09C1/00', 'H04L9/0866', 'H04L9/3278', 'H04L2209/12']"
US11256995B1,System and method for prediction of protein-ligand bioactivity using point-cloud machine learning,"A system and method that predicts whether a given protein-ligand pair is active or inactive, the ground-truth protein-ligand complex crystalline-structure similarity, and an associated bioactivity value. The system and method further produce 3-D visualizations of previously unknown protein-ligand pairs that show directly the importance assigned to protein-ligand interactions, the positive/negative-ness of the saliencies, and magnitude. Furthermore, the system and method make enhancements in the art by accurately predicting protein-ligand pair bioactivity from decoupled models, removing the need for docking simulations, as well as restricting attention of the machine learning between protein and ligand atoms only.","['G06N5/022', 'G16B15/30', 'G06F16/951', 'G06F18/22', 'G06F18/2413', 'G06K9/6215', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G16B40/20', 'G06N3/045', 'G06N5/02']"
US10970887B2,Tomographic image reconstruction via machine learning,"Tomographic/tomosynthetic image reconstruction systems and methods in the framework of machine learning, such as deep learning, are provided. A machine learning algorithm can be used to obtain an improved tomographic image from raw data, processed data, or a preliminarily reconstructed intermediate image for biomedical imaging or any other imaging purpose. In certain cases, a single, conventional, non-deep-learning algorithm can be used on raw imaging data to obtain an initial image, and then a deep learning algorithm can be used on the initial image to obtain a final reconstructed image. All machine learning methods and systems for tomographic image reconstruction are covered, except for use of a single shallow network (three layers or less) for image reconstruction.","['G06T11/008', 'A61B5/055', 'A61B5/00', 'A61B6/032', 'A61B6/037', 'A61B6/5205', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/006', 'G06T2210/41', 'G06T2211/421', 'G06T2211/424']"
US11170314B2,Detection and protection against mode switching attacks in cyber-physical systems,"A cyber-physical system may have a plurality of monitoring nodes each generating a series of current monitoring node values over time that represent current operation of the cyber-physical system. According to some embodiments, a features extraction computer platform may receive the series of current monitoring node values over time and generate current feature vectors based on the series of current monitoring mode values. A system mode estimation computer platform may provide the current feature vectors to a probabilistic graphical model to generate an estimated system mode. The system mode estimation computer platform may then compare the estimated system mode with a currently reported system mode output by the cyber-physical system and generate a system mode status indication based on a result of said comparison. According to some embodiments, the system mode status indication can be used to override the currently reported system mode of the cyber-physical system.","['H04L41/142', 'G06N7/005', 'G06F17/16', 'G06F17/18', 'G06F18/2411', 'G06F18/2433', 'G06F18/295', 'G06F9/542', 'G06K9/6297', 'G06N20/00', 'G06N7/01', 'H04L41/16', 'H04L43/0817', 'H04L63/14']"
US20230359193A1,System and method of predicting failures,"A system and method for prediction of failures and optimization, that can provide solution available for unsupervised learning models based on limited data that can predict different types of failure and pre-failure instances. The solution provides improvement upon previous methods of labelling by marking certain days data ahead of failure as belonging to failure data which will result in reduction of noisy data and improves good working condition data. The present invention helps with improved data quality due to labelling as the proposed method models complex distributions of feature vectors accurately and are better at finding deviations from normal data distribution which is used for detecting failures. The novel solution help to analyse and categorise the type of failures for PC Pumps currently deployed in CBM Fields for which failure days in advance can be predicted.","['G06Q50/02', 'G05B23/0283', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06Q10/20', 'G05B2219/45129']"
TWI833043B,"Method of performing semiconductor metrology, related non-transitory computer-readable storage medium and semiconductor-inspection system","First and second metrology data are used to train a machine-learning model to predict metrology data for a metrology target based on metrology data for a device area. The first metrology data are for a plurality of instances of a device area on semiconductor die fabricated using a fabrication process. The second metrology data are for a plurality of instances of a metrology target that contains structures distinct from structures in the device area. Using the trained machine-learning model, fourth metrology data are predicted for the metrology target based on third metrology data for an instance of the device area. Using a recipe for the metrology target, one or more parameters of the metrology target are determined based on the fourth metrology data. The fabrication process is monitored and controlled based at least in part on the one or more parameters.","['G01B11/0625', 'G03F7/70625', 'G06N3/088', 'G01B11/00', 'G01B11/24', 'G01B11/26', 'G01B21/02', 'G01N21/211', 'G01N21/55', 'G01N23/04', 'G01N23/20', 'G01N23/201', 'G01N23/2251', 'G03F7/705', 'G03F7/706841', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'H01L21/67253', 'H01L22/20', 'G01B2210/56']"
CN112330682B,Industrial CT image segmentation method based on deep convolutional neural network,"The invention requests to protect an industrial CT image segmentation method based on a deep convolutional neural network, which comprises the following steps: step 1, an industrial CT image data set construction step, and a training set, a verification set and a test set are obtained; step 2, making a labeling sample; step 3, designing a network structure of industrial CT image segmentation based on a deep convolutional neural network; step 4, designing a loss function: optimizing during training by using an improved loss function based on the Dice coefficient and the binary cross entropy as a new objective function; step 5, training a model, namely training the model by adopting a tensoflow deep learning framework, and continuously optimizing the custom loss function in the step 4 by adopting an Adam optimizer in advance; and 6, post-processing: and further refining the segmentation result of the neural network by adopting a fully connected conditional random field, and continuously optimizing the segmentation result. The invention has high segmentation efficiency, high precision and certain universality.","['G06T7/10', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US10950338B2,Method and apparatus for generating an artificial intelligence 3D dataset and performing interactive manipulation and rendering of the dataset,"A method comprises generating a 3D volumetric dataset through an artificial intelligence process. Then, performing a simulation by first assigning mechanical type properties to a 3D volumetric dataset. Then, performing rendering of the 3D volumetric wherein the 3D volumetric dataset has a first configuration. Then, receiving an input to cause the 3D volumetric dataset to change from a first configuration to a second configuration wherein the change in configuration is in accordance with the nature of the input and the mechanical type properties of the 3D dataset. Then, performing rendering of the 3D volumetric dataset in the second configuration. This cycle is repeated over multiple changes in configuration.","['G16H50/50', 'G16H30/40', 'G06F30/27', 'G06N20/00', 'G06N3/0475', 'G06N3/094', 'G06T15/08', 'G06T17/10', 'G06T19/20', 'G09B23/286', 'G09B9/00', 'G16H30/20', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T2210/41', 'G06T2219/2012', 'G16H20/40']"
US11195007B2,Classification of piping and instrumental diagram information using machine-learning,"Systems and methods for identifying patterns of symbols in standardized system diagrams are disclosed. Disclosed implementations obtain or synthetically generate a symbol recognition training data set including multiple training images, generate a symbol recognition model based on the symbol recognition training data set, obtain an image comprising a pattern of symbols, group symbols into process loops based on the logical relationships captured by process loop identification algorithm, apply a character classification model to image contours to identify the characters and group characters into tags via hierarchical clustering, and store the identified tags, symbols and identified process loops in a relational database.","['G06K9/00476', 'G06V10/82', 'G06F18/214', 'G06F18/217', 'G06F18/23', 'G06F18/24133', 'G06K9/00456', 'G06K9/6218', 'G06K9/6256', 'G06K9/6262', 'G06K9/6271', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06V30/19173', 'G06V30/413', 'G06V30/422', 'G06K2209/01', 'G06N20/10', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G06V30/10']"
EP4247243A1,Multiple partially redundant biometric sensing devices,"The present invention relates to a system and method for acquiring and analyzing physiological data from a user. The system includes a plurality of interconnected devices, which may communicate sensor data to a personal mobile electronic device. Each interconnected device includes at least one sensor to acquire physiological data. In addition, at least one sensor is operably connected to the body of the user. Further, the interconnected biometric devices may be implanted medical devices and/or wearable electronic devices. The personal mobile electronic device is wirelessly connected to each of the plurality of interconnected biometric devices. In addition, the personal mobile electronic device is configured to receive and analyze physiological data acquired by each of the plurality of interconnected devices and to compute the difference between the values of the same physiological parameter measured at a different location of the user's body.","['A61B5/7246', 'A61B5/0024', 'A61B5/002', 'A61B5/01', 'A61B5/021', 'A61B5/14532', 'A61B5/14551', 'A61B5/1468', 'A61B5/318', 'A61B5/389', 'A61B5/6817', 'A61B5/6823', 'A61B5/6846', 'A61B5/7203', 'A61B5/7221', 'A61B5/7225', 'A61B5/7264', 'A61B5/7267', 'A61B7/04', 'G16H10/20', 'G16H10/60', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'H04W4/38', 'A61B5/0031', 'A61B5/681', 'A61B5/6898', 'A61B7/003']"
US20210192175A1,System and method for the early visual detection of forest fires using a deep convolutional neural network,"A Wildfire Early Detection System uses Aerial Video Clips of surveilled areas—obtained through a Network of Hardware components including UAVs and Tethered Aerostats equipped with a Camera and an AI-enabled Embedded Computer—and an Aerial Training Dataset, digitally combining variations of Smoke-Plume-Clips with variations of Background-Clips in nine different positions in the first frame of said Background-Clips with a relative size to the background calculated by perspective and programmed to follow the background to stay apparently “static” in the same place relative to the background for all the remaining frames of the Clip. A Computer-Vision Algorithm trained with that Aerial Training Dataset is used to recognize early fire Plumes of Smoke in those Aerial Video Clips with use of a Multiplication-free Neural Network for Wildfire detection, an AddNet based Discriminator CNN, a GANs used as both event detectors and smoke-plume scene synthesis and Block-based detection.","['G06K9/0063', 'G06V10/82', 'G06F18/214', 'G06F18/28', 'G06K9/00718', 'G06K9/6255', 'G06K9/6256', 'G06V10/772', 'G06V20/13', 'G06V20/17', 'G06V20/41', 'G06K2009/00738', 'G06V20/44']"
GB2567723A,Digital image completion using deep learning,"Digital image completion using deep learning involving multiple neural networks is described. Initially, a digital image having at least one hole is received and this holey digital image is provided as input to an image completer formed with a framework that combines generative and discriminative neural networks based on learning architecture of the generative adversarial networks. From the holey digital image, the generative neural network generates a filled digital image having hole-filling content in place of holes. The discriminative neural networks detects whether the filled digital image and the hole-filling digital content correspond to or include computer-generated content or are photo-realistic. The generating and detecting are iteratively continued until the discriminative neural networks fail to detect computer-generated content for the filled digital image and hole-filling content or until detection surpasses a threshold difficulty. Responsive to this, the image completer outputs the filled digital image with hole-filling content in place of the holey digital image's holes.","['G06T5/77', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
CN108922518B,Voice data augmentation method and system,"The invention discloses a voice data amplification method and a system, wherein the method comprises the following steps: merging the original noise audio data and conditions associated with the original noise audio data into training data; inputting training data into at least one generator for generating an antagonistic network, and acquiring the generated data of the at least one generator; inputting the generated data of at least one generator into a discriminator for discrimination, and acquiring the discrimination result of the discriminator; training and optimizing at least one generator based on the discrimination result; training data is input into the training optimized generator to obtain augmented speech data.","['G10L15/063', 'G10L21/0208', 'G10L21/0216']"
US11501190B2,Machine learning pipeline for predictions regarding a network,"This disclosure describes techniques that include using an automatically trained machine learning system to generate a prediction. In one example, this disclosure describes a method comprising: based on a request for the prediction: training each respective machine learning (ML) model in a plurality of ML models to generate a respective training-phase prediction in a plurality of training-phase predictions; automatically determining a selected ML model in the plurality of ML models based on evaluation metrics for the plurality of ML; and applying the selected ML model to generate the prediction based on data collected from a network that includes a plurality of network devices.","['G06N3/084', 'G06F9/45558', 'G06N5/04', 'G06N20/00', 'G06N20/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/086', 'G06N3/09', 'H04L43/04', 'G06F2009/45595', 'G06N20/20', 'G06N3/044', 'G06N7/01', 'H04L12/4641']"
US12133783B2,Rendering of post treatment smile image,"Embodiments may include: receiving a facial image comprising a 2D depiction of a person's teeth at a first arrangement; receiving a tooth model comprising a 3D depiction of the person's teeth at a second arrangement; obtaining color information from the facial image, wherein the color information represents a color scheme of the person's teeth at the first arrangement; and generating a photo-realistic two-dimensional depiction of the person's teeth at the second arrangement using the 3D depiction of the person's teeth at the second arrangement and the color information obtained from the facial image.","['A61C7/002', 'G06T15/83', 'G06T19/006', 'G06T19/20', 'G06T5/70', 'H04N1/3871', 'H04N1/646', 'A61C2203/00', 'G06T2210/41', 'G06T2219/2012']"
LU503091B1,A machine learning method and system for deep deficiency clustering based on optimal transmission,"The present application discloses a method and system for deep missing clustering machine learning based on optimal transmission, wherein a deep missing clustering machine learning method based on optimal transmission is involved, comprising: S11. Acquire clustering task and target data samples; S12. The first clustering result; is obtained by dividing each sample in the acquired target data sample into the observable feature part and the missing feature part, initially filling the missing feature part based on the filling task and keeping the invariance of the observable feature part; S13. The reconstruction loss and clustering loss in the neural network structure are established by the optimal transmission distance and KL scatter, respectively, to obtain the optimization objective function; and S14. Fuse the filling task with the clustering task based on the obtained optimization objective function and filling the missing values of the missing feature part to obtain the final clustering result.","['G06F18/23', 'G06F18/2321', 'G06F18/15', 'G06N20/00', 'G06N3/04', 'G06N3/0455', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094']"
US9946858B2,Authentication system and device including physical unclonable function and threshold cryptography,"An authentication system and device including physical unclonable function (PUF) and threshold cryptography comprising: a PUF device having a PUF input and a PUF output and constructed to generate, in response to the input of a challenge, an output value characteristic to the PUF and the challenge; and a processor having a processor input that is connected to the PUF output, and having a processor output connected to the PUF input, the processor configured to: control the issuance of challenges to the PUF input via the processor output, receive output from the PUF output, combine multiple received PUF output values each corresponding to a share of a private key or secret, and perform threshold cryptographic operations. The system and device may be configured so that shares are refreshable, and may be configured to perform staggered share refreshing.","['G06F21/31', 'G06F21/34', 'G09C1/00', 'H04L9/3278', 'G06F2221/2129', 'H04L2209/12']"
CN110019732B,A kind of intelligent question answering method and related device,"The embodiment of the application discloses an intelligent question-answering method and a related device, which are used for improving the accuracy of an intelligent question-answering system. The method in the embodiment of the application comprises the following steps: obtaining a target user question; generating a target generation problem corresponding to the target user problem according to a problem optimization model, wherein the problem optimization model is obtained based on generative confrontation network training, and comprises a generator and a discriminator; judging whether the generation quality of the target generation problem is higher than a first preset threshold value or not according to the discriminator, wherein the generation quality is used for indicating the probability that the target generation problem is a standard problem; and if so, determining a target answer according to the target generation question.",['G06F16/3329']
US10789703B2,Semi-supervised anomaly detection in scanning electron microscope images,"Autoencoder-based, semi-supervised approaches are used for anomaly detection. Defects on semiconductor wafers can be discovered using these approaches. The model can include a variational autoencoder, such as a one that includes ladder networks. Defect-free or clean images can be used to train the model that is later used to discover defects or other anomalies.","['G06T7/0004', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T7/001', 'G06V10/764', 'G06V10/82', 'H01L21/67242', 'H01L22/12', 'H01L22/24', 'H01L22/30', 'G06N3/04', 'G06T2207/10061', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US11793605B2,Apparatus and methods for orthodontic treatment planning,"The present disclosure relates to an automated process for the design of dental aligners. Specifically, the present disclosure relates to a method for generating an orthodontic treatment plan for at least one dental arch of a patient, comprising extracting control points of teeth of the at least one dental arch of the patient from received patient-related data, determining, based on the extracted control points, a target dental arch of the patient, calculating, based on the determined target dental arch of the patient, one or more teeth movement stages, and generating, by processing circuitry and based on the calculated one or more teeth movement stages, the orthodontic treatment plan for the at least one dental arch of the patient.","['A61C19/06', 'A61C7/002', 'A61C7/08', 'G06T7/0014', 'G16H20/30', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2207/20084', 'G06T2207/30036']"
US11803944B2,Image cleanup on a mobile device,"Methods, systems, and articles of manufacture, including computer program products, are provided for image cleanup. In some embodiments, there is provide a method which may include subsampling a first image to a first level image of a multiscale transform; performing, based on a machine learning model, an identification of a foreground portion of the first level image and a background portion of the first level image; generating, based on the identification of the foreground portion and the background portion, a first mask; upscaling the first mask to a resolution corresponding to the first image depicting the foreground item; applying the upscaled first mask to the first image to form a second image depicting the foreground item; and providing the second image depicting the foreground item to a publication system. Related systems and articles of manufacture, including computer program products, are also provided.","['G06T5/77', 'G06T5/005', 'G06V10/26', 'G06F18/24', 'G06N20/00', 'G06T3/4084', 'G06T5/002', 'G06T5/70', 'G06T7/194', 'G06V10/52', 'G06T2207/10004', 'G06T2207/20072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20096']"
US20240365081A1,System and method for assisting selective hearing,A system and method for assisting selective hearing includes a detector for detecting an audio source signal portion of one or more audio sources by using at least two received microphone signals of a hearing environment. A position determiner allocates position information to each of the one or more audio sources. An audio type classifier assigns an audio source signal type to the audio source signal portion of each of the one or more audio sources. A signal portion modifier varies the audio source signal portion of at least one audio source of the one or more audio sources depending on the audio signal type of the audio source signal portion of the at least one audio source so as to obtain a modified audio signal portion of the at least one audio source. The system includes a signal generator.,"['H04S7/302', 'H04S7/304', 'G06T7/70', 'H04R3/005', 'H04R5/033', 'H04R5/04', 'H04S1/005', 'H04R1/32', 'H04R25/507', 'H04S2420/01']"
US12407715B2,Threat mitigation system and method,"A computer-implemented method, computer program product and computing system for maintaining a model repository that defines a plurality of AI models; establishing connectivity with a plurality of security-relevant subsystems within a computing platform; receiving an initial notification of a security event from one of the security-relevant subsystems, wherein the initial notification includes a computer-readable language portion that defines one or more specifics of the security event; and selecting a generative AI model for processing the initial notification of the security event from the plurality of AI models defined within the model repository, thus defining a selected generative AI model.","['G06F16/345', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06F40/103', 'G06F40/154', 'G06F40/56', 'G06N3/0475', 'H04L41/16', 'H04L63/1416', 'H04L63/1425', 'H04L63/1441', 'G06F2221/034']"
US11135514B2,"Data processing method and apparatus, and storage medium for concurrently executing event characters on a game client","A data processing method includes obtaining sample data of event execution of a game client, and performing preprocessing on the sample data to obtain a plurality of layers of data combinations. Each layer of the plurality of layers of data combinations corresponds to a target event object in a same target event, different layers correspond to different target event objects in the target event, and the target event objects are event objects on the game client to be executed concurrently. The method also includes performing processing on each layer of data combinations according to a preset processing algorithm, to obtain a processing result of each layer of data combinations, and performing consolidation processing on the processing result to obtain a target instruction. The target instruction is used for instructing the game client to concurrently execute the different target event objects corresponding to the different layers of data combinations.","['A63F13/57', 'G06F9/545', 'G06F9/542', 'A63F13/35', 'A63F13/42', 'A63F13/44', 'A63F13/45']"
US20240104486A1,Edge-Deployed Machine Learning Systems for Energy Regulation,An AI-based platform for enabling intelligent orchestration and management of at least one operating process is provided herein. The AI-based platform includes an artificial intelligence system that is configured to generate a prediction of an energy pattern associated with the at least one operating process. The AI-based platform is also configured to manage the at least one operating process based on the prediction of the energy pattern.,"['G06Q50/06', 'G01R21/133', 'G05B13/0265', 'G05B13/04', 'G05B13/042', 'G05B19/042', 'G06F1/26', 'G06F18/213', 'G06F18/214', 'G06F18/2453', 'G06F30/27', 'G06N10/00', 'G06N10/80', 'G06N20/00', 'G06N3/04', 'G06N3/08', 'G06N5/043', 'G06Q10/04', 'G06Q10/067', 'G06Q30/018', 'G06Q50/02', 'G06Q50/26', 'G06Q99/00', 'G06V10/82', 'H02J13/00001', 'H02J13/00002', 'H02J3/004', 'H02J3/008', 'H02J3/144', 'H02J3/32', 'H04L41/0833', 'H04L41/145', 'H04L41/16', 'H04L9/3239', 'H04L9/50', 'G05B2219/2639', 'G06Q2220/00', 'H02J2203/10', 'H02J2203/20', 'H02J2300/40', 'H02J3/003', 'H02J3/381']"
US10628589B2,"Methods, systems, and computer readable media for preventing code reuse attacks","Methods, systems, and computer readable media for preventing code reuse attacks are disclosed. According to one method, the method includes executing, on a processor, code in a memory page related to an application, wherein the memory page is protected. The method also includes detecting a read request associated with the code. The method further includes after detecting the read request, modifying, without using a hypervisor, at least one memory permission associated with the memory page such that the code is no longer executable after the code is read.","['G06F21/577', 'G06F12/145', 'G06F21/53', 'G06F21/563', 'G06F2212/1052']"
US20230410450A1,Beautification techniques for 3d data in a messaging system,"The subject technology applies, to image data and depth data, a 3D effect including at least one beautification operation based on an augmented reality content generator, the 3D effect including a beautification operation, the beautification operation comprising modifying image data, the image data including a region corresponding to a representation of a face, the beautification operation comprising using a machine learning model for at least one of smoothing blemishes or preserving facial skin texture. The subject technology generates a depth map using at least the depth data. The subject technology generates a segmentation mask based at least on the image data. The subject technology performs background inpainting and blurring of the image data using at least the segmentation mask to generate background inpainted image data. The subject technology generates a 3D message based at least in part on the applied 3D effect including the at least one beautification operation.","['G06T19/20', 'G06T19/006', 'G06F3/04842', 'G06F3/04883', 'G06N20/00', 'G06T15/50', 'G06T7/194', 'G06T7/50', 'G06T7/507', 'G06V40/161', 'G06V40/166', 'G06V40/171', 'H04L67/131', 'G06N3/045', 'G06T2200/24', 'G06T2207/10028', 'G06T2207/30201', 'G06T2219/2012', 'G06T2219/2024']"
US11645745B2,System and method for adverse event detection or severity estimation from surgical data,"Embodiments described herein may provide devices, systems, methods, and/or computer readable medium for adverse event detection and severity estimation in surgical videos. The system can train multiple models for adverse detection and severity estimation. The system can load selected models for real-time adverse event detection and severity estimation.","['G06K9/6268', 'G06T7/0012', 'G06F18/241', 'G06F18/24133', 'G06K9/6271', 'G06N20/10', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0481', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N3/098', 'G06T3/0093', 'G06T3/18', 'G06V10/70', 'G06V10/764', 'G06V10/82', 'G06V20/44', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US11885952B2,"Optics, device, and system for assaying and imaging","A method of assaying an analyte in a sample is disclosed. The method includes having a sample holder with a sample contact area for contacting a sample with an analyte, having a plurality of calibration structures on the sample contact area of the sample holder, imaging a part of the sample contact area that has the calibration structures, and using an algorithm that includes an image, calibration structures in the image, and artificial intelligence and/or machine learning to identify the analyte and/or determine the analyte concentration.","['G02B21/34', 'A61B5/00', 'A61B5/1455', 'A61B5/1495', 'G01N21/6456', 'G01N21/78', 'G01N33/54386', 'G02B27/32', 'G01N21/76', 'G01N2201/0221', 'G01N2496/05', 'G01N33/5094']"
US12141995B2,Systems and methods for simulating dynamic objects based on real world data,Systems and methods for generating simulation data based on real-world dynamic objects are provided. A method includes obtaining two- and three-dimensional data descriptive of a dynamic object in the real world. The two- and three-dimensional information can be provided as an input to a machine-learned model to receive object model parameters descriptive of a pose and shape modification with respect to a three-dimensional template object model. The parameters can represent a three-dimensional dynamic object model indicative of an object pose and an object shape for the dynamic object. The method can be repeated on sequential two- and three-dimensional information to generate a sequence of object model parameters over time. Portions of a sequence of parameters can be stored as simulation data descriptive of a simulated trajectory of a unique dynamic object. The parameters can be evaluated by an objective function to refine the parameters and train the machine-learned model.,"['G06T7/70', 'G06N20/00', 'G06T17/20', 'G06T7/246', 'G06T7/73', 'G06V10/774', 'G06V10/82', 'G06V20/58', 'G06V20/653', 'G06V40/23', 'G06N3/02', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30241', 'G06T2207/30252']"
CN111460130B,"Information recommendation method, device, equipment and readable storage medium","The embodiment of the invention provides an information recommendation method, an information recommendation device, electronic equipment and a readable storage medium, and user characteristic attribute vectors corresponding to target users are determined; inputting the user characteristic attribute vector corresponding to the target user into the corresponding recommendation model to obtain the prediction result of the interest preference score output by the recommendation model; the recommendation model and the countermeasure model form a countermeasure network; the generation of the countermeasure network is obtained by taking a user characteristic attribute vector sample, a fusion characteristic vector sample and a user behavior implicit feedback characteristic vector sample as input training of a countermeasure model; the fused feature vector samples are determined based on the user behavior data samples and the item auxiliary information samples corresponding to the item to be recommended. According to the method provided by the embodiment of the invention, the article auxiliary information corresponding to the article to be recommended is introduced, the information dimension of the input data of the model is increased, and the relation between the user behavior and the attribute of the article to be recommended can be effectively mined, so that the accuracy of recommendation is improved.","['G06F16/9035', 'G06F16/335', 'G06F16/635', 'G06F16/735', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
US9769658B2,Certificating vehicle public key with vehicle attributes,"A method for providing secure connection between vehicles. A unique pair of digitally signed public key and private key is provided to each vehicle, along with additional vehicle-related data. A certificate number is generated for each vehicle and the public key, the certificate number and the attributes of the vehicle is signed by a trusted certificate generating authority. Before communicating with a second vehicle, the first vehicle sends its unique certificate to a second vehicle; the second vehicle verifies the authenticity of received unique certificate number and visible attributes by a camera. If the attributes are verified successfully, the second vehicle sends its unique certificate number to the first vehicle, along with a secret key, which is valid for the current session only. Then the first vehicle verifies the authenticity of received certificate of the second vehicle and attributes by a camera that captures visible attributes of the second vehicle.","['H04W12/06', 'H04L9/3215', 'H04L9/3278', 'H04W12/50', 'H04W4/046', 'H04L2209/84', 'H04L63/0823', 'H04L9/3268', 'H04W12/04', 'H04W12/65', 'H04W84/005']"
US11170270B2,Automatic generation of content using multimedia,"Techniques for content generation are provided. A plurality of discriminative terms is determined based at least in part on a first plurality of documents that are related to a first concept, and a plurality of positive exemplars and a plurality of negative exemplars are identified using the plurality of discriminative terms. A first machine learning (ML) model is trained to classify images into concepts, based on the plurality of positive exemplars and the plurality of negative exemplars. A second concept related to the first concept is then determined, based on the first ML model. A second ML model is trained to generate images based on the second concept, and a first image is generated using the second ML model. The first image is then refined using a style transfer ML model that was trained using a plurality of style images.","['G06N3/08', 'G06K9/6281', 'G06F18/24317', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06V10/772', 'G06V10/774']"
CN110826638B,Zero sample image classification model based on repeated attention network and method thereof,"The invention relates to a zero sample image classification model based on a repeated attention network, which comprises a repeated attention network module, a zero sample image classification module and a zero sample image classification module, wherein the repeated attention network module is used for training and acquiring image region sequence information; the generation countermeasure network module is used for acquiring visual error information; the visual feature extraction network processing module is used for obtaining a one-dimensional visual feature vector of the image; the attribute semantic conversion network module is used for mapping the low-dimensional attribute semantic vector to a high-dimensional feature vector with the same dimension as the visual feature vector by using two linear activation layers; the visual-attribute semantic link network is used for realizing the fusion of the visual feature vector and the attribute semantic feature vector; and the score classification result and reward output module is used for classifying the classes with the labels which are already seen by adopting cross entropy loss, and the reward output is used for punishing the un-seen non-label data and punishing the prediction result with the highest possibility of the seen classes and the un-seen classes in the non-label data. The invention can effectively solve the problem of image category label deletion.",['G06F18/241']
CN111754396B,"Face image processing method, device, computer equipment and storage medium","The application relates to a face image processing method, a face image processing device, a computer device and a storage medium. The method comprises the following steps: acquiring a first face image and a second face image, wherein the first face image and the second face image are images containing real faces; processing the first face image to generate a first updated face image having non-real face image characteristics; adjusting the color distribution of the first updated face image according to the color distribution of the second face image to obtain a first adjusted face image; acquiring a target face mask of the first face image, wherein the target face mask is generated by randomly deforming a face area of the first face image; and fusing the first facial image and the second facial image according to the target facial mask to obtain a target facial image. By adopting the method, various target face images can be generated.","['G06V10/774', 'G06T11/00', 'G06T3/04', 'G06T11/001', 'G06T11/60', 'G06T3/18', 'G06T3/40', 'G06T5/50', 'G06T5/70', 'G06T7/90', 'G06T9/002', 'G06V10/25', 'G06V10/772', 'G06V10/776', 'G06V10/803', 'G06V10/82', 'G06V20/95', 'G06V40/161', 'G06V40/171', 'G09G5/377', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201', 'G09G2340/10']"
US11645470B2,Automated testing of dialog systems,"Methods, systems and computer program products for automated testing of dialog systems are provided herein. A computer-implemented method includes receiving information pertaining to a given conversation workspace of an automated dialog system and identifying test case inputs to the automated dialog system, the test case inputs comprising user input for the given conversation workspace that has portions thereof modified and which the automated dialog system maps to a different intent and/or a different entity relative to the user input. The method further includes generating human-interpretable explanations of mappings of portions of the test case inputs to the different intent and/or entity, generating suggestions for modifying intents, entities and dialog flows of the given conversation workspace such that the test case inputs map to the same intent and/or the same entity as their corresponding user input, and outputting the suggestions and the human-interpretable explanations to a user.","['G06F40/30', 'G06F40/35', 'G06F40/247', 'G06F40/295', 'G06F40/56', 'G06N5/045', 'G06N7/01', 'G06N3/006', 'G10L15/1822']"
US11450324B2,Method of defending against inaudible attacks on voice assistant based on machine learning,"The present disclosure discloses a machine learning-based method for defending a voice assistant from being controlled by an inaudible command, including following steps: 1) collecting data of positive and negative samples, 2) performing data segmentation on data of the positive and negative samples; 3) selecting and normalizing sample features; 4) selecting a classifier to be trained and generate a detection model for a malicious voice command; 5) detecting a voice command to be detected by the detection model. The present disclosure selects an original feature selection method, and for smart devices of different types, it is necessary to obtain normal voice commands and malicious voice commands by means of a smart device of this type, and use them as the positive and negative samples to train a specific classifier for the device. Such a customized approach can well solve a problem that detection and defense between devices cannot work.","['G10L17/26', 'G10L15/26', 'G06N20/00', 'G06N20/10', 'G10L15/063', 'G10L15/22', 'G10L25/03', 'G10L25/18', 'G10L25/51']"
US10192029B2,Secure and scalable mapping of human sequencing reads on hybrid clouds,"System and methods are provided for performing privacy-preserving, high-performance, and scalable DNA read mapping on hybrid clouds including a public cloud and a private cloud. The systems and methods offer strong privacy protection and have the capacity to process millions of reads and allocate most of the workload to the public cloud at a small overall cost. The systems and methods perform seeding on the public cloud using keyed hash values of individual sequencing reads' seeds and then extend matched seeds on the private cloud. The systems and methods are designed to move the workload of read mapping from the extension stage to the seeding stage, thereby ensuring that the dominant portion of the overhead is shouldered by the public cloud.","['G06F19/22', 'G06F19/28', 'G16B30/00', 'G16B30/10', 'G16B50/00', 'G16B50/40', 'H04L63/0428', 'H04L9/0637', 'H04L9/3239']"
US11620391B2,Data encryption based on immutable pointers,"Technologies disclosed herein provide cryptographic computing. An example processor includes a core to execute an instruction, where the core includes a register to store a pointer to a memory location and a tag associated with the pointer. The tag indicates whether the pointer is at least partially immutable. The core also includes circuitry to access the pointer and the tag associated with the pointer, determine whether the tag indicates that the pointer is at least partially immutable. The circuitry is further, based on a determination that the tag indicates the pointer is at least partially immutable, to obtain a memory address of the memory location based on the pointer, use the memory address to access encrypted data at the memory location, and decrypt the encrypted data based on a key and a tweak, where the tweak including one or more bits based, at least in part, on the pointer.","['G06F21/602', 'G06F12/0207', 'G06F12/0646', 'G06F12/0811', 'G06F12/0875', 'G06F12/0897', 'G06F12/1408', 'G06F12/1458', 'G06F12/1466', 'G06F21/12', 'G06F21/54', 'G06F21/6227', 'G06F21/64', 'G06F21/72', 'G06F21/78', 'G06F21/79', 'G06F9/30043', 'G06F9/30101', 'G06F9/30178', 'G06F9/321', 'G06F9/45558', 'G06F9/48', 'G06F9/5016', 'H04L9/0631', 'H04L9/0637', 'H04L9/0822', 'H04L9/0836', 'H04L9/0861', 'H04L9/0869', 'H04L9/0894', 'H04L9/14', 'H04L9/32', 'H04L9/3242', 'G06F2009/45587', 'G06F21/556', 'G06F2212/1032', 'G06F2212/1041', 'G06F2212/1052', 'G06F2212/402', 'G06F2221/2107', 'H04L2209/125', 'Y02D10/00']"
US11900613B2,"Image segmentation method and apparatus, model training method and apparatus, device, and storage medium","This application relates to an image segmentation method and apparatus. The method includes obtaining a current frame and historical affine transformation information transmitted by a previous video frame in a video frame sequence; performing affine transformation on the current frame according to the historical affine transformation information to obtain a candidate region image corresponding to the current frame; performing feature extraction on the candidate region image to obtain a feature map corresponding to the candidate region image; performing semantic segmentation based on the feature map to obtain a segmentation result corresponding to a target in the current frame; and revising the historical affine transformation information according to the feature map to obtain updated affine transformation information, and using the updated affine transformation information as historical affine transformation information corresponding to a subsequent video frame in the video frame sequence.","['G06F18/24', 'G06T7/174', 'G06T7/11', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/0006', 'G06T3/02', 'G06T3/4046', 'G06T7/0012', 'G06T7/248', 'G06V10/25', 'G06V10/267', 'G06T2207/10016', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30048']"
US11741392B2,Data sample label processing method and apparatus,"Disclosed are a data sample label processing method and apparatus. The data sample label processing method comprises: obtaining a first set of data samples without determined labels and a second set of data samples with determined labels; performing an iteration with the following steps until an accuracy rate meets a preset requirement: training a prediction model based on a combination of the first set of data samples and the second set of data samples; inputting data samples from the first set of data samples into the prediction model to obtain prediction values as learning labels for each data sample, and associating the learning labels with the data samples respectively; obtaining a subset from the first set of data samples, wherein the subset comprise data samples associated with learning labels; obtaining determined labels for the data samples in the subset; obtaining the accuracy rate based at least on the learning labels of the data samples in the subset and the determined labels of the data samples in the subset; and if the accuracy rate does not meet the preset requirement, labeling the data samples in the subset with the determined labels for the data samples in the subset, and moving the subset from the first set of data samples to the second set of data samples; and after the iteration ends, labeling the remaining data samples in the first set with the associated learning labels.","['G06F18/214', 'G06N20/00', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/045']"
US11899457B1,Augmenting autonomous driving with remote viewer recommendation,"Autonomous vehicles are an exciting prospect to the future of driving. However, concerns about the decision-making made by the AI controlling a vehicle has been of concern, particularly in light of high-profile accidents. We can alleviate some concern, introduce better decisions, and also train an AI to make better decisions by introducing a remote viewer's, e.g., a human's, reaction to a possibly complex environment surrounding a vehicle that includes a potential threat to the vehicle. One or more remote viewer may provide a recommended response to the threat that may be incorporated in whole or in part in how the vehicle reacts. Various ways to engage and utilize remote viewers are proposed to improve the likelihood of receiving useful recommendations, including modifying how the environment is presented to a remote viewer to best suit the remote viewer, e.g., perhaps present the threat in a game.","['G05D1/0088', 'G08G1/16', 'B60W30/09', 'B60W40/02', 'B60W50/00', 'B60W60/0015', 'B60W60/00274', 'G05D1/0033', 'G05D1/0038', 'G05D1/0214', 'G05D1/0221', 'G05D1/222', 'G05D1/223', 'G05D1/228', 'G05D1/617', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'B60W2050/0002', 'G05D2201/0213']"
CN115560983B,Rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions,"The invention provides a rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions, and relates to the technical field of rolling bearing fault diagnosis. The method comprises the technical key points of performing wavelet transformation on rolling bearing time domain vibration data to obtain a time-frequency spectrogram, taking priori labeled public data as a source domain and multi-user label-free island privacy data as a target domain, introducing a multi-representation feature extraction structure to improve an original residual error network, extracting multi-representation features of the source domain and the target domain to respectively construct a multi-user local model, improving a parameter transfer strategy in a federal migration learning framework by using a model compression idea of a deep neural network, enhancing the safety of the federal framework and reducing communication expenditure, and constructing a federal global model which can be used for fault diagnosis of the rolling bearing under different working conditions at a server side. The island data knowledge can be integrated without multi-user sharing data, and the island data knowledge integration method has higher accuracy and stronger generalization.","['G01M13/04', 'G01M13/045', 'G06N20/00']"
US12327328B2,Aesthetics-guided image enhancement,Methods and systems are provided for generating enhanced image. A neural network system is trained where the training includes training a first neural network that generates enhanced images conditioned on content of an image undergoing enhancement and training a second neural network that designates realism of the enhanced images generated by the first neural network. The neural network system is trained by determine loss and accordingly adjusting the appropriate neural network(s). The trained neural network system is used to generate an enhanced aesthetic image from a selected image where the output enhanced aesthetic image has increased aesthetics when compared to the selected image.,"['G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06T5/00', 'G06T5/60', 'G06T7/0002', 'G06V10/454', 'G06V10/774', 'G06V10/82', 'G06V20/10', 'G06V30/19173', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US20190009133A1,Systems and methods for data-driven movement skill training,A data-driven movement skill training system is disclosed. The system uses movement skill assessment and diagnostics at distinct levels of the human movement system hierarchy to specify training goals for a user. The system may provide various augmentations that are synthesized to help the user pursue the training goals. The system may include features to track and/or manage training or learning processes.,"['A63B24/0062', 'G09B19/00', 'A63B24/0003', 'A63B24/0075', 'A63B69/40', 'A63B71/0622', 'G01B21/04', 'G06V40/23', 'G09B19/003', 'G09B19/0038', 'G16H20/30', 'A63B2024/0065', 'A63B2024/0071', 'A63B2071/0625', 'A63B2220/10', 'A63B2220/40', 'A63B2220/54', 'A63B2220/56', 'A63B2220/803', 'A63B2220/806', 'A63B2230/60']"
WO2022093456A1,"Graphics security with synergistic encryption, content-based and resource management technology","Systems, apparatuses and methods may provide for encryption based technology. Data may be encrypted locally with a graphics processor with encryption engines. The graphics processor components may be verified with a root-of-trust and based on collection of claims. The graphics processor may further be able to modify encrypted data from a non-pageable format to a pageable format. The graphics processor may further process data associated with a virtual machine based on a key that is known by the virtual machine and the graphics processor.","['G06F21/602', 'G06F21/105', 'G06F21/53', 'G06F21/84', 'G06F8/65', 'G06F9/45558', 'G06F9/5027', 'G06N3/04', 'G06N3/08', 'G06T1/20', 'G06T1/60', 'H04L63/0428', 'H04L63/061', 'H04L9/085', 'H04L9/0866', 'H04L9/0891', 'H04L9/3242', 'H04L9/3247', 'H04L9/3263', 'G06F2009/45587', 'G06N3/063', 'H04L2209/603', 'H04L2463/081', 'H04L2463/101']"
US10902651B2,Systems and methods for magnetic resonance image reconstruction,The disclosure relates to systems and methods for magnetic resonance imaging (MRI). A method may include obtaining k-space data associated with MR signals acquired by an MR scanner. The k-space data may corresponding to a first sampling rate. The method may also include generating one or more estimated images based on the k-space data and a target neural network model. The one or more estimated images may correspond to a second sampling rate that exceeds the first sampling rate. The method may further include determining one or more target images based on the one or more estimated images and the k-space data using a compressed sensing model. The compressed sensing model may be constructed based on the one or more estimated images.,"['G06T11/003', 'G06T11/006', 'G01R33/4818', 'G01R33/5608', 'G01R33/561', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T11/005', 'G06T5/10', 'G06N3/047', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/416', 'G06T2211/424']"
US10803249B2,Convolutional state modeling for planning natural language conversations,"In one aspect, a computerized method useful for, with an ensemble of Natural Language Understanding and Processing methods converting a set of user actions into machine queries, includes the step of providing a knowledge model. The method includes the step of receiving a natural language user query; preprocesses the natural language user query for further processing as a preprocessed user query. The preprocessing includes the step of chunking a set of sentences of the natural language query into a set of smaller sentences and retaining the reference between chunks of the set of sentences. The method includes the step of, with the preprocessed user query. For each chunk of the chunked preprocessed user query the method implements the following steps.","['G06F40/295', 'G06F40/30']"
US12036085B2,Systems and methods for remote dental monitoring,"The present disclosure provides systems and methods for remote dental monitoring. In an aspect, the present disclosure provides a computer-implemented method for remote dental monitoring. The method may comprise (a) providing a patient portal for one or more patients to remotely communicate with a caregiver, wherein the patient portal comprises a graphical user interface that is configured to aid the one or more patients in capturing one or more dental scans, wherein the one or more dental scans comprise (i) one or more intraoral videos and (ii) a plurality of images derived from the one or more intraoral videos; and (b) providing the one or more dental scans to the caregiver for an assessment of a dental condition based on the one or more dental scans.","['A61C7/002', 'A61B1/24', 'A61B1/32', 'A61B5/0064', 'A61B5/0088', 'A61B5/6898', 'A61B5/7425', 'A61B5/7465', 'A61C9/0053', 'G09B19/003', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H80/00']"
US11577741B1,Systems and methods for testing collision avoidance systems,"A vehicle may include a primary system for generating data to control the vehicle and a secondary system that validates the data and/or other data to avoid collisions. For example, the primary system may localize the vehicle, detect an object around the vehicle, predict an object trajectory, and generate a trajectory for the vehicle. The secondary system may localize the vehicle, detect an object around the vehicle, predict an object trajectory, and determine a likelihood of a collision of the vehicle with the object. A simulation system may generate simulation scenarios that test aspects of the primary system and the secondary system. Simulation scenarios may include simulated vehicle control data that causes the primary system to generate a driving trajectory and simulated object data that causes the secondary system to determine a collision.","['B60W50/045', 'G06F11/3698', 'B60W30/0953', 'B60W30/0956', 'B60W2050/0031', 'B60W2050/041']"
US12367375B2,System and method for structure learning for graph neural networks,"A graph structure having nodes and edges is represented as an adjacency matrix, and nodes of the graph structure have node features. A computer-implemented method and system for generating a graph structure are provided, the method comprising: generating an adjacency matrix based on a plurality of node features; generating a plurality of noisy node features based on the plurality of node features; generating a plurality of denoised node features using a neural network based on the plurality of noisy node features and the adjacency matrix; and updating the adjacency matrix based on the plurality of denoised node features.","['G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/0895', 'G06N3/09', 'G06N5/022', 'G06N3/042', 'G06N3/082']"
CN110879959B,"Method and device for generating data set, and testing method and testing device using same","The present invention relates to a method and apparatus for generating a CNN learning data set for detecting at least one obstacle in an automatic driving situation, a test method and test apparatus using the same, the method comprising: (a) A learning device obtains (i) an original image representing a road driving situation and (ii) a composite label generated using an original label corresponding to the original image and an additional label corresponding to an image of any specific object not corresponding to the original image; and (b) the learning device causes the first CNN module to generate a composite image using the original image and the composite tag, wherein the composite image is an image obtained by compositing an image of the arbitrary specific object corresponding to the additional tag on the original image.","['G06V20/58', 'G06N3/084', 'G06N3/088', 'B60W60/001', 'G05D1/0088', 'G06F18/2148', 'G06F18/241', 'G06F18/24143', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/10', 'G06V20/70', 'B60W2552/50', 'G06N3/045', 'G06N7/01']"
US20240404025A1,"Method for image motion deblurring, apparatus, electronic device and medium therefor","A method for image motion deblurring, an apparatus, an electronic device and medium therefor are provided. The method includes obtaining a motion-blurred image to be deblurred; inputting the obtained blurred image into a pre-constructed and pre-trained image motion deblur model based on a multi-scale feature fusion module and a local channel information interaction module to obtain a clear image; wherein, the image motion deblur model is obtained through extracting characteristic information of different spatial scales and frequencies through the multi-scale feature fusion module for feature fusion, and exchanging local channel information of the fused feature map with local channel information in an one-dimensional convolution manner through the local channel information interaction module, and then training a dataset with a objective of minimizing a loss function based on adversarial loss and content loss. It can effectively eliminate artifacts and restore texture details, further improving the clarity of images.","['G06N3/0464', 'G06T3/40', 'G06N3/09', 'G06T5/60', 'G06T5/73', 'G06T2207/10016', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20201', 'Y02T10/40']"
US10657253B2,System and method for determining correspondence and accountability between binary code and source code,"A first set of code, for example source code, and a second code, for example binary code, are compared to find corresponding functions. A comparison of features can be used to find correspondences of functions. The comparison of functions can be iterated and can be refined and can be further used to carry out a further, stricter comparison of functions found to correspond to reduce the chance of falsely finding a function in the second code to be accountable in the first code.","['G06F21/563', 'G06F16/9024', 'G06F18/24', 'G06F21/56', 'G06F21/57', 'G06K9/6267']"
US11501101B1,Systems and methods for securing machine learning models,"In an embodiment, a method is performed by a computer system and includes intercepting machine learning (ML) input data before the ML input data flows into a ML model. The method also includes scanning the ML input data against a plurality of ML threat signatures, the scanning yielding at least a first result. The method also includes examining a correlation between values of first and second variables in the ML input data, the examining yielding at least a second result. The method also includes validating at least one of the first and second results via a variability analysis of error instances in the ML input data, the validating yielding at least a third result. The method also includes applying thresholding to the ML input data via the third result, where the applying thresholding results in at least a portion of the ML input data being filtered.","['G06K9/6223', 'G06F18/23213', 'G06F18/217', 'G06F18/22', 'G06F21/552', 'G06F21/554', 'G06K9/6201', 'G06K9/6262', 'G06N20/00']"
US11816568B2,Optimizing execution of a neural network based on operational performance parameters,"The disclosed embodiments relate to a system that optimizes execution of a DNN based on operational performance parameters. During operation, the system collects the operational performance parameters from the DNN during operation of the DNN, wherein the operational performance parameters include parameters associated with operating conditions for the DNN, parameters associated with resource utilization during operation of the DNN, and parameters associated with accuracy of results produced by the DNN. Next, the system uses the operational performance parameters to update the DNN model to improve performance and efficiency during execution of the DNN.","['G06N3/08', 'G06F16/9024', 'G06F17/18', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/10', 'G06N5/04', 'H04L41/0816', 'H04L41/145', 'H04L41/16', 'G06N3/047', 'H04L41/142', 'H04L43/045']"
US12107914B2,Realistic neural network based image style transfer,"A mobile device can implement a neural network-based style transfer scheme to modify an image in a first style to a second style. The style transfer scheme can be configured to detect an object in the image, apply an effect to the image, and blend the image using color space adjustments and blending schemes to generate a realistic result image. The style transfer scheme can further be configured to efficiently execute on the constrained device by removing operational layers based on resources available on the mobile device.","['H04L67/04', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/094', 'G06T11/60', 'G06T5/00', 'G06T5/40', 'G06T5/92', 'G06T7/90', 'G06V10/7753', 'G06V10/82', 'G06V40/161', 'G06V40/175', 'H04L67/10', 'H04N1/60', 'G06N3/047', 'G06Q50/01', 'G06T2207/10024', 'G06T2207/20132']"
US11978245B2,Method and apparatus for generating image,"The present disclosure discloses a method and apparatus for generating an image. A specific embodiment of the method comprises: acquiring at least two frames of facial images extracted from a target video; and inputting the at least two frames of facial images into a pre-trained generative model to generate a single facial image. The generative model updates a model parameter using a loss function in a training process, and the loss function is determined based on a probability of the single facial generative image being a real facial image and a similarity between the single facial generative image and a standard facial image. According to this embodiment, authenticity of the single facial image generated by the generative model may be enhanced, and then a quality of a facial image obtained based on the video is improved.","['G06V10/82', 'G06F18/214', 'G06F18/2413', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/00', 'G06T11/00', 'G06T7/251', 'G06T7/97', 'G06V10/764', 'G06V40/165', 'G06V40/167', 'G06V40/168', 'G06V40/172', 'G06N20/10', 'G06N7/01', 'G06T2207/20081', 'G06T2207/30201']"
US12299813B2,Systems and methods for generating three-dimensional images,"The present disclosure relates to systems and methods for generating a three-dimensional (3D) image. The method may include obtaining a target two-dimensional (2D) image of a subject; obtaining a 3D image generation model that includes a plurality of sequentially connected layers, at least one layer of which may include a down-sampling block, a connection block, and an up-sampling block; and determining a target 3D image of the subject by processing the target 2D image using the 3D image generation model. The down-sampling block may be configured to generate a plurality of 2D feature maps by coding an input of the down-sampling block. The connection block may be configured to generate at least one 3D feature map based on the plurality of 2D feature maps. The up-sampling block may be configured to generate at least one target 3D feature map by processing the at least one 3D feature map.","['G06T17/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T7/50', 'G06N20/00', 'G06T2207/10012', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30016', 'G06T2207/30201', 'G06T2210/41']"
US11972599B2,Method and apparatus for generating vehicle damage image on the basis of GAN network,"Embodiments of the present specification disclose a system and method for generating a vehicle damage image on the basis of a GAN model. During operation, the system obtains a real vehicle image, generates an intermediate image based on the real vehicle image by labeling a target box on the real vehicle image and removing a portion of the real vehicle image within the target box, and generates the vehicle damage image based on the intermediate image by inputting the intermediate image into a machine-learning model, which outputs the vehicle damage image by filling a local image indicating vehicle damage into the target box of the intermediate image.","['G06V10/454', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T11/40', 'G06T11/60', 'G06T7/00', 'G06V30/19173', 'G06V30/274', 'G06V2201/08']"
US10936947B1,Recurrent neural network-based artificial intelligence system for time series predictions,"At a network-accessible artificial intelligence service for time series predictions, a recurrent neural network model is trained using a plurality of time series of demand observations to generate demand forecasts for various items. A probabilistic demand forecast is generated for a target item using multiple executions of the trained model. Within the training set used for the model, the count of demand observations of the target item may differ from the count of demand observations of other items. A representation of the probabilistic demand forecast may be provided via a programmatic interface.","['G06F17/18', 'G06N3/08', 'G06F30/20', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/0985', 'G06N3/088']"
US11545133B2,On-device personalization of speech synthesis for training of speech model(s),"Processor(s) of a client device can: identify a textual segment stored locally at the client device; process the textual segment, using an on-device TTS generator model, to generate synthesized speech audio data that includes synthesized speech of the textual segment; process the synthesized speech, using an on-device ASR model to generate predicted ASR output; and generate a gradient based on comparing the predicted ASR output to ground truth output corresponding to the textual segment. Processor(s) of the client device can also: process the synthesized speech audio data using an on-device TTS generator model to make a prediction; and generate a gradient based on the prediction. In these implementations, the generated gradient(s) can be used to update weight(s) of the respective on-device model(s) and/or transmitted to a remote system for use in remote updating of respective global model(s). The updated weight(s) and/or the updated model(s) can be transmitted to client device(s).","['G10L13/02', 'G10L13/033', 'G10L13/047', 'G10L13/10', 'G10L15/063', 'G10L25/30']"
US20210106281A1,Implantable medical system,"A system to monitor a biological subject includes an implantable device to be inserted inside the subject, the device including an implanted transceiver, an accelerometer, one or more sensors, a battery to power the transceiver, accelerometer and one or more sensors, and a wireless charger to charge the battery; and a wireless charging system outside of the subject to charge the battery in the implantable device. Drug(s) may be carried in reservoir(s) and dispensed based on sensor output.","['A61B5/686', 'A61B5/6861', 'A61B5/0022', 'A61B5/0031', 'A61B5/02055', 'A61B5/0404', 'A61B5/076', 'A61B5/113', 'A61B5/486', 'A61B5/6805', 'A61B5/7267', 'A61B5/7282', 'A61B2503/40', 'A61B2560/0219', 'A61B2560/0223', 'A61B2562/0219', 'A61B5/002', 'A61B5/0077', 'A61B5/01', 'A61B5/021', 'A61B5/024', 'A61B5/02438', 'A61B5/053', 'A61B5/0538', 'A61B5/0816', 'A61B5/085', 'A61B5/14532', 'A61B5/14551', 'A61B5/14552', 'A61B5/1459', 'A61B5/283', 'A61B5/318', 'A61B5/332', 'A61B5/4839', 'A61B5/4872', 'A61B5/4875', 'A61N1/362', 'A61N1/36557', 'A61N1/37282', 'A61N1/3787']"
CN111540193B,Traffic data restoration method for generating countermeasure network based on graph convolution time sequence,"The invention discloses a traffic data restoration method for generating an confrontation network based on a graph convolution time sequence, which comprises the following steps: acquiring an original traffic data set acquired by traffic equipment, and performing abnormal value processing on the acquired original traffic data set by adopting a unitary Gaussian distribution outlier screening method; selecting a data set within a period of time from the data set after abnormal value processing as a complete real data set, and randomly deleting the real data set according to different proportions to obtain a plurality of data sets to be repaired; constructing a generation confrontation network model with repaired traffic data by utilizing a generation network and a judgment network, inputting a data set to be repaired into the generation network to obtain a reconstructed data set, and then inputting the reconstructed data set and a real data set into the judgment network together to complete dynamic confrontation training of the generation network and the judgment network so that the judgment network cannot distinguish the reconstructed data from the real data set; and carrying out traffic data restoration on the generated countermeasure network after training is completed.",['G08G1/0125']
US20240420810A1,Systems and Methods for Supplementing Data with Generative Models,"Systems and methods for determining treatment effects of a randomized control trial (RCT) in accordance with embodiments of the invention are illustrated. One embodiment includes a method for determining treatment effects. The method includes steps for receiving data from a RCT, generating result data using a set of one or more generative models, and determining treatment effects for the RCT using the generated result data.","['G16H10/20', 'A61B5/4848', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'G06N5/02', 'G06N7/01', 'G16H10/60', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G16H70/20', 'G06N20/00']"
US20210117529A1,Authenticating an identity of a person,"Methods, systems and computer programs are provided for authenticating an identity of a person, which includes: obtaining, from a capturing device, one or more captures including image and/or audio captures; detecting, based on spoofing-detection criteria, spoofing indicators in the captures and whether said spoofing indicators correspond to spoofing indicia; detecting, based on liveness-detection criteria, biometric-features in the captures and whether said biometric-features correspond to liveness indicia; detecting, based on identity-biometric criteria, biometric attributes in the captures and whether said biometric attributes correspond to a predefined human identity; extracting, based on time-related criteria, a time-reference hidden or codified in the captures and detecting whether said time-reference satisfies predefined time constraints; and authenticating the identity of the person depending on whether spoofing indicia have been detected, whether liveness indicia have been detected, whether biometric attributes have been detected corresponding to predefined human identity, and whether the time-reference satisfies predefined time constraints.","['G06F21/32', 'H04L63/08', 'G06F21/30', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'H04L9/32', 'H04W12/06', 'G06K9/00906', 'G06N20/00', 'G06N3/02', 'G06V20/40', 'G06V40/15', 'G06V40/45', 'G06V40/50', 'G06V40/70']"
CN111275518B,Video virtual fitting method and device based on mixed optical flow,"The invention discloses a video virtual try-on method and a device based on mixed optical flow, wherein the method comprises the following steps: step S1, acquiring a posture heat map according to a human body image, processing the human body image to obtain a human body segmentation image which only keeps the head and lower body areas, and generating a target human body semantic segmentation map under a target posture by the posture heat map, the human body segmentation image and a corresponding clothes image; step S2, respectively extracting a human body SMPL model from a human body image and a skeleton diagram representing human body posture, and calculating a 3D light flow diagram between the two SMPL models; step S3, predicting a clothes light flow graph between an example clothes image and a target clothes image by using a progressive correction network according to binary masks of the two images; and S4, synthesizing the current try-on video frame by utilizing the feature fusion network under the guidance of the 3D optical flow diagram and the clothes optical flow diagram according to the human body segmentation image, the clothes image, the target gesture heat diagram, the target human body semantic segmentation diagram and the last synthesized video frame.","['G06Q30/0621', 'G06F18/214', 'G06T7/11', 'G06V40/10', 'G06T2207/10021']"
US11679331B2,"Object jump control method and apparatus, computer device, and storage medium","The present disclosure provides a virtual object jump control method performed by a computer device. The method includes determining, in a process that a first virtual object in a virtual scene moves to a destination, a target landing point of the first virtual object according to a position of the destination when a current position of the first virtual object meets a jump condition; determining, according to the current position and the target landing point, a jump trajectory of the first virtual object jumping from the current position to the target landing point; and controlling the first virtual object to jump from the current position to the target landing point according to the jump trajectory.","['A63F13/55', 'A63F13/573', 'A63F13/426', 'A63F13/56']"
US12230399B2,"Multimodal fusion for diagnosis, prognosis, and therapeutic response prediction","Systems and methods can quantify the tumor microenvironment for diagnosis, prognosis and therapeutic response prediction by fusing different data types (e.g., morphological information from histology and molecular information from omics) using an algorithm that harnesses deep learning. The algorithm employs tensor fusion to provide end-to-end multimodal fusion to model the pairwise interactions of features across multiple modalities (e.g., histology and molecular features) and deep learning. The systems and methods improve upon traditional methods for quantifying the tumor microenvironment that rely on concatenation of extracted features.","['G16H50/20', 'G06T7/0012', 'G06V10/806', 'G06V20/695', 'G16B30/00', 'G16B40/20', 'G06T2207/10056', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30024', 'G06T2207/30096', 'G06V2201/03']"
US12189782B2,Methods and systems for natural language processing of graph database queries,"Methods and systems for translating a natural language user query into a graph database query are described. In some instances, the methods may comprise receiving a first input from a user comprising a natural language query regarding data in a graph database; processing the natural language query using a named entity recognition (NER) machine learning model to extract named entities from the natural language query and tag them according to an entity type; processing the tagged named entities using a semantic similarity algorithm to identify corresponding nodes and edges, and their associated properties, in the graph database; processing the natural language query using an intent classification machine learning model to determine a user intent for the natural language query; and applying a user intent-based template to the identified nodes and edges to formulate a graph database query that corresponds to the natural language query.","['G06F21/577', 'G06F16/24522', 'G06F16/9024', 'G06F16/90332', 'G06F40/169', 'G06F40/295', 'G06F21/552', 'G06F2221/034']"
US12335293B2,Capturing importance in a network using graph theory,"A cyber security system includes an importance node module to compute and use graphs to compute an importance of a node based on factors including a hierarchy and a job title of the user, aggregated account privileges from network domains and a level of shared resource access for the user. The graphs are supplied into an attack path modeling component to understand an importance of the network nodes and determine key pathways within the network that a cyber-attack would use, via a modeling the cyber-attack on a simulated and a virtual device version of the network. The cyber security system provides an intelligent prioritization of remediation action to a remediation suggester module to analyze results of the modeling the cyber-attack for each node and suggest how to perform intelligent prioritization of remediation action on a network node in one of a report and an autonomous remediation action.",['H04L63/1433']
US10812521B1,Security monitoring system for internet of things (IOT) device environments,"Techniques are described for implementing a security service that can be used to monitor and provide security-related information for Internet of Things (IoT) devices. An IoT security service uses a reference framework to model the progressive stages of IoT security attacks, also referred to herein as an IoT kill chain. Each stage of an IoT kill chain is associated with a set of security threat “facilitators” and/or security threat “indicators.” Facilitators represent characteristics of an IoT device that cause the device to be susceptible to various types of security threats, while indicators represent detected device activity indicating a potential ongoing security attack. An IoT security service collects data from IoT devices being monitored and possibly other related components, analyzes the collected data to detect defined facilitators and indicators, and uses the detected facilitators and indicators to calculate various security scores for individual devices or for groups of devices.","['H04W4/70', 'H04L63/1433', 'H04L63/20', 'H04L67/303']"
US20230352133A1,Systems and methods for processing medical data,"The present disclosure provides methods for processing medical data. The method may comprise receiving a plurality of data inputs associated with (i) at least one medical patient or (ii) at least one surgical procedure. The method may further comprise receiving one or more annotations for at least a subset of the plurality of data inputs. The method may further comprise generating an annotated data set using (i) the one or more annotations and (ii) one or more data inputs of the plurality of data inputs. The method may further comprise using the annotated data set to (i) perform data analytics for the plurality of data inputs, (ii) develop one or more medical training tools, or (iii) train one or more medical models.","['G16H20/40', 'G16H20/00', 'A61B34/10', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'A61B2034/105', 'A61B2034/107']"
US11599782B2,Self-powered analog computing architecture with energy monitoring to enable machine-learning vision at the edge,"An analog computing method includes the steps of: (a) generating a biasing current (IWi) using a constant gm bias circuit operating in the subthreshold region for ultra-low power consumption, wherein gm is generated by PMOS or NMOS transistors, the circuit including a switched capacitor resistor; and (b) multiplying the biasing current by an input voltage using a differential amplifier multiplication circuit to generate an analog voltage output (VOi). In one or more embodiments, the method is used in a vision application, where the biasing current represents a weight in a convolution filter and the input voltage represents a pixel voltage of an acquired image.","['H03F3/45183', 'G06N3/0635', 'G06F18/21', 'G06F18/24', 'G06G7/16', 'G06K9/6217', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/065', 'G06N3/08', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V10/955', 'H03F3/4508', 'H03F3/45179', 'H03F2203/45634']"
US20220108043A1,Method and device for automatically generating residential building plan,"A method and device for automatically generating residential building plan, comprises: obtaining the standard plans of the residential buildings in each geographical region, analyzing the standard plans to obtain information on the construction area, residential unit area, unit layout, unit plan outline and functional composition and dimension corresponding to each of the standard plans as original training data; conducting training with original training data according to each geographical region in order to establish the residential building plan generative adversarial network model; receiving constraints and objective such as the target construction area, target residential unit area, target unit plan outline and target unit layout of the target residential building, generating residential unit plan model with functional zones based on the generative adversarial network model; denoising and trimming the residential unit plan model to obtain defined geometric information of residential building plan.","['G06N3/088', 'G06F30/13', 'G06F30/27', 'G06N3/045', 'G06N3/047', 'G06T3/0081', 'G06T3/153', 'G06T5/002', 'G06T5/70']"
US10650492B2,Method and apparatus for generating image,"A method and an apparatus for generating an image are provided. A specific embodiment of the method comprises: acquiring a to-be-processed facial image, the image resolution of the to-be-processed facial image being lower than a preset first resolution threshold; and inputting the to-be-processed facial image into a pre-trained generative","['G06T3/4007', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06T5/50', 'G06T7/344', 'G06N20/10', 'G06N7/01', 'G06T2207/30201']"
CN112183788B,Domain adaptive equipment operation detection system and method,"The invention discloses a domain self-adaptive equipment operation detection system and a domain self-adaptive equipment operation detection method. The method comprises the steps of acquiring a to-be-detected inspection image of the power transmission line by using an image acquisition and processing module and preprocessing the image; inputting the inspection image to be detected into a preset weather condition classification model to identify the weather condition of the inspection image to be detected, and obtaining a weather condition classification result; selecting a corresponding preset domain self-adaptive equipment operation inspection model according to the weather condition classification result; inputting the inspection image to be detected into a preset domain self-adaptive equipment operation inspection model to obtain a detection result of the inspection image to be detected, wherein the detection result comprises one or more combinations of equipment type, working condition and position information of a detection object in the inspection image to be detected. The invention ensures that the sample to be detected of the high-voltage transmission line domain self-adaptive equipment operation detection system is not restricted by sample marking and region or weather conditions, and the equipment operation detection result of the target domain in the domain self-adaptive scene has the same detection performance as that of the source domain.","['G06V10/806', 'G06Q10/20', 'G05B19/042', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06Q50/06', 'G06V10/30', 'G06V10/454', 'G06V20/17', 'G07C1/20', 'G05B2219/2639', 'G05B23/0221', 'Y04S10/50']"
CN108765319B,Image denoising method based on generation countermeasure network,"The invention provides an image denoising method based on a generation countermeasure network, and belongs to the technical field of computer vision. The method comprises the following steps: (1) designing a neural network to estimate the noise intensity of the noisy image; (2) according to the estimated noise intensity, adding the intensity noise to the image blocks in the image library to be used as samples of a training network; (3) when training the network, designing a new generation network and a new judgment network. The network is subjected to countermeasure training in a form of fixedly generating a network training judgment network and fixedly judging network parameters to train and generate the network. (4) And selecting network parameters according to a result obtained by the noise identification network by using the trained generation network as a denoising network, and denoising the noise-containing image. The method has the advantages of improving the visual effect of the de-noised image, adjusting parameters without manual intervention and better recovering the texture details of the image.","['G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
CN106951867B,"Face identification method, device, system and equipment based on convolutional neural networks","The invention discloses a kind of face identification method based on convolutional neural networks, device, system and equipment, and method is the following steps are included: S1: Face datection, using multi-layer C NN feature framework；S2: crucial point location obtains face key point position using the multiple reference frame Recurrent networks of deep learning cascade；S3: pretreatment obtains the facial image of fixed size；S4: feature extraction obtains feature representation vector by Feature Selection Model；S5: aspect ratio pair provides face recognition result according to threshold determination similitude or according to distance-taxis.The present invention increases the combination of multi-layer C NN feature on traditional CNN single layer feature framework to cope with different image-forming conditions, based on depth convolutional neural networks algorithm, from training one in mass picture data set in the case where monitoring environment with the Face datection network of higher robustness, false detection rate is reduced, detection response speed is promoted.","['G06V40/161', 'G06N3/045', 'G06V40/168', 'G06V40/172']"
US20230164509A1,System and method for headphone equalization and room adjustment for binaural playback in augmented reality,"A system is provided. The system includes an analyzer for determining a plurality of binaural room impulse responses, and a loudspeaker signal generator for generating at least two loudspeaker signals depending on the plurality of binaural room impulse responses and depending on the audio source signal of at least one audio source. The analyzer is configured to determine the plurality of the binaural room impulse responses such that each of the plurality of the binaural room impulse responses considers an effect that results from a headphone being worn by a user.","['H04S7/306', 'H04S3/008', 'H04R1/1083', 'H04R2225/41', 'H04R2225/43', 'H04R2460/01', 'H04R25/507', 'H04R5/027', 'H04R5/033', 'H04R5/04', 'H04S2400/01', 'H04S2400/11', 'H04S2400/15', 'H04S2420/01', 'H04S7/301', 'H04S7/304']"
US12192204B2,System and method for storing and distributing consumer information,"A computer implemented system for controlling access to data associated with an entity includes a data storage device having a computer memory, and one or more processors. The one or more processors are configured for: storing a secret key associated with the entity in a computer memory associated with the entity; upon receiving entity data, storing the entity data in the computer memory; and upon receiving an access grant signal, enabling communication of information relating to the entity data.","['H04L63/0428', 'H04L63/10', 'H04L63/0807', 'H04L9/0894', 'H04L9/30', 'H04L9/3218', 'H04L9/3234', 'H04L9/3239', 'H04L9/50', 'H04L9/3247']"
US10915820B2,Generating data associated with underrepresented data based on a received data input,An example method described herein involves receiving a data input; identifying a plurality of topics in the data input; determining an underrepresented set of data for a first set of topics of the plurality of topics based on a plurality of knowledge graphs associated with the first set of topics; calculating a score for each topic of the first set of topics based on a representative learning technique; determining that the score for a first topic of the first set of topics satisfies a threshold score; selecting a topic specific knowledge graph based on the first topic; identifying representative objects that are similar to objects of the data input based on the topic specific knowledge graph; generating representation data that is similar to the data input based on the representative objects to balance the underrepresented set of data with a set of data associated with a second set of topics of the plurality of topics; and performing an action associated with the representation data.,"['G06F16/367', 'G06F16/9024', 'G06F16/2462', 'G06F16/288', 'G06F18/22', 'G06K9/6215', 'G06N20/00', 'G06N5/02']"
US11212076B2,Distributed platform for computation and trusted validation,"An example operation may include one or more of generating a data frame storing content of a simulation, compressing the simulation content within the data frame based on previous simulation content stored in another data frame to generate a compressed data frame, and transmitting the compressed data frame via a blockchain request to one or more endorsing peer nodes of a blockchain network for inclusion of the compressed data frame within a hash-linked chain of blocks of the blockchain network.","['H04L9/3239', 'H04L9/0643', 'G06F16/1805', 'G06F16/27', 'H04L63/123', 'H04L9/50', 'H04W72/0446', 'H04L2209/38']"
WO2021056746A1,"Image model testing method and apparatus, electronic device and storage medium","Provided is an image model testing method, the method comprising: acquiring an original image sample; inputting the original image sample into a trained mainstream image classification model; using the mainstream image classification model and a momentum-based gradient iteration algorithm to perform an adversarial attack on the original image sample to obtain an adversarial image; acquiring a first recognition result obtained after an image model to be tested recognizes the original image sample, and acquiring a second recognition result obtained after the image model to be tested recognizes the adversarial image; determining whether the first recognition result is consistent with the second recognition result; and if the first recognition result is consistent with the second recognition result, determining that the image model to be tested successfully recognizes the adversarial image. Further provided in the present application are an image model testing apparatus, an electronic device and a storage medium. According to the present application, the security of a deep neural network model can be tested.","['G06F21/577', 'G06F18/217', 'G06F2221/033', 'Y02T10/40']"
US11455427B2,"Systems, methods, and apparatuses for implementing a privacy-preserving social media data outsourcing model","In accordance with embodiments disclosed herein, there are provided methods and systems for implementing a privacy-preserving social media data outsourcing model. For example, there is disclosed a Data Services Provider (DSP) Framework system, which includes a receive interface to receive an unperturbed social media data set having social media data corresponding to each of a plurality of users represented therein; a data privacy engine to map the received unperturbed social media data set into a high-dimensional user-keyword matrix connecting each of the plurality of users represented with multi-variable keywords corresponding to each user's social media data within the unperturbed social media data set; the data privacy engine further to inject controlled noise generate as output, a perturbed user-keyword matrix which protects each of the plurality of users' privacy during a statistical query against the perturbed user-keyword matrix having the social media data of the plurality of users embodied therein by preventing an attacker from (i) inferring whether a targeted user by the attacker is one of the plurality of users or (ii) inferring whether any record is associated with the targeted user. Other related embodiments are disclosed.","['G06F21/6254', 'G06F16/90344', 'G06F16/9536', 'G06Q50/01']"
US10347241B1,Speaker-invariant training via adversarial learning,"Systems and methods can be implemented to conduct speaker-invariant training for speech recognition in a variety of applications. An adversarial multi-task learning scheme for speaker-invariant training can be implemented, aiming at actively curtailing the inter-talker feature variability, while maximizing its senone discriminability to enhance the performance of a deep neural network (DNN) based automatic speech recognition system. In speaker-invariant training, a DNN acoustic model and a speaker classifier network can be jointly optimized to minimize the senone (triphone state) classification loss, and simultaneously mini-maximize the speaker classification loss. A speaker invariant and senone-discriminative intermediate feature is learned through this adversarial multi-task learning, which can be applied to an automatic speech recognition system. Additional systems and methods are disclosed.","['G10L15/16', 'G10L15/063', 'G10L15/02', 'G10L17/04', 'G10L17/18']"
US10540961B2,Convolutional recurrent neural networks for small-footprint keyword spotting,"Described herein are systems and methods for creating and using Convolutional Recurrent Neural Networks (CRNNs) for small-footprint keyword spotting (KWS) systems. Inspired by the large-scale state-of-the-art speech recognition systems, in embodiments, the strengths of convolutional layers to utilize the structure in the data in time and frequency domains are combined with recurrent layers to utilize context for the entire processed frame. The effect of architecture parameters were examined to determine preferred model embodiments given the performance versus model size tradeoff. Various training strategies are provided to improve performance. In embodiments, using only ˜230 k parameters and yielding acceptably low latency, a CRNN model embodiment demonstrated high accuracy and robust performance in a wide range of environments.","['G10L15/16', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G10L15/063', 'G10L25/30', 'G06F3/16', 'G06N7/01', 'G10L15/18', 'G10L2015/088', 'G10L21/0208']"
CN110427846B,Face recognition method for small unbalanced samples by using convolutional neural network,"The invention relates to a face recognition method for small unbalanced samples by using a convolutional neural network. The method comprises the following steps: aiming at the problem of unbalance of positive and negative samples in a training data set, a DCGAN countermeasure generation network is utilized to generate data samples which are approximately distributed with original training data, and the diversity of a small amount of samples is increased. Aiming at the problems that deep learning needs a large amount of training data and overfitting is easy to occur on a small sample, the problem is solved by using transfer learning, and firstly an Alex-Net network trained on an Image-Net large data set is transferred to a target data set; and then changing the number of the neurons of the output layer into a target data set category, and finally training the reinitialization of the following full-connection layer by using the target data set. The method starts from unbalanced and small data sets, and solves the problem of low confidence coefficient when the small data sets are easy to over-fit and the samples are unbalanced by using a deep learning method.","['G06N3/045', 'G06N3/084', 'G06V40/172']"
US12056892B2,"Image processing method and apparatus, electronic device and computer readable storage medium","The disclosure relates to a communication method and system for converging a 5th-Generation (5G) communication system for supporting higher data rates beyond a 4th-Generation (4G) system with a technology for IoT. The disclosure may be applied to intelligent services based on the 5G communication technology and the IoT-related technology, such as smart home, smart building, smart city, smart car, connected car, health care, digital education, smart retail, security and safety services. An image processing method and apparatus, electronic device and computer readable storage medium, which belong to image processing field are provided. The method and apparatus, electronic device and computer readable storage medium include segmenting an image to be processed to obtain a target region in the image to be processed, and performing style transfer on the target region. The solution provided may effectively improve effects of image processing, and better meet requirements of practical application.","['G06T7/73', 'G06T3/04', 'G06F18/253', 'G06T3/40', 'G06T3/60', 'G06T3/608', 'G06T5/00', 'G06T7/11', 'G06V10/242', 'G06V10/267', 'G06V10/454', 'G06V10/764', 'G06V10/803', 'G06V10/806', 'G06V10/82', 'G06V40/10', 'G06V40/161', 'G06T2207/20081', 'G06T2207/20084']"
US10967202B2,Adaptive image filtering for volume reconstruction using partial image data,"A method of generating an image synthesis process is disclosed, where the image synthesis process improves image quality of degraded volumetric images. In the method, a machine learning process is trained in a supervised learning framework as the image synthesis process. In the supervised learning process, a lower-quality partial-data reconstruction of a target volume is employed as an input object in the supervised learning process and a higher-quality full data reconstruction of the target volume is employed as an expected output. The full data reconstruction is generated based on a first set of projection images of the three-dimensional volume and the partial-data reconstruction is generated based on a second set of projection images of the three-dimensional volume, where the second set of projection images includes projection images that have less image information and/or are of a lower image quality than the first set of projection images.","['A61N5/1067', 'A61B6/4447', 'A61B6/4452', 'A61B6/48', 'A61N5/1081', 'A61B6/032', 'A61B6/541', 'A61N2005/1054', 'A61N2005/1061', 'A61N2005/1074', 'A61N5/1031', 'A61N5/1038', 'A61N5/1039', 'A61N5/1049', 'A61N5/107', 'A61N5/1071', 'G06T11/008', 'G06T2207/10081', 'G06T2207/20081', 'G06T7/0012']"
US11727596B1,Controllable video characters with natural motions extracted from real-world videos,"A video generation system is described that extracts one or more characters or other objects from a video, re-animates the character, and generates a new video in which the extracted characters. The system enables the extracted character(s) to be positioned and controlled within a new background scene different from the original background scene of the source video. In one example, the video generation system comprises a pose prediction neural network having a pose model trained with (i) a set of character pose training images extracted from an input video of the character and (ii) a simulated motion control signal generated from the input video. In operation, the pose prediction neural network generates, in response to a motion control input from a user, a sequence of images representing poses of a character. A frame generation neural network generates output video frames that render the character within a scene.","['G06T7/73', 'G06T7/75', 'G06N20/20', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T7/194', 'G06T7/20', 'G06N3/048', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30221']"
US10915631B2,Deep learning on execution trace data for exploit detection,"Technologies disclosed herein provide for converting a first data of a first control flow packet to a first pixel, where the first data indicates one or more branches taken during a known execution of an application, generating an array of pixels using the first pixel and one or more other pixels associated with one or more other control flow packets generated from the known execution, transforming the array of pixels into a series of images, and using a machine learning algorithm with inputs to train a behavior model to identify a malicious behavior in an unknown execution of the application. The inputs include one or more images of the series of images and respective image labels assigned to the one or more images. More specific embodiments include extracting the first control flow packet from an execution trace representing at least part of the known execution.","['G06F21/552', 'G06F18/214', 'G06F18/217', 'G06F21/54', 'G06F21/56', 'G06F21/566', 'G06K9/325', 'G06K9/4628', 'G06K9/6256', 'G06K9/6262', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06V10/454', 'G06V20/62', 'G06F2221/034', 'G06N20/10', 'G06N3/044', 'G06N3/0445', 'G06N3/047', 'G06N3/0472']"
US11475624B2,"Method and apparatus for generating three-dimensional model, computer device and storage medium",Provided are a method and apparatus for generating a three-dimensional model. The method includes following. A first image containing a first face is acquired. First point cloud data including contour information of the first face is determined based on the first image. First albedo information of the first face and second point cloud data including detail information of the first face are determined based on the first point cloud data and the first image. A three-dimensional model of the first face is generated based on the first albedo information and the second point cloud data.,"['G06V10/774', 'G06T17/00', 'G06F18/25', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/094', 'G06T15/04', 'G06T15/506', 'G06T17/20', 'G06T7/529', 'G06T7/70', 'G06V10/80', 'G06V10/82', 'G06V40/169', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/30201', 'G06V2201/12', 'G06V40/165']"
US20240312249A1,Methods and apparatus to detect deepfake content,"Methods, apparatus, systems and articles of manufacture are disclosed to detect deepfake content. An example apparatus to determine whether input media is authentic includes a classifier to generate a first probability based on a first output of a local binary model manager, a second probability based on a second output of a filter model manager, and a third probability based on a third output of an image quality assessor, a score analyzer to obtain the first, second, and third probabilities from the classifier, and in response to obtaining a first result and a second result, generate a score indicative of whether the input media is authentic based on the first result, the second result, the first probability, the second probability, and the third probability.","['G06V40/172', 'G06V10/449', 'G06V10/54', 'G06V20/49', 'G06V40/171', 'G06V40/40', 'G06V40/45']"
CN111899288B,Tunnel leakage water area detection and identification method based on infrared and visible light image fusion,"The invention discloses a tunnel leakage water area detection and identification method based on infrared and visible light image fusion, which comprises the following steps: firstly, acquiring infrared and visible light data in a tunnel of a region to be detected by using an industrial camera; preprocessing the acquired data to obtain initial infrared and visible light image data, and registering the infrared and visible light images; then, fusing infrared and visible light data obtained after registration by utilizing a deep learning technology; then, the obtained fusion image is subjected to target detection of water leakage and elimination of epoxy resin abnormity, and detection and identification of water leakage in the tunnel are realized; and finally, the function of positioning and marking the water leakage area is realized in the tunnel which cannot use an external positioning system by using an inertial navigation system. The method effectively solves the problem of interference of poor illumination conditions and epoxy resin abnormality in the tunnel on water leakage detection, has the advantages of high precision and high adaptability, and provides a foundation for disease backtracking and rechecking in the tunnel.","['G06T7/337', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T5/40', 'G06T5/70', 'G06T7/10', 'G06V10/751', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30204', 'Y02E10/20']"
US11731663B2,Systems and methods for actor motion forecasting within a surrounding environment of an autonomous vehicle,"Systems and methods are provided for forecasting the motion of actors within a surrounding environment of an autonomous platform. For example, a computing system of an autonomous platform can use machine-learned model(s) to generate actor-specific graphs with past motions of actors and the local map topology. The computing system can project the actor-specific graphs of all actors to a global graph. The global graph can allow the computing system to determine which actors may interact with one another by propagating information over the global graph. The computing system can distribute the interactions determined using the global graph to the individual actor-specific graphs. The computing system can then predict a motion trajectory for an actor based on the associated actor-specific graph, which captures the actor-to-actor interactions and actor-to-map relations.","['B60W60/00276', 'B60W40/072', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'B60W2554/4041', 'B60W2554/4044']"
US10140544B1,Enhanced convolutional neural network for image segmentation,"This disclosure relates to digital image segmentation and region of interest identification. A computer implemented image segmentation method and system are particularly disclosed, including a predictive model trained based on a deep fully convolutional neural network. The model is trained using a loss function in at least one intermediate layer in addition to a loss function at the final stage of the full convolutional neural network. The predictive segmentation model trained in such a manner requires less training parameters and facilitates quicker and more accurate identification of relevant local and global features in the input image. In one implementation, the fully convolutional neural network is further supplemented with a conditional adversarial neural networks iteratively trained with the fully convolutional neural network as a discriminator measuring the quality of the predictive model generated by the fully convolutional neural network.","['G06K9/4628', 'G06N3/084', 'G06F15/18', 'G06K9/66', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/09', 'G06N3/094', 'G06N5/046', 'G06T7/11', 'G06T7/143', 'G06V10/25', 'G06V10/454', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/30061']"
US11584525B2,Deep learning-based localization of UAVs with respect to nearby pipes,"A system and methodology for launching, flying and perching on a cylindrically curved surface in an environment without human intervention. The system and methodology include an environment awareness sensor device suite having a depth camera arranged to capture and output image data and 3D point cloud data of a field of view; an asset targeting unit arranged to set an asset as a destination location for a landing; a trajectory path determiner arranged to calculate a trajectory path to the destination location; a flight controller arranged to launch and fly the autonomous aerial vehicle to the destination location according to the trajectory path; a situational status determiner arranged to, in real-time, predict a location of an object with respect to the autonomous aerial vehicle based on 3D point cloud data for the object, determine the object is the asset based on a confidence score and autonomously land on the asset.","['B64C39/024', 'B64U10/13', 'B64U60/50', 'B64U70/99', 'G05D1/0094', 'G05D1/12', 'G06T7/74', 'B64C2201/127', 'B64C2201/146', 'B64U2101/30', 'B64U2101/64', 'B64U2201/20', 'F17D5/00', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084']"
CN111656357B,"Modeling method, device and system for ophthalmic disease classification model","A modeling method, apparatus and system for an ophthalmic disease classification model, the method comprising creating an ophthalmic image dataset and an ophthalmic non-image disease diagnosis questionnaire dataset (S101); training a first neural network model with the ophthalmic image dataset to obtain a first classification model (S102); training a second classification model using the ophthalmic non-image disease diagnosis questionnaire dataset (S103); and fusing the first classification model and the second classification model to obtain a target classification network model, and taking a test result output based on the target classification network model as a diagnosis result obtained by diagnosing the eye diseases (S104). The method can integrate clinical and ophthalmic images and assist patient personal information to carry out ophthalmic diagnosis, can enable an artificial intelligence technology to better assist ophthalmic disease diagnosis modeling, effectively improves the intellectualization and the accuracy of ophthalmic full-class disease diagnosis modeling, and improves the diagnosis effect.","['G06N3/08', 'A61B3/12', 'A61B3/14', 'G06F18/214', 'G06F18/2178', 'G06F18/25', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0012', 'G06V10/764', 'G06V10/80', 'G06V10/82', 'G06V20/698', 'G16H10/20', 'G16H50/20', 'G06N20/20', 'G06T2207/20081', 'G06T2207/20084']"
US10388002B2,Automatic image correction using machine learning,"In one embodiment, a computing system may access a training image and a reference image of a person and an incomplete image. A generate may generate an in-painted image based on the incomplete image, and a discriminator may be used to determine whether each of the in-painted image, the training image, and the reference image is likely generated by the generator. The system may compute losses based on the determinations and update the discriminator accordingly. Using the updated discriminator, the system may determine whether a second in-painted image generated by the generator is likely generated by the generator. The system may compute a loss based on the determination and update the generator accordingly. Once training is complete, the generator may be used to generate a modified version of a given image, such as making the eyes of a person appear open even if they were closed in the input image.","['G06T5/77', 'G06T5/005', 'G06F18/214', 'G06K9/00268', 'G06K9/6256', 'G06T5/60', 'G06V10/764', 'G06V10/82', 'G06V10/98', 'G06V40/168', 'G06V40/171', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30201']"
CN113711236B,Data-driven generalization analysis and improvement of deep learning models,"Techniques for evaluating and defining a range of data-driven deep learning models are provided. In one embodiment, a machine-readable storage medium is provided that includes executable instructions that, when executed by a processor, facilitate performance of operations comprising employing a machine learning model to extract first training data features included in a training data set and first target data features included in a target data set. The operations also include determining whether the target data set is within a defined data range of the training data set based on an analysis of correspondence between the first training data feature and the first target data feature, and determining whether application of the target data set to a target neural network model developed using the training data set will generate a result having an acceptable level of accuracy based on whether the target data set is within the defined data range.","['G06N3/08', 'G06F17/18', 'G06F18/214', 'G06F18/22', 'G06F18/24', 'G06N20/00', 'G06N20/10', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/01', 'G06V10/454', 'G06V10/761', 'G06V10/772', 'G06V10/82', 'G06V2201/03']"
US11830505B2,Identification of fake audio content,"A computer system that classifies audio content is described. During operation, the computer system may receive audio content. Then, the computer system may determine a representation of the audio content (such as a signal-processing representation) by performing a transformation on the audio content. In some embodiments, the transformation may include a neural network and/or the representation may include word embedding or sense embedding of words in the audio content. Moreover, the computer system may analyze the representation using a predetermined neural network. Next, the computer system may classify, based at least in part on an output of the predetermined neural network, the audio content as being fake or real, where the fake audio content is, at least in part, computer-generated. Furthermore, the computer system may selectively perform a remedial action based at least in part on the classification.","['G10L19/0212', 'G06F16/635', 'G06F16/65', 'G06F21/30', 'G06F21/31', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G10L17/00', 'G10L19/022', 'G10L25/30', 'G10L25/48', 'G10L25/51', 'G06F21/32', 'G06N3/063', 'G06N3/082']"
US11544458B2,Automatic grammar detection and correction,"Systems and processes for operating an intelligent automated assistant are provided. In one example process a set of words including a grammatical error is received. The process can generate, using a neural network based on the set of words including the grammatical error and a reference set of words, a transformed set of words and further determine, based on the set of words including the grammatical error and the reference set of words, a reconstructed reference set of words. The process can also determine, based on a comparison of the transformed set of words and the reconstructed reference set of words, whether the transformed set of words is grammatically correct and provide an indication of whether the transformed set of words is grammatically correct to the neural network.","['G06F40/253', 'G06F40/232', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/048', 'G06N3/088']"
US20250278897A1,System and Method for Generating Simulated Scenes from Open Map Data for Machine Learning,Systems and methods for generating simulated scenes from open map data for machine learning are presented. The system includes an automatic scene generative pipeline that uses freely-available map information and random texture maps to create large-scale 3D urban scene layouts for supervised learning methods. The system generates synthetic datasets that have improved generalization capabilities with respect to a given target domain of interest using data from open maps and texture map from the same geographic locations. Data from the generation pipeline of the system improves a model's generalization to real image sets beyond arbitrarily-simulated sets or labeled real data from other geographical regions.,"['G06T17/20', 'G06F18/2148', 'G06F18/40', 'G06T15/04', 'G06T15/20', 'G06T17/05', 'G06V30/274', 'G06T2210/12']"
US11120582B2,"Unified dual-domain network for medical image formation, recovery, and analysis",An apparatus and method for coupled medical image formation and medical image signal recovery using a dual domain network is disclosed. The dual-domain network includes a first deep neural network (DNN) to perform signal recovery in a sensor signal domain and a second DNN to perform signal recovery in an image domain. A sensor signal is acquired by a sensor of a medical imaging device. A refined sensor signal is generated from the received sensor signal using the first DNN. A first reconstructed medical image is generated from the received sensor signal. A second reconstructed medical image is generated from the refined sensor signal generated by the first DNN. An enhanced medical image is generated based on the both the first reconstructed medical image and the second reconstructed medical image using the second DNN. The enhanced medical image generated by the second DNN is displayed.,"['G06N3/084', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/09', 'G06T11/006', 'G06T3/4007', 'G06T5/001', 'G06N3/048', 'G06T2210/41', 'G06T2211/441']"
US11528435B2,Image dehazing method and image dehazing apparatus using the same,"The disclosure is directed to an image dehazing method and an image dehazing apparatus using the same method. In an aspect, the disclosure is directed to an image dehazing method, and the method would include not limited to: receiving an input image; dehazing the image by a dehazing module to output a dehazed RGB image; recovering image brightness of the dehazed RGB image by a high dynamic range (HDR) module to output an HDR image; and removing reflection of the HDR image by a ReflectNet inference model, wherein the ReflectNet inference model uses a deep learning architecture.","['G06T5/73', 'H04N5/357', 'G06T5/002', 'G06T5/003', 'G06T5/60', 'G06T5/70', 'G06T5/92', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/30252']"
US11651381B2,Machine learning for marketing of branded consumer products,"A method including retrieving a product information from a database is provided. The method includes associating the product information with multiple classification values, forming a vector associated with a consumer product. The classification values form coordinates of the vector in a vector space that comprises multiple vectors associated with multiple consumer products. The method includes determining a cluster in the vector space, including at least one vector selected according to a relative distance within a cluster boundary. The method includes selecting a discriminator vector from a vector difference between a first vector in a first cluster in the vector space and a second vector in a second cluster in the vector space and identifying a new consumer product associated with a new vector that is formed by adding the discriminator vector to a third vector from the vector space, the third vector associated with a known consumer product.","['G06Q30/0202', 'G06F16/26', 'G06F16/285', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0472', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/088', 'G06N3/0895', 'G06N3/094', 'G06Q10/06315', 'G06Q30/0633']"
WO2021164772A1,"Method for training cross-modal retrieval model, cross-modal retrieval method, and related device","A method for training a cross-modal retrieval model, a cross-modal retrieval method, and a related device, relating to the field of artificial intelligence. The method comprises: determining a reference model by using unsupervised learning; performing knowledge distillation on the basis of the reference model and training data to obtain similar data of the training data; and performing supervised learning by using the similar data of the training data and the training data, so as to obtain a cross-modal retrieval model. High accuracy of a trained cross-modal retrieval model can be ensured, without manually tagging training data used for supervised learning.","['G06F16/90335', 'G06F16/907', 'G06F18/22', 'G06N3/045', 'G06N3/084', 'G06N3/088']"
US12190904B2,"Anomaly detection apparatus, probability distribution learning apparatus, autoencoder learning apparatus, data transformation apparatus, and program","An anomaly detection technique which realizes high accuracy while reducing cost required for normal model learning is provided. An anomaly detection apparatus includes an anomaly degree estimating unit configured to estimate an anomaly degree indicating a degree of anomaly of anomaly detection target equipment from sound emitted from the anomaly detection target equipment (hereinafter, referred to as anomaly detection target sound) based on association between a first probability distribution indicating distribution of normal sound emitted from one or more pieces of equipment different from the anomaly detection target equipment and normal sound emitted from the anomaly detection target equipment (hereinafter, referred to as normal sound for adaptive learning).","['G05B23/024', 'G06N3/045', 'G06N3/0455', 'G06N3/088', 'G06N3/0895', 'G06N3/096', 'G10L25/30', 'G10L25/51', 'G06N3/048', 'G06N5/01']"
WO2021056969A1,Super-resolution image reconstruction method and device,"A super-resolution image reconstruction method, comprising: constructing a generative adversarial network; constructing an original resolution image training set; training the generative adversarial network on the basis of the original resolution image training set; and reconstructing an input image by using a generator of the trained generative adversarial network. In the super-resolution image reconstruction method and device in embodiments of the present invention, the constructed generative adversarial network comprises a generator, a discriminator, and a loss function calculator. The generative adversarial network is trained by adopting an original resolution image training set, so that the original resolution image can be used as a reference image to reconstruct a super-resolution image, and even if the original resolution is relatively low, a relatively high-resolution image can still be reconstructed.","['G06T3/4053', 'G06F18/214', 'G06N3/045', 'G06N3/088', 'G06T3/4046']"
CN116030078B,Method and system for lung lobe segmentation combined with attention under the framework of multi-task learning,"The invention discloses a lung lobe segmentation method and a system combining attention under a multi-task learning framework. The invention takes the lung lobe segmentation task as a main task and the lung parenchyma segmentation task as an auxiliary task, and calculates the lung lobe segmentation task and the lung parenchyma segmentation task in parallel; and a channel attention module and a sharpening space attention module are inserted into the network, the channel attention module can strengthen channel characteristic information, the sharpening space attention can improve edge test effect, the network can adaptively weigh different tasks, the network of a multi-task target is optimized, and finally, a segmentation model obtained through training can realize rapid and accurate segmentation of a three-dimensional image. The invention can effectively utilize the common characteristics among the neural network learning multitasks, is hopeful to extract more comprehensive characteristics, strengthens the performance of the main task lung lobe segmentation network, and improves the segmentation capability of the deep network on lung lobes under the condition of not increasing the complexity of the deep network in actual use.",['Y02T10/40']
US11178166B2,Information leakage-aware computer aided cyber-physical manufacturing,"A methodology as described herein allows cyber-domain tools such as computer aided-manufacturing (CAM) to be aware of the existing information leakage. Then, either machine process or product design parameters in the cyber-domain are changed to minimize the information leakage. This methodology aids the existing cyber-domain and physical-domain security solution by utilizing the cross-domain relationship.","['H04L63/1433', 'B33Y50/02', 'B33Y99/00', 'G06F21/10', 'G06F21/554', 'G06F21/608', 'H04L63/1466']"
CN111797976B,"Training method, image recognition method, device, equipment and medium for neural network","The embodiment of the disclosure discloses a training method, an image recognition device, equipment and a storage medium of a neural network. The neural network includes a plurality of network layers and at least one enhancement layer disposed between the network layers, the method comprising: acquiring an original image sample; inputting the original image sample into the neural network to obtain a prediction result; obtaining a real result corresponding to the original image sample; determining a loss value according to a loss function, the prediction result and the real result, and training parameters of the neural network based on the loss value; and when the training conditions are met, removing the enhancement layer in the neural network to obtain the trained neural network. Not only can the occupancy rate of the sample to the storage space be reduced, but also the generalization performance of the neural network can be improved.","['G06N3/045', 'G06N3/084']"
CN112200244B,Intelligent detection method for anomaly of aerospace engine based on hierarchical countermeasure training,"The invention discloses an intelligent detection method for an aerospace engine abnormity based on hierarchical confrontation training, which comprises the steps of collecting original signals of the aerospace engine in a running state by using a plurality of sensors as multi-source data, intercepting a time sequence by a fixed length to obtain a multi-channel data sample set, and converting a one-dimensional sequence into a two-dimensional image; dividing a two-dimensional image sample into a training set and a test set; constructing a relatively generated confrontation network as an anomaly detection model, and performing hierarchical confrontation training by using a training set; carrying out state evaluation on the training set sample by using a training model, modeling the obtained evaluation score distribution, and calculating the score threshold of a normal sample; and using the model for test set state evaluation, aggregating neighborhood information during testing, and performing anomaly detection according to the score threshold. According to the invention, the detection capability of the model is improved through the hierarchical confrontation training, the multi-source information and the neighborhood information are fused to improve the reliability of the result, and finally, the intelligent detection of the abnormal operation of the aerospace engine can be realized.","['G06F18/2414', 'G06F17/18', 'G06F18/214', 'G06F18/25', 'G06N3/045', 'G06N3/08']"
US11301602B2,Simulation-based testing of blockchain and other distributed ledger systems,"Some embodiments of the invention provide a framework for simulating the operation of a blockchain system. Simulation may produce quantitative, practical estimates of how varying certain aspects of the system's design affects its performance, cost, and/or other metrics of interest. Some embodiments provide a unified simulation framework which enables designers and operators to use the data produced from one test or model in another, and allowing the system's parameters and/or protocol to be optimized relative to one or more objective functions.","['G06F30/20', 'G06Q30/0185', 'G06Q50/06', 'G06F2111/08', 'G06F30/27', 'G06Q2230/00', 'G06Q40/10']"
CN110490884B,Lightweight network semantic segmentation method based on countermeasure,"The invention relates to a countermeasure-based lightweight network semantic segmentation method which is used for solving the problems of low prediction accuracy, low network processing speed and difficulty in meeting the requirement of real-time prediction. The invention provides a countermeasure-based lightweight semantic segmentation method from the perspective of improving semantic segmentation speed and precision. Firstly, reducing parameter quantity in jump connection by utilizing asymmetric convolution, increasing feature map receptive field by using cavity convolution, improving network information acquisition capability by channel scrambling operation, and constructing a lightweight asymmetric coding and decoding semantic segmentation network; then, the recognition network is used for recognizing the segmented image and the calibrated semantic label by utilizing the countermeasure idea, a recognition loss function and a segmentation loss function are designed, and the segmentation network and the recognition network are alternately updated by a back propagation method until the recognition network cannot distinguish the labels generated by the segmentation network and the real labels, so that the semantic segmentation of the image is realized. The invention ensures real-time property of the segmentation network by utilizing the lightweight model and the countermeasure idea, and has higher segmentation precision.","['G06N3/045', 'G06N3/082', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US12190228B2,Generating and executing context-specific neural network models based on target runtime parameters,"The disclosed embodiments relate to a system that generates and executes a deep neural network (DNN) based on target runtime parameters. During operation, the system receives a trained original model and a set of target runtime parameters for the DNN, wherein the target runtime parameters are associated with one or more of the following for the DNN: desired operating conditions, desired resource utilization, and desired accuracy of results. Next, the system generates a context-specific model based on the original model and the set of target runtime parameters. The system also generates an operational plan for executing both the original model and the context-specific model to meet requirements of the target runtime parameters. Finally, the system controls execution of the original model and the context-specific model based on the operational plan.","['G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06V10/764', 'G06V10/768', 'H04L41/145', 'H04L41/16', 'G06N3/047']"
US20240087130A1,Autonomous multidimensional segmentation of anatomical structures on three-dimensional medical imaging,"A method for autonomous multidimensional segmentation of anatomical structures from 3D scan volumes including receiving the 3D scan volume including a set of medical scan images comprising the anatomical structures; automatically defining succeeding multidimensional regions of input data used for further processing; autonomously processing), by means of a pre-trained segmentation convolutional neural network, the defined multidimensional regions to determine weak segmentation results that define a probable 3D shape, location, and size of the anatomical structures; automatically combining multiple weak segmentation results by determining segmented voxels that overlap on the weak segmentation results, to obtain raw strong segmentation results with improved accuracy of the segmentation; autonomously filtering the raw strong segmentation results with a predefined set of filters and parameters for enhancing shape, location, size and continuity of the anatomical structures to obtain filtered strong segmentation results; and autonomously identifying classes of the anatomical structures from the filtered strong segmentation results.","['G06T7/11', 'A61B34/10', 'G06F3/0484', 'G06N3/045', 'G06T7/62', 'A61B2034/107', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
CN112800937B,Intelligent face recognition method,"The invention discloses an intelligent face recognition method, which comprises the following steps: 1) Face detection: a source gesture face picture taking a face as main content is cut from an original picture; 2) Face alignment: identifying and positioning key points of the human face in the source gesture human face picture; 3) Face gesture rotation: according to the source pose face picture and the selected pose, preserving identity information and expression information of the source pose face picture and the selected pose, and generating a target pose face picture; 4) Facial expression and identity recognition: and combining the source pose face picture and the target pose face picture, and judging the expression and the identity of the face in the picture. The invention provides three innovative points of combining an attention mechanism, generating an countermeasure network and integrated learning, and establishes an end-to-end identification method. Breaks through the limit of extreme gesture, uses the synthesized front picture for face identity and expression recognition without constraint condition, improves accuracy and robustness, and has wide application prospect in the face recognition field.","['G06V40/171', 'G06F21/32', 'G06N3/045', 'G06N3/08', 'G06V10/462', 'Y02D10/00']"
US11636370B2,Quantum computer with improved continuous quantum generator,A hybrid quantum-classical (HQC) computer which includes both a classical computer component and a quantum computer component performs generative learning on continuous data distributions. The HQC computer is capable of being implemented using existing and near-term quantum computer components having relatively low circuit depth.,"['G06N10/00', 'G06N10/60', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/094']"
US10075846B1,Method for continuous user authentication with wearables,"Systems and methods for continuous and transparent verification, authentication, and identification of individuals are provided. A method can include detecting a signal from a sensor embedded in a wearable device, determining a set of features unique to the wearer of the wearable device, creating a user profile of that individual, detecting a signal from a sensor of an unknown individual, determining a set of features unique to the unknown individual, and comparing the features of the unknown individual to the previously created user profile.","['H04W12/065', 'H04W12/06', 'H04L63/0861', 'H04L63/102', 'H04W12/08', 'H04W12/086', 'H04W12/33', 'H04W88/06']"
US11354778B2,Systems and methods for contrastive learning of visual representations,"Provided are systems and methods for contrastive learning of visual representations. In particular, the present disclosure provides systems and methods that leverage particular data augmentation schemes and a learnable nonlinear transformation between the representation and the contrastive loss to provide improved visual representations. In contrast to certain existing techniques, the contrastive self-supervised learning algorithms described herein do not require specialized architectures or a memory bank. Some example implementations of the proposed approaches can be referred to as a simple framework for contrastive learning of representations or “SimCLR.” Further example aspects are described below and provide the following benefits and insights.","['G06T5/002', 'G06T11/60', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/096', 'G06T11/001', 'G06T3/40', 'G06T3/60', 'G06T5/20', 'G06T5/70', 'G06T7/90', 'G06V10/764', 'G06V10/82', 'G06V20/35', 'G06N3/044', 'G06N3/048', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/22']"
US11823425B2,Few-shot defect detection method based on metric learning,"A few-shot defect detection method based on metric learning, including: (S1) performing data enhancement on a to-be-detected few-shot defect data set through a G2-Generative adversarial network (G2-GAN); (S2) extracting features of a defect data set similar to the to-be-detected few-shot defect data set based on an adaptive convolution kernel-based convolutional neural network (SKM-CNN) to generate a pre-training model; and (S3) transferring the pre-training model to a few-shot defect detection network (S2D2N) based on metric learning; and performing target feature extraction and metric learning in sequence to realize rapid identification and location of defects.","['G06F18/214', 'G06V10/774', 'G06F18/22', 'G06F18/24', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T7/0004', 'G06T7/73', 'G06V10/454', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30164', 'G06V2201/06']"
CN112634429B,Rock core three-dimensional image reconstruction method based on mixed depth generation model,"The invention discloses a rock core three-dimensional image reconstruction method based on a mixed depth generation model, which comprises the following steps of: (1) Preprocessing a binary three-dimensional rock core CT image to construct a training sample set; (2) Constructing a three-dimensional reconstruction hybrid network model based on a fusion network of a variational self-encoder and a generation countermeasure network; (3) defining a porosity-based constraint function; (4) designing a network optimization training strategy; (5) And finishing the three-dimensional reconstruction of the core CT image based on the model and the training strategy. The invention can improve the stability of network training, has better reconstruction effect on homogeneous and heterogeneous core CT images, and has important application value in the field of petroleum geology.","['G06T17/00', 'G06T11/003', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US11100506B2,Fraud score manipulation in self-defense of adversarial artificial intelligence learning,"A system and method for programmatically revealing misleading confidence values in Fraud Score is presented to protect artificial intelligence models from adversarial neural networks. The method is used to reduce an adversarial learning neural network model effectiveness. With the score manipulation implemented, the adversary models are shown to systematically become less successful in predicting the true behavior of the Fraud detection artificial intelligence model and what it will flag as fraudulent transactions, thus reducing the true fraud dollars penetrated or taken by adversaries.","['G06Q20/4016', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/08', 'G06N3/09', 'G06N3/094']"
US11448753B2,System and method for transferring electro-optical (EO) knowledge for synthetic-aperture-radar (SAR)-based object detection,"Described is a system for transferring learned knowledge from an electro-optical (EO) domain to a synthetic-aperture-radar (SAR) domain. The system uses a measured similarity between the EO domain and the SAR domain to train a model for classifying SAR images using knowledge previously learned from the electro-optical (EO) domain. Using the trained model, a SAR image is processed to determine regions of interest in the SAR image. A region of interest is classified to determine whether the region of interest corresponds to an object of interest, and classified regions of interest that contain the object of interest are output. The object of interest is displayed on a visualization map, and the visualization map is automatically updated to reflect a change in position of the object of interest.","['G06N3/088', 'G01S13/867', 'G01S13/9027', 'G01S7/417', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T7/74', 'G06V20/13', 'G06T2207/10044', 'G06T2207/20081', 'G06T2207/20084']"
WO2022048182A1,"Image style transfer method and apparatus, and image style transfer model training method and apparatus","Disclosed are an image style transfer method and apparatus, and an image style transfer model training method and apparatus. The image style transfer method comprises: respectively inputting first-style images and second-style images into a content encoder and a style encoder in an encoder network, and respectively extracting content encoded feature images and style encoded feature images; and respectively inputting the style encoded feature images and the content encoded feature images into a decoder network, so as to obtain target images that are transferred from a first style to a second style, wherein an image style transfer model composed of the encoder network and the decoder network is obtained by means of performing pre-training on the basis of image training samples that comprise a plurality of first-style images and second-style images, and instance images cropped from the image training samples. By using the present invention, the style transfer adaptability to a plurality of different scenarios can be improved, the problems of image blur, and poor instance effects in an image after style transfer can be ameliorated, and coarse-grained and fine-grained high-quality image style transfer can also be achieved.","['G06T3/04', 'G06T7/11', 'G06T9/002', 'G06T2207/10024', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
CN112507997B,Face super-resolution system based on multi-scale convolution and receptive field feature fusion,"The invention discloses a face super-resolution system based on multi-scale convolution and receptive field feature fusion, which comprises a coarse super-resolution module, a coarse up-sampling module, a first multi-scale convolution module, a high-low frequency enhancement module, a fine super-resolution module, a fine up-sampling module, a third-degree scale convolution module, an image enhancement module and a confrontation network which are sequentially connected; the face key point extraction network and the high-low frequency enhancement module are respectively connected with the fusion module, and the fusion module and the coarse super-resolution module are respectively connected with the fine super-resolution module. The system is suitable for enhancing the human face, particularly the human face with small resolution, and has the characteristics of high amplification factor and high-frequency detail reduction degree through high-low frequency feature interactive enhancement and human face priori knowledge utilization; the adoption of the receptive field module is helpful for extracting detail characteristics and reducing the computational complexity.","['G06V40/168', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/084', 'G06V10/449']"
US10984532B2,Joint deep learning for land cover and land use classification,"Land cover (LC) and land use (LU) have commonly been classified separately from remotely sensed imagery, without considering the intrinsically hierarchical and nested relationships between them. A novel joint deep learning framework is proposed and demonstrated for LC and LU classification. The proposed Joint Deep Learning (JDL) model incorporates a multilayer perceptron (MLP) and convolutional neutral network (CNN), and is implemented via a Markov process involving iterative updating. In the JDL, LU classification conducted by the CNN is made conditional upon the LC probabilities predicted by the MLP. In turn, those LU probabilities together with the original imagery are re-used as inputs to the MLP to strengthen the spatial and spectral feature representation. This process of updating the MLP and CNN forms a joint distribution, where both LC and LU are classified simultaneously through iteration.","['G06T7/11', 'G06F17/18', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/08', 'G06N3/09', 'G06T7/10', 'G06V10/764', 'G06V10/82', 'G06V20/13', 'G06N20/10', 'G06N7/01', 'G06T2207/20084', 'G06T2207/30181']"
CN115857447B,Operation monitoring method and system for complex industrial systems based on digital twin,"The invention discloses a complex industrial system operation monitoring method and system based on digital twinning, comprising the following steps: acquiring equipment component information in an industrial system, and mapping with an entity of the industrial system to acquire a three-dimensional simulation model of the industrial system; constructing a mapping relation between a three-dimensional simulation model of an industrial system and real-time data, and generating a digital twin body model of the industrial system; the method comprises the steps of obtaining twin data, carrying out data fusion on the twin data and monitoring working condition data, and extracting current data characteristics of an industrial system; constructing an operation state recognition model based on deep learning, inputting current data characteristics into the operation state recognition model, and evaluating the operation state of the industrial system; and performing fault diagnosis according to the evaluation result, and generating a corresponding operation and maintenance scheme through the fault diagnosis. The invention realizes the on-line monitoring of the operation health condition of the complex industrial system, ensures the safe and stable operation on site, reduces the probability of the occurrence of potential safety hazard accidents of equipment and greatly saves the cost of human resources.",['Y02P90/02']
US20220292240A1,Artificial intelligence determination of building metrics for code compliance,"Artificial Intelligence systems receive two dimensional design plans (e.g., physical, or electronic documents) that are processed to mimic the perception, learning, problem-solving, and decision-making formerly performed by human workers assessing the design plans for compliance with an applicable code. AI analysis converts vector images into patterns that are conducive to machine learning and generates a dynamic interface that allows a user to interact with the AI findings. The AI assesses whether a building described in the design plans complies with a relevant code set forth by an authority having jurisdiction. Codes may include, for example, codes enforcing fire safety and the Americans with Disabilities Act.","['G06F30/27', 'G06F30/13', 'G06N3/0475', 'G06N3/08']"
US10949743B2,Method and system for implementing reinforcement learning agent using reinforcement learning processor,"The embodiments herein disclose a system and method for implementing reinforcement learning agents using a reinforcement learning processor. An application-domain specific instruction set (ASI) for implementing reinforcement learning agents and reward functions is created. Further, instructions are created by including at least one of the reinforcement learning agent ID vectors, the reinforcement learning environment ID vectors, and length of vector as an operand. The reinforcement learning agent ID vectors and the reinforcement learning environment ID vectors are pointers to a base address of an operations memory. Further, at least one of said reinforcement learning agent ID vector and reinforcement learning environment ID vector is embedded into operations associated with the decoded instruction. The instructions retrieved by agent ID vector indexed operation are executed using a second processor, and applied onto a group of reinforcement learning agents. The operations defined by the instructions are stored in an operations storage memory.","['G06N3/08', 'G06N20/00', 'G06N3/004', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0475', 'G06N3/06', 'G06N3/092', 'G06N3/094', 'G06N5/043', 'G06N7/005', 'G06N7/01']"
US9754221B1,Processor for implementing reinforcement learning operations,"A reinforcement learning processor specifically configured to execute reinforcement learning operations by the way of implementing an application-specific instruction set is envisaged. The application-specific instruction set incorporates ‘Single Instruction Multiple Agents (SIMA)’ instructions. SIMA type instructions are specifically designed to be implemented simultaneously on a plurality of reinforcement learning agents which interact with corresponding reinforcement learning environments. The SIMA type instructions are specifically configured to receive either a reinforcement learning agent ID or a reinforcement learning environment ID as the operand. The reinforcement learning processor uses neural network data paths to communicate with a neural network which in turn uses the actions, state-value functions, Q-values and reward values generated by the reinforcement learning processor to approximate an optimal state-value function as well as an optimal reward function.","['G06N20/00', 'G06N99/005', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/092', 'G06N3/094']"
US10621695B2,Video super-resolution using an artificial neural network,"According to one implementation, a video processing system includes a computing platform having a hardware processor and a system memory storing a software code including an artificial neural network (ANN). The hardware processor is configured to execute the software code to receive a first video sequence having a first display resolution, and to produce a second video sequence based on the first video sequence using the ANN. The second video sequence has a second display resolution higher than the first display resolution. The ANN is configured to provide sequential frames of the second video sequence that are temporally stable and consistent in color to reduce visual flicker and color shifting in the second video sequence.","['G06T3/4046', 'G06T3/4007', 'G06T3/4053', 'G06T2207/10016', 'G06T2207/20081']"
US12148408B2,Systems and methods for transforming digital audio content into visual topic-based segments,"A system for platform-independent visualization of audio content, in particular audio tracks utilizing a central computer system in communication with user devices via a computer network. The central system utilizes various algorithms to identify spoken content from audio tracks and selects visual assets associated with the identified content. Thereafter, a visualized audio track is available for users to listen and view. Audio tracks, for example Podcasts, may be segmented into topical audio segments based upon themes or topics, with segments from disparate podcasts combined into a single listening experience, based upon certain criteria, e.g., topics, themes, keywords, and the like.","['G06F16/61', 'G10H1/0008', 'G06F16/685', 'G06F16/686', 'G10H2220/106']"
US10552712B2,Training device and training method for training image processing device,"The disclosure relates to a training device and method for an image processing device and an image processing device. The training device is used for training first and second image processing units, comprising: a training unit to input a first realistic image without a specific feature into the first image processing unit to generate a first generated image with the specific feature through first image processing, and to input a second realistic image with the specific feature into the second image processing unit to generate a second generated image without the specific feature through second image processing; and a classifying unit performing classification processing to discriminate realistic and generated images, wherein the training unit performs first training processing of training the classifying unit based on the realistic and generated images, and performs second training processing of training the first and second image processing units based on the training result.","['G06V10/82', 'G06K9/6256', 'G06F18/214', 'G06F18/217', 'G06F18/2431', 'G06F18/285', 'G06K9/00281', 'G06K9/6227', 'G06K9/6262', 'G06K9/628', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06V40/171', 'G06V40/172']"
US12045961B2,Image denoising method and apparatus based on wavelet high-frequency channel synthesis,"Disclosed is an image denoising method and apparatus based on wavelet high-frequency channel synthesis. Image data are expanded to a plurality of frequency-domain channels, a plurality of “less-noise” channels and a plurality of “more-noise” channels are grouped through a noise-sort algorithm, and a denoising submodule and a synthesis submodule based on style transfer are combined to form a generative network. A discriminative network is established to add a constraint to the global loss function. After iteratively training the GAN model described above, the denoised image data can be obtained through wavelet inverse transformation. The disclosed algorithm can effectively solve the problem of “blurring” and “loss of details” introduced by traditional filtering or CNN-based deep learning methods, which is especially suitable for noise-overwhelmed image data or high dimensional image data.","['G06T5/70', 'G06N3/084', 'G06T11/00', 'G06T5/10', 'G06T5/60', 'G06T2207/20064', 'G06T2207/20081', 'G06T2207/20084']"
US12175364B2,Reinforcement-learning modeling interfaces,"A system including one or more processors and one or more non-transitory computer-readable media storing computing instructions that, when executed on the one or more processors, perform certain acts. The acts can include transmitting a user interface to be displayed to a user. The user interface can include one or more first interactive elements. The one or more first interactive elements display policy settings of a reinforcement learning model. The one or more first interactive elements are configured to allow the user to update the policy settings of the reinforcement learning model. The acts also can include receiving one or more inputs from the user. The inputs include one or more modifications of at least a portion of the one or more first interactive elements of the user interface to update the policy settings of the reinforcement learning model. The acts additionally can include training a neural network model using a reinforcement learning model with the policy settings as updated by the user to adjust rewards assigned in the reinforcement learning model. Other embodiments are described.","['G06N20/10', 'G06N3/006', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/092', 'G06N3/098', 'G06N3/0985', 'H04L41/12', 'H04L41/145', 'H04L41/16', 'H04L41/22', 'H04L45/08']"
US11652627B2,Systems and methods for distributed key storage,"A system for distributed key storage, comprising a requesting device communicatively connected to a plurality of distributed storage nodes, the requesting device designed and configured to receive at least a confidential datum, select at least a distributed storage node of a plurality of distributed storage nodes, whereby selecting further comprises receiving a storage node authorization token from the at least a distributed storage node, querying an instance of a distributed authentication listing containing authentication information using at least a datum of the storage node authorization token, retrieving an authentication determination from the instance of the authentication listing, and selecting the at least a distributed storage node as a function of the authentication determination, generate at least a retrieval authentication datum, and transmit the at least a confidential datum and the at least a retrieval verification datum to the at least a distributed storage node.","['H04L9/3239', 'G06F21/602', 'G06F21/6209', 'G06F21/6218', 'G06F21/64', 'H04L63/0807', 'H04L63/205', 'H04L9/085', 'H04L9/088', 'H04L9/0894', 'H04L9/3213', 'H04L9/3218', 'H04L9/50', 'H04L2209/56', 'H04L2463/121']"
US20190197358A1,Generative Adversarial Network Medical Image Generation for Training of a Classifier,Mechanisms are provided to implement a machine learning training model. The machine learning training model trains an image generator of a generative adversarial network (GAN) to generate medical images approximating actual medical images. The machine learning training model augments a set of training medical images to include one or more generated medical images generated by the image generator of the GAN. The machine learning training model trains a machine learning model based on the augmented set of training medical images to identify anomalies in medical images. The trained machine learning model is applied to new medical image inputs to classify the medical images as having an anomaly or not.,"['G06V10/82', 'G06K9/6259', 'A61B6/5217', 'G06F18/2155', 'G06F18/24', 'G06K9/6267', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/082', 'G06N5/022', 'G06N99/005', 'G06T7/0012', 'G06T7/0014', 'G06V10/764', 'G06V10/7753', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30096', 'G06V2201/03']"
US20200198130A1,Robotic systems and methods for robustly grasping and targeting objects,"Embodiments are generally directed to generating a training dataset of labelled examples of sensor images and grasp configurations using a set of three-dimensional (3D) models of objects, one or more analytic mechanical representations of either or both of grasp forces and grasp torques, and statistical sampling to model uncertainty in either or both sensing and control. Embodiments can also include using the training dataset to train a function approximator that takes as input a sensor image and returns data that is used to select grasp configurations for a robot grasping or targeting mechanism.","['B25J9/163', 'B25J9/161', 'B25J9/1697', 'G06K9/00208', 'G06V20/647', 'B25J9/1612', 'G05B2219/39082', 'G05B2219/39505', 'G05B2219/39531', 'G05B2219/39542', 'G05B2219/40053', 'G05B2219/40155', 'G05B2219/40571']"
US11922923B2,Optimal human-machine conversations using emotion-enhanced natural speech using hierarchical neural networks and reinforcement learning,"A system and method for emotion-enhanced natural speech using dilated convolutional neural networks, wherein an audio processing server receives a raw audio waveform from a dilated convolutional artificial neural network, associates text-based emotion content markers with portions of the raw audio waveform to produce an emotion-enhanced audio waveform, and provides the emotion-enhanced audio waveform to the dilated convolutional artificial neural network for use as a new input data set.","['G10L13/10', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G10L13/033', 'G10L13/047', 'G10L25/63']"
US12298524B2,Multi-lens system for imaging in low light conditions and method,"Described herein are imaging devices and associated methods. Devices and methods are described that include a plurality of topological phase modulators. In one example, the plurality of topological phase modulators includes an array of spiral vortices. Devices and methods are described that include a neural network to reconstruct images using data from the plurality of topological phase modulators.","['G02B27/0905', 'G02B27/4205', 'G02B3/0006', 'G06N3/04', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'B82Y20/00', 'G02B27/283']"
US10426442B1,Adaptive image processing in assisted reproductive imaging modalities,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['A61B8/085', 'A61B8/5207', 'A61B8/5223', 'A61D19/02', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H50/20', 'A61B8/0866', 'A61B8/483', 'G06T2207/10136', 'G06T2207/30044', 'Y02A90/10']"
US12067487B2,Method and apparatus employing distributed sensing and deep learning for dynamic spectrum access and spectrum sharing,"The present application describes a method for training a neural network via deep reinforcement learning (DRL) in a RF network. The method includes a step of receiving, via the neural network, a policy from a third party. The method also includes a step of receiving, via the neural network, features of plural telecommunication groups located in an RF network. The method also includes a step of observing, via the neural network, a graphical representation of the received features of the plural telecommunication groups in the RF network. The method further includes a step of assigning, based on the observation, one of the plural telecommunication groups to one of plural channels in the RF network. The method even further includes a step of determining, via the neural network, a change in throughput of the RF network based on the assignment. The method yet even further incudes as step of adjusting, based on the determined change in throughput, the policy received from the third party.","['H04W24/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/098', 'H04L41/0894', 'H04L41/16', 'H04L43/0888', 'H04W16/00', 'H04W16/02', 'H04W16/18', 'H04W24/06', 'H04W24/08', 'H04W24/10', 'H04W28/22', 'H04W16/14']"
US12020165B2,System and method for transforming holographic microscopy images to microscopy images of various modalities,"A trained deep neural network transforms an image of a sample obtained with a holographic microscope to an image that substantially resembles a microscopy image obtained with a microscope having a different microscopy image modality. Examples of different imaging modalities include bright-field, fluorescence, and dark-field. For bright-field applications, deep learning brings bright-field microscopy contrast to holographic images of a sample, bridging the volumetric imaging capability of holography with the speckle-free and artifact-free image contrast of bright-field microscopy. Holographic microscopy images obtained with a holographic microscope are input into a trained deep neural network to perform cross-modality image transformation from a digitally back-propagated hologram corresponding to a particular depth within a sample volume into an image that substantially resembles a microscopy image of the sample obtained at the same particular depth with a microscope having the different microscopy image modality.","['G06N3/084', 'G02B21/0008', 'G02B21/365', 'G03H1/0005', 'G03H1/0443', 'G03H1/0866', 'G03H1/268', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T5/70', 'G06T7/50', 'G06V10/764', 'G06V10/82', 'G06V20/69', 'G02B21/0016', 'G03H2001/005', 'G03H2001/0447', 'G03H2001/0883', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20081', 'G06T2207/20084']"
CN112633280B,A method and system for generating an adversarial sample,"The invention discloses a method and a system for generating a confrontation sample. The disclosed method includes acquiring an interpretable area image of an original image; determining a proper pixel threshold, generating a disturbance adding template of the original image under the threshold according to the interpretable area image, adding superposition disturbance at the corresponding pixel point of the original image according to the 0 pixel point value in the disturbance adding template, and generating a confrontation sample of the original image. The disclosed system is a system for performing the challenge sample generation method. The method can ensure the perceptibility and the aggressivity of the countermeasure sample, human eyes cannot easily find the disturbance added in the countermeasure sample, and the countermeasure sample is misclassified by the verification model with higher probability.","['G06V10/25', 'G06F18/213', 'G06F18/214', 'G06F18/241', 'G06N3/045', 'G06N3/084']"
US10990096B2,Reinforcement learning on autonomous vehicles,The present disclosure generally relates to methods and systems for controlling an autonomous vehicle. The vehicle may collect scenario information from one or more sensors mounted on a vehicle. The vehicle may determine a high-level option for a fixed time horizon based on the scenario information. The vehicle may apply a prediction algorithm to the high-level option to mask undesired low-level behaviors for completing the high-level option where a collision is predicted to occur. The vehicle may evaluate a restricted subspace of low-level behaviors using a reinforcement learning system. The vehicle may control the vehicle to perform the high-level option by executing a low-level behavior selected from the restricted subspace. The vehicle may adjust the reinforcement learning system by evaluating a metric of the executed low-level behavior.,"['G06N3/08', 'G05D1/0088', 'G06N3/006', 'G06N3/0499', 'G06N3/092']"
US10696298B2,Path prediction for a vehicle,"A method and a system for predicting a near future path and an associated output control signal for a vehicle. Prediction sensor data, vehicle driving data, and road data are collected. An input control signal indicative of an intended driving action is received. The sensor data and the vehicle driving data are pre-processed to provide a set of object data comprising a time series of previous positions of a respective object relative the vehicle, a time series of the previous headings of the object, and a time series of previous velocities of the object. The object data, the road data, the vehicle driving data, the control signal, and the sensor data are processed in a deep neural network. Based on the processing in the deep neural network, a predicted path output and an output control signal are provided.","['B60W30/09', 'B60W30/095', 'B60W30/0953', 'B60W30/0956', 'B60W30/10', 'B60W50/0097', 'B60W60/0027', 'F02D41/1405', 'G06F16/29', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'B60W2050/0063', 'B60W2050/0075', 'B60W2050/0089', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2520/10', 'B60W2520/14', 'B60W2552/00', 'B60W2552/10', 'B60W2552/53', 'B60W2554/00', 'B60W2554/20', 'B60W2554/4029', 'B60W2554/806', 'B60W2556/10', 'B60W2900/00', 'F02D2200/701', 'F02D2200/702']"
US11640527B2,Near-zero-cost differentially private deep learning with teacher ensembles,"Systems and methods are provided for near-zero-cost (NZC) query framework or approach for differentially private deep learning. To protect the privacy of training data during learning, the near-zero-cost query framework transfers knowledge from an ensemble of teacher models trained on partitions of the data to a student model. Privacy guarantees may be understood intuitively and expressed rigorously in terms of differential privacy. Other features are also provided.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06T2207/00', 'G06T2207/20081', 'G06T2207/20084']"
US20210049811A1,Method and System for Remote Clothing Selection,"The method for remote clothing selection includes determination of anthropometric dimensional parameters of a user, automatic assessment of correspondence of a garment to the shape and body measurements of a user, determination and provision of recommendations to a user on the selection of a particular garment and, optionally, visualization of a garment on a digital avatar of this user in the virtual fitting room, including optional change of his/her pose. The invention provides an increase in the efficiency of remote clothing selection by a user, an improvement in user's experience of remote purchase, an increase in user satisfaction and, ultimately, an increase in online sales of clothing and a decrease in the proportion of clothing returned after a purchase due to unsatisfactory matching to the shape and measurements of user's body.","['G06T17/00', 'G06Q30/0643', 'G06T17/20', 'G06T19/20', 'G06T7/50', 'G06T7/60', 'G06T2200/04', 'G06T2207/10028', 'G06T2207/20028', 'G06T2207/30196', 'G06T2210/56', 'G06T2219/2021']"
CN107945118B,Face image restoration method based on generating type confrontation network,"The invention discloses a face image restoration method based on a generative confrontation network, which comprises the following steps: (1) collecting a large number of images containing complete and clear faces and establishing a face image database; (2) constructing a generative confrontation network; (3) training the generative confrontation network, and optimizing parameters of a generator and a discriminator in the generative confrontation network; (4) inputting random vectors which are subject to normal distribution into a trained generator to generate a face image, comparing a complete lossless region of the face image to be restored with a corresponding region of the generated image, continuously adjusting the input vectors until the two are similar, and finally replacing the pixel values of the shielded or damaged region in the face image to be restored with the pixel values of the corresponding region of the generated face image. Aiming at the problem of repairing the shielded or damaged face image, the invention adopts the generation type countermeasure network with the deep learning structure, thereby effectively solving the problem of image repairing in the image processing.","['G06T5/77', 'G06T3/40', 'G06T2207/20081', 'G06T2207/30201']"
WO2022242029A1,"Generation method, system and apparatus capable of visual resolution enhancement, and storage medium","A generation method, system and apparatus capable of visual resolution enhancement, and a storage medium. An acquired low-resolution single image to be processed is subjected to resolution processing by means of a single-image training model established by using training samples and a preset loss function, which training samples contain a high-resolution single image sample, a low-resolution single image sample and corresponding image description information samples thereof, such that the effect of restoring the low-resolution single image to a high-resolution single image can be accurately and efficiently realized. A single image having a higher resolution can be acquired on the basis of specific image description information prior, and high-frequency information of the single image can be restored, such that an output high-resolution single image contains more texture structure details, and the definition of the single image is thus improved. The present invention can be widely applied to the technical field of image processing.","['G06T3/4053', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/084']"
AU2020103905A4,Unsupervised cross-domain self-adaptive medical image segmentation method based on deep adversarial learning,"The invention provides an unsupervised cross-domain self-adaptive medical image segmentation method based on deep adversarial learning, which comprises the following steps: constructing deep encoder-decoder fully convolutional network segmentation model, constructing a domain discriminator network model, segmentation system pre-training and parameter optimization, constructing the target domain MRI automatic semantic segmentation system to form an MRI semantic segmentation image. In this application, the deep encoder decoder fully convolutional neural network is adopted to model segmentation system, and the high-level semantic features and low-level detail features are jointly utilized to predict pixel label; and the domain discriminaor network is used to guide the segmentation model to learn domain invariant features and strong generalized segmentation functions through adversarial learning, so as to minimize the data distribution difference between the source domain and the target domain indirectly, so that the learned segmentation system has the same segmentation accuracy in the target domain as in the source domain, which improves the cross domain generalization performance of the MRI automatic semantic segmentation method, and realizes the unsupervised cross domain adaptive MRI accurate segmentation. -1/4 MRI segmentation image MRI images and Training MRI brain tumor automatic segmentation segmentation labels of -system with the data set of the source domain Label predictor the source domain MR I images and Feature extractor for the source domain (fixed domain labels of the _ parameters) source domain Training domain discriminator adversarial training MRI images and Feature extractor for domain labels of the Training feature extractor for the target domain the target domain target domain images ofthe trget domain Figure 1","['G06T7/0012', 'A61B5/0033', 'A61B5/05', 'A61B5/7267', 'G06N3/0455', 'G16H30/40', 'G06N20/00', 'G06T2207/10088', 'G06T2207/30016', 'G06T2207/30096', 'G06V2201/03']"
US20210110306A1,Meta-transfer learning via contextual invariants for cross-domain recommendation,"Systems, apparatuses, methods, and computer-readable media are provided to alleviate data sparsity in cross-recommendation systems. In particular, some embodiments are directed to a recommendation framework that addresses data sparsity and data scalability challenges seamlessly by meta-transfer learning contextual invariances cross domain, e.g., from dense source domain to sparse target domain. Other embodiments may be described and/or claimed.","['G06N3/08', 'G06N20/00', 'G06N3/045', 'G06N5/04']"
US11726844B2,Data sharing system and data sharing method therefor,"The present disclosure provides a processing device for performing generative adversarial network and a method for machine creation applying the processing device. The processing device includes a memory configured to receive input data including a random noise and reference data, and store a discriminator neural network parameter and a generator neural network parameter, and the processing device further includes a computation device configured to transmit the random noise input data into a generator neural network and perform operation to obtain a noise generation result, and input both of the noise generation result and the reference data into a discriminator neural network and perform operation to obtain a discrimination result, and further configured to update the discriminator neural network parameter and the generator neural network parameter according to the discrimination result.","['G06F9/544', 'G06F12/0875', 'G06F13/28', 'G06F15/163', 'G06F15/167', 'G06F30/27', 'G06F9/223', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06F2212/452', 'H04L2012/5686']"
US10880330B2,Systems and methods for detection of infected websites,"System and method for detecting an infected website are disclosed. A semantic finder receives top-level domains and identifies keywords of the top-level domains representing a predetermined semantics. The keywords are compared with irrelevant bad terms to find at least one irrelevant term. An inconsistency searcher searches the top-level domains and detects at least one fully-qualified domain name carrying the at least one irrelevant term. A context analyzer evaluates context information associated with the irrelevant term, identifies at least one frequently-used term identified in the context information, and determines whether the at least one frequently-used term is unrelated to a generic content of the at least one fully-qualified domain name An irrelevant bad term collector extracts the at least one frequently-used term unrelated to the generic content and adds the extracted frequently-used term to an irrelevant bad term list for detecting the infected website.","['H04L63/1483', 'G06F16/9535', 'G06F21/566', 'G06F40/205', 'G06F40/30', 'H04L63/1416']"
CN111295884B,Image processing apparatus and image processing method,"An image processing device (100) is provided with a memory (120) and a circuit (110); a circuit (110) performs processing for bringing the compression-released image close to the original image by using a neural network model that performs learning for bringing the compression-released image close to the original image; the neural network model comprises more than 1 convolution block and more than 1 residual block; 1 or more convolution blocks are processing blocks including convolution layers, respectively; the 1 or more residual blocks are respectively the following processing blocks: the method includes including a convolution group configured of at least 1 of 1 or more convolution blocks, inputting data input to the residual block to the convolution group included in the residual block, and adding the data input to the residual block to data output from the convolution group.","['H04N19/80', 'H04N19/865', 'G06T9/002', 'H04N19/85']"
US11533332B2,Executing enterprise process abstraction using process aware analytical attack graphs,"Methods, systems, and computer-readable storage media for receiving a process aware AAG from computer-readable memory, the process aware AAG having been generated from the AAG, processing the process aware AAG to consolidate asset nodes to group nodes at least partially by providing metadata describing an asset node to a set of properties of a group node and pruning the asset node and any child nodes of the asset node from the process aware AAG, providing the aggregation graph by identifying relationships between group nodes and, for each relationship, inserting an edge between group nodes, and aggregating one or more of a set of node properties and a set of edge properties for each group node or edge, respectively, storing the aggregation graph to computer-readable memory, and executing one or more remedial actions in the enterprise network in response to analytics executed on the aggregation graph.","['H04L63/1425', 'H04L41/0893', 'H04L41/22', 'H04L63/1416', 'H04L63/1433', 'H04L63/145', 'H04L63/20']"
CN111028306B,Fast Magnetic Resonance Imaging Method Based on AR2 U-Net Neural Network,"The invention discloses a rapid magnetic resonance imaging method based on an AR2U-Net neural network, which improves the existing R2U-Net convolutional neural network, adds an attention gate module on the basis of the R2U-Net convolutional neural network, uses an AG trained model to implicitly learn and restrain irrelevant areas in an input image, and simultaneously highlights obvious characteristics useful for specific tasks, so that the AR2U-Net convolutional neural network only needs a small amount of training data under the condition of reconstructing a homogeneous image. For the problem that the swing amplitude of the optimized loss function is overlarge in updating, the invention adopts the Adam optimization algorithm to replace the conventional SGD optimization algorithm, so that the convergence speed of a convolution network can be further accelerated, the problem that training is finished too early can be effectively prevented, and for the processing of the learning rate, the learning can be stably reduced by adopting a polynomial attenuation strategy, and the reduction is faster along with the increase of the number of rounds.","['G06T11/005', 'G06N3/045', 'G06N3/084', 'G06T11/006', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/30']"
US11999364B2,Systems and methods for intrusion detection in vehicle systems,"A vehicle control system (VCS) for a vehicle may include an in-vehicle bus and an intrusion detection system (IDS). The IDS may: calculate a planned output of the vehicle based on a message of a message stream received from at least one electronic control unit (ECU) coupled to the in-vehicle bus, calculate a reachable set based on an uncertainty metric, and identify an intrusion of the VCS based on a comparison of the planned output and the reachable set.","['B60W50/0205', 'H04L63/1466', 'B60W50/029', 'B60W50/038', 'B60W60/00188', 'B60W60/0053', 'G06N3/006', 'G06N3/047', 'G06N3/08', 'G06N7/01', 'H04L63/1416', 'H04L63/1425', 'B60W2050/0292', 'B60W2050/046']"
CN109493303B,An Image Dehazing Method Based on Generative Adversarial Networks,"An image defogging method based on generation of a countermeasure network, the method comprising: 1) acquiring sample data; 2) the real foggy image in the sample data is used as input data of a first generator, and the first generator generates a primary fogless image; the real fog-free image in the sample data is used as input data of a second generator, and the second generator generates a primary fog-containing image; the first discriminator feeds back the error between the primary foggy image and the real foggy image to the second generator, the second discriminator feeds back the error between the primary foggy image and the real foggy image to the first generator, and the second generator and the first generator reduce the error and improve the truth of the generated images; the generator and the discriminator carry out repeated confrontation training to obtain an optimal defogging network model; 3) and (5) defogging the image. The method adopts the generation of the countermeasure network structure and the loss function, network training does not need the fog-free matching images of the same scene, and simultaneously ensures that the colors of the images before and after defogging are not distorted.","['G06T5/73', 'G06N3/045', 'G06T2207/10004', 'G06T2207/20081']"
US10749888B2,Prerequisite quantitative risk assessment and adjustment of cyber-attack robustness for a computer system,"Aspects of the disclosure relate to assessing and adjusting robustness to cyber-attacks of a computer system. The capability of defending against cyber-attacks by cyber-tools (via protection methods) is mapped to one or more attack vectors. One or more cyber-tools may be activated based on the capability mapping. Based on protection data generated by the computer system, an assessment computing device determines a cyber-robustness metric for the one or more cyber-tools and may invoke a reconfiguration of the cyber-tools to increase the cyber-robustness of the computer system. A machine learning machine may process the protection data, such as log data, to detect one or more patterns to determine an effectiveness of the activated cyber-tools. With some embodiments, the machine learning machine groups the protection data using a subset of variables and forms meta structures from the subset.","['H04L63/1433', 'G06F21/577', 'G06N20/00', 'H04L63/1425']"
US11068593B2,Using LSTM encoder-decoder algorithm for detecting anomalous ADS-B messages,"A method for detecting anomalous ADS-B messages in airplanes and air-traffic control system, comprising: extracting features from application level data, which is information broadcasted in said ADS-B messages, contextual data and flight plans; analyzing said extracted features and computing relative measures of a flight based on said extracted features; training a machine learning model to represent a benign ADS-B messages; applying said machine learning model on said extracted features thereby deriving a reputation score for said ADS-B message; issuing a decision based on said score, thereby recognizing an attack and issuing an alarm regarded said recognized attack.","['G06F21/566', 'G06F11/00', 'G06F21/554', 'G06F21/64', 'G06N20/00', 'G06N3/042', 'G06N3/0427', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N7/005', 'G06N7/01', 'G08G5/00', 'G08G5/0004', 'G08G5/0008', 'G08G5/0013', 'G08G5/0021', 'G08G5/003', 'G08G5/0056', 'G08G5/0095', 'G08G5/20', 'G08G5/21', 'G08G5/25', 'G08G5/26', 'G08G5/30', 'G08G5/55', 'G08G5/58', 'G06F2221/034', 'G06N20/10', 'G06N20/20', 'G06N5/003', 'G06N5/01']"
US11907234B2,Software agents facilitating affective computing applications,"Software agents collect measurements of affective response and provide them in a selective manner that maintains user privacy. In one embodiment, a sensor takes measurements of affective response of the user. A computer receives a request for an affective value indicative of an emotional response to an experience. The computer selects, from among the measurements, a certain measurement of affective response of the user that corresponds to an event in which the user had the experience. The computer then utilizes a model to calculate, based on the certain measurement, the affective value indicative of the emotional response of the user to experience. Optionally, the model is generated based on previously taken measurements of affective response of the user, taken while the user had various experiences, and indications of emotional responses the user had while said previously taken measurements were taken. The computer sends the affective value to fulfil the request.","['G06F16/24578', 'G06F16/2358', 'G06F16/24573', 'G06F16/24575', 'G06F16/337', 'G06F16/904', 'G06F16/9535', 'G06Q10/04', 'G06Q10/067', 'G06Q30/0203', 'G06Q30/0282']"
US10565758B2,Neural face editing with intrinsic image disentangling,"Techniques are disclosed for performing manipulation of facial images using an artificial neural network. A facial rendering and generation network and method learns one or more compact, meaningful manifolds of facial appearance, by disentanglement of a facial image into intrinsic facial properties, and enables facial edits by traversing paths of such manifold(s). The facial rendering and generation network is able to handle a much wider range of manipulations including changes to, for example, viewpoint, lighting, expression, and even higher-level attributes like facial hair and age—aspects that cannot be represented using previous models.","['G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T5/005', 'G06T5/60', 'G06T5/77', 'G06V40/16', 'G06N3/044', 'G06N3/088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US10043035B2,Systems and methods for enhancing data protection by anonosizing structured and unstructured data and incorporating machine learning and artificial intelligence in classical and quantum computing environments,"Systems, computer-readable media, and methods for improving both data privacy/anonymity and data value, wherein real-world, synthetic, or other data related to a data subject can be used while minimizing re-identification risk by unauthorized parties and enabling data, including quasi-identifiers, related to the data subject to be disclosed to any authorized party by granting access only to the data relevant to that authorized party's purpose, time period, purpose, place and/or other criterion via the required obfuscation of specific data values, e.g., pursuant to the GDPR or HIPAA, by incorporating a given range of those values into a cohort, wherein only the defined cohort values are disclosed to the given authorized party. Privacy policies may include any privacy enhancement techniques (PET), including: data protection, dynamic de-identification, anonymity, pseudonymity, granularization, and/or obscurity policies. Such systems, media and methods may be implemented on both classical and quantum computing devices.","['G06F21/6254', 'G06F21/6218', 'G06F21/6263', 'H04L63/0414', 'H04L63/1441', 'H04L9/065', 'G06F2221/2101', 'H04L2209/42', 'H04L63/0281', 'H04L9/30']"
US20220215259A1,"Neural network training method, data processing method, and related apparatus","Technical solutions in this application are applied to the field of artificial intelligence. This application provides a neural network training method, a method for performing data processing by using a neural network trained by using the method, and a related apparatus. According to the training method in this application, a target neural network is trained in an adversarial manner, so that a policy search module can continuously discover a weakness of the target neural network, generate a policy of higher quality according to the weakness, and perform data augmentation according to the policy to obtain data of higher quality. A target neural network of higher quality can be trained according to the data. In the data processing method in this application, data processing is performed by using the foregoing target neural network, so that a more accurate processing result can be obtained.","['G06N3/084', 'G06N3/045', 'G06F18/214', 'G06K9/6298', 'G06N3/04', 'G06N3/044', 'G06N3/08', 'G06V10/774', 'G06V10/82', 'G06V20/58', 'G06V2201/07', 'Y02T10/40']"
CN110390650B,OCT image denoising method based on dense connection and generation countermeasure network,"The invention discloses an OCT image denoising method based on dense connection and generation countermeasure network, belonging to the technical field of image restoration, and the invention adopts a multi-frame registration mode to synthesize a reference image according to the characteristics of noise randomness, so that the network can learn the mapping relation between a noise image and the reference image; the step of synthesizing the noise can effectively expand the diversity of the speckle noise and synthesize new sample data; dense fusion is carried out by utilizing the multi-scale characteristics of the network, and the reutilization and the transmission of effective characteristics are enhanced by less parameters; the overall perception quality of the image is ensured by adopting a mode of resisting a generation network; the trained generative model can directly process noise OCT images with any resolution, has higher speed and performance and higher use value in clinic.","['G06T5/70', 'G06T11/008', 'G06T2207/10101', 'G06T2207/30041']"
US20210019541A1,Technologies for transferring visual attributes to images,"Systems, methods, and computer-readable media are provided media for transferring visual attributes to images. In some examples, a system can obtain a first image associated with a user; generate a second image including image data from the first image modified to add a first visual attribute transferred from one or more images or remove a second visual attribute in the image data; compare a first set of features from the first image with a second set of features from the second image; determine, based on a comparison result, whether the first image and the second image match at least partially; and update a library of user verification images to include the second image when the first image and the second image match at least partially.","['G06K9/00926', 'G06V10/82', 'G06F18/22', 'G06K9/00281', 'G06K9/00288', 'G06K9/6215', 'G06V10/764', 'G06V40/16', 'G06V40/171', 'G06V40/172', 'G06V40/50']"
US11024299B1,Privacy and intent-preserving redaction for text utterance data,"Systems, methods, and computer-readable media are disclosed for providing privacy and intent preserving redactions of text derived from utterance data. Certain embodiments provide new techniques for using MadLib-style replacements to replace one or more terms or phrases in a text string. Example methods may include receiving utterance data and determining a public portion and a private portion of the utterance data. Certain methods include determining a cluster of candidates having a same semantic context as the private portion and identifying from within the cluster of candidates a first candidate. Certain methods include determining a redacted utterance comprising the public portion of the utterance and the first candidate. Certain methods include providing the redacted utterance to downstream systems and processes.","['G10L15/197', 'G06F40/30', 'G06F21/6245']"
US11074688B2,Determination of a degree of deformity of at least one vertebral bone,"For processing a medical image, medical image data representing a medical image of at least a portion of a vertebral column is received. The medical image data is processed to determine a plurality of positions within the image. Each of the plurality of positions corresponds to a position relating to a vertebral bone within the vertebral column. Data representing the plurality of positions is processed to determine a degree of deformity of at least one vertebral bone within the vertebral column.","['G16H30/20', 'G06T7/0012', 'A61B5/4509', 'A61B6/505', 'A61B6/5217', 'G06F18/2413', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06T7/73', 'G06V10/454', 'G06V10/457', 'G06V10/764', 'G06V10/82', 'G06T2207/10072', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10116', 'G06T2207/10121', 'G06T2207/20084', 'G06T2207/30012', 'G06V10/143', 'G06V2201/033']"
US12045195B2,Efficient configuration compliance verification of resources in a target environment of a computing system,"A method includes executing a configuration engine on one or more data processing device(s) of a computing system. In accordance with the execution, the method also includes discovering at least a subset of a number of resources associated with a target environment of the computing system, generating an environment definition associated with the target environment, building baseline configurations, policies and metadata for at least the subset of the number of resources, and versioning the aforementioned data. Further, the method includes, in accordance with tracking the metadata versioned in the repository, automatically scanning at least the subset of the number of resources and retrieving a first and/or a second specific configuration based on the scanning, and automatically determining a misconfiguration based on comparing the first specific configuration to a corresponding baseline configuration and/or verifying that a sequence of configurations is correctly defined based on the second specific configuration.","['G06F16/122', 'G06F11/3688', 'G06F16/144', 'G06F16/1734', 'G06F16/182', 'G06F8/71', 'G06F9/44505', 'G06N20/00']"
US12136203B2,Photo relighting using deep neural networks and confidence learning,Apparatus and methods related to applying lighting models to images of objects are provided. A neural network can be trained to apply a lighting model to an input image. The training of the neural network can utilize confidence learning that is based on light predictions and prediction confidence values associated with lighting of the input image. A computing device can receive an input image of an object and data about a particular lighting model to be applied to the input image. The computing device can determine an output image of the object by using the trained neural network to apply the particular lighting model to the input image of the object.,"['G06T5/94', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06T15/50', 'G06T5/60', 'G06T15/506', 'G06T2207/20081', 'G06T2207/20084']"
US20230177682A1,Systems and methods for characterizing a tumor microenvironment using pathological images,"Implementations discussed and claimed herein provide systems and methods for characterizing patient tissue of a patient. In one implementation, a pathological image of the patient tissue is received. Nuclei of the plurality of cells in the pathological image are simultaneously segmented and classified using a histology-based digital staining system. The nuclei of the plurality of cells are segmented according to spatial location and classified according to cell type, thereby generating one or more groups of nuclei. Each of the one or more groups of nuclei have an identified cell type. A composition and a spatial organization of a tumor microenvironment of the patient tissue is determined based on the one or more groups of nuclei. A prognostic model for the patient is generated based on the composition and the spatial organization of the tumor microenvironment.","['G06F18/214', 'G06F18/2413', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T7/0012', 'G06T7/0014', 'G06T7/11', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/698', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096']"
US20200402497A1,Systems and Methods for Speech Generation,"Systems and methods for generating audio data in accordance with embodiments of the invention are illustrated. One embodiment includes a method for generating audio data. The method includes steps for generating a plurality of style tokens from a set of audio inputs, generating an input feature vector based on the plurality of style tokens and a set of text features, and generating audio data (e.g., a spectrogram, audio waveforms, etc.) based on the input feature vector.","['G10L13/10', 'G10L13/02', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10L13/04', 'G10L19/167', 'G10L21/0332', 'G06N3/044', 'G10L19/00', 'G10L25/30']"
US20240354553A1,"Method and data processing system for lossy image or video encoding, transmission and decoding","A method for lossy image and video encoding, transmission and decoding, the method comprising the steps of: receiving an input image at a first computer system; encoding the input image using a first trained neural network to produce a latent representation; performing a quantization process on the latent representation to produce a quantized latent, wherein the sizes of the bins used in the quantization process are based on the input image; transmitting the quantized latent to a second computer system; decoding the quantized latent using a second trained neural network to produce an output image, wherein the output image is an approximation of the input image.","['G06T9/002', 'H04N19/124', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06N7/01', 'G06T3/4046', 'G06T5/20', 'H04N19/119', 'H04N19/136', 'H04N19/17', 'H04N19/182', 'H04N19/186', 'H04N19/91', 'G06T2207/20084']"
US11182924B1,System for estimating a three dimensional pose of one or more persons in a scene,"A system for estimating a three dimensional pose and determining one or more biomechanical performance parameters of at least one person in a scene is disclosed herein. The system includes at least one camera and at least one measurement assembly, the at least one camera configured to capture an image of the scene; and a data processor including at least one hardware component, the data processor configured to execute computer executable instructions. The computer executable instructions comprising instructions for: (i) receiving the image of the scene from the at least one camera; (ii) extracting features from the image of the scene for providing inputs to a convolutional neural network; (iii) generating one or more volumetric heatmaps using the convolutional neural network; and (iv) applying a maximization function to the one or more volumetric heatmaps to obtain a three dimensional pose of the at least one person in the scene.","['G06T7/75', 'G06T7/73', 'A61B5/015', 'A61B5/1038', 'A61B5/1116', 'A61B5/1121', 'A61B5/1128', 'A61B5/486', 'A61B5/7267', 'A61B5/7405', 'A61B5/742', 'A61B5/7455', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06T7/246', 'G06T7/85', 'G08B7/06', 'G09B19/003', 'G09B19/0038', 'A61B2562/0219', 'G06N3/042', 'G06N3/048', 'G06N5/01', 'G06T2200/04', 'G06T2207/10021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US10579875B2,Systems and methods for object identification using a three-dimensional scanning system,"A method for identifying and tracking objects includes: capturing one or more 3-D models of one or more objects in a scene using a three-dimensional (3-D) scanning system, the one or more 3-D models including color and geometry information of the one or more objects; and computing, by an analysis agent, one or more descriptors of the one or more 3-D models, each descriptor corresponding to a fixed-length feature vector; and retrieving metadata identifying the one or more objects based on the one or more descriptors.","['G06K9/00664', 'G06V10/82', 'G06F18/24', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06Q20/208', 'G06T15/10', 'G06T17/00', 'G06T7/0004', 'G06T7/174', 'G06T7/285', 'G06V10/764', 'G06V20/10', 'G06V20/52', 'G06V20/64', 'G07G1/0063', 'G06T2207/10012', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US11201798B2,Automated virtual network function modification,Systems and methods provide automated virtual network function modification using replicated environments and functions to measure and test modified functions against one another before implementation.,"['H04L41/40', 'H04L12/4641', 'H04L41/0894', 'H04L41/0895', 'H04L41/5009', 'H04L43/08', 'H04L43/20', 'H04L43/50', 'H04L41/0886', 'H04L41/0893']"
US11544503B2,Domain alignment for object detection domain adaptation tasks,"A domain alignment technique for cross-domain object detection tasks is introduced. During a preliminary pretraining phase, an object detection model is pretrained to detect objects in images associated with a source domain using a source dataset of images associated with the source domain. After completing the pretraining phase, a domain adaptation phase is performed using the source dataset and a target dataset to adapt the pretrained object detection model to detect objects in images associated with the target domain. The domain adaptation phase may involve the use of various domain alignment modules that, for example, perform multi-scale pixel/path alignment based on input feature maps or perform instance-level alignment based on input region proposals.","['G06K9/6257', 'G06V30/40', 'G06F18/2148', 'G06F18/217', 'G06F18/2413', 'G06F18/2431', 'G06K9/6232', 'G06K9/6262', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/046', 'G06V10/764', 'G06V10/82', 'G06V30/19147', 'G06V30/1916']"
US11507745B2,System and method for detecting undesirable and potentially harmful online behavior,"Embodiments include computer-implemented methods and systems for detecting undesirable and potentially harmful online behavior. The embodiments described and claimed could also be applied to detecting any other type of online behavior to be detected, but the descriptions focuses on detecting online violence. More particularly, the embodiments disclosed relate to detecting online violence using symbolic methods of natural language processing (NLP) that utilize and govern the usage of: 1) syntactic parser for analyzing grammatical context of the input text data, 2) unsupervised learning methods for improving selected aspects of the system and adjusting the system to new data sources and guidelines, and 3) statistical classifiers for resolving specific well-defined sub-tasks, in which statistical approaches surpass the symbolic methods.","['H04L51/063', 'G06F40/211', 'G06F40/216', 'G06F40/253', 'G06F40/279', 'G06N20/00', 'G06N3/042', 'G06N3/088', 'G06N5/025', 'H04L51/046', 'H04L51/212']"
CN110287461B,"Text conversion method, device and storage medium","The application provides a text conversion method, a text conversion device and a storage medium, wherein the method comprises the following steps: acquiring a written text to be processed, wherein the text to be processed comprises a plurality of sentences to be processed, and sequentially inputting the sentences to be processed into a sentence style conversion model for conversion to obtain a plurality of target sentences, and the target texts are formed by the target sentences; the sentence style conversion model is obtained by training in advance according to a plurality of neural network models, and is used for converting written sentences into spoken sentences. The sentence style conversion model in the technical scheme is obtained by training according to the plurality of neural network models in advance, and can accurately convert the written sentences into spoken sentences, so that the conversion accuracy is improved.","['G06F40/151', 'G06F40/16', 'G06N3/08']"
CN111553397B,Cross-domain target detection method based on regional full convolution network and self-adaption,"The invention discloses a cross-domain target detection method based on a regional full convolution network and self-adaption, and belongs to the technical field of computer vision. The method uses a deep learning target detection technology, aims at the problem of different data distribution of a training domain and a testing domain in target detection, and improves the cross-domain robustness of the target detection by using a self-adaptive method. Firstly, constructing a regional full convolution network model based on deep learning; then designing two corresponding domain classifiers as self-adaptive components on the image level and the target level to reduce the difference of domain transformation, and adding consistency regularization on the domain classifiers; then training the network in an end-to-end manner; and finally, removing the self-adaptive components and using the network for a target detection task. By adopting the designed cross-domain target detection method, the average precision of target detection in various domain transformation scenes can be effectively improved.","['G06F18/24', 'G06N3/045', 'G06N3/084', 'G06V10/25', 'G06V2201/07']"
US11688139B1,System for estimating a three dimensional pose of one or more persons in a scene,"A system for estimating a three dimensional pose of one or more persons in a scene is disclosed herein. The system includes one or more cameras and a data processor configured to execute computer executable instructions. The computer executable instructions include: (i) receiving one or more images of the scene from the one or more cameras; (ii) extracting features from the one or more images of the scene for providing inputs to a first branch pose estimation neural network and a second branch pose estimation neural network; (iii) generating, by using a three dimensional reconstruction module, three dimensional reconstructions from two dimensional pose estimates produced by the second branch pose estimation neural network; and (iv) projecting, by using a reprojection module, the three dimensional reconstructions to camera image planes of respective image samples, and uploading the reprojections and image samples to an annotation server.","['G06N3/0455', 'G06T19/00', 'G06N3/0464', 'G06N3/0895', 'G06T15/10', 'G06T17/00', 'G06T7/73', 'G06V10/454', 'G06V10/763', 'G06V10/82', 'G06V20/64', 'G06V40/103', 'G09B19/0038', 'G06N20/00', 'G06N3/048', 'G06N3/082', 'G06N3/084', 'G06T2200/08', 'G06T2200/24', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2219/004']"
US11348279B1,System for estimating a three dimensional pose of one or more persons in a scene,"A system for estimating a three dimensional pose of one or more persons in a scene is disclosed herein. The system includes at least one camera, the at least one camera configured to capture an image of the scene; and a data processor including at least one hardware component, the data processor configured to execute computer executable instructions. The computer executable instructions comprising instructions for: (i) receiving the image of the scene from the at least one camera; (ii) extracting features from the image of the scene for providing inputs to a convolutional neural network; (iii) generating one or more volumetric heatmaps using the convolutional neural network; and (iv) applying a maximization function to the one or more volumetric heatmaps to obtain a three dimensional pose of one or more persons in the scene.","['A61B5/1038', 'G06T7/73', 'A61B5/1116', 'A61B5/1121', 'A61B5/1128', 'A61B5/486', 'A61B5/7267', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06T7/50', 'G06T7/70', 'G06V10/454', 'G06V10/763', 'G06V10/82', 'G06V20/64', 'G06V40/103', 'G09B19/0038', 'A61B2562/0219', 'G06N20/00', 'G06N3/042', 'G06N3/048', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11665178B2,Methods and arrangements for message time series intrusion detection for in-vehicle network security,"Logic may reduce the latency and increase the confidence in message time series (MTS) intrusion detection systems (IDSs). Logic may capture traffic on an in-vehicle network bus during a first traffic window. Logic may filter the traffic within the first traffic window to determine more than one observation window, wherein the more than observation window comprises at least a first observation window and a second observation window. Logic may evaluate the more than one observation window to determine a first output based on a first observation window and a second output based on a second observation window, the first and second outputs to indicate if an intrusion is detected. Logic may determine, based on a combination of the outputs, that the traffic during the first traffic window comprises an intrusion. Logic may output an indication of the intrusion.","['H04L63/1408', 'G06N20/20', 'G06N3/08', 'G06N3/09', 'G06N3/0985', 'G06N5/01', 'G06N7/00', 'H04L12/40032', 'H04L12/40169', 'H04L63/0227', 'H04L63/1425', 'H04L63/1441', 'H04L2012/40273']"
WO2022221680A1,Methods and arrangements to aid recycling,"A waste stream is analyzed and sorted to segregate different items for recycling. Certain features of the technology improve the accuracy with which waste stream items are diverted to collection repositories. Other features concern adaptation of neural networks in accordance with context information sensed from the waste. Still other features serve to automate and simplify maintenance of machine vision systems used in waste sorting. Yet other aspects of the technology concern marking 2D machine readable code data on items having complex surfaces (e.g., food containers with integral ribbing for structural strength or juice pooling), to mitigate issues that such surfaces can introduce in code reading. Still other aspects of the technology concern prioritizing certain blocks of conveyor belt imagery for analysis. Yet other aspects of the technology concern joint use of near infrared spectroscopy, artificial intelligence, digital watermarking, and/or other techniques, for waste sorting. A variety of further features and arrangements are also detailed.","['G06K19/06037', 'B07C5/342', 'B65G47/26', 'G06F18/214', 'G06K19/06046', 'G06K7/1417', 'G06K7/1482', 'G06N3/045', 'G06N3/08', 'G06V10/143', 'G06V10/225', 'G06V10/245', 'G06V10/764', 'G06V10/768', 'G06V10/82', 'G06V20/52', 'G06V20/64', 'B07C2501/0054', 'B65G2203/0208', 'B65G2203/041', 'G06V2201/06', 'G06V2201/10']"
US12412564B2,Text data processing method and apparatus,"This application discloses example text data processing method. One example method includes obtaining a target text. The target text can then be processed based on a noise generation model to obtain a noisy text, where when the noise generation model is trained, training data of the noise generation model at least includes a first text and a second text, the first text is a correct text corresponding to speech data, and the second text is obtained by performing speech recognition on the speech data by using a first speech recognition model. A text processing model can then be trained, by using at least the noisy text as training data, to obtain a trained text processing model.","['G10L15/26', 'G06F40/279', 'G06F40/30', 'G06F40/40', 'G06N3/0442', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G10L15/063', 'G10L15/16', 'G10L15/20', 'G10L15/22', 'G06F40/295']"
US11954822B2,"Image processing method and device, training method of neural network, image processing method based on combined neural network model, constructing method of combined neural network model, neural network processor, and storage medium","An image processing method, an image processing device, a training method of a neural network, an image processing method based on a combined neural network model, a constructing method of a combined neural network model, a neural network processor, and a storage medium are provided. The image processing method includes: obtaining, based on an input image, initial feature images of N stages with resolutions from high to low, where N is a positive integer and N>2, performing, based on initial feature images of second to N-th stages, cyclic scaling processing on an initial feature image of a first stage, to obtain an intermediate feature image; and preforming merging processing on the intermediate feature image to obtain an output image. The cyclic scaling processing includes hierarchically-nested scaling processing of N−1 stages, and scaling processing of each stage includes down-sampling processing, concatenating processing, up-sampling processing, and residual link addition processing.","['G06T5/92', 'G06T3/4046', 'G06T1/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/4053', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US9985984B1,Dynamic defense and network randomization for computer systems,"The various technologies presented herein relate to determining a network attack is taking place, and further to adjust one or more network parameters such that the network becomes dynamically configured. A plurality of machine learning algorithms are configured to recognize an active attack pattern. Notification of the attack can be generated, and knowledge gained from the detected attack pattern can be utilized to improve the knowledge of the algorithms to detect a subsequent attack vector(s). Further, network settings and application communications can be dynamically randomized, wherein artificial diversity converts control systems into moving targets that help mitigate the early reconnaissance stages of an attack. An attack(s) based upon a known static address(es) of a critical infrastructure network device(s) can be mitigated by the dynamic randomization. Network parameters that can be randomized include IP addresses, application port numbers, paths data packets navigate through the network, application randomization, etc.","['H04L63/1441', 'G05B19/05', 'G06N20/00', 'G06N20/20', 'G06N3/09', 'G06N99/005', 'H04L61/2503', 'H04L63/1425', 'H04L67/327', 'H04L67/63', 'G05B2219/1105', 'G06N20/10', 'G06N3/045', 'G06N5/01', 'G06N7/01', 'H04L67/10']"
CN111723780B,Directional migration method and system of cross-domain data based on high-resolution remote sensing image,"The invention discloses a method and a system for directionally migrating cross-domain data based on a high-resolution remote sensing image, wherein the method comprises the steps of firstly, establishing a target loss function fusing conversion image loss and model adaptability loss of an image conversion network model; the technical defects that a specific task is separated from the existing data conversion process, and negative effects brought to the specific task by data conversion are ignored are overcome, the trained image conversion network model is finely adjusted based on sample data, the image conversion network model is ensured to be continuously converted to the expected direction of a target model, the technical defects of excessive interpretation or excessive simplification in the directional migration process of cross-domain data are overcome, and the accuracy of the directional migration of the cross-domain data based on the high-resolution remote sensing image is improved.","['G06N3/008', 'G06T3/4092', 'G06V20/13', 'G06F18/213', 'G06F18/214', 'G06F18/2155', 'G06F18/24', 'G06F18/2415', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T3/4053', 'G06V10/267', 'G06V10/774', 'G06V10/82', 'Y02A90/10']"
US20210271980A1,Deterministic decoder variational autoencoder,"A model of a deterministic decoder VAE (DD-VAE) is provided. The DD-VAE has evidence lower bound derived, and a convenient approximation can be proposed with proven convergence to optimal parameters of a non-relaxed objective. The invention introduces bounded support distributions as a solution thereto. Experiments on multiple datasets (synthetic, MNIST, MOSES, ZINC) are performed to show that DD-VAE yields both a proper generative distribution and useful latent codes. A computer-implemented method of generating objects with a deterministic decoder variational autoencoder can include: providing a model configured as a deterministic decoder variational autoencoder; inputting object data into a stochastic encoder of the deterministic decoder variational autoencoder; generating latent codes in the latent space with the encoder; providing the latent codes from the latent space to a decoder, wherein the decoder is configured as a deterministic decoder; generating decoded objects with the decoder; and generating a report that identifies the decoded object.","['G06N3/088', 'G06N3/08', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047']"
US11704775B2,Bright spot removal using a neural network,A method for image capture includes identifying a bright spot in an image. A neural network is used to recover details in bright spot area through a trained de-noising process. Post-processing of the image is conducted to match image parameters of recovered details in the bright spot area to another area of the image.,"['G06T5/77', 'G06T5/70', 'G06T5/002', 'G06N3/08', 'G06T3/4046', 'G06T5/005', 'G06T5/60', 'G06T5/94', 'G06T7/11', 'H04N23/64', 'H04N23/70', 'H04N23/71', 'H04N23/81', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US20240104386A1,"Radio signal identification, identification system learning, and identifier deployment","Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training and deploying machine-learned identification of radio frequency (RF) signals. One of the methods includes: determining an RF signal configured to be transmitted through an RF band of a communication medium; determining first classification information that is associated with the RF signal, and that includes a representation of a characteristic of the RF signal or a characteristic of an environment in which the RF signal is communicated; using at least one machine-learning network to process the RF signal and generate second classification information as a prediction of the first classification information; calculating a measure of distance between (i) the second classification information that was generated by the at least one machine-learning network, and (ii) the first classification information associated with the RF signal; and updating the at least one machine-learning network based on the measure of distance.","['G06N3/086', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'H04B17/30', 'H04W24/08', 'G06F18/217', 'G06F2218/00', 'G06N3/006', 'G06N3/044', 'G06N3/048']"
US11886815B2,Self-supervised document representation learning,"One example method involves operations for a processing device that include receiving, by a machine learning model trained to generate a search result, a search query for a text input. The machine learning model is trained by receiving pre-training data that includes multiple documents. Pre-training the machine learning model by generating, using an encoder, feature embeddings for each of the documents included in the pre-training data. The feature embeddings are generated by applying a masking function to visual and textual features in the documents. Training the machine learning model also includes generating, using the feature embeddings, output features for the documents by concatenating the feature embeddings and applying a non-linear mapping to the feature embeddings. Training the machine learning model further includes applying a linear classifier to the output features. Additionally, operations include generating, for display, a search result using the machine learning model based on the input.","['G06F40/279', 'G06F16/334', 'G06F16/93', 'G06F40/103', 'G06F40/131', 'G06F40/205', 'G06F40/216', 'G06F40/289', 'G06F40/30', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/088', 'G06N3/0895']"
CN109587372B,Invisible image steganography based on generation of countermeasure network,"The invention discloses invisible image steganography based on a generation countermeasure network, which can realize that a gray secret image is embedded in a color carrier image to obtain a secret image and can successfully recover the secret image from the secret image. The method comprises the following steps: the encoder network is responsible for embedding the secret image into the carrier image to generate a carrier image; the decoder network is responsible for recovering the secret image from the secret-carrying image; and the discriminator network is responsible for performing steganalysis on the natural image and the secret-carrying image so as to adjust the security of the encoder network and the decoder network. The invention provides a new design idea for hiding image information by constructing the image steganography based on the generation countermeasure network.","['H04N1/32309', 'G06N3/045', 'G06N3/08']"
US12045348B2,Methods and arrangements for multi-layer in-vehicle network intrusion detection and characterization,"Logic may implement observation layer intrusion detection systems (IDSs) to combine observations by intrusion detectors and/or other intrusion detection systems. Logic may monitor one or more control units at one or more observation layers of an in-vehicle network, each of the one or more control units to perform a vehicle function. Logic may combine observations of the one or more control units at the one or more observation layers. Logic may determine, based on a combination of the observations, that one or more of the observations represent an intrusion. Logic may determine, based at least on the observations, characteristics of an attack, and to pass the characteristics of the attack information to a forensic logging system to log the attack or pass the characteristics of the attack to a recovery system for informed selection of recovery procedures. Logic may dynamically adjust a threshold for detection of suspicious activity.","['G06F21/554', 'G06F21/566', 'G06F2221/034']"
US10812084B2,Reconfigurable physically unclonable functions based on analog non-volatile memories,A security primitive for an integrated circuit comprises an array of floating-gate transistors monolithically integrated into the integrated circuit and coupled to one another in a crossbar configuration. The floating-gate transistors have instance-specific process-induced variations in analog behavior to provide one or more reconfigurable physically unclonable functions (PUFs).,"['G11C11/4085', 'G11C11/5621', 'G11C11/5628', 'G11C11/5642', 'G11C16/0425', 'G11C16/22', 'G11C27/005', 'G11C7/16', 'G11C7/222', 'G11C7/24', 'H03K19/17756', 'H03K19/17768', 'H04L9/0866', 'H04L9/3278', 'H04L2209/12']"
US10847162B2,Multi-modal speech localization,"Multi-modal speech localization is achieved using image data captured by one or more cameras, and audio data captured by a microphone array. Audio data captured by each microphone of the array is transformed to obtain a frequency domain representation that is discretized in a plurality of frequency intervals. Image data captured by each camera is used to determine a positioning of each human face. Input data is provided to a previously-trained, audio source localization classifier, including: the frequency domain representation of the audio data captured by each microphone, and the positioning of each human face captured by each camera in which the positioning of each human face represents a candidate audio source. An identified audio source is indicated by the classifier based on the input data that is estimated to be the human face from which the audio data originated.","['G10L17/10', 'G10L17/005', 'G01S3/801', 'G01S3/802', 'G06F18/2413', 'G06K9/00288', 'G06T7/70', 'G06V10/454', 'G06V10/764', 'G06V40/165', 'G06V40/166', 'G10L17/00', 'G10L21/0232', 'G10L25/84', 'H04N23/611', 'H04N7/147', 'H04N7/15', 'H04N7/155', 'G01S5/18', 'G06T2207/30201', 'G06V40/172', 'G10L17/18', 'G10L2021/02166', 'H04N23/90', 'H04N5/247', 'H04R1/406', 'H04R2201/401', 'H04R2430/20']"
US10602163B2,Encoder pre-analyser,"The present disclosure relates to analysing input data, prior to encoding, using one or more hierarchical algorithms. According to a first aspect, there is provided a method for producing output data using one or more input data and one or more hierarchical algorithms, comprising the steps of applying the hierarchical algorithm to the one or more input data; and producing output data to be used by an encoder; wherein one of the one or more input data is uncompressed; and wherein the output data is used to modify a decision making process associated with the encoder.","['H04N19/30', 'H04N19/103', 'H04N19/119', 'H04N19/124', 'H04N19/139', 'H04N19/149', 'H04N19/159', 'H04N19/174', 'H04N19/176', 'H04N19/1883', 'H04N19/196', 'G06N5/04']"
US11776097B2,"Image fusion method, model training method, and related apparatuses","Methods, devices, and storage medium for fusing at least one image are disclosed. The method includes obtaining a first to-be-fused image and a second to-be-fused image, the first to-be-fused image comprising first regions, and the second to-be-fused image comprising second regions; obtaining a first feature set according to the first to-be-fused image and obtaining a second feature set according to the second to-be-fused image; performing first fusion processing on the first to-be-fused image and the second to-be-fused image by using a shape fusion network model to obtain a third to-be-fused image, the third to-be-fused image comprising at least one first encoding feature and at least one second encoding feature; and performing second fusion processing on the third to-be-fused image and the first to-be-fused image by using a condition fusion network model to obtain a target fused image. Model training methods, apparatus, and storage medium are also disclosed.","['G06T3/18', 'G06T5/50', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T11/00', 'G06N3/04', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US11477209B2,Managing access rights of transferable sensor systems,"An apparatus comprises at least one processing device comprising a processor coupled to a memory. The processing device is configured to receive from a requester a request to modify a parameter of an access-controlled account associated with a set of sensor devices. Responsive to receipt of the request, the processing device initiates at least one instance of a proof of physical presence protocol, the proof of physical presence protocol requiring performance by the requester of at least one action involving at least one sensor device of the set of sensor devices associated with the access-controlled account. Responsive to successful completion of at least one instance of the proof of physical presence protocol, the processing device sends at least one notification to each of one or more registered users of the access-controlled account. The processing device approves or rejects the request based at least in part on at least one of a number and a type of responses to the one or more notifications.","['H04L63/102', 'H04L63/108', 'H04L67/125', 'H04W12/08', 'H04W12/63', 'H04W4/021', 'H04W4/33', 'H04W4/80']"
US20190096135A1,Systems and methods for visual inspection based on augmented reality,"A system for visual inspection includes: a scanning system configured to capture images of an object and to compute a three-dimensional (3-D) model of the object based on the captured images; an inspection system configured to: compute a descriptor of the object based on the 3-D model of the object; retrieve metadata corresponding to the object based on the descriptor; and compute a plurality of inspection results based on the retrieved metadata and the 3-D model of the object; and a display device system including: a display; a processor; and a memory storing instructions that, when executed by the processor, cause the processor to: generate overlay data from the inspection results; and show the overlay data on the display, the overlay data being aligned with a view of the object through the display.","['G06T19/006', 'G02B27/0172', 'G06F18/2148', 'G06F18/24', 'G06F18/24765', 'G06K9/6257', 'G06K9/626', 'G06K9/6267', 'G06T17/00', 'G06T17/20', 'G06T19/20', 'G06T7/0006', 'G06T7/001', 'G06T7/11', 'G06T7/50', 'G06T7/73', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G02B2027/0138', 'G02B2027/014', 'G02B2027/0141', 'G06K2209/27', 'G06T2200/08', 'G06T2207/10008', 'G06T2207/10028', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2219/2004', 'G06T2219/2012', 'G06T2219/2016', 'G06V10/25', 'G06V2201/10']"
US11171483B2,Method and systems for detection and protection from electromagnetic pulse events using hardware implemented artificial intelligence,"A system and method for detecting and isolating a high-altitude electromagnetic pulse (“HEMP”) along electrical lines electrically connected to a monitored infrastructure so as to protect the monitored infrastructure, the method including a phase unit receiving sensor signals from a plurality of sensors electrically connected to each of the electrical lines, respectively, upstream of and associated with the monitored infrastructure. The method includes determining if the received sensors signals associated with the respective electrical line is indicative of an E1 component of an EMP and, if so, actuating an isolation subsystem in less than 300 nanoseconds to electrically isolate the respective electrical line against propagation against the monitored infrastructure. Determining in real time if received sensor signals is indicative of the E1 component includes a hardware implemented neural network (NN) having algorithms for machine learning (ML) and artificial intelligence (AI) operable to provide instantaneous detection and classification.","['H02H9/045', 'H02H5/005', 'G01R31/12', 'G01R31/327', 'H02H5/00', 'H02H9/04', 'H02H3/08', 'H02H3/105', 'H02H3/22', 'H02H9/005', 'H02H9/041', 'H02H9/046']"
US20190227562A1,Constructing and updating a behavioral layer of a multi layeredroad network high definition digital map,Described herein is a method for constructing and updating a behavioral layer of a multi layered road network high definition digital map. By sensors of a plurality of road vehicles travelling through the road network is detected data relating to at least the positions and velocities of static and moving objects. Data concerning the detected objects is sent to the cloud for data aggregation. The aggregated data is analyzed to determine or predict behavioral patterns of the detected objects for different segments of the map. The determined or predicted behavioral patterns of the detected objects are added to the behavioral layer of the map. Also described is a road network high definition map comprising such a behavioral layer as well as a Geographic Information System that is arranged to construct and update such a behavioral layer of a multi layered road network high definition digital map.,"['G01C21/3878', 'G05D1/0221', 'G01C21/367', 'G01C21/3841', 'G05D1/0088', 'G06F16/29', 'G06N20/00', 'G06N5/04', 'G08G1/0112', 'G08G1/0129', 'G08G1/0141', 'G05D1/0223', 'G05D2201/0213']"
CN111914928B,A method for defending image classifiers against adversarial examples,"The invention discloses a method for defending an countermeasure sample for an image classifier, which comprises the steps of firstly constructing a model, preparing image training data and initializing super parameters; secondly, dividing the image training data into a plurality of batches; updating model parameters using a batch of image training data, comprising: generating a challenge sample, mixing the challenge sample with the image training data and adjusting the relative position of the image data in the challenge sample, updating model parameters using a back propagation algorithm; the image training data of the rest batches are repeatedly used to update the model parameters; restarting a new round of training until the training is completed; and outputting the trained model. The invention combines the Siamese architecture with the countermeasure training, is an improvement of the traditional countermeasure training algorithm, and can better cope with the attack of the countermeasure sample in the image classifier.","['G06F18/24', 'G06F18/214', 'G06N3/084', 'Y02T10/40']"
US20250285465A1,Face reenactment,"Systems and methods for text and audio-based real-time face reenactment are provided. An example method includes receiving a target video that includes a target face, receiving a source video that includes a source face, determining, based on a parametric face model, facial expression parameters of the source face, modifying, in real time, the target face to imitate a face expression of the source face based on the facial expression parameters to generate a sequence of modified video frames, and displaying at least part of the sequence of modified video frames on a computing device during the generation of at least one frame of the sequence of modified video frames.","['G06N3/04', 'G06N3/08', 'G06Q30/0254', 'G06Q30/0269', 'G06T11/00', 'G06T11/001', 'G06T11/60', 'G06V10/82', 'G06V40/161', 'G06V40/174', 'G06V40/175', 'G06T2207/20084', 'G06T2207/30201', 'G06V40/178']"
US10984112B2,Systems and methods for automated threat modeling of an existing computing environment,"Automated threat modeling methods include providing one or more servers and one or more data stores communicatively coupled with the server(s). The data store(s) may include a plurality of threat model components stored therein (stored components) and a plurality of threats stored therein (stored threats), each stored threat associated through the data store(s) with at least one of the stored components. Using one or more input fields displayed on one or more computing devices communicatively coupled with at least one of the server(s), one or more inputs are received, the input(s) including access credentials associated with an existing computing environment and one or more inputs configured to initiate, using the server(s) and the access credentials, automatic generation of a relational diagram (diagram) of the existing computing environment and automatic generation of a threat report. Automated modeling systems include systems configured to carry out automated modeling of an existing computing environment.","['G06F21/577', 'G06F21/566', 'G06F21/57', 'G06F9/547', 'G06N5/04', 'G06F2221/034', 'G06N20/00', 'G06N5/022']"
US11159559B2,Systems and methods for importing diagrams for automated threat modeling,"Automated diagram import methods include providing one or more servers and one or more data stores communicatively coupled with the server(s). The data store(s) may include a plurality of computing environment assets and a plurality of connections between the assets. The method may include receiving a digital image of the hand drawn diagram and identifying a plurality of shapes and one or more links in the received digital image. The method further includes, for each component, identifying a text label for the component and classifying the component as an asset. The method further includes, for each link, determining a text label for the link and identifying two components connected by the link. The method may also include generating a diagram and displaying the diagram on a user interface. Automated hand drawn diagram import systems include systems configured to carry out automated importing of the hand drawn diagram.","['G06F21/57', 'G06F21/577', 'H04L41/145', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/20', 'G06F2221/034', 'G06N20/00', 'G06N5/022']"
US12306959B2,Threat model chaining and attack simulation systems and related methods,"Systems and methods for determining one or more security threats associated with code in a code file are described. The method includes analyzing the code file to identify one or more properties, of a plurality of properties associated with one or more resources included in the code file. For each property of the identified one or more properties, the method further includes identifying a value for the property defined in the code file, and determining whether a security threat is associated with the property based on the identified value for the property and information regarding security threats associated with one or more values of the plurality of properties.","['G06F21/57', 'G06F21/563', 'G06F21/577', 'G06F30/20', 'H04L41/046', 'H04L41/145', 'H04L63/1433', 'H04L63/20', 'G06F2119/02', 'G06F2221/034', 'G06N20/00', 'G06N5/01', 'G06N5/022', 'G06N5/04']"
TWI760929B,Semiconductor metrology method and semiconductor metrology system,"A semiconductor metrology system including a spectrum acquisition tool for collecting, using a first measurement protocol, baseline scatterometric spectra on first semiconductor wafer targets, and for various sources of spectral variability, variability sets of scatterometric spectra on second semiconductor wafer targets, the variability sets embodying the spectral variability, a reference metrology tool for collecting, using a second measurement protocol, parameter values of the first semiconductor wafer targets, and a training unit for training, using the collected spectra and values, a prediction model using machine learning and minimizing an associated loss function incorporating spectral variability terms, the prediction model for predicting values for production semiconductor wafer targets based on their spectra.","['G06N20/00', 'G01B11/06', 'G03F7/705', 'G03F7/70616', 'G03F7/706841', 'G06N5/04', 'H01L21/681', 'H01L22/26', 'G01B2210/56']"
US10755120B2,End-to-end lightweight method and apparatus for license plate recognition,"Embodiments of the present invention provide an end-to-end lightweight method and apparatus for license plate recognition. The method comprises: obtaining an image to be recognized; obtaining a number of a license plate in the image to be recognized and position coordinates of the license plate in the image to be recognized on the basis of the image to be recognized and a pre-trained target license plate recognition model, wherein the target license plate recognition model comprises a target feature extraction network, a target region candidate localization network, a target super-resolution generation network and a target recurrent neural network. Because in this solution, once an image to be recognized is input into the target license plate recognition model, the target license plate recognition model can output the license plate number and position coordinates of the license plate in the image to be recognized, one realizes an end-to-end model. The model has relatively strong robustness, and it can detect and recognize pictures taken under different camera angles. Moreover, computation variables such as image features can be reused without repeated computations, the model takes up less RAM and the speed of license plate recognition is greatly improved.","['G06V10/255', 'G06V10/82', 'G06K9/00825', 'G06F18/24133', 'G06K9/3258', 'G06K9/46', 'G06K9/6271', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T3/4053', 'G06V10/764', 'G06V20/584', 'G06V20/63', 'G06K2209/15', 'G06V20/625']"
US11521373B1,System for estimating a three dimensional pose of one or more persons in a scene,A system for estimating a three dimensional pose of one or more persons in a scene is disclosed herein. The system includes one or more cameras and a data processor configured to execute computer executable instructions. The computer executable instructions include: (i) receiving one or more images of the scene from the one or more cameras; (ii) extracting features from the one or more images of the scene for providing inputs to a first branch pose estimation neural network and second branch pose estimation neural network; (iii) generating a first training signal from the second branch pose estimation neural network using a three dimensional reconstruction module for input into the first branch pose estimation neural network; (iv) generating one or more volumetric heatmaps; and (v) applying a maximization function to the one or more volumetric heatmaps to obtain a 3D pose of one or more persons in the scene.,"['A61B5/1038', 'A61B5/1116', 'A61B5/1121', 'A61B5/1128', 'A61B5/486', 'A61B5/7267', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06T7/73', 'G06V10/454', 'G06V10/76', 'G06V10/763', 'G06V10/82', 'G06V20/64', 'G06V40/10', 'G06V40/103', 'G09B19/0038', 'A61B2562/0219', 'G06N3/048', 'G06N3/082', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06V2201/07']"
CN110998663B,"Image generation method, electronic device and storage medium for simulation scene","The embodiment of the disclosure relates to an image generation method, electronic equipment and storage medium of a simulation scene, wherein the method comprises the following steps: acquiring semantic segmentation information and instance segmentation information of a scene white model; receiving instance text information of a scene white mode; the instance text information is editable information and is used for describing the attribute of the instance; based on the semantic segmentation information, the instance text information, and the pre-trained generation countermeasure network, an image of the simulated scene is generated. In the embodiment of the disclosure, only the scene white mode is required to be established, and then the image of the simulation scene can be generated based on the semantic segmentation information and the instance segmentation information of the scene white mode, so that the attributes such as color, texture, illumination and the like are not required to be refined in the scene establishment process, and the generation efficiency is improved; moreover, the instance text information can be edited, and the different instance text information describes the attributes of different instances and corresponds to different instances, so that simulation scenes are diversified.","['G06T11/00', 'G06T19/20', 'G06V20/70', 'G06N3/045', 'G06N3/08', 'G06T17/00', 'G06V10/7715', 'G06V10/82', 'G06T2219/2016', 'Y02T10/40']"
US11556749B2,Domain adaptation and fusion using weakly supervised target-irrelevant data,Aspects include receiving a request to perform an image classification task in a target domain. The image classification task includes identifying a feature in images in the target domain. Classification information related to the feature is transferred from a source domain to the target domain. The transferring includes receiving a plurality of pairs of task-irrelevant images that each includes a task-irrelevant image in the source domain and in the target domain. The task-irrelevant image in the source domain has a fixed correspondence to the task-irrelevant image in the target domain. A target neural network is trained to perform the image classification task in the target domain. The training is based on the plurality of pairs of task-irrelevant images. The image classification task is performed in the target domain and includes applying the target neural network to an image in the target domain and outputting an identified feature.,"['G06N3/08', 'G06K9/6292', 'G06F18/2148', 'G06F18/2414', 'G06F18/25', 'G06F18/254', 'G06K9/6257', 'G06K9/6273', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/454', 'G06V10/764', 'G06V10/7747', 'G06V10/80', 'G06V10/809', 'G06V10/82']"
US12373729B2,System and method for federated learning with local differential privacy,"In one embodiment, a method includes accessing a plurality of initial gradients associated with a machine-learning model from a data store associated with a first electronic device, selecting one or more of the plurality of initial gradients for perturbation, generating one or more perturbed gradients for the one or more selected initial gradients based on a gradient-perturbation model, respectively, wherein for each selected initial gradient: an input to the gradient-perturbation model comprises the selected initial gradient having a value x, the gradient-perturbation model changes x into a first continuous value with a first probability or a second continuous value with a second probability, and the first and second probabilities are determined based on x, and sending the one or more perturbed gradients from the first electronic device to a second electronic device.","['G06F21/6263', 'G06N3/0442', 'G06N3/0464', 'G06N3/09', 'G06N3/098', 'G06N20/00', 'G06N3/044']"
US10976412B2,Deep learning for super resolution in a radar system,"A system and method to use deep learning for super resolution in a radar system include obtaining first-resolution time samples from reflections based on transmissions by a first-resolution radar system of multiple frequency-modulated signals. The first-resolution radar system includes multiple transmit elements and multiple receive elements. The method also includes reducing resolution of the first-resolution time samples to obtain second-resolution time samples, implementing a matched filter on the first-resolution time samples to obtain a first-resolution data cube and on the second-resolution time samples to obtain a second-resolution data cube, processing the second-resolution data cube with a neural network to obtain a third-resolution data cube, and training the neural network based on a first loss obtained by comparing the first-resolution data cube with the third-resolution data cube. The neural network is used with a second-resolution radar system to detect one or more objects.","['G01S7/417', 'G01S13/42', 'G01S13/584', 'G01S13/931', 'G06N3/045', 'G06N3/084']"
CN112801895B,An image inpainting algorithm based on two-stage attention mechanism GAN network,"The invention discloses a two-stage attention mechanism-based GAN network image restoration algorithm, which comprises the following steps: building a Pythroch deep learning framework operating environment based on a GPU version; preparing data sets, wherein each data set comprises a real picture and a mask; constructing a depth neural network from an operation image to an image, wherein the depth neural network comprises a generator and a discriminator; a generalization experiment was performed. The generator adopts an encoder-decoder structure and is continuously trained to generate a predicted image; the discriminator measures the authenticity of the generated image against loss as a loss function. And continuously iterating the joint optimization generator and the arbiter to improve the network prediction performance. The invention can train and realize the end-to-end self-supervision image conversion, and can be used for learning the mapping relation between the input image and the output image and learning the loss function for training the mapping relation.","['G06T5/77', 'G06N3/04', 'G06N3/08', 'G06T2207/10004']"
CN109993825B,Three-dimensional reconstruction method based on deep learning,"A three-dimensional reconstruction method based on deep learning is disclosed, which comprises the following steps: (1) Reconstructing the constrained potential vector of the input image into a complete three-dimensional shape of the target, learning the mapping between the partial three-dimensional shape and the complete three-dimensional shape, and then realizing three-dimensional reconstruction of a single depth image; (2) Learning an intermediate feature representation between the three-dimensional real object and the reconstructed object, thereby obtaining the target latent variable in step (1); (3) And (3) converting the voxel floating value predicted in the step (1) into a binary value by using an extreme learning machine, and completing high-precision reconstruction.","['G06T17/20', 'G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/048', 'G06N3/09', 'G06N3/094', 'G06T17/00', 'G06T7/50', 'G06V10/82', 'G06V20/653', 'G06T2207/20084', 'Y02T10/40']"
US10832450B2,Semantic preserved style transfer,"A method for image style transfer using a Semantic Preserved Generative Adversarial Network (SPGAN) includes: receiving a source image; inputting the source image into the SPGAN; extracting a source-semantic feature data from the source image; generating, by the first decoder, a first synthetic image including the source semantic content of the source image in a target style of a target image using the source-semantic feature data extracted by the first encoder of the first generator network, wherein the first synthetic image includes first-synthetic feature data; determining a first encoder loss using the source-semantic feature data and the first-synthetic feature data; discriminating the first synthetic image against the target image to determine a GAN loss; determining a total loss as a function of the first encoder loss and the first GAN loss; and training the first generator network and the first discriminator network.","['G06N3/088', 'G06T3/04', 'B60R11/04', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T11/001', 'G06T11/60', 'G06T5/001', 'G06T5/50']"
CN111737743B,Deep learning differential privacy protection method,"The invention discloses a deep learning differential privacy protection method, and belongs to the technical field of information system safety. The invention provides a novel deep learning differential privacy protection model, and adopts WGAN to generate an image result on data subjected to model privacy protection treatment, selects a result closest to a real image from the generated image, compares the similarity between the generated result and an original image, calculates a difference value, and performs threshold comparison, and feeds back and adjusts privacy parameters in a model gradient under the condition of limiting the similarity threshold, thereby providing a certain pushing effect for the application of differential privacy in the fields of deep learning and the like.","['G06F21/6245', 'G06F18/24', 'G06N3/044', 'G06N3/045', 'G06N3/084']"
US11856013B2,Method and system for detecting lateral movement in enterprise computer networks,"A system includes a log receiving module, an authentication graph module, a sampling module, an embedding module, a training module, a link prediction module, and an anomaly detection module. The log receiving module is configured to receive a first plurality of network-level authentication logs. The authentication graph module is configured to generate an authentication graph. The sampling module is configured to generate a plurality of sequences. The embedding module is configured to tune a plurality of node embeddings according to the plurality of sequences. The training module is configured to train a link predictor according to the plurality of node embeddings and ground-truth edge information from the authentication graph. The link prediction module is configured to apply the link predictor to performs a link prediction. The anomaly detection module is configured to perform anomaly detection according to the link prediction.","['H04L63/1425', 'G06N20/00', 'G06N5/022', 'G06N5/04', 'G06N7/01', 'H04L63/08', 'H04L63/0876', 'H04L63/1441']"
US20220301114A1,Noise Reconstruction For Image Denoising,"An apparatus for denoising an image, the apparatus having a processor configured to receive an input image, implement a trained artificial intelligence model to form an estimate of a noise pattern in the input image and form an output image by subtracting the estimate of the noise pattern from the input image, the model being configured to form the estimate of the noise pattern such that the estimate of the noise pattern is representative of a noise pattern that is characteristic to a specific image sensor type.","['G06T5/70', 'G06T5/002', 'G06N3/088', 'G06T5/50', 'G06T5/60', 'G06T7/80', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224']"
US20230077187A1,Three-Dimensional Facial Reconstruction,A computer implemented method of generating a three-dimensional facial rendering from a two-dimensional image having a facial image includes: generating a three-dimensional shape model of the facial image and a low resolution two-dimensional texture map of the facial image from the two-dimensional image using a fitting neural network; applying a super-resolution model to the low resolution two-dimensional texture map to generate a high resolution two-dimensional texture map; generating a two-dimensional diffuse albedo map from the high resolution texture map using a de-lighting image-to-image translation neural network; and rendering a high resolution three-dimensional model of the facial image using the two-dimensional diffuse albedo map and the three dimensional shape model.,"['G06T15/205', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T11/001', 'G06T15/04', 'G06T17/00', 'G06T17/20', 'G06T3/4046', 'G06T3/4053', 'G06V20/64', 'G06V40/16', 'G06N3/02', 'G06T13/40', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084']"
US12106845B2,Clinically relevant anonymization of photos and video,"The disclosed systems and methods for anonymizing clinical data may include receiving representation data corresponding to a body part. The representation data may include a clinically relevant region and an anonymization region. The method may include extracting, from the representation data, clinical representation data corresponding to the clinically relevant region of the representation data and generating artificial representation data corresponding to the anonymization region of the representation data. The method may further include creating, based at least on the clinical representation data and the artificial representation data, anonymized representation data that substantially preserves the clinically relevant region. Various other methods, systems, and computer-readable media are also disclosed.","['G16H30/20', 'A61B5/0088', 'G06F21/6254', 'G06T11/001', 'G06V40/171', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G06T2210/41']"
US10798386B2,Video compression with generative models,"A processing system having at least one processor may obtain a sequence of frames of a video, and detect a correlation between visual properties of a first frame of the sequence of frames and a second frame of the sequence of frames, where the second frame comprises a next frame following the first frame in the sequence of frames. The processing system may then generate a first difference vector comprising a difference between a latent space representation of the second frame and a latent space representation of the first frame in response to detecting the correlation between the visual properties, where the latent space representation of the first frame and the latent space representation of the second frame are generated via an autoencoder, and store the first difference vector in a first encoding block.","['H04N19/94', 'H04N19/149', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/088', 'G06N3/094', 'H04N19/137', 'H04N19/147', 'H04N19/176']"
US20210225463A1,System and Method with Federated Learning Model for Medical Research Applications,The technology disclosed relates to a system and method of conducting virtual clinical trials. The system comprises a sponsor server configured to specify a target mapping of a clinical trial objective mapper. The target mapping maps participant-specific clinical data to an objective of a virtual clinical trial. The system comprises a plurality of edge devices accessible by respective participants in a plurality of participants. The system comprises a clinical trial conductor server configured to distribute coefficients of the clinical trial objective mapper to respective edge devices to implement distributed training of the clinical trial objective mapper. The clinical trial conductor server is configured to receive participant-specific gradients generated during the distributed training in response to processing participant-specific clinical data. The clinical trial conductor server is configured to aggregate the participant-specific gradients to generate aggregated gradients that cumulatively satisfy the target mapping of the clinical trial objective mapper.,"['G16H10/20', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G16H40/67', 'G16H50/20', 'G16H70/60']"
US11587548B2,Text-driven video synthesis with phonetic dictionary,"Presented herein are novel approaches to synthesize video of the speech from text. In a training phase, embodiments build a phoneme-pose dictionary and train a generative neural network model using a generative adversarial network (GAN) to generate video from interpolated phoneme poses. In deployment, the trained generative neural network in conjunction with the phoneme-pose dictionary convert an input text into a video of a person speaking the words of the input text. Compared to audio-driven video generation approaches, the embodiments herein have a number of advantages: 1) they only need a fraction of the training data used by an audio-driven approach; 2) they are more flexible and not subject to vulnerability due to speaker variation; and 3) they significantly reduce the preprocessing, training, and inference times.","['G10L25/57', 'G06F16/7834', 'G06F16/7867', 'G06F40/242', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G10L13/027', 'G10L13/08', 'G10L15/187']"
US11227187B1,Generating artificial intelligence solutions using raw data and simulated data,"Artificial intelligence systems are created for end users based on raw data received from the end users or obtained from any source. Training, validation and testing data is maintained securely and subject to authentication prior to use. A machine learning model is selected for providing solutions of any type or form and trained, verified and tested by an artificial intelligence engine using such data. A trained model is distributed to end users, and feedback regarding the performance of the trained model is returned to the artificial intelligence engine, which updates the model on account of such feedback before redistributing the model to the end users. When an end user provides data to an artificial intelligence engine and requests a trained model, the end user monitors progress of the training of the model, along with the performance of the model in providing quality artificial intelligence solutions, via one or more dashboards.","['G06F18/214', 'G06T7/0004', 'G06K9/6256', 'G06N20/00', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06T3/40', 'G06T3/60', 'G06T5/007', 'G06T5/90', 'G06T7/11', 'G10L15/19', 'G10L15/22', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06V10/778', 'G06V10/945', 'G10L15/063']"
US12282837B2,Systems and methods for processing data collected in an industrial environment using neural networks,"Methods and an expert system for processing a plurality of inputs collected from sensors in an industrial environment are disclosed. A modular neural network, where the expert system uses one type of neural network for recognizing a pattern relating to at least one of: the sensors, components of the industrial environment and a different neural network for self-organizing a data collection activity in the industrial environment is disclosed. A data communication network configured to communicate at least a portion of the plurality of inputs collected from the sensors to storage device is also disclosed.","['G05B19/4183', 'B62D15/0215', 'G01M13/028', 'G01M13/04', 'G01M13/045', 'G05B13/028', 'G05B19/4184', 'G05B19/41845', 'G05B19/4185', 'G05B19/41865', 'G05B19/41875', 'G05B23/0221', 'G05B23/0229', 'G05B23/024', 'G05B23/0264', 'G05B23/0283', 'G05B23/0286', 'G05B23/0289', 'G05B23/0291', 'G05B23/0294', 'G05B23/0297', 'G06F18/2178', 'G06N20/00', 'G06N3/006', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0499', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N5/046', 'G06N7/01', 'G06Q10/04', 'G06Q10/0639', 'G06Q30/02', 'G06Q30/0278', 'G06Q30/06', 'G06Q50/00', 'G06V10/7784', 'G06V10/82', 'G16Z99/00', 'H02M1/12', 'H03M1/12', 'H03M13/353', 'H04B17/23', 'H04B17/26', 'H04B17/309', 'H04B17/318', 'H04B17/345', 'H04L1/0002', 'H04L1/0041', 'H04L1/18', 'H04L1/1854', 'H04L1/1874', 'H04L67/1097', 'H04L67/12', 'H04W4/35', 'H04W4/38', 'H04W4/70', 'H04W4/80', 'B62D5/0463', 'G05B19/042', 'G05B2219/32287', 'G05B2219/35001', 'G05B2219/37337', 'G05B2219/37351', 'G05B2219/37434', 'G05B2219/37537', 'G05B2219/40115', 'G05B2219/45004', 'G05B2219/45129', 'G05B23/02', 'G05B23/0208', 'G06F17/18', 'G06F18/21', 'G06F18/217', 'G06F18/25', 'G06F2218/00', 'G06N3/042', 'G06N3/126', 'H01B17/40', 'H03M13/1102', 'H04B17/29', 'H04B17/40', 'H04L1/0009', 'H04L1/0057', 'H04L1/0076', 'H04L5/0064', 'H04L67/306', 'H04L67/565', 'H04L69/163', 'H04L69/164', 'Y02P80/10', 'Y02P90/02', 'Y02P90/80', 'Y04S40/18', 'Y04S50/00', 'Y04S50/12', 'Y10S707/99939']"
US11735322B2,Systems and methods for ossification center detection and bone age assessment,"Systems and methods for ossification center detection (OCD) and bone age assessment (BAA) may be provided. The method may include obtaining a bone age image of a subject. The method may include generating a normalized bone age image by preprocessing the bone age image. The method may include determining, based on the normalized bone age image, positions of a plurality of ossification centers using an ossification center localization (OCL) model. The method may include estimating, based on the normalized bone age image and information related to the positions of the plurality of ossification centers, a bone age of the subject using a bone age assessment (BAA) model.","['G16H50/50', 'A61B5/4504', 'G06T3/4007', 'G06T7/0012', 'G06T7/11', 'G06T7/143', 'G06T7/73', 'G06T7/74', 'G06V10/143', 'G06V40/107', 'G16H10/60', 'G16H30/00', 'G16H30/40', 'G16H50/30', 'A61B5/055', 'A61B5/7203', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30008']"
CN112084962B,Face privacy protection method based on generation type countermeasure network,"The invention relates to a face privacy protection method based on a generation type confrontation network, which is characterized in that: the face de-recognition method based on the generation countermeasure network is respectively loaded in the workstation and the robot platform, and the feature model is trained on the workstationW(ii) a When a camera on the robot platform captures a face image, the robot platform applies a face recognition method based on a generated countermeasure network to the face image needing privacy protection to recognize the face, so that the privacy characteristics of the face image are protected, and the visual privacy of a user is ensured not to be invaded. The face recognition method based on the generation countermeasure network comprises 1 generator of the improved U-Net networkGAnd 2 discriminatorsD 1、D 2The discriminator and the generator are composed of convolution layer, residual block and self-attention layer. The method has the characteristics of reducing or eliminating the problems of mode collapse and over-fitting in the training process, improving the quality of the generated image and protecting the privacy of the image visually.","['G06V40/172', 'G06F18/214', 'G06F21/6245', 'G06N3/045', 'G06N3/08']"
CN108417205B,Semantic understanding training method and system,"The invention discloses a semantic understanding training method, a semantic understanding training system and electronic equipment, wherein the method comprises the following steps: carrying out semantic annotation on a correct text of user voice data to generate a correct text with semantic annotation; inputting the user voice data into a voice recognition system for recognition to obtain a recognition text; and randomly inputting the correct text, the correct text with semantic labels and the recognition text into a semantic understanding system to perform unsupervised adaptive training on the semantic understanding system. The invention can label only the correct text without labeling the recognition text, and can train to obtain a semantic understanding system robust to speech recognition errors by carrying out unsupervised self-adaptive learning on the correct text, the correct text with semantic labels and the recognition text without labels.","['G10L15/26', 'G06F40/117', 'G06F40/30', 'G10L15/063', 'G10L15/1822']"
US11868933B2,Intelligence driven method and system for multi-factor optimization of schedules and resource recommendations for smart construction,Techniques to generate a digitally optimized schedule for a construction activity to meet a construction objective(s) of a construction project are disclosed. An artificial intelligence system receives a plurality of input data sets that impact the construction project. Each of the plurality of input data sets is processed to achieve the construction objective(s). The artificial intelligence system processes the plurality of input data sets using a respective ensemble of machine learning models. The artificial intelligence system generates machine learning validated intermediate output data sets corresponding to each of the plurality of input data sets. The artificial intelligence system implements a supervisory machine learning model to generate an optimized schedule for the construction activity based on the machine learning validated intermediate output data sets and the construction objective(s).,"['G06Q10/06312', 'G06F18/217', 'G06N20/20', 'G06N3/045', 'G06N3/09', 'G06N5/022', 'G06Q10/06311', 'G06Q10/06316', 'G06Q10/0633', 'G06Q10/103', 'G06N3/0475']"
US20210117760A1,Methods and apparatus to obtain well-calibrated uncertainty in deep neural networks,"Methods, systems, and apparatus to obtain well-calibrated uncertainty in probabilistic deep neural networks are disclosed. An example apparatus includes a loss function determiner to determine a differentiable accuracy versus uncertainty loss function for a machine learning model, a training controller to train the machine learning model, the training including performing an uncertainty calibration of the machine learning model using the loss function, and a post-hoc calibrator to optimize the loss function using temperature scaling to improve the uncertainty calibration of the trained machine learning model under distributional shift.","['G06N3/0472', 'G06N3/084', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N3/047', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06N3/048']"
US12172667B2,3D surface reconstruction with point cloud densification using deep neural networks for autonomous systems and applications,"In various examples, a 3D surface structure such as the 3D surface structure of a road (3D road surface) may be observed and estimated to generate a 3D point cloud or other representation of the 3D surface structure. Since the estimated representation may be sparse, a deep neural network (DNN) may be used to predict values for a dense representation of the 3D surface structure from the sparse representation. For example, a sparse 3D point cloud may be projected to form a sparse projection image (e.g., a sparse 2D height map), which may be fed into the DNN to predict a dense projection image (e.g., a dense 2D height map). The predicted dense representation of the 3D surface structure may be provided to an autonomous vehicle drive stack to enable safe and comfortable planning and control of the autonomous vehicle.","['G06N3/0464', 'G06T17/20', 'B60W40/00', 'B60W40/09', 'B60W50/00', 'B60W60/001', 'G06N20/00', 'G06N3/02', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N7/01', 'B60W2050/0005', 'B60W2050/0028', 'B60W2420/403', 'B60W2420/408', 'B60W2552/00', 'B60W2552/20', 'B60W2552/35', 'G06N3/0442', 'G06N3/0455', 'G06N3/084']"
US20240266074A1,"Cognitive Communications, Collaboration, Consultation and Instruction with Multimodal Media and Augmented Generative Intelligence","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with networked cognitive collaboration, augmented clinical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal clinical communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms, including augmented generative AI algorithms, models and systems. The invention enables cognitively-enriched, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized clinical intelligence.","['A61B34/30', 'G06F40/169', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16H10/60', 'G16H15/00', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H80/00', 'H04L12/1822', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/152', 'A61B2090/365', 'A61B2090/373', 'A61B2090/376', 'A61B2090/378', 'A61B34/25', 'A61B34/73', 'A61B90/361', 'H04L51/10', 'H04M3/561', 'H04M3/567', 'H04M7/0027']"
US10853970B1,System for estimating a three dimensional pose of one or more persons in a scene,"A system for estimating a three dimensional pose of one or more persons in a scene is disclosed herein. The system includes at least one camera, the at least one camera configured to capture an image of the scene; and a data processor including at least one hardware component, the data processor configured to execute computer executable instructions. The computer executable instructions comprising instructions for: (i) receiving the image of the scene from the at least one camera; (ii) extracting features from the image of the scene for providing inputs to a convolutional neural network; (iii) generating one or more volumetric heatmaps using the convolutional neural network; and (iv) applying a maximization function to the one or more volumetric heatmaps to obtain a three dimensional pose of one or more persons in the scene.","['G06T7/75', 'G06T7/85', 'G06T1/0007', 'G06T1/20', 'G06T7/73', 'G06T2200/04', 'G06T2207/10012', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
CN110866536B,A cross-regional enterprise tax evasion identification method based on PU learning,"The invention discloses a cross-regional enterprise tax evasion identification method based on PU learning, which comprises the following steps: firstly, based on PU learning, generating a label of a non-label sample in a source domain by utilizing a small amount of labeled positive samples in the source domain; secondly, constructing a cross-region enterprise tax evasion identification model by a domain adaptation method for maximizing classifier difference; and finally, carrying out tax evasion identification on the tax payment data of the target domain by using the trained tax evasion identification model. The method achieves the purpose of establishing the tax evasion identification model for the target domain without the label of the tax payment data under the condition that the tax payment data of the source domain only has the positive sample and a large number of unmarked samples.","['G06F18/2411', 'G06F18/214', 'G06N3/045', 'G06N3/084', 'G06Q40/123']"
US10980096B2,Learning a lighting preference based on a reaction type,"During operation, a computer provides, based at least in part on an initial lighting preference of an individual, instructions specifying initial lighting states of one or more lights in a lighting configuration in an environment, where an initial lighting state of a given light includes an intensity and a color of the given light. Then, the computer receives sensor data specifying a non-verbal physical response of the individual to initial lighting states. Moreover, the computer determines, based at least in part on the non-verbal physical response, a type of reaction of the individual to the initial lighting state. Next, the computer selectively modifies, based at least in part on a lighting behavior history of the individual and the determined type of reaction, the initial lighting preference of the individual to obtain an updated lighting preference.","['G06V10/764', 'H05B47/175', 'G06F18/2155', 'G06F30/12', 'G06F30/13', 'G06K9/00335', 'G06K9/6259', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06V10/7753', 'G06V10/82', 'G06V40/107', 'G06V40/20', 'H04L12/282', 'H04Q9/00', 'H05B47/11', 'H05B47/115', 'H05B47/12', 'H05B47/125', 'H05B47/155', 'H05B47/16', 'H05B47/198', 'G06F3/167', 'G06F40/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G10L15/00', 'G10L25/51', 'H05B47/197', 'Y02B20/40']"
CN112667080B,Intelligent control method for electroencephalogram signal unmanned platform based on deep convolution countermeasure network,"The invention discloses an intelligent control method of an electroencephalogram signal unmanned platform based on a deep convolution countermeasure network, which comprises the steps that a terminal carries out noise removal on an acquired electroencephalogram signal to obtain a denoised electroencephalogram signal; deep feature extraction is carried out on the denoised electroencephalogram signals through a capsule network, and deep feature signals are obtained; the deep characteristic signals and the electroencephalogram signals are fused and then classified and identified, and corresponding control instruction signals are determined; and the terminal respectively performs off-line test verification and on-line test verification on the unmanned platform, and after the verification is successful, the unmanned platform receives and executes the control instruction signal sent by the terminal. The invention utilizes the existing noise data set to form a one-dimensional electroencephalogram signal training network, simplifies a mathematical model, solves the problem of insufficient noise training data, utilizes a self-encoder architecture to reconstruct a one-dimensional prediction signal, performs feature selection by a attention mechanism, and improves the calculation efficiency.",['Y02P90/02']
CN110689081B,Weak supervision target classification and positioning method based on bifurcation learning,"The invention provides a method for classifying and positioning a weakly supervised target based on bifurcation learning, which comprises the following steps: constructing a training sample set; constructing a classification and positioning network based on the hierarchical bifurcation activation module or the hierarchical bifurcation activation module-difference bifurcation activation module; inputting samples in a training sample set into a preliminarily constructed classification and positioning network for multi-scale target feature extraction; designing a loss function, calculating a gradient according to the loss function, carrying out gradient back transmission on the whole convolutional layer network, updating convolutional layer network parameters, and realizing optimization of the network. The method of the invention provides two divergent learning forms: the method can find the complementation of the target and a visual mode with discrimination, can keep the high performance of image classification while accurately positioning the target, and has very good practicability and expansibility.","['G06F18/217', 'G06F18/24', 'G06N3/045']"
WO2020235696A1,"Artificial intelligence apparatus for interconverting text and speech by considering style, and method for same","An embodiment of the present invention provides an artificial intelligence apparatus for interconverting text and speech, the artificial intelligence apparatus comprising: a memory which stores a plurality of Text-To-Speech (TTS) engines; and a processor which obtains image data including text, determines a speech style corresponding to the text, generates speech corresponding to the text by using a TTS engine corresponding to the determined speech style among the plurality of TTS engines, and outputs the generated speech.","['G10L25/30', 'G10L13/033', 'G06N20/00', 'G06N3/08', 'G10L13/08', 'G10L13/10', 'G10L15/02', 'G10L15/16', 'G10L15/22', 'G10L15/26', 'G10L2015/227']"
US11729198B2,Mapping a vulnerability to a stage of an attack chain taxonomy,"In an embodiment, a semantic model and a semantic model training method that obtains a textual description of one or more features associated with a first vulnerability that has been used in one or more attacks. Text is parsed from the first textual description in accordance with one or more rules. The system determines a first label for the first vulnerability that is associated with one or more of a plurality of stages of an attack chain taxonomy. The model is generated or refined to map the parsed text to the first label associated with the one or more stages of the attack chain taxonomy.","['H04L63/1433', 'G06F40/205', 'G06F40/30', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/0442', 'G06N3/09', 'G06N5/022', 'G06N5/04']"
CN113887136B,Electric automobile motor bearing fault diagnosis method based on improved GAN and ResNet,"The invention belongs to the technical field of motor fault diagnosis and health management of electric vehicles, and provides an electric vehicle motor bearing fault diagnosis method based on improved GAN and ResNet. Firstly, discretizing a bearing vibration signal and constructing an unbalanced data set in an actual scene; the countermeasure generation network is improved by introducing category labels and constructing a loss function by using Wasserstein distance, and data with more category characteristics is generated so as to solve the problem of unbalanced data sets; and finally, inputting the balance data set with the generated data and the real data into a fault diagnosis network, and constructing a multi-scale residual error attention convolution block in the diagnosis network to solve the gradient disappearance problem of deep network training and learn multi-scale deep features. The method aims at solving the problems that a data set is unbalanced and effective features are difficult to extract under complex working conditions caused by difficult collection of fault data in a real scene, and the generated data is closer to the real data, so that the model can extract effective multi-scale deep features.","['G06F30/27', 'G01M13/045', 'G06N3/045', 'G06N3/084', 'G06F2119/10']"
US11948177B2,Image/text-based design creating device and method,Provided is a design creating device including: a parsing unit for parsing image data and text data; a learning unit for learning a design creation model by using artificial intelligence on the basis of parsed image data and text data; and a design creating unit for creating a new design of a specific item or a design element by using the design creation model learned by the learning unit.,"['G06Q30/06', 'G06Q50/10', 'G06F16/951', 'G06F18/21', 'G06F30/27', 'G06F40/205', 'G06N3/045', 'G06N3/0475', 'G06N3/088', 'G06N3/094', 'G06Q30/0621', 'G06Q30/0643', 'G06Q50/01', 'G06N3/047']"
US20240202425A1,Implementation of deep neural networks for testing and quality control in the production of memory devices,"Techniques are presented for the application of neural networks to the fabrication of integrated circuits and electronic devices, where example are given for the fabrication of non-volatile memory circuits and the mounting of circuit components on the printed circuit board of a solid state drive (SSD). The techniques include the generation of high precision masks suitable for analyzing electron microscope images of feature of integrated circuits and of handling the training of the neural network when the available training data set is sparse through use of a generative adversary network (GAN).","['G06F30/398', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'H01L22/12', 'H05K13/081', 'G06F2119/22']"
US11636634B2,Systems and methods for positron emission tomography image reconstruction,Methods and systems for PET image reconstruction are provided. A method may include obtaining an image sequence associated with a subject. The image sequence may include one or more images generated via scanning the subject at one or more consecutive time periods. The method may also include obtaining a target machine learning model. The method may further include generating at least one target image using the target machine learning model based on the image sequence. The at least one target image may present a dynamic parameter associated with the subject. The target machine learning model may provide a mapping between the image sequence and the at least one target image.,"['G06N3/045', 'A61B6/037', 'A61B5/7267', 'A61B6/486', 'G06N3/084', 'G06T11/003', 'G06T11/008', 'A61B6/4417', 'A61B6/5205', 'G06T2210/41', 'G06T2211/424', 'G06T2211/441']"
US20220360597A1,Cyber security system utilizing interactions between detected and hypothesize cyber-incidents,"An apparatus may include a set of modules and artificial intelligence models to detect a cyber incident, a simulator to simulate an actual cyber attack of the cyber incident on a network including physical devices being protected by the set of modules and artificial intelligence models; and a feedback loop between i) the set of modules and artificial intelligence models and ii) the simulator, during an ongoing detected cyber incident. An attack path modeling module is configured to feed details of the detected incident by a cyber threat module into an input module of the simulator, and to run one or more hypothetical simulations of that detected incident in order to predict and control an autonomous response to the detected incident. Any software instructions forming part of the set of modules, the artificial intelligence models, and the simulator are stored in an executable form in memories and executed by processors.","['G06F21/577', 'G06F21/552', 'G06N20/00', 'G06N7/01', 'H04L51/212', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/1483', 'G06N3/006', 'H04L63/1416']"
EP4199607A1,System energy efficiency in a wireless network,"The present disclosure relates to a device for use in a wireless network, the device including: a processor configured to: provide input data to a trained machine learning model, the input data representative of a network environment of the wireless network, wherein the trained machine learning model is configured to provide, based on the input data, output data representative of an expected performance of a plurality of configurations of network components with respect to power consumption and performance of the wireless network; select a configuration of a network component from the plurality of configurations based on the output data of the trained machine learning model; and instruct an operation of the network component according to the selected configuration; and a memory coupled with the processor, the memory storing the input data provided to the trained machine learning model and/or the output data from the trained machine learning model.","['H04B17/3912', 'H04W52/0258', 'G06N20/00', 'G06N3/02', 'H04B17/3913', 'H04L41/0833', 'H04L41/0893', 'H04L41/16', 'H04W24/06', 'H04W48/16', 'H04W52/0206', 'Y02D30/70']"
CN112101083B,Method and system for weakly supervised object detection using neural networks,"The invention discloses weak supervised object detection using one or more neural networks, and in particular, devices, systems, and techniques for detecting objects in images, including digital representations of such objects. In at least one embodiment, one or more objects in the image are detected based at least in part on one or more pseudo tags corresponding to the one or more objects.","['G06N3/084', 'G06V40/10', 'G06F18/2113', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/048', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06V10/25', 'G06V10/454', 'G06V10/765', 'G06V10/7753', 'G06V10/82', 'G06V20/10', 'G06N3/049']"
US12412132B2,Smart contract management of licensing and apportionment using a distributed ledger,Transaction-enabled methods for providing provable access to a distributed ledger with a tokenized instruction set for polymer production processes are described. A method may include accessing a distributed ledger comprising an instruction set for a polymer production process and tokenizing the instruction set. The method may further include interpreting an instruction set access request and providing provable access to the instruction set. The method may further include providing commands to a production tool of the polymer production process and recording the transaction on the distributed ledger.,"['G06Q10/04', 'G05B19/00', 'G05B19/41865', 'G05B19/4188', 'G06F16/182', 'G06F16/1865', 'G06F16/23', 'G06F16/2365', 'G06F16/2379', 'G06F16/24', 'G06F16/27', 'G06F16/951', 'G06F18/2148', 'G06F18/2155', 'G06F21/105', 'G06F21/602', 'G06F30/27', 'G06F9/3836', 'G06F9/3891', 'G06F9/466', 'G06F9/4806', 'G06F9/4881', 'G06F9/50', 'G06F9/5005', 'G06F9/5016', 'G06F9/5027', 'G06F9/5072', 'G06F9/541', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/042', 'G06N3/043', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06Q10/0631', 'G06Q10/06314', 'G06Q10/06315', 'G06Q10/067', 'G06Q20/06', 'G06Q20/065', 'G06Q20/0655', 'G06Q20/0855', 'G06Q20/12', 'G06Q20/123', 'G06Q20/145', 'G06Q20/29', 'G06Q20/308', 'G06Q20/367', 'G06Q20/38215', 'G06Q20/384', 'G06Q20/389', 'G06Q20/4016', 'G06Q20/405', 'G06Q30/0201', 'G06Q30/0202', 'G06Q30/0205', 'G06Q30/0206', 'G06Q30/0247', 'G06Q30/0273', 'G06Q30/06', 'G06Q40/04', 'G06Q40/10', 'G06Q50/04', 'G06Q50/06', 'G06Q50/184', 'H02J3/008', 'H02J3/14', 'H02J3/28', 'H02J3/388', 'H04L12/14', 'H04L47/783', 'H04L47/788', 'H04L47/83', 'H04L9/3239', 'H04L9/50', 'G05B2219/36542', 'G06F16/2457', 'G06F9/3838', 'G06N3/0418', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06N5/022', 'G06N5/046', 'G06Q20/4015', 'G06Q2220/00', 'G06Q2220/12', 'G06Q2220/18', 'G06Q30/0254', 'G06Q30/0276', 'G06Q50/01', 'H02J3/003', 'H04L67/10', 'H04L67/12', 'H04L67/34', 'H04L9/0643', 'Y02B70/3225', 'Y02D10/00', 'Y02P90/02', 'Y02P90/845', 'Y04S10/50', 'Y04S20/222', 'Y04S40/20', 'Y04S50/10', 'Y04S50/12', 'Y04S50/14']"
US20230377099A1,Synthesizing content using diffusion models in content generation systems and applications,"Approaches presented herein provide for the generation of synthesized data from input noise using a denoising diffusion network. A higher order differential equation solver can be used for the denoising process, with one or more higher-order terms being distilled into one or more separate efficient neural networks. A separate, efficient neural network can be called together with a primary denoising model at inference time without significant loss in sampling efficiency. The separate neural network can provide information about the curvature (or other higher-order term) of the differential equation, representing a denoising trajectory, that can be used by the primary diffusion network to denoise the image using fewer denoising iterations.","['G06T5/002', 'G06T5/70', 'G06N3/042', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/096', 'G06T11/00', 'G06T5/60', 'G06T7/64', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
US11297164B2,"Device and content agnostic, interactive, collaborative, synchronized mixed reality system and method","A method and system provides a device and content agnostic, interactive, collaborative and synchronized virtual world comprising of three dimensional and two dimensional virtual objects defined by data, which can be viewed, customized, built on and interacted with simultaneously by geographically disparate users with different device types, including VR, AR, Tablet, and Computer devices, whereby the content may be ingested from or controlled by data and models from external sources or the system's internal storage. A machine learning component is implemented as a set of software containers. The containerized solution can be deployed as an enterprise service, in a cloud architecture, or as a part of a monolithic deployment that runs natively in any one of the components as part of the larger architecture. Exemplary use cases include: Real Estate property demonstration, property design, landscape design; health care medical image presentation, clinical decision support, training; Military training, planning, observation, and combat decision support.","['H04L67/38', 'H04L67/131', 'A63F13/358', 'A63F13/44', 'A63F13/55', 'G06N20/20', 'G06T19/003', 'G09B9/003', 'H04L67/2809', 'H04L67/562', 'A63F13/497', 'A63F13/58']"
US11944903B2,Using playstyle patterns to generate virtual representations of game players,"In various embodiments of the present disclosure, playstyle patterns of players are learned and used to generate virtual representations (“bots”) of users. Systems and methods are disclosed that use game session data (e.g., metadata) from a plurality of game sessions of a game to learn playstyle patterns of users, based on user inputs of the user in view of variables presented within the game sessions. The game session data is applied to one or more machine learning models to learn playstyle patterns of the user for the game, and associated with a user profile of the user. Profile data representative of the user profile is then used to control or instantiate bots of the users, or of categories of users, according to the learned playstyle patterns.","['A63F13/56', 'A63F13/55', 'A63F13/355', 'A63F13/67', 'A63F13/795', 'A63F13/798', 'A63F13/825', 'G06N3/006', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06N7/00', 'A63F13/49', 'A63F13/497', 'A63F13/60', 'A63F13/79', 'A63F2300/208', 'A63F2300/535', 'A63F2300/55', 'A63F2300/5546', 'A63F2300/558', 'A63F2300/6027', 'G06N20/00']"
TWI847228B,"Computer-implemented method, system for dynamically monitoring and securing factory processes, equipment and control systems, and non-transitory, computer-readable storage medium","A system including a deep learning processor receives one or more control signals from one or more of a factory’s process, equipment and control (P/E/C) systems during a manufacturing process. The processor generates expected response data and expected behavioral pattern data for the control signals. The processor receives production response data from the one or more of the factory’s P/E/C systems and generates production behavioral pattern data for the production response data. The process compares at least one of: the production response data to the expected response data, and the production behavioral pattern data to the expected behavioral pattern data to detect anomalous activity. As a result of detecting anomalous activity, the processor performs one or more operations to provide notice or cause one or more of the factory’s P/E/C systems to address the anomalous activity.","['G06F21/552', 'G05B19/4155', 'G05B23/02', 'G05B23/0275', 'G06F21/554', 'G06F21/56', 'G06F21/566', 'G06N20/10', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'H04L63/1425', 'G05B2219/31368', 'G06F21/577', 'G06F2221/034', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N7/01', 'H04L63/1433']"
US10755129B2,Disease recognition from images having a large field of view,"In an embodiment, a computer-implemented method of detecting infected objects from large field-of-view images is disclosed. The method comprises receiving, by a processor, a digital image capturing multiple objects; generating, by the processor, a plurality of scaled images from the digital image respectfully corresponding to a plurality of scales; and computing a group of feature matrices for the digital image. The method further comprises, for each of the plurality of scaled images. selecting a list of candidate regions from the scaled image each likely to capture a single object; and for each of the list of candidate regions, performing the following steps: mapping the candidate region back to the digital image to obtain a mapped region; identifying a corresponding portion from each of the group of feature matrices based on the mapping; and determining whether the candidate region is likely to capture the single object infected with a disease based on the group of corresponding portions. In addition, the method comprises choosing a group of final regions from the lists of mapped regions based on the determining; and causing display of information regarding the group of final regions.","['G06K9/3241', 'G06F18/214', 'G06Q50/02', 'A01H1/04', 'C12N15/8281', 'G06F18/2411', 'G06F18/24133', 'G06K9/00664', 'G06K9/4642', 'G06K9/6271', 'G06V10/50', 'G06V10/764', 'G06V10/82', 'G06V20/10', 'G01N2021/8466', 'G06K9/34', 'G06K9/4652', 'G06K9/68', 'G06T2207/30188']"
US12051240B2,Predicting visible/infrared band images using radar reflectance/backscatter images of a terrestrial region,"The present invention relates to a method and apparatus that can predict the visible-infrared band images of a region of the Earth's surface that would be observed by an Earth Observation (EO) satellite or other high-altitude imaging platform, using data from radar reflectance/backscatter of the same region. The method and apparatus can be used to predict images of the Earth's surface in the visible-infrared bands when the view between an imaging instrument and the ground is obscured by cloud or some other medium that is opaque to electromagnetic (EM) radiation in the visible-infrared spectral range, approximately spanning 400-2300 nanometres (nm), but transparent to EM radiation in the radio-/microwave part of the spectrum. Regular, uninterrupted monitoring of the Earth's surface is important for a wide range of applications, from agriculture to defence.","['G06V20/13', 'G06T5/77', 'G01S13/867', 'G01S13/9004', 'G01S13/9021', 'G01S7/417', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T5/60', 'G06T5/92', 'G06T7/11', 'G01C11/02', 'G06T2207/10044', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30192']"
US12232891B2,Systems and methods for image data acquisition,"The present disclosure provides a system and method for image data acquisition. The method may include acquiring physiological data of a subject. The physiological data may correspond to a motion of the subject over time. The method may include obtaining a trained machine learning model configured to detect feature data represented in the physiological data. The method may include determining, based on the physiological data, an output result of the trained machine learning model that is generated based on the feature data. The method may include acquiring, based on the output result, image data of the subject using an imaging device.","['G16H30/20', 'A61B5/0245', 'A61B5/055', 'A61B5/08', 'A61B5/113', 'A61B5/318', 'A61B5/352', 'A61B5/7203', 'A61B5/7264', 'A61B5/7267', 'A61B5/7285', 'A61B6/037', 'A61B6/541', 'G01R33/5608', 'G01R33/5673', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N5/04', 'G06T7/0016', 'G16H10/60', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'A61B5/0035', 'A61B6/5247', 'G01R33/56', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06T2207/10104', 'G06T2207/20081']"
US20250070994A1,Generating improved digital transcripts utilizing digital transcription models that analyze dynamic meeting contexts,"The present disclosure relates to systems, non-transitory computer-readable media, and methods for improving digital transcripts of a meeting based on user information. For example, a digital transcription system creates a digital transcription model to automatically transcribe audio from a meeting based on documents associated with meeting participants, event details, user features, and other meeting context data. In one or more embodiments, the digital transcription model creates a digital lexicon based on the user information, which the digital transcription system uses to generate the digital transcript. In some embodiments, the digital transcription model trains and utilizes a digital transcription neural network to generate the digital transcript.","['G06F16/435', 'G06F16/345', 'G06F16/438', 'G06F16/44', 'G06F16/483', 'G06N20/00', 'G10L15/083', 'H04L12/1818', 'H04L12/1822', 'H04L12/1831', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N7/01', 'G10L15/1822', 'G10L2015/088', 'H04L51/10']"
US12125268B2,Method and device for testing the robustness of an artificial neural network,"A computer-implemented neural network system including a first machine learning system, in particular a first neural network, a second machine learning system, in particular a second neural network, and a third machine learning system, in particular a third neural network. The first machine learning system is designed to ascertain a higher-dimensional constructed image from a predefinable low-dimensional latent variable. The second machine learning system is designed to ascertain the latent variable again from the higher-dimensional constructed image, and the third machine learning system is designed to distinguish whether or not an image it receives is a real image.","['G06N3/088', 'G06V10/7747', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06V10/82']"
US11813480B2,Systems and methods for generating a dose distribution,"A system for generating a dose distribution is provided. The system may obtain a first dose distribution in at least a portion of a subject. The system may also obtain a trained machine learning model. The system may further generate, based on the first dose distribution and the trained machine learning model, a second dose distribution in the at least a portion of the subject, wherein the second dose distribution has a higher accuracy than that of the first dose distribution.","['A61N5/103', 'A61N5/1031', 'G06N20/00', 'A61N2005/0627', 'A61N2005/1034']"
US12306919B2,Systems and methods for dynamic passphrases,"Systems, devices, methods, and computer readable media are provided in various embodiments relating to generating a dynamic challenge passphrase data object. The method includes establishing, a plurality of data record clusters, representing a mutually exclusive set of structured data records of an individual, ranking the plurality of feature data fields based on a determined contribution value of each feature data field relative to the establishing of the data record cluster, and identifying, using the ranked plurality of feature data fields, a first and a second feature data field of the plurality of feature data fields. The method includes generating the dynamic challenge passphrase data object, wherein the first or the second feature data field is used to establish a statement string portion, and a remaining one of the first or the second feature data field is used to establish a question string portion and a correct response string.","['G06F21/32', 'G06F18/2113', 'G06F18/22', 'G06F18/24137', 'G06F18/251', 'G06F21/31', 'G06F21/33', 'G06F21/46', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06Q20/108', 'G06Q20/1085', 'G06Q20/202', 'G06Q20/206', 'G06Q20/322', 'G06Q20/3267', 'G06Q20/3276', 'G06Q20/36', 'G06Q20/38215', 'G06Q20/3825', 'G06Q20/385', 'G06Q20/4014', 'G06Q20/40145', 'G06Q20/4016', 'G06V10/17', 'G06V10/454', 'G06V10/764', 'G06V10/771', 'G06V10/776', 'G06V10/803', 'G06V10/82', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06V40/20', 'G06V40/40', 'G07G1/009', 'G10L15/25', 'G10L17/24', 'H04L63/0838', 'H04L63/0876', 'H04L9/0866', 'H04L9/3213', 'H04L9/3226', 'H04L9/3231', 'H04L9/3271', 'G06N3/047', 'G10L17/14']"
US11798261B2,Image face manipulation,"Aspects of the present disclosure involve a system comprising a computer-readable storage medium storing a program and a method for synthesizing a realistic image with a new expression of a face in an input image by receiving an input image comprising a face having a first expression; obtaining a target expression for the face; and extracting a texture of the face and a shape of the face. The program and method for generating, based on the extracted texture of the face, a target texture corresponding to the obtained target expression using a first machine learning technique; generating, based on the extracted shape of the face, a target shape corresponding to the obtained target expression using a second machine learning technique; and combining the generated target texture and generated target shape into an output image comprising the face having a second expression corresponding to the obtained target expression.","['G06V10/764', 'G06V10/82', 'G06V40/161', 'G06V40/168', 'G06V40/172', 'G06V40/175']"
US11354582B1,System and method for automated retrosynthesis,"A system and method for automated retrosynthesis which can reliably identify valid and practical precursors and reaction pathways. The methodology involves a k-beam recursive process wherein at each stage of recursion, retrosynthesis is performed using a library of molecule disconnection rules to identify possible precursor sets, validation of the top k precursor sets is performed using a transformer-based forward reaction prediction scoring system, the best candidate of the top k precursor sets is selected, and a database is searched to determine whether the precursors are commercially available. The recursion process is repeated until a valid chain of chemical reactions is found wherein all precursors necessary to synthesize the target molecule are found to be commercially available.","['G16B15/30', 'G06F16/951', 'G06F18/214', 'G06F18/22', 'G06K9/6215', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06N5/01', 'G06N5/022', 'G06N7/01', 'G06V30/10', 'G16B15/00', 'G16B40/00', 'G16B40/20', 'G16B45/00', 'G16B50/10', 'G16C20/10', 'G16C20/70', 'G06N3/006']"
WO2020235712A1,Artificial intelligence device for generating text or speech having content-based style and method therefor,"An embodiment of the present invention provides an artificial intelligence device for generating speech having a content-based style, the artificial intelligence device comprising: a memory for storing a plurality of text-to-speech (TTS) engines; and a processor for acquiring image data or text data including a text, extracting at least one content keyword corresponding to the text, determining a speech style on the basis of the extracted content keyword, generating speech corresponding to the text by using a TTS engine corresponding to the determined speech style, among the plurality of TTS engines, and outputting the generated speech.","['G10L13/047', 'G06F40/279', 'G06Q50/10', 'G06F40/103', 'G06F40/295', 'G06N20/10', 'G06N3/09', 'G10L13/08', 'G10L13/10', 'G10L13/033']"
US11836741B2,"Systems and methods for identifying, tracking, and managing a plurality of social network users having predefined characteristics","Systems and methods of an integrated technology platform create a marketplace providing dashboards configured to allow brands and social media influencers to directly connect with each other. The system includes an integrated platform that enables an advertising party to find social media influencers who are most suited to the brands' contexts, market appeal, and demographic targets, build and manage relationships with the influencers, and identify fake influencers using machine learning models.","['G06Q30/0185', 'G06F16/27', 'G06N20/10', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06Q30/0201', 'G06Q30/0242', 'G06Q30/0269', 'G06Q30/0276', 'G06Q50/01']"
US11430523B2,Storage device and method for operating the same,"A storage device is provided. The storage device includes a nonvolatile memory device including a first block and a second block, and a controller including processing circuitry configured to, predict a number of writes to be performed on the nonvolatile memory device using a machine learning model, determine a type of reclaim command based on the predicted number of writes, the reclaim command for reclaiming data of the first block to the second block, and issue the reclaim command.","['G06F3/0679', 'G06F12/0246', 'G06F11/1048', 'G06F12/0882', 'G06F18/214', 'G06F3/0605', 'G06F3/0619', 'G06F3/064', 'G06F3/0644', 'G06F3/065', 'G06K9/6256', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0475', 'G06N3/094', 'G11C16/14', 'G11C16/26', 'G11C16/3472', 'G11C29/42', 'G11C29/44', 'G06F2212/7202']"
US20200097389A1,Error recovery,"A system and method may provide assistance to programmer during programming to detect and predict the existence of errors in code and, in some aspects, predict fixes for erroneous code. In some aspects, the system and method may use artificial intelligence to learn based on edits made by programmers, by observing code changes that cause errors and code changes that fix errors, or based on other data.","['G06F11/3476', 'G06F11/0775', 'G06F11/0793', 'G06F11/302', 'G06F11/3055', 'G06F11/3404', 'G06F11/3447', 'G06F11/3495', 'G06F11/3612', 'G06F11/3636', 'G06F11/366', 'G06F18/214', 'G06K9/6256', 'G06N3/04', 'G06N3/084', 'G06N3/045', 'G06N3/047']"
US20230120282A1,"Systems and methods for managing autoimmune conditions, disorders and diseases","An artificial intelligence (AI) system and methods for management of an autoimmune or inflammatory condition, disorder or disease in a patient for the diagnosis, prognosis, or risk assessment of symptoms thereof. The AI system includes patient and provider applications and a payer application interface accessible via a communications network. The system contains a data-driven recommendation engine using machine learning and/or deep learning based on active monitoring of patients with an autoimmune or inflammatory-related condition, disorder, or disease. The system can alert clinicians to an impending symptom flare and provide a treatment solution that reduces symptom severity, reduces or eliminates the onset.","['G16H20/10', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G16B40/20', 'G16H10/60', 'G16H15/00', 'G16H40/67', 'G16H50/20', 'G16H80/00', 'G06N5/01', 'G06N7/01']"
US20220415471A1,Method and system for using sensor data to identify secondary conditions of a user based on a detected joint misalignment of the user who is using a treatment device to perform a treatment plan,"A method includes receiving treatment data associated with a user capable of using a treatment device to perform a treatment plan. The method also includes receiving alignment data associated with the user while the user engages in at least one activity and receiving at least one alignment characteristic associated with the user and determining, using at least the at least one alignment characteristic, whether the at least one alignment characteristic correlates with at least one secondary condition of the user. The method also includes generating secondary condition information indicating at least the secondary condition and modifying at least one aspect of the treatment plan in response to receiving, from a healthcare professional, treatment plan input. The treatment plan input includes at least one modification to the at least one aspect of the treatment plan and wherein, further, the treatment plan input is generated based on the secondary condition information.","['A61H1/0214', 'G16H20/30', 'A61H1/024', 'A63B21/00178', 'A63B21/00181', 'A63B21/0058', 'A63B22/0605', 'A63B24/0062', 'A63B24/0087', 'G06N20/00', 'G16H15/00', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H80/00', 'A61H2201/1215', 'A61H2201/1261', 'A61H2201/1633', 'A61H2201/164', 'A61H2201/1642', 'A61H2201/1671', 'A61H2201/501', 'A61H2201/5012', 'A61H2201/5043', 'A61H2201/5046', 'A61H2201/5048', 'A61H2201/5061', 'A61H2201/5064', 'A61H2201/5069', 'A61H2201/5071', 'A61H2201/5092', 'A61H2201/5097', 'A61H2203/0431', 'A61H2205/10', 'A63B2022/0652', 'A63B2024/0065', 'A63B2024/0093', 'A63B2071/063', 'A63B2071/0652', 'A63B2071/0655', 'A63B2071/0663', 'A63B2071/068', 'A63B2220/13', 'A63B2220/16', 'A63B2220/30', 'A63B2220/51', 'A63B2220/52', 'A63B2225/20', 'A63B2225/50']"
US20220201042A1,Ai-driven defensive penetration test analysis and recommendation system,A system and method for automated defensive penetration test analysis that predicts the evolution of new cybersecurity attack strategies and makes recommendations for cybersecurity improvements to networked systems based on a cost/benefit analysis. The system and method use captured system data to classify networked system based upon their susceptibility to privilege escalation attacks measured against the networked system's response to a penetration test. The system and method use machine learning algorithms to run simulated attack and defense strategies against a model of the networked system created using a directed graph. Recommendations are generated based on an analysis of the simulation results and system classifications against a variety of cost/benefit indicators.,"['H04L63/1425', 'G06F16/2477', 'G06F16/951', 'G06F21/577', 'H04L63/20', 'G06F2221/033', 'G06F2221/034', 'H04L63/1441']"
US20250178595A1,Controlling autonomous vehicles using safe arrival times,"In various examples, sensor data representative of a field of view of at least one sensor of a vehicle in an environment is received from the at least one sensor. Based at least in part on the sensor data, parameters of an object located in the environment are determined. Trajectories of the object are modeled toward target positions based at least in part on the parameters of the object. From the trajectories, safe time intervals (and/or safe arrival times) over which the vehicle occupying the plurality of target positions would not result in a collision with the object are computed. Based at least in part on the safe time intervals (and/or safe arrival times) and a position of the vehicle in the environment a trajectory for the vehicle may be generated and/or analyzed.","['B60W30/08', 'B60W30/0956', 'B60W60/0015', 'B60W60/0027', 'G05D1/0214', 'G05D1/0231', 'G06V20/58', 'G06V20/584', 'B60R2300/30', 'B60W2050/0014', 'B60W2554/4041', 'B60W2554/804', 'G05D1/0242', 'G05D1/0255', 'G05D1/0257']"
US20230050882A1,"Method and System for Activity Prediction, Prefetching and Preloading of Computer Assets by A Client-Device","A solution arranged to build or train a machine learning model and to upload the machine learning model to a server arranged to deploy the machine learning model to a plurality of communicating devices. The solution can include a machine learning model builder arranged to build the machine learning model and a machine learning production pipeline. The machine learning production pipeline can be arranged to train the machine learning model, convert the machine learning model to a web browser compatible format, and upload the converted machine learning model to the server. The machine learning model can be arranged to receive as input a sequence of one or more prior activities on one communicating device in the plurality of communicating devices, analyze the sequence of one or more prior activities on said one communicating device, predict a next activity on said one communicating device based on the analysis of the sequence of one or more prior activities, preemptively search a computer network based on the predicted next activity to find a computer asset, and preload the found computer asset to a storage in said one communicating device.","['G06F16/9574', 'G06N20/00', 'G06N3/08']"
US20190377987A1,Discriminative Caption Generation,"A discriminative captioning system generates captions for digital images that can be used to tell two digital images apart. The discriminative captioning system includes a machine learning system that is trained by a discriminative captioning training system that includes a retrieval machine learning system. For training, a digital image is input to the caption generation machine learning system, which generates a caption for the digital image. The digital image and the generated caption, as well as a set of additional images, are input to the retrieval machine learning system. The retrieval machine learning system generates a discriminability loss that indicates how well the retrieval machine learning system is able to use the caption to discriminate between the digital image and each image in the set of additional digital images. This discriminability loss is used to train the caption generation machine learning system.","['G06K9/6268', 'G06F40/56', 'G06F15/18', 'G06F17/16', 'G06F17/27', 'G06F17/28', 'G06F17/30247', 'G06F18/241', 'G06F40/216', 'G06F40/40', 'G06F40/44', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/7788', 'G06V20/30', 'G06V20/35', 'G06F16/583']"
US11875491B2,Method and system for image processing,"An image processing system comprising: a computer readable medium and at least one processor configured to provide a machine learning architecture for image processing. In particular, keyframes are selected for modification by a visual artist, and the modifications are used for training the machine learning architecture. The modifications are then automatically propagated to remaining frames requiring modification through interpolation or extrapolation through processing remaining frames through the trained machine learning architecture. The generated modified frames or frame portions can then be inserted into an original video to generate a modified video where the modifications have been propagated. Example usages include automatic computational approaches for aging/de-aging and addition/removal of tattoos or other visual effects.","['G06T5/50', 'G06T11/00', 'G06T11/60', 'G06T7/11', 'G06V10/25', 'G06V10/774', 'G06V10/7788', 'G06V10/82', 'G06V20/46', 'G06V40/10', 'G06V40/103', 'G06V40/161', 'G06T2207/20084', 'G06T2207/30196']"
US10867702B2,Individual and cohort pharmacological phenotype prediction platform,"For patients who exhibit or may exhibit primary or comorbid disease, pharmacological phenotypes may be predicted through the collection of panomic data over a period of time. A machine learning engine may generate a statistical model based on training data from training patients to predict pharmacological phenotypes, including drug response and dosing, drug adverse events, disease and comorbid disease risk, drug-gene, drug-drug, and polypharmacy interactions. Then the model may be applied to data for new patients to predict their pharmacological phenotypes, and enable decision making in clinical and research contexts, including drug selection and dosage, changes in drug regimens, polypharmacy optimization, monitoring, etc., to benefit from additional predictive power, resulting in adverse event and substance abuse avoidance, improved drug response, better patient outcomes, lower treatment costs, public health benefits, and increases in the effectiveness of research in pharmacology and other biomedical fields.","['G16H50/20', 'G16B40/30', 'A61K31/37', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G16B20/00', 'G16B20/20', 'G16B30/00', 'G16B40/00', 'G16B40/20', 'G16H10/60', 'G16H50/30', 'G16H50/70']"
US20230058605A1,Method and system for using sensor data to detect joint misalignment of a user using a treatment device to perform a treatment plan,"A method that includes receiving treatment data associated with a user capable of using a treatment device to perform a treatment plan. The method also includes receiving user related data (URD) associated with the use and receiving alignment data associated with the user while the user engages in at least one activity. The method also includes identifying, based on at least the treatment data, the URD, and the alignment data, at least one alignment characteristic associated with the user and modifying at least one aspect of the treatment plan in response to receiving, from a healthcare professional, treatment plan input including at least one modification to the at least one aspect of the treatment plan.","['A61H1/0214', 'A61H1/024', 'A63B21/00178', 'A63B21/00181', 'A63B21/0058', 'A63B22/0605', 'A63B24/0062', 'A63B24/0075', 'A63B24/0087', 'G16H15/00', 'G16H20/30', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H80/00', 'A61H2201/1215', 'A61H2201/1261', 'A61H2201/1633', 'A61H2201/164', 'A61H2201/1642', 'A61H2201/1671', 'A61H2201/501', 'A61H2201/5012', 'A61H2201/5043', 'A61H2201/5046', 'A61H2201/5048', 'A61H2201/5061', 'A61H2201/5064', 'A61H2201/5069', 'A61H2201/5071', 'A61H2201/5092', 'A61H2201/5097', 'A61H2203/0431', 'A61H2205/10', 'A61H2230/06', 'A61H2230/202', 'A61H2230/207', 'A61H2230/30', 'A61H2230/42', 'A63B2022/0623', 'A63B2022/0652', 'A63B2024/0065', 'A63B2024/0093', 'A63B2071/063', 'A63B2071/0652', 'A63B2071/0655', 'A63B2071/0663', 'A63B2071/068', 'A63B2071/0683', 'A63B2220/13', 'A63B2220/16', 'A63B2220/30', 'A63B2220/51', 'A63B2220/52', 'A63B2225/20', 'A63B2225/50', 'A63B2230/06', 'A63B2230/202', 'A63B2230/207', 'A63B2230/30', 'A63B2230/42', 'A63B2230/50']"
US11222424B2,Systems and methods for analyzing electronic images for quality control,"Systems and methods are disclosed for receiving a digital image corresponding to a target specimen associated with a pathology category, determining a quality control (QC) machine learning model to predict a quality designation based on one or more artifacts, providing the digital image as an input to the QC machine learning model, receiving the quality designation for the digital image as an output from the machine learning model, and outputting the quality designation of the digital image. A quality assurance (QA) machine learning model may predict a disease designation based on one or more biomarkers. The digital image may be provided to the QA model which may output a disease designation. An external designation may be compared to the disease designation and a comparison result may be output.","['G06T7/0014', 'G16H30/40', 'G06N20/00', 'G16B40/20', 'G16H50/20', 'G16H70/60', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/30024', 'G06T2207/30168']"
US12131436B2,"Target image generation method and apparatus, server, and storage medium","The present disclosure provides a target image generation method. The method includes obtaining a first parsed image and a first pose image based on an original image, the first parsed image being an image labeled with parts of an object in the original image, the first pose image representing a pose of the object in the original image; inputting the first parsed image, the first pose image, and a second pose image representing a target pose into a first image generation model, and determining, a first transformation parameter and adjusting the first parsed image based on the first transformation parameter to obtain a target parsed image, a pose of the object in the target parsed image being the target pose; and inputting a first combined image and a second combined image into a second image generation model, and adjusting the first combined image to obtain a target image.","['G06T3/04', 'G06T7/344', 'G06T11/00', 'G06T3/14', 'G06T3/18', 'G06T3/40', 'G06T7/70', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US11494637B2,Layer-wise distillation for protecting pre-trained neural network models,"Neural network protection mechanisms are provided. The neural network protection engine receives a pre-trained neural network computer model and forward propagates a dataset through layers of the pre-trained neural network computer model to compute, for each layer of the pre-trained neural network computer model, inputs and outputs of the layer. For at least one layer of the pre-trained neural network computer model, a differentially private distillation operation is performed on the inputs and outputs of the at least one layer to generate modified operational parameters of the at least one layer. The modified operational parameters of the at least one layer obfuscate aspects of an original training dataset used to train the pre-trained neural network computer model, present in original operational parameters of the at least one layer. The neural network protection engine generates a privatized trained neural network model based on the modified operational parameters.","['G06N3/08', 'G06F21/6227', 'G06N3/0464', 'G06N3/09', 'G06N3/02']"
US10230745B2,Using high-interaction networks for targeted threat intelligence,"Provided are methods, network devices, and computer-program products for targeted threat intelligence using a high-interaction network. In some implementations, a network device in a network may receive suspect network traffic. The suspect network traffic may include network traffic identified as potentially causing harm to the network. The network device may determine that the suspect traffic is associated with an unknown threat. The network device may further analyze the suspect network traffic using a high-interaction network. In various implementations, the high-interaction network may be configured to emulate at least a part of the network. In various implementations, analyzing the suspect network traffic may include determining a behavior of the suspect network traffic in the high-interaction network. The network device may further generate indicators, where the indicators may describe the suspect network traffic. In various implementations, the indicators facilitate analysis of a network's susceptibility to the unknown threat.","['H04L63/1416', 'H04L41/145', 'H04L43/062', 'H04L51/12', 'H04L51/212', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/1491', 'G06F21/53', 'G06F21/564', 'H04L41/0816', 'H04L41/0886', 'H04L63/1408']"
TWI768323B,Image processing apparatus and image processing method thereof,"An image processing apparatus applies an image to a first learning network model to optimize the edges of the image, applies the image to a second learning network model to optimize the texture of the image, and applies a first weight to the first image and a second weight to the second image based on information on the edge areas and the texture areas of the image to acquire an output image.","['G06N3/045', 'G06N3/08', 'G06T7/13', 'G06T2207/20084']"
US12182694B2,"Training, testing, and verifying autonomous machines using simulated environments","In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment—in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack—to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle.","['G06N3/063', 'G05D1/00', 'G06F18/24133', 'G06F9/455', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/096', 'G06N3/098', 'G06N3/0985', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/56']"
US11595738B2,Generating videos with a character indicating a region of an image,"Methods, systems, and computer-readable media for generating videos with characters indicating regions of images are provided. For example, an image containing a first region may be received. At least one characteristic of a character may be obtained. A script containing a first segment of the script may be received. The first segment of the script may be related to the first region of the image. The at least one characteristic of a character and the script may be used to generate a video of the character presenting the script and at least part of the image, where the character visually indicates the first region of the image while presenting the first segment of the script.","['H04N21/8106', 'H04N21/8126', 'G06F40/58', 'G10L13/00', 'G10L13/033', 'G10L13/086', 'G10L13/10', 'H04N21/233', 'H04N21/23418', 'H04N21/26603', 'H04N21/2668', 'H04N21/4394', 'H04N21/44008', 'H04N21/458', 'H04N21/4755']"
CN118312922B,Multi-mode network content security intelligent auditing system and method thereof,"The invention provides a multimode network content security intelligent auditing system and a method thereof, belonging to the network content security field, wherein the system comprises: the data access and preprocessing module is used for receiving the multi-mode network content data from different sources and preprocessing the multi-mode network content data; the multi-mode analysis module is used for extracting the characteristics of different modes of content from the multi-mode network content data; the strategy management module is used for configuring and managing auditing strategies of different-mode contents; the auditing engine module is used for comprehensively utilizing the rule engine and the machine learning model and auditing the multi-mode network content data according to the characteristics of different-mode content and auditing strategies; the auditing result disposal module is used for outputting and storing auditing results and triggering corresponding manual auditing or automatic disposal flow according to the auditing results. The invention comprehensively utilizes a plurality of artificial intelligence technologies to comprehensively audit texts, pictures, videos and audios, thereby greatly improving the content security management and control capability.","['G06F18/253', 'G06F18/213', 'G06F18/214', 'G06F18/241', 'G06F18/256', 'G06F18/259', 'G06N3/042', 'G06N3/045', 'G06N3/0495', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G06N5/045']"
US20230145919A1,Method and apparatus for class incremental learning,"The present application generally relates to a method for training a machine learning, ML, model using class incremental learning, and to a computer-implemented method and apparatus for using the trained machine learning, ML, model. The method may learn how to update semantic representations of old concepts (classes) by modelling drift of semantic representations. The method may also learn how to update feature representations of old concepts (classes) by modelling drift of feature representations","['G06N3/0455', 'G06N20/00', 'G06N3/08', 'G06N3/084', 'G06N5/02']"
US20230059827A1,Multi-modal routing engine and processing architecture for orchestration of lending terms using currency usage patterns,"An integration system for a system of platforms includes an orchestration platform, a blockchain transactional platform, a digital transactional platform, a merchant system, a user trust platform, and one or more user devices connected to each other and a distributed ledger and/or a secondary mesh network via one or more networks. The blockchain transactional platform performs accesses and performs actions on the distributed ledger and/or the secondary mesh network. The digital transactional platform maintains transactional data indicative of an amount of first-domain value correlated to a user. The blockchain transactional platform maintains blockchain transactional data indicative of an amount of second-domain value correlated to the user. The orchestration platform manages data exchange, synthesis, fusion, analysis, and transformation between the components of the system, including the orchestration of lending terms using currency usage patterns.","['G06Q40/025', 'G06Q40/04', 'G06Q20/02', 'G06Q20/065', 'G06Q20/0658', 'G06Q20/10', 'G06Q20/108', 'G06Q20/3678', 'G06Q20/381', 'G06Q20/389', 'G06Q40/03', 'G06Q2220/00', 'G06Q2220/10']"
US10710119B2,Material sorting using a vision system,"A material sorting system sorts materials utilizing a vision system that implements a machine learning system in order to identify or classify each of the materials, which are then sorted into separate groups based on such an identification or classification. The material sorting system may include an x-ray fluorescence system to perform a classification of the materials in combination with the vision system, whereby the classification efforts of the vision system and x-ray fluorescence system are combined in order to classify and sort the materials.","['B07C5/3416', 'B07C5/3422', 'G01N23/223', 'G06N20/00', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'B07C2501/0054', 'B07C5/368', 'G01N2223/643']"
CN111259906B,Method for generating remote sensing image target segmentation countermeasures under condition containing multilevel channel attention,"A method for generating a remote sensing image confrontation target segmentation method under the condition of multi-level channel attention comprises the following steps: s100: the method comprises the following steps of improving a main network which is divided, wherein the main network comprises a generation network and a judgment network, and the improvement is specifically that: s101: the generating network is composed of a partition network containing multi-level channel attention; s102: the discrimination network is composed of a step convolution and a leakage type correction linear unit; s200: adopting an improved image segmentation network with multilevel channel attention to generate antagonism to segment the remote sensing image; s300: and outputting a segmentation result of the remote sensing image. The method uses the condition with multi-level channel attention to generate the antagonistic image segmentation network, improves multi-scale target information, simultaneously provides a more real generated image, solves the problem of small target missing, and improves the accuracy and smoothness of the segmentation result boundary.","['G06V10/267', 'G06N3/045', 'G06N3/084', 'G06V10/449']"
US10878314B2,System and method for training artificial intelligence systems using a SIMA based processor,A reinforcement learning processor specifically configured to train reinforcement learning agents in the AI systems by the way of implementing an application-specific instruction set is disclosed. The application-specific instruction set incorporates ‘Single Instruction Multiple Agents (SIMA)’ instructions. SIMA type instructions are specifically designed to be implemented simultaneously on a plurality of reinforcement learning agents which interact with corresponding reinforcement learning environments. The SIMA type instructions are specifically configured to receive either a reinforcement learning agent ID or a reinforcement learning environment ID as the operand. The reinforcement learning processor is designed for parallelism in reinforcement learning operations. The reinforcement learning processor executing of a plurality of threads associated with an operation or task in parallel.,"['G06N3/063', 'G06N3/006', 'G06F9/46', 'G06N3/045', 'G06N3/0454', 'G06N3/0475', 'G06N3/08', 'G06N3/092', 'G06N3/094', 'G06N7/005', 'G06N7/01']"
US11385292B2,Battery materials screening,"A method, apparatus, system for batter material screening is disclosed. First, microstructure generation parameters for a plurality of microstructures are received, where the microstructure generation parameters include microstructure characteristics. Microstructure statistics are generated using a first artificial intelligence (“AI”) model, where the received microstructure generation parameters are inputs for the first AI model. Microstructure properties are predicted using a second AI model for the microstructures based on the generated microstructure statistics, the received microstructure generation parameters, and battery cell characteristics. It is determined whether at least one of the microstructures is within a predefined energy profile range based on the predicted microstructure properties.","['G01R31/367', 'H01M10/04', 'G01R31/378', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N3/0985', 'G06N7/005', 'G06N7/01', 'H01M4/02', 'G06N20/00', 'H01M10/0525']"
US20210224319A1,Artificially generating audio data from textual information and rhythm information,"Methods and systems for artificially generating media streams are provided. Textual information, rhythm information and voice characteristics may be received. It may be determined that a first portion of the textual information corresponds to a first portion of the rhythm information and that a second portion of the textual information corresponds to a second portion of the rhythm information. Audio stream may be generated based on the textual information, the rhythm information and the voice characteristics. A first portion of the audio stream may include a vocal expression of the first portion of the textual information in a voice corresponding to the voice characteristics and according to the first portion of the rhythm information, and a second portion may include a vocal expression of the second portion of the textual information in the voice corresponding to the voice characteristics and according to the second portion of the rhythm information.","['G06F16/685', 'G10L13/033', 'G06F16/637', 'G06F16/686', 'G06F16/687', 'G06F40/253', 'G06F40/40', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G10H1/40', 'G10L15/005', 'G10L17/26', 'G10H2210/056', 'G10H2240/036', 'G10H2250/455', 'G10L15/26', 'G10L25/57', 'G10L25/63']"
CN109712203B,Image coloring method for generating antagonistic network based on self-attention,"The invention discloses an image coloring method based on a self-attention generation countermeasure network, which comprises the following steps: step 1, training a gray level picture coloring model; step 2, inputting the gray level images in the training data set into an antagonistic network to execute a feature extraction stage, a feature fusion stage, a deconvolution calculation stage and a self-attention mechanics learning stage to reconstruct corresponding color images; step 3, comparing the reconstructed color image after the attention learning with the corresponding original color image, and calculating
A penalty function; step 4, based on
The loss function is used as the optimal loss of the GAN; and 5, dividing the training process into a plurality of preset sub-training periods, and adopting a stepping increasing strategy to train the sub-training periods in sequence to obtain a generator network. The invention adopts the confrontation generation network to reconstruct the color image which accords with the subjective visual preference of human from a black-and-white or gray-scale image, so that the color image is more vivid.",[]
AU2019395322B2,Reconciliation between simulated data and speech recognition output using sequence-to-sequence mapping,"A synthetic training data item comprising a first sequence of symbols that represent a synthetic sentence output by a simulator is received. The synthetic training data item is processed using a machine learning model, which outputs a second sequence of symbols that represent the synthetic sentence. The synthetic training data item is modified by replacing the first sequence of symbols with the second sequence of symbols. A statistically significant mismatch exists between the first sequence of symbols and a third sequence of symbols that would be output by an acoustic model that processes a set of acoustic features that represent an utterance of the synthetic sentence, and no statistically significant mismatch exists between the second sequence of symbols and the third sequence of symbols. The modified synthetic training data item may be used to train a second machine learning model that processes data output by the acoustic model.","['G10L15/063', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/088', 'G06N3/09', 'G06N5/046', 'G06N7/01', 'G10L15/02', 'G10L15/16', 'G10L15/1822', 'G10L15/22', 'G10L2015/025', 'G10L2015/027', 'G10L2015/0635']"
US11159597B2,Systems and methods for artificial dubbing,"Methods, systems, and computer-readable media for artificially generating a revoiced media stream are provided. In one implementation, a system may receive a media stream including an individual with particular voice speaking in an origin language. The system may obtain a transcript of the media stream including utterances spoken in the origin language and translate the transcript to a target language. The translated transcript may include a set of words in the target language for each of at least some of the utterances spoken in the origin language. The system may analyze the media stream to determine a voice profile for the individual. Thereafter, the system may determine a synthesized voice for a virtual entity intended to dub the individual that is similar to the particular voice. Then, the system may generate a revoiced media stream in which the translated transcript in the target language is spoken by the virtual entity.","['H04L65/605', 'H04L65/765', 'G10L13/08', 'G10L13/00', 'G10L13/033', 'G10L17/00', 'H04L65/762']"
US12051332B2,Path perception diversity and redundancy in autonomous machine applications,"In various examples, a path perception ensemble is used to produce a more accurate and reliable understanding of a driving surface and/or a path there through. For example, an analysis of a plurality of path perception inputs provides testability and reliability for accurate and redundant lane mapping and/or path planning in real-time or near real-time. By incorporating a plurality of separate path perception computations, a means of metricizing path perception correctness, quality, and reliability is provided by analyzing whether and how much the individual path perception signals agree or disagree. By implementing this approach—where individual path perception inputs fail in almost independent ways—a system failure is less statistically likely. In addition, with diversity and redundancy in path perception, comfortable lane keeping on high curvature roads, under severe road conditions, and/or at complex intersections.","['G08G1/167', 'G05D1/0088', 'G05D1/0214', 'G05D1/0219', 'G05D1/0223', 'G05D1/617', 'G05D1/648', 'G05D1/65', 'G05D1/81', 'G06F18/23', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06V20/588', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/047', 'G06N5/01', 'G06N7/01']"
AU2024201361B2,Processing images using self-attention based neural networks,"#$%^&*AU2024201361B220250717.pdf##### Abstract Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing images using self-attention based neural networks. One of the methods includes obtaining one or more images comprising a plurality of pixels; determining, for each image of the one or more images, a plurality of image patches of the image, wherein each image patch comprises a different subset of the pixels of the image; processing, for each image of the one or more images, the corresponding plurality of image patches to generate an input sequence comprising a respective input element at each of a plurality of input positions, wherein a plurality of the input elements correspond to respective different image patches; and processing the input sequences using a neural network to generate a network output that characterizes the one or more images, wherein the neural network comprises one or more self-attention neural network layers. Abstract Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing images using self-attention based neural networks. One of the methods includes obtaining one or more images comprising a plurality of pixels; determining, for each image of the one or more images, a plurality of image patches of the image, wherein each image patch comprises a different subset of the pixels of the image; processing, for each image of the one or more images, the corresponding plurality of image patches to generate an input sequence comprising a respective input element at each of a plurality of input positions, wherein a plurality of the input elements correspond to respective different image patches; and processing the input sequences using a neural network to generate a network output that characterizes the one or more images, wherein the neural network comprises one or more self-attention neural network layers.","['G06F18/24', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06T7/97', 'G06V10/764', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US20190043506A1,Methods and systems for transcription,"A method of transcription a media file is provided. The method includes: receiving, from a first transcription engine, one or more transcribed portions of a media file; identifying a first transcribed portion from the one or more transcribed portions that needs to be reexamined based at least on metadata of the media file; selecting a second transcription engine to transcribe a first segment of the media file corresponding to the first transcribed portion; receiving, from the second transcription engine, a second transcribed portion of the first segment; determining confidences of accuracy of the first and second transcribed portions of the first segment based at least on metadata of the first and second transcribed portions, respectively; and selecting the first or second transcribed portion as transcript for the first segment of the media file based at least on confidences of accuracy of the first and second transcribed portions.","['G10L15/32', 'G06F17/274', 'G06F17/277', 'G06F17/2785', 'G06F40/20', 'G06F40/253', 'G06F40/284', 'G06F40/30', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'G10L15/02', 'G10L15/16', 'G10L15/1815', 'G10L15/30']"
US20240267344A1,Chatbot for interactive platforms,"A chatbot system for filtering conversation content. A chatbot system receives, from a client system, a prompt of a user during an interactive session. The chatbot system filters the prompt of the user based on a set of platform policies and generates a response based on the filtering of the prompt of the user, and communicates the response to the client system.","['H04L51/02', 'H04L51/04', 'H04L51/212', 'H04L51/214']"
CN112313715B,Automatically correcting metal-affected voxel representations of X-ray data using deep learning techniques,"A computer-implemented method for correcting a voxel representation of metal-influenced X-ray data representing artifacts in X-ray data caused by metal or metal-containing objects in a volume of tissue imaged by an X-ray imager is described, wherein the method comprises a first 3D depth neural network receiving at its input an initial voxel representation of the metal-influenced X-ray data and generating at its output a voxel map identifying voxels of an area of the initial voxel representation that belong to the metal-influenced voxel, and a second 3D depth neural network receiving at its input the initial voxel representation and the voxel map generated by the first 3D depth neural network and generating a corrected voxel representation comprising voxel estimates for voxels of portions of the voxel map identified as metal-influenced areas, the first 3D depth neural being trained based on training data and reference data, the training data and the reference data comprising a voxel representation of clinical X-ray data of a predetermined body part of the patient.","['G06T19/20', 'G06F18/2415', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T11/008', 'G06T15/08', 'G06T7/0012', 'G06V20/64', 'G06V20/647', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30036', 'G06T2207/30052', 'G06T2210/41', 'G06T2219/2012']"
US12100230B2,Using neural networks for 3D surface structure estimation based on real-world data for autonomous systems and applications,"In various examples, to support training a deep neural network (DNN) to predict a dense representation of a 3D surface structure of interest, a training dataset is generated from real-world data. For example, one or more vehicles may collect image data and LiDAR data while navigating through a real-world environment. To generate input training data, 3D surface structure estimation may be performed on captured image data to generate a sparse representation of a 3D surface structure of interest (e.g., a 3D road surface). To generate corresponding ground truth training data, captured LiDAR data may be smoothed, subject to outlier removal, subject to triangulation to filling missing values, accumulated from multiple LiDAR sensors, aligned with corresponding frames of image data, and/or annotated to identify 3D points on the 3D surface of interest, and the identified 3D points may be projected to generate a dense representation of the 3D surface structure.","['G06V20/64', 'G06V20/647', 'G05D1/0236', 'G01S17/86', 'G01S17/89', 'G01S17/931', 'G01S7/4808', 'G05D1/024', 'G05D1/0242', 'G05D1/0251', 'G05D1/0255', 'G06F18/214', 'G06V10/26', 'G06V10/774', 'G06V10/82', 'G06V20/56', 'G06V20/58', 'G06V20/70', 'B60G17/0165', 'B60K31/00', 'B60W2420/408', 'B60W60/001']"
US12373702B2,Training a digital twin in artificial intelligence-defined networking,"A system including one or more processors and one or more non-transitory computer-readable media storing computing instructions that, when executed on the one or more processors, perform certain acts. The acts can include generating a digital twin network simulation of a physical computer network controlled through a software-defined-network (SDN) control system. The acts also can include training a routing agent model on the digital twin network simulation using a reinforcement-learning model on traffic that flows through nodes of the digital twin network simulation. The routing agent model includes a machine-learning model. The acts additionally can include deploying the routing agent model, as trained, from the digital twin network simulation to the SDN control system of the physical computer network. Other embodiments are described.","['G06N3/006', 'G06N3/10', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/0895', 'G06N3/092', 'G06N3/094', 'G06N3/098', 'G06N3/0985']"
US11036965B2,Shape estimating apparatus,"A shape estimating apparatus includes an acquiring unit and an estimating unit. The acquiring unit is configured to acquire a two-dimensional image. The estimating unit has artificial intelligence, and is configured to provide the artificial intelligence with the two-dimensional image and cause the artificial intelligence to estimate a three-dimensional shape of a subject of the two-dimensional image. A learning result of machine learning performed using learning data containing supervisor data expressing a three-dimensional shape of a sample subject and a sample two-dimensional image obtained by capturing an image of the three-dimensional shape of the sample subject is set to the artificial intelligence.","['G06K9/00208', 'G01B11/24', 'G06V20/647', 'G06T7/50', 'G06T17/00', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084']"
CN112884758B,Defect insulator sample generation method and system based on style migration method,"The invention discloses a defective insulator sample generation method and a defective insulator sample generation system based on a style migration method.A plurality of acquired insulator image samples are divided into a plurality of image domains according to visual difference, each image domain is coded, and then the style migration training is carried out on the image domains through a style migration network to obtain a style migrator between any two image domains; finally, carrying out style migration on the defective insulator sample in the image domain by using the obtained style migration device to generate a new defective insulator sample; according to the method, the style migration device is used for carrying out style migration on the defective insulator sample in the image domain to generate a new more vivid style migration image sample, the generated defective insulator image sample is high in quality, semantic connection information of the insulator sample is reserved, the generated defective insulator sample can effectively provide accuracy and recall rate of a target detection model based on deep learning, and the method has certain practical value.","['G06T7/0004', 'G06F18/214', 'G06T3/04', 'G06T7/11', 'G06T2207/20081', 'G06T2207/20084']"
US20240249318A1,Determining user intent from chatbot interactions,"A system and method for determining user intent and providing targeted advertising using chatbot interactions is disclosed. The system receives user prompts during chat sessions with a chatbot and generates responses using a large language model. User intent is extracted by analyzing the chat conversations using natural language processing and machine learning techniques. The extracted user intent, comprising weighted keywords and concepts, is used to create a user intent profile. Targeted advertising content is generated based on the user intent profile and provided to the user during subsequent platform interactions. The large language model is continuously retrained using user engagement data to improve intent modeling accuracy. User privacy is maintained by limiting context extraction to chatbot conversations. The system enables personalized and relevant advertising by inferring user intent through conversational interactions.","['G06Q30/0269', 'G06Q30/0257', 'G06Q30/0277', 'H04L51/02', 'G06F40/20']"
US20240161477A1,Object detection with cross-domain mixing,"Implementations are described herein for improving unsupervised domain adaptation (UDA) by using improved adaptive teacher for object detection with cross-domain mix-up. In various implementations, cross-domain training of an object detection machine learning model may include: performing weak augmentation on images from a target domain DT to generate a first set of weakly augmented target domain images; perform strong augmentation on images from the source domain DS and images from the target domain DT to generate a second set of strongly augmented images; processing the second set of strongly augmented images to generate a third set of inter-domain mixes of the images from DS and DT; and jointly train the object detection machine learning model, as a student machine learning model, with a teacher machine learning model using the first and third sets.","['G06V10/7753', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V10/7792', 'G06V10/82']"
US10950047B2,Techniques for anonymizing neuromuscular signal data,"Methods and apparatus for anonymizing neuromuscular signals used to generate a musculoskeletal representation. The method comprises recording, using a plurality of neuromuscular sensors arranged on one or more wearable devices, a plurality of neuromuscular signals from a user, providing as input to a trained statistical model, the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals; and generating, the musculoskeletal representation based, at least in part, on an output of the trained statistical model, wherein the musculoskeletal representation is an anonymized musculoskeletal representation from which at least one personal characteristic of the user has been removed.","['G06T19/00', 'G06F3/014', 'G06F3/015', 'G06F3/016', 'G06F3/017', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06N7/01', 'G06F2203/011']"
US20220004923A1,Systems and methods for model explanation,"Systems and methods for model explanation are disclosed. In one embodiment, the disclosed process determines a score based on a scoring function and a plurality of values associated with a plurality of features of a denied credit applicant. (e.g., credit score of 550, no loans repaid, etc.). The process then determines a score of an approved credit applicant. (e.g., credit score of 750, 3 loans repaid, etc.). A next differential credit assignment associated with the current denied/approved pair is then calculated. If a convergence stopping criteria, (e.g., current accuracy>99% based on a statistical t-distribution) is not satisfied, the process repeats for a different approved credit applicant. When the convergence stopping criteria is satisfied, explanation information is generated. For example, the explanation information may include an adverse action reason code, fairness metric, disparate impact metric, human readable text, feature importance metric, credit value, and/or an importance rank.","['G06N20/20', 'G06F18/2113', 'G06K9/6212', 'G06K9/623', 'G06N20/00', 'G06Q40/025', 'G06Q40/03', 'G06N7/01']"
US12285236B2,Methods and systems for generating depth profiles with improved optical resolution,"Provided herein are methods, devices, and systems that may improve optical resolution when imaging through a thickness of samples. A method for generating a depth profile of a tissue of a subject may comprise using an optical probe to transmit an excitation light beam from a light source towards a surface of the tissue; using one or more focusing units in the optical probe to simultaneously adjust a depth and a position of a focal point of the excitation light beam along a scanning path; detecting at least a subset of the signals generated upon contacting the tissue with the excitation light beam; and using one or more computer processors programmed to process the at least the subset of the signals to generate the depth profile of the tissue.","['A61B5/0062', 'A61B5/0071', 'A61B5/0075', 'A61B5/0084', 'G06T7/0012', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/30024']"
US11704791B2,Multivariate and multi-resolution retinal image anomaly detection system,"Machine learning technologies are used to identify and separating abnormal and normal subjects and identifying possible disease types with images (e.g., optical coherence tomography (OCT) images of the eye), where the machine learning technologies are trained with only normative data. In one example, a feature or a physiological structure of an image is extracted, and the image is classified based on the extracted feature. In another example, a region of the image is masked and then reconstructed, and a similarity is determined between the reconstructed region and the original region of the image. A label (indicating an abnormality) and a score (indicating a severity) can be determined based on the classification and/or the similarity.","['G06T7/0012', 'G06V40/193', 'A61B3/102', 'G06N20/20', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06V10/809', 'A61B3/12', 'A61B5/7275', 'G06N3/045', 'G06T2207/30041', 'G06V2201/03']"
WO2020246631A1,Temperature prediction model generation device and simulation environment provision method,"Disclosed is a temperature prediction model generation device. The temperature prediction model generation device according to an embodiment of the present invention comprises a processor which sets a temperature prediction model that provides a simulation environment, and a hyper-parameter of the temperature prediction model, trains the temperature prediction model, in which the hyper-parameter is set, to output a predicted temperature, updates the hyper-parameter on the basis of a difference between the predicted temperature output from the trained temperature prediction model and an actual temperature, and repeats setting of the hyper-parameter, training of the temperature prediction model, and updating of the hyper-parameter based on the difference between the predicted temperature and the actual temperature a predetermined number of times or more, so as to set a final hyper-parameter of the temperature prediction model.","['F24F11/30', 'F24F11/63', 'G06F11/3688', 'G06F18/214', 'G06F18/24133', 'G06N20/00', 'G06N3/044', 'G06N3/08', 'G06N7/01', 'F24F2110/10', 'F24F2120/20', 'G06F16/24578', 'G06N3/006', 'G06N3/04', 'G06N5/01', 'G09B7/02']"
US11278413B1,"Devices, systems, techniques and methods for determining the fit, size and/or shape of orthopedic implants using computer systems, artificial neural networks and artificial intelligence","Devices, systems, techniques and methods for determining the fit of an implant and for determining one or more prognosticators, indicators or risk factors of postoperative performance are provided.","['A61F2/30942', 'A61B34/10', 'A61F2/32', 'A61F2/38', 'A61F2/40', 'A61F2/4202', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'A61B2034/105', 'A61B2034/108', 'A61B34/20', 'A61F2002/3093', 'A61F2002/30943', 'A61F2002/30948', 'A61F2002/30952']"
CN111386364B,Controller and method for tare processing,"A system, controller and method for decorticating one or more input units of hemp into one or more end products. The method comprises the following steps: analyzing one or more characteristics of the input unit; cutting the input unit into a predetermined size; opening a cutting input unit; performing decortication on the opened input unit to separate the hemp into a plurality of components including bast, fiber and in-core fiber (hurd); compacting the fibers into bales; crushing the fibers and bast in the core; mixing the comminuted core fibers and bast with a thermoplastic polymer to form a final product; receiving analyzer data from at least one of peeling, compacting, shredding, and combining; training a machine learning model according to analyzer data; the trained machine learning model is used to adjust one or more aspects to achieve a desired end product.","['D01B1/30', 'B27N1/00', 'B27N1/029', 'B27N3/02', 'B27N3/04', 'B27N3/18', 'B27N3/28', 'C08L97/02', 'D01B1/14', 'B27N1/02', 'B30B9/3007', 'G05B13/0265']"
US12333790B2,Diagnostic assistance apparatus and model generation apparatus,"A diagnostic assistance apparatus according to an aspect of the present disclosure determines whether a body part of a target examinee captured in a target medical image is normal, by using a trained first classification model generated by unsupervised learning using a plurality of first learning medical images of normal cases and a trained second classification model generated by supervised learning using a plurality of learning data sets including normal cases and abnormal cases.","['G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06T7/0012', 'G06T7/0014', 'G06V10/7747', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30061', 'G06V2201/03', 'G16H30/20']"
US11853891B2,System and method with federated learning model for medical research applications,"Method and system with federated learning model for health care applications are disclosed. The system for federated learning comprises multiple edge devices of end users, one or more federated learner update repository, and one or more cloud. Each edge device comprises a federated learner model, configured to send tensors to federated learner update repository. Cloud comprises a federated learner model, configured to send tensors to federated learner update repository. Federated learner update repository comprises a back-end configuration, configured to send model updates to edge devices and cloud.","['G06N3/084', 'G06F18/2413', 'G06F18/254', 'G06N20/20', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06N3/098', 'G06V10/764', 'G06V10/809', 'G06V10/945', 'G06V10/95', 'G06V10/96', 'G16H30/40', 'G16H50/20', 'G16H70/60', 'G06N3/006', 'G06N3/047', 'G06N3/063', 'G06N3/088', 'G06N5/02', 'G06N7/023']"
US20230391016A1,"Systems, methods, and media for artificial intelligence process control in additive manufacturing","Systems, methods, and media for additive manufacturing are provided. In some embodiments, an additive manufacturing system comprises: a hardware processor that is configured to: receive a captured image; apply a trained failure classifier to a low-resolution version of the captured image; determine that a non-recoverable failure is not present in the printed layer of the object; generate a cropped version of the low-resolution version of the captured image; apply a trained binary error classifier to the cropped version of the low-resolution version of the captured image; determine that an error is present in the printed layer of the object; apply a trained extrusion classifier to the captured image, wherein the trained extrusion classifier generates an extrusion quality score; and adjust a value of a parameter of the print head based on the extrusion quality score to print a subsequent layer of the printed object.","['B29C64/393', 'B22F10/30', 'B22F10/85', 'B22F12/90', 'B29C64/209', 'B33Y10/00', 'B33Y30/00', 'B33Y50/02', 'G06F18/2411', 'G06F18/295', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/088', 'G06V10/764', 'G06V10/82', 'G06V10/993', 'B22F10/12', 'B22F10/18', 'B22F10/25', 'B22F10/28', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N7/01', 'Y02P10/25']"
US12100121B2,"System, method and computer-accessible medium for detecting structural disorder(s) using magnetic resonance imaging","An exemplary system, method, and computer-accessible medium for detection of structural disorder(s) of patient(s) can be provided which can include, for example, receiving magnetic resonance imaging (MRI) information of the portion(s), generating gadolinium (“Gd”) enhanced map(s) based on the MRI information using a machine learning procedure(s), and detecting the structural disorder(s) of the patient(s) based on a GD contrast of the Gd enhanced map(s). The Gd enhanced map(s) can be a full dosage Gd enhanced map. The machine learning procedure can be a convolutional neural network. The MRI information can include (i) a low-dosage Gd MRI scan(s), or (ii) a Gd-free MRI scan(s). The Gd contrast can be generated in the Gd enhanced map(s) using a T2-weighted MRI image of the portion(s). Structural disorder(s) can include Stroke, tumor, trauma, infection, Multiple sclerosis and/or other inflammatory disease.","['G06T5/00', 'G16H30/40', 'G06T5/50', 'G06T5/60', 'G06T5/92', 'G16H30/20', 'G16H50/20', 'G16H50/50', 'G16H50/70', 'G06T2207/10088', 'G06T2207/10096', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016']"
US11256994B1,System and method for prediction of protein-ligand bioactivity and pose propriety,"A system and method that predicts whether a given protein-ligand pair is active or inactive and outputs a pose score classifying the propriety of the pose. A 3D bioactivity platform comprising a 3D bioactivity module and data platform scrapes empirical lab-based data that a docking simulator uses to generate a dataset from which a 3D-CNN model is trained. The model then may receive new protein-ligand pairs and determine a classification for the bioactivity and pose propriety of that protein-ligand pair. Furthermore, gradients relating to the binding affinity in the 3D model of the molecule may be used to generate profiles from which new protein targets may be determined.","['G16B15/30', 'G06N5/022', 'G06F16/951', 'G06F18/22', 'G06K9/6215', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06V10/82', 'G06V20/69', 'G16B15/00', 'G16B40/20', 'G16B5/00', 'G06N3/048', 'G06N3/084', 'G06N5/02', 'G06V30/10']"
CN113988126B,Rolling bearing fault diagnosis method based on few-label data feature migration,"A rolling bearing fault diagnosis method based on few-label data feature migration is used for solving the problem that model classification accuracy is not high due to large difference of source domain data and target domain data distribution and the fact that a large amount of marked data is lacking in the source domain data in training data of an existing rolling bearing fault diagnosis model. The technical key points of the invention include: introducing prototype contrast learning to carry out domain adaptation, and establishing a fault diagnosis model based on prototype domain adaptation; the method is characterized in that a CBAM attention mechanism module is added in a Res2Net structure, an activation function of a feature extraction network is further replaced, the feature extraction capability of a deep network on the rolling bearing data is improved, and finally diagnosis of different states of the rolling bearing under the condition of less marked data variable load is realized. The method has better classification performance under the variable load condition of the rolling bearing, can well solve the problem of unbalanced data distribution of the collected vibration data in the normal state and the fault state, and has good generalization performance.","['G06F2218/08', 'G06F18/214', 'G06N3/045', 'G06N3/084', 'G06F2218/12']"
US20200293019A1,Assembly error correction for assembly lines,"Aspects of the disclosed technology provide a computational model that utilizes machine learning for detecting errors during a manual assembly process and determining a sequence of steps to complete the manual assembly process in order to mitigate the detected errors. In some implementations, the disclosed technology evaluates a target object at a step of an assembly process where an error is detected to a nominal object to obtain a comparison. Based on this comparison, a sequence of steps for completion of the assembly process of the target object is obtained. The assembly instructions for creating the target object are adjusted based on this sequence of steps.","['G05B19/41805', 'G05B19/406', 'G05B19/19', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G05B2219/31027', 'G05B2219/32177', 'G05B2219/40556', 'G06N20/20', 'Y02P90/02']"
US11321831B2,Automated evaluation of human embryos,"Systems and methods are provided for provided for automatic evaluation of a human embryo. An image of the embryo is obtained and provided to a neural network to generate a plurality of values representing the morphology of the embryo. The plurality of values representing the morphology of the embryo are evaluated at an expert system to provide an output class representing one of a current quality of the embryo, a future quality of the embryo, a likelihood that implantation of the embryo will be successful, and a likelihood that implantation of the embryo will result in a live birth.","['G06T7/0012', 'G06T2207/10024', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30044']"
US12039247B2,Test pattern generation systems and methods,"Systems and methods are provided for generating test patterns. In various embodiments, systems and methods are provided in which machine learning is utilized to generate the test patterns in a manner so that the test patterns conform with design rule check (DRC) specified for a particular semiconductor manufacturing process or for particular types of devices. A test pattern generation system includes test pattern generation circuitry which receives a noise image. The test pattern generation generates a pattern image based on the noise image, and further generates a test pattern based on the pattern image. The test pattern is representative of geometric shapes of an electronic device design layout that is free of design rule check violations.","['G06F30/398', 'G01R31/318364', 'G06F30/394']"
US11321556B2,Person re-identification apparatus and method,"The present disclosure can provide a person re-identification apparatus and method that includes an identity feature extraction part configured to receive a multiple number of images each including a person requiring re-identification, extract features related to an identity of a person included in each image according to a pattern estimation method learned beforehand, and obtain an identity-related feature vector for each image; and a re-identification determination part configured to analyze a degree of similarity between an identity-related feature vector obtained for a base image including a search target from among the plurality of images and an identity-related feature vector obtained for another image to determine whether or not a person corresponding to the search target is included in the other image.","['G06V40/10', 'G06K9/00288', 'G06F18/2148', 'G06F18/217', 'G06F18/22', 'G06F18/2413', 'G06K9/4671', 'G06K9/6257', 'G06K9/6262', 'G06N20/00', 'G06T5/50', 'G06V10/40', 'G06V10/469', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V40/172']"
US11770510B2,Video information compression using sketch-video,A method involves receiving a color video signal having a first frame rate. The color video signal is pre-processed to produce a pre-processed color video stream. The pre-processed color video stream is transformed into a monochromatic sketch stream. The first frame rate of the sketch stream is adapted to a second frame rate in accordance with dynamics of objects in a scene and are encoded to produce an encoded sketch stream. Frame-hints are produced using the pre-processed color video stream and are encoded to produce encoded frame-hints. The encoded sketch stream is multiplexed with the encoded frame-hints and service data to produce multiplexer output data which is transmitted via a communication channel or stored in a data storage system.,"['G06F16/70', 'H04L65/403', 'G06F17/00', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T1/00', 'G06T1/60', 'G06T11/203', 'G06T11/60', 'G06T3/4007', 'G06T3/4023', 'G06T3/4046', 'G06T9/002', 'H03M7/30', 'H04L65/70', 'H04L65/75', 'H04L65/756', 'H04L65/80', 'H04N19/117', 'H04N19/132', 'H04N19/136', 'H04N19/142', 'H04N19/17', 'H04N19/537', 'H04N19/85', 'H04N21/238', 'H04N9/64', 'G06N3/045', 'G06T9/001']"
US20240256582A1,Search with Generative Artificial Intelligence,"Methods and apparatuses for utilizing generative artificial intelligence (AI) techniques to automatically generate and display summaries of search results are described. A search and knowledge management system may generate a set of search results for a given search query and provide the set of search results (e.g., a set of verified documents that are the most relevant verified documents for the search query) as part of an input prompt to guide a generative AI model in generating a summary response of the set of search results. The generative AI model may comprise a Generative Pre-trained Transformer (GPT) model. The summary response may comprise a natural language text response and the set of search results may comprise electronic documents and messages and/or portions thereof.","['G06F16/338', 'G06F16/3329', 'G06F16/345', 'G06N20/00', 'G06N3/045']"
US20240362286A1,Semantic search and summarization for electronic documents,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,"['G06F16/901', 'G06F16/93', 'G06F16/9538', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06N5/022']"
US11397272B2,Data augmentation for seismic interpretation systems and methods,A method and apparatus for machine learning for use with automated seismic interpretation include: obtaining input data; extracting patches from a pre-extraction dataset based on the input data; transforming data of a pre-transformation dataset based on the input data and geologic domain knowledge and/or geophysical domain knowledge; and generating augmented data from the extracted patches and the transformed data. A method and apparatus for machine learning for use with automated seismic interpretation include: a data input module configured to obtain input data; a patch extraction module configured to extract patches from a pre-extraction dataset that is based on the input data; a data transformation module configured to transform data from a pre-transformation dataset that is based on the input data and geologic domain knowledge and/or geophysical domain knowledge; and a data augmentation module configured to augment data from the extracted patches and the transformed data.,"['G01V1/28', 'G01V1/32', 'G01V1/303', 'G01V1/306', 'G01V1/345', 'G01V1/364', 'G01V20/00', 'G06N20/00', 'G01V2210/64']"
US10957041B2,Determining biomarkers from histopathology slide images,A generalizable and interpretable deep learning model for predicting biomarker status and biomarker metrics from histopathology slide images is provided.,"['G06T1/20', 'G06F18/21', 'G06F18/2431', 'G06K9/6217', 'G06K9/628', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06T11/00', 'G06T7/0012', 'G06T7/11', 'G06V10/44', 'G06V10/764', 'G06V10/82', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G06V2201/03']"
US12037027B2,Systems and methods for generating synthetic motion predictions,"Systems and methods for generating synthetic testing data for autonomous vehicles are provided. A computing system can obtain map data descriptive of an environment and object data descriptive of a plurality of objects within the environment. The computing system can generate context data including deep or latent features extracted from the map and object data by one or more machine-learned models. The computing system can process the context data with a machine-learned model to generate synthetic motion prediction for the plurality of objects. The synthetic motion predictions for the objects can include one or more synthesized states for the objects at future times. The computing system can provide, as an output, synthetic testing data that includes the plurality of synthetic motion predictions for the objects. The synthetic testing data can be used to test an autonomous vehicle control system in a simulation.","['B60W60/00276', 'G06F18/2148', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06V20/584', 'G06N3/044']"
US10991067B2,Virtual presentations without transformation-induced distortion of shape-sensitive areas,"A technique for transforming an image of an article for virtual presentation without transformation-induced distortion of a shape-invariant area of the article. In an embodiment, a first region of the article image may be identified using automated image processing. The first region may represent a shape-sensitive area of the article whose aspect ratio needs to be controlled when the article image is transformed for use in the virtual presentation. The article image may be transformed to provide a transformed article image for use in the virtual presentation. The transformation of the article image may include a differential transformation that transforms a shape or size of the first region of the article image differently than a shape or size of a second region of the article image representing an area of the article outside the shape-sensitive area. The differential transformation prevents distortion of the first region of the article image.","['G06T3/10', 'G06T3/0056', 'G06T11/60', 'G06Q30/0621', 'G06Q30/0623', 'G06Q30/0631', 'G06T15/20', 'G06T19/006', 'G06T5/006', 'G06T5/50', 'G06T5/80', 'G06T7/30', 'G06T2210/16']"
US20210209775A1,"Image Processing Method and Apparatus, and Computer Readable Storage Medium","Embodiments of the present disclosure disclose an image processing method and apparatus, an electronic device, and a computer readable storage medium. The method includes: obtaining an image to be registered and a reference image used for registration; inputting the image to be registered and the reference image into a preset neural network model, where the preset neural network model is obtained by training based on mutual information loss of a preset image to be registered and a preset reference image; and registering the image to be registered with the reference image based on the preset neural network model to obtain a registration result. The precision and real-time performance of image registration can be improved.","['G06T7/337', 'G06N3/084', 'G06N3/04', 'G06N3/08', 'G06N3/088', 'G06T5/50', 'G06T7/0014', 'G06T7/33', 'G06T7/38', 'G16H50/20', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
AU2020248416B2,Determining biomarkers from histopathology slide images,A generalizable and interpretable deep learning model for predicting biomarker status and biomarker metrics from histopathology slide images is provided.,"['G16B45/00', 'G06F18/24143', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06T3/4046', 'G06T7/0012', 'G06T7/12', 'G06T7/187', 'G06V10/454', 'G06V10/82', 'G06V20/698', 'G16B15/30', 'G16B40/00', 'G16B5/00', 'G16H30/40', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/10064', 'G06T2207/20016', 'G06T2207/20021', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024', 'G06T2207/30096', 'G06T2207/30101', 'G06T2219/004']"
CN111696168B,High-speed MRI reconstruction method based on residual self-attention image enhancement,"The invention relates to an MRI (magnetic resonance imaging) accelerated acquisition method, in particular to a high-speed acquisition MRI reconstruction method based on residual self-attention image enhancement. The method adopts a generated countermeasure network to construct the network structure of the invention, and embeds a characteristic enhancement module based on residual self-attention to the bottom of the U-NET contraction path; inputting the high-power undersampled image into a generator, extracting a high-level feature map through a U-NET contraction path, inputting the high-level feature map into a feature enhancement module to obtain a feature enhancement map, decoding the feature enhancement map through a U-NET expansion path, merging the feature enhancement map with a feature map corresponding to the contraction path, fusing features of a corresponding level contraction layer during expansion, supplementing missing boundary information, and accurately predicting edge information to obtain a reconstructed image. The method can capture more abstract and richer texture detail characteristics of the image, fuse local information and non-local information to enhance the overall information amount, automatically select effective characteristics by a network in the whole process, can realize the self-adaptive extraction and reconstruction of the texture details of a key area, and can well reconstruct the high-speed acquisition MR image.","['G06T11/003', 'G06F18/253', 'G06N3/045', 'G06N3/084', 'G06V10/44', 'G06T2207/10088']"
US11206278B2,Risk-informed autonomous adaptive cyber controllers,"Technology related to risk-informed autonomous adaptive cyber controllers is disclosed. In one example of the disclosed technology, a method includes generating probabilities of a cyber-attack occurring along an attack surface of a network. The probabilities can be generated using sensor and operational data of a network as inputs to an attack graph. The risk scores can be determined using a plurality of fault trees and the generated probabilities from the attack graph. The respective risk scores can correspond to respective nodes of an event tree. The event tree and the determined risk scores can be used to determine risk estimates for a plurality of configurations of the network. The risk estimates for the plurality of configurations of the network can be used to reconfigure the network to reduce a risk from the cyber-attack.","['H04L63/1433', 'H04L41/142', 'H04L41/16', 'H04L63/0236', 'H04L63/1416', 'H04L63/20']"
US11663307B2,RtCaptcha: a real-time captcha based liveness detection system,"Example systems and methods for defending against powerful, automated attacks on facial authentication systems are disclosed. A first verification is performed based at least in part on determining a response time for a response to a CAPTCHA or other challenge. In response to determining that the response time is within a threshold, a second verification is performed based at least in part on extracting a face feature or a voice feature from a plurality of samples associated with the response.","['G06F21/32', 'G06V40/172', 'G06V40/40', 'G06V40/45', 'G06F2221/2103', 'G06F2221/2133', 'G06F2221/2141', 'G06V40/193', 'G06V40/20', 'G10L17/22']"
CN111508079B,"Virtual clothes try-on method and device, terminal equipment and storage medium","The embodiment of the application provides a virtual clothes try-on method, a virtual clothes try-on device, terminal equipment and a storage medium. The method comprises the following steps: acquiring a face image and a body image of a target object; inputting a face image and a body image into a pre-trained deep learning model to obtain a virtual human body model which is output by the pre-trained deep learning model and corresponds to the face image and the body image; acquiring target apparel information based on the face image and the body image; and matching the target clothes information with the virtual human body model to generate a fitting effect image. According to the virtual clothing fitting method and device, the virtual human body model which is consistent with the figure and the face of the target object is generated according to the face image and the body image of the target object, so that the reality of the virtual clothing fitting is enhanced.","['G06T19/00', 'G06F18/22', 'G06N3/08', 'G06T2210/16', 'Y02P90/30']"
US10007866B2,Neural network image classifier,"A training engine is described which has a memory arranged to access a neural network image classifier, the neural network image classifier having been trained using a plurality of training images from an input space, the training images being labeled for a plurality of classes. The training engine has an adversarial example generator which computes a plurality of adversarial images by, for each adversarial image, searching a region in the input space around one of the training images, the region being one in which the neural network is linear, to find an image which is incorrectly classified into the plurality of classes by the neural network. The training engine has a processor which further trains the neural network image classifier using at least the adversarial images.","['G06K9/6257', 'G06V10/82', 'G06F18/2148', 'G06F18/2413', 'G06F18/24147', 'G06K9/6276', 'G06V10/764', 'G06V10/7747']"
US20210390355A1,Image classification method based on reliable weighted optimal transport (rwot),"An image classification method based on reliable weighted optimal transport (RWOT) includes: preprocessing data in a source domain, so that a deep neural network fits a sample image in the source domain to obtain a sample label; performing image labeling to add a pseudo label to a data sample in a target domain; performing node pairing to pair associated images in the source domain and the target domain; and performing automatic analysis by using a feature extractor and an adaptive discriminator, to perform image classification. The present disclosure proposes a subspace reliability method for dynamically measuring a difference between the source domain and the target domain based on spatial prototypical information and an intra-domain structure. This method can be used as a preprocessing step of an existing domain adaptation technology, and greatly improves efficiency.","['G06F18/241', 'G06K9/6269', 'G06V30/18057', 'G06F18/10', 'G06F18/214', 'G06F18/2411', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06K9/6298', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06V10/40', 'G06V10/82']"
US11557085B2,Neural network processing for multi-object 3D modeling,"Embodiments are directed to neural network processing for multi-object three-dimensional (3D) modeling. An embodiment of a computer-readable storage medium includes executable computer program instructions for obtaining data from multiple cameras, the data including multiple images, and generating a 3D model for 3D imaging based at least in part on the data from the cameras, wherein generating the 3D model includes one or more of performing processing with a first neural network to determine temporal direction based at least in part on motion of one or more objects identified in an image of the multiple images or performing processing with a second neural network to determine semantic content information for an image of the multiple images.","['G06T17/00', 'G06F18/211', 'G06F18/2413', 'G06F3/012', 'G06F3/013', 'G06K9/6228', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T7/20', 'G06T7/248', 'G06V10/28', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/64', 'G06V30/274', 'G06N3/044', 'G06N3/047', 'G06T2207/10016', 'G06T2207/10021', 'G06T2207/20081', 'G06T2207/20084']"
US11483324B2,Detection of malicious activity using behavior data,Techniques are provided for detection of malicious activity using behavior data. A behavior model is trained with behavior data generated in association with a plurality of requests. Data is received that describes a particular request from a particular client device to a server system hosting a website. The data includes particular behavior data generated at the particular client device in association with the particular request. The particular behavior data is analyzed using the behavior model to generate a behavior model result. An automation determination for the particular request is generated based on the behavior model result. The particular request is handled based on the automation determination for the particular request.,"['H04L63/1425', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/09', 'H04L63/1416', 'G06N3/088']"
US11263525B2,Progressive modification of neural networks,"A neural network learns a particular task by being shown many examples. In one scenario, a neural network may be trained to label an image, such as cat, dog, bicycle, chair, etc. In other scenario, a neural network may be trained to remove noise from videos or identify specific objects within images, such as human faces, bicycles, etc. Rather than training a complex neural network having a predetermined topology of features and interconnections between the features to learn the task, the topology of the neural network is modified as the neural network is trained for the task, eventually evolving to match the predetermined topology of the complex neural network. In the beginning the neural network learns large-scale details for the task (bicycles have two wheels) and later, as the neural network becomes more complex, learns smaller details (the wheels have spokes).","['G06N3/08', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/047', 'G06N3/048']"
US10972503B1,Deception mechanisms in containerized environments,"Provided are systems, methods, and computer-program products for deception mechanisms in a containerized environment. In various implementations, a deception platform can detect the configuration of a containerized environment, including namespaces, services, and configuration of the environment. The deception platform can determine appropriate decoy containerized services for the environment, and can deploy the decoy alongside production containerized service. The deception platform can further determine decoy breadcrumbs for luring attackers to the decoy containerized service. The decoy breadcrumbs can be injected into the environment at locations where an attacker will look for information for further infiltrating the environment. The deception platform can then monitor the decoy containerized service for unexpected accesses.","['H04L63/1491', 'G06F21/55', 'H04L63/14', 'H04L63/1441', 'H04L63/20', 'G06F2221/2127', 'H04W12/00', 'H04W12/12', 'H04W12/1201', 'H04W12/121']"
US10762892B2,Rapid deployment of dialogue system,"A method for a dialogue system includes establishing a dialogue session between an application executing on a server and a remote machine. The dialogue session includes one or more utterances received from a user at the remote machine. A natural language processing machine identifies a request associated with a computer-readable representation of an utterance. A dialogue expansion machine generates a plurality of alternative actions for responding to the request. A previously-trained machine learning confidence model assesses a confidence score for each alternative. If a highest confidence score for a top alternative does not satisfy a threshold, the plurality of alternatives including the top alternative are transmitted to a remote machine (which may be the same remote machine or a different remote machine) for review by a human reviewer. After the dialogue system and/or the human reviewer select an alternative, computer-readable instructions defining the selected alternative are executed.","['G10L15/063', 'G06F16/90332', 'G06F40/169', 'G06F40/35', 'G06N20/00', 'G06N3/006', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G10L15/22', 'G10L15/30', 'G06N20/10', 'G06N3/044', 'G06N3/0445', 'G06N3/047', 'G06N3/0472', 'G06N7/005', 'G06N7/01', 'G10L2015/0638', 'G10L2015/225']"
US20220391585A1,Multi-modal language interpretation using unified input model,"Systems and processes for multi-modal input interpretation are provided. For example, an input associated with a touch is received from a user. A first reconstruction based on the input is determined. A first simulated input is obtained based on a modification of the input. A second reconstruction is determined based on the first reconstruction and the first simulated input. Based on at least the first reconstruction and the second reconstruction, a probability representation is obtained. An output is determined, by a language model, based on the probability representation. The output is then provided to the user.","['G06F40/274', 'G06F17/18', 'G06F3/0237', 'G06F3/04842', 'G06F3/04883', 'G06F3/04886', 'G06F40/279', 'G06F40/30', 'H04L51/063', 'H04L51/04']"
US10958478B2,Resilient polymorphic network architectures,"Methods and systems for mutating a network topology on which various containers run. The system includes a host controller to assign each of a plurality of hosts an unchanging public virtual IP address that maps to changing real IP address, a threat detection module to detect a mutation stimuli, and a management module configured to receive a mutation policy and execute the mutation policy to enact a container mutation upon the threat detection module detecting the mutation stimuli.","['H04L12/4641', 'G06F21/14', 'G06F9/45558', 'H04L61/2514', 'H04L61/2521', 'G06F2009/4557', 'G06F2009/45587', 'G06F2009/45595', 'H04L61/1511', 'H04L61/4511']"
US11392800B2,Computer vision systems and methods for blind localization of image forgery,Computer vision systems and methods for localizing image forgery are provided. The system generates a constrained convolution via a plurality of learned rich filters. The system trains a convolutional neural network with the constrained convolution and a plurality of images of a dataset to learn a low level representation of each image among the plurality of images. The low level representation is indicative of a statistical signature of at least one source camera model of each image. The system can determine a splicing manipulation localization by the trained convolutional neural network.,"['G06K9/6265', 'G06N3/08', 'G06F18/2148', 'G06F18/2193', 'G06K9/6257', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N7/01', 'G06V10/30', 'G06V10/50', 'G06V10/764', 'G06V10/7796', 'G06V10/82', 'G06V20/40', 'G06V20/90']"
US20240330927A1,Smart contract generation and validation,"A method for generating and validating a smart contract is disclosed. The method may include receiving text input describing a desired operation of a smart contract and processing the text input with a language model to output a smart contract logic description and synthetic data for validating the smart contract. The method may further include processing the smart contract logic description with a generative artificial intelligence model to generate smart contract code, validating the smart contract code using the synthetic data to simulate transactions with the smart contract, and deploying the smart contract code on a blockchain upon successful validation of the smart contract code.","['G06F8/35', 'G06F11/3457', 'G06F21/64', 'G06F8/31', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06Q20/065', 'G06Q20/382', 'G06Q20/389', 'G06Q20/401', 'G06Q2220/00']"
US12225046B1,Method and system for stopping multi-vector phishing attacks using cloud powered endpoint agents,"An endpoint protection system is provided. The system comprises: an endpoint agent deployed to an endpoint device, wherein the endpoint agent is built-into one or more existing applications running on the endpoint device and is configured to capture network session activity between the endpoint device and one or more internet servers to detect a phishing attack using a set of machine learning algorithm trained classifiers, and block the phishing attack; and an endpoint management system in remote communication with the endpoint agent, wherein the endpoint management system is configured to train and develop the set of classifiers, and receive information about the detected phishing attack and an incident report from the endpoint agent, the endpoint agent provides a graphical user interface running on the endpoint device allowing an end user to configure one or more protections provided by the endpoint agent.","['H04L63/1483', 'H04L41/16', 'H04L41/22', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1441', 'H04L63/20']"
US11544886B2,Generating digital avatar,"In one embodiment, a method includes, by one or more computing systems: receiving one or more non-video inputs, where the one or more non-video inputs include at least one of a text input, an audio input, or an expression input, accessing a K-NN graph including several sets of nodes, where each set of nodes corresponds to a particular semantic context out of several semantic contexts, determining one or more actions to be performed by a digital avatar based on the one or more identified semantic contexts, generating, in real-time in response to receiving the one or more non-video inputs and based on the determined one or more actions, a video output of the digital avatar including one or more human characteristics corresponding to the one or more identified semantic contexts, and sending, to a client device, instructions to present the video output of the digital avatar.","['G06T13/00', 'G06T13/40', 'G06F40/216', 'G06F40/30', 'G06N20/00', 'G06N3/006', 'G06N3/042', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N5/022', 'G06N5/04', 'G06N5/041', 'G06V40/174', 'G06N3/044']"
US11813113B2,Automated extraction of echocardiograph measurements from medical images,Mechanisms are provided to implement an automated echocardiograph measurement extraction system. The automated echocardiograph measurement extraction system receives medical imaging data comprising one or more medical images and inputs the one or more medical images into a deep learning network. The deep learning network automatically processes the one or more medical images to generate an extracted echocardiograph measurement vector output comprising one or more values for echocardiograph measurements extracted from the one or more medical images. The deep learning network outputs the extracted echocardiograph measurement vector output to a medical image viewer.,"['A61B8/0883', 'A61B5/316', 'A61B5/318', 'A61B5/72', 'A61B8/5223', 'G06F18/21', 'G06F18/253', 'G06T7/0012', 'G06T7/0014', 'G06T7/62', 'G06V10/454', 'G06V10/806', 'G16H30/40', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06V2201/031', 'G16H10/60']"
US11615324B2,System and method for de novo drug discovery,"A system and method for de novo drug discovery using machine learning algorithms. In a preferred embodiment, de novo drug discovery is performed via data enrichment and interpolation/perturbation of molecule models within the latent space, wherein molecules with certain characteristics can be generated and tested in relation to one or more targeted receptors. Filtering methods may be used to determine active novel molecules by filtering out non-active molecules and contain activity predictors to better navigate the molecule-receptor domain. The system may comprise neural networks trained to reconstruct known ligand-receptors pairs and from the reconstruction model interpolate and perturb the model such that novel and unique molecules are discovered. A second preferred embodiment trains a variational autoencoder coupled with a bioactivity model to predict molecules exhibiting a range of desired properties.","['G06N3/088', 'G06N5/022', 'G06F16/951', 'G06F18/22', 'G06K9/6215', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/091', 'G06N3/092', 'G06N3/094', 'G06V10/82', 'G06V20/698', 'G16C60/00', 'G06N20/10', 'G16C20/30', 'G16C20/70']"
TWI830791B,"Method and system for optimizing workflow in an assembly line, and non-transitory computer-readable media","Aspects of the disclosed technology provide an Artificial Intelligence Process Control (AIPC) for automatically detecting errors in a manufacturing workflow of an assembly line process, and performing error mitigation through the update of instructions or guidance given to assembly operators at various stations. In some implementations, the disclosed technology utilizes one or more machine-learning models to perform error detection and/or propagate instructions/assembly modifications necessary to rectify detected errors or to improve the product of manufacture.","['G05B19/406', 'G05B19/41805', 'G06N20/20', 'G05B19/19', 'G05B19/4183', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06Q10/0633', 'G06Q10/0639', 'G05B2219/31027', 'G05B2219/31046', 'G05B2219/40556', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N7/01', 'G06Q50/04', 'Y02P90/02']"
US11507084B2,Collaborative 3-D environment map for computer-assisted or autonomous driving vehicles,"Disclosures herein may be directed to a method, technique, or apparatus directed to a computer-assisted or autonomous driving (CA/AD) vehicle that includes a system controller, disposed in a first CA/AD vehicle, to manage a collaborative three-dimensional (3-D) map of an environment around the first CA/AD vehicle, wherein the system controller is to receive, from another CA/AD vehicle proximate to the first CA/AD vehicle, an indication of at least a portion of another 3-D map of another environment around both the first CA/AD vehicle and the another CA/AD vehicle and incorporate the at least the portion of the 3-D map proximate to the first CA/AD vehicle and the another CA/AD vehicle into the 3-D map of the environment of the first CA/AD vehicle managed by the system controller.","['G05D1/0044', 'G06T17/05', 'B60W50/00', 'G01C21/32', 'G01C21/3841', 'G05D1/0274', 'G05D1/0287', 'G06F18/214', 'G06F18/2411', 'G06F18/2415', 'G06K9/6256', 'G06K9/6277', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N7/005', 'G06N7/01', 'G06T17/005', 'G06V10/764', 'G06V10/82', 'G06V20/58', 'G06V20/582', 'G08G1/096716', 'G08G1/096725', 'G08G1/096741', 'G08G1/09675', 'G08G1/096791', 'G08G1/161', 'G08G1/166', 'H04W4/46', 'B60W2050/0075', 'B60W2556/65', 'G06N20/10', 'G06N3/044', 'G06N3/048', 'G06T2200/08']"
WO2021236961A1,System and method for processing medical claims,"A computer-implemented system for processing medical claims is disclosed. The system includes a medical device configured to be manipulated by a user while the user performs a treatment plan; a patient interface associated with the medical device, the patient interface comprising an output configured to present telemedicine information associated with a telemedicine session; and a processor. During the telemedicine session, the processor is configured to receive information from a medical device. Using the device-generated information, the processor is further configured to determine device-based medical coding information. The processor is further configured to transmit the device-based medical coding information to a claim adjudication server.","['G16H40/63', 'G16H10/60', 'G16H20/00', 'G16H40/20', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/20', 'G16H80/00', 'H04L67/04', 'H04L67/12', 'H04L67/14', 'H04L69/22', 'H04L69/40', 'H04L41/16']"
US11361071B2,Apparatus and method for conducting endpoint-network-monitoring,"Provided is an intrusion detection technique configured to: obtain kernel-filter criteria indicative of which network traffic is to be deemed potentially malicious, determine that a network packet is resident in a networking stack, access at least part of the network packet, apply the kernel-filter criteria to the at least part of the network packet and, based on applying the kernel-filter criteria, determining that the network packet is potentially malicious, associate the network packet with an identifier of an application executing in userspace of the operating system and to which or from which the network packet is sent, and report the network packet in association with the identifier of the application to an intrusion-detection agent executing in userspace of the operating system of the host computing device, the intrusion-detection agent being different from the application to which or from which the network packet is sent.","['G06F21/552', 'G06F21/554', 'G06F21/567', 'H04L43/028', 'H04L43/062', 'H04L63/0263', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1441', 'H04L63/20', 'H04L43/0876', 'H04L47/10', 'H04L69/22']"
CN114332568B,"Training method, system, device and storage medium for domain-adapted image classification network","The invention discloses a training method, a system, equipment and a storage medium of a domain adaptive image classification network, which introduce contrast learning to cluster features with the same semantics and solve the problem that a domain adaptive image classification task is insufficient in a target domain; according to the invention, the feature contrast learning is improved into the probability contrast learning, and the distance between the clustered homosemantic features and class weights is reduced by performing contrast learning in a probability space, so that the classification accuracy is improved; moreover, only one loss of contrast learning (i.e., total probabilistic contrast loss) is added, no complex additional modules are added, and the number of parameters is not increased compared to previous methods. In general, the overall performance of the model is improved under the condition that other additional modules are not added, and a more accurate image classification result can be obtained.",[]
WO2021151276A1,"Oct image-based image recognition method and apparatus, and device and storage medium","An OCT image-based image recognition method, relating to the field of artificial intelligence, the method comprising: acquiring OCT images not containing an abnormal region to serve as sample images to construct a generative adversarial network, training a generator and a discriminator of the generative adversarial network respectively to obtain a target discriminator and a target generator, alternately iterating the target generator and the target discriminator to train the generative adversarial network until training is complete, acquiring an image to be recognized uploaded by a client and input same into the completely trained generative adversarial network to obtain a simulated image, using a first algorithm to calculate an abnormality score between the simulated image and the image to be recognized, and when the abnormality score is greater than a second pre-set threshold, determining the image to be recognized to be an abnormal image containing an abnormal region. The present method is able to improve the accuracy of recognizing whether the information reflected in an OCT image is abnormal.","['G06F18/22', 'G06N3/045', 'G06N3/08', 'G06V10/462']"
CN114603564B,"Robotic arm navigation obstacle avoidance method, system, computer equipment and storage medium","The invention belongs to the technical field of artificial intelligence, and discloses a mechanical arm navigation obstacle avoidance method, a system, computer equipment and a storage medium, wherein the method comprises the following steps: acquiring the current state tensor of the mechanical arm; inputting the current state tensor of the mechanical arm into a preset mechanical arm navigation obstacle avoidance depth reinforcement learning model to obtain a decision action track of the mechanical arm; the mechanical arm navigation obstacle avoidance depth reinforcement learning model is constructed based on an initial mechanical arm navigation obstacle avoidance depth reinforcement learning model obtained by pre-training under a simulated learning environment with a navigation planning algorithm as priori guidance; and controlling the mechanical arm to run according to the decision motion track of the mechanical arm. Based on the navigation planning algorithm, the model has certain basic implicit knowledge, can adapt to different types of obstacle environments, can be quickly trained and smoothly moved to the actual environment for use, avoids the construction of a complex rewarding system, greatly improves the training speed and reduces the resource consumption.","['B25J9/1676', 'B25J9/1666']"
US20240370479A1,Semantic search and summarization for electronic documents,Techniques for an artificial intelligence (AI) platform to search a document collection are described. Embodiments may use AI and machine learning techniques within a framework of an electronic document management system to perform semantic searching of an electronic document or a collection of electronic documents for certain types of information. The AI platform may summarize the information in a natural language representation of a human language. Other embodiments are described and claimed.,"['G06V30/416', 'G06F16/316', 'G06F16/3347', 'G06F40/30']"
TWI853877B,"System, computational method, and computer program product for defect classification and source analysis for semiconductor equipment","Defects on a substrate comprising electronic components can be classified with a computational defect analysis system that may be implemented in multiple stages. For example, a first stage classification engine may process metrology data to produce an initial classification of defects. A second stage classification engine may use the initial classification, along with manufacturing information and/or prior defect knowledge to output probabilities that the defects are caused by one or more potential sources.","['G01N21/9501', 'G01N21/8851', 'G06N3/045', 'G06N3/08', 'G06T7/0004', 'H01L21/67288', 'G01N2021/8854', 'G01N2021/8864', 'G01N2021/8887', 'G06T2207/30148', 'H01L22/12', 'H01L22/20']"
US20190278600A1,Tiled compressed sparse matrix format,"Approaches in accordance with various embodiments provide for the processing of sparse matrices for mathematical and programmatic operations. In particular, various embodiments utilize a tiling approach that divides a sparse matrix into submatrices, many of which will include only zero-value entities. These empty tiles can be ignored, and only the tiles with non-zero entries processed, which reduces resource and time requirements for the processing. An indexing approach can be used for each entity that is a combination of the tile identifier and an offset value, which enables the values to be multiplied correctly against, for example, values of a dense matrix. The tiles can be processed in parallel and the results accumulated to generate a matrix product. The matrix product can then be passed to the next step in a process or operation, such as to a next layer in a deep neural network.","['G06F9/30036', 'G06F17/16', 'G06F9/3877', 'G06F9/3885', 'G06N3/0418', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N3/084', 'G06N3/088']"
US11410372B2,Artificial intelligence based virtual object aging,"Embodiments of the systems and methods described herein provide a virtual object aging system. The virtual object aging system can utilize artificial intelligence to modify virtual objects within a video game to age and/or deteriorate for a certain time period. The virtual object aging system can be used to determine erosion, melting ice, and/or other environmental effects on virtual objects within the game. The virtual object aging system can apply aging, rust, weathering, and/or other effects that cause persistent change to object meshes and textures.","['G06T19/20', 'G06T15/04', 'A63F13/57', 'A63F13/655', 'A63F13/67', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T17/20', 'A63F2300/695', 'G06T2200/04', 'G06T2210/64', 'G06T2219/2012', 'G06T2219/2021']"
AU2025208552A1,Scalable neutral atom based quantum computing,"#$%^&*AU2025208552A120250814.pdf##### ABSTRACT The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation. ABSTRACT The present disclosure provides methods and systems for performing non-classical computations. The methods and systems generally use a plurality of spatially distinct optical trapping sites to trap a plurality of atoms, one or more electromagnetic delivery units to apply electromagnetic energy to one or more atoms of the plurality to induce the atoms to adopt one or more superposition states of a first atomic state and a second atomic state, one or more entanglement units to quantum mechanically entangle at least a subset of the one or more atoms in the one or more superposition states with at least another atom of the plurality, and one or more readout optical units to perform measurements of the superposition states to obtain the non-classical computation.20 25 20 85 52 28 J ul 2 02 5 A B S T R A C T 2 0 2 5 2 0 8 5 5 2 2 8 J u l 2 0 2 5 T h e p r e s e n t d i s c l o s u r e p r o v i d e s m e t h o d s a n d s y s t e m s f o r p e r f o r m i n g n o n - c l a s s i c a l c o m p u t a t i o n s . T h e m e t h o d s a n d s y s t e m s g e n e r a l l y u s e a p l u r a l i t y o f s p a t i a l l y d i s t i n c t o p t i c a l t r a p p i n g s i t e s t o t r a p a p l u r a l i t y o f a t o m s , o n e o r m o r e e l e c t r o m a g n e t i c d e l i v e r y u n i t s t o a p p l y e l e c t r o m a g n e t i c e n e r g y t o o n e o r m o r e a t o m s o f t h e p l u r a l i t y t o i n d u c e t h e a t o m s t o a d o p t o n e o r m o r e s u p e r p o s i t i o n s t a t e s o f a f i r s t a t o m i c s t a t e a n d a s e c o n d a t o m i c s t a t e , o n e o r m o r e e n t a n g l e m e n t u n i t s t o q u a n t u m m e c h a n i c a l l y e n t a n g l e a t l e a s t a s u b s e t o f t h e o n e o r m o r e a t o m s i n t h e o n e o r m o r e s u p e r p o s i t i o n s t a t e s w i t h a t l e a s t a n o t h e r a t o m o f t h e p l u r a l i t y , a n d o n e o r m o r e r e a d o u t o p t i c a l u n i t s t o p e r f o r m m e a s u r e m e n t s o f t h e s u p e r p o s i t i o n s t a t e s t o o b t a i n t h e n o n - c l a s s i c a l c o m p u t a t i o n .","['G06N10/40', 'G06N10/20', 'G06N10/60', 'G06N20/20', 'B82Y10/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US12254545B2,Generating modified digital images incorporating scene layout utilizing a swapping autoencoder,"The present disclosure relates to systems, methods, and non-transitory computer readable media for accurately and flexibly generating modified digital images utilizing a novel swapping autoencoder that incorporates scene layout. In particular, the disclosed systems can receive a scene layout map that indicates or defines locations for displaying specific digital content within a digital image. In addition, the disclosed systems can utilize the scene layout map to guide combining portions of digital image latent code to generate a modified digital image with a particular textural appearance and a particular geometric structure defined by the scene layout map. Additionally, the disclosed systems can utilize a scene layout map that defines a portion of a digital image to modify by, for instance, adding new digital content to the digital image, and can generate a modified digital image depicting the new digital content.","['G06T11/60', 'G06T11/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T5/50', 'G06T5/60', 'G06T5/77', 'G06T7/10', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US11741593B2,"Product defect detection method, device and system","A product defect detection method, device and system are disclosed. The method comprises: acquiring a sample image of a product, extracting candidate image blocks probably including a product defect from the sample image, and extracting preset shape features corresponding to the candidate image blocks and texture features corresponding to the candidate image blocks; training a first-level classifier using the preset shape features to obtain a first-level classifier that can further screen out target image blocks probably including a product defect from the candidate image blocks; training a second-level classifier using the texture features to obtain a second-level classifier that can correctly identify a product defect; and when performing product defect detection, inputting preset shape features of candidate image blocks extracted from a product image into the first-level classifier, and then inputting texture features of obtained target image blocks into the second-level classifier to detect a defect in the product.","['G06T7/0004', 'G01N21/8851', 'G06F18/214', 'G06F18/2411', 'G06V10/70', 'G01N2021/8854', 'G01N2021/8883', 'G01N2021/8887', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/30108', 'G06T2207/30164']"
US12266442B2,Decision support system for medical therapy planning,"For decision support in a medical therapy, machine learning provides a machine-learned generator for generating a prediction of outcome for therapy personalized to a patient. Deep learning may result in features more predictive of outcome than handcrafted features. More comprehensive learning may be provided by using multi-task learning where one of the tasks (e.g., segmentation, non-image data, and/or feature extraction) is unsupervised and/or draws on a greater number of training samples than available for outcome prediction alone.","['G16H30/20', 'G16H50/70', 'G16H20/40', 'A61B5/7267', 'A61N5/103', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T7/0012', 'G16H50/20', 'G16H50/30', 'A61B6/032', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084']"
US12257064B2,Personalized skin care from skin scanning,"Various techniques pertain to a user interface that includes an instructional display portion comprising one or more textual or graphical instructions pertaining to preparing for a body scan for body care of a client and a scan initiation display portion that includes a scan initiation widget which, when interacted by the client, invokes execution of a scan process and an analysis process for a respective body area of the client. The user interface further includes a scan result display portion including interactable textual or graphical information pertaining to a result of the body scan for the body care and an adjustment display portion having a plurality of adjustment widgets that transform at least a color index or value into a transformed color index or value in a L*A*B* color space or a Lch color space.","['A61B5/441', 'A45D44/005', 'A61B5/0064', 'A61B5/442', 'G06Q30/0621', 'G06Q30/0631', 'G06Q30/0633', 'G06T7/0012', 'G06T7/90', 'G06V10/26', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V40/10', 'A45D2044/007', 'G06Q30/01', 'G06Q30/0641', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/30088', 'G06T2207/30201']"
EP3407292A1,Neural network point cloud generation system,"A system includes one or more processors (204) and a memory (206) that stores a generative adversarial network (GAN) (210). The one or more processors (204) are configured to receive a low resolution point cloud (306) comprising a set of three-dimensional (3D) data points (410) that represents an object (110, 112). A generator (302) of the GAN (210) is configured to generate a first set of generated data points based at least in part on one or more characteristics of the data points (410) in the low resolution point cloud (306), and to interpolate the generated data points into the low resolution point cloud (306) to produce a super-resolved point cloud (310) that represents the object (110, 112) and has a greater resolution than the low resolution point cloud (306). The one or more processors are further configured to analyze the super-resolved point cloud (310) for detecting one or more of an identity of the object (110, 112) or damage to the object (110, 112).","['G06T7/0004', 'G06T3/4053', 'G06F18/22', 'G06F18/2413', 'G06T3/4007', 'G06T3/4076', 'G06T7/0002', 'G06T2200/04', 'G06T2207/10028', 'G06T2207/20084', 'G06T2207/30108', 'G06T2207/30164']"
US20210286068A1,Simulated lidar devices and systems,"Systems and methods for generating simulated LiDAR data using RADAR and image data are provided. An algorithm is trained using deep-learning techniques such as loss functions to generate simulated LiDAR data using RADAR and image data. Once trained, the algorithm can be implemented in a system, such as a vehicle, equipped with RADAR and image sensors in order to generate simulated LiDAR data describing the system's environment. The simulated LiDAR data may be used by a vehicle control system to determine, generate, and implement modified driving operations.","['G01S13/89', 'G01S13/867', 'G01S13/87', 'G01S13/931', 'G01S7/02', 'G09B9/006', 'G01S15/87', 'G01S15/931', 'G01S2013/93271', 'G01S2013/93272', 'G01S2013/93273', 'G01S2013/93274', 'G01S2013/93275', 'G05D1/0257', 'G09B9/54']"
KR102271070B1,Method and apparatus for determining mixed coal combination,"The present invention relates to a method and an apparatus for determining a mixed coal combination which use data collected from a coal-fired power plant to establish a combustion result prediction model of a boiler of the coal-fired power plant, and determine an optimal mixed coal combination satisfying an objective function and a constraint based on the combustion result prediction model. According to an embodiment of the present invention, the method for determining a mixed coal combination comprises: a step of loading a boiler combustion result prediction model for a coal-fired power plant; a step of selecting a boiler combination becoming a target of mixed coal combination determination among a plurality of boilers provided in the coal-fired power plant; a step of optimizing the boiler combustion result prediction model for the selected boiler combination; a step of setting an objective function as an operating issue to be optimized through a mixed coal combination among operating issues for the coal-fired power plant; a step of setting a constraint to be reflected when determining the mixed coal combination; and a step of determining a coal type and a mixed coal ratio satisfying the objective function and the constraint as an optimal mixed coal combination based on the optimized boiler combustion result prediction model. According to the present invention, the boilers of the coal-fired power plant can be operated in an optimal state by determining the coal type and the mixed coal ratio satisfying the objective function and the constraint as the optimal mixed coal combination based on the boiler combustion result prediction model.","['G05B13/026', 'F23K3/00', 'F23N1/002', 'G06N3/02', 'G06Q50/06', 'F23K2201/50', 'F23N2223/08', 'F23N2223/48', 'F23N2239/02', 'Y02E40/70', 'Y04S10/50']"
US10021127B2,Threat indicator analytics system,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for analyzing threat intelligence information. One of the methods includes receiving by a threat information server, threat intelligence information from one or more intelligence feeds and generating one or more identified security threats, identifying a compromise by a management process orchestration server and retrieving information from the threat information server and identifying one or more actions to be performed, determining by an indicator analytics processor, a composite credibility based on the actions, and determining one or more components for profiling and determining indicators of compromise for each component, and communicating the indicators of compromise to the management process orchestration server.","['H04L63/1433', 'H04L63/1408', 'H04L63/1441']"
US11449931B2,Dynamic business governance based on events,"Provided is process, including: obtaining interaction-event records; determining, based on at least some of the interaction-event records, sets of event-risk scores, wherein: at least some respective event-risk scores are indicative of an effective of a respective risk ascribed by a first entity to a respective aspect of a second entity; and at least some respective event-risk scores are based on both: respective contributions of respective corresponding events to a subsequent event, and a risk ascribed to a subsequent event; and storing the sets of event-risk scores in memory.","['G06Q40/025', 'G06N3/08', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/0475', 'G06N3/09', 'G06N3/091', 'G06N3/094', 'G06N7/005', 'G06N7/01', 'G06Q40/03']"
US11657513B2,Method and system for generating a tri-map for image matting,"A system and a method of performing an image matting on an image are provided. The method includes detecting, by an image processing system, one or more objects in the image; determining, by the image processing system, a confidence map associated with the image using one or more image segmentation techniques for each of the one or more objects; and generating, by the image processing system, a tri-map for each of the one or more objects in the image from the confidence map based on at least one of a size of each of the one or more objects in the image and a distance between a first pixel in the image and a second pixel in at least one of the one or more objects in the image, wherein the tri-map is used to perform the image matting.","['G06T7/11', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/155', 'G06T7/194', 'G06V10/7747', 'G06V40/161', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084']"
US20240220319A1,Automated visual information context and meaning comprehension system,"A system for analyzing images and video that is capable of recognizing, classifying, and processing the context and meaning contained therein in a manner similar to human intuitive understanding of such context and meaning. Images and video are gathered through a crowdsourcing portal, cameras, and other remote sensing devices. Real world data relevant to the images and video is gathered using a deep web collection and extraction engine. The resulting inputs are analyzed for context and meaning using machine learning algorithms, whose outputs, or resulting models, are reviewed and adjusted by humans through a crowdsourcing or collaborative labor portal.","['G06F9/5011', 'G06F16/9024', 'G06F18/29', 'G06N5/022', 'G06N5/025', 'G06Q10/067', 'G06Q30/0201', 'G06Q30/0205', 'G06Q40/04']"
AU2021290842B2,Terrain-based automated detection of well pads and their surroundings,"Aspects of the invention include includes detecting, using a first machine learning model, a first well pad at a first location based at least in part on a first set of data comprising spectral data describing a gas emission from the first location. Detecting an environmental event within a threshold distance of the well pad. Determining a probability of damage to the first well pad from the environmental event.","['G06V20/194', 'G06V20/176', 'E21B41/00', 'G06F18/2413', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/13', 'G06V10/764', 'E21B2200/20', 'G06T2207/10036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30188', 'G06V20/188']"
US11182598B2,Smart area monitoring with artificial intelligence,"The present disclosure provides various approaches for smart area monitoring suitable for parking garages or other areas. These approaches may include ROI-based occupancy detection to determine whether particular parking spots are occupied by leveraging image data from image sensors, such as cameras. These approaches may also include multi-sensor object tracking using multiple sensors that are distributed across an area that leverage both image data and spatial information regarding the area, to provide precise object tracking across the sensors. Further approaches relate to various architectures and configurations for smart area monitoring systems, as well as visualization and processing techniques. For example, as opposed to presenting video of an area captured by cameras, 3D renderings may be generated and played from metadata extracted from sensors around the area.","['G06V20/54', 'G06K9/00335', 'G06F18/231', 'G06F18/24143', 'G06K9/00771', 'G06K9/00785', 'G06K9/00825', 'G06K9/209', 'G06K9/3241', 'G06K9/6219', 'G06K9/6274', 'G06T7/246', 'G06T7/292', 'G06T7/70', 'G06T7/73', 'G06V10/147', 'G06V10/25', 'G06V10/255', 'G06V10/7625', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G06V20/584', 'G06V40/20', 'H04N23/90', 'H04N5/247', 'G06K2209/15', 'G06K2209/23', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/30201', 'G06T2207/30232', 'G06T2207/30241', 'G06T2207/30264', 'G06V20/625', 'G06V2201/08']"
US10891673B1,Semantic modeling for search,"A semantic analysis can be performed to determine an intent of a received query. The intent can relate to a primary object of the query, which can be identified through the semantic analysis. Other attributes can be determined from the query that help to focus the object of the intent. A query vector is generated, based on the intent and primary object, and used to search a multi-dimensional semantic space including semantic representations of possible matches. The attributes are used to adjust the query vector in the semantic space. Objects having vectors ending proximate the query vector are identified as potential search results, with the distance from the query vector being used as a ranking mechanism. If refinement is needed, a dialog is used to obtain additional information from the user. Once results are obtained with sufficient confidence, results can be returned as search results for the query.","['G06Q30/0643', 'G06F16/2455', 'G06F16/248', 'G06F16/3344', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06Q30/0625', 'G06N3/045', 'G06N3/047']"
US10362057B1,Enterprise DNS analysis,"Provided are methods, network devices, and computer-program products for a domain name system (DNS) threat detection engine for analyzing DNS traffic for potential threats. In various implementations, the DNS threat detection engine can include threat profiles that include characteristics of network threats associated with DNS. When a DNS message includes a characteristic associated with a particular threat profile, a remediation rule associated with the threat profile can be used to modify the DNS message, including modifying the destination for the DNS message. When the DNS message is received at the new destination, the DNS message can be analyzed to determine whether the DNS message is associated with a threat to the network.","['H04L63/1408', 'H04L61/4511', 'H04L63/0236', 'H04L63/1491']"
US11593588B2,"Artificial intelligence apparatus for generating training data, artificial intelligence server, and method for the same","An artificial intelligence apparatus for generating training data includes a memory configured to store a target artificial intelligence model, and a processor configured to receive sensor data, determine whether the received sensor data is irrelevant to a learning of the target artificial intelligence model, determine whether the received sensor data is useful for the learning if the received sensor data is determined to be relevant to the learning, extract a label from the received sensor data by using a label extractor if the received sensor data is determined to be useful for the learning, determine a confidence level of the extracted label, and generate training data including the received sensor data and the extracted label if the determined confidence level exceeds a first reference value.","['G06N3/008', 'G06K9/6256', 'G06F16/35', 'G06F18/214', 'G06F18/22', 'G06K9/6215', 'G06N20/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N5/04', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82']"
US11694392B2,Environment synthesis for lighting an object,"Various implementations disclosed herein include devices, systems, and methods that render a reflective surface of a computer-generated reality (“CGR”) object based on synthesis in a CGR environment. In order to render a reflective surface of the CGR object, one exemplary implementation involves synthesizing an environment map of a CGR environment representing a portion of a physical scene based on observed characteristics of the physical scene. In an implementation, generation of a complete environment map includes identifying pixels of the environment map with no corresponding texture and generating synthesized texture based on textural information associated with one or more camera images of the physical scene. In an implementation, a CGR object is rendered in the CGR environment, wherein an appearance of a reflective surface of the CGR object is determined based on the complete environment map of the CGR environment.","['G06T15/04', 'G06T15/50', 'G06T19/006', 'G06T19/20', 'G06T7/40', 'G06T7/73', 'G06T2219/2021']"
US11797823B2,Model training with retrospective loss,"Generating a machine learning model that is trained using retrospective loss is described. A retrospective loss system receives an untrained machine learning model and a task for training the model. The retrospective loss system initially trains the model over warm-up iterations using task-specific loss that is determined based on a difference between predictions output by the model during training on input data and a ground truth dataset for the input data. Following the warm-up training iterations, the retrospective loss system continues to train the model using retrospective loss, which is model-agnostic and constrains the model such that a subsequently output prediction is more similar to the ground truth dataset than the previously output prediction. After determining that the model's outputs are within a threshold similarity to the ground truth dataset, the model is output with its current parameters as a trained model.","['G06N3/04', 'G06F18/214', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G06N3/09', 'G06V10/764', 'G06V10/82']"
US11631014B2,"Computer-based systems configured for detecting, classifying, and visualizing events in large-scale, multivariate and multidimensional datasets and methods of use thereof","Systems and methods of the present disclosure include at least one processor that receives a data set of a data stream from a data source, where the data set includes a time-varying data points. The processor determines event observations associated with data points of the time-varying data points based on a detection model to identify types of the event observations, including: i) anomalies, ii) change-points, iii) patterns, or iv) outliers. The processor generates anomaly records in an event data store based on the event observations and automatically generates event records for at least one of the anomaly records based on variables of at least one dimension of the time-varying data points, where the event record links one or more event observations. The processor automatically applies changes in the event record to each event observation of the one or more event observations based on the linking by the event record.","['G06F16/285', 'G06N5/04', 'G06F16/283', 'G06N20/00', 'G06N3/084', 'G06N3/105']"
US12322177B2,Automatic content recognition and information in live streaming suitable for video games,"In various examples, one or more Machine Learning Models (MLMs) are used to identify content items in a video stream and present information associated with the content items to viewers of the video stream. Video streamed to a user(s) may be applied to an MLM(s) trained to detect an object(s) therein. The MLM may directly detect particular content items or detect object types, where a detection may be narrowed to a particular content item using a twin neural network, and/or an algorithm. Metadata of an identified content item may be used to display a graphical element selectable to acquire the content item in the game or otherwise. In some examples, object detection coordinates from an object detector used to identify the content item may be used to determine properties of an interactive element overlaid on the video and presented on or in association with a frame of the video.","['G06V20/41', 'H04L65/764', 'H04N21/2187', 'A63F13/35', 'A63F13/537', 'A63F13/5372', 'A63F13/5375', 'A63F13/792', 'A63F13/86', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/82', 'G06V20/46', 'H04L65/1083', 'H04L65/61', 'H04L65/611', 'H04N21/4781']"
US11491350B2,Decision support system for individualizing radiotherapy dose,"For decision support in a medical therapy, machine learning provides a machine-learned generator for generating a prediction of outcome for therapy personalized to a patient. The outcome prediction may be used to determine dose. To assist in decision support, a regression analysis of the cohort used for machine training relates the outcome from the machine-learned generator to the dose and an actual control time (e.g., time-to-event). The dose that minimizes side effects while minimizing risk of failure to a time for any given patient is determined from the outcome for that patient and a calibration from the regression analysis.","['A61N5/103', 'A61N5/1075', 'A61B6/032', 'A61B6/5211', 'A61B6/5217', 'G06N20/00', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/065', 'G06N3/088', 'G06N3/0895', 'G06N3/09', 'G06N3/096', 'G06N5/04', 'G06N7/01', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/084']"
CN109948117B,Satellite anomaly detection method for network self-encoder,"The invention discloses an anomaly detection method for satellite telemetering data through a countermeasure network self-encoder, which comprises the following steps: breaking the limitation of the traditional empirical model, and adopting a pure data driving model; on the basis of a variational self-encoder, a countermeasure network idea is introduced, a bidirectional LSTM (long-short-time memory network) is used as a discriminator, and errors of reconstructed data and original data are utilized to judge whether satellite telemetering data are abnormal or not; aiming at the redundancy problem of the satellite sensor, the conventional method is broken, and the Mahalanobis distance is used for measuring the reconstruction error. And (3) providing a dynamic threshold value determination method based on a periodic time window in combination with the periodicity of the satellite orbital operation. The invention has the advantages that: the data is driven by pure data, expert experience is not needed, and the method can be suitable for various occasions; combining the advantages of a variational self-encoder and the advantages of a generation countermeasure network, the proposed network has the characteristics of fast training and easier convergence; the mahalanobis distance is adopted, so that the influence of redundant data among satellite telemetering data is eliminated; according to the periodicity of the satellite, a dynamic threshold method based on a periodic time window is provided, and the misjudgment rate is reduced.","['G06F17/18', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/084', 'G06N3/088', 'G06N3/094', 'H04B7/18582']"
US20230047092A1,User-level Privacy Preservation for Federated Machine Learning,"User-level privacy preservation is implemented within federated machine learning. An aggregation server may distribute a machine learning model to multiple users each including respective private datasets. Individual users may train the model using the local, private dataset to generate one or more parameter updates. Prior to sending the generated parameter updates to the aggregation server for incorporation into the machine learning model, a user may modify the parameter updates by applying respective noise values to individual ones of the parameter updates to ensure differential privacy for the dataset private to the user. The aggregation server may then receive the respective modified parameter updates from the multiple users and aggregate the updates into a single set of parameter updates to update the machine learning model. The federated machine learning may further include iteratively performing said sending, training, modifying, receiving, aggregating and updating steps.","['G06F21/6245', 'G06N20/00', 'G06N3/098']"
US12137979B2,Eye system,A method to analyze an eye with a mobile device includes capturing an eye image using a mobile device camera coupled to a processor; capturing gyroscope or accelerometer readings as image metadata to aid in orientation normalization and image registration by the processor; extracting features of the eye using the image corrected with image metadata; and applying the extracted features to a deep learning neural network to detect eye focus data or eye gaze data.,"['A61B3/0025', 'A61B3/14', 'A61B3/0008', 'A61B3/0016', 'A61B3/107', 'A61B3/16', 'G16H30/40', 'G16H50/20', 'G06T2207/20084', 'G06T2207/30041']"
US11922303B2,Systems and methods for distilled BERT-based training model for text classification,"Embodiments described herein provides a training mechanism that transfers the knowledge from a trained BERT model into a much smaller model to approximate the behavior of BERT. Specifically, the BERT model may be treated as a teacher model, and a much smaller student model may be trained using the same inputs to the teacher model and the output from the teacher model. In this way, the student model can be trained within a much shorter time than the BERT teacher model, but with comparable performance with BERT.","['G06N3/08', 'G06F40/40', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06N3/096', 'G06N3/048']"
US11599729B2,Method and apparatus for intelligent automated chatting,The present disclosure provides a method for intelligent automated chatting. A conversation with a user is performed by using a first identity of a first artificial intelligence entity. A message is received from the user in the conversation. Matching rates between the message and trigger contents of other artificial intelligence entities are scored. A second artificial intelligence entity is selected from the other artificial intelligence entities based on the matching rates. A conversation with the user is performed by using a second identity of the second artificial intelligence entity by switching from the first identity of the first artificial intelligence entity to the second identity of the second artificial intelligence entity.,"['G06F16/3329', 'G06F40/35', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'H04L51/04', 'G06F40/253', 'G06F40/295']"
US11893763B2,Generating modified digital images utilizing a global and spatial autoencoder,"The present disclosure relates to systems, methods, and non-transitory computer readable media for generating a modified digital image from extracted spatial and global codes. For example, the disclosed systems can utilize a global and spatial autoencoder to extract spatial codes and global codes from digital images. The disclosed systems can further utilize the global and spatial autoencoder to generate a modified digital image by combining extracted spatial and global codes in various ways for various applications such as style swapping, style blending, and attribute editing.","['G06T9/002', 'G06T11/60', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/094', 'G06T3/4046', 'G06T2200/24', 'G06T2210/36', 'G06T2219/2024']"
WO2021185225A1,Image super-resolution reconstruction method employing adaptive adjustment,"An image super-resolution reconstruction method employing adaptive adjustment, pertaining to the technical field of image processing. A basic framework comprises an adversarial training model involving a generative adversarial network. The training model consists of a generative model and a discriminant model competing with each other. The generative model is responsible for generating a high-resolution image. The discriminant model is used to determine whether an input image is generated or is a sample acquired from a high-resolution database. With the recognition ability gradually improved, the discriminant model transmits information to the generative model, and by optimizing a loss function, the high-resolution image generated by the generative model is closer to a real sample. As the quality of the generated image improves, the loss of the discriminant model increases. In addition, since the recognition ability of the discriminant model is continuously improved, when the discriminant model cannot distinguish between the generated image and the real sample, the generative model completes a super-resolution task. The invention improves the ability to express a model feature, and achieves a good super-resolution reconstruction effect.","['G06T3/4053', 'G06N3/045', 'G06T3/4046']"
US10762444B2,Real-time drift detection in machine learning systems and applications,"The present disclosure is for systems and methods for connecting offline machine learning training systems with online near-real time machine learning scoring systems. It is not trivial to connect an offline training environment with an online scoring environment. For example, offline training environments are usually static and contain large amounts of historical data that is needed for the initial training of models. Once trained, the model algorithms are then migrated into an online scoring environment for transactional or event based scoring. This migration effectively breaks the connection between the data in the offline environment and the model now running in the online environment. When new or shifting data occurs in the online environment, the static model running in the online environment goes unaltered to the changing inputs. The present disclosure solves the issues that are caused by the break in the offline and online environments.","['G06N20/00', 'G06F11/327', 'G06F17/18', 'G06N3/047', 'G06N3/09', 'G06N7/01', 'G06N7/023']"
US11531921B1,Early warning and event predicting systems and methods for predicting future events,"An early warning and event monitoring computer device for predicting events is provided. The computer device programmed to a) store a plurality of models associated with a plurality of future events, b) receive a plurality of data from a plurality of data sources, c) preprocess the plurality of data to remove noise and populate the plurality of models with the plurality of data, d determine a subset of models of the plurality of models to execute based on a user query, e) execute the subset of models to receive a plurality of results, f) ensemble the plurality of results from the subset of models to determine a combination model, and g) execute the combination model to forecast at least one future event based on the user query. The computer device uses predictive analytical results to visualize which actors, events, sentiments, and key variables across the topologies are critical to support.","['G06N7/005', 'G06N20/20', 'G06N20/00', 'G06N5/01', 'G06N7/01']"
AU2022201703B2,Generating modified digital images using deep visual guided patch match models for image inpainting,"OF THE DISCLOSURE The present disclosure relates to systems, methods, and non-transitory computer readable media for accurately, efficiently, and flexibly generating modified digital images utilizing a guided inpainting approach that implements a patch match model informed by a deep visual guide. In particular, the disclosed systems can utilize a visual guide algorithm to automatically generate guidance maps to help identify replacement pixels for inpainting regions of digital images utilizing a patch match model. For example, the disclosed systems can generate guidance maps in the form of structure maps, depth maps, or segmentation maps that respectively indicate the structure, depth, or segmentation of different portions of digital images. Additionally, the disclosed systems can implement a patch match model to identify replacement pixels for filling regions of digital images according to the structure, depth, and/or segmentation of the digital images. 2/12 CI C14 CNo CN 0- > m Co 0 -- -- -- -------------------------------------- ,C 00","['G06T5/77', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06T11/60', 'G06T3/4053', 'G06T5/60', 'G06T7/11', 'G06T7/50', 'G06T2207/20081', 'G06T2207/20084']"
US20220103472A1,Network routing of media streams based upon semantic contents,"Methods, computer-readable media, and devices are disclosed for routing media streams to destination devices based upon semantic contents detected in the media streams. For example, a method may include a processing system including at least one processor detecting a first semantic content in a media stream of a media source device in accordance with a machine learning model for detecting the first semantic content, selecting a first destination device for the media stream based upon the first semantic content, and sending the media stream to the first destination device that is selected.","['H04L45/70', 'H04L45/30', 'G06N20/00', 'G06N3/08', 'G06V20/70', 'G06K2009/00738', 'G06V20/41', 'G06V20/44']"
US20230217195A1,Bluetooth enabled intercom with hearing aid functionality,"A hearing aid, comprising a microphone configured to produce a microphone output signal representing sounds transduced by the microphone; an earphone speaker configured to convert an equalized output electrical signal into acoustic waves; a Bluetooth wireless transceiver; and an automated processor configured to spot a plurality of different keywords; and selectively control a Bluetooth communication partner dependent on the spotted keyword.","['H04R25/554', 'G06F3/165', 'G06F3/167', 'G10L15/16', 'G10L15/22', 'H04R25/602', 'H04R25/606', 'H04R25/609', 'G10L2015/088', 'G10L2015/223', 'H04R2225/025', 'H04R2225/55', 'H04R2420/07', 'H04R2460/13', 'H04R3/12']"
US10366490B2,Highly integrated annotation and segmentation system for medical imaging,"A method for training a segmentation correction model includes performing an iterative model training process over a plurality of iterations. During each iteration, an initial segmentation estimate for an image is provided to a human annotators via an annotation interface. The initial segmentation estimate identifies one or more anatomical areas of interest within the image. Interactions with the annotation interface are automatically monitored to record annotation information comprising one or more of (i) segmentation corrections made to the initial segmentation estimate by the annotators via the annotation interface, and (ii) interactions with the annotation interface performed by the annotators while making the corrections. A base segmentation machine learning model is trained to automatically create a base segmentation based on the image. Additionally, a segmentation correction machine learning model is trained to automatically perform the segmentation corrections based on the image.","['G06T7/11', 'G06N3/044', 'G06N3/0445', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T11/60', 'G06T7/0012', 'G06V10/987', 'G16H30/40', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092']"
US10628527B2,Automatically cross-linking application programming interfaces,"A method for automatically cross-linking a plurality of APIs in an artificial intelligence (AI) graph structure comprises maintaining an AI graph structure defining a plurality of API-agnostic semantic entities, a plurality of function nodes, a plurality of input-adapter edges, and a plurality of output adapter edges. The method further comprises cross-linking a new function from a new API by computer-analyzing documentation of the new API with a natural language processing (NLP) machine in order to recognize the new function, and updating the AI graph data structure to include a new function node based on the new function.","['G06F17/2785', 'G06F40/216', 'G06F16/3329', 'G06F16/9024', 'G06F40/30', 'G06N3/09', 'G06N3/092', 'G06N5/022', 'G06N5/046', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088']"
US20240390794A1,"Systems and Methods for Dynamically Generating and Modulating Music Based on Gaming Events, Player Profiles and/or Player Reactions",The application describes methods and systems for dynamically generating a music clip for rendering at client devices in a multi-player gaming network. Player data and event data are acquired and classified into two or more profiles. The music clip is then generated by identifying a mood based on one of the two or more event profiles and one of the two or more player profiles and modulating one or more music elements of a segment of audio data based on the identified mood.,"['A63F13/54', 'A63F13/35', 'A63F13/67', 'A63F13/79', 'A63F13/87']"
US20230410266A1,Generating gaze corrected images using bidirectionally trained network,"An example apparatus for adjusting eye gaze in images one or more processors to execute instructions to bidirectionally train a neural network; access a target angle and an input image, the input image including an eye in a first position; generate a vector field with the neural network; and generate a gaze-adjusted image based on the vector field, the gaze-adjusted image including the eye in a second position.","['G06V40/19', 'G06T5/006', 'G06T5/80', 'G06F18/214', 'G06F18/217', 'G06T3/0093', 'G06T3/18', 'G06T5/20', 'G06T5/60', 'G06T7/73', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V10/98', 'G06V40/193', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2210/44']"
US11430071B2,Navigation based on liability constraints,"A method including operations to obtain a planned driving action for accomplishing a navigational goal of a host vehicle on a roadway, identify a planned trajectory for the host vehicle, corresponding to the planned driving action, identify, from sensor data representative of an environment of the host vehicle, an occluded location of a potential object that is occluded from view of the host vehicle, identify a possible trajectory of the potential object, based on possible movement of the potential object from the location into the roadway, identify an intersection of the planned trajectory for the host vehicle with the possible trajectory for the potential object, determine a safety action of the host vehicle to respond to the possible movement of the potential object, and apply the safety action to change the planned driving action of the host vehicle.","['G06Q40/08', 'B60W10/04', 'B60W10/18', 'B60W10/20', 'B60W30/09', 'B60W30/095', 'B60W30/0953', 'B60W30/0956', 'B60W30/18163', 'B60W60/0027', 'G01C21/3407', 'G01C21/3602', 'G05D1/0088', 'G05D1/0246', 'G06Q10/00', 'G07C5/02', 'G07C5/08', 'G08G1/163', 'B60W2400/00', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2520/10', 'B60W2554/00', 'B60W2554/4048', 'B60W2554/801', 'B60W2554/804', 'B60W2555/60', 'B60W2710/18', 'G05D2201/0213', 'G07C5/0808']"
US10970819B2,"Image processing device, image processing method, and image processing program","An image processing device according to one embodiment includes a processor. The processor executes a step of acquiring an input image, a step of calculating a feature residual by processing the input image in a convolutional layer, a step of performing at least one convolution on the input image, a step of generating an output feature by applying the feature residual to the convolved input image, and a step of generating an image residual based on the output feature. The image residual is applied to the input image, and thereby a high-resolution image with higher resolution than the input image is generated.","['G06T3/4053', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T3/4046']"
US20200301015A1,Systems and methods for localization,"Systems and methods for localization are provided. In one aspect, a LIDAR scan is captured from above to generate a point cloud. One or more locations may be sampled in the point cloud and LIDAR scans may be simulated at each location. The sampled locations and associated simulated LIDAR scans may be used to train a regressor to localize vehicles in the environment that are at poses different from the pose from which the LIDAR point cloud was captured. In one aspect, a mapping UAV systematically scans an environment with a camera to generate a plurality of map images. The map images are stitched together into an orthographic image. A runtime UAV captures one or more runtime images of the environment with a camera. Feature matching is performed between the runtime images and the orthographic image for localization. In one aspect, a first machine learning model is trained to transform a camera image into a LIDAR image and a second machine learning model is trained to estimate a pose based on a LIDAR image. A runtime image may be input to the first machine learning model to generate a simulated LIDAR scan. The simulated LIDAR scan may be input to the second machine learning model to estimate a pose, which localizes the vehicle.","['G01S17/933', 'B64C39/024', 'G01S17/006', 'G01S17/10', 'G01S17/42', 'G01S17/46', 'G01S17/86', 'G01S17/89', 'G01S17/931', 'G01S7/4802', 'G01S7/4808', 'G06F18/2155', 'G06F18/2433', 'G06K9/0063', 'G06K9/6259', 'G06N20/20', 'G06V10/462', 'G06V10/758', 'G06V10/764', 'G06V20/13', 'B64C2201/127', 'B64U10/10', 'B64U10/25', 'B64U2101/30', 'G06N3/08', 'G06N5/01']"
US11520881B2,Framework for cyber-physical system protection of electric vehicle charging stations and power grid,"Some embodiments provide a system to protect an electric vehicle charging infrastructure. An electric vehicle charging site may receive AC power from a power grid and provide DC power to electric vehicles. The charging site may include a plurality of monitoring nodes each generating a series of current monitoring node values over time that represent a current operation of the electric vehicle charging infrastructure. A supply equipment communication controller may receive an access request from an access requestor associated with an electric vehicle, the access request being associated with a platform certificate. A secondary actor policy decision point at the charging site may evaluate the access requestor's identity and respond with an action message allowing high-level communication with the access requestor to proceed. Note that information associated with the current monitoring node values and/or the access request may be stored in a secure, distributed transaction ledger (e.g., an attestation blockchain).","['H04L9/3239', 'B60L3/0046', 'B60L53/305', 'B60L53/65', 'B60L53/66', 'B60L53/68', 'G06F21/554', 'G06F21/57', 'G06F21/64', 'H04L9/0637', 'H04L9/0897', 'H04L9/3236', 'H04L9/50', 'H04L2209/84', 'Y02T10/70', 'Y02T10/7072', 'Y02T90/12', 'Y02T90/16', 'Y02T90/167', 'Y04S30/14']"
CN111738940B,An eye-completion method for face images,"The invention provides a human face image eye completing method for generating an antagonistic network based on a self-attention mechanism model, and belongs to the field of machine learning. Firstly, selecting a face photo of a person belonging to the same identity and having different postures as a reference, inputting a corresponding reference image, eyes of the reference image, a missing image, eyes of the missing image and a 10-dimensional noise vector into a generator network of a model built by people, wherein the generator network consists of a certain number of convolution layers, residual blocks and deconvolution layers, and finally outputting a completed face image by a generator. And then the generated complementary image is judged to be true or false through a discriminator network. The invention can improve the quality of the generated eye image of the human face, and meanwhile, the generated eye part is not directly and simply copied with the reference image, and the generated eye part does not fall into the problem of mode collapse and corresponds to respective identity.","['G06T5/77', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11811794B2,Privacy interface for data loss prevention via artificial intelligence models,The technology disclosed provides systems and methods related to preventing exfiltration of training data by feature reconstruction attacks on model instances trained on the training data during a training job. The system comprises a privacy interface that presents a plurality of modulators for a plurality of training parameters. The modulators are configured to respond to selection commands via the privacy interface to trigger procedural calls. The procedural calls modify corresponding training parameters in the plurality of training parameters for respective training cycles in the training job. The system comprises a trainer configured to execute the training cycles in dependence on the modified training parameters. The trainer can determine a performance accuracy of the model instances for each of the executed training cycles. The system comprises a differential privacy estimator configured to estimate a privacy guarantee for each of the executed training cycles in dependence on the modified training parameters.,"['H04L63/1441', 'H04L63/1416', 'G06N20/00', 'G06N20/20']"
US12286106B2,Systems and methods for vehicle navigation,"Systems and methods are provided for vehicle navigation. In one implementation, at least one processor may receive, from a camera, at least one captured image representative of features in an environment of the vehicle. The processor may identify an intersection and a pedestrian in a vicinity of the intersection represented in the image. The processor may determine a navigational action for the vehicle relative to the intersection based on routing information for the vehicle; and determine a predicted path for the vehicle relative to the intersection based on the determined navigational action and a predicted path for the pedestrian based on analysis of the image. The processor may further determine whether the vehicle is projected to collide with the pedestrian based on the projected paths; and, in response, cause a system associated with the vehicle to implement a collision mitigation action.","['B60W30/0953', 'B60W30/09', 'B60W30/0956', 'B60W30/18145', 'B60W50/14', 'B60W60/0027', 'G06V40/103', 'B60W2050/143', 'B60W2050/146', 'B60W2420/403', 'B60W2520/10', 'B60W2552/05', 'B60W2554/4029', 'B60W2554/4042', 'B60W2554/4045', 'B60W2554/4048', 'B60W2554/80', 'B60W2554/802', 'B60W2554/806', 'B60W2710/18', 'B60W2710/20', 'B60W2754/10', 'B60W60/0011', 'B60W60/0017', 'G01S13/86', 'G01S13/867', 'G01S2013/9318', 'G01S2013/93185', 'G01S2013/9319', 'G01S2013/9323', 'G06V20/58']"
US11516036B1,Systems and methods for enhancing meetings,"The present disclosure provides methods and systems for quantifying meeting effectiveness. A method for quantifying meeting effectiveness may comprise: (a) receiving calendar data related to a meeting; (b) generating a feedback survey based on the calendar data for collecting user feedback data, wherein the feedback survey is presented to a user on an electronic device; (c) generating, using a trained machine learning algorithm, a meeting score indicative of an effectiveness of the meeting based on the meeting data and the user feedback data, and (d) displaying the meeting score within a graphical user interface (GUI) on the electronic device.","['G06Q10/1093', 'G06Q10/1095', 'H04L12/1822', 'H04L12/1827', 'H04L12/1831']"
US11931207B2,Artificial intelligence (AI) recognition of echocardiogram images to enhance a mobile ultrasound device,"Artificial intelligence (AI) recognition of echocardiogram (echo) images by a mobile ultrasound device comprises receiving a plurality of the echo images captured by the ultrasound device, the ultrasound device including a display and a user interface (UI) that displays the echo images to a user, the echo images comprising 2D images and Doppler modality images of a heart. One or more neural networks process the echo images to automatically classify the echo images by view type. The view type of the echo images is simultaneously displayed in the UI of the ultrasound device along with the echo images. A report is generated showing the calculated measurements of features in the echo images. The report showing the calculated measurements is displayed on a display device.","['A61B8/466', 'G06N3/08', 'A61B8/463', 'A61B8/468', 'A61B8/469', 'A61B8/488', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06T7/0012', 'G06T7/10', 'G06T7/70', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H50/20', 'G16H50/70', 'A61B8/4472', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30244', 'G16H70/20']"
US20210019674A1,Risk profiling and rating of extended relationships using ontological databases,"A system and method for understanding and analyzing risk for use in business and financial decisions. The system and method allow a user to query an individual or business and returns a profile and a rating associated with the risk of that entity. The profile consists of an advanced temporospatial weighted and directional knowledge graph that is generated by ingesting, processing, and transforming a vast amount of complex data for the purpose of human comprehension and further system analysis. Meanwhile, the rating is generated from a risk analysis algorithm that conducts a comprehensive analysis by categorizing and weighting all available risk factors. The system and method provide advanced insights and analytics into the inherent state, value, and risk associated with an entity and its relations.","['G06F15/76', 'G06F16/367', 'G06F16/9024', 'G06F16/90332', 'G06N20/00', 'G06N5/022', 'G06Q10/0635', 'G06V20/35', 'G06V20/41', 'G06V20/70', 'G06V30/274']"
US11715213B2,Apparatus and methods for determining multi-subject performance metrics in a three-dimensional space,"Apparatus and methods for extraction and calculation of multi-person performance metrics in a three-dimensional space. An example apparatus includes a detector to identify a first subject in a first image captured by a first image capture device based on a first set of two-dimensional kinematic keypoints in the first image, the two-dimensional kinematic keypoints corresponding to a joint of the first subject, the first image capture device associated with a first view of the first subject, a multi-view associator to verify the first subject using the first image and a second image captured by a second image capture device, the second image capture device associated with a second view of the first subject, the second view different than the first view, and a keypoint generator to generate three-dimensional keypoints for the first subject using the first set of two-dimensional kinematic keypoints.","['G06T7/246', 'G06T7/292', 'G06T7/596', 'G06T7/73', 'G06V10/147', 'G06V10/22', 'G06V10/255', 'G06V10/757', 'G06V20/42', 'G06V20/647', 'G06V40/23', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30196', 'G06T2207/30221']"
US20230286536A1,Systems and methods for evaluating domain-specific navigation system capabilities,"Systems and methods evaluate navigation system capabilities. In one implementation, at least one processing device is programmed to acquire characteristics of one or more sensors included in the host vehicle; establish a testing domain, wherein the testing domain includes at least one mapped representation of a geographic region; and simulate operation of the one or more sensors relative to the testing domain. Based on the simulated operation of the one or more sensors, the at least one processing device may determine whether one or more regions exist within the geographic region where outputs of the one or more sensors are insufficient for ensuring that each navigational action implemented by the navigation system of the host vehicle will not result in an accident for which the host vehicle is at fault.","['B60W60/001', 'G01C21/3415', 'G01C21/3461', 'G01C21/3822', 'G01C21/3837', 'G06V20/56', 'G06V20/58', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52', 'B60W2555/20']"
CN113936217B,Priori semantic knowledge guided high-resolution remote sensing image weak supervision building change detection method,"The invention provides a priori semantic knowledge guided high-resolution remote sensing image weak supervision building change detection method, which utilizes high-resolution remote sensing images to perform building automatic change detection, firstly adopts a building extraction algorithm integrating domain self-adaption and weak supervision strategies to generate priori semantic knowledge, and fully utilizes the domain self-adaption and weak supervision strategies to furthest improve the domain expansion capability of the priori knowledge and reduce the number and difficulty of sample dataset production. And then designing a priori semantic knowledge guided high-resolution remote sensing image weak supervision building change detection network, taking intermediate results of all stages of a building extraction network as priori knowledge, reducing dependence of the network on change detection sample data to the greatest extent, and improving the effect of building change detection.","['G06N3/045', 'G06N3/08']"
US11023708B2,Within document face verification,"A computer-implemented method for determining whether images of faces contained in a document correspond to each other. The method comprises acquiring image data pertaining to the document and performing facial detection on the image data to detect one or more facial representations existing within the document. If two or more facial representations are detected, a first facial representation and a second facial representation are selected, and determination of whether the image of a face of the first facial representation corresponds to the image of a face of the second facial representation is performed.","['G06V30/40', 'G06K9/00228', 'G06V30/1429', 'G06K9/3233', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06T7/11', 'G06V10/143', 'G06V30/41', 'G06V40/161', 'G06T2207/30201']"
US20190298195A1,System and method for non-invasive determination of blood pressure dip based on trained prediction models,"The present disclosure pertains to a method and system for determining the blood pressure dip of a subject based on features extracted from information generated by an on-body sensor system. The on-body sensor system includes a photoplethysmographic (PPG) sensor and a motion sensor. Blood pressure variation is captured throughout the day and utilized along with determinations of whether a subject is asleep or awake. The blood pressure determinations collected throughout the day, along with determinations of sleep periods, are used to determine a blood pressure dip for the day the on-body sensor system is worn.","['A61B5/02255', 'A61B5/02108', 'A61B5/02405', 'A61B5/02416', 'A61B5/4809', 'A61B5/681', 'A61B5/7264', 'A61B5/0295', 'G16H50/20']"
US11397888B2,Virtual agent with a dialogue management system and method of training a dialogue management system,"A virtual agent with a dialogue management system and a method of training the dialogue management system is disclosed. The dialogue management system is trained using a deep reinforcement learning process. Training involves obtaining or simulating training dialogue data. During the training process, actions for the dialogue management system are selected using a Deep Q Network to process observations. The Deep Q Network is updated using a target function that includes a reward. The reward may be generated by considering one or more of the following metrics: task completion percentage, dialogue length, sentiment analysis of the user's response, emotional analysis of the user's state, explicit user feedback, and assessed quality of the action. The set of actions that the dialogue management system can take at any time may be limited by an action screener that predicts the subset of actions that the agent should consider for a given state of the system.","['G06N3/08', 'G06F40/30', 'G06F16/24578', 'G06F16/3329', 'G06N3/006', 'G06N3/0499', 'G06N3/084', 'G06N3/092', 'G06F40/40', 'G06N7/01']"
US11232357B2,Method for injecting human knowledge into AI models,"Human knowledge may be injected in an explainable AI system in order to improve the model's generalization error, model accuracy, interpretability of the model, avoid or eliminate bias, while providing a path towards the integration of connectionist systems with symbolic logic in a combined AI system. Human knowledge injection may be implemented by harnessing the white-box nature of explainable/interpretable models. In one exemplary embodiment, a user applies intuition to model-specific cases or exceptions. In another embodiment, an explainable model may be embedded in workflow systems which enable users to apply pre-hoc and post-hoc operations. A third exemplary embodiment implements human-assisted focusing. An exemplary embodiment also presents a method to train and refine explainable or interpretable models without losing the injected knowledge defined by humans when applying gradient descent techniques. The white-box nature of explainable models allows for precise source attribution and traceability of knowledge incorporated into the model.","['G06N3/08', 'G06N5/045', 'G06N20/00', 'G06N3/042', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N3/098', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N5/025', 'G06N7/01']"
US12126868B2,Content filtering in media playing devices,"Various approaches relate to user defined content filtering in media playing devices of undesirable content represented in stored and real-time content from content providers. For example, video, image, and/or audio data can be analyzed to identify and classify content included in the data using various classification models and object and text recognition approaches. Thereafter, the identification and classification can be used to control presentation and/or access to the content and/or portions of the content. For example, based on the classification, portions of the content can be modified (e.g., replaced, removed, degraded, etc.) using one or more techniques (e.g., media replacement, media removal, media degradation, etc.) and then presented.","['H04N21/4542', 'H04N21/44004', 'G06F16/4393', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T3/40', 'G06T5/20', 'G06T7/11', 'G06V20/41', 'G06V20/46', 'G06V20/49', 'H04N21/4312', 'H04N21/4392', 'H04N21/4394', 'H04N21/4398', 'H04N21/44008', 'H04N21/440218', 'H04N21/440245', 'H04N21/4532', 'H04N21/45452', 'H04N21/4665', 'G06T2207/20084']"
US11964170B2,Standardized artificial intelligence automatic radiation therapy planning method and system,"A standardized artificial intelligence automatic radiotherapy planning method includes acquiring a medical image; automatically delineating an ROI area of the medical image to acquire a geometric anatomical structure; determining a prescription according to disease type information corresponding to the medical image, the geometric anatomical structure, and a preset disease-prescription template library, and determining a radiation angle of radiation therapy; obtaining a radiation therapy dose distribution result using a dose prediction model; performing optimization processing using a reverse optimization algorithm based on dose distribution or DVH guidance, with reference to the radiation dose distribution result, to generate executable radiation therapy plans.","['A61N5/1031', 'A61N5/1036', 'A61N5/1039', 'A61N5/1048', 'G16H20/40', 'A61N2005/1034', 'A61N2005/1041']"
US20210102197A1,"Designing sensitive, specific, and optimally active binding molecules for diagnostics and therapeutics","The invention provides for methods for designing sensitive, specific, and optimally active binding molecules. Systems, methods and compositions utilizing the designed molecules in diagnostics and therapeutics are also provided.","['C12N9/22', 'C12N15/1089', 'C12N15/113', 'G16B30/10', 'G16B35/10', 'G16B40/20', 'C12N2310/141', 'C12N2310/20']"
US11562490B2,Systems and methods for video object segmentation,"Systems and methods for generating object segmentations across videos are provided. An example system can enable an annotator to identify objects within a first image frame of a video sequence by clicking anywhere within the object. The system processes the first image frame and a second, subsequent, image frame to assign each pixel of the second image frame to one of the objects identified in the first image frame or the background. The system refines the resulting object masks for the second image frame using a recurrent attention module based on contextual features extracted from the second image frame. The system receives additional user input for the second image frame and uses the input, in combination with the object masks for the second image frame, to determine object masks for a third, subsequent, image frame in the video sequence. The process is repeated for each image in the video sequence.","['G06T7/11', 'G06F18/2178', 'G06K9/6263', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T7/246', 'G06V10/945', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20101', 'G06T2207/30252', 'G06T7/174', 'G06V10/235', 'G06V10/82', 'G06V20/56', 'G06V20/70']"
CN112767958B,Zero-order learning-based cross-language tone conversion system and method,"The invention discloses a zero-order learning-based cross-language tone conversion system and a zero-order learning-based cross-language tone conversion method. The system takes a Mel spectrum of a voice signal as an input signal, extracts bottleneck characteristics of the Mel spectrum through a phoneme recognition module, normalizes the characteristics, transmits the bottleneck characteristics to an acoustic model, controls a speaking ginseng reference vector, thereby controlling the Mel spectrum synthesized by the acoustic model, and finally synthesizes audio through a vocoder. The system can convert the voice of a general speaker into the tone of a designated speaker, is suitable for the accent corpus which does not appear in a training database, can be suitable for the voice changing of multi-regional dialects, and has wide application prospect.","['G10L21/013', 'G10L15/02', 'G10L15/063', 'G10L15/07', 'G10L19/0212', 'G10L19/26', 'G10L25/24', 'G10L25/30', 'G10L25/87', 'G10L2015/025', 'G10L2021/0135']"
US20210390723A1,Monocular unsupervised depth estimation method based on contextual attention mechanism,"The present invention provides a monocular unsupervised depth estimation method based on contextual attention mechanism, belonging to the technical field of image processing and computer vision. The invention adopts a depth estimation method based on a hybrid geometric enhancement loss function and a context attention mechanism, and adopts a depth estimation sub-network, an edge sub-network and a camera pose estimation sub-network based on convolutional neural network to obtain high-quality depth maps. The present invention uses convolutional neural network to obtain the corresponding high-quality depth map from the monocular image sequences in an end-to-end manner. The system is easy to construct, the program framework is easy to implement, and the algorithm runs fast; the method uses an unsupervised method to solve the depth information, avoiding the problem that ground-truth data is difficult to obtain in the supervised method.","['G06T7/55', 'G06T7/50', 'G06F18/2132', 'G06F18/2193', 'G06K9/6234', 'G06K9/6265', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/088', 'G06T7/529', 'G06T7/564', 'G06T7/74', 'G06T7/75', 'G06T9/002', 'G06V10/454', 'G06V10/82', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US11722359B2,Drift detection for predictive network models,"A method, computer system, and computer program product are provided for detecting drift in predictive models for network devices and traffic. A plurality of streams of time-series telemetry data are obtained, the time-series telemetry data generated by network devices of a data network. The plurality of streams are analyzed to identify a subset of streams, wherein each stream of the subset of streams includes telemetry data that is substantially empirically distributed. The subset of streams of time-series data are analyzed to identify a change point. In response to identifying the change point, additional time-series data is obtained from one or more streams of the plurality of streams of time-series telemetry data. A predictive model is trained using the additional time-series data to update the predictive model and provide a trained predictive model.","['H04L41/064', 'G06F18/214', 'G06F18/2433', 'G06F18/27', 'H04L41/147', 'H04L41/16', 'H04L43/04', 'G06F2218/00']"
EP4300440A2,Method and apparatus for image segmentation,"Broadly speaking, the present techniques generally relate to a method for training a machine learning, ML, model to perform semantic image segmentation, and to a computer-implemented method and apparatus for performing semantic image segmentation using a trained machine learning, ML, model. The training method enables a semantic image segmentation ML model that is able to make predictions faster, without significant loss in accuracy. The training method also enables the ML model to be implemented on apparatus with different hardware specifications, i.e. different computational power and memory, for example.","['G06T7/12', 'G06V10/26', 'G06N3/045', 'G06N3/0464', 'G06V10/70', 'G06V10/7792', 'G06V10/82', 'G06V10/95', 'G06V20/20', 'G06V20/70', 'G06T2207/20081']"
US20230329646A1,Classifying biomedical acoustics based on image representation,"A method in an illustrative embodiment comprises obtaining an acoustic signal for a given individual, generating an image representation of at least a portion of the acoustic signal, processing the image representation in at least one neural network of an acoustics classifier to generate a classification for the acoustic signal, and executing at least one automated action based at least in part on the generated classification. The acoustic signal illustratively comprises, for example, at least one of a heart sound signal, a blood flow sound signal, a lung sound signal, a bowel sound signal, a cough sound signal, or other physiological sound signal of the given individual. Generating the image representation illustratively comprises generating at least one spectrogram. Additionally or alternatively, generating the image representation may comprise generating one or more recurrence plots, Markov transition field image representations and/or Gramian angular field image representations.","['G10L25/66', 'A61B5/7267', 'A61B7/00', 'A61B7/003', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'G10L21/0232', 'G10L25/30', 'G16H70/60']"
CN110097543B,Hot-rolled strip steel surface defect detection method based on generation type countermeasure network,"The invention relates to a hot-rolled strip steel surface defect detection method based on a generative confrontation network, which comprises the following specific steps: (1) Extracting surface defect images of hot-rolled strip steel on an industrial site, and performing image preprocessing; (2) And constructing a generator model and a discriminator model of the generative confrontation network GAN. Adding a condition label vector c into the input of a generator for outputting a classified image; introducing pixel loss L in generator training p The quality of the generated image is improved; a discrimination branch and a multi-classification branch are arranged in the discriminator, so that the multi-classification function is realized and the classification precision is improved; (3) Optimizing the constructed generative confrontation network parameters by using a Particle Swarm Optimization (PSO); (4) And combining the generated image and the real image into a hot-rolled strip steel surface defect sample set. The method provided by the invention can solve the problem of insufficient sample data, improve the speed and accuracy of defect image feature extraction, and provide a new effective method for the surface defect detection of the hot-rolled strip steel.","['G06N3/006', 'G06N3/045', 'G06T7/0004']"
US11373632B2,Using communicative discourse trees to create a virtual persuasive dialogue,"Techniques are disclosed for generating a virtual persuasive dialogue. In an example, a dialogue application receives a selection of a topic from a user device. The application identifies document results that are associated with the topic. Using communicative discourse trees, the application identifies document results that include argumentation, transforms these document results into a dialogue form, and presents the results to a user device as a virtual persuasive dialogue.","['G10L13/00', 'G06F16/3329', 'G06F16/35', 'G10L13/10']"
US20230197289A1,Epidemic Monitoring System,"Systems and methods for monitoring the spread of pandemic pneumonia using IOT technology is provided. Sensor data from wearable devices is utilized to determine: a probability of developing complications from a pandemic for an unexposed user using existing indicators of the wearer’s health; the impact of lockdown measures on health; a probability that a user exposed to the pathogen experiences complications; and a probability of various disease stages for the user including normal, asymptomatic, pre-symptomatic, symptomatic, complication development and recovery is provided.","['G16H40/63', 'G16H50/80', 'G16H15/00', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'Y02A90/10']"
US11125844B2,Deep learning based methods to accelerate multi-spectral imaging,"A method for magnetic resonance imaging reconstructs images that have reduced under-sampling artifacts from highly accelerated multi-spectral imaging acquisitions. The method includes performing by a magnetic resonance imaging (MRI) apparatus an accelerated multi-spectral imaging (MSI) acquisition within a field of view of the MRI apparatus, where the sampling trajectories of different spectral bins in the acquisition are different; and reconstructing bin images using neural network priors learned from training data as regularization to reduce under-sampling artifacts.","['G01R33/5608', 'G01R33/5611', 'G01R33/56536', 'G01R33/56545']"
US11106943B2,Model-aware synthetic image generation,"A computer implemented method includes obtaining a first deep neural network (DNN) model trained on labeled real image data for a downstream vision task, obtaining a second DNN model trained on synthetic images created with random image parameter values for the downstream vision task, obtaining a third DNN model trained on the labeled real image data and the synthetic images for the downstream vision task, performing a forward pass execution of each model to generate a loss, backpropagating the loss to modify parameter values, and iterating the forward pass execution and backpropagating with images generated by the modified parameters to jointly train the models and optimize the parameters.","['G06K9/6262', 'G06N3/084', 'G06F18/214', 'G06F18/217', 'G06F18/22', 'G06K9/6215', 'G06K9/6256', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06N3/094']"
US11645524B2,System and method for machine learning architecture with privacy-preserving node embeddings,"A computer system and method for machine inductive learning on a graph is provided. In the inductive learning computational approach, an iterative approach is used for sampling a set of seed nodes and then considering their k-degree (hop) neighbors for aggregation and propagation. The approach is adapted to enhance privacy of edge weights by adding noise during a forward pass and a backward pass step of an inductive learning computational approach. Accordingly, it becomes more technically difficult for a malicious user to attempt to reverse engineer the edge weight information. Applicants were able to experimentally validate that acceptable privacy costs could be achieved in various embodiments described herein.","['G06N3/08', 'G06F16/9024', 'G06F17/16', 'G06F17/18', 'G06F18/23213', 'G06K9/6223', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0472', 'G06N3/084', 'G06N3/09']"
CN110147883B,"Training method, device, equipment and storage medium for model for combat simulation","The invention relates to a training method, a device, equipment and a storage medium of a neural network model for combat simulation, wherein the method comprises the following steps: acquiring multiple groups of first environment information; inputting any group of first environment information into a pre-constructed neural network model to obtain a first action to be executed; scoring the first execution action by applying a pre-trained evaluation model, and updating parameters of a pre-constructed neural network model according to a scoring result; optimizing a pre-constructed neural network model according to the parameters; and sequentially inputting each group of the rest first environment information into the neural network model optimized last time to obtain the action to be executed corresponding to the group of the first environment information, executing the corresponding action, scoring the executed action by applying a pre-trained evaluation model until the optimized neural network model meets a first convergence condition, and determining a first target neural network model. The method is applied to a combat simulation platform, so that the combat behavior is more intelligent.","['G06N3/10', 'Y02T10/40']"
US11874911B2,Privacy preserving face-based authentication,Example systems and methods for biometric authentication that can bridge fuzzy extractors with deep learning and achieve the goals of preserving privacy and providing recoverability from zero are disclosed. Embeddings comprising a face or speaker embedding in a non-Hamming distance space can be processed to create a personal reliable bit map and a reliable locality-sensitive hash (LSH) for mapping the non-Hamming distance space to a Hamming distance space. A fuzzy extractor can be applied to create metadata that can be stored on a computing device. A secret can be recovered from the metadata and can be used for identification.,"['G06F21/32', 'G06F21/602', 'G06F21/62', 'H04L9/0861', 'H04L9/0894', 'H04L9/14', 'H04L9/3231', 'H04L9/3271', 'G06F2221/2133', 'H04L2209/04', 'H04L2209/08', 'H04L2209/34']"
KR102365433B1,Method and apparatus for emotion recognition based on cross attention model,"Provided are a method and device for recognizing an emotion to predict an emotion of a speaker through a cross attention model operating based on the audio data and the text data representing an utterance corresponding to an utterance of the speaker. Therefore, the present invention improves an accuracy of predicting the emotion. The method for recognizing the emotion comprises: a step of obtaining; a step of dividing; a step of extracting sentence expression data; a step of extracting voice expression data; a step of calculating cross attention model; and a step of calculating emotion prediction result.","['G10L25/63', 'G10L15/04', 'G10L15/063', 'G10L15/16', 'G10L15/26', 'G10L2015/0635']"
US11509683B2,System and method for securing a network,"A system for generating a cyber-attack to penetrate a network. The system includes an identification module configured to identify at least one vulnerability of the network by examining at least one of a node of the network, data transmission within the network, or data received from a cyber defense mechanism; a generation module configured to generate a cyber-attack based on the at least one vulnerability of the network, and a goal to be achieved by the cyber-attack. The system includes a penetration module configured to penetrate the network with the cyber-attack and determine an effectiveness rating of the penetration; and a feedback module configured to provide a feedback to the identification module based on at least the effectiveness rating of the penetration.","['H04L63/1433', 'H04L63/1416', 'H04L63/1466']"
US20250279084A1,Text and audio-based real-time face reenactment,"Systems and methods for text and audio-based real-time face reenactment are provided. An example method includes receiving an input text and a target image, where the target image includes a target face, generating, based on the input text, a sequence of acoustic feature sets, generating, based on the sequence of acoustic feature sets, a sequence of mouth texture images, inserting a mouth texture image of the sequence of mouth texture images into a mouth region of the target face to produce an output frame of a sequence of output frames, and generating an output video including the sequence of output frames.","['G10L13/00', 'G06T13/40', 'G06V10/764', 'G06V10/82', 'G06V40/171', 'G10L13/08']"
US11763100B2,System and method for controllable machine text generation architecture,"A system is provided comprising a processor and a memory storing instructions which configure the processor to process an original sentence structure through an encoder neural network to decompose the original sentence structure into an original semantics component and an original syntax component, process the original syntax component through a syntax variation autoencoder (VAE) to receive a syntax mean vector and a syntax covariance matrix, obtain a sampled syntax value from a syntax Gaussian posterior parameterized by the syntax mean vector and the syntax covariance matrix, process the original semantics component through a semantics VAE to receive a semantics mean vector and a semantics covariance matrix, obtain a sampled semantics vector from the Gaussian semantics posterior parameterized by the semantics mean vector and the semantics covariance matrix, and process the sampled syntax vector and the sampled semantics vector through a decoder neural network to compose a new sentence.","['G06F40/56', 'G06F40/30', 'G06F40/211', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/088', 'G06N3/0895', 'G06N3/08']"
EP4517643A2,Event determination for vehicles and occupants of mobility provider on maas platform,"A mobility player system including memory and a processor is provided. The memory stores a trained Al model. The processor receives on-board diagnostic (OBD) data associated with a first vehicle registered with a first mobility provider. The processor receives occupant data, different from the OBD data, from plurality of sensors associated with the first vehicle. The processor determines a plurality of parameters based on the received OBO data and the received occupant data. The processor applies the trained Al model on the plurality of parameters. The processor determines one or more events related to the first vehicle, or related to an occupant of the first vehicle, based on the application of the trained Al model on the plurality of parameters. The processor transmits information about the determined one or more events to one or more nodes of a distributed ledger associated with a Mobility-as-a-Service (MaaS) network.","['H04L67/12', 'B60W40/09', 'G06N3/02', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06Q10/047', 'G06Q10/06', 'G06Q30/02', 'G06Q50/265', 'G06Q50/40', 'G07C5/008', 'G08G1/20', 'H04L67/306', 'H04W4/40', 'B60W2540/043', 'B60W2540/22', 'B60W2540/229', 'B60W2556/45', 'B60W2756/10', 'G06Q2220/00']"
US20250265944A1,Audiovisual content selection,"Systems and techniques are disclosed for aspects of audiovisual content selection based on collecting and processing physiological data. In an example, a system comprises: a sensor device with at one physiological sensor to capture physiological data from a human subject; an output device with a display device to output video and a speaker to output audio to the human subject; and a computing device with at least one processor to control an output of digital audiovisual data to a human subject via the output device, based on data processing operations including a comparison of an observed pattern of autonomic nervous system activity to a target pattern of autonomic nervous system activity.","['G09B19/00', 'A61B5/0205', 'A61B5/165', 'A61B5/7264', 'A61B5/7267', 'A61M21/00', 'G09B5/02', 'G16H20/70', 'G16H50/20', 'H04N21/4667', 'H04N21/472', 'H04N21/8106', 'A61B5/162', 'A61B5/163', 'A61M2021/0027', 'A61M2021/0044']"
US10956817B2,Unsupervised domain adaptation with similarity learning for images,Systems and methods for addressing the cross domain issue using a similarity based classifier convolutional neural network. An input image is passed through a convolutional neural network that extracts its features. These features are compared to features of multiple sets of prototype representations with each set of prototype representations being extracted from and representing a category of images. The similarity between the features of the input image and features of the various prototype representations is scored and the prototype representation whose features are most similar to the features of the input image will have its label applied to the input image. The classifier is trained using images from a source domain and the input images are from a target domain. The training for the classifier is such that the classifier will be unable to determine if a specific data point is from the source domain or from the target domain.,"['G06N3/08', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0895', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06N5/046', 'G06T3/40', 'G06T7/0002', 'G06T2207/20081']"
AU2023206202A1,Risk identification and risk register generation system and engine,"The present invention relates to a computer-based system for generating a risk register relating to a named entity. The system comprises a computing device, a risk database accessible by the computing device and having stored therein a set of risk types based on an induced taxonomy of risk types previously derived at least in part upon operation of a machine learning module, an input adapted to receive a set of source data, the set of source data being in electronic form and representing textual content comprising potential risk phrases, a entity-risk relation classifier adapted to identify and extract entity-risk relations from the set of source data, a risk tagger adapted to identify in the set of source data a set of risk candidates (ri) based on the set of risk types, a entity tagger adapted to identify mentions of entity names (ci) in the set of source data, and a risk register aggregator adapted to generate a first risk register based on the set of tuples associated with a first entity.","['G06Q10/0635', 'G06F16/2246', 'G06N20/00', 'G06N20/10', 'G06N5/025']"
CN111915526B,Photographing method of low-illumination image enhancement algorithm based on brightness attention mechanism,"The invention belongs to the technical field of image processing, and discloses a photographing method of a low-illumination image enhancement algorithm based on a brightness attention mechanism, wherein the low-illumination image enhancement algorithm is embedded into a camera, a low-illumination image enhancement mode is programmed in a program of a camera, photographing is carried out by utilizing the low-illumination image enhancement mode of the camera, and a low-illumination image enhancement network enhancement image result based on a brightness attention generation countermeasure network is directly applied; or the image capturing device is used for capturing the low-illumination image, the low-illumination image enhancement network based on the brightness attention generation countermeasure network is used for enhancing the captured image, and the enhanced captured image is obtained. The invention introduces a brightness attention mechanism, improves the picture perception quality of the enhanced image, improves the enhancement efficiency, and further introduces the field of scientific photography, thereby forming the application capable of solving the problem in the scientific photography.","['G06T5/90', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T2207/20081', 'G06T2207/20084']"
US20230347564A1,Computer-implemented method for controlling and/or monitoring at least one injection molding process,Disclosed herein is a computer-implemented method for controlling and/or monitoring at least one injection molding process in at least one injection molding machine. The method includes:,"['B29C45/766', 'B29C45/7693', 'B29C45/77', 'B29C45/78', 'G06F30/10', 'G06N20/00', 'G06N3/08', 'B29C2945/76006', 'B29C2945/7604', 'B29C2945/76451', 'B29C2945/76498', 'B29C2945/76531', 'B29C2945/76595', 'B29C2945/76936', 'B29C2945/76943', 'B29C2945/76949', 'B29C2945/76973']"
AU2019264603B2,Method and system for information extraction from document images using conversational interface and database querying,"Various methods are using SQL based data extraction for extracting relevant information from images. These are rule based methods of generating SQL-Query from NL, if any new English sentences are to be handled then manual intervention is required. Further becomes difficult for non-technical user. A system and method for extracting relevant from the images using a conversational interface and database querying have been provided. The system eliminates noisy effects, identifying the type of documents and detect various entities for diagrams. Further a schema is designed which allows an easy to understand abstraction of the entities detected by the deep vision models and the relationships between them. Relevant information and fields can then be extracted from the document by writing SQL queries on top of the relationship tables. A natural language based interface is added so that a non-technical user, specifying the queries in natural language, can fetch the information effortlessly. 24 100 Inpdut Noise removing module 108 HTR + Document identifier - 110 102 Engine OCR Engine 112 lx , 114 124 Schema designing module - 1 104 Storing module -- 116 Conversational interface -118 106 Conversion module 120 Database querying module 126 Database Intent identifier 128 FIG. 1","['G06F16/93', 'G06V30/412', 'G06F16/2433', 'G06F16/24522', 'G06F16/2455', 'G06F16/284', 'G06F18/217', 'G06F40/295', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T5/70', 'G06V10/22', 'G06V30/413', 'G06V30/10']"
KR102393095B1,"A system for predicting and diagnosing malfunctions in rotating equipment based on artificial intelligence using vibration, sound, and image data","According to an embodiment of the present invention, a system for predicting and diagnosing failures in a rotating facility based on artificial intelligence comprises: a sensor data collection unit for collecting vibration and sound through a plurality of sensors; a sensor data conversion unit for converting the vibration and sound data collected through the sensor data collection unit; a feature extraction unit for extracting features of sensor data including the vibration and the sound converted through the sensor data conversion unit; a data learning unit for extracting normal/failure features through the feature extraction unit, and learning data using a convolutional neural network (CNN); and a failure cause diagnosis unit for diagnosing and predicting the cause of failure by comparing the sensor data with the data learned through the data learning unit. The present invention can precisely monitor the cause of failure for each type of each facility and provide a diagnosis result.","['G05B23/0283', 'G05B23/0221', 'G05B23/0243', 'G06N20/00']"
US11961620B2,Method and apparatus for determining health status,"A system and method for monitoring the state of an individual. The method includes providing a stimulus to the individual, measuring a response to the provided stimulus, comparing the measured response to an expected response, and diagnosing one or more aspects of disease in accordance with the result of the comparison between the measured response and the expected response. The stimulus may be a predetermined test sequence, such as a visually displayed predetermined sequence of images, or may include observation of the physical response of the individual while performing one or more predetermined activities. Stored images or video of the individual responding to one or more test sequences may be stored in a lossy or lossless state, and thus security and de-identification may be provided to stored data. This stored data may also be de-identified in a manner to allow for the answering of the greatest number of future questions.","['G16H50/30', 'A61B5/0077', 'A61B5/0205', 'A61B5/1118', 'A61B5/4833', 'A61B5/68', 'A61B5/7267', 'G16H10/60', 'G16H20/00', 'G16H50/20', 'A61B2562/0219', 'A61B5/0022', 'A61B5/0035', 'A61B5/162', 'A61B5/163', 'A61B5/165']"
US12116015B2,Automatic annotation of object trajectories in multiple dimensions,"Techniques for improving the performance of an autonomous vehicle (AV) by automatically annotating objects surrounding the AV are described herein. A system can obtain sensor data from a sensor coupled to the AV and generate an initial object trajectory for an object using the sensor data. Additionally, the system can determine a fixed value for the object size of the object based on the initial object trajectory. Moreover, the system can generate an updated initial object trajectory, wherein the object size corresponds to the fixed value. Furthermore, the system can determine, based on the sensor data and the updated initial object trajectory, a refined object trajectory. Subsequently, the system can generate a multi-dimensional label for the object based on the refined object trajectory. A motion plan for controlling the AV can be generated based on the multi-dimensional label.","['B60W60/0027', 'B60W60/00274', 'G05D1/0221', 'G05D1/0231', 'G05D1/249', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'B60W2554/4026', 'B60W2554/4029', 'B60W2554/4041', 'B60W2554/4044', 'B60W2554/4045', 'B60W2556/45', 'G06N3/045', 'G06N3/084']"
US11446009B2,Clinical workflow to diagnose heart disease based on cardiac biomarker measurements and AI recognition of 2D and doppler modality echocardiogram images,"An automated workflow receives a patient study comprising cardiac biomarker measurements and a plurality of echocardiographic images taken by an ultrasound device of a patient heart. A filter separates the plurality of echocardiogram images by 2D images and Doppler modality images based on analyzing image metadata. The 2D images are classified by view type, and the Doppler modality images are classified by view type. The cardiac chambers are segmented in the 2D images, and the Doppler modality images are segmented to generate waveform traces, producing segmented 2D images and segmented Doppler modality images. Using both the sets of images, measurements of cardiac features for both left and right sides of the heart are calculated. The cardiac biomarker measurements and the calculated measurements are compared with international cardiac guidelines to generate conclusions, and a report is output showing the measurements that fall within or outside of the guidelines.","['A61B8/5207', 'G06N3/08', 'A61B8/06', 'A61B8/0833', 'A61B8/0883', 'A61B8/462', 'A61B8/465', 'A61B8/466', 'A61B8/468', 'A61B8/469', 'A61B8/481', 'A61B8/486', 'A61B8/488', 'A61B8/5223', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G06T7/0012', 'G06T7/11', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'G16H70/20', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/10132', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30104']"
US11132441B2,Systems and methods for inhibiting threats to a computing environment,"Novel hardware-based frameworks and methods for the detection and inhibition or prevention of insider threats utilizing machine learning methods and data collection done at the physical layer are provided. Analysis is done on unknown USB-powered devices, such as a keyboard or mouse, introduced to a computing environment and, through the utilization of machine learning, the behavior of the unknown device is determined before it can potentially cause harm to the computing environment.","['G06N20/10', 'G06F21/55', 'G06F21/6218', 'G06F21/85', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G06N5/04', 'G06N7/01', 'G06F2221/034']"
US11410401B2,Beautification techniques for 3D data in a messaging system,"The subject technology receives a selection of a selectable graphical item from a plurality of selectable graphical items, the selectable graphical item comprising an augmented reality content generator for applying a 3D effect, the 3D effect including at least one beautification operation. The subject technology captures image data and depth data using a camera. The subject technology applies, to the image data and the depth data, the 3D effect including the at least one beautification operation based at least in part on the augmented reality content generator, the beautification operation being performed as part of applying the 3D effect. The subject technology generates a 3D message based at least in part on the applied 3D effect including the at least one beautification operation. The subject technology renders a view of the 3D message based at least in part on the applied 3D effect including the at least one beautification operation.","['G06T19/006', 'G06T19/20', 'G06F3/04842', 'G06F3/04883', 'G06N20/00', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06T15/50', 'G06T7/507', 'G06V40/161', 'G06V40/166', 'G06V40/171', 'G06N3/045', 'G06T2200/24', 'G06T2219/2012', 'G06T2219/2024']"
US12067707B2,Multimodal safety systems and methods,"Multimodal systems are provided for managing safety in an industrial environment. The system comprises: (a) a computer vision component for generating a first output data; (b) a real-time locating component for generating a second output data about an object within the industrial environment and a mobile tag device deployed to the object; (c) a LIDAR component for generating a third output data; and (d) an edge computing device connected to the computer vision component, the real-time locating component and the LIDAR component via a local network, and is configured to: (i) receive a data stream including the first output data, the second output data and the third output data, (ii) process the data stream using a machine learning algorithm trained model to generate a safety related result and feedback data, and (iii) deliver the feedback data to the object via the mobile tag device.","['G06T7/0004', 'G01P13/00', 'G01S17/42', 'G01S17/86', 'G01S17/894', 'G01S7/4865', 'G06V20/52', 'G08B21/02', 'G08B21/043', 'G08B21/0446', 'G08B21/0453', 'G08B21/0476', 'G08B21/0492', 'G08B29/186', 'G08B31/00', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/30108']"
WO2021174723A1,"Training sample expansion method and apparatus, electronic device, and storage medium","A training sample expansion method and apparatus, an electronic device, and a storage medium. The method comprises: determining, when the number of the samples of target disease types is less than a preset quantity threshold value, the samples as target samples; performing vector conversion on a disease name corresponding to each target sample so as to obtain a name vector; according to a pre-trained first disease classification model, based on the precision of the first disease classification model and the gradient change of a discrimination network, training a generation network to obtain a trained generation model; inputting the name vector into the trained generation model so as to obtain a generation sample data set; and if a plurality of generation samples in the generation sample data set may be used for model training, determining a real sample data set and the generation sample data set as a first training sample data set of an auxiliary diagnosis model. The method can expand the number of training samples, and improve the accuracy of the auxiliary diagnosis model.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/084', 'Y02A90/10']"
CN112307921B,Vehicle-mounted end multi-target identification tracking prediction method,"The invention discloses a vehicle-mounted end Multi-target recognition Tracking prediction method, which is based on a vehicle-mounted end Multi-target recognition Tracking prediction method fusing YOLOv5s (You Only Look Oncce v5 s) and FairMOT (Fair Multi-Object Tracking), and is characterized in that a YOLOv5s deep learning Object detection technology is used for rapidly, accurately and real-timely detecting vehicles, pedestrians, obstacles and the like in front of a road, and a YOLOv5s model is fused into a FairMOT framework detection module for carrying out target detection and re-recognition Tracking in a single network, so that the position detection, the type recognition and the Multi-target motion track Tracking of a traffic target in front of a vehicle on the road are realized, and the prediction of driving behaviors of lane changing, driving, deceleration and the like of the traffic target in front of the vehicle is realized.","['G06V20/56', 'G06N3/045', 'G06N5/04', 'G06T5/50', 'G06V40/103', 'G06T2207/20081', 'G06T2207/30252', 'Y02T10/40']"
CN115326783B,"Raman spectrum preprocessing model generation method, system, terminal and storage medium","The invention relates to a method, a system, a terminal and a storage medium for generating a Raman spectrum preprocessing model, which are characterized in that noise, a baseline background signal and a Raman peak in a real Raman spectrum library are extracted and built, raman characteristic peaks in the Raman peak library are freely combined to generate an ideal spectrum library without noise and the baseline background signal, the extracted noise and the baseline background signal are superposed on the ideal spectrum library to generate a reference spectrum library, the ideal spectrum library and a random Gaussian noise input generator generate a simulation spectrum library, a discriminator and the generator form countertraining, and a high-simulation Raman spectrum library conforming to the real Raman spectrum characteristic is generated after the training is finished; training a spectrum preprocessing model based on an automatic supervision algorithm by using the library so as to complete automatic parameter setting; the ideal spectrum library is used as a label for model training, the model can be directly used for processing the actually acquired spectrum after the training is finished, the use is simple and quick, the effect of denoising and baseline background removing is good, and the spectrum is high in fidelity.","['G01N21/65', 'G01N21/658', 'G06F30/27']"
CN109785258B,Face image restoration method based on multi-discriminator generated countermeasure network,"The invention discloses a face image restoration method based on a multi-discriminator generation countermeasure network, which comprises the following steps: (1) Preprocessing images in a public human face image database, and inputting the images into a generator to obtain a generated image; (2) Inputting the real image and the generated image into a plurality of discriminators to obtain feedback values; (3) Taking the feedback values of the plurality of discriminators as countermeasure loss, and generating the countermeasure network by combining the perception loss and the reconstruction loss; (4) And inputting the missing face image into a trained generator to obtain a repaired face image. Aiming at the problem of repairing the shielded or damaged face image, the generation countermeasure network structure with multiple discriminators is adopted, so that the problem of low true degree of the repaired image is solved, and the repaired image is more natural and more true.",[]
US11468164B2,"Dynamic, resilient virtual sensing system and shadow controller for cyber-attack neutralization","An industrial asset may have monitoring nodes (e.g., sensor or actuator nodes) that generate current monitoring node values. An abnormality detection and localization computer may receive the series of current monitoring node values and output an indication of at least one abnormal monitoring node that is currently being attacked or experiencing a fault. An actor-critic platform may tune a dynamic, resilient state estimator for a sensor node and output tuning parameters for a controller that improve operation of the industrial asset during the current attack or fault. The actor-critic platform may include, for example, a dynamic, resilient state estimator, an actor model, and a critic model. According to some embodiments, a value function of the critic model is updated for each action of the actor model and each action of the actor model is evaluated by the critic model to update a policy of the actor-critic platform.","['G06F21/552', 'G05B13/027', 'G05B13/042', 'G05B13/048', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/0455', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/092', 'G06N3/094', 'G06N7/01', 'G06F2221/034', 'Y04S40/20']"
CN110007347B,Deep learning seismic data denoising method,"The invention discloses a deep learning seismic data denoising method, which aims to solve the problems that the traditional shallow linear structure feature extraction capability is limited, and the existing seismic data denoising model based on deep learning has slow convergence, long and weak training time and the like. A residual convolution self-coding block composed of a residual block, a batch normalization layer and a self-coder is used as a basic denoising network structure, and a multifunctional denoising residual convolution self-coding neural network is provided. The seismic data denoising method disclosed by the invention can maintain higher denoising quality and denoising precision while occupying less resources and rapidly converging.","['G01V1/36', 'G06N3/045', 'G01V2210/32']"
EP4152797A1,Information processing method and related device,"Embodiments of this application disclose an information processing method and a related device. Embodiments of this application provide a first AI entity in an access network, and define a plurality of basic interaction modes between the first AI entity and a terminal device. In an interaction mode, the first AI entity may receive second AI model information sent by the terminal device. The second AI model information does not include user data of the terminal device. The first AI entity may update first AI model information of the first AI entity based on the second AI model information, and then send updated first AI model information to the terminal device, so that the terminal device trains and updates the second AI model information. It can be learned that the first AI entity in the access network applies an AI technology to a radio access network. This helps improve a processing capability of the radio access network.","['G06F18/295', 'H04W24/02', 'G06F18/214', 'G06F18/217', 'G06N7/01', 'H04W48/14']"
US12322198B2,Text based image search,"Method and system for building a machine learning model for finding visual targets from text queries, the method comprising the steps of receiving a set of training data comprising text attribute labelled images, wherein each image has more than one text attribute label. Receiving a first vector space comprising a mapping of words, the mapping defining relationships between words. Generating a visual feature vector space by grouping images of the set of training data having similar attribute labels. Mapping each attribute label within the training data set on to the first vector space to form a second vector space. Fusing the visual feature vector space and the second vector space to form a third vector space. Generating a similarity matching model from the third vector space.","['G06N3/08', 'G06V30/413', 'G06N20/00', 'G06V10/454', 'G06V10/76']"
US12306877B2,Multi-modal virtual experiences of distributed content,"Systems and techniques are described herein for providing a beholder, via a user interface on a user experience device, with a multi-faceted and flexibly-dimensional virtual experience of one or more target identities placed in a subject matter context. A system's aspects include selecting, finding, and interpreting digital content pertaining to a subject matter context indicated by the beholder; deconstructing digital content into discrete content elements containing content segments that are classified according to a schema of element facets, and then constructing a facet-segmented repository of discrete content elements pertaining to a target identity; supplementing existing digital content with supplemental information and content to support the presentation of expanded information content, dimensions, or sensory capabilities; and creating and presenting a virtual experience container that is adapted to the beholder and the capabilities of the beholder's user experience device.","['G06F16/9035', 'G06F16/335', 'G02B30/52', 'G06F16/211', 'G06F16/27', 'G06F16/9038', 'G06F3/011', 'G06F3/017', 'G06N3/0442', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/09', 'H04N13/395', 'G06F2203/011']"
US10990852B1,Method and apparatus for training model for object classification and detection,"A method of training a model for object classification and detection includes training a first classification model including a shared feature extractor shared by classification models and a first classifier for outputting a result of an object in a first input image based on feature values of the first input image, training a second classification model including the shared feature extractor and a second classifier for outputting a result about authenticity of a second input image based on feature values of the second input image, and training a third classification model including the shared feature extractor and a third classifier for outputting a classification result about a rotation angle of a third input image on the basis of feature values of the third input image extracted by the shared feature extractor, using a third training image set including images rotated at one or more angles.","['G06T7/11', 'G06K9/6257', 'G06V20/56', 'G06F18/2115', 'G06F18/2148', 'G06F18/2155', 'G06F18/24', 'G06F18/254', 'G06K9/3275', 'G06K9/6231', 'G06K9/6259', 'G06N3/08', 'G06T7/001', 'G06V10/7747', 'G06V10/809', 'G06K2209/21', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/07']"
US11227053B2,Malware management using I/O correlation coefficients,"A malware attack is detected in a computing system by monitoring file I/O and coordinated network I/O traffic and referencing criteria including a correlation coefficient calculated relative to the I/O. If the file I/O and coordinated network I/O was initiated by an executing process that meets criteria indicative of malware, a correlation coefficient is calculated with respect to the file I/O and coordinated network I/O. The executing process is identified as malware if a threshold criteria is met that considers the correlation coefficient.","['G06F21/552', 'G06F21/554', 'G06F21/566', 'G06N20/00', 'H04L63/1416', 'H04L63/145', 'G06F2221/033']"
US20230011621A1,Artifact Origination and Content Tokenization,"Devices can be configured to broadcast blocks incorporating artifact origination tokens. Devices can include network interfaces, memory; and processors. Processors can be configured to obtain artifact-to-time association elements. Artifact-to-time association elements can include artifact references and timestamps. Timestamps can include references to artifact references. Processors can be further configured to obtain artifact origination tokens. Artifact origination tokens can include artifact-to-time association element, certifier descriptors indicating certifier public keys, and/or certifier digital signatures. Certifier digital signatures can be generated based on certifier public keys and/or artifact-to-time association elements. Processors can be further configured to obtain ledger entries including artifact origination tokens with public keys, compute challenges based on ledger entries, and broadcast blocks incorporating the ledger entries. Blocks can be validated using cryptographic systems to obtain proof based challenges.","['H04L9/50', 'H04L9/3213', 'H04L9/30', 'H04L9/3247', 'H04L9/3297']"
US12394520B2,Systems and methods for operations and incident management,"The present disclosure provides methods and systems for managing safety and risk in a remote workplace. The method may comprise: collecting, via a local network, data stream from one or more sensors and a user device; transmitting the data stream to an edge computing device via the local network, wherein the data stream is stored in a local database; processing, at the edge computing device, the data stream to identify a hazardous condition and a health condition of a user associated with the user device; and automatically generating a dynamic geofencing area in the remote workplace base at least in part on the hazardous condition and the health condition.","['G16H40/63', 'G06N20/00', 'G16H40/67', 'G16H50/20', 'H04L67/12', 'H04L67/52', 'H04Q9/00', 'H04Q2209/43']"
CN112649198B,"Intelligent fault diagnosis method, system and equipment for quasi-unbalanced rolling bearing and application","The invention belongs to the technical field of intelligent fault diagnosis of mechanical equipment, and discloses an intelligent fault diagnosis method, system, equipment and application of an unbalanced-like rolling bearing, wherein a vibration signal of the rolling bearing is collected, zscore standardization is carried out on an original signal, and a mobile time window is utilized for signal segmentation; constructing a generator and a discriminator combined condition to generate a confrontation network CGAN; generating an antagonistic network for the established conditions, optimizing network parameters in a cyclic antagonistic training mode until the training is finished, and directionally generating a sample of a category with less data volume by a generator to enhance the data of the training set so as to relieve the category imbalance phenomenon of the original data set; constructing a fault diagnosis model based on a deep convolutional neural network; and training the established fault diagnosis model by using the training data set optimized by the CGAN to realize intelligent diagnosis of the unknown label sample. The invention can enhance the reliability of the rolling bearing state identification, and has low cost, simplicity and practicability.","['G01M13/045', 'G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06F2218/08', 'G06F2218/12']"
US11741372B2,Prediction-correction approach to zero shot learning,"Approaches to zero-shot learning include partitioning training data into first and second sets according to classes assigned to the training data, training a prediction module based on the first set to predict a cluster center based on a class label, training a correction module based on the second set and each of the class labels in the first set to generate a correction to a cluster center predicted by the prediction module, presenting a new class label for a new class to the prediction module to predict a new cluster center, presenting the new class label, the predicted new cluster center, and each of the class labels in the first set to the correction module to generate a correction for the predicted new cluster center, augmenting a classifier based on the corrected cluster center for the new class, and classifying input data into the new class using the classifier.","['G06N3/088', 'G06F16/55', 'G06F16/906', 'G06F18/217', 'G06F18/24137', 'G06F18/256', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G06V10/764', 'G06V10/776', 'G06V10/811', 'G06V10/82']"
US12056915B2,"Method for generating defective image, electronic device using the same","A method for generating defective image of products applied in an electronic device includes generating first input data according to flawless sample images and a first noise vector, using an autoencoder as a generator of a Generative Adversarial Network (GAN), inputting the first input data to the generator, and generating images for training in defects. The method further includes calculating a first loss value between the flawless sample images and the defect training images, inputting the defect training images into a discriminator of the GAN, and calculating a second loss value. The method further includes obtaining an optimized GAN and taking the optimized GAN as a defective image adversarial network, obtaining flawless testing images, inputting the flawless testing images and a second noise into a generator of the defective image adversarial network, and generating images of defects by processing the flawless testing images and the second noise.","['G06T7/0004', 'G06F18/214', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/094', 'G06T11/00', 'G06T7/001', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30148']"
US12373668B2,"Methods, systems and non-transitory computer readable media for automated design of molecules with desired properties using artificial intelligence","The subject matter described herein includes computational methods, systems and non-transitory computer readable media for de-novo drug discovery, which is based on deep learning and reinforcement learning techniques. The subject matter described herein allows generating chemical compounds with desired properties. Two deep neural networks-generative and predictive, represent the general workflow. The process of training consists of two stages. During the first stage, both models are trained separately with supervised learning algorithms, and during the second stage, models are trained jointly with reinforcement learning approach. In this study, we conduct a computational experiment, which demonstrates the efficiency of proposed strategy to maximize, minimize or impose a desired range to a property. We also thoroughly evaluate our models with quantitative approaches and provide visualization and interpretation of internal representation vectors for both predictive and generative models.","['G16C20/50', 'G06N3/006', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/092', 'G06N20/00', 'G06N3/048', 'G16C20/62', 'G16C20/70']"
US20240119934A1,Systems and methods for recognizing a speech of a speaker,"Systems, methods, and computer readable media comprising instructions executable by a processor, for recognizing speech within a received audio signal segment the audio signal to isolate the speech based on a speaker audio profile, determine from the audio signal a command, a first score reflecting confidence in determining the command, and a second score reflecting a potential error in determining the command, and cause the command to be executed if the first score is above a first threshold value and the second score is below a second threshold value.","['G10L15/22', 'G06N3/08', 'G10L13/00', 'G10L15/04', 'G10L15/16', 'G10L15/24', 'G10L15/30', 'G10L25/90', 'G10L17/00', 'G10L2015/223', 'G10L25/30', 'G10L25/84']"
US12051080B2,Virtual environment-based interfaces applied to selected objects from video,"A method and system for virtual environment-based interfaces applied to selected objects from video directs a system's focus of attention to an image within a first video stream and identifies an object in the image by applying a trained neural network. In response to a communication from a user comprising language and/or images describing a virtual environment, a second trained neural network is applied to generate a second video stream that embodies the identified object within a virtual environment that is in accordance with the user-described virtual environment. The second video stream is then delivered to the user. The system's focus of attention and/or generation of the virtual environment may be informed by user preferences that are inferred from user behaviors.","['G06V10/774', 'G06Q30/02', 'G06N20/00', 'G06N3/02', 'G06N3/043', 'G06N3/0464', 'G06N3/0475', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06N5/02', 'G06N7/023', 'G06Q30/0241', 'G06Q30/0261', 'G06Q30/0273', 'G06T19/006', 'G06V10/7788', 'G06V10/82', 'G06V20/20', 'G06V20/40', 'G06V20/41', 'G09B5/065', 'G06N3/045', 'G06N3/047', 'G06N5/04', 'G06V10/255', 'G06V10/422']"
US11790534B2,Attention-based joint image and feature adaptive semantic segmentation method,"The invention discloses an attention-based joint image and feature adaptive semantic segmentation method. First, the image adaptation procedure is used to transform the source domain image Xs to a target-domain-like image Xs-t with an appearance similar with the target domain image Xt, to reduce the domain gap between the source domain and the target domain at the image appearance level; then using the feature adaptation procedure to align the features between Xs-t and Xt in the semantic prediction space and the image generation space, respectively, to extract the domain-invariant features, to reduce the domain difference between Xs-t and Xt. In addition, the present invention introduces an attention module in the feature adaptation procedure to help the feature adaptation procedure pay more attention to image regions worthy of attention. Finally, combining the image adaptation procedure and the feature adaptation procedure in the end-to-end manner. The present invention effectively solves the problem of domain gap existing in the cross-modal image semantic segmentation, improves the performance of the semantic segmentation model, and achieves the optimal effect in multiple public data sets.","['G06V10/267', 'G06T7/174', 'G06F18/24', 'G06N3/045', 'G06N3/084', 'G06T1/20', 'G06T7/11', 'G06V10/462', 'G06V10/764', 'G06V10/774', 'G06V10/778', 'G06V10/82', 'G06T2207/20004', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
US11723568B2,Mental state monitoring system,"A system predicts the mental state of a user using a variety of contact or contactless sensors that measure heart rate, breathing or other data of the user. The mental state may be flow, overload, underload, stress, attention, motivation, valence, arousal, etc. While performing a game-playing task the difficulty of the task is adjusted based upon the predicted mental state of the user. A classifier for classifying a mental state is trained using event marking and ground truth data. Computer usage generates event markers. Game playing is used to simulate a mental state. Interruptions of a user are prevented when the user enters a flow, focused, or effortful attention state by classifying that state and indicating physically or electronically that the user should not be interrupted. Interruptions of a user are also prevented when the user enters a mind wandering state by classifying or predicting that state and indicating physically or electronically that the user should not be interrupted. A cost of interrupting is calculated and displayed. Users may also be coached regarding mental state. Advertisements to the user may vary based upon a classified mental state of the user.","['A61B5/165', 'G16H20/70', 'A61B5/0205', 'A61B5/02405', 'A61B5/0816', 'A61B5/11', 'A61B5/163', 'A61B5/377', 'A61B5/7267', 'A61B5/7282', 'G16H40/63', 'G16H50/20', 'A61B2503/24', 'A61B3/112', 'A61B3/113', 'G16H10/60']"
US11869170B2,Generating super-resolution images using neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes receiving a training image and a ground truth super-resolution image; processing a first training network input comprising the training image using the neural network to generate a first training super-resolution image; processing a first critic input generated from (i) the training image and (ii) the ground truth super-resolution image using a critic neural network to map the first critic input to a latent representation; processing a second critic input generated from (i) the training image and (ii) the first training super-resolution image using the critic neural network to map the second critic input to a latent representation; determining a gradient of a generator loss function that measures a distance between the latent representations of the critic inputs; and determining an update to the parameters.","['G06T3/4046', 'G06F18/22', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06N3/094', 'G06T3/4053', 'G06T5/50', 'G06T2207/20081', 'G06T2207/20084']"
US11417057B2,Realistic 3D virtual world creation and simulation for training automated driving systems,"A computer implemented method of creating a simulated realistic virtual model of a geographical area for training an autonomous driving system, comprising obtaining geographic map data of a geographical area, obtaining visual imagery data of the geographical area, classifying static objects identified in the visual imagery data to corresponding labels to designate labeled objects, superimposing the labeled objects over the geographic map data, generating a virtual 3D realistic model emulating the geographical area by synthesizing a corresponding visual texture for each of the labeled objects and injecting synthetic 3D imaging feed of the realistic model to imaging sensor(s) input(s) of the autonomous driving system controlling movement of an emulated vehicle in the realistic model where the synthetic 3D imaging feed is generated to depict the realistic model from a point of view of emulated imaging sensor(s) mounted on the emulated vehicle.","['G06T17/05', 'G01C11/04', 'G01C21/3815', 'G01C21/3826', 'G01C21/3867', 'G05D1/0088', 'G05D1/0221', 'G05D1/81', 'G06F30/20', 'G06T19/006', 'G05D2201/0213']"
US10819724B2,Systems and methods for cyberbot network detection,"There is provided a neural network system for detection of domain generation algorithm generated domain names, the neural network system comprising: an input receiver configured for receiving domain names from one or more input sources; a convolutional neural network unit including one or more convolutional layers, the convolutional unit configured for receiving the input text and processing the input text through the one or more convolutional layers; a recurrent neural network unit including one or more long short term memory layers, the recurrent neural network unit configured to process the output from the convolutional neural network unit to perform pattern recognition; and a classification unit including one or more classification layers, the classification unit configured to receive output data from the recurrent neural network unit to perform a determination of whether the input text or portions of the input text are DGA-generated or benign domain names.","['H04L63/1425', 'G06F18/24', 'G06F40/126', 'G06K9/6267', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'H04L61/3025', 'H04L63/1441', 'H04L2463/144', 'H04L61/1511', 'H04L61/4511']"
US11586854B2,Devices and methods for accurately identifying objects in a vehicle's environment,Vehicle navigation control systems in autonomous driving rely on accurate predictions of objects within the vicinity of the vehicle to appropriately control the vehicle safely through its surrounding environment. Accordingly this disclosure provides methods and devices which implement mechanisms for obtaining contextual variables of the vehicle's environment for use in determining the accuracy of predictions of objects within the vehicle's environment.,"['G06N20/00', 'G06K9/6265', 'G06V20/58', 'B60W60/0016', 'G05B13/027', 'G05B13/048', 'G05D1/0088', 'G05D1/0214', 'G05D1/0221', 'G06F18/2148', 'G06F18/2193', 'G06K9/6257', 'G06N3/0464', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/091', 'G06N7/01', 'G06V10/774', 'G06V10/7784', 'G06V10/7788', 'G06V10/82', 'G06V20/20', 'G06V20/70', 'G06V40/103', 'G05B2219/21002', 'G05B2219/32335', 'G05B2219/33027', 'G05B2219/39271', 'G05D2201/0213', 'G06F18/24155', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N5/01']"
US10998101B1,Health management,A method includes capturing continuously vital signs and motion data from one or more sensors adapted to be coupled to a user; capturing food consumption of the user; predicting a predetermined health condition of the user based on the vital signs; generating a plan for the predetermined health condition; and prompting the user to execute the plan with a closed-loop feedback based on sensor data.,"['G06Q50/01', 'A61B5/0205', 'A61B5/1118', 'A61B5/14532', 'A61B5/4836', 'A61B5/486', 'A61B5/4866', 'A61B5/7267', 'A61B5/7275', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06N3/098', 'G16H10/60', 'G16H20/30', 'G16H20/60', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'A61B5/021', 'A61B5/0537', 'G06N3/045', 'G06N7/01']"
