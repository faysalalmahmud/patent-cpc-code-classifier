publication_number,title,abstract,cpc_codes
US12242969B2,Graph diffusion for structured pruning of neural networks,"An apparatus includes at least one processor; and at least one non-transitory memory including computer program code; wherein the at least one memory and the computer program code are configured to, with the at least one processor, cause the apparatus at least to: estimate an importance of parameters of a neural network based on a graph diffusion process over at least one layer of the neural network; determine the parameters of the neural network that are suitable for pruning or sparsification; remove neurons of the neural network to prune or sparsify the neural network; and provide at least one syntax element for signaling the pruned or sparsified neural network over a communication channel, wherein the at least one syntax element comprises at least one neural network representation syntax element.","['G06N3/082', 'G06N3/04', 'G06N3/0495', 'H03M7/3059', 'H03M7/3066', 'H03M7/3068']"
US12395641B2,Hybrid neural network based end-to-end image and video coding method,"Improved neural-network-based image and video coding techniques are presented, including hybrid techniques that include both tools of a host codec and neural-network-based tools. In these improved techniques, the host coding tools may include conventional video coding standards such H.266 (VVC). In an aspects, source frames may be partitioned and either host or neural-network-based tools may be selected per partition. Coding parameter decisions for a partition may be constrained based on the partitioning and coding tool selection. Rate control for host and neural network tools may be combined. Multi-stage processing of neural network output may use a checkerboard prediction pattern.","['H04N19/147', 'H04N19/119', 'H04N19/124', 'H04N19/172', 'H04N19/176', 'H04N19/186', 'H04N19/42', 'H04N19/60', 'H04N19/70', 'H04N19/91']"
US20220067527A1,Neural network compression,"A neural network model is trained, where the training includes multiple training iterations. Weights of a particular layer of the neural network are pruned during a forward pass of a particular one of the training iterations. During the same forward pass of the particular training iteration, values of weights of the particular layer are quantized to determine a quantized-sparsified subset of weights for the particular layer. A compressed version of the neural network model is generated from the training based at least in part on the quantized-sparsified subset of weights.","['G06N3/082', 'G06N3/045', 'G06N3/047', 'G06N3/0472', 'G06N3/048', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'H03M7/702', 'G06N3/044']"
US11295423B2,Unsupervised training of neural network for high dynamic range image compression,"Techniques are provided for unsupervised training of a neural network to perform compression of a high dynamic range (HDR) image. A methodology implementing the techniques according to an embodiment includes performing global tone mapping on an HDR training image to generate a low dynamic range (LDR) training image. The method also includes applying the neural network to the HDR training image and the LDR training image to generate a delta image representing image detail lost in the global tone mapping operation. The method further includes summing the delta image with the LDR training image to generate an output training image, and generating a loss function calculated from a weighted sum of a contrast loss and a compression loss. The contrast loss is based on the output training image and the HDR training image, and the compression loss is based on the output training image and the LDR training image.","['G06T5/90', 'G06T5/92', 'G06T5/009', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06T5/50', 'G06T9/002', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US20200272905A1,Artificial neural network compression via iterative hybrid reinforcement learning approach,"Systems and computer-implemented methods for facilitating automated compression of artificial neural networks using an iterative hybrid reinforcement learning approach are provided. In various embodiments, a compression architecture can receive as input an original neural network to be compressed. The architecture can perform one or more compression actions to compress the original neural network into a compressed neural network. The architecture can then generate a reward signal quantifying how well the original neural network was compressed. In (α)-proportion of compression iterations/episodes, where α∈[0,1], the reward signal can be computed in model-free fashion based on a compression ratio and accuracy ratio of the compressed neural network. In (1−α)-proportion of compression iterations/episodes, the reward signal can be predicted in model-based fashion using a compression model learned/trained on the reward signals computed in model-free fashion. This hybrid model-free-and-model-based architecture can greatly reduce convergence time without sacrificing substantial accuracy.","['G06N3/082', 'G06N3/006', 'G06N3/045', 'G06N3/088', 'G06N7/01', 'H03M7/3059', 'H03M7/3073', 'H03M7/70', 'H03M7/702', 'G06N3/084']"
WO2020233130A1,Deep neural network compression method and related device,"A deep neural network compression method and apparatus, a device and a computer-readable medium, relating to the technical field of computers. By means of an adaptive decomposition rank algorithm based on a tensor train decomposition algorithm, a parameter matrix of each layer in a deep neural network model is decomposed layer by layer according to a set network precision threshold during a network training process, and other network layers are fixed while decomposition; the decomposition rank of the current network layer is adjusted in order, and retraining is performed to restore the precision; the current rank is determined as the decomposition rank of the selected network layer after the precision reaches the precision threshold. The complexity and uncertainty problems in manual determination of the decomposition rank are solved, and the compression effect of the neural network model is achieved by compressing the parameter matrices.","['G06N3/045', 'G06N3/08']"
CN107944555B,"Neural network compression and acceleration method, storage device and terminal","The invention provides a neural network compression and acceleration method, a storage device and a terminal, wherein the method comprises the following steps: pruning the original neural network; clustering and quantifying the network weight of the pruned original neural network, and training the clustered and quantified original neural network to obtain a target neural network; storing the target neural network by adopting a sparse matrix; converting the input feature map into an input matrix; and multiplying the sparse matrix and the input matrix to obtain an output characteristic diagram corresponding to the input characteristic diagram. This embodiment reduces neural network computational resources and memory space, thereby reducing computational costs.","['G06N3/082', 'G06F18/2136', 'G06F18/23213', 'G06F18/24', 'G06T1/20']"
CN107679617B,Multi-iteration deep neural network compression method,"A method of compressing a neural network, wherein weights between individual neurons of the neural network are represented by a plurality of matrices, the method comprising: a sensitivity analysis step for analyzing the sensitivity of each matrix of the plurality of matrices and determining the initial compression ratio of each matrix; a compression step, which is used for compressing each matrix based on the initial compression ratio to obtain a compressed neural network; and a retraining step for retraining the compressed neural network. The invention also discloses a device for compressing the neural network.","['H04L63/10', 'G06N3/04', 'G10L15/063', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G10L15/16']"
CN111882040B,Convolutional Neural Network Compression Method Based on Channel Number Search,"The invention provides a convolutional neural network compression method based on channel number search, which comprises the following steps: firstly, selecting a target image data set for image recognition, and dividing the target image data set into a training set and a testing set; secondly, inputting the training set into a convolutional neural network for training, and outputting importance indexes of each channel corresponding to the convolutional neural network; then comparing the importance index value with a set threshold value, and discarding channels corresponding to the importance index lower than the threshold value to obtain an improved convolutional neural network; and finally, replacing the convolutional layer of the improved convolutional neural network by using the deep convolutional layer to obtain a lightweight network model, and inputting the test set into the lightweight network model to verify the identification performance of the lightweight network model. The invention combines the searching of the number of channels with the network convolution improving mode to construct the lightweight convolution neural network model, greatly reduces the parameters of the network model and improves the operation speed of the model.","['G06N3/045', 'G06F18/214', 'G06N3/082']"
CN110728361B,Deep neural network compression method based on reinforcement learning,"The invention discloses a deep neural network compression method based on reinforcement learning, which comprises the following steps of S100: training an reinforcement learning agent based on the trained convolutional neural network, wherein the reinforcement learning agent is used for identifying the network sparsity and compressing the model by adopting a compression method; step S200: and training the compressed model again, and optimizing the parameters of the model to obtain the final compressed model. The invention compresses the huge and complex deep neural network model, so that the compressed model can run on a platform with limited hardware resources, such as intelligent household equipment, and the like, compared with the original model, the compressed model not only greatly reduces the requirements on storage space and computation amount, but also keeps the performance of the model at the original level, is beneficial to realizing the wide application of an image recognition technology in daily life, and improves the convenience and safety of life.","['G06N3/045', 'G06F18/241', 'G06N3/082']"
US11763156B2,Neural network compression based on bank-balanced sparsity,"In embodiments of the present disclosure, there is provided an approach for neural network model compression based on bank-balanced sparsity. In embodiments of the present disclosure, a set of weight parameters, such as a weight matrix, in a neural network is divided into a plurality of equal-sized banks in terms of number of elements, and then all of the equal-sized banks are pruned at the same sparsity level. In this way, each pruned bank will have the same number of non-zero elements, which is suitable for hardware speedup. Moreover, since each bank is pruned independently in a fine granularity, the model accuracy can be ensured. Thus, according to embodiments of the present disclosure, the neural network compression method based on bank-balanced sparsity can achieve both high model accuracy and high hardware speedup.","['G06N3/082', 'G06N3/063', 'G06N3/044', 'G06N3/045']"
US11928601B2,Neural network compression,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for neural network compression. In one aspect, a method comprises receiving a neural network and identifying a particular set of multiple weights of the neural network. Multiple anchor points are determined based on current values of the particular set of weights of the neural network. The neural network is trained by, at each of multiple training iterations, performing operations comprising adjusting the values of the particular set of weights by backpropagating gradients of a loss function. The loss function comprises a first loss function term based on a prediction accuracy of the neural network and a second loss function term based on a similarity of the current values of the particular set of weights to the anchor points. After training, the values of the particular set of weights are quantized based on the anchor points.","['G06N3/084', 'G06N3/044', 'G06N3/08', 'G06N7/01', 'G06N20/00', 'G06N3/063']"
US11966837B2,Compression of deep neural networks,"In an approach for compressing a neural network, a processor receives a neural network, wherein the neural network has been trained on a set of training data. A processor receives a compression ratio. A processor compresses the neural network based on the compression ratio using an optimization model to solve for sparse weights. A processor re-trains the compressed neural network with the sparse weights. A processor outputs the re-trained neural network.","['H03M7/3059', 'G06N3/08', 'G06N3/047', 'G06N3/084', 'G06N5/01', 'H03M7/6047', 'H03M7/702', 'G06N3/044', 'G06N3/045', 'G06N3/063']"
US20250053814A1,Efficient neural networks with elaborate matrix structures in machine learning environments,"A mechanism is described for facilitating slimming of neural networks in machine learning environments. A method of embodiments, as described herein, includes learning a first neural network associated with machine learning processes to be performed by a processor of a computing device, where learning includes analyzing a plurality of channels associated with one or more layers of the first neural network. The method may further include computing a plurality of scaling factors to be associated with the plurality of channels such that each channel is assigned a scaling factor, wherein each scaling factor to indicate relevance of a corresponding channel within the first neural network. The method may further include pruning the first neural network into a second neural network by removing one or more channels of the plurality of channels having low relevance as indicated by one or more scaling factors of the plurality of scaling factors assigned to the one or more channels.","['G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06T1/20', 'G06N3/082', 'G06N7/046']"
CN109934285B,Deep learning-based image classification neural network compression model system,"The invention relates to the technical field of electronic information science and provides an image classification neural network compression model design based on deep learning. The deep neural network is difficult to train, and a large amount of memory is occupied in the training process, so that a simple, efficient and modular compression dual-channel network structure is provided. The network takes a dual-channel network as a backbone, introduces a computing unit for compressing network convolution, converts a trained network model into a DLC file loaded by SNPE, can select a quantized DLC file to run on a Hexagon DSP, prepares input picture data of the model, and loads and executes the model when the SNPE runs. The experiment was run through two baseline datasets: imagnet-1k and PASCAL VOC prove that the model and the calculation complexity can be effectively reduced while the performance is kept by a compressed double-channel network.",[]
CN111220958B,Radar target Doppler image classification and identification method based on one-dimensional convolutional neural network,"The invention relates to a radar target Doppler image classification recognition method based on a one-dimensional convolutional neural network, which comprises the steps of acquiring original echo data through radar equipment, obtaining each frame of data containing targets and clutter through pulse compression and moving target detection, extracting one-dimensional Doppler images in a distance unit where the targets are located according to Doppler differences of different targets, and forming a data set; designing a one-dimensional convolutional neural network model, and initializing model parameters; training the network through forward propagation and backward propagation processes, and calculating a loss function; and (3) performing iterative training until the loss function converges or reaches the maximum number of times, and obtaining the one-dimensional convolutional neural network model after the training is finished.","['G01S7/417', 'G06F18/241', 'G06N3/045', 'G06N3/084', 'Y02A90/10']"
US20220180199A1,"Neural network model compression method and apparatus, storage medium, and chip","This application provides a neural network model compression method in the field of artificial intelligence. The method includes: obtaining, by a server, a first neural network model and training data of the first neural network that are uploaded by user equipment; obtaining a PU classifier based on the training data of the first neural network and unlabeled data stored in the server; selecting, by using the PU classifier, extended data from the unlabeled data stored in the server, where the extended data has a property and distribution similar to a property and distribution of the training data of the first neural network model; and training a second neural network model by using a knowledge distillation (KD) method based on the extended data, where the first neural network model is used as a teacher network model and the second neural network model is used as a student network model.","['G06N3/084', 'G06N3/063', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454', 'G06V10/82', 'G06F18/214', 'G06F18/2415', 'G06K9/6256', 'G06N3/047']"
CN110880036B,"Neural network compression method, device, computer equipment and storage medium","The application relates to a neural network compression method, a device, computer equipment and a storage medium, and relates to the technical field of neural networks. The method comprises the following steps: respectively inputting training samples into a teacher network and a student network; acquiring first network data containing a first model parameter and a first feature map of an ith layer in a teacher network and second network data containing a second model parameter and a second feature map of the ith layer in a student network, performing cross calculation on the first network data and the second network data to obtain a loss function value, and updating the second model parameter of the ith layer in the student network according to the loss function value. According to the scheme, the accuracy of the compressed neural network can be improved under the condition that the trained neural network is compressed through a small amount of training data.","['G06N3/045', 'G06N3/082']"
US10834106B2,Network security event detection via normalized distance based clustering,"A method may include a processing system assigning samples of network traffic data to positions in a list, where each of the samples is assigned a cluster identifier corresponding to the respective position, and traversing the list, where for each position, the processing system: increments an order indicator, and when the cluster identifier is not less than the order indicator, computes a distance between a sample assigned to the position and other samples, records a cluster identifier of another sample when a distance between the sample and the other sample is less than a threshold distance, and assigns a minimum cluster identifier that is recorded to all of the samples with cluster identifiers that are recorded. The processing system may determine clusters from cluster identifiers in the list after the traversing and identify at least one cluster as representing anomalous network traffic data.","['G06N3/088', 'G06F18/21', 'G06F18/22', 'G06F18/23', 'G06K9/6215', 'G06K9/6218', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'H04L43/045', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'G06N3/084']"
US10936941B2,Efficient data access control device for neural network hardware acceleration system,"The technical disclosure relates to artificial neural network. In particular, the technical disclosure relates to how to implement efficient data access control in the neural network hardware acceleration system. Specifically, it proposes an overall design of a device that can process data receiving, bit-width transformation and data storing. By employing the technical disclosure, neural network hardware acceleration system can avoid the data access process becomes the bottleneck in neural network computation.","['G06N3/063', 'G06N3/045', 'G06N3/0454', 'G06F2207/4824', 'G06F7/501', 'G06F7/523', 'G06F7/5443', 'G06N3/044', 'G06N3/0445']"
US11983493B2,Data processing method and pronoun resolution neural network training method,"A data processing method includes: obtaining a to-be-detected text, and determining a context word set and a candidate substitute word set corresponding to a to-be-detected word in the to-be-detected text to be inputted into a pronoun resolution neural network for feature extraction; performing positive-example iteration processing and negative-example iteration processing on the features corresponding to the context word set and the candidate substitute word set, to obtain a positive-example feature vector length and a negative-example feature vector length, and calculating a substitute probability corresponding to each candidate substitute word in the candidate substitute word set according to the positive-example feature vector length and the negative-example feature vector length; determining a target substitute word according to the substitute probability corresponding to the each candidate substitute word; and inserting the target substitute word into the to-be-detected text according to a position corresponding to the to-be-detected word, to obtain a target text.","['G06F40/253', 'G06F18/214', 'G06F18/24137', 'G06F40/211', 'G06F40/247', 'G06F40/279', 'G06F40/289', 'G06N3/044', 'G06N3/08']"
CN108734283B,Neural network system,The present disclosure provides systems and methods related to artificial neural networks. The systems and methods obtain a teacher network including an artificial neural layer configured to automatically identify one or more objects in an image that pass the artificial neural layer inspection; receiving a set of task images at the teacher network; checking the set of task images with the teacher network; identifying a subset of the artificial neural layers that are used during inspection of the set of task images with the teacher network; a student network is defined based on the set of task images. The student network is configured to automatically identify one or more objects in the image that pass the subset verification.,"['G06N3/063', 'G06N3/082', 'G06F18/214', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06V20/64', 'G06V40/16']"
TWI796257B,Analog hardware realization of neural networks,"Systems and methods are provided for analog hardware realization of neural networks. The method incudes obtaining a neural network topology and weights of a trained neural network. The method also includes transforming the neural network topology to an equivalent analog network of analog components. The method also includes computing a weight matrix for the equivalent analog network based on the weights of the trained neural network. Each element of the weight matrix represents a respective connection between analog components of the equivalent analog network. The method also includes generating a schematic model for implementing the equivalent analog network based on the weight matrix, including selecting component values for the analog components.","['G06N3/082', 'G06N3/065', 'G06F1/3206', 'G06F1/3287', 'G06F30/39', 'G06N3/045', 'G06N3/049', 'G06N3/0499', 'G06N3/063', 'G06N5/04', 'G06N3/044', 'G06N3/048']"
CN107516129B,Dimension self-adaptive Tucker decomposition-based deep network compression method,"The invention discloses a depth network compression method based on dimension self-adaptive adjustment Tucker decomposition, which comprises a dimension self-adaptive adjustment process and a dimension self-adaptive weight tensor decomposition process, wherein a new tensor of any order is generated by adaptively adjusting the size of each dimension of the tensor, and tensor decomposition is realized through a learnable kernel tensor and a transfer matrix, so that the purpose of network optimization compression is achieved. Compared with the existing low-rank compression method, the method has the advantages that under the condition of keeping the network performance, the network parameters have larger compression times, and higher compression times can be obtained; meanwhile, the guide positions of the non-zero elements do not need to be stored, indexes do not need to be recorded, and the storage space can be more effectively utilized.","['G06N3/045', 'G06N3/084']"
CN107229967B,Hardware accelerator and method for realizing sparse GRU neural network based on FPGA,"The invention provides a device for realizing a sparse GRU neural network, which comprises the following components: an input receiving unit for receiving a plurality of input vectors and distributing the plurality of input vectors to a plurality of computing units; the plurality of calculation units are used for acquiring input vectors from the input receiving unit, reading weight matrix data of the neural network, decoding the weight matrix data, performing matrix operation on the decoded weight matrix data and the input vectors, and outputting matrix operation results to the hidden layer state calculation module; the hidden layer state calculation module is used for acquiring a matrix operation result from the calculation unit PE and calculating the hidden layer state; and the control unit is used for carrying out global control. On the other hand, the invention provides a method for realizing the sparse GRU neural network through iteration.","['G06N3/047', 'G06N3/063']"
US12254064B2,"Image generation method, neural network compression method, and related apparatus and device","The present application discloses an image generation method, a neural network compression method, and a related apparatus and device in the field of artificial intelligence. The image generation method includes: inputting a first matrix into an initial image generator to obtain a generated image; inputting the generated image into a preset discriminator to obtain a determining result, where the preset discriminator is obtained through training based on a real image and a category corresponding to the real image; updating the initial image generator based on the determining result to obtain a target image generator; and further inputting a second matrix into the target image generator to obtain a sample image. Further, a neural network compression method is disclosed, to compress the preset discriminator based on the sample image obtained by using the foregoing image generation method.","['G06F18/2148', 'G06F18/243', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/084', 'G06N3/088', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/778', 'G06V10/82', 'G06V30/19', 'G06V40/16', 'G06V40/174', 'G06V40/178', 'G06N3/048']"
US11924445B2,Instance-adaptive image and video compression using machine learning systems,"Techniques are described for compressing data using machine learning systems and tuning machine learning systems for compressing the data. An example process can include receiving, by a neural network compression system (e.g., trained on a training dataset), input data for compression by the neural network compression system. The process can include determining a set of updates for the neural network compression system, the set of updates including updated model parameters tuned using the input data. The process can include generating, by the neural network compression system using a latent prior, a first bitstream including a compressed version of the input data. The process can further include generating, by the neural network compression system using the latent prior and a model prior, a second bitstream including a compressed version of the updated model parameters. The process can include outputting the first bitstream and the second bitstream for transmission to a receiver.","['H04N19/13', 'H04N19/463', 'H04N19/184', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06T9/002', 'H04N19/147', 'H04N19/91', 'G06T2207/20084']"
US12126367B2,Method and system for compressing application data for operations on multi-core systems,"A system and method to compress application control data, such as weights for a layer of a convolutional neural network, is disclosed. A multi-core system for executing at least one layer of the convolutional neural network includes a storage device storing a compressed weight matrix of a set of weights of the at least one layer of the convolutional network and a decompression matrix. The compressed weight matrix is formed by matrix factorization and quantization of a floating point value of each weight to a floating point format. A decompression module is operable to obtain an approximation of the weight values by decompressing the compressed weight matrix through the decompression matrix. A plurality of cores executes the at least one layer of the convolutional neural network with the approximation of weight values to produce an inference output.","['H03M7/3059', 'G06F18/2135', 'G06F18/24', 'G06F18/2413', 'G06F7/483', 'G06F9/445', 'G06N3/02', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'H03M7/02', 'H03M7/40', 'H03M7/6005', 'H03M7/6011', 'H03M7/70', 'G06N3/08', 'H03M7/6017']"
US11556796B2,Compressing weight updates for decoder-side neural networks,"A method, apparatus, and computer program product are provided for training a neural network or providing a pre-trained neural network with the weight-updates being compressible using at least a weight-update compression loss function and/or task loss function. The weight-update compression loss function can comprise a weight-update vector defined as a latest weight vector minus an initial weight vector before training. A pre-trained neural network can be compressed by pruning one or more small-valued weights. The training of the neural network can consider the compressibility of the neural network, for instance, using a compression loss function, such as a task loss and/or a weight-update compression loss. The compressed neural network can be applied within a decoding loop of an encoder side or in a post-processing stage, as well as at a decoder side.","['G06N3/082', 'G06N20/10', 'G06N3/045', 'G06N3/084', 'G06T3/4046', 'G06T9/002', 'H04N19/103', 'H04N19/154', 'G06N3/063']"
US12206851B2,Implicit image and video compression using machine learning systems,"Techniques are described for compressing and decompressing data using machine learning systems. An example process can include receiving a plurality of images for compression by a neural network compression system. The process can include determining, based on a first image from the plurality of images, a first plurality of weight values associated with a first model of the neural network compression system. The process can include generating a first bitstream comprising a compressed version of the first plurality of weight values. The process can include outputting the first bitstream for transmission to a receiver.","['H04N19/126', 'H04N19/51', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06T9/002', 'H04N19/103', 'H04N19/124', 'H04N19/146', 'H04N19/147', 'H04N19/172', 'H04N19/463', 'H04N19/537', 'H04N19/91', 'H04N19/177']"
US20240288926A1,Multiple Stage Network Microphone Device with Reduced Power Consumption and Processing Load,"Systems, methods, and devices with reduced power consumption in network microphone devices. In one embodiment, a network microphone device is configured to perform a method that includes (i) capturing audio content; (ii) using a first algorithm to perform a keyword detection process for determining whether the audio content includes a keyword; (iii) responsive to determining that the audio content includes the keyword, using a second, more computationally intensive algorithm to perform a wake-word detection process for determining whether the audio content includes a wake word; and (iv) responsive to performing the wake-word detection process, (a) causing a voice service corresponding to the wake word to process the audio content if the wake-word detection process confirms that the audio content includes the wake word or (b) ceasing performance of the wake-word detection process if the wake-word detection process disconfirms that the audio content includes the wake word.","['G06F1/3293', 'G06F1/3215', 'G06F1/3231', 'G06F1/3287', 'G06F3/167', 'H04R29/005', 'H04R3/00', 'H04R3/005', 'H04R2201/028', 'H04R2420/07', 'H04R5/027', 'Y02D10/00']"
US20240064318A1,Apparatus and method for coding pictures using a convolutional neural network,"The present disclosure relates to encoding and decoding of a picture or a plurality of pictures (e.g. video) using a neural network which is partially trained online. Accordingly, at an encoder one or more layers are selected which are to be trained. Then, the training of the neural network is performed in which parameters of the selected layers are updated. The parameters of the remaining layers are maintained and not updated. The updated parameters are provided within a bitstream. The picture(s) is/are also encoded. The decoder receives an indication of the updated parameters, updates only those parameters indicated, and applies the so obtained neural network.","['H04N19/82', 'H04N19/42', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/096', 'H04N19/172', 'H04N19/30', 'H04N19/463', 'H04N19/70', 'H04N19/85', 'H04N19/117', 'H04N19/132', 'H04N19/14', 'H04N19/147', 'H04N19/80']"
TWI801356B,"Method for network quantization, apparatus in neural network, method of manufacturing chipset, and method of testing apparatus","Apparatuses and methods of manufacturing same, systems, and methods for performing network parameter quantization in deep neural networks are described. In one aspect, multi-dimensional vectors representing network parameters are constructed from a trained neural network model. The multi-dimensional vectors are quantized to obtain shared quantized vectors as cluster centers, which are fine-tuned. The fine-tuned and shared quantized vectors are then encoded. Decoding reverses the process.","['G06N3/063', 'G06N3/08', 'G06N3/0495', 'G06F18/23213', 'G06F7/582', 'G06N3/0455', 'G06N3/047', 'G06N3/084']"
US20200184333A1,Apparatus and method of compressing neural network,"Provided are an apparatus and method of compressing an artificial neural network. According to the method and the apparatus, an optimal compression rate and an optimal operation accuracy are determined by compressing an artificial neural network, determining a task accuracy of a compressed artificial neural network, and automatically calculating a compression rate and a compression ratio based on the determined task accuracy. The method includes obtaining an initial value of a task accuracy for a task processed by the artificial neural network, compressing the artificial neural network by adjusting weights of connections among layers of the artificial neural network included in information regarding the connections, determining a compression rate for the compressed artificial neural network based on the initial value of the task accuracy and a task accuracy of the compressed artificial neural network, and re-compressing the compressed artificial neural network according to the compression rate.","['G06N3/082', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/063']"
CN107967515B,Method and apparatus for neural network quantization,"A method and apparatus for neural network quantization. Devices and methods, systems, and methods of manufacturing the devices are described for performing network parameter quantification in deep neural networks. In one aspect, a diagonal of a second order partial derivative matrix of a loss function of a network parameter of the neural network is determined, and the network parameter is then weighted using the diagonal as part of a quantization operation on the network parameter, wherein the second order partial derivative matrix is a sea-sev matrix. In another aspect, a neural network is trained using first and second moment estimates of gradients of network parameters, and the network parameters are then weighted using the second moment estimates as part of a quantization operation on the network parameters. On the other hand, network parameter quantization is performed by scalar quantization (ECSQ) iterative algorithm using entropy constraints. On the other hand, the network parameter quantization is performed by quantizing network parameters of all layers of the deep neural network together at once.","['G06N3/08', 'G06N3/063', 'G06N3/084', 'G06F17/16', 'G06F18/23213', 'G06N3/0464', 'G06N3/0495', 'G06N3/06', 'G06N3/082', 'G06N3/09']"
US20210342730A1,System and method of quantum enhanced accelerated neural network training,"A novel and useful system and method of quantum enhanced accelerated training of a classic neural network (NN). The quantum system implements an optimizer that accelerates training of the classic NN by exploiting the properties of quantum mechanics and manipulating the quantum system into a state that represents the complete state of the classic NN, including the loss function. The quantum system is then allowed to transition to its “optimum state” and the minimum energy state is read out from detectors and weight updates are calculated and fed back to the classic NN. Mapping and detection helper neural networks learn the characteristics of the quantum system structures. By averaging this over a number of images the learning weight or gradient of descent can be controlled to yield optimum neural network parameters. The time and energy required for training the classic NN as well as for inference is drastically reduced.","['G06N10/00', 'G06N10/60', 'G06N10/40', 'G06N10/70', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/06', 'G06N3/08']"
US11961000B2,Lossy layer compression for dynamic scaling of deep neural network processing,"An apparatus of operating a neural network is configured to compress one or more of activations or weights in one or more layer of the neural network. The activations and/or weights may be compressed based on a compression ratio or a system event. The system event may be a bandwidth condition, a power condition, a debug condition, a thermal condition or the like. The apparatus may operate the neural network to compute an inference based on the compressed activations or the compressed weights.","['G06N3/084', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/088', 'G06V10/764', 'G06V10/82', 'G06V20/582', 'G06V20/584', 'G06V20/588', 'G06F18/2136', 'G06V2201/08']"
US11632181B2,Learning and deploying compression of radio signals,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training and deploying machine-learned compact representations of radio frequency (RF) signals. One of the methods includes: determining a first RF signal to be compressed; using an encoder machine-learning network to process the first RF signal and generate a compressed signal; calculating a measure of compression in the compressed signal; using a decoder machine-learning network to process the compressed signal and generate a second RF signal that represents a reconstruction of the first RF signal; calculating a measure of distance between the second RF signal and the first RF signal; and updating at least one of the encoder machine-learning network or the decoder machine-learning network based on (i) the measure of distance between the second RF signal and the first RF signal, and (ii) the measure of compression in the compressed signal.","['G06N3/086', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'H04B17/30', 'H04W24/08', 'G06F18/217', 'G06F2218/00', 'G06N3/006', 'G06N3/044', 'G06N3/048']"
US10229356B1,Error tolerant neural network model compression,"Features are disclosed for error tolerant model compression. Such features could be used to reduce the size of a deep neural network model including several hidden node layers. The size reduction in an error tolerant fashion ensures predictive applications relying on the model do not experience performance degradation due to model compression. Such predictive applications include automatic recognition of speech, image recognition, and recommendation engines. Partially quantized models are re-trained such that any degradation of accuracy is “trained out” of the model providing improved error tolerance with compression.","['G06N3/063', 'G06N3/08', 'G06N3/084', 'G10L15/16']"
US10832123B2,Compression of deep neural networks with proper use of mask,"The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a compression method for deep neural networks with proper use of mask and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks while maintaining or even improving the accuracy of the neural networks after compression.","['G06N3/0445', 'G06N3/082', 'G06N3/044', 'G06N3/045', 'G06N3/0454']"
US11595062B2,Decompression apparatus for decompressing a compressed artificial intelligence model and control method thereof,"A decompression apparatus is provided. The decompression apparatus includes a memory configured to store compressed data decompressed and used in neural network processing of an artificial intelligence model, a decoder configured to include a plurality of logic circuits related to a compression method of the compressed data, decompress the compressed data through the plurality of logic circuits based on an input of the compressed data, and output the decompressed data, and a processor configured to obtain data of a neural network processible form from the data output from the decoder.","['H03M13/6312', 'G06N3/063', 'G06N3/048', 'G06N3/06', 'G06N3/082', 'H03M13/1105', 'H03M13/118', 'H03M13/2778', 'G06N3/04', 'G06N3/084']"
CN108921013B,A system and method for visual scene recognition based on deep neural network,"A deep neural network based visual scene recognition system, comprising: the vehicle-mounted vision system is used for acquiring a vehicle forward-looking vision image; the off-line training module is used for carrying out sample acquisition on a vehicle forward-looking visual image acquired from a vehicle-mounted visual system by utilizing a deep convolutional neural network for visual input, marking the acquired sample to generate a sample label and carrying out step-by-step training on neural network parameters; the deep convolutional neural network is composed of three-branch classification networks sharing two layers of shallow convolutional characteristics, and network parameters are trained through samples and training tasks; and the online analysis module is used for carrying out real-time scene analysis on the sample trained by the offline training module by adopting a network compression and time-sharing parallel analysis strategy and outputting the time of day, the weather and the scene abnormal state of the road scene where the vehicle-mounted vision system is located.","['G06V20/10', 'G06N3/045', 'G06N3/08']"
US11003985B2,Convolutional neural network system and operation method thereof,"Provided is a convolutional neural network system including a data selector configured to output an input value corresponding to a position of a sparse weight from among input values of input data on a basis of a sparse index indicating the position of a nonzero value in a sparse weight kernel, and a multiply-accumulate (MAC) computator configured to perform a convolution computation on the input value output from the data selector by using the sparse weight kernel.","['G06N3/063', 'G06F17/15', 'G06F17/153', 'G06F7/5443', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/082']"
US11868867B1,Decompression and compression of neural network data using different compression schemes,"Described herein is a neural network accelerator (NNA) with a decompression unit that can be configured to perform multiple types of decompression. The decompression may include a separate subunit for each decompression type. The subunits can be coupled to form a pipeline in which partially decompressed results generated by one subunit are input for further decompression by another subunit. Depending on which types of compression were applied to incoming data, any number of the subunits may be used to produce a decompressed output. In some embodiments, the decompression unit is configured to decompress data that has been compressed using a zero value compression scheme, a shared value compression scheme, or both. The NNA can also include a compression unit implemented in a manner similar to that of the decompression unit.","['G10L15/05', 'G06N3/048', 'G10L25/87', 'G06F17/16', 'G06F5/01', 'G06F7/5443', 'G06F7/57', 'G06N3/08', 'G06N3/10', 'G06N5/04', 'G10L15/02', 'G10L15/14', 'G10L15/1822', 'G10L15/19', 'G10L15/193', 'H03M7/42', 'H03M7/702', 'G06F40/289', 'G06N3/02', 'G10L15/01', 'G10L15/083', 'G10L15/16', 'G10L15/18', 'G10L2025/783']"
CN113011570B,Facial expression recognition method adopting neural network compression system,"The invention discloses a facial expression recognition method adopting a neural network compression system, and belongs to the fields of artificial intelligence, computer vision and image processing. The method firstly carries out coarse-grained pruning on the neural network model by using a differential evolution algorithm, and obtains a near-optimal neural network structure by quickly searching in a coarse-grained space through an entropy importance criterion and an objective function with a good guiding function. And then constructing a fine-grained search space on the basis of the optimal individual obtained by coarse-grained search, and performing fine-grained pruning through a differential evolution algorithm neural network model to obtain a network model with an optimal structure. And finally, recovering the performance of the optimal model by using a multi-teacher multi-step knowledge distillation network to ensure that the optimal model reaches the precision of the original model. The invention can carry out structure search pruning and knowledge distillation in a fully self-adaptive manner, effectively compress the model, effectively reduce the calculated amount and keep the high precision of the pruning model.","['G06N3/0464', 'G06N3/045', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/086', 'G06N3/09', 'Y02D10/00']"
CN111079781B,Lightweight convolutional neural network image recognition method based on low rank and sparse decomposition,"The invention belongs to the field of image recognition, and relates to a lightweight convolutional neural network image recognition method based on low rank and sparse decomposition. The construction process of the lightweight convolutional neural network with low rank and sparse decomposition comprises the following steps: in the structural design stage, decomposing the weight matrix into the sum of a low-rank matrix and a sparse matrix, and decomposing the low-rank matrix into the product of two small matrices according to the size of the rank; in the training stage, adding regularization terms into the loss function to restrict the sparse matrix; in the post-processing stage, unimportant parameters are deleted according to the energy distribution of the sparse matrix. Preferably, the method further comprises: and fine tuning the lightweight convolutional neural network with low rank and sparse decomposition. According to the invention, a lightweight convolutional neural network is trained from the beginning by combining a low-rank decomposition method and a sparse compression method, and compression and acceleration of the convolutional neural network are realized while the image recognition precision is maintained.","['G06F18/214', 'G06N3/045', 'G06N3/082', 'Y02D10/00']"
US11636337B2,System and method for knowledge distillation between neural networks,"Systems and methods for knowledge distillation provide supervised training of a student network with a teacher network, including inputting a batch to the teacher network, inputting the batch to the student network, generating a teacher activation map at a layer of the teacher network, generating a student activation map at a layer of the student network corresponding to the layer of the teacher network, generating a pairwise teacher similarity matrix based on the teacher activation map, generating a pairwise student similarity matrix based on the student activation map, and minimizing a knowledge distillation loss defined as a difference between the pairwise teacher similarity matrix and the pairwise student similarity matrix.","['G06N3/08', 'G06F17/16', 'G06F17/18', 'G06F18/20', 'G06K9/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454']"
US10726335B2,Generating compressed representation neural networks having high degree of accuracy,"Machine learning based models, for example, neural network models employ large numbers of parameters, from a few million to hundreds of millions or more. A machine learning based model is trained using fewer parameters than specified. An initial parameter vector is initialized, for example, using random number generation based on a seed. During training phase, the parameter vectors are modified in a subspace around the initial vector. The trained model can be stored or transmitted using seed values and the trained parameter vector in the subspace. The neural network model can be uncompressed using the seed values and the trained parameter vector in the subspace. The compressed representation of neural networks may be used for various applications such as generating maps, object recognition in images, processing of sensor data, natural language processing, and others.","['G06N3/082', 'G06N3/084', 'G05D1/0088', 'G06F17/16', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N5/01', 'G06N3/044']"
CN111461322B,Deep neural network model compression method,"The invention relates to a deep neural network model compression method, which comprises the following steps: 1) Training a complex model through a standard neural network training process to obtain an original model; 2) Pruning the original model using structured pruning and unstructured pruning according to one of the following formulas: { (s, st, u, ut) ×n-1, (s, st, u) } or { (u, ut, s, st) ×n-1, (u, ut, s) }; wherein, s: structured pruning; st: structural pruning retraining; u: unstructured pruning; ut: unstructured pruning retraining; (s, st, u, ut) n-1 represents repeating (s, st, u, ut) n-1 times in the order, (u, ut, s, st) n-1 represents repeating (u, ut, s, st) n-1 times in the order, wherein n is 1 or more; 3) Training the model obtained by pruning in the step 2).","['G06N3/082', 'G06N3/045']"
AU2019232899B2,Sparsity constraints and knowledge distillation based learning of sparser and compressed neural networks,"5 In deep neural network research is porting the memory- and computation-intens ive network models on embedded platforms with a minimal compromise in model accuracy. Embodiments of the present disclosure build a Bayesian student network using the knowledge learnt by an accurate but complex pre-trained teachernetwork, 10 and sparsity induced by the variational parameters in a student network. Further, the sparsity inducing capability of the teacher on the student network is leamt by employing a Block Sparse Regularizer on a concatenated tensor of teacher and student network weights. Specifically, the student network is trained using the variational lower bound based loss function, constrained on the hint from the teacher, and block 15 sparsity of weights. [To be published with FIG. 3] 32 3/8 initializing, by one or more hardware processors, a first 202 neural network with a plurality of weights passing through the first neural network, (i) a subset of an input data received corresponding to a specific domain and (ii) ground truth information corresponding to the subset of 204 the input data dynamically updating, by the one or more hardware processors, the plurality of weights of the first neural network based on a first difference in an output generated by the 206 first neural network and the corresponding ground truth information of the subset of an input data dynamically updating, by the one or more hardware processors, the plurality of weights of the first network based on a second difference in an output generated by (i) the first 208 neural network and (ii) a second neural network for the subset applying sparsity constraints on the plurality of weights of the first neural network with reference to a set of weights of the second neural network to determine weights to be 210 dropped or retained, from or in, the plurality of weights of the first neural network to obtain a trained compressed and sparser neural network FIG. 3","['G06N3/08', 'G06N3/047', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/09']"
US12361518B2,"Image recognition method and device, and computer-readable storage medium","An image recognition method includes: inputting a sample image data set into an original neural network model in advance; and for each convolution layer of the original neural network model, using a feature map of the sample image data set in the current layer as a reconstruction target, firstly obtaining an update weight of a convolution kernel by using a kernel set construction method, then calculating an input channel combination having a minimum reconstruction error, cutting a redundant input channel to obtain a compression result of the current convolution layer, and finally, splicing compression results of the convolution layers to generate an image recognition model. An image to be recognized is obtained and is inputted into the image recognition model, and an output result of the image recognition model is used as an image recognition result of the image.","['G06F18/214', 'G06T5/20', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06V10/454', 'G06V10/771', 'G06V10/82']"
US9665565B2,"Semantic similarity evaluation method, apparatus, and system","A semantic similarity evaluation method includes performing word vectorization processing separately on words in a first sentence and a word in a second sentence to obtain a first word vector and a second word vector; performing, in a preset word vector compression order, compression coding processing on the first word vector according to a first compression coding parameter to obtain a first statement vector; performing, in the preset word vector compression order, compression coding processing on the second word vector according to a second compression coding parameter to obtain a second statement vector; and determining a vector distance between the first statement vector and the second statement vector, and evaluating a semantic similarity between the first sentence and the second sentence according to the vector distance. The method is used to evaluate a semantic similarity.","['G06F17/2785', 'G06F40/47', 'G06F17/2836', 'G06F17/2854', 'G06F40/30', 'G06F40/51']"
US11818399B2,Techniques for signaling neural network topology and parameters in the coded video stream,"There is included a method and apparatus comprising computer code configured to cause a processor or processors to perform obtaining a video bitstream, coding the video bitstream at least partly by a neural network, determining topology information and parameters of the neural network, signaling the determined topology information and the parameters of the neural network in a plurality of syntax elements associated with the coded video bitstream.","['H04N19/70', 'G06N3/04', 'G06N3/045', 'G06N3/105', 'G06T9/002', 'H04N19/117', 'H04N19/184', 'H04N19/42', 'H04N19/573', 'H04N19/593', 'H04N19/61']"
TWI722434B,Self-tuning incremental model compression method in deep neural network,"A method of compressing a pre-trained deep neural network model includes inputting the pre-trained deep neural network model as a candidate model. The candidate model is compressed by increasing sparsity of the candidate, removing at least one batch normalization layer present in the candidate model, and quantizing all remaining weights into fixed-point representation to form a compressed model. Accuracy of the compressed model is then determined utilizing an end-user training and validation data set. Compression of the candidate model is repeated. The compressed model is output for inference utilization.","['G06N3/063', 'G06N3/082', 'G06N20/10', 'G06N3/045']"
US10373300B1,System and method for lossy image and video compression and transmission utilizing neural networks,"A system and method for lossy image and video compression and transmission that utilizes a neural network as a function to map a known noise image to a desired or target image, allowing the transfer only of hyperparameters of the function instead of a compressed version of the image itself. This allows the recreation of a high-quality approximation of the desired image by any system receiving the hyperparameters, provided that the receiving system possesses the same noise image and a similar neural network. The amount of data required to transfer an image of a given quality is dramatically reduced versus existing image compression technology. Being that video is simply a series of images, the application of this image compression system and method allows the transfer of video content at rates greater than existing technologies in relation to the same image quality.","['G06T5/50', 'H04N19/90', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T5/002', 'G06T5/70', 'G06T7/0002', 'G06T7/97', 'G06T9/002', 'H04N7/035', 'H04N7/12', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30168']"
US12154030B2,Method and apparatus for data-free post-training network quantization and generating synthetic data based on a pre-trained machine learning model,"A method for training a generator, by a generator training system including a processor and memory, includes: extracting training statistical characteristics from a batch normalization layer of a pre-trained model, the training statistical characteristics including a training mean μ and a training variance σ2; initializing a generator configured with generator parameters; generating a batch of synthetic data using the generator; supplying the batch of synthetic data to the pre-trained model; measuring statistical characteristics of activations at the batch normalization layer and at the output of the pre-trained model in response to the batch of synthetic data, the statistical characteristics including a measured mean {circumflex over (μ)}ψ and a measured variance {circumflex over (σ)}ψ 2; computing a training loss in accordance with a loss function Lψ based on μ, σ2, {circumflex over (μ)}ψ, and {circumflex over (σ)}ψ 2; and iteratively updating the generator parameters in accordance with the training loss until a training completion condition is met to compute the generator.","['G06N3/082', 'G06N3/08', 'G06T11/00', 'G06F17/18', 'G06F18/2113', 'G06F18/214', 'G06F18/22', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06N3/088', 'G06N3/096', 'G06N7/01', 'G06T5/50', 'G06V10/761', 'G06V10/772', 'G06V10/774', 'G06V10/82', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US12147914B2,Compression for deep learning in case of sparse values mapped to non-zero value,"Embodiments described herein provide a processing apparatus comprising compute circuitry to generate neural network data for a convolutional neural network (CNN) and write the neural network data to a memory buffer. The compute circuitry additionally includes a direct memory access (DMA) controller including a hardware codec having encode circuitry and a decode circuitry. The DMA controller reads the neural network data from the memory buffer, encode the neural network data via the encode circuit, writes encoded neural network data to a memory device coupled with the processing apparatus, writes metadata for the encoded neural network data to the memory device coupled with the processing apparatus, and decodes encoded neural network data via the decode circuit in response to a request from the compute circuitry.","['G06N5/046', 'G06F13/10', 'G06F13/28', 'G06F17/16', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06T1/20', 'G06T15/205', 'G06T9/002', 'Y02D10/00']"
US11468331B2,"Neural network load reduction device, information processing unit, and neural network load reduction method and computer-readable storage medium","An information processing unit includes: an attention module having an attention layer and a computation section and that is for a neural network including plural levels of layer, the attention layer being configured to compute an output feature corresponding to an input feature from a predetermined layer and based on a parameter; the computation section that multiplies the input feature by the output feature, and outputs a computed result to a layer at a next level; the first learning unit connected to the neural network and that learns the parameter in a state in which learning has been suspended at least for the predetermined layer and the next level layer; and the channel selection section that selects as a redundant channel a channel satisfying a predetermined relationship between the output feature and a predetermined threshold value.","['G06N3/045', 'G06N3/0454', 'G06N3/082', 'G06N3/084']"
US12045729B2,"Neural network compression method, apparatus and device, and storage medium","A neural network compression method whereby forward inference is performed on target data by using a target parameter sharing network to obtain an output feature map of the last convolutional module, a channel related feature is extracted from the output feature map, the extracted channel related feature and a target constraint condition are input into a target meta-generative network, and an optimal network architecture under the target constraint condition is predicted by using the target meta-generative network to obtain a compressed neural network model.","['G06N3/082', 'G06N3/045', 'G06N3/0464', 'G06N3/0475', 'G06N3/0495', 'G06N3/0895', 'G06N3/0985', 'G06N5/046']"
US11544539B2,"Hardware neural network conversion method, computing device, compiling method and neural network software and hardware collaboration system","A hardware neural network conversion method, a computing device, a compiling method and a neural network software and hardware collaboration system for converting a neural network application into a hardware neural network fulfilling a hardware constraint condition are disclosed. The method comprises: obtaining a neural network connection diagram corresponding to the neural network application; splitting the neural network connection diagram into neural network basic units; converting each of the neural network basic units so as to form a network having equivalent functions thereto and formed by connecting basic module virtual entities of neural network hardware; and connecting the obtained basic unit hardware network according to the sequence of splitting so as to create a parameter file for the hardware neural network. The present disclosure provides a novel neural network and a brain-like computing software and hardware system.","['G06N3/049', 'G06F17/16', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/084']"
US10698657B2,Hardware accelerator for compressed RNN on FPGA,"The present invention relates to recurrent neural network. In particular, the present invention relates to how to implement and accelerate a recurrent neural network based on an embedded FPGA. Specifically, it proposes an overall design processing method of matrix decoding, matrix-vector multiplication, vector accumulation and activation function. In another aspect, the present invention proposes an overall hardware design to implement and accelerate the above process.","['G06F7/501', 'G06F7/5443', 'G06F7/523', 'G06N3/044', 'G06N3/0445', 'G06N3/063', 'G06F2207/4824']"
US11238341B2,Efficient encoding and decoding sequences using variational autoencoders,"Embodiments include applying neural network technologies to encoding/decoding technologies by training and encoder model and a decoder model using a neural network. Neural network training is used to tune a neural network parameter for the encoder model and a neural network parameter for the decoder model that approximates an objective function. The common objective function may specify a minimized reconstruction error to be achieved by the encoder model and the decoder model when reconstructing (encoding then decoding) training data. The common objective function also specifies for the encoder and decoder models, a variable f representing static aspects of the training data and a set of variables z1:T representing dynamic aspects of the training data. During runtime, the trained encoder and decoder models are implemented by encoder and decoder machines to encode and decoder runtime sequences having a higher compression rate and a lower reconstruction error than in prior approaches.","['H03M7/00', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G10L19/04', 'H03M1/00', 'H03M13/6502', 'H03M7/30']"
CN109784153B,"Emotion recognition method, emotion recognition device, computer equipment and storage medium","The invention discloses a emotion recognition method, a device, computer equipment and a storage medium, wherein the method comprises the following steps: obtaining a face sample picture, preprocessing the face sample picture to obtain a training sample, inputting the training sample into a preset dense convolutional neural network model, carrying out convolutional calculation on the training sample by adopting a compressed convolutional layer of the dense convolutional neural network model, extracting face characteristic data of the training sample, carrying out model training on the dense convolutional neural network model by using a back propagation algorithm according to the face characteristic data to obtain an emotion recognition model, inputting the face picture to be recognized into the emotion recognition model to carry out recognition, and obtaining the emotion state of a face in the face picture to be recognized. According to the embodiment of the invention, the training sample is used for training the dense convolutional neural network model, so that the accuracy of the emotion recognition model obtained through training of the neural network structure is higher, and the recognition accuracy of the emotion recognition model on the emotion of the person is improved.",[]
US20200258263A1,Policy-based system interface for a real-time autonomous system,"Embodiments are generally directed to compression in machine learning and deep learning processing. An embodiment of an apparatus for compression of untyped data includes a graphical processing unit (GPU) including a data compression pipeline, the data compression pipeline including a data port coupled with one or more shader cores, wherein the data port is to allow transfer of untyped data without format conversion, and a 3D compression/decompression unit to provide for compression of untyped data to be stored to a memory subsystem and decompression of untyped data from the memory subsystem.","['G06T9/002', 'G06F12/08', 'G06F12/023', 'G06T1/20', 'G06T15/005', 'G06F2212/302', 'G06F2212/401']"
US11030997B2,Slim embedding layers for recurrent neural language models,"Described herein are systems and methods for compressing or otherwise reducing the memory requirements for storing and computing the model parameters in recurrent neural language models. Embodiments include space compression methodologies that share the structured parameters at the input embedding layer, the output embedding layers, or both of a recurrent neural language model to significantly reduce the size of model parameters, but still compactly represent the original input and output embedding layers. Embodiments of the methodology are easy to implement and tune. Experiments on several data sets show that embodiments achieved similar perplexity and BLEU score results while only using a fraction of the parameters.","['G10L15/063', 'G06F40/123', 'G06F17/16', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G10L15/16', 'H03M7/3082', 'H03M7/42']"
CN109685202B,"Data processing method and device, storage medium and electronic device","The invention discloses a data processing method and device, a storage medium and an electronic device. Wherein, the method comprises the following steps: performing first processing on data to be processed by using a first submodel in an AI processing model to obtain an intermediate processing result, wherein the AI processing model is used for performing target processing on the data to be processed to obtain a target processing result, the AI processing model comprises a first submodel and a second submodel, the first submodel corresponds to M neural network layers, the second submodel comprises K neural network layers, and M and K are positive integers greater than or equal to 1; sending the intermediate processing result to a first server, wherein the first server is used for executing second processing on the intermediate processing result by using a second submodel to obtain a target processing result, and the target processing comprises first processing and second processing; and receiving a target processing result returned by the first server.","['H04L67/10', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06T5/73', 'G06V10/764', 'G06V10/82', 'G06V40/16', 'G06T2207/20081', 'G06T2207/20084', 'H04L69/04']"
US10810484B2,Hardware accelerator for compressed GRU on FPGA,"The present technical disclosure relates to artificial neural networks, e.g., gated recurrent unit (GRU). In particular, the present technical disclosure relates to how to implement a hardware accelerator for compressed GRU based on an embedded FPGA. Specifically, it proposes an overall design processing method of matrix decoding, matrix-vector multiplication, vector accumulation and activation function. In another aspect, the present technical disclosure proposes an overall hardware design to implement and accelerate the above process.","['G06N3/0445', 'G06F7/5443', 'G06N3/044', 'G06F7/50', 'G06F7/523', 'G06N3/063', 'G06N3/082', 'G06F2207/4824']"
US20230128061A1,Unsupervised encoder-decoder neural network security event detection,"A method may include a processing system having at least one processor obtaining a first plurality of domain name system traffic records, generating an input aggregate vector from the first plurality of domain name system traffic records, where the input aggregate vector comprises a plurality of features derived from the first plurality of domain name system traffic records, and applying an encoder-decoder neural network to the input aggregate vector to generate a reconstructed vector, where the encoder-decoder neural network is trained with a plurality of aggregate vectors generated from a second plurality of domain name system traffic records. In one example, the processing system may then calculate a distance between the input aggregate vector and the reconstructed vector, and apply at least one remedial action associated with the first plurality of domain name system traffic records when the distance is greater than a threshold distance.","['H04L63/1425', 'G06F16/245', 'G06F17/16', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G08G1/0125', 'H04L43/16', 'H04L61/4511', 'H04L63/0236', 'H04L63/0254', 'H04L63/1416', 'H04L63/1458', 'H04L61/4552']"
US11670010B2,Data compression using conditional entropy models,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for compressing and decompressing data. In one aspect, a method comprises: processing data using an encoder neural network to generate a latent representation of the data; processing the latent representation of the data using a hyper-encoder neural network to generate a latent representation of an entropy model; generating an entropy encoded representation of the latent representation of the entropy model; generating an entropy encoded representation of the latent representation of the data using the latent representation of the entropy model; and determining a compressed representation of the data from the entropy encoded representations of: (i) the latent representation of the data and (ii) the latent representation of the entropy model used to entropy encode the latent representation of the data.","['G06T9/001', 'G06F17/18', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T3/40', 'G06T9/002']"
US20200302276A1,Artificial intelligence semiconductor chip having weights of variable compression ratio,"An artificial intelligence (AI) semiconductor having an embedded convolution neural network (CNN) may include a first convolution layer and a second convolution layer, in which the weights of the first layer and the weights of the second layer are quantized in different bit-widths, thus at different compression ratios. In a VGG neural network, the weights of a first group of convolution layers may have a different compression ratio than the weights of a second group of convolution layers. The weights of the CNN may be obtained in a training system including convolution quantization and/or activation quantization. Depending on the compression ratio, the weights of a convolution layer may be trained with or without re-training. An AI task, such as image retrieval, may be implemented in the AI semiconductor having the CNN described above.","['G06N3/08', 'G06N3/063', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N5/046']"
CN110222821B,Weight distribution-based convolutional neural network low bit width quantization method,"The invention discloses a weight distribution-based convolutional neural network low bit width quantization method, which comprises the steps of firstly pruning a whole feature map by utilizing pruning so as to generate a network which can efficiently run on embedded or mobile equipment; in order to further reduce the requirement of a deep neural network on a storage space, an efficient quantization algorithm is applied on the basis of pruning, a uK-means algorithm is adopted to optimize quantization parameters before quantization, an ideal quantization parameter which is beneficial to positioning a global solution can be searched in a larger solution space, then a progressive quantization method is adopted to quantize weights in batches, and the residual unquantized weight values are adjusted to compensate errors caused by quantized parts until all weights are quantized. The quantization method has high flexibility and high operation speed, does not need to change the network structure, and has higher accuracy without retraining.","['G06F18/23213', 'G06F18/241', 'G06N3/045', 'G06N3/08']"
CN110413255B,Artificial neural network adjusting method and device,"A method and apparatus for tuning an Artificial Neural Network (ANN) is provided. The ANN includes at least a plurality of layers, the method comprising: obtaining a trained floating point neural network model; performing fixed-point quantization on the floating-point neural network model; and outputting the fixed point neural network model subjected to fixed point quantization. The direct fixed-point scheme of the invention does not relate to model training, does not need to label a data set and does not relate to reverse operation, so that the compression and optimization of the neural network can be realized conveniently, quickly, with low cost and high precision.","['G06F7/575', 'G06N3/063']"
US20250045582A1,Dynamic neural network surgery,Techniques related to compressing a pre-trained dense deep neural network to a sparsely connected deep neural network for efficient implementation are discussed. Such techniques may include iteratively pruning and splicing available connections between adjacent layers of the deep neural network and updating weights corresponding to both currently disconnected and currently connected connections between the adjacent layers.,"['G06N3/08', 'G06N3/04', 'G06N3/082', 'G06N3/045']"
US11516473B2,Bandwidth compression for neural network systems,"Techniques and systems are provided for compressing data in a neural network. For example, output data can be obtained from a node of the neural network. Re-arranged output data having a re-arranged scanning pattern can be generated. The re-arranged output data can be generated by re-arranging the output data into the re-arranged scanning pattern. One or more residual values can be determined for the re-arranged output data by applying a prediction mode to the re-arranged output data. The one or more residual values can then be compressed using a coding mode.","['H04N19/13', 'H03M7/3071', 'G06N3/02', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'H03M7/3066', 'H04L69/04', 'H04N19/129', 'H04N19/159', 'H04N19/176', 'H04N19/182', 'H04N19/91', 'H03M7/40', 'H03M7/46']"
US20200304802A1,Video compression using deep generative models,"Certain aspects of the present disclosure are directed to methods and apparatus for compressing video content using deep generative models. One example method generally includes receiving video content for compression. The received video content is generally encoded into a latent code space through an encoder, which may be implemented by a first artificial neural network. A compressed version of the encoded video content is generally generated through a trained probabilistic model, which may be implemented by a second artificial neural network, and output for transmission.","['H04N19/124', 'H04N19/20', 'G06F18/21', 'G06K9/00744', 'G06K9/6217', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/08', 'G06N3/084', 'G06T9/002', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'H04N19/13', 'H04N19/136', 'H04N19/14', 'H04N19/179', 'H04N19/186', 'H04N19/46', 'H04N19/90', 'H04N23/90', 'H04N5/247', 'H04N7/183']"
CN112016674B,Knowledge distillation-based convolutional neural network quantification method,"The invention provides a knowledge distillation-based convolutional neural network quantization method, which relates to the technical field of convolutional neural networks, and adopts a dynamic search mode to obtain the optimal clipping proportion and quantization bit number of each network weight layer of the convolutional neural network. In the quantization compression process of the convolutional neural network, a teacher network is used for fine adjustment training based on knowledge distillation, different quantization precision can be adopted for different network weight layers of the convolutional neural network, network precision cannot be excessively lost, and the compression degree of the convolutional neural network can be increased in the quantization process.","['G06N3/045', 'G06N3/082']"
WO2022141754A1,Automatic pruning method and platform for general compression architecture of convolutional neural network,"Disclosed in the present invention are an automatic pruning method and platform for a general compression architecture of a convolutional neural network. The method comprises: firstly randomly performing channel width sampling of a convolution module of an input model to generate a channel pruning coding vector; then designing a pruned cell network, inputting the channel pruning coding vector into the cell network, outputting a weighting matrix used for constructing a pruned network model and generating a corresponding pruned structure model, and jointly training the pruned cell network and the generated pruned network model to update the pruned cell network; and finally using the weightings generated by the trained pruned network to search for the pruned network with the best performance; no fine-tuning is needed during the search. By means of training a single pruned network of a target network, the user can search for various pruned networks in different constraint conditions with little need for manual involvement, accelerating the speed of the search for high-performance neural network structures.","['G06N3/082', 'G06N3/045', 'G06N3/084', 'G06N3/086']"
US20180247193A1,Neural network training using compressed inputs,"Aspects relate to systems and methods for improving the operation of computer-implemented neural networks. Some aspects relate to training a neural network using a compressed representation of the inputs either through efficient discretization of the inputs, or choice of compression. This approach allows a multiscale approach where the input discretization is adaptively changed during the learning process, or the loss of the compression is changed during the training. Once a network has been trained, the approach allows for efficient predictions and classifications using compressed inputs. One approach can generate a larger more diverse training dataset based on both simulations from physical models, as well as incorporating domain expertise and other available information. One approach can automatically match the documents to the list, while still allowing a user to input information to update and correct the matching process.","['G06N20/00', 'G06F16/2365', 'G06F18/22', 'G06F18/2411', 'G06F18/28', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N7/01', 'G06T9/002', 'G06V30/1914', 'G06V30/2504', 'H04N19/60', 'G06F30/20', 'G06N20/10', 'G06N5/01', 'H04N19/96']"
CN110378338B,"Text recognition method and device, electronic equipment and storage medium","The embodiment of the application discloses a text recognition method, a text recognition device, electronic equipment and a storage medium; as can be seen from the above, after the image to be identified containing the text information is obtained, the vertex of the area where the text information is located can be determined to obtain a plurality of corner points, then a polygon is drawn in the image to be identified according to the plurality of corner points, and the text information in the polygon is identified to obtain an identification result; the scheme can be suitable for various scenes, and improves the recognition effect under the condition that the object to be recognized is not standard (such as the inclination angle level or the distortion of the text region to be recognized is large).","['G06N3/045', 'G06V10/243', 'G06V10/255', 'G06V30/10']"
CN106485316B,Neural network model compression method and device,"The invention discloses a kind of neural network model compression method and devices.Wherein method includes: that the model parameter set of each neuronal layers is determined for each of neural network model neuronal layers, wherein model parameter set includes multiple model parameters；First transformation is carried out to generate multiple intermediate parameters to multiple model parameters；Multiple intermediate parameters are quantified according to preset quantization step, obtain multiple quantization parameters；According to preset quantization digit, multiple sample quantization points are chosen from multiple quantization parameters；According to the value of multiple quantization parameters and multiple sample quantizations point, the quantized value of multiple model parameters is generated；Compression storage is carried out to multiple model parameters according to quantized value.This method can be better maintained modelling effect, greatly reduce the size of neural network model, reduces computing resource, is especially the reduction of the occupancy of memory source.","['G06N3/02', 'G06N3/06', 'H03M1/38', 'H03M1/54']"
US11269529B2,"Neural network data processing apparatus, method and electronic device","A neural network data processing apparatus includes: an instruction parsing module, configured to split a DMA task into multiple subtasks and acquire configuration information of a data sub-block corresponding to each subtask, where the subtasks are in a one-to-one correspondence with data sub-blocks of transported neural network data; a data reading module, configured to read a first data sub-block according to the configuration information, where the first data sub-block is a data sub-block among data sub-blocks corresponding to multiple subtasks; a data processing module, configured to compress the first data sub-block; a data write-out module, configured to output compressed data resulting from the compression of the first data sub-block.","['G06F3/064', 'G06N3/063', 'G06F13/28', 'G06F3/0623', 'G06F3/0656', 'G06F3/0659', 'G06F9/3004', 'G06F9/4843', 'G06N3/08', 'G06F3/0673', 'G06F9/3836']"
CN112771541B,Data Compression Using Integer Neural Networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for reliably performing data compression and data decompression across a variety of hardware and software platforms using integer neural networks. In one aspect, a method for entropy encoding data defining a sequence comprising a plurality of components is provided, the method comprising, for each of the plurality of components, processing an input comprising (i) a respective integer representation of each of one or more components of the data preceding the component in the sequence, (ii) an integer representation of one or more respective latent variables characterizing the data, or (iii) both, using an integer neural network to generate data defining a probability distribution of the component of the data over a predetermined set of possible code symbols.","['G06T9/002', 'G06N3/045', 'G06F17/18', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/09']"
US10540574B2,Image compression method and related device,"An example image compression method may include acquiring an original image with a first resolution; compressing the original image on the basis of the target model to obtain a compressed image with a second resolution; recognizing the compressed image on the basis of a recognition neural network model to obtain reference tag information; acquiring a loss function according to the target tag information and the reference tag information; if the loss function is convergent to a first threshold value or the present number of training times of the compression neural network is more than or equal to a second threshold value, acquiring a target original image with the first resolution, and determining the target model as a corresponding compression neural network model if training of the compression neural network is completed; compressing the target original image on the basis of the compression neural network model.","['G06N3/084', 'G06K9/6262', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06N3/045', 'G06V10/454', 'G06V10/764', 'H04N19/132', 'H04N19/172', 'H04N19/30', 'H04N19/46', 'H04N19/85', 'G06V10/955', 'G06V20/582', 'G06V40/172']"
CN111683250B,Generation type remote sensing image compression method based on deep learning,"The technical scheme of the invention provides a deep learning-based generation-type remote sensing image compression method. The invention adopts a Pythroch deep learning framework for training, takes an auto encoder (AutoEncoder) + generation confrontation model (GAN) as an example, and a network model is mainly divided into three parts, namely an encoder, a pre-quantization and quantization module, a decoder (generator) and a discriminator. The framework is suitable for compression processing of homologous remote sensing images with any spectral dimension, compression and transmission of remote sensing images under the conditions of low bandwidth and low code rate, has excellent image reconstruction capability, is optimized for the scale and the running speed of a deep neural network, and is convenient for deployment and popularization of equipment facing the Internet of things.","['H04N19/42', 'G06N3/045', 'G06N3/08', 'H04N19/124', 'H04N19/147', 'H04N19/44']"
CN111144561B,Neural network model determining method and device,"The embodiment of the application provides a neural network model determining method and device, wherein the neural network model determining method comprises the following steps: acquiring task configuration parameters of a target task, resource configuration parameters of training resources, model design configuration parameters and model compression configuration parameters; generating an initial neural network model for the target task based on the task configuration parameters, the resource configuration parameters and the model design configuration parameters; and selecting a corresponding preset compression mode according to the model compression configuration parameters, and performing compression processing on the initial neural network model to obtain the neural network model to be deployed. By the aid of the method and the device, development efficiency in the process of determining the neural network model can be improved.","['G06N3/082', 'Y02D10/00']"
US8463722B2,Implementing a neural associative memory based on non-linear learning of discrete synapses,"This invention is in the field of machine learning and neural associative memory. In particular the invention discloses a neural associative memory structure for storing and maintaining associations between memory address patterns and memory content patterns using a neural network, as well as methods for retrieving such associations. A method for a non-linear synaptic learning of discrete synapses is disclosed, and its application on neural networks is laid out.","['G06N3/08', 'G06N3/044']"
CN111275175B,"Neural network training method, device, image classification method, device and medium","The disclosure provides a neural network training method, a neural network training device, an image classification method, image classification equipment and a neural network training medium. The neural network training method comprises the following steps: obtaining a source domain and a target domain, wherein the source domain comprises a plurality of first samples and the target domain comprises a plurality of second samples; determining category weights of various categories corresponding to a source domain and a target domain respectively, and calculating a soft weight maximum mean difference of the source domain and the target domain based on the category weights; calculating redundancy values for network compression based on the batch normalization layer coefficients of the neural network; and training the neural network based on the soft weight maximum mean difference and the redundancy value.","['G06N3/045', 'G06N20/00', 'G06N3/082', 'G06N3/084']"
CN117121480A,High level syntax for signaling neural networks within a media bitstream,"An example method is provided, comprising: receiving a media bitstream comprising one or more media units and a first enhancement information message, wherein the first enhancement information message comprises at least two independently resolvable structures, a first independently resolvable structure comprising information related to at least one purpose of one or more Neural Networks (NN) to be applied to the one or more media units, and a second independently resolvable structure comprising or identifying the one or more neural networks; decoding one or more media units; and based on at least one purpose, enhancing or filtering the one or more frames of the decoded one or more media units using one or more neural networks. Example methods include. Corresponding apparatus and computer program products are also provided.","['A61B5/4839', 'H04N19/463', 'A61B5/7275', 'A61M5/1723', 'G06N3/04', 'G06N3/0455', 'G16H20/10', 'G16H20/17', 'G16H50/30', 'G16H50/50', 'H04N19/117', 'H04N19/154', 'H04N19/156', 'H04N19/17', 'H04N19/177', 'H04N19/70', 'H04N21/435', 'H04N21/44', 'A61M2230/201']"
CN106027300B,A kind of intelligent robot Parameter Optimization System and method using neural network,"The present invention relates to a kind of intelligent robot Parameter Optimization Systems and method using neural network, are related to intelligent robot parameter optimization field.Parameter optimization and compression process are completed by cloud server, to reduce the operand of terminal machine people.The system includes at least one cloud server and at least one terminal machine people, the terminal machine people and cloud server pass through network connection, terminal machine people is internally embedded the terminal neural network module calculated for positive transmission, and cloud server is embedded in the cloud neural network module for optimizing parameter according to sample database.Method includes the following steps: terminal machine people identifies and acquires to environmental information and action command；Different cloud neural network modules carry out parameter optimization to different types of information and store；Judge whether to compress the parameter optimisation procedure of neural network module；Parameter after optimization is compressed.The present invention is suitable for intelligent robot neural network module parameter optimization.","['H04L41/0813', 'G06N3/045', 'H04L41/0246', 'H04L41/0803']"
US20180053091A1,System and method for model compression of neural networks for use in embedded platforms,"Embodiments of the present disclosure include a non-transitory computer-readable medium with computer-executable instructions stored thereon executed by one or more processors to perform a method to select and implement a neural network for an embedded system. The method includes selecting a neural network from a library of neural networks based on one or more parameters of the embedded system, the one or more parameters constraining the selection of the neural network. The method also includes training the neural network using a dataset. The method further includes compressing the neural network for implementation on the embedded system, wherein compressing the neural network comprises adjusting at least one float of the neural network.","['G06N3/08', 'G06N3/04', 'G06N3/045']"
WO2019205391A1,"Apparatus and method for generating vehicle damage classification model, and computer readable storage medium","An apparatus for generating a vehicle damage classification model, comprising a memory and a processor, a model generating program capable of running on the processor being stored on the memory, and the program implementing the following steps when executed by the processor: preparing an original vehicle damage photograph for each vehicle damage part, using the original vehicle damage photograph as a sample image after labelling and pre-processing, and constructing a sample library (S10); using the images in the sample library as input data for a vgg network, and implementing pruning of the vgg network according to a preset pruning algorithm and a preset compression rate (S20); on the basis of the pruned vgg network, constructing a vehicle damage classification model, and using the sample images in the sample library to train the vehicle damage classification model in order to determine model parameters of the vehicle damage classification model (S30); Also provided are a method for generating the vehicle damage classification model, and a computer readable storage medium, for solving the technical problem in the prior art of being unable to implement vehicle damage assessment on a mobile device by means of a convolutional neural network model.","['G06V20/20', 'G06N3/082', 'G06Q40/08']"
US20190392300A1,Systems and methods for data compression in neural networks,"A method for processing a neural network includes performing a decompression step before executing operations associated with a block of layers of the neural network, performing a compression step after executing operations associated with the block of layers of a neural network, gathering performance indicators for the executing the operations associated with the block of layers of the neural network, and determining whether target performance metrics have been met with a compression format used for at least one of the decompression step and the compression step.","['G06N3/08', 'H03M7/70', 'G06N3/04', 'G06N3/063', 'G06N3/082', 'H03M7/3059']"
TW202137142A,Apparatus and method for displaced mesh compression,"Apparatus and method for lossy displaced mesh compression. For example, one embodiment of an apparatus comprises: displacement mapping circuitry/logic to generate an original displacement-mapped mesh by performing a displacement mapping of a plurality of vertices of a base subdivision mesh; and mesh compression circuitry/logic to compress the original displacement-mapped mesh, the mesh compression circuitry/logic comprising a quantizer to quantize the displacement mapping of the plurality of vertices in view of a base mesh to generate a displacement array.","['G06T9/001', 'G06T17/205', 'G06T9/00', 'G06T17/20', 'G06F9/5027', 'G06T1/20', 'G06T15/005', 'G06T15/06', 'G06T15/08', 'G06T17/10', 'G06T3/4007', 'G06T2200/28']"
WO2020190772A1,Neural network model compression and optimization,Apparatus and methods for compressing a deep convolutional neural network (CNN) compress the CNN feature map and weight tensors with relatively high inference speed to optimize a rate-distortion-speed (RDS) objective function. The method reorders a weight tensor into blocks compatible with a matrix multiplication operation. The reordered weight tensor is then quantized to provide a quantized reordered weight tensor. An input feature map is multiplied by the quantized reordered weight tensor to provide an output feature map. The output feature map and the weight tensor are compressed for transmission to other devices to allow the CNN to be reconstituted on the other devices.,"['G06N3/063', 'G06N3/045', 'G06N3/048', 'G06N5/01', 'G06N3/084']"
US20240135180A1,Systems of neural networks compression and methods thereof,"Systems and methods provide improved neural network compression by training, based on training data and an optimization problem, a deep neural network to produce a trained deep neural network by iteratively updating a weight matrix of the deep neural network according to, at each iteration, minimizing a rank value of the weight matrix until a memory capacity metric is satisfied, minimizing a loss function based on the training data and the weight matrix and updating the weight matrix, and terminating the iterations upon the loss function being minimized within the memory capacity metric. Tensor decomposition is used to compress the trained deep neural network based on the rank value and the weight matrix to obtain a trained tensor decomposition format deep neural network. The trained tensor decomposition format deep neural network is retrained with the training data to obtain a fine-tuned trained tensor decomposition format deep neural network.","['G06N3/09', 'G06N3/08', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/063', 'H03M7/3059']"
WO2022006919A1,Activation fixed-point fitting-based method and system for post-training quantization of convolutional neural network,"An activation fixed-point fitting-based method and system for the post-training quantization of a convolutional neural network, which aims to solve the problem in the existing technology in which the post-training quantization of a convolutional neural network cannot be implemented by means of a more efficient low-bit quantization method. The quantization method comprises: performing low-bit fixed-point quantization on a weight matrix of each layer of an original convolutional neural network; obtaining a group of verification data, constructing an optimized target function from input activation to output activation, iteratively optimizing a fixed-point weight matrix and a weight quantization scale factor, and obtaining a weight fixed-point quantization convolutional neural network; and on the basis of the verification data and the weight fixed-point quantization convolutional neural network, solving an activation quantization scale factor, and obtaining a weight-activated fixed-point convolutional neural network. By means of directly learning a low-bit mapping function from input activation to output activation, it is ensured that the convolution output before and after weight quantization is similar, the accuracy of a quantized model is high, and the quantization process does not require the use of data for retraining.","['G06N3/045', 'G06N3/08']"
US20190190538A1,Accelerator hardware for compression and decompression,"A system may include a memory device that stores parameters of a layer of a neural network that have been compressed. The system may also include a special-purpose hardware processing unit programmed to, for the layer of the neural network: (1) receive the compressed parameters from the memory device, (2) decompress the compressed parameters, and (3) apply the decompressed parameters in an arithmetic operation of the layer of the neural network. Various other methods, systems, and accelerators are also disclosed.","['H03M7/6011', 'G06N3/02', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'H03M7/30', 'H03M7/6094', 'H03M7/70', 'G06N3/044']"
US12026925B2,Channel-wise autoregressive entropy models for image compression,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for channel-wise autoregressive entropy models. In one aspect, a method includes processing data using a first encoder neural network to generate a latent representation of the data. The latent representation of data is processed by a quantizer and a second encoder neural network to generate a quantized latent representation of data and a latent representation of an entropy model. The latent representation of data is further processed into a plurality of slices of quantized latent representations of data wherein the slices are arranged in an ordinal sequence. A hyperprior processing network generates a hyperprior parameters and a compressed representation of the hyperprior parameters. For each slice, a corresponding compressed representation is generated using a corresponding slice processing network wherein a combination of the compressed representations form a compressed representation of the data.","['G06N3/088', 'G06T9/002', 'G06F17/18', 'G06N3/045', 'G06N3/08']"
US12225239B2,High-fidelity generative image compression,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an encoder neural network configured to receive a data item and to process the data item to output a compressed representation of the data item. In one aspect, a method includes, for each training data item: processing the data item using the encoder neural network to generate a latent representation of the training data item; processing the latent representation using a hyper-encoder neural network to determine a conditional entropy model; generating a compressed representation of the training data item; processing the compressed representation using a decoder neural network to generate a reconstruction of the training data item; processing the reconstruction of the training data item using a discriminator neural network to generate a discriminator network output; evaluating a first loss function; and determining an update to the current values of the encoder network parameters.","['H04N19/463', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'H04N19/124', 'H04N19/154', 'H04N19/91']"
EP3651069A1,"Data processing device, data processing method, and compressed data","A data processing unit (101) processes input data using a neural network. A compression controlling unit (102) generates quantization information that defines quantization steps. An encoding unit (103) encodes network configuration information including parameter data which is quantized using the quantization steps determined by the compression controlling unit (102), and the quantization information, to generate compressed data.","['G06N3/0495', 'G06N3/063', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H03M7/30', 'G06N3/048']"
US20180046914A1,Compression method for deep neural networks with load balance,"The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a compression method considering load balance for deep neural networks and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks in an efficient way so as to improve utilization of resources of the hardware platform.","['G06N3/08', 'G06N3/082', 'G06N3/044', 'G06N3/045']"
US20180046919A1,Multi-iteration compression for deep neural networks,"The present invention relates to artificial neural networks, for example, deep neural networks. In particular, the present invention relates to a multi-iteration compression method for deep neural networks and the device thereof. More specifically, the present invention relates to how to compress dense neural networks into sparse neural networks without degrading the accuracy of the neural","['G06N3/082', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G10L15/16']"
US20180260695A1,Neural network compression via weak supervision,"A method, a computer-readable medium, and an apparatus for compressing a neural network with an unlabeled data set are provided. The apparatus may generate a first set of consecutive layers for the neural network. The first set of consecutive layers may share inputs with a second set of consecutive layers of the neural network. The apparatus may adjust weights associated with the first set of consecutive layers based on a function the difference between a first set of output values from the first set of consecutive layers and a second set of output values from the second set of consecutive layers in response to the unlabeled data set. The apparatus may remove the second set of consecutive layers from the neural network when the function of the difference between the first set of output values and the second set of output values satisfies a threshold.","['G06N3/08', 'G06N3/082', 'G06N3/045', 'G06N3/084']"
US20210216871A1,Fast Convolution over Sparse and Quantization Neural Network,"Processes and systems are disclosed. The processes and systems are arranged to apply convolution for a CNN where the CNN is simplified using sparse techniques, quantization techniques or both sparse and quantization techniques. A location vector (LV) table is provided to record the coordinates of non-zero weights. A look up table is provided to recover the real weight value from the weight identification. Convolution is applied by retrieving the coordinates of the next non-zero weight and the associated real weight value and by accumulating the multiplication of the real weight value and the input value across the input activation plane.","['G06N3/08', 'G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/084']"
US20230074979A1,Instance-adaptive image and video compression in a network parameter subspace using machine learning systems,"Techniques are described for compressing data using machine learning systems. An example process can include receiving input data for compression by a neural network compression system. The process can include determining, based on the input data, a set of updated model parameters for the neural network compression system, wherein the set of updated model parameters is selected from a subspace of model parameters. The process can include generating at least one bitstream including a compressed version of the input data and a compressed version of one or more subspace coordinates that correspond to the set of updated model parameters. The process can include outputting the at least one bitstream for transmission to a receiver.","['G06N3/08', 'H04N19/426', 'H04N19/196', 'G06F18/211', 'G06K9/6228', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'H04N19/124', 'H04N19/13', 'H04N19/147', 'H04N19/91', 'G06N3/063']"
CN104537415B,A kind of non-linear process industry failure predication and recognition methodss based on compressed sensing and DROS ELM,"The invention provides a kind of high performance non-linear process industry failure predication and recognition methodss, Complex Industrial Systems nonlinear production process is overcome to lack the difficulty of online failure predication and identification, compressed sensing and artificial neural network are applied to into industrial circle, the failure predication identification model based on compressed sensing feature extraction and dynamical feedback OS ELM neutral nets (DROS ELM) technology is built respectively, realize failure predication, ensure to keep the safety in production for enterprise, improve production efficiency, saving production cost provide technical support.",[]
US20210326710A1,Neural network model compression,"Methods and apparatuses of neural network model compression/decompression are described. In some examples, an apparatus of neural network model decompression includes receiving circuitry and processing circuitry. The processing circuitry can be configured to receive a dependent quantization enabling flag from a bitstream of a compressed representation of a neural network. The dependent quantization enabling flag can indicate whether a dependent quantization method is applied to model parameters of the neural network. The model parameters of the neural network can be reconstructed based on the dependent quantization method in response to the dependent quantization enabling flag indicating the dependent quantization method is used for encoding the model parameters of the neural network.","['G06N3/0455', 'G06N3/02', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/084', 'H03M7/3064', 'H03M7/3082', 'H03M7/6005', 'H04N19/124', 'H04N19/184', 'H04N19/44', 'H04N19/597', 'H04N19/70', 'H04N19/96']"
US20180096249A1,Convolutional neural network system using adaptive pruning and weight sharing and operation method thereof,"Provided is a method for operating a convolutional neural network. The method includes performing learning on weights between neural network nodes by using input data, removing an adaptive parameter that performs learning using the input data after removing a weight having a size less than a threshold value among weights, and mapping remaining weights in the removing of the adaptive parameter to a plurality of representative values.","['G06N3/082', 'G06N3/045']"
CN113011581B,"Neural network model compression method and device, electronic equipment and readable storage medium","The invention discloses a neural network model compression method, a neural network model compression device, electronic equipment and a readable storage medium. Wherein, the method comprises the following steps: inputting a neural network to be compressed into a compression model which is trained in advance, wherein the compression model comprises a channel pruning module and a self-distillation quantification module; performing channel pruning operation on a neural network to be compressed through a channel pruning module to obtain a first output; and carrying out self-distillation quantization operation on the first output through a self-distillation quantization module to obtain the target neural network. The invention solves the technical problem that the compressed neural network model generates larger precision loss in the related technology.","['G06N3/082', 'G06N3/04', 'Y02D10/00']"
US11551094B2,System and method for deep neural network compression,"A system and a method are provided for compressing a deep neural network (“DNN”). In some examples, the DNN is trained, where the DNN has at least one layer having multiple filters. Clustering of the filters of at least one layer is performed. Dimension reduction can be applied as well to the filters to reduce the channel dimensionality of the at least one layer. The dimensionally reduced DNN can then be retrained. Once retrained, the compressed DNN can be stored in a storage device.","['G06N3/082', 'G06F18/22', 'G06F18/23', 'G06K9/6215', 'G06K9/6218', 'G06N3/045', 'H04W4/40', 'H04W4/44']"
US11838519B2,"Image encoding/decoding method and apparatus for signaling image feature information, and method for transmitting bitstream","An image encoding/decoding method and apparatus are provided. An image decoding method comprises obtaining, from a bitstream, encoded data of feature information generated by applying an artificial neural network-based feature extraction method to an image, reconstructing feature information by decoding the encoded data of the feature information, and generating analysis data of the image based on the feature information.","['H04N19/70', 'G06N20/00', 'G06N3/04', 'G06N3/08', 'G06T9/002', 'H04N19/124', 'H04N19/136', 'H04N19/167', 'H04N19/17', 'H04N19/184', 'H04N19/188', 'H04N19/423', 'H04N19/60', 'H04N19/61', 'G06T2207/20084']"
US20220261616A1,Clustering-based quantization for neural network compression,"Systems, methods, and instrumentalities are disclosed for clustering-based quantization for neural network (NN) compression. A distribution of weights in weight tensors in NN layers may be analyzed to identify cluster outliers. Cluster inliers may be coded from cluster outliers, for example, using scalar and/or vector quantization. Weight-rearrangement may rearrange weights for higher dimensional weight tensors into lower dimensional matrices. For example, weight rearrangement may flatten a convolutional kernel into a vector. Correlation between kernels may be preserved, for example, by treating a filter or kernels across a channel as a point. A tensor may be split into multiple subspaces, for example, along an input and/or an output channel. Predictive coding may be performed for a current block of weights or weight matrix based on a reshaped or previously coded block or matrix. Arrangement, inlier, outlier, and/or prediction information may be signaled to a decoder for reconstruction of a compressed NN.","['G06N3/04', 'G06N3/063', 'G06N3/045', 'G06N3/082']"
TW202234890A,Encoding by indicating feature map data,"The present disclosure relates to methods and apparatuses for encoding data for (still or video processing into a bitstream). In particular, the data are processed by a network which includes a plurality of cascaded layers. In the processing, feature maps are generated by the layers. The feature maps processed (output) by at least two different layers have different resolutions. In the processing, a layer is selected, out of the cascaded layers, which is different from the layer generating the feature map of the lowest resolution (e.g. latent space). The bitstream includes information related to the selected layer. With this approach, scalable processing which may operate on different resolutions is provided so that the bitstream may convey information relating to such different resolutions. Accordingly, the data may be efficiently coded within the bitstream, depending on the resolution which may vary depending on the content of the picture data coded.","['H04N19/46', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'H04N19/132', 'H04N19/59', 'H04N19/70']"
CN111723915B,Target detection method based on deep convolutional neural network,"The invention relates to a target detection method based on a deep convolutional neural network, wherein the pruning method of the deep convolutional neural network comprises the following steps: (1) performing a convolution kernel spectral clustering algorithm by taking the layer as a unit; (2) performing intra-layer convolution kernel pruning, dynamically calculating the spectral clustering pruning rate of the current round, pruning convolution kernels of non-clustering centers, and finely adjusting a certain number of rounds to recover the precision; (3) calculating the importance of a convolution kernel by taking the whole situation as a unit; (4) carrying out global convolution kernel pruning, dynamically calculating the global pruning rate of the round, pruning a convolution kernel with low importance, and finely adjusting a certain round number to restore the precision; (5) circularly executing the steps (1) to (4) until the target pruning rate is reached; (6) and taking the weight of the retained descending convolution kernel as initialization, and continuously fine-tuning a certain number of rounds to obtain the final pruning network. The method solves the problem that the existing deep convolution neural network has a large number of redundant parameters, and realizes the compression and acceleration of the network on a general hardware platform.","['G06N3/045', 'G06F18/23', 'G06F18/241', 'G06N3/082']"
WO2019228082A1,Compression method and system for frequent transmission of deep neural network,"Disclosed are a compression method and system for the frequent transmission of a deep neural network. The deep neural network compression is extended to the field of transmission, and the potential redundancy among deep neural network models is utilized for compressing, so that the overhead of the deep neural network under frequency transmission is reduced. The advantages of the present invention are that: in the present invention, the redundancy among multiple models of the deep neural network on the frequency transmission is combined, knowledge information among deep neural networks is utilized for compressing, and the size and the bandwidth of the required transmission are reduced. The deep neural network can be better transmitted under the same bandwidth limitation; meanwhile, the deep neural network is allowed to be performed targeted compression at a front end, rather than being restored partially after being performed targeted compression.","['G06N3/0495', 'G06N3/082', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/098']"
US20220083866A1,Apparatus and a method for neural network compression,"There is provided an apparatus comprising means for performing: training a neural network by applying an optimization loss function, wherein the optimization loss function considers empirical errors and model redundancy (210); pruning a trained neural network by removing one or more filters that have insignificant contributions from a set of filters (220); and providing the pruned neural network for transmission (230).","['H04L69/04', 'G06F18/2113', 'G06K9/623', 'G06N3/082', 'G06V10/764', 'G06V10/82', 'G06N3/045']"
US20160328644A1,Adaptive selection of artificial neural networks,A method of adaptively selecting a configuration for a machine learning process includes determining current system resources and performance specifications of a current system. A new configuration for the machine learning process is determined based at least in part on the current system resources and the performance specifications. The method also includes dynamically selecting between a current configuration and the new configuration based at least in part on the current system resources and the performance specifications.,"['G06V10/82', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/454']"
CN109523017A,"Compression method, device, equipment and the storage medium of deep neural network","The invention discloses the compression method of deep neural network, device, equipment and storage mediums.This method comprises: determining the different degree of convolution kernel in each convolutional layer of neural network model to be compressed；According to the convolution kernel of minimum different degree to neural network model beta pruning to be compressed, neural network model is obtained；Judge whether neural network model meets compression termination condition；If the neural network model meets compression termination condition, using the neural network model as target depth neural network；If the neural network model does not meet compression termination condition, repeat using the neural network model as the operation of neural network model beta pruning to be compressed.Using this method, operational efficiency of the deep neural network model on embedded platform is effectively increased, while also having simplified the memory space of deep neural network model, and then also improves the user experience for relying on the application product of deep neural network model.","['G06N3/045', 'G06F18/2413', 'G06N3/082', 'G06V40/10']"
KR20190130455A,A method and a system for constructing a convolutional neural network (cnn) model,"Provided is a method for constructing a convolutional neural network. The method regularizes a spatial domain weight, provides quantization to the spatial domain weight, prunes a weight smaller than a predetermined threshold in a spatial domain, fine-tunes a quantization codebook, compresses quantization output from the quantization codebook, decompresses the spatial domain weight, and uses sparse Winograd domain convolution or uses sparse Winograd convolution after pruning a Winograd-domain weight.","['G06N3/0464', 'G06N3/082', 'G06N3/04', 'G06N3/045', 'G06N3/0495', 'G06N3/08', 'G06N3/084']"
CN111275190B,"Compression method and device of neural network model, image processing method and processor","The application discloses a compression method and device of a neural network model, an image processing method and an image processor, and relates to the field of neural network compression. The compression method of the neural network model comprises the following steps: establishing a search space corresponding to each neural network layer of the neural network model, wherein the search space comprises candidate pruning rates; the candidate pruning rate of each search space is input into a pruning strategy generation model to obtain a pruning strategy; pruning is carried out on the neural network model according to the pruning strategy. Because the corresponding search space is established for each neural network layer, the pruning rates corresponding to the neural network layers can be different, and the technical problems that the speed of the neural network model is not obvious after pruning and the performance of the model is poor due to the fact that the pruning rates corresponding to the neural network layers are the same are overcome, and the speed and the performance of the neural network model are effectively improved.","['G06N3/082', 'Y02D10/00']"
WO2019060670A1,Compression of sparse deep convolutional network weights,"The present disclosure describes methods, computer-readable media, and apparatuses for operating neural networks. For example, a first apparatus may receive a set of sparse weight vectors. The first apparatus may compress the set of sparse weight vectors to produce a compressed set of sparse weight vectors. The first apparatus may operate a neural network based on the compressed set of sparse weight vectors. In another example, a second apparatus may receive a set of sparse weight vectors. The second apparatus may perform a sparse computation based on the set of sparse weight vectors, and the performance of the sparse computation may produce one or more partial sums. The second apparatus may operate a neural network based at least in part on the one or more partial sums.","['G06N3/063', 'G06F7/5443', 'G06N3/045', 'G06N3/084', 'G06N3/044', 'G06N3/047']"
US20240313838A1,Techniques for channel state information and channel compression switching,"Methods, systems, and devices for wireless communications are described. A wireless communications system may support compression of channel information (e.g., channel feedback) in accordance with multiple compression schemes, from which a transmitting device may select for a channel reporting transmission. For example, a user equipment (UE) may be configured with multiple channel state information compression schemes, corresponding to different encoders or decoders, which may involve various machine learning or neural network techniques. The UE may select or otherwise determine which compression scheme to use for channel reporting in various scenarios, including a selection based on whether a compression scheme maintains relatively accurate reporting, or whether a more power-intensive or processor-intensive compression scheme is supported by an operating mode of the UE, among other selection criteria. The UE may indicate which compression scheme was selected by a transmitted indication included with or otherwise accompanying a channel reporting transmission.","['H04B7/0626', 'H04B7/063', 'H04B7/0632', 'H04B7/0639', 'H04B7/0658']"
CN110751260B,"Electronic device, task processing method and neural network training method","The embodiment of the application provides electronic equipment, a task processing method and a neural network training method. The method comprises the following steps: and acquiring input data corresponding to the task, respectively carrying out corresponding processing on the input data through each neural network corresponding to the task, and then determining a processing result corresponding to the task based on the processing result of each neural network and the neural network weight information corresponding to the task. The embodiment of the application reduces the calculation cost and the storage cost of the neural network, thereby reducing the processing complexity of the task.","['G06N3/045', 'G06N3/08', 'Y02D10/00']"
US20210264266A1,Split Architecture for Artificial Intelligence-Based Base Caller,"The technology disclosed relates to a system that comprises a spatial convolution network and a bus network. The spatial convolution network is configured to process a window of per-cycle sequencing image sets on a cycle-by-cycle basis by separately processing respective per-cycle sequencing image sets through respective spatial processing pipelines to generate respective per-cycle spatial feature map sets for respective sequencing cycles. The bus network is configured to form buses between spatial convolution layers within the respective spatial processing pipelines. The buses are configured to cause respective per-cycle spatial feature map sets generated by two or more spatial convolution layers in a particular sequence of spatial convolution layer for a particular sequencing cycle to combine into a combined per-cycle spatial feature map set, and provide the combined per-cycle spatial feature map set as input to another spatial convolution layer in the particular sequence of spatial convolution layer.","['G06N3/084', 'C12Q1/6869', 'G06F18/23', 'G06K9/6218', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06V10/454', 'G06V10/762', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G16B30/00', 'G16B30/20', 'G16B40/10', 'G16B40/20']"
CN110574044A,Method and apparatus for augmenting binary weight neural networks using dependency trees,"Methods and apparatus for enhancing binary weighted neural networks using dependency trees are disclosed. A method of enhancing a Convolutional Neural Network (CNN) with binary weights includes constructing a tree for the obtained binary tensors, the tree having a plurality of nodes beginning at a root node in each layer of the CNN. The convolution of the input feature map with the input binary tensor is computed at the root node of the tree. A next node is searched from a root node of the tree and a convolution is calculated at the next node using a previous convolution result calculated at the root node of the tree. Starting from the root node, the search for the next node is repeated for all nodes starting from the root node of the tree, and the convolution is calculated at each next node using the previous convolution results.","['G06N3/063', 'G06N3/042', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/09', 'G06N5/01', 'G06N3/044', 'G06N3/082', 'G06N3/084']"
US11586924B2,Determining layer ranks for compression of deep networks,An apparatus of operating a computational network is configured to determine a low-rank approximation for one or more layers of the computational network based at least in part on a set of residual targets. A set of candidate rank vectors corresponding to the set of residual targets may be determined. Each of the candidate rank vectors may be evaluated using an objective function. A candidate rank vector may be selected and used to determine the low rank approximation. The computational network may be compressed based on the low-rank approximation. In turn the computational network may be operated using the one or more compressed layers.,"['G06N3/063', 'G06N3/084', 'G06N3/04', 'G06N3/048', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
CN112861602B,Face living body recognition model compression and transplantation method based on depth separable convolution,"The invention relates to a face living body recognition model compression and transplantation method based on depth separable convolution, which comprises the following steps: s1, obtaining a training data set in a data enhancement mode; s2, training the image by using the improved convolutional neural network, and storing a convolutional neural network model obtained after training; s3, compressing the model based on the depth separable convolution, and reducing the size of the model, so that the model parameters are reduced to about 20% of the original model, and the size of the model is more suitable for a mobile terminal. S4, further compressing the model by carrying out semi-precision flow 16 quantization on the model weight, and accelerating the model reasoning speed, so that the model size is compressed to be 50% of the step S3, the recognition speed of the mobile terminal is shortened to 400ms, and the transplanting of the model on the mobile terminal software is completed. The invention compresses the model based on depth separable convolution and the flow 16 semi-precision quantifies.","['G06V40/161', 'G06F18/214', 'G06N3/045', 'G06V40/45', 'Y02T10/40']"
WO2020044527A1,Information processing device,"This information processing device comprises an arithmetic processing unit that realizes an artificial intelligence function by performing a neural network operation on input data. The arithmetic processing unit comprises: an arithmetic circuit that can handle the maximum input channel, output channel, and kernel size when performing a product-sum operation between an input vector and a weighting matrix at each layer of a neural network; an input image temporary storage unit that inputs images to the arithmetic circuit; and an output image temporary storage unit that stores the output from the arithmetic circuit and copies the images to the input image temporary storage unit for the operation to be performed in the next layer.","['G06N3/063', 'G06T7/00']"
US11341415B2,Method and apparatus for compressing neural network,"A method and apparatus for compressing a neural network are provided. A specific embodiment of the method includes: acquiring a to-be-compressed trained neural network; selecting at least one layer from layers of the neural network as a to-be-compressed layer; performing the following processing steps sequentially on each of the to-be-compressed layers in descending order of the number of level of the to-be-compressed layer in the neural network: quantifying parameters of the to-be-compressed layer based on a specified number, and training the quantified neural network based on a preset training sample using a machine learning method; and determining the neural network obtained after performing the processing steps on the selected at least one to-be-compressed layer as a compressed neural network, and storing the compressed neural network. This embodiment achieves efficient compression of the neural network.","['G06N3/10', 'G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/044', 'G06N3/063']"
WO2019127362A1,"Neural network model block compression method, training method, computing device and system","A network model block compression method for use with a neural network, comprising: a step of obtaining a weight matrix, obtaining a weight matrix of a network model of a neural network that is obtained after training; a step of blocking a weight matrix, dividing the weight matrix according to a predetermined array size into an array composed of a plurality of initial sub-blocks; a step of concentrating weighting elements to be cropped, according to the absolute value of weight and the value of matrix elements in the sub-blocks, concentrating matrix elements having a smaller weight by means of row-column exchange into a sub-block to be cropped such that the absolute value of weight and the value of the matrix elements in the sub-block to be cropped are smaller than the absolute value of weight and the value of matrix elements in other sub-blocks not to be cropped; a step of cropping a sub-block, cropping out the weight of the matrix elements in the sub-block to be cropped to obtain a final weight matrix so as to implement the compression of the network model of the neural network. Thus, resources and overhead may be saved, and a large-scale neural network is arranged with limited resources.","['G06N3/063', 'G06N3/08']"
WO2019041833A1,Compression apparatus used for deep neural network,"Provided is an acceleration system used for a deep neural network. The system comprises: a 3D memory, a deep neural network calculation unit connected to a memory controller on a logic layer of a vault of the 3D memory, a router connected to the memory controller, and a compressor and a decompressor, wherein the memory controller of each vault carries out data transmission via the router connected to the memory controller and by means of a network-on-chip; and the compressor is used for compressing data to be compressed which needs to be transmitted in the network-on-chip and is used for the deep neural network, and the decompressor is used for decompressing data to be decompressed which comes from the network-on-chip and is used for the deep neural network.","['G06N3/04', 'G06N3/063']"
CN111079923B,Spark convolutional neural network system suitable for edge computing platform and circuit thereof,"The application provides a Spark convolutional neural network system and a circuit thereof, which are applicable to an edge computing platform; the basic building module of the convolutional neural network provided by the application absorbs the basic module building thought of the SquezeNet, and the module is divided into a compression layer and an expansion layer which are connected in front of and behind. The feature map tensor input to the convolution module also needs to perform a process of compressing and then expanding in the channel direction, so as to reduce the number of parameters of the convolution layer and the calculated amount during the convolution operation. The difference is that in the expansion layer, the application does not adopt the traditional standard convolution kernel, but absorbs the essence of the MobileNet convolution neural network model, and adopts the lightweight depth separable convolution kernel to construct the network layer. The introduction of the depth separable convolution can further reduce the parameter number and the calculation amount of the convolution layer.","['G06N3/063', 'G06F15/781', 'G06N3/045', 'G06N3/048', 'Y02D10/00']"
US20230252273A1,Systems and methods for encoding/decoding a deep neural network,"The disclosure relates to a method comprising, responsive to a determination that at least one first tensor of at least one layer of at least one Deep Neural Network is decomposed into a second tensor and a third tensor whose parameters are encoded in a bitstream, decoding from the bitstream a size of at least one of the second tensor and the third tensor, and decoding the at least one of the second tensor and the third tensor from the bitstream based on the decoded size. Corresponding apparatus, encoding method, signal; bitstream, storage media and encoder and/or decoder devices are also provided.","['G06N3/045', 'G06N3/105', 'G06N3/0495', 'H03M7/3057', 'H03M7/6005', 'G06N3/08', 'H03M7/3059', 'H03M7/70']"
TWI850806B,Attention-based context modeling for image and video compression,"The present invention describes methods and apparatus for entropy encoding and entropy decoding of latent tensors. The method includes: separating the latent tensor into segments in a spatial dimension, wherein each segment includes at least one latent tensor element; processing the arrangement of the segments by a neural network, wherein the neural network includes at least one attention layer; obtaining a probabilistic model for entropy encoding or entropy decoding of latent tensor elements from the processed segments.","['G06N3/088', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N7/01', 'G06V10/44', 'G06V10/82', 'H04N19/119', 'H04N19/13', 'H04N19/436', 'H04N19/91', 'G06N3/044', 'G06N3/048']"
US20220253708A1,Deep neural network compression based on filter importance,"Techniques are provided for compressing deep neural networks using a structured filter pruning method that is extensible and effective. According to an embodiment, a computer-implemented method comprises determining, by a system operatively coupled to a processor, importance scores for filters of layers of a neural network model previously trained until convergence for an inferencing task on a training dataset. The method further comprises removing, by the system, a subset of the filters from one or more layers of the layers based on the importance scores associated with the subset failing to satisfy a threshold importance score value. The method further comprises converting, by the system, the neural network model into a compressed neural network model with the subset of the filters removed.","['G06N3/082', 'G06F18/2115', 'G06F18/214', 'G06F18/2415', 'G06K9/6231', 'G06K9/6256', 'G06N3/045', 'G06N3/063', 'G06N5/04', 'G06V10/82']"
CN109257600A,A kind of adaptive minimizing technology of video compression artifact based on deep learning,"The present invention discloses a kind of adaptive minimizing technology of the video compression artifact based on deep learning, and the compressive features of video frame are automatically extracted using the dense connection convolutional network of depth, can be effectively prevented from conventional method, disadvantage brought by hand-designed filter.The present invention acts on the post-processing stages of video, does not influence the process flow and real-time of existing coding and decoding video algorithm.Image quality prediction model is proposed, realization automatically selects varying strength compression artefacts model, has stronger adaptive ability.Using the compression artefacts of the dense connection convolutional network removal video of depth, which can effectively alleviate gradient disappearance problem, convenient for deepening network structure, enhance non-linear expression's ability of network.At the same time, which can also make full use of the feature of middle layer, not only strengthen the propagation and multiplexing of feature, and greatly reduce the parameter amount of network.","['H04N19/86', 'H04N19/117']"
CN116546221A,Compress images using neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for compressing images using a neural network. One of the methods includes receiving an image; processing the image using an encoder neural network, wherein the encoder neural network is configured to receive the image and process the image to generate an output defining values of a first number of latent variables, each latent variable representing a feature of the image; generating a compressed representation of the image using the output defining values of the first number of latent variables; and providing the compressed representation of the image for generating a reconstruction of the image. By compressing an image using latent variables defined by the output of the encoder neural network, an improved lossy image compression scheme, i.e., a scheme that improves compression quality, can be achieved.","['H04N19/42', 'G06T9/002', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/0495', 'G06N3/08', 'G06V10/82', 'H04N19/30', 'H04N19/44']"
US20210241094A1,Rank selection in tensor decomposition based on reinforcement learning for deep neural networks,"Tensor decomposition can be advantageous for compressing deep neural networks (DNNs). In many applications of DNNs, reducing the number of parameters and computation workload is helpful to accelerate inference speed in deployment. Modern DNNs comprise multiple layers with multi-array weights where tensor decomposition is a natural way to perform compression—in which the weight tensors in convolutional layers or fully-connected layers are decomposed with specified tensor ranks (e.g., canonical ranks, tensor train ranks). Conventional tensor decomposition with DNNs involves selecting ranks manually, which requires tedious human efforts to finetune the performance. Accordingly, presented herein are rank selection embodiments, which are inspired by reinforcement learning, to automatically select ranks in tensor decomposition. Experimental results validate that the learning-based rank selection embodiments significantly outperform hand-crafted rank selection heuristics on a number of tested datasets, for the purpose of effectively compressing deep neural networks while maintaining comparable accuracy.","['G06N3/08', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/088']"
US10834114B2,Multi-tiered server architecture to mitigate malicious traffic,"A processing system having at least one processor may obtain domain name system (DNS) traffic records of a DNS platform, the DNS traffic records associated with a source device having a first status and that is submitting DNS queries, where a first-tier DNS authoritative server of the DNS platform is configured to forward the DNS queries from the source device to at least a first second-tier DNS authoritative server of the DNS platform designated for the first status. The processing system may further detect anomalous DNS traffic records from the DNS traffic records, identify a change of the source device from a first status to a second status, based upon the detecting the anomalous DNS traffic records, and reconfigure the first-tier DNS authoritative server to redirect the DNS queries from the source device to at least a second second-tier DNS authoritative server designated for the second status.","['G06N3/088', 'G06N20/00', 'G06N3/045', 'H04L41/0816', 'H04L41/142', 'H04L41/16', 'H04L61/1511', 'H04L61/4511', 'H04L63/10', 'H04L63/1425', 'H04L63/1458', 'G06N3/0454', 'G06N3/084', 'H04L43/0817']"
US10827952B2,Electrocardiographic biometric authentication,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for obtaining an electrocardiographic (ECG) signal of a user; obtaining a feature vector of the ECG signal of the user with neural network based feature extraction. Comparing the feature vector of the ECG signal with a stored feature vector of a registered user. Authenticating the user in response to determining that a similarity of the ECG feature vector of the ECG signal and the stored ECG feature vector of the registered user exceeds a pre-defined threshold value.","['A61B5/117', 'A61B5/0452', 'A61B5/04525', 'A61B5/0456', 'A61B5/349', 'A61B5/35', 'A61B5/352', 'A61B5/7203', 'A61B5/7246', 'G06F21/32', 'G06K9/00885', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06V40/10', 'H04L29/06', 'H04L9/40', 'H04W12/0605', 'H04W12/065', 'G06K2009/00939', 'G06V40/15', 'H04L63/0861']"
CN107563965A,Jpeg compressed image super resolution ratio reconstruction method based on convolutional neural networks,"The invention discloses a kind of jpeg compressed image super resolution ratio reconstruction method based on convolutional neural networks.Mainly include the following steps that：For jpeg compressed image, the Super-resolution reconstruction established model based on convolutional neural networks is built；Using training image, the convolutional neural networks of structure are trained；The low-resolution image through JPEG compression is rebuild using the convolutional neural networks model trained.The convolutional neural networks framework built in the present invention can be optimized training end to end by going pinch effect network, increase resolution network and quality enhancing network to form to it.The method of the invention can reduce the compression noise in jpeg compressed image and improve its resolution ratio.The inventive method can be applied to the field such as image and video compress, Digital multimedia communications.",[]
CN113595993B,A joint learning method for vehicle sensing equipment based on model structure optimization under edge computing,"The invention discloses a vehicle-mounted sensing equipment joint learning method for model structure optimization under edge calculation, which comprises the following steps of: establishing a neural network model suitable for the vehicle-mounted equipment as a local model according to a target detection algorithm adopted by the vehicle-mounted equipment, training the local model by using an initialization parameter provided by a central server, and updating a local gradient to obtain an updated gradient; carrying out gradient sparsification, local gradient quantification and lossless compression treatment on the local model; uploading the quantized local gradient and the compressed binary mask matrix to a central server in a pipeline form; after the vehicle-mounted equipment completes the gradient compression and uploading of the local model, the central server performs neuron-by-neuron gradient aggregation; and acquiring a global aggregation gradient through the vehicle-mounted equipment, updating the local model, and sensing the road by using the updated model.","['H04L63/0428', 'G06F9/5072', 'G06N3/045', 'G06N3/082', 'H04L41/145', 'H04L63/0407', 'H04L67/10', 'H04L67/125', 'H04L67/34', 'Y02T10/40']"
CN113726375B,Channel information compression feedback reconstruction method based on deep learning,"The invention discloses a channel information compression feedback reconstruction method based on deep learning, which comprises the following steps: preprocessing the channel state information data; establishing a channel information compression feedback model; compressing and decompressing channel information through a feedback model; carrying out generalization training on the feedback model; evaluating the compression feedback reconstruction; the compression feedback models are easy to realize, are suitable for compression feedback of channel state information configured in different scenes, and have strong adaptability; by the preprocessing step of the channel state information matrix, the problem that the channel state information matrix is too large for a large-scale MIMO system is solved by utilizing the characteristic that the channel matrix is sparse in an angle domain; finer characteristics can be better extracted, the sparsity of channel state information in actual tasks is adapted, and the robustness and the application universality of the model are improved; the method can reserve the complete information of the channel with higher integrity, approach lossless transmission and greatly improve the feedback performance of the channel information.","['H04B7/0413', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'H04B7/0456', 'H04B7/0626']"
CN111339433B,Information recommendation method and device based on artificial intelligence and electronic equipment,"The invention provides an information method, an information device, electronic equipment and a computer readable storage medium based on artificial intelligence; the method comprises the following steps: determining a corresponding first click rate based on a plurality of logistic regression features of each piece of information in a first information set, and selecting a plurality of pieces of information sorted at the front from descending sorting results of the first click rate to form a second information set; compressing the multiple logistic regression features of each piece of information in the second information set to obtain multiple shared features corresponding to each piece of information; determining a corresponding second click rate based on a plurality of shared features of each information in the second information set; and executing recommendation operation based on the descending sorting result of the second click rate of each information in the second information set. By the method and the device, the complexity of characteristic engineering can be reduced, and the recommendation response speed can be improved.","['G06F16/9535', 'G06F16/9538', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084']"
CN109543829A,Method and system for hybrid deployment of deep learning neural network on terminal and cloud,"The invention provides a method and a system for hybrid deployment of a deep learning neural network on a terminal and a cloud, wherein a distributed system architecture is adopted, the cloud and the terminal are used for hybrid deployment of the neural network, and the neural network and the cloud and the terminal are matched with each other to jointly complete a reasoning operation task; the method comprises the steps of deploying a trained deep neural network compression model on terminal equipment and deploying a deep neural network on a cloud terminal. The invention enhances the sensor fusion, data privacy and system fault tolerance capabilities through distributed computing, and allows early exit points to be placed in the terminal equipment. The image classification can be finished and quit on the local terminal, and the rapid local inference can be carried out; the deep neural network of the cloud can be further utilized for processing, so that the performance precision of the system is improved.","['G06N3/063', 'G06N3/045', 'G06N3/08']"
US20210281491A1,Compressed transmission of network data for networking machine learning systems,"In one embodiment, a service receives telemetry data indicative of a plurality of performance metrics captured in a network. The service jointly trains, using the received telemetry data, a compression model and an inference model, the compression model being a first machine learning model trained to convert the telemetry data into a compressed representation of the telemetry data and the inference model being a second machine learning model trained to take the compressed representation of the telemetry data as input and apply a classification label to it. The service deploys the compression model to the network. The service receives compressed telemetry data generated by the compression model deployed to the network. The service uses the inference model to classify the compressed telemetry data generated by the compression model deployed to the network.","['H04L43/08', 'G06F18/24', 'G06F18/24137', 'G06K9/6267', 'G06N3/045', 'G06N3/084', 'H04L41/145', 'H04L41/16', 'H04L41/5019', 'H04L47/2441', 'G06N3/044', 'H04L41/142', 'H04L41/147', 'H04L41/149']"
WO2022110638A1,"Human image restoration method and apparatus, electronic device, storage medium and program product","A human image restoration method and apparatus, an electronic device, a storage medium and a program product. Said method comprises: acquiring a facial image to be restored (S21); extracting a brightness channel of the facial image to be restored, and performing human image restoration on the basis of the brightness channel, so as to obtain a target facial image (S22); fusing color channels of the target facial image and the facial image to be restored, so as to obtain a first facial restored image (S23); and performing image transformation processing on the first facial restored image, so as to obtain a second facial restored image (S24). Said method facilitates improving the quality of a restored facial image and improving the overall restoration effect of the facial image.","['G06T5/77', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'G06T5/73', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'Y02D10/00']"
US11310498B2,Receptive-field-conforming convolutional models for video coding,"An apparatus for encoding a block of a picture includes a convolutional neural network (CNN) for determining a block partitioning of the block, the block having an N×N size and a smallest partition determined by the CNN being of size S×S. The CNN includes feature extraction layers; a concatenation layer that receives, from the feature extraction layers, first feature maps of the block, where each first feature map of the first feature maps is of the smallest possible partition size S×S of the block; and at least one classifier that is configured to infer partition decisions for sub-blocks of size (αS)×(αS) of the block, where α is a power of 2.","['H04N19/119', 'H04N19/147', 'H04N19/176', 'H04N19/19']"
CN110555508B,Artificial neural network adjusting method and device,"A method and apparatus for tuning an Artificial Neural Network (ANN) is provided. The ANN includes at least a plurality of layers, the method comprising: acquiring a neural network model to be trained; training the neural network model using high bit fixed point quantization to obtain a trained high bit fixed point quantized neural network model; fine-tuning the high-bit fixed-point quantized neural network model using low bits to obtain a trained neural network model with low-bit fixed-point quantization; and outputting the trained neural network model with low-bit specific-point quantization. The neural network training scheme with gradually reduced bit width gives consideration to the training and deployment of the neural network, so that the calculation precision comparable to that of a floating point network can be realized under the condition of extremely low bit width.","['G06N3/045', 'G06N3/08']"
US11324418B2,Multi-coil magnetic resonance imaging using deep learning,"Techniques for generating magnetic resonance (MR) images from MR data obtained by a magnetic resonance imaging (MRI) system comprising a plurality of RF coils configured to detect RF signals. The techniques include: obtaining a plurality of input MR datasets obtained by the MRI system to image a subject, each of the plurality of input MR datasets comprising spatial frequency data and obtained using a respective RF coil in the plurality of RF coils; generating a respective plurality of MR images from the plurality of input MR datasets by using an MR image reconstruction technique; estimating, using a neural network model, a plurality of RF coil profiles corresponding to the plurality of RF coils; generating an MR image of the subject using the plurality of MR images and the plurality of RF coil profiles; and outputting the generated MR image.","['G01R33/5611', 'G06T11/003', 'A61B5/055', 'G01R33/36', 'G01R33/445', 'G01R33/4824', 'G01R33/4835', 'G01R33/5608', 'G01R33/56509', 'G06F18/21347', 'G06K9/6203', 'G06K9/6245', 'G06K9/741', 'G06K9/748', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06N7/01', 'G06T11/006', 'G06T11/008', 'G06T3/60', 'G06T5/60', 'G06T5/70', 'G06T7/0012', 'G06T7/207', 'G06T7/262', 'G06T7/38', 'G06V10/30', 'G06V10/431', 'G06V10/454', 'G06V10/52', 'G06V10/7515', 'G06V10/82', 'G06V10/89', 'G06V10/92', 'G16H30/40', 'G01R33/383', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/20216', 'G06T2207/20224', 'G06T2207/30016', 'G06T2210/41', 'G06V2201/03']"
US20200311549A1,Method of pruning convolutional neural network based on feature map variation,"Provided in the present disclosure is a method of pruning a convolutional neural network based on feature map variation. The present invention enables compression of an entire network by means of removing a portion of filters in a convolutional layer, and such process is called pruning. A main contribution of the present invention is determining a pruning rule for filters in a single convolutional layer according to a feature map variation condition, using the rule to analyze network sensitivity, and pruning the entire network according to the network sensitivity.","['G06N3/082', 'G06N3/04', 'G06N3/045']"
CN112183742B,Neural network hybrid quantization method based on progressive quantization and Hessian information,"The invention discloses a neural network mixed quantization method based on progressive quantization and Hessian information, which comprises the following steps: dividing a sample set and a calibration set by a given image-label pair set; defining a quantization precision range selectable by each layer of the neural network; randomly selecting a quantization layer to perform bit-down quantization, and repeatedly sampling for n times to obtain n basic mixed precision models; taking the image-label pair in the calibration set as input, and carrying out a forward process on all candidate hybrid precision neural network models; calculating a Hessian approximation by using Adam second-order Momentum information; recalculating the performance evaluation index
N are to
The index is sequenced, a mixed precision strategy corresponding to the minimum value is selected as a mixed precision super-parameter combination with the best performance under the current step, the calculation cost of the model is calculated, and then the current mixed precision network model is trained; and iterating until the ending condition is met. The method can greatly reduce the optimized mixed precision search space in each step and improve the performance evaluation efficiency of the quantization model.","['G06N3/08', 'G06N3/02', 'Y02D10/00']"
CN112348914B,A deep learning image compression sensing method and system based on Internet of Vehicles,"The invention relates to a deep learning image compression sensing method based on the Internet of vehicles, which comprises the steps of carrying out block compression sampling on pictures acquired by an intelligent terminal of the Internet of vehicles through a measurement matrix to obtain a measurement data set Y; transmitting the measurement data set Y to a cloud server in a wireless manner, and importing a trained deep neural network model, namely recovering to intermediate reconstruction through a full-connection layer to obtain a preliminary reconstructed image X'; reconstructing an image through a residual denoising network to obtain a final reconstructed image X'; and determining a loss function of the original image, and reversely transferring and updating the network weight by the loss function to realize optimization. The invention also discloses a deep learning image compression sensing system based on the Internet of vehicles. The invention greatly reduces the data transmission quantity, reduces the bandwidth pressure, greatly saves the flow cost and the limitation of the storage space, simultaneously restores the real-time response, and can obtain better effects on the accuracy of the reconstructed image and the inhibition of the image noise.","['G06T11/00', 'G06N3/045', 'G06N3/084', 'G06T3/4046', 'G06T5/70', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'Y02T10/40']"
US11494948B2,Point cloud geometric compression method based on depth auto-encoder,"The invention discloses a point cloud geometric compression method based on a depth auto-encoder, which comprises the following steps of: (1) point cloud preprocessing: collecting a type of point cloud to be compressed as a training set, and normalizing the training set into a unit circle; (2) point cloud down-sampling: down-sampling the point clouds in the training set so that each point cloud have the same point number m and each point in the point cloud has (x, y, z) three-dimensional coordinates; and adopting a farthest point down-sampling method by randomly selecting a point for the first time and then selecting the point farthest away from the selected point set every time to add into the selected point set until the selected point number meets the requirement; (3) training a compression model: inputting the point cloud sampled in step (2) into a point cloud geometric compression framework based on a depth auto-encoder for training; and (4) geometric compression of the point cloud: applying the trained compression framework to the geometric compression of all the point clouds of the type. The method can not only obtain a good compression effect but also adapt to a new point cloud type more quickly.","['G06T9/001', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T17/00', 'G06T9/002']"
CN113767400B,Using rate-distortion cost as a loss function for deep learning,"An apparatus for encoding an image block includes a processor that presents the image block to a machine learning model, obtains a segmentation decision from the model for encoding the image block, and encodes the image block using the segmentation decision. The model is trained to output segmentation decisions for encoding image blocks using training data of a plurality of training blocks as input, the training data comprising: for a training block, segmentation decisions for encoding the training block and for each segmentation decision, rate distortion values resulting from encoding the training block using the segmentation decisions. The model is trained using a loss function that combines the following: a partition loss function based on a relationship between the partition decision and the respective prediction partition and a rate distortion cost loss function based on a relationship between the rate distortion value and the respective prediction rate distortion value.","['G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06T9/002', 'H04N19/119', 'H04N19/147', 'H04N19/172', 'H04N19/176', 'H04N19/19', 'H04N19/96']"
CN114071189B,Video processing device and video streaming processing method,"The embodiment of the invention provides a video processing device and a video streaming processing method. In the method, coding units are formed for the image frames, the secondary coding units are coded according to the correlation between the first secondary coding unit and the second secondary coding unit in the secondary coding units in the plurality of coding units in the image sequence, and a video stream is generated according to the coding result of the image sequence. The image picture is a picture in the image sequence, and each coding unit is used for recording coding information of the block to which the image picture belongs. Thereby, the coding efficiency can be improved.","['H04N19/65', 'H04N21/2343', 'H04N19/119', 'H04N19/122', 'H04N19/132', 'H04N19/137', 'H04N19/14', 'H04N19/146', 'H04N19/154', 'H04N19/172', 'H04N19/176', 'H04N21/4402', 'H04N7/15']"
CN115098705B,Network security event analysis method and system based on knowledge graph reasoning,"The invention provides a network security event analysis method and system based on knowledge graph reasoning, and relates to the technical field of network security. In the invention, the target network security event is extracted. And constructing and forming a target network security knowledge graph according to each target network behavior included by the target network security event, wherein each target graph member corresponds to one target network behavior in the target network security knowledge graph, and the target network security knowledge graph carries information for reflecting behavior correlation among the target network behaviors. And analyzing the neural network by using the target knowledge graph, and analyzing and processing the target network security knowledge graph to output an event security risk degree corresponding to the target network security event, wherein the event security risk degree is used for reflecting the probability that the target network equipment is attacked by the network. Based on the above, the reliability of the network security event analysis can be improved to a certain extent.","['G06F16/367', 'G06N3/04', 'H04L63/1416']"
US9282330B1,Method and apparatus for data compression using content-based features,"Disclosed herein are methods and apparatuses for compressing a video signal. In one embodiment, the method includes storing a function derived from a set of human ratings in a memory, identifying within at least a portion of the video signal at least one content-based feature, inputting the at least one identified content-based feature into the stored function, determining a compression ratio based on the function using a processor and generating a compressed video signal at the determined compression ratio.","['G06T9/20', 'H04N19/115', 'H04N19/004', 'G06F21/10', 'H04N19/136', 'H04N19/154', 'H04N19/23', 'G06F16/433']"
US20230199179A1,Image and video coding using machine learning prediction coding models,"Video coding may include generating, by a processor, a decoded frame by decoding a current frame from an encoded bitstream and outputting a reconstructed frame based on the decoded frame. Decoding includes identifying a current encoded block from the current frame, identifying a prediction coding model for the current block, wherein the prediction coding model is a machine learning prediction coding model from a plurality of machine learning prediction coding models, identifying reference values for decoding the current block based on the prediction coding model, obtaining prediction values based on the prediction coding model and the reference values, generating a decoded block corresponding to the current encoded block based on the prediction values, and including the decoded block in the decoded frame.","['H04N19/107', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'H04N19/105', 'H04N19/154', 'H04N19/184', 'H04N19/593', 'H04N19/503']"
US20200401891A1,Methods and apparatus for hardware-aware machine learning model training,"Methods, apparatus, systems, and articles of manufacture are disclosed for hardware-aware machine learning model training. An example apparatus includes a configuration determiner to determine a hardware configuration of a target hardware platform on which the machine learning model is to be executed, a layer generator to assign sparsity configurations to layers of the machine learning model based on the hardware configuration, and a deployment controller to deploy the machine learning model to the target hardware platform in response to outputs of the machine learning model satisfying respective thresholds, the outputs including a quantity of clock cycles to execute the machine learning model with the layers having the assigned sparsity configurations.","['G06N20/00', 'G06N3/105', 'G06F1/10', 'G06F9/30036', 'G06F9/3877', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/006', 'G06N3/044', 'G06N3/048']"
US10848765B2,Rate/distortion/RDcost modeling with machine learning,"A method for encoding a block of a video stream includes generating, using pixel values of the block, block features for the block; for each candidate encoding mode of candidate encoding modes, generating, using the block features and the each candidate encoding mode as inputs to a machine-learning module, a respective encoding cost; selecting, based on the respective encoding costs, a predetermined number of the candidate encoding modes; selecting, based on the respective encoding costs of the at least some encoding modes, a best mode for encoding the block; and encoding, in a compressed bitstream, the block using the best mode.","['H04L65/607', 'H04L65/65', 'H04L65/70', 'H04L65/762', 'H04N19/103', 'H04N19/124', 'H04N19/147', 'H04N19/159', 'H04N19/176', 'H04N19/19', 'H04N19/96']"
CN113259665B,Image processing method and related equipment,"The application relates to the field of artificial intelligence and discloses an image processing method, which comprises the following steps: acquiring a first image; performing feature extraction on the first image to obtain at least one first feature map, wherein the at least one first feature map comprises N first feature values, and N is a positive integer; obtaining a target compression code rate, wherein the target compression code rate corresponds to M target gain values, each target gain value corresponds to a first characteristic value, and M is a positive integer less than or equal to N; processing the corresponding first characteristic values according to the M target gain values respectively to obtain M second characteristic values; and quantizing and entropy coding the processed at least one first feature map to obtain coded data, wherein the processed at least one first feature map comprises the M second feature values. The method and the device can realize compression code rate control in the same compression model.","['H04N19/124', 'G06T9/00', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'G06T3/4007', 'G06T9/002', 'G06V10/48', 'H04N19/146', 'H04N19/172', 'H04N19/42', 'H04N19/91']"
CN110232203B,"Knowledge distillation to optimize RNN short-term power outage prediction method, storage medium and equipment","The invention provides a knowledge distillation optimization RNN short-term power failure prediction method, a storage medium and equipment, wherein the high-relevancy characteristic of power failure faults is obtained and is used as an initial fault characteristic, fault data are divided into a linear main body part and a nonlinear main body part, short-term data prediction of the linear main body part is realized by using an ARIMA algorithm, prediction of the nonlinear main body part is realized by using the RNN, the linear main body part and the nonlinear main body part are used as input of softmax, and a regional short-term power failure prediction value is finally given out, so that the simplification and compression of an RNN model are realized on the premise of ensuring the prediction precision, and the operation speed and parameter adjustment performance of the model are further improved.","['G06F30/20', 'G06N3/044', 'G06N3/045', 'G06N3/084']"
CN110139109B,Image coding method and corresponding terminal,"The invention provides an image coding method and a corresponding terminal, wherein the coding method comprises the following steps: determining coding related information corresponding to the bare image to be processed according to the characteristic information of the bare image to be processed; according to the coding related information, coding the bare image to be processed; according to the method, the coded bare image is transmitted to the cloud server through the network, so that the decoded and reconstructed bare image is optimized by the image optimization module of the cloud server.","['H04N19/124', 'H04N19/186', 'H04N19/176', 'H04N19/30', 'H04N19/46', 'H04N19/587', 'H04N19/59', 'H04N19/70']"
CN111563275B,A Data Desensitization Method Based on Generative Adversarial Networks,"The invention discloses a data desensitization method based on a generation countermeasure network, which comprises the following steps: A. setting a generation countermeasure network, deploying a discriminator node in equipment for storing original data, and deploying a generator node in equipment needing to use the data; B. performing local updating on the discriminator node and the generator node; C. aggregating the discriminator nodes; D. generating an antagonistic network and performing iterative training; E. and inputting the original data into the trained generation countermeasure network to obtain desensitization data which is consistent with the characteristics of the original data and does not relate to the privacy of the user. The invention can solve the defects of the prior art and can better adapt to unreliable networks and dynamic bandwidths.","['G06F21/6245', 'G06N3/045', 'G06N3/088', 'H04L69/04']"
US7855966B2,"Network congestion detection and automatic fallback: methods, systems and program products","A codec detects congestion in a packet network and responds via a session control protocol to re-negotiate codec-type and/or parameters with the receiving codec to reduce bit rate for supporting a session. Once the connection and session are established, encoded packets start flowing between the two codecs. A control entity sends and receives network congestion control packets periodically in the session. The congestion control packets provide a “heartbeat” signal to the receiving codec. When the network is not congested, all “heartbeat” packets will be passed through the network. As network congestion increases, routers within the network discard excess packets to prevent network failure. The codecs respond to the missing packets by slowing down the bit rate or proceeding to renegotiate a lower bit rate via the session control protocol. If there are no missing packets, the codecs detect if the session is operating at the highest bit rate, and if not, re-negotiate a higher bit rate.","['H04L47/10', 'H04L12/6418', 'H04L47/2425', 'H04L47/263', 'H04L47/70', 'H04L47/745', 'H04L47/748', 'H04L47/762', 'H04L65/1106', 'H04L65/70', 'H04L65/752', 'H04L65/80', 'H04L2012/6481', 'H04L2012/6497']"
US11689726B2,Hybrid motion-compensated neural network with side-information based video coding,"A hybrid apparatus for coding a video stream includes a first encoder. The first encoder includes a neural network having at least one hidden layer, and the neural network receives source data from the video stream at a first hidden layer of the at least one hidden layer, receives side information correlated with the source data at the first hidden layer, and generates guided information using the source data and the side information. The first encoder outputs the guided information and the side information for a decoder to reconstruct the source data.","['H04N19/147', 'H04N19/61', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/088', 'G06T9/002', 'H04N19/103', 'H04N19/119', 'H04N19/134', 'H04N19/176', 'H04N19/184', 'H04N19/19', 'H04N19/30', 'H04N19/463', 'H04N19/59', 'G06N3/063']"
CN111008640B,"Image recognition model training and image recognition method, device, terminal and medium","The invention provides an image recognition model training method, which comprises the following steps: collecting a plurality of original images and corresponding categories as an original data set and dividing the original data set into a training set and a testing set; determining a layer to be pruned in a preset Resnet network, and pruning the layer to be pruned; inputting a training set into a pruned Resnet network and other preset neural networks for training; the characteristics output by the Resnet network after pruning and other preset neural networks are one-dimensional vectors, the one-dimensional vectors are input into a softmax classifier to calculate a loss value, and when the loss value is smaller than or equal to a preset loss threshold value, an image recognition model is output; testing by using a test set; and outputting the image recognition model obtained through training when the test passing rate is greater than a preset passing rate threshold value. The invention also provides an image recognition model training method, an image recognition model training device, a terminal and a medium. The invention can shorten the time for training the image recognition model and improve the recognition rate of the image.","['G06F18/214', 'G06F18/241']"
CN110324621B,"Video encoding method, video encoding device, electronic equipment and storage medium","The disclosure relates to a video coding method, a video coding device, an electronic device and a storage medium, and relates to the technical field of video coding. The method comprises the following steps: predicting video quality information corresponding to original video data based on previous original video data corresponding to the original video data; inputting the video quality information and the acquired network condition information between the sending end and the receiving end into a pre-trained coding rate selection evaluation network to obtain code rate evaluation information corresponding to each preset coding rate; determining a target coding rate in each preset coding rate based on the rate evaluation information; and encoding the original video data based on the target encoding code rate. By adopting the method and the device, the quality of the coded video data can be ensured, the network bandwidth occupied by the transmission of the coded video data can be reduced, and the network resources are reasonably utilized.","['G06N3/044', 'G06N3/045', 'G06N3/08', 'H04N19/146', 'H04N21/234381', 'H04N21/26216', 'H04N21/2662']"
US11282172B2,Guided restoration of video data using neural networks,"Guided restoration is used to restore video data degraded from a video frame. The video frame is divided into restoration units (RUs) which each correspond to one or more blocks of the video frame. Restoration schemes are selected for each RU. The restoration schemes may indicate to use one of a plurality of neural networks trained for the guided restoration. Alternatively, the restoration schemes may indicate to use a neural network and a filter-based restoration tool. The video frame is then restored by processing each RU according to the respective selected restoration scheme. During encoding, the restored video frame is encoded to an output bitstream, and the use of the selected restoration schemes may be signaled within the output bitstream. During decoding, the restored video frame is output to an output video stream.","['H04N19/82', 'G06T5/001', 'G06F18/214', 'G06K9/6256', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T3/40', 'G06T5/50', 'G06T5/60', 'G06T9/002', 'H04N19/176', 'H04N19/70', 'H04N19/85', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'H04N19/117', 'H04N19/17']"
NL2036871A,Multi-edge Cooperative Universal Framework for Load Prediction with Personalized Federated Deep Learning,"A Multi-edge Cooperative Universal Framework for Load Prediction with Personalized Federated Deep Learning is provided. Adopts an FDL-based cooperative training manner in multi-edge environments, use site IDs of edge servers as the basis for dividing the regions of cooperative training; The edge servers within the same site are regarded as clients in FDL, and they conduct cooperative training with the cloud server (i.e., the parameter server in FDL).customize personalized models for each edge by independent control parameters and theoretically analyze the model convergence improvement.","['G06Q10/06315', 'G06N3/098', 'G06F9/5072', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06F2209/5019']"
CN110198444B,"Video frame encoding method, video frame encoding apparatus, and device having storage function","The application discloses a video frame coding method, a video frame coding device and a device with a storage function, wherein the coding method comprises the following steps: acquiring a current frame, wherein the current frame is a non-first frame video frame; preprocessing the current frame to obtain various frame information of the current frame; analyzing the multiple kinds of frame information as time-type characteristic parameters to obtain multi-dimensional input characteristics of a quantization parameter prediction network, and inputting the quantization parameter prediction network to predict quantization parameters of a current frame, wherein the quantization parameter prediction network is a pre-trained neural network; and coding the current frame by using the quantization parameter of the current frame to obtain a corresponding video code stream. By means of the method, the performance of code stream control can be improved.","['H04N19/124', 'H04N19/172', 'H04N19/44', 'H04N19/70']"
US8199810B2,Polymorphic codec system and method,"An input module obtains a media signal to be communicated to a destination system, after which an identification module identifies a plurality of segments within the media signal. A codec includes a selection module that automatically selects different compression methods to respectively compress at least two of the segments. The compression methods are automatically selected to produce a highest compression quality for the respective segments according to a set of criteria without exceeding a target data rate. A compression module within the codec then compresses the segments using the automatically-selected compression methods, after which an output module delivers the compressed segments to the destination system with an indication of which compression method was used to compress each segment.","['H04L65/1096', 'H04L65/611', 'H04L65/612', 'H04L65/70', 'H04L65/764', 'H04L65/80', 'H04L67/303', 'H04L69/04', 'H04N19/105', 'H04N19/115', 'H04N19/12', 'H04N19/122', 'H04N19/124', 'H04N19/149', 'H04N19/152', 'H04N19/154', 'H04N19/164', 'H04N19/172', 'H04N19/176', 'H04N19/177', 'H04N19/192', 'H04N19/61', 'H04N21/23406', 'H04N21/23418', 'H04N21/23439', 'H04N21/25825', 'H04N21/25858', 'H04N21/44209', 'H04N21/4621', 'H04N21/6131', 'H04N21/6379', 'G10L19/18', 'H04L69/329']"
CN111447449B,ROI-based video coding method and system and video transmission and coding system,"The invention discloses a video coding method based on ROI, comprising the following steps: s101: acquiring a video frame of a video to be coded; s102: extracting an ROI (region of interest) region of the video frame through a neural network model; s103: coding the ROI area of the video frame by adopting a first coding mode; and aiming at the non-ROI area of the video frame, coding by adopting a second coding mode, wherein the quality level of a coded image of the first coding mode is higher than that of the coded image of the second coding mode. The invention also discloses a video coding device based on the ROI and a video transmission and coding system.","['H04N19/167', 'G06N3/04', 'H04N19/154', 'H04N21/2187', 'H04N7/15', 'H04N7/18']"
CN110647893B,"Target object identification method, device, storage medium and equipment","A target object recognition method, apparatus, storage medium and device are disclosed. The identification method comprises the following steps: providing the image to be recognized to a neural network for target object recognition; in the process of performing feature extraction processing operation on the image to be identified through the neural network, performing packet convolution processing on input features of the packet convolution layers according to the convolution packet number corresponding to the packet convolution layers in the neural network to obtain output features of the packet convolution layers; the convolutional packet number corresponding to the packet convolutional layer is determined according to the input characteristic channel number and the packet base number of the packet convolutional layer; obtaining a target object feature vector of the image to be recognized according to the output of the neural network; and identifying a target object in the image to be identified based on the feature vector. The present disclosure is advantageous for neural networks with less computational cost and lower computational delay.","['G06V10/40', 'G06F18/214']"
US11562208B2,Continuous relaxation of quantization for discretized deep neural networks,A method for quantizing a neural network includes modeling noise of parameters of the neural network. The method also includes assigning grid values to each realization of the parameters according to a concrete distribution that depends on a local fixed-point quantization grid and the modeled noise and. The method further includes computing a fixed-point value representing parameters of a hard fixed-point quantized neural network.,"['G06N3/063', 'G06N3/0472', 'G06F17/18', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/044', 'G06N3/047', 'G06N3/088']"
US6990246B1,Image coding,"An image coding method comprising generating an ordered sequence of coded image data, the sequence beginning with coded data representative of an area of the image having high importance, and ending with coded data representative of an area of the image having lower importance.","['H04N19/94', 'H04N19/129', 'H04N19/167', 'H04N19/172', 'H04N19/186', 'H04N19/51', 'H04N19/61', 'H04N19/63']"
CN115578687A,Power transformation operation area management and control method based on intelligent image recognition,"The application relates to the technical field of transformer substation management and control, and discloses a transformer operation area management and control method based on intelligent image recognition, which is implemented according to the following steps: collecting the head portraits of the members of the work team, training a deep learning algorithm by taking the head portraits of the members of the work team as samples, and generating a feature dictionary of the members of the work team; utilizing a deep learning algorithm to identify fence images of field operation areas and judge the type of construction; calling a construction site monitoring video, comparing the images of the members of the site working team with the feature dictionary, judging whether the members of the site working team are corresponding working team members or not, and giving an alarm; and identifying the positions of the construction team members by using a deep learning algorithm, judging whether the construction team members are in the construction range or not according to the construction type, and giving an alarm. According to the power transformation operation area management and control method based on intelligent image recognition, the problem of low management and control efficiency caused by the fact that the power transformation operation area is managed and controlled manually is solved.","['G06V20/52', 'G06N3/08', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/82', 'G06V20/41']"
CN110178373B,Method and apparatus for training a classifier and for encoding and decoding video frames,"The classifier is used to determine whether to partition a block in a frame during prediction using recursive partitioning. Blocks in the training video frames are encoded using recursive partitioning to generate encoded blocks. A training instance is generated for the encoded blocks that includes values of features extracted from each encoded block and a tag indicating whether the encoded block is partitioned into smaller blocks in the recursive partitioning. The classifier is trained for different block sizes using training instances associated with the block sizes as inputs to the machine learning process. When encoding frames of a video sequence, the output of the classifier determines whether to partition the input block during encoding.","['H04N19/192', 'H04N19/119', 'H04N19/136', 'H04N19/176', 'H04N19/503', 'H04N19/66', 'H04N19/96']"
US12250383B2,Dynamic parameter selection for quality-normalized video transcoding,"Video streams uploaded to a video hosting platform are transcoded using quality-normalized transcoding parameters dynamically selected using a learning model. Video frames of a video stream are processed using the learning model to determine bitrate and quality score pairs for some or all possible transcoding resolutions. The listing of bitrate and quality score pairs determined for each resolution is processed to determine a set of transcoding parameters for transcoding the video stream into each resolution. The bitrate and quality score pairs of a given listing may be processed using one or more predefined thresholds, which may, in some cases, refer to a weighted distribution of resolutions according to watch times of videos of the video hosting platform. The video stream is then transcoded into the various resolutions using the set of transcoding parameters selected for each resolution.","['H04N19/154', 'H04N19/149', 'H04N21/23418', 'H04N21/234363', 'H04N21/23439', 'H04N21/251', 'H04N21/25891', 'H04N21/2662', 'H04N21/2743', 'H04N21/4666']"
CN112767711B,Multi-class multi-scale multi-target snapshot method and system,"The invention discloses a multi-class multi-scale multi-target snapshot method and a multi-class multi-scale multi-target snapshot system, which belong to the technical field of artificial intelligence and computer vision and comprise the following steps: acquiring a panoramic video processing frame from a miscellaneous scene; carrying out intelligent real-time multi-class multi-scale multi-target detection; performing category-by-category online multi-target tracking; removing the weight of the snapshot and selecting the best; and transmitting the snapshot result to a server or a data center. The video with multiple types, multiple scales and multiple targets can be detected and analyzed in real time on one front-end camera, and the target object snapshot results which are classified, high in image quality and low in repeated redundancy can be efficiently obtained.","['G08G1/0175', 'G06N3/045', 'G06N3/08', 'G08G1/0116', 'G08G1/0125']"
CA2542800C,System and method for compressing portions of a media signal using different codecs,"An input module (fig. 3, 302) obtains a media signal to be communicated to a destination system (204), after which an identification module (304) identifies a plurality of scenes within the media signal. A selection module (306) automatically selects different codecs from a codec library (308) to respectfully compress at least two of the scenes. The codecs are automatically selected to produce a highest compression quality for the respective scenes according to a set of criteria without exceeding a target data rate. A compression module (310) then compresses the scenes using the automatically selected codecs, after which an output module (312) delivers the compressed scenes to the destination system (204) with an indication of which codec was used to compress each scene.","['H04L65/1096', 'H04L65/1101', 'H04L65/611', 'H04L65/612', 'H04L65/70', 'H04L65/764', 'H04L65/80', 'H04L67/303', 'H04L69/04', 'H04L9/40', 'H04N19/115', 'H04N19/12', 'H04N19/136', 'H04N19/142', 'H04N19/156', 'H04N19/164', 'H04N21/23406', 'H04N21/23418', 'H04N21/23439', 'H04N21/25825', 'H04N21/25858', 'H04N21/44209', 'H04N21/4621', 'H04N21/6131', 'H04N21/6379', 'H04L69/329']"
US8199980B2,Digital image search system and method,"A method and system for matching an unknown facial image of an individual with an image of an unknown twin using facial recognition techniques and human perception is disclosed herein. The invention provides a internet hosted system to find, compare, contrast and identify similar characteristics among two or more individuals using a digital camera, cellular telephone camera, wireless device for the purpose of returning information regarding similar faces to the user The system features classification of unknown facial images from a variety of internet accessible sources, including mobile phones, wireless camera-enabled devices, images obtained from digital cameras or scanners that are uploaded from PCs, third-party applications and databases. The method and system uses human perception techniques to weight the feature vectors.","['G06V40/168', 'G06V10/98']"
US20220217371A1,Framework for video conferencing based on face restoration,"There is included a method and apparatus comprising computer code configured to cause a processor or processors to perform obtaining video data, detecting at least one face from at least one frame of the video data, determining a set of facial landmark features of the at least one face from the at least one frame of the video data, and coding the video data at least partly by a neural network based on the determined set of facial landmark features.","['H04N19/29', 'H04N19/20', 'H04N19/27', 'G06K9/00228', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T3/40', 'G06T7/62', 'G06T7/73', 'G06T9/002', 'G06V10/82', 'G06V10/993', 'G06V40/161', 'G06V40/165', 'G06V40/168', 'G06V40/171', 'H04N19/132', 'H04N19/14', 'H04N19/17', 'H04N19/184', 'H04N19/30', 'H04N19/423', 'H04N19/59', 'H04N19/70', 'H04N19/85', 'H04N7/15', 'G06N3/047', 'G06N3/08', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30201', 'H04N19/593']"
US11350105B2,Selection of video quality metrics and models to optimize bitrate savings in video encoding applications,"Videos may be characterized by objective metrics that quantify video quality. Embodiments are directed to target bitrate prediction methods in which one or more objective metrics may serve as inputs into a model that predicts a mean opinion score (MOS), a measure of perceptual quality, as a function of metric values. The model may be derived by generating training data through conducting subjective tests on a set of video encodings, obtaining MOS data from the subjective tests, and correlating the MOS data with metric measurements on the training data. The MOS predictions may be extended to predict the target (encoding) bitrate that achieves a desired MOS value. The target bitrate prediction methods may be applied to segments of a video. The methods may be made computationally faster by applying temporal subsampling. The methods may also be extended for adaptive bitrate (ABR) applications by applying scaling factors to predicted bitrates at one frame size to determine predicted bitrates at different frame sizes. A dynamic scaling algorithm may be used to determine predicted bitrates at different frame sizes.","['H04N19/146', 'G06T7/0002', 'H04N19/115', 'H04N19/124', 'H04N19/154', 'H04N19/172', 'H04N19/179', 'H04N19/192', 'H04N19/50', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/30168']"
US10198076B2,Method and system for providing adjunct sensory information to a user,"A method for providing information to a user, the method including: receiving an input signal from a sensing device associated with a sensory modality of the user; generating a preprocessed signal upon preprocessing the input signal with a set of preprocessing operations; extracting a set of features from the preprocessed signal; processing the set of features with a neural network system; mapping outputs of the neural network system to a device domain associated with a device including a distribution of haptic actuators in proximity to the user; and at the distribution of haptic actuators, cooperatively producing a haptic output representative of at least a portion of the input signal, thereby providing information to the user.","['G06F3/016', 'A61F11/045', 'G08B1/08', 'G08B6/00', 'G09B21/04', 'G10L15/16', 'G10L21/16', 'G10L15/144']"
CN112101918B,Performance assessment method and system,"The invention discloses a performance assessment method and a system, wherein the method comprises the following steps: configuring a performance assessment index system and an assessment task on a server; the performance assessment index system and the assessment tasks are issued to a data acquisition unit and an assessed assessment unit; the data acquisition unit receives the index data reported by the evaluated assessment unit, and performs assessment scoring on the index data to obtain assessment scoring corresponding to the index data; and the server side summarizes the assessment scores corresponding to the index data and feeds the summarized assessment scores corresponding to the index data back to the assessed assessment unit. In the embodiment of the invention, the setting of the corresponding assessment index task and the index scoring standard for the assessment unit can be realized, the progress monitoring and the finishing quality of the data of the index task completed by the assessment unit can be scored, and scientific, fine and standardized management can be realized.",['G06Q10/105']
US10699195B2,Training of artificial neural networks using safe mutations based on output gradients,"Systems and methods are disclosed herein for ensuring a safe mutation of a neural network. A processor determines a threshold value representing a limit on an amount of divergence of response for the neural network. The processor identifies a set of weights for the neural network, the set of weights beginning as an initial set of weights. The processor trains the neural network by repeating steps including determining a safe mutation representing a perturbation that results in a response of the neural network that is within the threshold divergence, and modifying the set of weights of the neural network in accordance with the safe mutation.","['G06N3/063', 'G06F18/25', 'G06K9/6288', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/084', 'G06N3/086']"
US12323607B2,"Apparatus, method and computer program product for optimizing parameters of a compressed representation of a neural network","In example embodiments, an apparatus, a method, and a computer program product are provided. An example apparatus include processing circuitry; and at least one memory including computer program code, the at least one memory and the computer program code configured to, with the processing circuitry, cause the apparatus at least to: overfit a neural network on each media item, from a batch of media items, for a number of iterations to obtain an overfitted neural network model for the each media item; evaluate the overfitted neural network model on the each media item to obtain evaluation errors; and update parameters of the neural network to be based on the evaluation errors.","['G06N3/047', 'H04N19/42', 'G06N3/045', 'G06N3/0455', 'G06N3/0985', 'H04N19/124', 'H04N19/176', 'G06N3/084', 'G06N3/088', 'H04N19/90']"
CN109785847B,Audio compression algorithm based on dynamic residual error network,"The invention belongs to the field of audio signal compression processing, and particularly relates to a dynamic coding algorithm based on a residual error network. The algorithm is designed based on a residual error network method in deep learning, and mainly comprises three parts, namely a self-encoder preprocessing module, dynamic encoding of a multi-section residual error network and model compression of the dynamic residual error network. The algorithm firstly segments audio, removes features of audio signals according to psychoacoustics, and then uses a self-encoder for pre-training. The attention behavior of dynamic coding in multiple sections of residual errors is optimized by utilizing a bidirectional cyclic neural network, and dynamic bit rate distribution is realized, so that the compression effect of a dynamic residual error network is better. And finally, performing model compression training on the network by using a distillation learning mode, reducing the training difficulty and finally obtaining an encoding mode with good compression performance.",[]
CN113269054B,An aerial video analysis method based on spatiotemporal 2D convolutional neural network,"The invention belongs to the field of intelligent analysis of remote sensing images, and particularly relates to an aerial video analysis method based on a space-time 2D convolutional neural network, which comprises the steps of acquiring aerial video data in real time and preprocessing the acquired aerial video data; inputting the preprocessed aerial video data into a trained aerial video recognition model for recognition analysis processing; carrying out statistical analysis on the recognition result; the aerial photography video identification model comprises a 2D convolutional neural network, a long time sequence feature extraction module LTFE, a short-term motion feature extraction module SMFE and a feature fusion module FFM, wherein the long time sequence feature extraction module LTFE, the short-term motion feature extraction module SMFE and the feature fusion module FFM are arranged in the 2D convolutional neural network; the method adopts an improved 2D convolutional neural network model and combines a long time sequence feature extraction module, a short-term motion feature extraction module and a feature fusion module, so that the calculation efficiency and the identification accuracy of the aerial video are improved.","['G06V20/42', 'G06F18/2415', 'G06F18/253', 'G06N3/047', 'G06N3/048', 'G06N3/049', 'G06N3/08', 'G06V10/44', 'G06V20/46']"
US10936913B2,Automatic filter pruning technique for convolutional neural networks,"An automated pruning technique is proposed for reducing the size of a convolutional neural network. A large-sized network is trained and then connections between layers are explored to remove redundant parameters. Specifically, a scaling neural subnetwork is connected to the neural network and designed to infer importance of the filters in the neural network during training of the neural network. Output from the scaling neural subnetwork can then be used to remove filters from the neural network, thereby reducing the size of the convolutional neural network.","['G06K9/6262', 'G06N3/082', 'G06F18/217', 'G06K9/00845', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06V10/764', 'G06V10/82', 'G06V20/597', 'G06N3/048']"
CN111291836B,Method for generating student network model,"The application provides a method for generating a student network model. The method comprises the following steps: step 1), obtaining a pre-trained teacher network model; step 2), constructing an auxiliary network model; step 3), initializing the auxiliary network model, and generating a student network by using the initialized auxiliary network model; step 4), training the auxiliary network by using the training image with the image label. The auxiliary network can automatically learn the structure, the neuron number and the convolution kernel number of the student network. The manual trial is avoided, and the model detection precision of the automatic learning result of the method is higher than that of the manual trial method. The amount of computation required decreases exponentially.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/082', 'G06N3/084', 'Y02T10/40']"
CN113469073B,SAR image ship detection method and system based on lightweight deep learning,"The invention discloses a SAR image ship detection method and system based on lightweight deep learning, which are used for preprocessing a large-size SAR image and selecting a training sample; introducing a Ghost module and GhostBottleneck to upgrade the YOLOv5s to obtain a preliminary lightweight model of the YOLOv5 s; based on the preliminary lightweight model, the further lightweight of the model is realized by utilizing traditional model lightweight algorithm network pruning and knowledge distillation; utilizing a TensorRT reasoning optimizer to perform reasoning acceleration on the lightweight YOLOv5s model and disposing the model on NVIDIA Jetson TX 2; cutting the large-size SAR image to be detected, and sequentially sending the large-size SAR image to be detected into a model to complete detection; and synthesizing the detection result, and using NMS non-maximum value inhibition screening prediction frame on the final large-size SAR image. On the premise of meeting the acceptable precision loss, the parameter quantity and floating point operation quantity of the compression model are improved, and the detection speed is improved.","['G06F18/214', 'G06N3/045']"
CN113132723B,Image compression method and device,"The application is applicable to the technical field of image processing, and provides an image compression method and device, wherein the method comprises the following steps: acquiring a target image and a target code rate corresponding to the target image; determining a first code rate parameter corresponding to the target code rate; inputting the target image and the first code rate parameter into a trained image compression model for processing to obtain a compressed image with the code rate being the target code rate; wherein the image compression model is trained based on a plurality of code rate parameters including the first code rate parameter.","['H04N19/124', 'H04N19/115', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04N19/13', 'H04N19/146', 'H04N19/149', 'H04N19/172', 'H04N19/196', 'H04N19/197', 'H04N19/42', 'H04N19/44', 'H04N19/91', 'G06N3/048']"
US11025907B2,Receptive-field-conforming convolution models for video coding,"Convolutional neural networks (CNN) that determine a mode decision (e.g., block partitioning) for encoding a block include feature extraction layers and multiple classifiers. A non-overlapping convolution operation is performed at a feature extraction layer by setting a stride value equal to a kernel size. The block has a N×N size, and a smallest partition output for the block has a S×S size. Classification layers of each classifier receive feature maps having a feature dimension. An initial classification layer receives the feature maps as an output of a final feature extraction layer. Each classifier infers partition decisions for sub-blocks of size (αS)×(αS) of the block, wherein α is a power of 2 and α=2, . . . , N/S, by applying, at some successive classification layers, a 1×1 kernel to reduce respective feature dimensions; and outputting by a last layer of the classification layers an output corresponding to a N/(αS)×N/(αS)×1 output map.","['H04N19/107', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'H04N19/103', 'H04N19/117', 'H04N19/119', 'H04N19/147', 'H04N19/176', 'H04N19/186', 'H04N19/19', 'H04N19/33', 'H04N19/61', 'H04N19/96', 'G06N3/048', 'G06N3/082']"
CN107197260B,Video coding post-filter method based on convolutional neural networks,"Video coding post-filter method based on convolutional neural networks, including convolutional neural networks model training step and filter step, training step include: that the quantization parameter of setting video compress is that 20 to 51 pairs of original videos carry out coding compression, obtain compression video；Frame is carried out to all videos to extract to obtain the frame pair of multiple compressed video frame-original video frames；To extract and obtain frame is multiple groups to the different demarcation by frame type and quantization parameter；Convolutional neural networks frame and initialization network parameter are built, neural network is trained respectively using the group of aforementioned division, obtains multiple neural network models corresponding to different quantization parameters and frame type.Filter step includes: the post-filtering link that the multiple neural network models that will be obtained are embedded in video encoder；Coding compression above-mentioned is executed to original video to be processed and frame extracts to obtain frame pair to be processed, and quantization parameter according to frame pair to be processed and the corresponding neural network model of frame type selection are filtered.","['H04N19/117', 'G06N3/08', 'H04N19/124', 'H04N19/85']"
US11157815B2,Efficient convolutional neural networks and techniques to reduce associated computational costs,"The present disclosure provides systems and methods to reduce computational costs associated with convolutional neural networks. In addition, the present disclosure provides a class of efficient models termed “MobileNets” for mobile and embedded vision applications. MobileNets are based on a straight-forward architecture that uses depthwise separable convolutions to build light weight deep neural networks. The present disclosure further provides two global hyper-parameters that efficiently trade-off between latency and accuracy. These hyper-parameters allow the entity building the model to select the appropriately sized model for the particular application based on the constraints of the problem. MobileNets and associated computational cost reduction techniques are effective across a wide range of applications and use cases.","['G06N3/082', 'G06N3/045', 'G06N3/04', 'G06T2207/20084']"
CN111711824B,"Loop filtering method, device and equipment in video coding and decoding and storage medium","The application provides a loop filtering method, a loop filtering device, loop filtering equipment and a loop filtering storage medium in video coding and decoding, and relates to the technical field of video coding and decoding. The method comprises the following steps: acquiring a reconstructed frame and residual distribution information corresponding to a current frame in a video, wherein the residual distribution information is information influencing or reflecting the data distribution of residual signals; carrying out fusion processing on the reconstructed frame and the residual distribution information to obtain fusion data; and filtering the fusion data through a loop filtering model to obtain a filtered reconstruction frame. According to the method and the device, information capable of influencing or reflecting data distribution of residual signals is added into input data of the loop filter model, so that the model can better learn mapping (simulation quantization reverse process) from the residual after quantization to the residual before quantization, quantization losses of different degrees are recovered or relieved, the model can be designed according to factors influencing the degree of coding loss, the sensitivity of the loop filter model to the degree of quantization loss is improved, and the filter quality of the model is improved.","['H04N19/82', 'G06N3/045', 'G06N3/084', 'H04N19/124', 'H04N19/50']"
US10349313B2,Enhanced features for a gateway coordinating multiple small cell radio access networks,"A method of coordinating a plurality of radio access networks (RANs) includes aggregating, with a gateway, communications interfaces between a plurality of RANs and a packet core network through the gateway. A plurality of radio nodes (RNs) in each of the RANs is communicatively coupled to the gateway and to user equipment (UE) devices associated with the RNs in each of the RANs. The gateway also controls and coordinates mobility of the UE devices within and among the RANs.","['H04W36/0022', 'H04W36/0055', 'H04W4/025', 'H04W36/0058', 'H04W76/19', 'H04W88/16']"
US20210186329A1,Mesh network personal emergency response appliance,A monitoring system a user activity sensor to determine patterns of activity based upon the user activity occurring over time.,"['A61B5/0022', 'G08B21/0423', 'A43B3/42', 'A43B3/46', 'A43B3/48', 'A61B5/0006', 'A61B5/0008', 'A61B5/0013', 'A61B5/002', 'A61B5/0077', 'A61B5/01', 'A61B5/02055', 'A61B5/053', 'A61B5/1112', 'A61B5/1116', 'A61B5/1117', 'A61B5/1118', 'A61B5/318', 'A61B5/369', 'A61B5/384', 'A61B5/389', 'A61B5/395', 'A61B5/6803', 'A61B5/6806', 'A61B5/6807', 'A61B5/681', 'A61B5/6824', 'A61B5/6826', 'A61B5/6891', 'A61B5/7264', 'A61B7/00', 'A61B7/04', 'A61B7/045', 'A61B8/00', 'A61B8/06', 'A61B8/488', 'A61B8/565', 'G08B21/02', 'G08B21/0446', 'G08B21/0492', 'G08B25/016', 'G16H15/00', 'G16H40/67', 'G16H50/20', 'G16H80/00', 'G16Z99/00', 'H04M3/5116', 'A61B2562/0219', 'A61B5/0261', 'A61B8/0808', 'G08B21/0453', 'G08B21/0461', 'G08B21/0476', 'G08B21/0484', 'G16H20/13', 'G16H20/30', 'H04M2250/12', 'H04W84/18']"
CN110880038B,"FPGA-based system for accelerating convolution computing, convolutional neural network","The invention belongs to the field of deep learning, and particularly relates to a system for accelerating convolution calculation based on an FPGA (field programmable gate array) and a convolution neural network, aiming at solving the problems in the prior art. The invention comprises the following steps: the parameter quantization module stores the fixed-point weight parameters, the scales and the offsets of the convolution layers; the parameter loading module is used for loading the fixed-point CNN model parameter file into the FPGA; the input module is used for acquiring low-bit data after the input data is fixed in point; the convolution calculation module divides the characteristic diagram matrix of the input data into a plurality of small matrixes which are sequentially loaded into the FPGA, and performs convolution calculation in batches according to the number of convolution kernels; the output module is used for combining convolution calculation results corresponding to the small matrixes to be used as an input image of the next layer; the invention reduces the storage of the network model and realizes the acceleration of the convolution calculation on the premise of ensuring small precision loss of the network model on the hardware FPGA.","['G06N3/063', 'G06N3/045']"
CN112543347B,"Video super-resolution method, device, system and medium based on machine vision codec","A video super-resolution (SR) method based on machine vision coding and decoding (VCM). The method comprises the following steps: acquiring a low-resolution LR video; generating a feature representation of the LR video based on a Deep Neural Network (DNN); encoding the feature representation of the LR video and the LR video based on a VCM standard to generate an encoded feature representation of the LR video and an encoded LR video, wherein the feature representation of the LR video contains spatial and temporal information of the LR video for creating a high resolution HR video corresponding to the LR video; and decoding the encoded feature representation of the LR video and the encoded LR video.","['H04N21/2343', 'G06T3/4053', 'G06F18/25', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06T3/4046', 'G06T5/50', 'G06V10/454', 'G06V10/82', 'H04N21/4402', 'G06T2207/10016']"
CN110784759B,"Bullet screen information processing method and device, electronic equipment and storage medium","The embodiment of the disclosure provides a bullet screen information processing method, a bullet screen information processing device, electronic equipment and a storage medium, which relate to the technical field of artificial intelligence and machine learning technology, wherein the method comprises the following steps: acquiring an image to be processed in image data; performing scene recognition on the image to be processed to determine a scene label to which the image to be processed belongs, wherein the scene label is used for representing a scene category to which the image belongs; and taking the selectable bullet screen information associated with the scene label as candidate bullet screen information, and displaying the candidate bullet screen information. According to the method and the device, the user is guided to improve the behavior of sending the bullet screen according to the identified scene label, and the utilization rate of bullet screen information is improved; the method and the device can trigger the appropriate bullet screen information in a targeted manner, avoid the step of using the bullet screen information universal for the platform, and improve the accuracy and timeliness of sending the bullet screen information.","['H04N21/435', 'A63F13/87', 'G06F16/7867', 'G06N3/045', 'G06N3/08', 'H04N21/44008', 'H04N21/4884']"
CN107688849B,A dynamic strategy fixed-point training method and device,"The application discloses a fixed point training method and device based on dynamic fixed point parameters for a deep neural network. More specifically, a corresponding fixed-point training method is proposed for the computation structure of a deep neural network (e.g., an LSTM neural network), in the training process of the neural network, forward computation is performed in a fixed-point mode, and the network precision reaches the level of floating-point computation within a plurality of training cycles.","['G06N3/063', 'G06N3/045', 'G06N3/044', 'G06N3/0442', 'G06N3/048', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G10L15/16', 'G06N7/01']"
CN107679618B,Static strategy fixed-point training method and device,"A static strategy fixed-point training method and device. The application discloses a static fixed point parameter-based fixed point training method and device for a deep neural network. More specifically, for the computation structure of a deep neural network (e.g., an LSTM neural network), a corresponding fixed-point training method is proposed, in the retraining process of the neural network, forward computation is performed in a fixed-point mode, and within a plurality of training cycles, the network precision is restored to the level of floating-point computation.","['G06N3/08', 'G06N3/048', 'G06N3/044', 'G06N3/0442', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/09', 'G10L15/16', 'G06F7/485', 'G06N7/01']"
US7457359B2,"Systems, devices and methods for securely distributing highly-compressed multimedia content","A multimedia distribution device includes a nonvolatile memory that stores a compressed media signal in which at least two scenes are selectively compressed using different codecs from a codec library, the codecs being automatically selected to produce a highest compression quality for the respective scenes according to a set of criteria without exceeding a target data rate. The nonvolatile memory also stores a plurality of codec indicators specifying which codecs from the codec library were used to respectively compress each scene within the compressed media signal.","['H04N21/23418', 'H04L65/1096', 'H04L65/1101', 'H04L65/611', 'H04L65/70', 'H04L65/764', 'H04L65/80', 'H04L67/303', 'H04L69/04', 'H04L9/40', 'H04N19/105', 'H04N19/115', 'H04N19/12', 'H04N19/122', 'H04N19/124', 'H04N19/142', 'H04N19/152', 'H04N19/154', 'H04N19/162', 'H04N19/172', 'H04N19/176', 'H04N19/177', 'H04N19/179', 'H04N19/61', 'H04N21/23406', 'H04N21/23439', 'H04N21/2347', 'H04N21/235', 'H04N21/25825', 'H04N21/25858', 'H04N21/435', 'H04N21/440254', 'H04N21/440281', 'H04N21/4405', 'H04N21/44209', 'H04N21/6131', 'H04N21/6379', 'H04L69/329']"
CN111445026B,Acceleration method for deep neural network multi-path reasoning for edge intelligence applications,"The invention discloses a deep neural network multipath reasoning acceleration method for edge intelligent application, which comprises the steps of firstly analyzing classification capacity and calculation cost of each layer of the deep neural network, setting an exit combination with the maximum reasoning benefit, and adding the exit combination to an original model; then a threshold unit is arranged between the exit and the trunk layer and trained to judge whether the task can exit at the current exit; for tasks which cannot exit in advance at the terminal layer and must be transmitted to the edge layer, compressing intermediate characteristic data; and finally, the network load, the computing capacities of the terminal and the edge equipment are monitored and analyzed on line under the edge computing environment, the multipath model is cut by taking the minimum reasoning time delay as a target, the model cutting blocks are respectively deployed at the terminal layer and the edge layer, and finally, the multipath reasoning acceleration framework is formed. The method can improve the flexibility of reasoning, ensure the accuracy, reduce the total time delay of reasoning and meet the real-time and high-precision requirements of the intelligent application of the edge.","['G06N5/04', 'G06N3/045', 'G06N3/08', 'Y02D10/00']"
CN112232511B,Multitask-oriented automatic compression method and platform of pre-trained language model,"The invention discloses a pre-training language model automatic compression method and platform for multiple tasks. Designing a meta-network of a structure generator, constructing a knowledge distillation coding vector based on a Transformer layer sampling knowledge distillation method, and generating a distillation structure model corresponding to a currently input coding vector by using the structure generator; simultaneously, a Bernoulli distributed sampling method is provided to train a structure generator; in each iteration, each encoder unit is moved by using a Bernoulli distribution sampling mode to form a corresponding encoding vector; by changing the coding vector input into the structure generator and the training data of a small batch, combining the training structure generator and the corresponding distillation structure, the structure generator capable of generating weights for different distillation structures can be learned; and meanwhile, on the basis of the trained meta-learning network, searching for an optimal compression structure through an evolutionary algorithm, thereby obtaining an optimal general compression architecture of the pre-training language model irrelevant to the task.","['G06N3/082', 'G06N5/04']"
CN110401834B,An adaptive video coding method based on deep learning,"Disclosure of the inventionA method for adaptive video coding based on deep learning is disclosed. The method comprises the following steps: generating training data and test data by using a diversified video database; constructing a neural network model for deep learning; the neural network model comprises a convolutional neural network CNN feature extractor, a long-short term memory network LSTM feature extractor, a full connection layer and an output layer; training the deep-learning neural network model by using training data; verifying the trained model by using the test data; obtaining predicted CRF using the neural network modeloptimal(v) Taking the value of (A); according to the obtained CRFoptimal(v) Video compression is performed. The method can accurately predict the coding parameters meeting the video quality evaluation scores for each video, thereby realizing code rate self-adaptation of video coding on the premise of meeting user experience.","['H04N19/149', 'H04N19/154', 'H04N19/30']"
US20230222353A1,Method and system for training a neural network model using adversarial learning and knowledge distillation,"Method and system of training a student neural network using adversarial learning and knowledge distillation, including: training a generator to generate adversarial data samples for respective training data samples by masking parts of the training data samples with an objective of maximizing a divergence between output predictions generated by the student neural network and a teacher neural network model for the adversarial data samples; and training the student neural network based on objectives of (i) minimizing a divergence between output predictions generated by the student neural network and the teacher neural network model for the adversarial data samples, and (ii) minimizing a divergence between output predictions generated by the student neural network and the teacher neural network model for the training data samples.","['G06N3/094', 'G06N3/088', 'G06N3/045']"
CN110909667B,A lightweight design method for multi-angle SAR target recognition network,"The invention discloses a lightweight design method for a multi-angle SAR target recognition network, and belongs to the cross field of computer vision and remote sensing. The conventional neural network compression method generally gradually compresses ideas with identification precision loss, and combines the requirements of SAR target multi-angle feature maintenance, a lightweight SAR target identification CNN network structure is generated by using structured pruning, the multi-angle feature extraction capability of the CNN network model is recovered by using knowledge distillation, the network model storage space requirement is further compressed by using weight sharing, and finally, a lossless lightweight multi-angle SAR target identification network model is obtained. On the premise of lossless identification precision, the compression rate can reach more than 60 times, and meanwhile, the calculated amount can be reduced by more than 2 times.","['G06V20/13', 'G06F18/214', 'G06F18/23', 'G06N3/045']"
US20210256385A1,Computer-implemented methods and systems for dnn weight pruning for real-time execution on mobile devices,"A computer-implemented method is disclosed for compressing a deep neural network (DNN) model by DNN weight pruning to accelerate DNN inference on mobile devices. The method includes the steps of (a) performing an intra-convolution kernel pruning of the DNN model wherein a fixed number of weights are pruned in each convolution kernel of the DNN model to generate sparse convolution patterns; (b) performing inter-convolution kernel pruning of the DNN model to generate connectivity sparsity, wherein inter-convolution kernel pruning comprises cutting connections between given input and output channels of the DNN model to remove corresponding kernels; and (c) training the DNN model compressed in steps (a) and (b).","['G06N3/082', 'G06F18/2136', 'G06K9/6249', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06N3/105']"
US11494644B2,"System, method, and computer program for recommending items using a direct neural network structure","The present disclosure relates to a system, method, and computer program for recommending products using a neural network architecture that directly learns a user's predicted rating for an item from user and item data. A set of encoding neural networks maps each input source for user and item data to a lower-dimensional vector space. The individual lower-dimensional vector outputs of the encoding neural networks are combined to create a single multidimensional vector representation of user and item data. A prediction neural network is trained to predict a user's rating for an item based on the single multidimensional vector representation of user and item data. The neural network architecture allows for more efficient optimization and faster convergence that recommendations systems that rely on autoencoders. The system recommends items to users based on the users' predicted ratings for items.","['G06N3/08', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/044', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084', 'H04Q2213/054']"
CN110866891B,"Image recognition device, image recognition method, and storage medium","Provided are an image recognition device, an image recognition method, and an image recognition program, which can recognize with high accuracy a qualified image having a high similarity to an ongoing teacher image or a non-qualified image having a low similarity to an ongoing teacher image. The image recognition device comprises: a classification unit that calculates a classification score of an input image from a neural network and the input image, the neural network having each layer weight coefficient determined by calculating a classification score indicating similarity with a teacher image through machine learning of the teacher image based on a positive solution and a non-positive solution; an abnormality determination unit that calculates an abnormality score of an input image from a function approximator that is constructed by machine learning based on a forward-solved teacher image in order to calculate an abnormality score indicating a degree of difference from the forward-solved teacher image, and the input image; and a recognition unit that classifies the input image into a qualified image having a high similarity to the forward-solved teacher image or a non-qualified image having a low similarity to the forward-solved teacher image, based on the classification score and the abnormality score.","['G06T7/0004', 'G06V10/82', 'G06F18/214', 'G06F18/217', 'G06F18/22', 'G06F18/24', 'G06F18/2411', 'G06F18/24143', 'G06F18/2451', 'G06V10/764', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108']"
US11631004B2,Channel pruning of a convolutional network based on gradient descent optimization,"Techniques and mechanisms for determining the pruning of one or more channels from a convolutional neural network (CNN) based on a gradient descent analysis of a performance loss. In an embodiment, a mask layer selectively masks one or more channels which communicate data between layers of the CNN. The CNN provides an output, and calculations are performed to determine a relationship between the masking and a loss of the CNN. The various masking of different channels is based on respective random variables and on probability values each corresponding to a different respective channel In another embodiment, the masking is further based on a continuous mask function which approximates a binary step function.","['G06N3/082', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
CN117196014B,"Model training method, device, computer equipment and medium based on federated learning","The embodiment of the invention discloses a model training method, a model training device, computer equipment and a model training medium based on federal learning. The method comprises the following steps: training the global model by utilizing local data through a plurality of clients to obtain a local model, determining a model update vector, selecting a target element from the model update vector, and generating a local index vector according to the target element; receiving and aggregating local index vectors uploaded by a client, determining a global index vector according to an aggregation result, and sending the global index vector to the client; uploading model updating elements in the model updating vector to the programmable switch by the client according to the global index vector; and receiving and aggregating the model updating elements uploaded by the clients to obtain global updating elements, and sending the global updating elements to the clients so that each client updates the global model according to the global updating elements. Therefore, the quantity and the aggregation times of aggregation parameters are reduced, the communication time delay is shortened, and the training process of federal learning is quickened.",['Y02D10/00']
US7068601B2,"Codec with network congestion detection and automatic fallback: methods, systems & program products","A codec detects congestion in a packet network and responds via a session control protocol to re-negotiate codec-type and/or parameters with the receiving codec to reduce bit rate for supporting a session. Once the connection and session are established, encoded packets start flowing between the two codecs. A control entity sends and receives network congestion control packets periodically in the session. The congestion control packets provide a “heartbeat” signal to the receiving codec. When the network is not congested, all “heartbeat” packets will be passed through the network As network congestion increases, routers within the network discard excess packets to prevent network failure. The codecs respond to the missing packets by slowing down the bit rate or proceeding to renegotiate a lower bit rate via the session control protocol. If there are no missing packets, the codecs detect if the session is operating at the highest bit rate, and if not, re-negotiate a higher bit rate.","['H04L12/6418', 'H04L47/10', 'H04L47/12', 'H04L47/2425', 'H04L47/263', 'H04L47/70', 'H04L47/745', 'H04L47/748', 'H04L47/762', 'H04L65/1106', 'H04L65/70', 'H04L65/80', 'H04L2012/6481', 'H04L2012/6497']"
US20200096998A1,Methods and systems for detection in an industrial internet of things data collection environment with distributed data processing in a marginal network,"Systems and methods for data collection in an industrial environment can include a data collector communicatively coupled to a plurality of input channels, each of the plurality of input channels connected to a corresponding one of a plurality of data sources in the industrial environment; a plurality of distributed data acquisition circuits structured to interpret a plurality of detection values from the data collected from the plurality of input channels, each of the plurality of detection values corresponding to at least one of the plurality of input channels; and a controller. The controller may include a transmission environment circuit structured to determine a transmission condition corresponding to transmission of data a network; and a network management circuit structured to distribute a data processing operation of the plurality of detection values between at least two processing components of the industrial environment.","['H04B17/29', 'G05B23/0294', 'B62D15/0215', 'G01M13/028', 'G01M13/04', 'G01M13/045', 'G05B13/028', 'G05B19/4183', 'G05B19/4184', 'G05B19/41845', 'G05B19/4185', 'G05B19/41865', 'G05B19/41875', 'G05B23/0221', 'G05B23/0229', 'G05B23/024', 'G05B23/0264', 'G05B23/0283', 'G05B23/0286', 'G05B23/0289', 'G05B23/0291', 'G05B23/0297', 'G06F16/2477', 'G06F18/2178', 'G06F3/0608', 'G06F3/0619', 'G06F3/0635', 'G06F3/067', 'G06K9/6263', 'G06N20/00', 'G06N3/006', 'G06N3/02', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/084', 'G06N3/088', 'G06N5/046', 'G06N7/005', 'G06Q10/04', 'G06Q10/0639', 'G06Q30/02', 'G06Q30/0278', 'G06Q30/06', 'G06Q50/00', 'G06V10/7784', 'G06V10/82', 'G16Z99/00', 'H02M1/12', 'H03M1/12', 'H04B17/26', 'H04B17/309', 'H04B17/318', 'H04L1/0002', 'H04L1/0041', 'H04L1/18', 'H04L1/1874', 'H04L67/1097', 'H04L67/12', 'H04W4/38', 'H04W4/70', 'B62D5/0463', 'F01D21/003', 'F01D21/12', 'F01D21/14', 'G05B19/042', 'G05B2219/32287', 'G05B2219/35001', 'G05B2219/37337', 'G05B2219/37351', 'G05B2219/37434', 'G05B2219/37537', 'G05B2219/40115', 'G05B2219/45004', 'G05B2219/45129', 'G05B23/02', 'G05B23/0208', 'G06F17/18', 'G06F18/21', 'G06F18/217', 'G06F18/25', 'G06N3/126', 'G06N7/01', 'H04B17/23', 'H04B17/345', 'H04B17/40', 'H04L1/0009', 'H04L5/0064', 'H04L67/306', 'Y02P80/10', 'Y02P90/02', 'Y02P90/80', 'Y04S50/00', 'Y04S50/12', 'Y10S707/99939']"
US11093832B2,Pruning redundant neurons and kernels of deep convolutional neural networks,"Method and apparatus for optimizing a convolutional neural network (CNN). A respective measure of importance is calculated for each of a plurality of elements within a CNN. A first one of the measures of importance is calculated by back propagating a second one of the measures of importance through the CNN. One or more of the plurality of elements is pruned from the CNN, based on the calculated measures of importance.","['G06N3/084', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/048']"
KR20210106397A,"Voice conversion method, electronic device, and storage medium","Disclosed are a voice conversion method, a voice conversion device, an electronic device thereof. The present invention relates to the fields of speech conversion, speech interaction, natural language processing, and deep learning. According to a concrete embodiment of the present invention, the method comprises the following steps: acquiring a source voice of a first user and a reference voice of a second user; extracting first voice content information and a first acoustic feature from the source voice; extracting a second acoustic feature from the reference voice; acquiring a reconstructed third acoustic feature by inputting the first voice content information, the first acoustic feature, and the second acoustic feature into a pre-trained voice conversion model, wherein the pre-trained voice conversion model is acquired by training; and synthesizing a target voice according to the third acoustic feature. Accordingly, the target voice is synthesized according to a reconstructed third acoustic characteristic acquired by inputting the first voice content information and first acoustic feature of the source voice and the second acoustic feature of the reference voice into the pre-trained voice conversion model, thereby reducing time waiting for voice conversion.","['G10L21/013', 'G10L13/02', 'G06N3/08', 'G10L13/033', 'G10L13/08', 'G10L15/02', 'G10L21/003', 'G10L21/007', 'G10L25/03', 'G10L25/30', 'G10L15/14', 'G10L2015/025', 'G10L2021/0135']"
US20230351187A1,Accelerating neural networks with one shot skip layer pruning,"Systems, methods, and devices for pruning a convolutional neural network (CNN). A subset of layers of the CNN is chosen, and for each layer of the subset of layers, how salient each filter in the layer is to an output of the CNN is determined, a subset of the filters in the layer is determined based on the salience of each filter in the layer, and the subset of filters in the layer is pruned. In some implementations, the layers of the subset of layers of the CNN are non-contiguous. In some implementations, the subset of layers includes odd numbered layers of the CNN and excludes even numbered layers of the CNN. In some implementations, the subset of layers includes even numbered layers of the CNN and excludes odd numbered layers of the CNN.","['G06N3/082', 'G06F18/214', 'G06F9/3455', 'G06N3/0418', 'G06N3/045', 'G06N3/063']"
CN118968665B,Intelligent access control management method and system based on multi-mode identification and Internet of things technology,"The invention discloses an intelligent access control management method and system based on multi-mode identification and the internet of things technology. According to the method, multi-mode data are acquired through distributed Internet of things equipment, synchronous alignment and self-adaptive preprocessing are carried out, and multi-scale features are extracted and dynamically fused. And carrying out depth feature fusion by adopting a nonlinear dimension reduction, multi-order tensor decomposition, a graph rolling network and a multi-head attention mechanism. And combining with the dynamically updated identity template, realizing multi-factor identity verification, including biometric feature matching, behavior pattern analysis and environmental context verification. And determining a verification result through the self-adaptive decision threshold, and performing dynamic access control, self-adaptive people stream control and real-time abnormal event detection. The method improves the accuracy, the system safety and the adaptability of the identity identification, and is suitable for intelligent access control management in complex environments such as construction sites, parks, markets and the like.","['G07C9/37', 'G06F18/10', 'G06F18/213', 'G07C9/38']"
CN110503630B,"Cerebral hemorrhage classifying, positioning and predicting method based on three-dimensional deep learning model","The invention discloses a cerebral hemorrhage classifying, positioning and predicting method based on a three-dimensional deep learning model, which is used for carrying out three-dimensional modeling on a two-dimensional CT image by a surface reconstruction method to obtain a three-dimensional CT image; then, a three-dimensional convolutional neural network is used for extracting features of the three-dimensional CT image, and the extracted features are classified through an SVM classifier, so that whether the CT image contains bleeding points or not is classified and judged; slicing the three-dimensional CT image which is judged to contain the bleeding points by the classifier again, and accurately positioning the bleeding point positions of the two-dimensional CT image after slicing through a target detection network; compression encoding is carried out on physical characteristic information of a patient to serve as a three-dimensional conditional generation condition of an countermeasure network, the generation condition is integrated with random noise, and a three-dimensional CT image is output according to physical indexes of the patient by using a three-dimensional generator in the countermeasure network model, so that the diffusion of blood clots of the brain of the patient with time or the absorption condition of the brain of the patient by a human body is predicted.","['G06F18/2411', 'G06T11/003', 'G06T7/0012', 'G06T7/73', 'G16H50/20', 'G16H50/50', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'Y02A90/10']"
US12118803B2,Method of road detection based on internet of vehicles,"A method of road detection based on Internet of Vehicles is provided, the method is applied to vehicle terminals and includes: obtaining a target road image captured by an image collection terminal and inputting it into an improved YOLOv3 network, performing feature extraction by using backbone network of dense connection to obtain feature images with different scales; performing feature fusion of top-to-down and dense connection to the feature images by using an improved feature pyramid networks (FPN) to obtain prediction results; obtaining attribute information of the target road image according to the prediction results; the attribute information includes positions and categories of objects in the target road image; the improved YOLOv3 is formed by based on YOLOv3 network, replacing residual modules of backbone network to dense connection modules, increasing feature extraction scale, optimizing feature fusion mode of FPN, performing pruning and performing network recovery processing guided by knowledge distillation.","['G06V20/588', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/082', 'G06N5/02', 'G06V10/255', 'G06V10/454', 'G06V10/462', 'G06V10/75', 'G06V10/762', 'G06V10/806', 'G06V10/82', 'G06V10/95', 'G06V20/58', 'H04L12/40', 'H04L67/12', 'G06V2201/08', 'H04L2012/40273']"
US11509539B2,"Traffic analysis apparatus, system, method, and program","A traffic analysis apparatus includes: a first means that estimates a state sequence from time-series data of communication traffic based on a hidden Markov model, and groups, into one group, a plurality of patterns with resembling state transitions in the state sequence to perform extraction of a state sequence, with taking the plurality of patterns grouped into one group as one state; and a second means that determines an application state corresponding to the time-series data based on the state sequence extracted by the first means and predetermined application characteristics.","['H04L41/142', 'H04L1/002', 'H04L41/16', 'H04L41/5009', 'H04L41/509', 'H04L43/08', 'H04L47/24', 'G16Y10/75', 'H04L43/0888']"
US12306919B2,Systems and methods for dynamic passphrases,"Systems, devices, methods, and computer readable media are provided in various embodiments relating to generating a dynamic challenge passphrase data object. The method includes establishing, a plurality of data record clusters, representing a mutually exclusive set of structured data records of an individual, ranking the plurality of feature data fields based on a determined contribution value of each feature data field relative to the establishing of the data record cluster, and identifying, using the ranked plurality of feature data fields, a first and a second feature data field of the plurality of feature data fields. The method includes generating the dynamic challenge passphrase data object, wherein the first or the second feature data field is used to establish a statement string portion, and a remaining one of the first or the second feature data field is used to establish a question string portion and a correct response string.","['G06F21/32', 'G06F18/2113', 'G06F18/22', 'G06F18/24137', 'G06F18/251', 'G06F21/31', 'G06F21/33', 'G06F21/46', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06Q20/108', 'G06Q20/1085', 'G06Q20/202', 'G06Q20/206', 'G06Q20/322', 'G06Q20/3267', 'G06Q20/3276', 'G06Q20/36', 'G06Q20/38215', 'G06Q20/3825', 'G06Q20/385', 'G06Q20/4014', 'G06Q20/40145', 'G06Q20/4016', 'G06V10/17', 'G06V10/454', 'G06V10/764', 'G06V10/771', 'G06V10/776', 'G06V10/803', 'G06V10/82', 'G06V40/165', 'G06V40/171', 'G06V40/172', 'G06V40/20', 'G06V40/40', 'G07G1/009', 'G10L15/25', 'G10L17/24', 'H04L63/0838', 'H04L63/0876', 'H04L9/0866', 'H04L9/3213', 'H04L9/3226', 'H04L9/3231', 'H04L9/3271', 'G06N3/047', 'G10L17/14']"
CN119091362B,Controllable video generation method and system based on multimodal fusion,"The invention discloses a controllable video generation method and a controllable video generation system based on multi-mode fusion, wherein the method comprises the steps of acquiring multi-mode data and preprocessing the multi-mode data; extracting feature vectors, carrying out normalization processing on the feature vectors, combining the feature vectors to form a multi-mode feature matrix, converting the multi-mode feature matrix into a feature sequence, carrying out dynamic weight distribution on each mode feature in the feature sequence, carrying out multi-level deep fusion on the weighted feature sequence to obtain fusion feature representation, inputting the fusion feature representation into a multi-scale space-time attention mechanism to obtain enhancement feature representation, sequentially using a space attention module, a time attention module and a cross attention module to carry out processing to obtain global enhancement feature representation, generating multi-frame hidden space representation, decoding to generate a high-resolution video frame, and carrying out post processing to obtain a final high-quality video sequence. The invention maintains the time-space consistency of the video sequence and generates the video content with higher quality and stronger controllability.","['H04N21/816', 'G06F18/256', 'G06F40/289', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/094', 'G06V10/454', 'G06V10/806', 'G06V10/811', 'G06V10/82', 'G06V20/40']"
US7558622B2,Mesh network stroke monitoring appliance,A health care monitoring system for a person includes one or more wireless nodes forming a wireless mesh network; a wearable appliance having a sound transducer coupled to the wireless transceiver; and a heart attack or stroke attack sensor coupled to the wireless mesh network to communicate patient data over the wireless mesh network to detect a heart attack or a stroke attack.,"['A61B5/002', 'A61B5/0022', 'A61B5/0205', 'A61B5/026', 'A61B5/0295', 'A61B5/0537', 'A61B5/11', 'A61B5/1112', 'A61B5/1113', 'A61B5/1114', 'A61B5/1116', 'A61B5/1117', 'A61B5/1118', 'A61B5/14532', 'A61B5/33', 'A61B5/369', 'A61B5/389', 'A61B5/4076', 'A61B5/411', 'A61B5/4803', 'A61B5/4806', 'A61B5/681', 'A61B5/6816', 'A61B5/6822', 'A61B5/6826', 'A61B5/6838', 'A61B5/6898', 'A61B5/7203', 'A61B5/7225', 'A61B5/7267', 'A61B5/7271', 'A61B5/7435', 'A61B5/7455', 'A61B5/7465', 'A61B5/7475', 'A61B8/565', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'A61B2505/01', 'A61B2560/0214', 'A61B2560/0223', 'A61B2560/0468', 'A61B2562/0219', 'A61B5/0006', 'A61B5/0008', 'A61B5/02055', 'A61B5/02438', 'A61B5/1038', 'A61B5/112', 'A61B5/1124', 'A61B5/1128', 'A61B5/1176', 'A61B5/224', 'A61B5/30', 'A61B5/318', 'A61B5/4023', 'A61B5/4519', 'A61B5/4528', 'A61B5/7214', 'A61B5/726', 'A61B5/743', 'A61B8/0808', 'A61B8/56', 'G16H10/60', 'G16H20/60', 'G16H30/20']"
US20250061320A1,Adjusting activation compression for neural network training,"Apparatus and methods for training a neural network accelerator using quantized precision data formats are disclosed, and, in particular, for adjusting floating-point formats used to store activation values during training. In certain examples of the disclosed technology, a computing system includes processors, memory, and a floating-point compressor in communication with the memory. The computing system is configured to produce a neural network comprising activation values expressed in a first floating-point format, select a second floating-point format for the neural network based on a performance metric, convert at least one of the activation values to the second floating-point format, and store the compressed activation values in the memory. Aspects of the second floating-point format that can be adjusted include the number of bits used to express mantissas, exponent format, use of non-uniform mantissas, and/or use of outlier values to express some of the mantissas.","['G06N3/063', 'G06F18/217', 'G06F9/30025', 'G06N3/084', 'G06N3/044', 'G06N3/048']"
CN109978142B,Neural network model compression method and device,"The embodiment of the invention discloses a method and a device for compressing a neural network model. The method comprises the following steps: decomposing the neural network model into computational operations comprising channels; training a neural network model to update parameters of the calculation operation under the condition of keeping the calculation operation and a structure formed by the channel unchanged; under the condition of keeping the parameters of the calculation operation unchanged, training a neural network model to update the weights corresponding to the calculation operation and the channel respectively; deleting redundant computing operations based on the updated weights and deleting redundant channels in the retained computing operations; based on the retained computational operations, the corresponding channels, and the parameters, a compressed neural network model is constructed. The embodiment of the invention can effectively simplify the neural network model.",['G06N3/04']
CN114037844B,Global rank perception neural network model compression method based on filter feature map,"The invention discloses a global rank perception neural network model compression method based on a filter feature map, which solves the problems of high labor cost, low pruning efficiency and poor stability of the filter pruning model compression method, and comprises the following steps: acquiring image data and preprocessing; constructing a general convolutional neural network and setting super parameters; selecting a loss function and an optimization algorithm; training and storing a pre-training model; acquiring an average rank of a feature map; self-adaptive learning parameter matrix; representing and ordering filter importance; pruning and storing the pre-training model; and fine tuning the network model to realize the compression of the global rank perception neural network model based on the filter characteristic diagram. The invention adopts 'one-time learning multiple pruning', carries out overall sorting and unified pruning on the filter, and has no pathological selection. The pruning effect and stability are better, the pruning efficiency of the large-scale network with different complexity is high, and the adaptability of different edge devices is good. The edge device is used for computing and storing the resource limitation.","['G06F18/241', 'G06N3/045', 'G06N3/08', 'Y02T10/40']"
US20200210838A1,Neural network activation compression with narrow block floating-point,"Apparatus and methods for training a neural network accelerator using quantized precision data formats are disclosed, and in particular for storing activation values from a neural network in a compressed format for use during forward and backward propagation training of the neural network. In certain examples of the disclosed technology, a computing system includes processors, memory, and a compressor in communication with the memory. The computing system is configured to perform forward propagation for a layer of a neural network to produced first activation values in a first block floating-point format. In some examples, activation values generated by forward propagation are converted by the compressor to a second block floating-point format having a narrower numerical precision than the first block floating-point format. The compressed activation values are stored in the memory, where they can be retrieved for use during back propagation.","['G06N3/063', 'G06N3/084', 'G06F7/49915', 'G06F9/30025', 'G06F9/5027', 'G06N20/00', 'G06N5/046', 'G06N3/044']"
US12277502B2,Neural network activation compression with non-uniform mantissas,"Apparatus and methods for training a neural network accelerator using quantized precision data formats are disclosed, and in particular for storing activation values from a neural network in a compressed format having lossy or non-uniform mantissas for use during forward and backward propagation training of the neural network. In certain examples of the disclosed technology, a computing system includes processors, memory, and a compressor in communication with the memory. The computing system is configured to perform forward propagation for a layer of a neural network to produced first activation values in a first block floating-point format. In some examples, activation values generated by forward propagation are converted by the compressor to a second block floating-point format having a non-uniform and/or lossy mantissa. The compressed activation values are stored in the memory, where they can be retrieved for use during back propagation.","['G06N3/063', 'G06F9/30141', 'G06N3/048', 'G06N3/0495', 'G06N3/084', 'H03M7/3059', 'H03M7/46', 'H03M7/702']"
CN110033083B,"Convolutional neural network model compression method and device, storage medium and electronic device","The invention discloses a convolutional neural network model compression method and device, a storage medium and an electronic device. Wherein the method comprises the following steps: combining parameters of a first batch of standardization layers in the convolutional neural network model into a first convolutional layer in the convolutional neural network model to generate a first target neural network model containing a first target convolutional layer, wherein the convolutional neural network model and the first target neural network model have the same output for the same input; deleting convolution kernels with norms smaller than a first threshold value in a first target convolution layer in the first target neural network model to obtain a second target neural network model; and compressing the second target neural network model to obtain a third target neural network model. The method solves the technical problems of low use efficiency and poor flexibility of the neural network model in the related technology.","['G06N3/045', 'Y02D10/00']"
CN106529670B,"A neural network processor, design method and chip based on weight compression","The present invention propose it is a kind of based on weight compression neural network processor, design method, chip, which includes at least one storage unit, for store operational order and participate in calculate data；At least one storage unit controller, for controlling the storage unit；At least one computing unit, for executing the calculating operation of neural network；Control unit is connected with the storage unit controller with the computing unit, for obtaining the instruction of the storage unit storage via the storage unit controller, and parses described instruction to control the computing unit；At least one weight retrieval unit, wherein each weight retrieval unit is connected with the computing unit, guarantees compressed weight and the correct operation of corresponding data for retrieving to weight.Present invention reduces the occupancy of weight resource in neural network processor, improve arithmetic speed, improve energy efficiency.",['G06N3/063']
RU2767447C2,Neural network processor using compression and decompression of activation data in order to reduce memory bandwidth use,"FIELD: computing technology.SUBSTANCE: invention relates to the field of computing technology using neural processors. The technical result of the claimed technical solution is achieved by the fact that provided in the claimed solution are a neural network processor and a compression unit configured to receive an uncompressed portion of data generated in the neural network processor, when compressing the data, each bit in part of the mask corresponds to a byte in the uncompressed portion of data, wherein each bit in part of the mask is set to logical zero, wherein the corresponding byte in the uncompressed portion of data is zero, and is set to a logical unit wherein the corresponding byte in the uncompressed portion of data is non-zero; part of the data of the compressed output portion of the data is therein generated and the compressed output portion of the data is output, wherein the compressed output portion of the data comprises part of the mask and part of the data.EFFECT: increase in the productivity of data processing with simultaneous reduction in the energy consumption.15 cl, 11 dwg","['G06N3/0464', 'G06F13/1673', 'G06N3/04', 'G06F1/3206', 'G06F1/324', 'G06F1/3275', 'G06F1/3287', 'G06F12/0207', 'G06F12/0238', 'G06F12/08', 'G06F12/0862', 'G06F12/10', 'G06F13/1689', 'G06F13/28', 'G06F15/8007', 'G06F17/15', 'G06F3/0604', 'G06F3/0631', 'G06F3/067', 'G06F9/30087', 'G06F9/3836', 'G06F9/3858', 'G06F9/3887', 'G06F9/46', 'G06F9/467', 'G06F9/4881', 'G06F9/5016', 'G06F9/5033', 'G06F9/5061', 'G06F9/5077', 'G06N3/045', 'G06N3/049', 'G06N3/06', 'G06N3/063', 'G06N3/065', 'G06N3/08', 'G06N3/10', 'H03M7/3059', 'H03M7/3066', 'H03M7/3088', 'H03M7/46', 'H03M7/6005', 'H03M7/6011', 'H03M7/6058', 'H03M7/70', 'H04L45/04', 'H04L45/50', 'H04L67/02', 'H04L67/1001', 'G06F2209/484', 'G06F2209/485', 'G06F2212/1016', 'G06F2212/6026', 'G06F2212/657', 'Y02D10/00', 'Y02D30/50']"
WO2020077672A1,Method and device for training service quality evaluation model,"Disclosed are a method and device for training a service quality evaluation model, wherein the method comprises: collecting machine performance data, network feature data and quality monitoring data of a service node according to a fixed period; determining a feature value based on the machine performance data and the network feature data; determining target quality data based on the quality monitoring data; using the feature value and the target quality data; and using a training set to construct a service quality evaluation model. In the present invention, by means of associating indicators, such as machine performance data and network feature data, with service quality through the feature engineering function of a deep neural network itself, combining a back-propagation algorithm for training, and fitting a nonlinear relationship therein, the time consumption of artificial feature engineering can be reduced, and the accuracy of service quality evaluation can also be improved.","['G06N3/084', 'G06F30/20', 'G06F18/2178', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'H04L41/50', 'H04L41/5009', 'H04L43/0817', 'H04L43/0876', 'H04L43/10', 'H04L43/50', 'G06N3/044']"
CN107480770B,Neural network quantization and compression method and device capable of adjusting quantization bit width,"The invention relates to the technical field of neural networks, and particularly provides a method and a device for quantizing and compressing a convolutional neural network. The method aims to solve the problem that the existing method for quantizing and compressing the neural network causes great loss to the network performance. The method comprises the steps of obtaining a weight tensor and an input feature tensor of an original convolutional neural network, carrying out fixed-point quantization on the weight tensor and the input feature tensor based on a preset quantization bit width, and replacing the original weight tensor and the original input feature tensor with the obtained weight fixed-point representation tensor and the obtained input feature fixed-point representation tensor to obtain a new convolutional neural network obtained by quantizing and compressing the original convolutional neural network. The invention can flexibly adjust the bit width according to different task requirements, can realize the quantization and compression of the convolutional neural network without adjusting an algorithm structure and a network structure, and reduces the occupation of memory and storage resources. The invention also provides a storage device and a processing device, which have the beneficial effects.","['G06N3/045', 'G06N3/082']"
US11010929B2,Image compression with bounded deep neural network perception loss,"Example method includes: transmit a plurality of probe images from an Internet of Things (IoT) device at an edge network to a server hosting a target deep neural network (DNN), wherein the plurality of images are injected with a limited amount of noise; receive a feedback comprising a plurality of discrete cosine transform (DCT) coefficients from the server hosting the target DNN, wherein the plurality of DCT coefficients are unique to the target DNN; generate a quantization table based on the feedback received from the server hosting the target DNN; compress a set of real-time images using the generated quantization table by the IoT device at the edge network; and transmit the compressed set of real-time images to the server hosting the target DNN for DNN inferences.","['G06N3/084', 'G06F17/147', 'G06N3/04', 'G06N3/045', 'G06N5/04', 'G06T9/002']"
US8904181B1,System and method for secure three-party communications,"A system and method for communicating information between a first party and a second party, comprising the steps of receiving, by an intermediary, an identifier of desired information and accounting information for a transaction involving the information from the first party, transmitting an identifier of the first party to the second party, and negotiating, by the intermediary, a comprehension function for obscuring at least a portion of the information communicated between the first party and the second party. The data transmission may be made secure with respect to the intermediary by providing an asymmetric key or direct key exchange for encryption of the communication between the first and second party. The data transmission may be made secure with respect to the second party by maintaining the information in encrypted format at the second party, with the decryption key held only by the intermediary, and transmitting a secure composite of the decryption key and a new encryption key to the second party for transcoding of the data record, and providing the new decryption key to the first party, so that the information transmitted to the first party can be comprehended by it.","['H04L9/0825', 'H04L63/061', 'H04L9/0841', 'H04L9/302', 'H04L9/321', 'H04L9/3249', 'H04L2209/56', 'H04L2209/608', 'H04L2209/805', 'H04L2209/88', 'H04L63/0442']"
US20210004677A1,"Data compression using jointly trained encoder, decoder, and prior neural networks","Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an encoder neural network, a decoder neural network, and a prior neural network, and using the trained networks for generative modeling, data compression, and data decompression. In one aspect, a method comprises: providing a given observation as input to the encoder neural network to generate parameters of an encoding probability distribution; determining an updated code for the given observation; selecting a code that is assigned to an additional observation; providing the code assigned to the additional observation as input to the prior neural network to generate parameters of a prior probability distribution; sampling latent variables from the encoding probability distribution; providing the latent variables as input to the decoder neural network to generate parameters of an observation probability distribution; and determining gradients of a loss function.","['G06N3/08', 'G06N3/084', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06N5/046', 'G06N7/005', 'G06N7/01', 'G06N3/006', 'G10L19/00', 'H03M7/40']"
CN107301668B,"A kind of picture compression method based on sparse matrix, convolutional neural networks","The picture compression method based on sparse matrix, convolutional neural networks that the invention discloses a kind of, the following steps are included: converting images into dimensional matrix data, utilize convolutional neural networks assessment, optimization and building sparse matrix image, pass through convolutional neural networks preferred compressed scheme again, compression processing is carried out to sparse matrix image with the optimal compression scheme selected, finally obtains the compression image that high compression ratio is high, distortion is few.The present invention solves that existing compress technique compression ratio is low, picture quality decline is too many after compression, the problem of making image be difficult with and identify, and this compression method can be optimized according to image content, suitable picture construction and compression method are voluntarily selected, picture feature is extracted and has the ability for voluntarily optimizing and learning with compression method.","['G06T9/00', 'G06N3/02']"
CN109102064B,High-precision neural network quantization compression method,"The invention discloses a high-precision neural network quantization compression method, which comprises the following steps: counting a data range and compressing the data range inwards to ensure that the data range of each layer is compressed inwards to the minimum under the condition of keeping the accuracy rate unchanged; unsigned index quantization is adopted to replace signed value quantization so as to improve the operation precision and avoid the waste of quantization space; the invention can compress the quantization width to 8 bits or below and simultaneously save high calculation precision, has very little influence on the final result, and can ensure that the deep learning network model can be deployed and operated on the embedded equipment.","['G06N3/045', 'H03M7/30']"
CN113159173B,Convolutional neural network model compression method combining pruning and knowledge distillation,"The invention relates to a convolution neural network model compression method combining pruning and knowledge distillation. The method comprises the following steps: acquiring an image training set A; obtaining a target network model, and introducing a scaling factor gamma to each channel contained in the target network model; training a target network model, and taking the trained model as a teacher network; pruning the channel number of the teacher network according to the absolute value of the scaling factor gamma, and taking the pruned model as a student network; acquiring a small amount of images in the image training set A, inputting teacher and student networks at the same time, and respectively calculating the distribution difference between feature images output by all convolution layer channels of the teacher and student networks; training the student network by taking the distribution difference as a loss function, so that the model precision of the student network is quickly restored to the level of the teacher network; and outputting the trained student network. The invention has the advantages of high compression rate and quick recovery of the compression model precision, thereby facilitating the deployment of the network model on the terminal equipment.","['G06F18/214', 'G06N3/045', 'Y02D10/00']"
US10713818B1,Image compression with recurrent neural networks,"Methods, and systems, including computer programs encoded on computer storage media for compressing data items with variable compression rate. A system includes an encoder sub-network configured to receive a system input image and to generate an encoded representation of the system input image, the encoder sub-network including a first stack of neural network layers including one or more LSTM neural network layers and one or more non-LSTM neural network layers, the first stack configured to, at each of a plurality of time steps, receive an input image for the time step that is derived from the system input image and generate a corresponding first stack output, and a binarizing neural network layer configured to receive a first stack output as input and generate a corresponding binarized output.","['G06V10/82', 'G06F18/214', 'G06F18/2414', 'G06K9/6256', 'G06K9/66', 'G06T9/002', 'G06V10/454', 'G06V30/19173', 'H04N19/90']"
US11625613B2,Generative adversarial neural network assisted compression and broadcast,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display.","['G06N3/088', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T7/70', 'G06V10/7747', 'G06V10/82', 'G06V40/166', 'G06V40/168', 'G06N3/044', 'G06N3/084']"
US11791837B2,Method and apparatus for neural network model compression/decompression,"Aspects of the disclosure provide methods and apparatuses for neural network model compression/decompression. In some examples, an apparatus for neural network model decompression includes receiving circuitry and processing circuitry. The processing circuitry decodes, from a bitstream corresponding to a representation of a neural network, at least a syntax element to be applied to multiple blocks in the neural network. Then, the processing circuitry reconstructs, from the bitstream, weight coefficients in the blocks based on the syntax element.","['H03M7/3064', 'G06N3/02', 'G06N3/04', 'G06N3/063', 'H03M7/4075', 'H03M7/6005', 'H04N19/119', 'H04N19/124', 'H04N19/129', 'H04N19/146', 'H04N19/176', 'H04N19/184', 'H04N19/423', 'H04N19/44', 'H04N19/11', 'H04N19/13', 'H04N19/70']"
US20220343169A1,Cluster compression for compressing weights in neural networks,"A method for instantiating a convolutional neural network on a computing system. The convolutional neural network includes a plurality of layers, and instantiating the convolutional neural network includes training the convolutional neural network using a first loss function until a first classification accuracy is reached, clustering a set of F×K kernels of the first layer into a set of C clusters, training the convolutional neural network using a second loss function until a second classification accuracy is reached, creating a dictionary which maps each of a number of centroids to a corresponding centroid identifier, quantizing and compressing F filters of the first layer, storing F quantized and compressed filters of the first layer in a memory of the computing system, storing F biases of the first layer in the memory, and classifying data received by the convolutional neural network.","['G06N3/08', 'G06N3/084', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/0442']"
US10970617B2,Deep convolutional neural network acceleration and compression method based on parameter quantification,An acceleration and compression method for a deep convolutional neural network based on quantization of a parameter provided by the present application comprises: quantizing the parameter of the deep convolutional neural network to obtain a plurality of subcode books and respective corresponding index values of the plurality of subcode books; acquiring an output feature map of the deep convolutional neural network according to the plurality of subcode books and respective corresponding index values of the plurality of subcode books. The present application may implement the acceleration and compression for a deep convolutional neural network.,"['G06V10/82', 'G06F17/16', 'G06F18/21343', 'G06F18/24143', 'G06K9/4628', 'G06K9/6243', 'G06K9/6274', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454']"
US20220027704A1,Per kernel kmeans compression for neural networks,"Methods and apparatus relating to techniques for incremental network quantization. In an example, an apparatus comprises logic, at least partially comprising hardware logic to determine a plurality of weights for a layer of a convolutional neural network (CNN) comprising a plurality of kernels; organize the plurality of weights into a plurality of clusters for the plurality of kernels; and apply a K-means compression algorithm to each of the plurality of clusters. Other embodiments are also disclosed and claimed.","['G06N3/04', 'G06N3/063', 'G06F3/0608', 'G06F3/0644', 'G06F3/0673', 'G06N20/10', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N3/048', 'G06N3/088']"
US11625584B2,Reconfigurable memory compression techniques for deep neural networks,Examples described herein relate to a neural network whose weights from a matrix are selected from a set of weights stored in a memory on-chip with a processing engine for generating multiply and carry operations. The number of weights in the set of weights stored in the memory can be less than a number of weights in the matrix thereby reducing an amount of memory used to store weights in a matrix. The weights in the memory can be generated in training using gradients from back propagation. Weights in the memory can be selected using a tabulation hash calculation on entries in a table.,"['G06F7/5443', 'G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N3/086', 'Y02D10/00']"
CN113720399B,Remote intelligent monitoring method and device for insulation sling for extra-high voltage live working,"The invention relates to the field of artificial intelligence, in particular to a remote intelligent monitoring method and a remote intelligent monitoring device for an insulation sling for extra-high voltage live working, wherein the method comprises the following steps: acquiring a data group to be processed of the insulation sling, wherein the data group to be processed in each time period forms a data group set; presetting the number of times of cyclic compression, and performing cyclic compression on each data group set by using a self-coding network; for each data group set, after each compression, calculating the score of each compressed data based on the compression ratio and the information carrying capacity of the compressed data, the abnormal degree of the use state of the suspender represented by the data group to be processed corresponding to the compressed data and the electromagnetic interference degree in the corresponding time period of the data group set, and selecting the transmission data based on the scores; and transmitting the selected data to a control center, and carrying out remote monitoring on the insulating hanging strip by the control center according to the received data to realize monitoring on the use state of the hanging strip. The invention can carry out remote detection on the using state of the insulating sling.","['G01D21/02', 'G06N3/08']"
US11990148B2,Compressing audio waveforms using neural networks and vector quantizers,"Methods, systems and apparatus, including computer programs encoded on computer storage media. One of the methods includes receiving an audio waveform that includes a respective audio sample for each of a plurality of time steps, processing the audio waveform using an encoder neural network to generate a plurality of feature vectors representing the audio waveform, generating a respective coded representation of each of the plurality of feature vectors using a plurality of vector quantizers that are each associated with a respective codebook of code vectors, wherein the respective coded representation of each feature vector identifies a plurality of code vectors, including a respective code vector from the codebook of each vector quantizer, that define a quantized representation of the feature vector, and generating a compressed representation of the audio waveform by compressing the respective coded representation of each of the plurality of feature vectors.","['G10L19/00', 'G10L19/038', 'G06N3/045', 'G06N3/08', 'G10L25/30', 'H03M7/3082', 'H03M7/6029', 'G10L19/0017', 'G10L2019/0002', 'G10L2019/0005']"
US10614798B2,Memory compression in a deep neural network,"Aspects disclosed in the detailed description include memory compression in a deep neural network (DNN). To support a DNN application, a fully connected weight matrix associated with a hidden layer(s) of the DNN is divided into a plurality of weight blocks to generate a weight block matrix with a first number of rows and a second number of columns. A selected number of weight blocks are randomly designated as active weight blocks in each of the first number of rows and updated exclusively during DNN training. The weight block matrix is compressed to generate a sparsified weight block matrix including exclusively active weight blocks. The second number of columns is compressed to reduce memory footprint and computation power, while the first number of rows is retained to maintain accuracy of the DNN, thus providing the DNN in an efficient hardware implementation without sacrificing accuracy of the DNN application.","['G10L15/16', 'G06F18/24', 'G06K9/6267', 'G06N3/047', 'G06N3/0472', 'G06N3/063', 'G10L15/22', 'G10L15/285', 'G10L2015/223']"
CN111033530B,System and apparatus for compressing neural network parameters,"The present technology relates generally to storage and/or processing of signals and/or states representing neural network parameters in a computing device, and more particularly, may relate to compression of signals and/or states representing neural network nodes in a computing device.","['G06N3/04', 'G06N3/082', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/063', 'G06N3/10']"
US11301754B2,Sharing of compressed training data for neural network training,"An information processing device and method for sharing of compressed training data for neural network training is provided. The information processing device receives a first image which includes an object of interest. The information processing device extracts, from the received first image, a region of interest which includes the object of interest. Once extracted, the extracted region of interest is provided to an input layer of N numbers of layers of a first neural network, trained on an object detection task. The information processing device selects an intermediate layer of the first neural network and extracts a first intermediate result as an output generated by the selected intermediate layer of the first neural network based on the input RoI. Once extracted, the information processing device shares the extracted first intermediate result as compressed training data with a server to train a second neural network on the object detection task.","['G06N3/088', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T11/60', 'G06T7/0002', 'H04L65/601', 'H04L65/75', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G06T2210/12', 'G06T2210/22']"
US11412266B2,High level syntax for compressed representation of neural networks,"An apparatus includes at least one processor; and at least one non-transitory memory including computer program code; wherein the at least one memory and the computer program code are configured to, with the at least one processor, cause the apparatus at least to perform: encode or decode a high-level bitstream syntax for at least one neural network; wherein the high-level bitstream syntax comprises at least one information unit having metadata or compressed neural network data of a portion of the at least one neural network; and wherein a serialized bitstream comprises one or more of the at least one information unit.","['H04N19/70', 'G06N3/045', 'G06N3/0454', 'G06N3/105', 'H04N19/46', 'G06T9/002', 'G06T9/40', 'H04N19/61']"
WO2022052997A1,Method and system for training neural network model using knowledge distillation,"An agnostic combinatorial knowledge distillation (CKD) method for transferring trained knowledge of neural model from a complex model (teacher) to a less complex model (student) is described. In addition to training the student to generate a final output that approximates both the teacher's final output and a ground truth of a training input, the method further maximizes knowledge transfer by training hidden layers of the student to generate outputs that approximate a representation of a subset of teacher hidden layers are mapped to each of the student hidden layers for a given training input.","['G06N3/088', 'G06N3/08', 'G06N3/045']"
US20210279817A1,Systems and methods for utilizing compressed convolutional neural networks to perform media content processing,"Systems, methods, and non-transitory computer-readable media can receive a compressed convolutional neural network (CNN). A media content item to be processed can be acquired. The compressed CNN to can be utilized to apply a media processing technique to the media content item to produce information about the media content item. It can be determined, based on at least some of the information about the media content item, whether to transmit at least a portion of the media content item to one or more remote servers for additional media processing.","['G06N3/0464', 'G06F17/16', 'G06N20/00', 'G05B2219/40326', 'G06N3/045', 'G06N3/0454', 'G06Q50/01']"
CN109344921B,"A kind of image-recognizing method based on deep neural network model, device and equipment","The invention discloses a kind of image-recognizing methods based on deep neural network model, this method comprises: obtaining target image to be identified；Target image is input to, deep neural network model is carried out in the object module obtained after the beta pruning of channel using the characterization ability in channel；Classification processing is carried out to target image using the subsidiary classification device in object module, obtains recognition result.Since the object module of recognition target image is the model after the characterization ability based on channel carries out beta pruning, thus, calculation amount when identifying to target image can be greatly lowered.The invention also discloses a kind of pattern recognition device based on deep neural network model, equipment and readable storage medium storing program for executing, have corresponding technical effect.","['G06F18/24', 'G06N3/045']"
US11715019B2,Method and device for operating a neural network in a memory-efficient manner,"A method for operating a calculation system including a neural network, in particular a convolutional neural network, the calculation system including a processing unit for the sequential calculation of the neural network and a memory external thereto for buffering intermediate results of the calculations in the processing unit, including: incrementally calculating data sections, which each represent a group of intermediate results, with the aid of a neural network; lossy compression of one or multiple of the data sections to obtain compressed intermediate results; and transmitting the compressed intermediate results to the external memory.","['G06N3/10', 'G06F17/16', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06N3/063']"
CN110569901B,A weakly supervised object detection method based on channel selection for adversarial elimination,"The invention relates to a method for detecting a countermeasure elimination weak supervision target based on feature channel selection, which is used for solving the problem of detection and positioning errors of the weak supervision target. Firstly, using weak supervision depth target detection as a bottom-layer framework, generating a candidate frame on training set data by adopting a selective search method, and using the candidate frame, a training set image and a corresponding image label as input of a weak supervision network; secondly, constructing a feature extraction network model by taking VGG16 as a basic network, and carrying out channel weighting selection on the obtained feature images in a feature channel compression mode, so as to excite image feature layers beneficial to classification and inhibit feature layers with interference on classification; then, obtaining a complete characteristic expression capable of expressing the image target by adopting a countermeasure elimination method as the input of a prediction network; and finally, training a prediction network according to the multitask cross entropy loss to realize target detection. The invention not only can more accurately position the position of the target object, but also can improve the accuracy of object identification.","['G06F18/241', 'G06F18/253', 'G06V2201/07']"
CN111667054B,"Method, device, electronic equipment and storage medium for generating neural network model","The embodiment of the application discloses a method, a device, electronic equipment and a storage medium for generating a neural network model, and relates to the technical fields of artificial intelligence, deep learning and image processing. The specific implementation scheme is as follows: performing a plurality of iterative search operations, the iterative search operations comprising the steps of: determining a target compression strategy of a preset neural network model in a search space of the preset compression strategy by adopting a preset compression strategy controller, wherein the compression strategy comprises a combined strategy of pruning and quantization, pruning and quantizing the preset neural network model according to the target compression strategy to obtain a current compressed model, acquiring the performance of the current compressed model, generating feedback information based on the performance of the compressed model, and determining that the current compressed model is the generated target neural network model in response to determining that the feedback information reaches a preset convergence condition. The method can search out the optimal model compression strategy.","['G06N3/044', 'G06N3/045', 'G06N3/082', 'Y02D10/00']"
US7885988B2,Methods and apparatus for reducing storage size,"Prediction-based compression engines are spoon-fed with sequentially efficiently compressible (SEC) streams of input data that make it possible for the compression engines to more efficiently compress or otherwise compact the incoming data than would be possible with streams of input data accepted on a TV-raster scan basis. Various techniques are disclosed for intentionally forming SEC input data streams. Among these are the tight packing of alike files or fragments into concatenation suitcases and the decomposition of files into substantially predictably consistent (SPC) fragments or segments that are routed to different suitcases according to their type. In a graphics-directed embodiment, image frames are partitioned into segment areas that are internally SPC and multidirectional walks (i.e., U-turning walks) are defined in the segment areas where these defined walks are traced during compression and also during decompression. A variety of pre-compression data transformation methods are disclosed for causing apparently random data sequences to appear more compressibly alike to each other. The methods are usable in systems that permit substantially longer times for data compaction operations than for data decompaction operations.",['H03M7/30']
US10599935B2,Processing artificial neural network weights,A data processing apparatus processes a set of weight values for an artificial neural network by representing the set of weight values in the form of an array of weight values and by using an image compression scheme to provide compressed weight data for the artificial neural network. The data processing apparatus uses an image decompression scheme to derive decompressed weight values from the compressed weight data and applies the decompressed weight values when producing a result from an input to the artificial neural network. The data processing apparatus can provide for efficient storage and processing of the weight values for the artificial neural network.,"['G06K9/00986', 'G06N3/084', 'G06K9/4642', 'G06N3/045', 'G06N3/0454', 'G06V10/50', 'G06V10/82', 'G06V10/955']"
US12124779B2,Method of neural network construction for the simulation of physical systems,"A method of construction of a feedforward neural network includes a step of initialization of a neural network according to an initial topology, and at least one topological optimization phase, of which each phase includes: an additive phase including a modification of the network topology by adding at least one node and/or a connection link between the input of a node of a layer and the output of a node of any one of the preceding layers, and/or a subtractive phase including a modification of the network topology by removing at least one node and/or a connection link between two layers. Each topology modification includes the selection of a topology modification among several candidate modifications, based on an estimation of the variation in the network error between the previous topology and each topology modified according to a candidate modification.","['G06F30/27', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/084', 'G06N5/01']"
US20230328559A1,Reporting configurations for neural network-based processing at a ue,"This disclosure provides systems, devices, apparatus, and methods, including computer programs encoded on storage media, for reporting configurations for neural network-based processing at a UE. A network entity may transmit to the UE a CSI configuration that includes one or more parameters for a neural network and one or more reference signals. The UE may measure the one or more reference signals based on the CSI configuration. A CSI may be based on the one or more parameters and the measurement of the one or more reference signals. The UE may report the CSI to the network entity based on output of the neural network.","['H04L41/16', 'H04W24/08', 'G06N3/04', 'G06N3/08', 'H04L41/0806', 'H04W24/10']"
US20220138576A1,Neural network method and apparatus,"A lightened neural network method and apparatus. The neural network apparatus includes a processor configured to generate a neural network with a plurality of layers including plural nodes by applying lightened weighted connections between neighboring nodes in neighboring layers of the neural network to interpret input data applied to the neural network, wherein lightened weighted connections of at least one of the plurality of layers includes weighted connections that have values equal to zero for respective non-zero values whose absolute values are less than an absolute value of a non-zero value. The lightened weighted connections also include weighted connections that have values whose absolute values are no greater than an absolute value of another non-zero value, the lightened weighted connections being lightened weighted connections of trained final weighted connections of a trained neural network whose absolute maximum values are greater than the absolute value of the other non-zero value.","['G06N3/08', 'G06N3/04', 'G06N3/063', 'G06F5/01', 'G06F7/523', 'G06N3/082']"
CN109840589B,Method and device for operating convolutional neural network on FPGA,The invention provides a method and a device for operating a convolutional neural network on an FPGA (field programmable gate array)The method is used for solving the problems of complex implementation steps and high time cost when the convolutional neural network is operated on the FPGA in the prior art. The method comprises the following steps: the upper computer calculates a compression scale for quantizing each calculation parameter of each convolution layer of the convolutional neural network model according to a preset quantization bit width; determining convolution kernel weight W used by the FPGA for performing convolution calculation on the convolution layer when the FPGA executes the operation of the convolution layer according to the compression scale corresponding to each convolution layerfAnd a shift scale parameter scale for performing a shift operation on the convolution calculation result of the convolution layerfAnd a Bias for performing Bias operation on the displacement calculation result of the convolution layerf(ii) a W corresponding to each convolution layerf、scalefAnd BiasfWriting the FPGA so that the FPGA is based on the W corresponding to each convolution layer when the convolutional neural network model is operatedf、scalefAnd BiasfThe convolution layer is executed.,[]
US20230039729A1,Autonomous vehicle neural network optimization,"Methods and apparatus relating to autonomous vehicle neural network optimization techniques are described. In an embodiment, the difference between a first training dataset to be used for a neural network and a second training dataset to be used for the neural network is detected. The second training dataset is authenticated in response to the detection of the difference. The neural network is used to assist in an autonomous vehicle/driving. Other embodiments are also disclosed and claimed.","['G05B13/027', 'G05B13/0285', 'G05D1/0088', 'G06N20/00', 'G06N3/02', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/084', 'G06N5/047', 'H03M7/30', 'G06N3/063', 'G06N3/08', 'H04B1/66']"
US11295208B2,Robust gradient weight compression schemes for deep learning applications,"Embodiments of the present invention provide a computer-implemented method for adaptive residual gradient compression for training of a deep learning neural network (DNN). The method includes obtaining, by a first learner, a current gradient vector for a neural network layer of the DNN, in which the current gradient vector includes gradient weights of parameters of the neural network layer that are calculated from a mini-batch of training data. A current residue vector is generated that includes residual gradient weights for the mini-batch. A compressed current residue vector is generated based on dividing the residual gradient weights of the current residue vector into a plurality of bins of a uniform size and quantizing a subset of the residual gradient weights of one or more bins of the plurality of bins. The compressed current residue vector is then transmitted to a second learner of the plurality of learners or to a parameter server.","['G06N3/08', 'G06N3/084', 'G06N3/04', 'G06N3/044', 'G06N3/045']"
US20210374503A1,Network-centric architecture and algorithms to accelerate distributed training of neural networks,A distributed network includes a first group of computing devices. Each computing device is to be coupled to two neighbor computing devices of the first group of computing device and is to: (i) aggregate gradient values received from a first neighbor computing device with local gradient values to generate a partial aggregate of gradient values that are to train a neural network model; (ii) transfer the partial aggregate of gradient values to a second neighbor computing device; and repeat (i) and (ii) until a first aggregate of gradient values from the first group of computing devices is buffered at a first computing device of the first group of computing devices. The first computing device is to transfer the first aggregate of gradient values to a second group of computing devices of the distributed network for further aggregation.,"['G06N3/0454', 'G06N3/084', 'G06N3/045', 'G06N3/063', 'G06N3/10', 'H03M7/702']"
US20240161474A1,"Neural Network Inference Acceleration Method, Target Detection Method, Device, and Storage Medium","A neural network inference acceleration method includes: acquiring a neural network model to be accelerated and an accelerated data set; automatically performing accelerating process on the neural network model to be accelerated by using the accelerated data set to obtain the accelerated neural network model, wherein the accelerating process includes at least one of the following: model compression, graph optimization and deployment optimization, wherein the model compression includes at least one of the following: model quantification, model pruning and model distillation, wherein the graph optimization is the optimization for the directed graph of the neural network model to be accelerated, and the deployment optimization is the optimization for the deployment platform of the neural network model to be accelerated; and performing inference evaluation on the accelerated neural network model.","['G06N3/08', 'G06V10/776', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N5/04', 'G06V10/82', 'G06V10/87']"
US11049213B2,Efficient sharing and compression expansion of data across processing systems,"A mechanism is described for facilitating sharing of data and compression expansion of models at autonomous machines. A method of embodiments, as described herein, includes detecting a first processor processing information relating to a neural network at a first computing device, where the first processor comprises a first graphics processor and the first computing device comprises a first autonomous machine. The method further includes facilitating the first processor to store one or more portions of the information in a library at a database, where the one or more portions are accessible to a second processor of a computing device.","['G06T1/20', 'G06F9/544', 'G06F9/5027', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/084', 'H04L67/10']"
US11562244B2,Robust pruned neural networks via adversarial training,"Systems, methods, and computer readable media are described to train a compressed neural network with high robustness. The neural network is first adversarially pre-trained with both original data as well as data perturbed by adversarial attacks for some epochs, then “unimportant” weights or filters are pruned through criteria based on their magnitudes or other method (e.g., Taylor approximation of the loss function), and the pruned neural network is retrained with both clean and perturbed data for more epochs.","['G06N3/082', 'G06F17/13', 'G06F21/552', 'G06F21/577', 'G06N3/045', 'G06N3/084', 'G06N3/088']"
US11355033B2,Neural network model for generation of compressed haptic actuator signal from audio input,A method comprises inputting an audio signal into a machine learning circuit to compress the audio signal into a sequence of actuator signals. The machine learning circuit being trained by: receiving a training set of acoustic signals and pre-processing the training set of acoustic signals into pre-processed audio data. The pre-processed audio data including at least a spectrogram. The training further includes training the machine learning circuit using the pre-processed audio data. The neural network has a cost function based on a reconstruction error and a plurality of constraints. The machine learning circuit generates a sequence of haptic cues corresponding to the audio input. The sequence of haptic cues is transmitted to a plurality of cutaneous actuators to generate a sequence of haptic outputs.,"['G09B21/003', 'G01L5/0028', 'G06F3/011', 'G06F3/016', 'G06F3/167', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G08B6/00', 'G09B21/004', 'G09B21/04', 'G10L13/00', 'G10L15/02', 'G10L15/22', 'G10L21/02', 'G10L21/0272', 'G10L25/18', 'G10L25/48', 'G10L15/16', 'G10L19/0018', 'G10L2015/025', 'G10L2021/065', 'G10L21/06']"
EP4303820A1,Neural network based identification of areas of interest in digital pathology images,"A CNN is applied to a histological image to identify areas of interest. The CNN classifies pixels according to relevance classes including one or more classes indicating levels of interest and at least one class indicating lack of interest. The CNN is trained on a training data set including data which has recorded how pathologists have interacted with visualizations of histological images. In the trained CNN, the interest-based pixel classification is used to generate a segmentation mask that defines areas of interest. The mask can be used to indicate where in an image clinically relevant features may be located. Further, it can be used to guide variable data compression of the histological image. Moreover, it can be used to control loading of image data in either a client-server model or within a memory cache policy. Furthermore, a histological image of a tissue sample of a tissue type that has been treated with a test compound is image processed in order to detect areas where toxic reactions to the test compound may have occurred. An autoencoder is trained with a training data set comprising histological images of tissue samples which are of the given tissue type, but which have not been treated with the test compound. The trained autoencoder is applied to detect tissue areas by their deviation from the normal variation seen in that tissue type as learnt by the training process, and so build up a toxicity map of the image. The toxicity map can then be used to direct a toxicological pathologist to examine the areas identified by the autoencoder as lying outside the normal range of heterogeneity for the tissue type. This makes the pathologist's review quicker and more reliable. The toxicity map can also be overlayed with the segmentation mask indicating areas of interest. When an area of interest and an area identified as lying outside the normal range of heterogeneity for the tissue type, and increased confidence score is applied to the overlapping area.","['G06T7/0012', 'G06V10/454', 'G06V20/695', 'G06V10/26', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06V10/764', 'G06V10/82', 'G06V10/945', 'G16H80/00', 'G06T2207/10024', 'G06T2207/10056', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03', 'G06V2201/10']"
US11991368B2,Video compression using deep generative models,"Certain aspects of the present disclosure are directed to methods and apparatus for compressing video content using deep generative models. One example method generally includes receiving video content for compression. The received video content is generally encoded into a latent code space through an auto-encoder, which may be implemented by a first artificial neural network. A compressed version of the encoded video content is generally generated through a trained probabilistic model, which may be implemented by a second artificial neural network, and output for transmission.","['H04N19/149', 'H04N19/13', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/09', 'H04N19/117', 'H04N19/136', 'H04N19/172', 'H04N19/31', 'H04N19/90']"
CN116803075B,Machine learning based rate distortion optimizer for video compression,"Systems and techniques for data encoding are described that use a machine learning method to generate a distortion prediction d_hat and a prediction bit rate r_hat, and use d_hat and r_hat to perform Rate Distortion Optimization (RDO). For example, in response to the one or more neural networks receiving as input a residual portion of a block of a video frame, the video encoder may generate a distortion prediction d_hat and a bit rate residual prediction R res _hat based on an output of the one or more neural networks. The video encoder may determine a bit rate metadata prediction R meta _hat based on metadata associated with the compressed mode, and determine R as the sum of R res _hat and R meta _hat. The video encoder may determine a rate-distortion cost prediction, j_hat, as a function of d_hat and r_hat, and may determine a prediction mode for the compressed block based on j_hat.","['H04N19/147', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06T9/002', 'H04N19/103', 'H04N19/124', 'H04N19/149', 'H04N19/159', 'H04N19/176', 'H04N19/19', 'H04N19/46', 'G06T2207/20084']"
CN109255352B,"Target detection method, device and system","The invention provides a target detection method, a device and a system, which relate to the technical field of artificial intelligence, and the method comprises the following steps: acquiring a target image to be detected; performing feature extraction on the target image to generate a first feature map; wherein, the first characteristic diagram contains characteristic information with different scales; performing region candidate identification on the first feature map to obtain candidate region information of the target image; generating a detection result according to the candidate region information and the first feature map; the detection result includes a target category and/or a target position in the target image. The invention can effectively improve the detection effect.","['G06V10/255', 'G06N3/045', 'G06V10/462']"
US10223635B2,Model compression and fine-tuning,"Compressing a machine learning network, such as a neural network, includes replacing one layer in the neural network with compressed layers to produce the compressed network. The compressed network may be fine-tuned by updating weight values in the compressed layer(s).","['G06N3/0495', 'G06N3/082', 'G06N3/04', 'G06N3/048', 'G06N3/096', 'G06N3/08']"
US12015776B2,"Image compression and decoding, video compression and decoding: methods and systems","A computer-implemented method for lossy image or video compression, transmission and decoding, the method including the steps of: (i) receiving an input image at a first computer system; (ii) encoding the input image using a first trained neural network, using the first computer system, to produce a latent representation; (iii) quantizing the latent representation using the first computer system to produce a quantized latent; (iv) entropy encoding the quantized latent into a bitstream, using the first computer system; (v) transmitting the bitstream to a second computer system; (vi) the second computer system entropy decoding the bitstream to produce the quantized latent; (vii) the second computer system using a second trained neural network to produce an output image from the quantized latent, wherein the output image is an approximation of the input image. Related computer-implemented methods, systems, computer-implemented training methods and computer program products.","['G06N3/045', 'G06N3/047', 'G06N3/084', 'G06T3/4046', 'G06T9/002', 'G06V10/774', 'H04N19/126', 'H04N19/13', 'H04N19/503', 'H04N19/91', 'G06N3/044', 'G06N3/088']"
CN113515370B,Distributed training method for large-scale deep neural network,"The invention belongs to the crossing field of high-performance calculation and artificial intelligence, and particularly relates to a distributed training method for a large-scale deep neural network, which is characterized in that the communication process and the calculation process are overlapped by a layer-by-layer scheduling parameter synchronization process and reverse error propagation, so that communication overhead acceleration model training is hidden.","['G06N3/084', 'G06F9/5027', 'G06F9/5066', 'G06F9/5072', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/10', 'Y02D10/00']"
US20230229912A1,Model compression method and apparatus,"A model compression method is provided, which can be applied to the field of artificial intelligence. The method includes: obtaining a first neural network model, a second neural network model, and a third neural network model; processing first to-be-processed data using the first neural network model, to obtain a first output; processing the first to-be-processed data using the third neural network model, to obtain a second output; determining a first target loss based on the first output and the second output, and updating the second neural network model based on the first target loss, to obtain an updated second neural network model; and compressing the updated second neural network model to obtain a target neural network model. The model generated based on the method has higher processing precision.","['G06N3/0455', 'G06N3/063', 'G06N3/08', 'G06F18/214', 'G06N3/045', 'G06N3/0495', 'G06N3/082', 'G06N3/096']"
US11256984B2,Data compression for machine learning tasks,"A machine learning (ML) task system trains a neural network model that learns a compressed representation of acquired data and performs a ML task using the compressed representation. The neural network model is trained to generate a compressed representation that balances the objectives of achieving a target codelength and achieving a high accuracy of the output of the performed ML task. During deployment, an encoder portion and a task portion of the neural network model are separately deployed. A first system acquires data, applies the encoder portion to generate a compressed representation, performs an encoding process to generate compressed codes, and transmits the compressed codes. A second system regenerates the compressed representation from the compressed codes and applies the task model to determine the output of a ML task.","['G06N20/00', 'G06N3/0455', 'G06N3/04', 'G06N3/08', 'G06N3/084', 'G06V10/82', 'G06V20/52', 'G06V30/18057', 'G06V30/19147', 'G06V30/19167', 'G06V30/19173', 'G06V40/172', 'G06F18/214', 'G06F18/2178', 'G06F18/24143', 'G06K2209/01', 'G06K9/00288', 'G06K9/00744', 'G06K9/00771', 'G06K9/4619', 'G06K9/4628', 'G06K9/6212', 'G06K9/6232', 'G06K9/6256', 'G06K9/6263', 'G06K9/6274', 'G06K9/66', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06T5/002', 'G06T5/70', 'G06V10/449', 'G06V10/454', 'G06V10/758', 'G06V20/46', 'G06V30/10', 'G06V30/194', 'H04N19/126', 'H04N19/13', 'H04N19/149', 'H04N19/154', 'H04N19/167', 'H04N19/172', 'H04N19/18', 'H04N19/197', 'H04N19/33', 'H04N19/44', 'H04N19/48', 'H04N19/91']"
CN112203093B,Signal processing method based on deep neural network,"The invention discloses a signal processing method based on a deep neural network, which comprises the steps of firstly dividing a video frame into a key frame and a non-key frame according to a threshold value of mean square error of a current frame and a previous frame, and then compressing corresponding training network models of the key frame and the non-key frame respectively; for non-key frames, an entropy model self-encoder based on context and super-prior is adopted for intra-frame prediction; and for the non-key frame, extracting optical flow information and depth information to generate motion information in a combined manner, so as to reconstruct the frame, extracting and coding a residual between a reconstructed frame and a real frame, and finally generating a current frame by combining the transmitted motion information and residual information with a previous frame at a decoding end. The invention fully utilizes the strong nonlinear expression capability of the deep neural network and the advantages of joint training, and is an end-to-end video compression method with compression effect exceeding h.264.","['H04N19/159', 'G06T7/269', 'G06T9/002', 'H04N19/147', 'H04N19/172', 'H04N19/42', 'H04N19/85', 'H04N19/91', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
WO2021120719A1,"Neural network model update method, and image processing method and device","The present application discloses a neural network model update method, and an image processing method and device in the field of artificial intelligence. The neural network model updating method comprises: acquiring a structure of a neural network model, and a related parameter of the neural network model; training the neural network model on the basis of the related parameter of the neural network model to acquire a trained neural network model; and if an evaluation result of the trained neural network model does not meet a preconfigured condition, updating at least two items in the related parameter and the structure of the neural network model until an evaluation result of the updated neural network model meets the preconfigured condition and/or the number of updates reaches a preconfigured value. The method of the present application improves update efficiency of a neural network model, and obtains a structure and/or a related parameter of a neural network model having improved performance.","['G06N3/0464', 'G06N3/084', 'G06V10/778', 'G06F17/18', 'G06N3/006', 'G06N3/0442', 'G06N3/045', 'G06N3/047', 'G06N3/0495', 'G06N3/09', 'G06V10/774', 'G06V10/82', 'G06N3/063', 'G06N3/082', 'G06N5/025']"
US10699447B2,Multi-level image reconstruction using one or more neural networks,"A plurality of processors with logic units to train one or more neural networks for image construction, at least in part, using established one or more levels of compression for image data from a region of interest (ROI).","['G06T11/006', 'G06K9/3233', 'G06T1/20', 'G06T9/00', 'G06T2211/441']"
US20220156554A1,Lightweight Decompositional Convolution Neural Network,"A neural network (NN) and corresponding method employ an NN element (NNE) that includes a depthwise convolutional layer (DCL). The DCL outputs respective features by performing spatial convolution of respective input features having an original number of dimensions. The NNE includes a compression-expansion (CE) module that includes a first convolutional layer (CL) and second CL. The first CL outputs respective features as a function of respective input features. The respective features output from the first CL have a reduced number of dimensions relative to the original number of dimensions. The second CL outputs respective features, having the original number of dimensions, as a function of the respective features output from the first CL. The NNE further includes an add operator that outputs respective features as a function of the respective features output from the second CL and DCL. The NNE enables the NN to have a reduced size and to process data with competitive performance relative to conventional lightweight deep neural networks.","['G06N3/04', 'G06F17/153', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
US10015510B1,"Image compression system, decompression system, training method and device, and display device","The disclosure relates to an image compression system, an image decompression system, a training method and device, as well as a display device. In the image compression system, convolutional neural network modules are used to complete the update and prediction processes. As such, the weight of each filtering unit in the convolutional neural network module can be trained in order to provide the corresponding image compression system with a better compression rate, thereby reducing the difficulty in setting the filtering parameters of the image compression unit and the image decompression unit.","['H04N19/50', 'G06N3/045', 'G06N3/08', 'H04N19/117', 'H04N19/42', 'H04N19/48', 'H04N19/635', 'H04N19/90']"
CN112308200B,Neural network search method and device,"The application discloses a neural network searching method and device in the field of computer vision in the field of artificial intelligence. The searching method comprises the following steps: constructing a basic unit, wherein the basic unit is a network structure obtained by connecting basic modules through basic operation of a neural network, the basic module comprises a first module, the first module is used for carrying out dimension reduction operation and residual error connection operation on a first input feature map, the dimension reduction operation is used for transforming the dimension of the first input feature map from an original first dimension to a second dimension, the second dimension is smaller than the first dimension, and the residual error connection operation is used for carrying out feature addition processing on the first input feature map and the feature map processed by the first module; constructing a search space according to the basic unit and the network structure parameters; and searching a network structure in the search space to determine a target image super-resolution network. The method and the device can improve the precision of the super-resolution network under the condition of certain calculation performance.","['G06T3/4053', 'G06N3/0464', 'G06N3/04', 'G06N3/045', 'G06N3/0495', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'G06N3/086', 'G06N3/09', 'G06T3/40', 'H04N19/59']"
US11915144B2,"Apparatus, a method and a computer program for running a neural network","A method comprising: obtaining (400), in a first apparatus (500), media content, encoding (402), in a neural data compression network of the first apparatus (500), the media content wherein one or more parameters of the neural data compression network are determined based on a type of at least one analysis task to be performed on the media content; and transmitting (404) the encoded media content to a second apparatus (502).","['G06N3/084', 'G06F18/21', 'G06N3/045', 'G06N3/08', 'G06V10/70', 'G06V10/82', 'H04L65/70', 'H04L65/75', 'H04N19/117', 'H04N19/134', 'H04N19/136', 'H04N19/162', 'H04N21/8193', 'H04N21/845']"
US12079722B2,Method and device for optimizing neural network,"The embodiments of this application provide a method and device for optimizing neural network. The method includes: binarizing and bit-packing input data of a convolution layer along a channel direction, and obtaining compressed input data; binarizing and bit-packing respectively each convolution kernel of the convolution layer along the channel direction, and obtaining each corresponding compressed convolution kernel; dividing the compressed input data sequentially in a convolutional computation order into blocks of the compressed input data with the same size of each compressed convolution kernel, wherein the data input to one time convolutional computation form a data block; and, taking a convolutional computation on each block of the compressed input data and each compressed convolution kernel sequentially, obtaining each convolutional result data, and obtaining multiple output data of the convolution layer according to each convolutional result data.","['G06N3/08', 'G06F12/0207', 'G06F17/153', 'G06F17/16', 'G06N20/10', 'G06N3/045', 'G06N3/063', 'H03M7/30']"
CN112424797B,Concept of distributed learning of neural networks and/or transmission of parameterized updates thereof,The present application relates to several aspects that improve the efficiency of distributed learning.,"['G06N3/08', 'G06F18/214', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/09', 'G06N3/098', 'G06N3/044', 'G06N3/045']"
CN113435682B,Gradient compression for distributed training,Techniques for exchanging compression gradient data within a distributed system are disclosed. A set of gradients is calculated at a first operating node of the distributed system using the neural network model and a set of weights associated with the neural network model. Each of the gradient sets having a value less than the threshold is cropped to yield an unclamped data element and a cropped data element. A map is generated indicating which of the gradient sets correspond to unclamped data elements and which correspond to cropped data elements. Compressed data is generated based on the unclamped data elements. Mapping and compressing data is transmitted from a first working node to a second working node of the distributed system.,"['G06Q10/06311', 'G06F17/18', 'G06N20/00', 'G06N3/045', 'G06N3/0495', 'G06N3/0499', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/098', 'G06N5/046']"
US11847550B2,Sparse convolutional neural network accelerator,"A method, computer program product, and system perform computations using a processor. A first instruction including a first index vector operand and a second index vector operand is received and the first index vector operand is decoded to produce first coordinate sets for a first array, each first coordinate set including at least a first coordinate and a second coordinate of a position of a non-zero element in the first array. The second index vector operand is decoded to produce second coordinate sets for a second array, each second coordinate set including at least a third coordinate and a fourth coordinate of a position of a non-zero element in the second array. The first coordinate sets are summed with the second coordinate sets to produce output coordinate sets and the output coordinate sets are converted into a set of linear indices.","['G06N3/042', 'G06F17/11', 'G06F7/5443', 'G06F9/3001', 'G06F9/30018', 'G06F9/30025', 'G06F9/30036', 'G06F9/3851', 'G06F9/3887', 'G06F9/3888', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'G06F17/16', 'G06F2207/4824', 'G06F9/28', 'G06F9/3555']"
US10600147B2,Efficient memory layout for enabling smart data compression in machine learning environments,"A mechanism is described for facilitating efficient memory layout for enabling smart data compression in machine learning environments. A method of embodiments, as described herein, includes facilitating dividing an initial tile representing an image into primary multiple tiles such that each tile of the primary multiple tiles is regarded as an independent image as processed by one or more processors of a computing device. The method may further include computing the primary multiple tiles into secondary multiple tiles compatible in size of a local buffer. The method may further include merging the multiple secondary multiple tiles into a final tile representing the image, and compressing the final tile.","['G06T1/20', 'G06T1/60', 'G06N3/045', 'G06N3/08', 'G06T11/40', 'G06T9/002', 'G06T9/004', 'H04N19/119', 'H04N19/156', 'H04N19/176', 'H04N19/436']"
US20230051066A1,Partitioning Information In Neural Network-Based Video Coding,"A method implemented by a video coding apparatus. The method includes applying a neural network (NN) filter to an unfiltered sample of a video unit to generate a filtered sample, where the NN filter includes an NN filter model generated based on partitioning information of the video unit; and performing a conversion between a video media file and a bitstream based on the filtered sample.","['H04N19/117', 'H04N19/132', 'H04N19/182', 'H04N19/186', 'H04N19/82']"
US10997496B2,Sparse convolutional neural network accelerator,"A method, computer program product, and system perform computations using a sparse convolutional neural network accelerator. Compressed-sparse data is received for input to a processing element, wherein the compressed-sparse data encodes non-zero elements and corresponding multi-dimensional positions. The non-zero elements are processed in parallel by the processing element to produce a plurality of result values. The corresponding multi-dimensional positions are processed in parallel by the processing element to produce destination addresses for each result value in the plurality of result values. Each result value is transmitted to a destination accumulator associated with the destination address for the result value.","['G06N3/063', 'G06F7/523', 'G06F7/5443', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06F2207/4824', 'G06N3/082', 'G06N3/084']"
TWI716108B,Integrated circuit for convolution calculation in deep neural network and method thereof,"An integrated circuit applied in a deep neural network is disclosed. The integrated circuit comprises at least one processor, a first internal memory, a second internal memory, at least one MAC circuit, a compressor and a decompressor. The processor performs a cuboid convolution over decompression data for each cuboid of an input image fed to any one of multiple convolution layers. The MAC circuit performs multiplication and accumulation operations associated with the cuboid convolution to output a convoluted cuboid. The compressor compresses the convoluted cuboid into one compressed segment and store it in the second internal memory. The decompressor decompresses data from the second internal memory segment by segment to store the decompression data in the first internal memory. The input image is horizontally divided into multiple cuboids with an overlap of at least one row for each channel between any two adjacent cuboids.","['G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/048']"
US20230118031A1,Neural network adjustment method and apparatus,"A neural network adjustment method and apparatus. The neural network adjustment method relates to a first neural network and a second neural network. The method includes: whether a currently used neural network needs to be updated is first determined; and if the currently used neural network needs to be updated, a first device may autonomously complete the update or indicate a second device to complete the update. In other words, a more appropriate neural network may be obtained by updating a neural network in an AI model, to improve precision of information transmission based on the AI model.","['H04B7/0417', 'H04L1/0026', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04B7/0456', 'H04L1/0029', 'G06N3/048']"
CN112840358B,Cursor-based adaptive quantization for deep neural networks,"Deep Neural Network (DNN) model quantization can be used to reduce storage and computational burden by reducing bit width. A cursor-based adaptive quantization method for neural networks, a multi-bit quantization mechanism is formulated as a micro-architectural search (DAS) process with a continuous cursor representing possible quantized bits. The cursor-based DAS adaptively searches quantization bits for each layer. The DAS process may be accelerated via an alternative approximate optimization process designed for a hybrid quantization scheme of the DNN model. The new loss function is used in the search process to simultaneously optimize the accuracy and parameter size of the model. In the quantization step, DNN may be quantized together with two integers closest to the cursor as bits to reduce quantization noise and avoid the problem of local convergence.","['G06N3/063', 'G06N3/04', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06F16/28']"
US11863208B2,Data compression and storage,"A data compression method comprises encoding groups of data items by generating, for each group, header data comprising h-bits and a plurality of body portions each comprising b-bits and each body portion corresponding to a data item in the group. The value of h may be fixed for all groups and the value of b is fixed within a group, wherein the header data for a group comprises an indication of b for the body portions of that group. In various examples, b=0 and so there are no body portions. In examples where b is not equal to zero, a body data field is generated for each group by interleaving bits from the body portions corresponding to data items in the group. The resultant encoded data block, comprising the header data and, where present, the body data field can be written to memory.","['H03M7/40', 'H04L69/04', 'H03M7/6005', 'H03M7/30', 'G06N3/02', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'H03M7/3068', 'H03M7/4012', 'H03M7/46', 'H03M7/6011', 'H03M7/6047', 'G06T9/00', 'H03M7/3066', 'H03M7/4006', 'H04N19/184', 'H04N19/48', 'H04N19/93']"
US10623775B1,End-to-end video and image compression,"A system (e.g., an auto-encoder system) includes an encoder, a decoder and a learning module. The encoder generates compressed video data using a lossy compression algorithm, the lossy compression algorithm being implemented using a trained neural network with at least one convolution, generate at least one first parameter based on the compressed video data, and communicate the compressed video data and the model to at least one device configured to decode the compressed video data using an inverse algorithm based on the lossy compression algorithm. The decoder generates decoded video data based on the compressed video data using the inverse algorithm and the model, and generate at least one second parameter based on the decoded video data. The learning module trains the model using the at least one first parameter and the at least one second parameter.","['H04N19/61', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N3/088', 'H04N19/124']"
US11620766B2,Low rank matrix compression,"In an example, an apparatus comprises logic, at least partially including hardware logic, to implement a lossy compression algorithm which utilizes a data transform and quantization process to compress data in a convolutional neural network (CNN) layer.","['G06T9/002', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/048', 'G06N3/0481', 'G06N3/084', 'G06N3/088', 'H04N19/42', 'H04N19/436']"
US11049286B2,Deep neural network color space optimization,"Example method includes: transmitting a plurality of probe images from an IoT device at an edge network to a server hosting a target DNN, wherein the plurality of images are injected with a limited amount of noise to probe sensitivities of the target DNN to the red, green, and blue colors; receiving a feedback comprising a plurality of DCT coefficients unique to target DNN from the server hosting the target DNN; computing a plurality of color conversion weights based on the feedback received from the server; converting a set of real-time images from RGB color space to YUV color space using the plurality of color conversion weights unique to the target DNN; compressing the set of real-time images using a quantization table unique to the target DNN by the IoT device; and transmitting the compressed set of real-time images to the server hosting the target DNN for DNN inferences.","['G06T9/002', 'H04N1/64', 'G06T5/002', 'G06T5/70', 'H04N1/6027', 'H04N1/6077', 'H04N19/625', 'G06T2207/10024', 'G06T2207/20084', 'H04N1/644']"
US20240005135A1,Accelerating neural networks with low precision-based multiplication and exploiting sparsity in higher order bits,"An apparatus to facilitate accelerating neural networks with low precision-based multiplication and exploiting sparsity in higher order bits is disclosed. The apparatus includes a processor comprising a re-encoder to re-encode a first input number of signed input numbers represented in a first precision format as part of a machine learning model, the first input number re-encoded into two signed input numbers of a second precision format, wherein the first precision format is a higher precision format than the second precision format. The processor further includes a multiply-add circuit to perform operations in the first precision format using the two signed input numbers of the second precision format; and a sparsity hardware circuit to reduce computing on zero values at the multiply-add circuit, wherein the processor to execute the machine learning model using the re-encoder, the multiply-add circuit, and the sparsity hardware circuit.","['G06N3/063', 'G06F7/5443', 'G06N3/045', 'G06N3/048', 'G06N3/082', 'G06N3/088', 'G06F2207/3808']"
US12256332B2,"Method, apparatus, and device for reducing terminal power consumption","A method for reducing terminal power consumption includes sending, by a terminal device to an access device, power saving indication information indicating a power saving capability of the terminal device, and when the terminal device is idle, determining, by the access device, a sleep mode of the terminal device based on the power saving indication information and sending a sleep signal to the terminal device to indicate the terminal device to enter the sleep mode.","['H04W52/0212', 'H04W52/0235', 'H04L41/344', 'H04W52/0229', 'H04W76/27', 'H04W8/24', 'Y02D30/70']"
CN110059796B,Method and device for generating convolutional neural network,"The invention relates to a method and a device for generating a convolutional neural network, and belongs to the technical field of video coding and decoding. The method comprises the following steps: training the initial convolutional neural network to obtain a trained convolutional neural network; determining a convolutional neural network to be processed based on the trained convolutional neural network; and performing tensor decomposition operation on at least one target convolutional layer in the convolutional neural network to be processed to obtain a target convolutional neural network. The invention can solve the problem of low operation efficiency when the conventional convolutional neural network performs convolutional operation.","['G06F18/23211', 'G06N3/045', 'G06N3/08', 'H04N19/61']"
US11405626B2,Video compression using recurrent-based machine learning systems,"Techniques are described herein for coding video content using recurrent-based machine learning tools. A device can include a neural network system including encoder and decoder portions. The encoder portion can generate output data for the current time step of operation of the neural network system based on an input video frame for a current time step of operation of the neural network system, reconstructed motion estimation data from a previous time step of operation, reconstructed residual data from the previous time step of operation, and recurrent state data from at least one recurrent layer of a decoder portion of the neural network system from the previous time step of operation. A decoder portion of the neural network system can generate, based on the output data and recurrent state data from the previous time step of operation, a reconstructed video frame for the current time step of operation.","['H04N19/436', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04N19/137', 'H04N19/172', 'H04N19/42', 'H04N19/463', 'H04N19/503', 'H04N19/85']"
US7987003B2,Network media appliance system and method,"A network media appliance, comprising at least one packet data network interface, adapted for communicating data packets with a data network according to an Internet Protocol; a media data interface, and a processor, having an associated memory for storing executable code, said code defining at least a remote virtual interface function, and a data transfer function for controlling transfer of data through said media data interface.","['G05B15/02', 'G05B19/042', 'G06V40/103', 'G05B2219/25323', 'G05B2219/2613', 'G05B2219/2615', 'G05B2219/34038']"
CA3177620A1,"Quantum, biological, computer vision, and neural network systems for industrial internet of things","Computer-implemented methods for fault diagnosis in an industrial environment generally includes processing the plurality of sensor data values to determine a recognized pattern therefrom;
retrieving at least one industrial-environment digital twin corresponding to the industrial environment, the at least one industrial-environment digital twin comprising a plurality of component digital twins, with each of the plurality of component digital twins corresponding to one of the plurality of components in the industrial environment, and wherein the at least one industrial-environment digital twin and the plurality of component digital twins are visual digital twins that are configured to be rendered in a visual manner; and rendering the at least one industrial-environment digital twin and the at least one respective component digital twin corresponding to the particular component in the client application in response to the received request and based on the operational condition of the particular component.","['G05B19/41885', 'G05B13/027', 'G05B13/042', 'G05B13/048', 'G05B19/4184', 'G05B19/4188', 'G05B23/024', 'G05B23/0243', 'G05B23/0283', 'G06Q10/04', 'G06Q10/06', 'G06Q10/20', 'G06Q30/0201', 'G06Q30/0207', 'G06Q30/0251', 'G06Q50/04', 'G05B2219/31356', 'G05B2219/32014', 'G05B23/0272', 'G06Q2220/00']"
US20210201124A1,Systems and methods for neural network convolutional layer matrix multiplication using cache memory,"A computer processor may include a number of cores, a shared cache shared among the cores, and a local cache associated with each core and used by that core only. Input data for a neural network (NN) layer may be partitioned into a set of tiles of size T×T, and the tile set may be partitioned into blocks of R tiles. For each block, a core may perform a transform operation on the tiles to produce transformed data matrices fitting in a local cache, and a set of multiply operations, each multiply operation using a transformed data matrix and a transformed kernel matrix from a set of transformed kernel matrices. The set of transformed kernel matrices may fit in the shared cache. The result of at least one of the multiply operations may be stored in a location used to store a transformed data matrix.","['G06N3/063', 'G06F17/16', 'G06N3/045', 'G06N3/08']"
US12093210B2,Compression techniques,"Methods and apparatus relating to techniques for data compression. In an example, an apparatus comprises a processor receive a data compression instruction for a memory segment; and in response to the data compression instruction, compress a sequence of identical memory values in response to a determination that the sequence of identical memory values has a length which exceeds a threshold. Other embodiments are also disclosed and claimed.","['G06F12/0215', 'G06F12/0238', 'G06F12/0246', 'G06F12/0607', 'G06F12/0802', 'G06F12/0804', 'G06F12/0811', 'G06F12/0862', 'G06F12/0866', 'G06F12/0871', 'G06F12/0875', 'G06F12/0877', 'G06F12/0882', 'G06F12/0888', 'G06F12/0891', 'G06F12/0893', 'G06F12/0895', 'G06F12/0897', 'G06F12/1009', 'G06F12/128', 'G06F15/173', 'G06F15/7839', 'G06F15/8046', 'G06F16/24569', 'G06F17/16', 'G06F17/18', 'G06F7/5443', 'G06F7/575', 'G06F7/58', 'G06F7/588', 'G06F9/3001', 'G06F9/30014', 'G06F9/30036', 'G06F9/3004', 'G06F9/30043', 'G06F9/30047', 'G06F9/30065', 'G06F9/30079', 'G06F9/383', 'G06F9/3887', 'G06F9/3888', 'G06F9/5011', 'G06F9/5066', 'G06F9/5077', 'G06T1/20', 'G06T1/60', 'H03M7/46', 'G06F12/12', 'G06F2212/1008', 'G06F2212/1016', 'G06F2212/1021', 'G06F2212/1024', 'G06F2212/1044', 'G06F2212/2542', 'G06F2212/302', 'G06F2212/401', 'G06F2212/455', 'G06F2212/60', 'G06F2212/601', 'G06F2212/6026', 'G06F2212/6028', 'G06F2212/608', 'G06F2212/652', 'G06F9/3802', 'G06F9/3818', 'G06F9/3867', 'G06N3/08', 'G06T15/06']"
US11620497B2,Artificial neural networks,"An apparatus that operates in a first mode of operation to enable performance of a first predetermined task to transfer data via a transmitter device to a receiver device across a first communication channel using a first artificial neural network, wherein the first artificial neural network is partitioned to the transmitter device and the receiver device, and operate in a second mode of operation to enable performance of a second predetermined task to transfer data via the transmitter device to the receiver device across a second communication channel using a second artificial neural network, wherein the second artificial neural network is partitioned to the transmitter device and the receiver device, and determine to operate the apparatus in the first mode or the second mode.","['G06N3/0454', 'G06N3/045', 'G06F9/5077', 'H03M7/607', 'H04B1/0003']"
US11544559B2,System and method for executing convolution in a neural network,"A system and method of executing a convolution layer of a neural network may include: (a) selecting an output spatial position (OSP) of an output matrix data element of the convolution layer; (b) selecting, based on the selected OSP, a non-zero input element of an input matrix data element; (c) producing, based on the selected OSP, a vector of kernel elements from a kernel matrix data element; (d) performing a vectoral multiplication operation of the selected non-zero input element and the vector of kernel elements, and accumulating a product of the vectoral multiplication in a vector register of a processor; (e) repeating (c) and (d) with subsequent non-zero input elements and corresponding vectors of kernel elements to obtain an outcome of the convolution of the selected OSP; and (f) repeating (a) through (e) with subsequent selection of OSPs, to obtain an outcome of the convolution layer.","['G06N3/08', 'G06F17/153', 'G06F17/16', 'G06N20/10', 'G06N3/045', 'G06N3/048', 'G06N3/105']"
CN111488986B,"A model compression method, image processing method and device","The disclosure provides a model compression method, an image processing method and a device, which are used for carrying out channel pruning treatment on at least one network layer in a multi-layer network layer in a model to be compressed; the method comprises the following steps: determining a first target model according to the model compression progress in pruning processing of a corresponding channel of any network layer aiming at any network layer of at least one network layer, acquiring loss information of a sample image by using the first target model, and outputting first characteristic data of the sample image by the next network layer of any network layer in the first target model; determining classification loss guide information based on the loss information and the first feature data; and executing channel pruning processing on any network layer based on the classification loss guide information. According to the method and the device, pruning is carried out on one layer of neural network at a time, and channel pruning processing of the layer of neural network is guided based on the classification loss guiding information, so that compression efficiency can be guaranteed, and compression effect can be considered.","['G06N3/082', 'G06N3/045', 'G06N3/084', 'G06T9/00', 'H04N19/00', 'Y02D10/00']"
US10839452B1,Compressed network for product recognition,"Aspects of this disclosure include technologies to detect unpackaged, unlabeled, or mislabeled products based on product images. Leveraging from improved machine learning techniques, the disclosed technical solution can reduce a full product space for product search to a partial product space. Accordingly, a limited number of product candidates in the partial product space may be visually presented for user evaluation. Sometimes, a product candidate is to be comparatively presented with a live image of the product via a uniquely designed graphic user interface, which further improves the confidence of the user and the accuracy of the underlying transaction.","['G06Q30/0643', 'G06F17/15', 'G06F17/16', 'G06F18/2413', 'G06K17/0029', 'G06K9/00671', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/082', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/20', 'G06V20/68', 'G06V2201/07']"
US8370362B2,Database access system,"An improved human user computer interface system, wherein a user characteristic or set of characteristics, such as demographic profile or societal “role”, is employed to define a scope or domain of operation. The operation itself may be a database search, to interactively define a taxonomic context for the operation, a business negotiation, or other activity. After retrieval of results, a scoring or ranking may be applied according to user define criteria, which are, for example, commensurate with the relevance to the context, but may be, for example, by date, source, or other secondary criteria. A user profile is preferably stored in a computer accessible form, and may be used to provide a history of use, persistent customization, collaborative filtering and demographic information for the user. Advantageously, user privacy and anonymity is maintained by physical and algorithmic controls over access to the personal profiles, and releasing only aggregate data without personally identifying information or of small groups.","['G06Q30/0275', 'G06F16/2457', 'G06F16/24578', 'G06F16/248', 'G06F16/3323', 'G06F21/6245', 'G06Q30/0212', 'G06Q30/0226', 'G06Q30/0242', 'G06Q30/0247', 'G06Q30/0269', 'G06Q30/0277', 'Y10S707/99932', 'Y10S707/99933']"
CN109213999B,Subjective question scoring method,"A subjective question scoring method comprises sentence preprocessing, feature extraction, feature fusion, similarity calculation and comprehensive scoring. The sentence preprocessing is used for sentence segmentation, word segmentation, keyword detection, part-of-speech tagging and sentence emotion analysis of a target paragraph; the feature extraction algorithm is used for extracting word vectors, sentence vectors, word structures and syntax structures; the feature fusion is used for fusing M sentence target paragraphs into a comparison template (N < M) containing N templates: the similarity calculation is used for calculating word similarity and sentence similarity; and the comprehensive scoring is used for constructing a weight model according to the word similarity, sentence similarity, word structure similarity, syntax mechanism similarity, keyword score and emotion score of the student answers and the comparison template, so as to score the student answers. The invention meets the subjective question scoring requirements of various subjects, and can obtain good scoring effect through training of a small number of samples.","['G06F40/289', 'G06F40/211', 'G06F40/253', 'G06F40/30', 'Y02D10/00']"
US10839564B2,Leveraging JPEG discrete cosine transform coefficients in neural networks,A system classifies a compressed image or predicts likelihood values associated with a compressed image. The system partially decompresses compressed JPEG image data to obtain blocks of discrete cosine transform (DCT) coefficients that represent the image. The system may apply various transform functions to the individual blocks of DCT coefficients to resize the blocks so that they may be input together into a neural network for analysis. Weights of the neural network may be trained to accept transformed blocks of DCT coefficients which may be less computationally intensive than accepting raw image data as input.,"['G06T9/002', 'G06N3/02', 'G06N3/08', 'H04N19/186', 'H04N19/48', 'H04N19/625']"
WO2021052126A1,"Product information recommendation method and apparatus, storage medium, and computer device","A product information recommendation method and apparatus, a storage medium, and a computer device, relating to the technical field of information processing, and being able to improve the accuracy of information recognition. Said method comprises: training an initialized first product recommendation model according to group statistical information, so as to obtain a trained first product recommendation model (101); training an initialized second product recommendation model according to product quantification information, so as to obtain a trained second product recommendation model (102); constructing a product recommendation prediction model according to a first hidden layer of the trained first product recommendation model and a second hidden layer of the trained second product recommendation model (103); and obtaining, according to the historical purchase information of a user, product recommendation prediction information matching the historical purchase information by means of the constructed product recommendation prediction model (104). Said method is applicable to accurate pushing of products in both mobile Internet and e-commerce.","['G06Q30/0631', 'G06N3/045', 'G06N3/08', 'G06Q40/02']"
US11481613B2,"Execution method, execution device, learning method, learning device, and recording medium for deep neural network","Executing a deep neural network by obtaining, during deep neural network inference, a binary intermediate feature map in binary representation by converting a floating-point or fixed-point intermediate feature map into a binary vector using a first transformation module; generating a compressed feature map by compressing the binary intermediate feature map using a nonlinear dimensionality reduction layer; storing the compressed feature map into memory; reconstructing the binary intermediate feature map by decompressing the compressed feature map read from the memory using a reconstruction layer corresponding to the nonlinear dimensionality reduction layer; and converting the reconstructed binary intermediate feature map into a floating-point or fixed-point intermediate feature map using a second transformation module.","['G06N3/084', 'G06N3/04', 'G06N3/045', 'G10L15/22', 'G06N3/048', 'G06N3/063']"
CN111860757B,Efficient matrix formats for neural networks,"The invention discloses a high-efficiency matrix format suitable for a neural network. In particular, many computing systems process data organized in a matrix format. For example, artificial neural networks perform extensive computation on data organized into matrices using conventional matrix arithmetic operations. One such operation is a transpose operation. Techniques are presented to store matrices in a compressed format, e.g., that allow transpose operations to be performed during decompression. Thus, by utilizing the described techniques, transformation (e.g., transposition) of the compressed matrix may be achieved in a more efficient manner. Parallel processing may also be used to more efficiently compress and/or decompress.","['G06N3/045', 'G06T9/002', 'G06F17/16', 'G06F7/544', 'G06N3/063', 'G06N3/084', 'G06V10/513']"
CN113924786B,Neural network models for cochlear mechanics and processing,"A method and hearing device (100) for cochlear processing mimicking auditory stimulation are disclosed, wherein a multi-layer convolutional encoder-decoder neural network (10) sequentially compresses and then decompresses a time-domain input comprising a plurality of samples. At least one nonlinear unit for applying nonlinear transformation emulates cochlear filter tuning associated with levels associated with cochlear mechanics and outer hair cells. Other described modules include internal hair cell and auditory nerve fiber processing. The plurality of short-cut connections (15) forwards the input directly between the convolutional layer of the encoder (11) and the convolutional layer of the decoder (12). An output layer (14) generates N output sequences of cochlear response parameters for each input of the neural network to develop a cochlear frequency topology location-frequency map, the N output sequences of cochlear response parameters corresponding to N mimicked cochlear filters associated with N different center frequencies.","['G06N3/084', 'H04R25/507', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/0985', 'G10L21/0364', 'H04R25/606', 'A61N1/36038', 'G10L25/30', 'H04R2225/41']"
CN108307193B,A kind of the multiframe quality enhancement method and device of lossy compression video,"The present invention provides the multiframe quality enhancement method and device of a kind of lossy compression video, and method includes: the i-th frame for the video flowing of decompression, quality enhancing is carried out to i-th frame using the associated m frame of i-th frame, with enhanced i-th frame of play quality；The m frame belongs to the frame in the video flowing, and each frame and i-th frame are respectively provided with identical or corresponding pixel quantity greater than preset threshold in the m frame；M is the natural number greater than 1.In a particular application, enhance the non-non-peak quality frame between two peak value quality frames using peak value quality frame.The above method alleviates the quality fluctuation during video render between multiframe, while each frame quality in lossy compression rear video is enhanced.","['G06N3/08', 'H04N19/172', 'G06F18/214', 'G06F18/2411', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06V10/764', 'G06V10/82', 'G06V20/40', 'G06V20/46', 'H04N19/154', 'H04N19/159', 'H04N19/48', 'H04N19/51', 'H04N19/577', 'H04N19/86', 'H04N9/87', 'G06N20/10']"
CN110809771B,Systems and methods for compression and distribution of machine learning models,"The present disclosure provides systems and methods for compressing and/or distributing machine learning models. In one example, a computer-implemented method is provided for compressing a machine learning model, the method comprising obtaining, by one or more computing devices, the machine learning model. The method includes selecting, by one or more computing devices, a weight to be quantized, and quantizing, by the one or more computing devices, the weight. The method includes propagating, by the one or more computing devices, at least a portion of the quantization error to one or more unquantized weights, and quantizing, by the one or more computing devices, one or more of the unquantized weights. The method includes providing, by one or more computing devices, a quantized machine learning model.","['G06N20/00', 'G06N3/0495', 'G06N3/04', 'G06N3/096', 'G06N3/098', 'G06N3/063', 'G06N3/084']"
US11651192B2,Compressed convolutional neural network models,"Systems and processes for training and compressing a convolutional neural network model include the use of quantization and layer fusion. Quantized training data is passed through a convolutional layer of a neural network model to generate convolutional results during a first iteration of training the neural network model. The convolutional results are passed through a batch normalization layer of the neural network model to update normalization parameters of the batch normalization layer. The convolutional layer is fused with the batch normalization layer to generate a first fused layer and the fused parameters of the fused layer are quantized. The quantized training data is passed through the fused layer using the quantized fused parameters to generate output data, which may be quantized for a subsequent layer in the training iteration.","['G06N3/04', 'G06N3/084', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/044']"
US11307064B2,Apparatus and method for processing multi-type sensor signal on the basis of multi-modal deep learning,"An apparatus for processing multi-type sensor signals on the basis of multi-modal deep learning, the apparatus including: an individual sensor failure diagnosis unit configured to measure a normality of a sensor output of a single modal sensor at each sampling period, and sense an abnormal operation of the sensor on the basis of the measured normality; an inter-sensor mutual failure diagnosis unit including a multi-modal deep auto encoder, and configured to learn a correlation existing between multi-modalities, extract shared representation between modalities from multi-modal inputs on the basis of the learned correlation, and perform an inter-sensor mutual failure diagnosis; and a reconstruction target sensor output value reconstructing unit configured to, when an output value of a specific sensor is missing, predict and reconstruct the output value of the sensor using other sensor information using the shared representation extracted from other modal sensors.","['G05B23/0243', 'G01D3/08', 'G01D18/00', 'G05B21/02', 'G05B23/0221', 'G05B23/0283', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
US20210397943A1,Techniques for classification with neural networks,"Apparatuses, systems, and techniques to train neural networks to perform classification. In at least one embodiment, one or more neural networks are trained to perform classification based on, for example, using one or more compressed representations of one or more class labels, where the one or more compressed representations have fewer bits than a representation of the one or more class labels.","['G06F18/214', 'G06F18/241', 'G06N3/063', 'G06F18/24137', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06V10/764', 'G06V10/774', 'G06V10/82']"
US7966078B2,Network media appliance system and method,"A network media appliance, comprising at least one packet data network interface, adapted for communicating data packets with a data network according to an Internet Protocol; a media data interface, and a processor, having an associated memory for storing executable code, said code defining at least a remote virtual interface function, and a data transfer function for controlling transfer of data through said media data interface.","['G06F3/048', 'G05B15/02', 'G06N5/025', 'G06Q30/02', 'G06Q30/0248', 'G06Q30/0255', 'G06Q30/0267', 'G06Q30/0269', 'G06Q30/0273', 'H04N21/4131', 'H04N21/42201', 'H04N21/44224', 'H04N21/4532', 'H04N21/47', 'H04N5/782', 'H04N5/913', 'G06N20/00', 'H04N2005/91328', 'H04N2005/91364']"
US11995767B2,Apparatus and method for compressing ray tracing acceleration structure build data,"Apparatus and method for compression of acceleration structure build data in a ray tracing implementation. For example, one embodiment of an apparatus comprises: traversal hardware logic to traverse rays through a graphics scene comprising a plurality of primitives; and an acceleration data structure processing unit comprising: a bounding box compressor to compress a set of bounding boxes to generate a plurality of bounding box compression blocks, and an index compressor to compress a set of indices to generate a plurality of index compression blocks, and an acceleration data structure builder for constructing acceleration structures based on bounding box compression blocks and index compression blocks.","['G06F9/5016', 'G06T17/10', 'G06N20/00', 'G06T1/20', 'G06T15/06', 'G06T15/08', 'G06T17/20', 'G06T3/4007', 'G06T9/00', 'G06T9/001', 'G06T15/005', 'G06T2210/12']"
US11595847B2,Configuration of artificial intelligence (AI) modules and compression ratios for user-equipment (UE) feedback,"Certain aspects of the present disclosure provide techniques for feedback compression. Certain aspects provide a method for wireless communication by a user-equipment (UE). The method generally includes receiving, from a base station, a configuration to be used for compressing one or more measurements corresponding to at least one reference signal using an artificial intelligence (AI) encoder; receiving the at least one reference signal; and transmitting a codeword to the base station, the codeword being associated with a compression of the one or more measurements in accordance with the configuration.","['H04W28/06', 'H04B7/063', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'H04B7/0486', 'H04B7/0626', 'H04B7/0632', 'H04B7/0639', 'H04W24/10', 'H04W72/042', 'H04W72/23', 'H04W76/27', 'H04W80/02']"
CN107977704B,Weight data storage method and neural network processor based on the method,"The invention provides a weight data storage method and a convolution calculation method in a neural network. The weight storage method comprises the following steps: searching effective weights in a weight convolution kernel matrix and obtaining an effective weight index, wherein the effective weights are nonzero weights, and the effective weight index is used for marking the positions of the effective weights in the weight convolution kernel matrix; storing the effective weight and the effective weight index. According to the weight data storage method and the convolution calculation method, storage space can be saved, and calculation efficiency can be improved.","['G06F17/153', 'G06F17/16', 'G06F18/2163', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08']"
US11438632B2,Method and system of neural network loop filtering for video coding,"A method, system, medium, and article provide neural network loop filtering for video coding with multiple alternative neural networks.","['H04N19/82', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'H04N19/117', 'H04N19/172', 'H04N19/176', 'H04N19/70', 'G06N3/048']"
CN110969251A,Method and device for quantifying neural network model based on unlabeled data,"The invention relates to the technical field of image processing, in particular to a neural network model quantification method and device based on label-free data. In order to solve the problem that the neural network compression can be realized only by depending on a training set in the prior art, the invention provides a neural network model quantization method based on label-free data, which comprises the steps of quantizing the weight of an original neural network model based on a first preset quantization bit width to obtain a first quantized neural network model; optimizing the quantization bit width of each layer of different channels of the first quantization neural network model based on the output of the original neural network model and the output of the first quantization neural network model to obtain a second quantization neural network model; and optimizing the weight of the second quantitative neural network model based on the characteristics of the original neural network model and the characteristics of the second quantitative neural network model to obtain the target neural network model. The method of the invention can quantify the neural network model through a small amount of label-free data.",['G06N3/082']
US12212764B2,Image compression method and apparatus,"An image compression method includes obtaining a hidden variable of an input image using a coding network of a deep learning neural network comprising at least one downsampling back projection module including performing downsampling transformation on a first feature map of the input image input to the downsampling back projection module to obtain a second feature map, obtaining a third feature map having a same resolution as a resolution of the first feature map by reconstructing the second feature map, and obtaining a fourth feature map as an optimization result of the second feature map, based on a difference value between the first feature map and the third feature map; and obtaining a bitstream file of a compressed image by performing entropy coding based on the hidden variable obtained based on the fourth feature map of a last downsampling back projection module.","['H04N19/59', 'H04N19/42', 'G06T3/4046', 'H04N19/136', 'H04N19/147', 'H04N19/91']"
US10909728B1,Learned lossy image compression codec,"Techniques for learned lossy image compression are described. A system may perform image compression using an image compression model that includes an encoder to compress an image and a decoder to reconstruct the image. The encoder and the decoder are trained using machine learning techniques. After training, the encoder can encode image data to generate compressed image data and the decoder can decode compressed image data to generate reconstructed image data.","['G06T3/4046', 'G06N20/10', 'G06N3/045', 'G06N3/084', 'G06T3/40', 'G06T9/002', 'G06N3/048']"
CN109615016B,Target detection method of convolutional neural network based on pyramid input gain,"The invention relates to a target detection method of a convolutional neural network based on pyramid input gain, and belongs to the technical field of computer vision and target detection. The target detection method is based on a convolutional neural network model PiaNet comprising a feature extraction module and a multi-task prediction module; the target detection method comprises a training stage and a testing stage; the training stage adopts a two-stage transfer learning strategy, which comprises the following steps: step (1), data enhancement and data preprocessing are carried out to generate a training set of first-stage training, a training set of second-stage training and a test set; step (2) performing a first stage training in a two-class network; step (3) performing second-stage training to obtain a trained PiaNet network; the testing stage is to accurately detect the target, and specifically comprises the following steps: and inputting the test set into the trained PiaNet network, and outputting the position of the detection frame and the classification result through a multi-task loss function. The method has wide application range and high robustness.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06T7/0012', 'G06T2207/10012', 'G06T2207/10081', 'G06T2207/30064']"
US10048826B2,Interactive visualizations of a convolutional neural network,"Interactive visualizations of a convolutional neural network are provided. For example, a graphical user interface (GUI) can include a matrix having symbols indicating feature-map values that represent likelihoods of particular features being present or absent at various locations in an input to a convolutional neural network. Each column in the matrix can have feature-map values generated by convolving the input to the convolutional neural network with a respective filter for identifying a particular feature in the input. The GUI can detect, via an input device, an interaction indicating that that the columns in the matrix are to be combined into a particular number of groups. Based on the interaction, the columns can be clustered into the particular number of groups using a clustering method. The matrix in the GUI can then be updated to visually represent each respective group of columns as a single column of symbols within the matrix.","['G06F3/04812', 'G06F8/34', 'G06F9/451', 'G06N3/04', 'G06N3/045', 'G06N3/105', 'G06T11/206', 'G06T11/60', 'G06F2203/04803']"
US11429862B2,Dynamic adaptation of deep neural networks,"Techniques are disclosed for training a deep neural network (DNN) for reduced computational resource requirements. A computing system includes a memory for storing a set of weights of the DNN. The DNN includes a plurality of layers. For each layer of the plurality of layers, the set of weights includes weights of the layer and a set of bit precision values includes a bit precision value of the layer. The weights of the layer are represented in the memory using values having bit precisions equal to the bit precision value of the layer. The weights of the layer are associated with inputs to neurons of the layer. Additionally, the computing system includes processing circuitry for executing a machine learning system configured to train the DNN. Training the DNN comprises optimizing the set of weights and the set of bit precision values.","['G06N3/084', 'G06N3/006', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/065', 'G06N3/088', 'G06N3/10', 'G06N3/048', 'G06N3/082', 'G06N5/045']"
US11570466B2,Hybrid pixel-domain and compressed-domain video analytics framework,"In one embodiment, an apparatus comprises processing circuitry to: receive, via a communication interface, a compressed video stream captured by a camera, wherein the compressed video stream comprises: a first compressed frame; and a second compressed frame, wherein the second compressed frame is compressed based at least in part on the first compressed frame, and wherein the second compressed frame comprises a plurality of motion vectors; decompress the first compressed frame into a first decompressed frame; perform pixel-domain object detection to detect an object at a first position in the first decompressed frame; and perform compressed-domain object detection to detect the object at a second position in the second compressed frame, wherein the object is detected at the second position in the second compressed frame based on: the first position of the object in the first decompressed frame; and the plurality of motion vectors from the second compressed frame.","['G06N3/08', 'H04N19/52', 'G06F18/214', 'G06F18/22', 'G06K9/6256', 'G06N3/04', 'G06N3/045', 'G06V10/255', 'G06V10/75', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'H04N19/172', 'H04N19/523']"
US12131258B2,Joint pruning and quantization scheme for deep neural networks,A method for compressing a deep neural network includes determining a pruning ratio for a channel and a mixed-precision quantization bit-width based on an operational budget of a device implementing the deep neural network. The method further includes quantizing a weight parameter of the deep neural network and/or an activation parameter of the deep neural network based on the quantization bit-width. The method also includes pruning the channel of the deep neural network based on the pruning ratio.,"['G06N3/04', 'G06N3/047', 'G06N3/063', 'G06N3/082', 'G06N3/045', 'G06N3/048', 'G06N3/084']"
US12323608B2,On neural network-based filtering for imaging/video coding,"A method of processing video data. The method includes selecting an in-loop filter from a plurality of neural network (NN) filter model candidates, wherein the plurality of NN filter model candidates are based on a reconstructed quality level of a video unit, and performing a conversion between a video media file comprising the video unit and a bitstream based on the in-loop filter selected. A corresponding video coding apparatus and non-transitory computer readable medium are also disclosed.","['G06N3/084', 'H04N19/117', 'H04N19/124', 'H04N19/132', 'H04N19/136', 'H04N19/146', 'H04N19/184', 'H04N19/186', 'H04N19/187', 'H04N19/188', 'H04N19/1883', 'H04N19/31', 'H04N19/436', 'H04N19/70', 'H04N19/82']"
US12113974B2,High-level syntax for signaling neural networks within a media bitstream,"A method, an apparatus, and a computer program product are provided. An example method includes defining an enhancement message comprising at least one of the following: an identifying number for identifying a post-processing filter; a mode identity (idc) field used of indicating association of a post-processing filter with the identifying number; a flag for specifying the enhancement message being used for a current layer; and the payload byte comprising a bitstream; and using the enhancement message for at least one of specifying a neural network that is used as a post-processing filter or cancelling a use of a previous post-processing filter with the same identifying number.","['H04N19/117', 'H04N19/184', 'H04N19/70', 'H04N19/85']"
CN114241053B,Multi-category tracking method based on improved attention mechanism FairMOT,"The invention discloses a multi-category tracking method based on an improved attention mechanism FairMOT. The method specifically comprises the following steps of firstly preprocessing an unmanned aerial vehicle data set; constructing a model; training a network; performance evaluation of a multi-category multi-target tracking algorithm; on the basis of DL34-base of FairMOT, an attention mechanism is added, so that the network can learn semantic information and spatial information in the image better. Other structures of the network are modified, and the heatmap detection head and the box size detection head are modified in the target detection branch, so that the accuracy of the target detection branch in predicting the position of the target center point and the target size is higher, the tracking performance of the whole model is better improved, and the method has higher tracking accuracy.","['G06T7/75', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06T2207/30241']"
US11889458B2,Neural network functions for positioning measurement data processing at a user equipment,"In an aspect, a network component transmits, to a UE, at least one neural network function configured to facilitate processing of positioning measurement data into one or more positioning measurement features at the UE, the at least one neural network function being generated dynamically based on machine-learning associated with one or more historical measurement procedures. The UE may obtain positioning measurement data associated with the UE, and may process the positioning measurement data into a respective set of positioning measurement features based on the at least one neural network function. The UE may report the processed set of positioning measurement features to a network component, such as the BS or LMF.","['G01S5/0278', 'H04W64/00', 'G01S5/0036', 'G01S5/0236', 'G06N3/08', 'H04L5/0048', 'H04W24/08', 'G01S5/0205', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N5/01', 'H04L25/0224', 'H04L27/0006', 'H04L5/001', 'H04L5/005', 'H04L5/0057']"
US12113995B2,Neural network-based post filter for video coding,"A method of processing video data. The method includes determining that a supplemental enhancement information (SEI) message of a bitstream includes indicators specifying one or more neural network (NN) filter model candidates or selections for a video unit or samples within the video unit, and converting between a video media file comprising the video unit and the bitstream based on the indicators. A corresponding video coding apparatus and non-transitory computer readable medium are also disclosed.","['H04N19/117', 'H04N19/436', 'H04N19/124', 'H04N19/132', 'H04N19/157', 'H04N19/184', 'H04N19/186', 'H04N19/188', 'H04N19/46', 'H04N19/70', 'H04N19/82', 'H04N19/91']"
WO2022036777A1,Method and device for intelligent estimation of human body movement posture based on convolutional neural network,"The present application belongs to the field of deep learning computer vision. Disclosed are a human body movement posture intelligent estimation method and apparatus based on a convolutional neural network. The method comprises: inputting a human body image, on which movement posture estimation is to be performed, into a trained human body detection model to carry out processing to obtain an individual detection result; inputting the individual detection result into a trained global estimation model to carry out processing to obtain first feature images of human body key points at different scales; and inputting the first feature images into a trained supplementary fine-tuning model for to carry out processing to obtain second feature images of the human body key points at different scales by means of enhanced learning, wherein the supplementary fine-tuning model comprises a plurality of feature extraction branches, each feature extraction branch is equipped with a different quantity of fine-tuning modules, and the enhanced learning is performed by means of the fine-tuning modules of each feature extraction branch; and obtaining a human body posture estimation result on the basis of the second feature images at different scales. The present application effectively solves the problem of inaccurate body posture estimation caused by easily missing key points that are difficult to distinguish in a human body image in the prior art.","['G06F18/214', 'G06F18/22', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T7/60', 'G06V40/10', 'G06V40/20']"
US10257105B2,Facilitation of physical layer design for 5G networks or other next generation networks,"A more efficient 5G network can be achieved by leveraging a centralized radio access network (CRAN) and/or a virtualized radio access network (VRAN) architecture to comply with transport bandwidth requirements for better performance. Additionally, linear compression techniques can be used to reduce the transport bandwidth. Compression on a fronthaul can be achieved by utilizing the concept of spatial compression. After a signal has been compressed, it can be decompressed in accordance with a number of antennas.","['H04L47/38', 'H04L45/42', 'H04L45/64', 'H04B7/0413', 'H04W84/042']"
US11792438B2,Using neural network filtering in video coding,"Methods, systems, apparatus for media processing are described. One example method of digital media processing includes determining, for a conversion between visual media data and a bitstream of the visual media data, how to apply one or more convolutional neural network filters to at least some samples of a video unit of the visual media data according to a rule; and performing the conversion based on the determining.","['H04N19/82', 'H04N19/85', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T9/002', 'H04N19/107', 'H04N19/117', 'H04N19/124', 'H04N19/174', 'H04N19/176', 'H04N19/184', 'H04N19/186', 'H04N19/573', 'H04N19/70', 'H04N19/91', 'H04N19/96']"
US11521062B2,Neural network training using a data flow graph and dynamic memory management,"Processing a neural network data flow graph having a set of nodes and a set of edges. An insertion point is determined for a memory reduction or memory restoration operation. The determination is based on computing tensor timing slacks (TTS) for a set of input tensors; compiling a candidate list (SI) of input tensors, from the set of input tensors, using input tensors having corresponding TTS values larger than a threshold value (thTTS); filtering the SI to retain input tensors whose size meets a threshold value (thS); and determining an insertion point for the operation using the SI based on the filtering. A new data flow graph is generated or an existing one is modified using this process.","['G06N3/082', 'G06N3/08', 'G06F16/9024', 'G06F18/214', 'G06F9/5016', 'G06F9/5022', 'G06K9/6256', 'G06N3/04', 'G06N3/06', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/063']"
US10726583B2,System and method of encoding and decoding feature maps and weights for a convolutional neural network,"Embodiments described herein provide a processing apparatus comprising compute logic to generate output feature map data for a convolutional neural network (CNN) and write the feature map data to a memory buffer; a direct memory access (DMA) controller including a feature map encoder, the DMA controller to read the feature map data from the memory buffer, encode the feature map data using one of multiple encode algorithms, and write encoded feature map data to memory coupled with the processing apparatus; and wherein the compute logic is to read the encoded feature map data from the memory in an encoded format and decode the encoded feature map data while reading the encoded feature map data.","['G06T9/002', 'G06F13/10', 'G06N3/04', 'G06N3/08', 'G06T1/20', 'G06T15/005']"
RU2698414C1,Method and device for compressing video information for transmission over communication channels with varying throughput capacity and storage in data storage systems using machine learning and neural networks,"FIELD: computer equipment.SUBSTANCE: invention relates to the computer equipment. A method of compressing video information in digital form for transmission thereof over non-stationary communication channels of a data transmission network or storage in data storage systems, in which a color or black-and-white tone video stream is subjected to preprocessing and conversion into a black-and-white sketch form, is encoded taking into account specificity, packaged and sealed multiplexer with additional service data flow transmitted or placed in storage device, at output is restored by decoder in sketch form after decompression by demultiplexer, depacketizing of compressed video information and service data, wherein sketch-flow frames with low dynamics of objects in the scene are excluded from transmission using an interpolator and threshold selection of frames in the encoder; wherein the main encoded sketch stream is supplemented with service data packets on missed frames and a separate stream of first frame-hints generated when detecting scene change, if the scene change information and the first frame of the new scene are not provided for training the INN engine.EFFECT: high efficiency of processing a video stream for transmitting data in a network environment.10 cl, 4 dwg","['H04L65/403', 'G06F16/70', 'G06F17/00', 'G06N3/08', 'G06T1/00', 'G06T1/60', 'G06T11/203', 'G06T11/60', 'G06T3/4007', 'G06T3/4023', 'G06T3/4046', 'G06T9/002', 'H03M7/30', 'H04L65/70', 'H04L65/756', 'H04L65/80', 'H04N19/117', 'H04N19/132', 'H04N19/136', 'H04N19/142', 'H04N19/17', 'H04N19/537', 'H04N19/85', 'H04N21/238', 'H04N9/64', 'G06N3/045', 'G06T9/001']"
US11966835B2,Deep neural network accelerator with fine-grained parallelism discovery,"A sparse convolutional neural network accelerator system that dynamically and efficiently identifies fine-grained parallelism in sparse convolution operations. The system determines matching pairs of non-zero input activations and weights from the compacted input activation and weight arrays utilizing a scalable, dynamic parallelism discovery unit (PDU) that performs a parallel search on the input activation array and the weight array to identify reducible input activation and weight pairs.","['G06N3/063', 'G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/048']"
EP3534283A1,Classification of source data by neural network processing,"Example techniques described herein determine a classification of a variable-length source data such as an executable code. A neural network system that includes a convolution filter, a recurrent neural network, and a fully connected layer can be configured in a computing device to classify executable code. The neural network system can receive executable code of variable length and reduce its dimensionality by generating a variable-length sequence of features extracted from the executable code. The sequence of features is filtered, and applied to one or more recurrent neural networks and to a neural network. The output of the neural network classifies the data. Other disclosed systems include a system for reducing the dimensionality of command line input using a recurrent neural network. The reduced dimensionality of command line input may be classified using the disclosed neural network systems.","['G06F21/562', 'H03M7/4093', 'G06F8/74', 'G06N20/00', 'G06N3/08', 'G06N5/046']"
US20200210840A1,Adjusting precision and topology parameters for neural network training based on a performance metric,"Apparatus and methods for training neural networks based on a performance metric, including adjusting numerical precision and topology as training progresses are disclosed. In some examples, block floating-point formats having relatively lower accuracy are used during early stages of training. Accuracy of the floating-point format can be increased as training progresses based on a determined performance metric. In some examples, values for the neural network are transformed to normal precision floating-point formats. The performance metric can be determined based on entropy of values for the neural network, accuracy of the neural network, or by other suitable techniques. Accelerator hardware can be used to implement certain implementations, including hardware having direct support for block floating-point formats.","['G06N3/063', 'G06F18/217', 'G06F7/483', 'G06F9/30025', 'G06K9/6262', 'G06N3/047', 'G06N3/0472', 'G06N3/082', 'G06N3/084', 'G06F2207/4824', 'G06N3/044', 'G06N3/048']"
US10798386B2,Video compression with generative models,"A processing system having at least one processor may obtain a sequence of frames of a video, and detect a correlation between visual properties of a first frame of the sequence of frames and a second frame of the sequence of frames, where the second frame comprises a next frame following the first frame in the sequence of frames. The processing system may then generate a first difference vector comprising a difference between a latent space representation of the second frame and a latent space representation of the first frame in response to detecting the correlation between the visual properties, where the latent space representation of the first frame and the latent space representation of the second frame are generated via an autoencoder, and store the first difference vector in a first encoding block.","['H04N19/149', 'H04N19/94', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/088', 'H04N19/137', 'H04N19/147', 'H04N19/176']"
CN107516041B,WebShell detection method and system based on deep neural network,"The invention discloses a WebShell detection method and a system thereof based on a deep neural network, wherein a recursive cyclic neural network based on an abstract syntax tree automatically acquires lexical and syntax information of a script aiming at a script language, and completes feature extraction and WebShell detection by utilizing hierarchical structural features of the abstract syntax tree, wherein the feature extraction and WebShell detection comprise preprocessing, sample generation and WebShell detection; firstly, lexical and grammatical information of a script is automatically acquired, and then the characteristic extraction and WebShell detection are completed by using a recurrent neural network based on an abstract syntax tree. The method has the advantages of low deployment cost, good transportability and high detection accuracy.","['G06F21/563', 'G06F11/3688', 'G06F21/566', 'G06F8/42', 'G06F8/425', 'G06N3/045']"
US11379727B2,Systems and methods for enhancing a distributed medical network,"Methods and systems for enhancing a distributed medical network. For example, a computer-implemented method includes inputting training data corresponding to each local computer into their corresponding machine learning model; generating a plurality of local losses including generating a local loss for each machine learning model based at least in part on the corresponding training data; generating a plurality of local parameter gradients including generating a local parameter gradient for each machine learning model based at least in part on the corresponding local loss; generating a global parameter update based at least in part on the plurality of local parameter gradients; and updating each machine learning model hosted at each local computer of the plurality of local computers by at least updating their corresponding active parameter set based at least in part on the global parameter update.","['H04L67/1097', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G16H10/60', 'G16H30/20', 'H04L67/10', 'H04L67/12', 'H04L67/34', 'G06N20/00']"
US11610122B2,Generative adversarial neural network assisted reconstruction,"A latent code defined in an input space is processed by the mapping neural network to produce an intermediate latent code defined in an intermediate latent space. The intermediate latent code may be used as appearance vector that is processed by the synthesis neural network to generate an image. The appearance vector is a compressed encoding of data, such as video frames including a person's face, audio, and other data. Captured images may be converted into appearance vectors at a local device and transmitted to a remote device using much less bandwidth compared with transmitting the captured images. A synthesis neural network at the remote device reconstructs the images for display.","['G06N3/08', 'G06N3/088', 'G06N3/045', 'G06N3/047', 'G06T5/003', 'G06T5/73', 'G06T7/73', 'G06T9/002', 'G06V40/168', 'H04N19/20', 'H04N19/85', 'G06N3/044', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201', 'H04N7/157']"
US8200593B2,Method for efficiently simulating the information processing in cells and tissues of the nervous system with a temporal series compressed encoding neural network,"A neural network simulation represents components of neurons by finite state machines, called sectors, implemented using look-up tables. Each sector has an internal state represented by a compressed history of data input to the sector and is factorized into distinct historical time intervals of the data input. The compressed history of data input to the sector may be computed by compressing the data input to the sector during a time interval, storing the compressed history of data input to the sector in memory, and computing from the stored compressed history of data input to the sector the data output from the sector.",['G06N3/10']
CA3158597C,Conditional entropy coding for efficient video compression,"The present disclosure is directed to video compression using conditional entropy coding. An ordered sequence of image frames can be transformed to produce an entropy coding for each image frame. Each of the entropy codings provide a compressed form of image information based on a prior image frame and a current image frame (the current image frame occurring after the prior image frame). In this manner, the compression model can capture temporal relationships between image frames or encoded representations of the image frames using a conditional entropy encoder trained to approximate the joint entropy between frames in the image frame sequence.","['H04N19/13', 'H04N19/91', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06N3/09', 'H04N19/136', 'H04N19/172', 'H04N19/463']"
US12020135B2,Convolutional neural network optimization mechanism,"A library of machine learning primitives is provided to optimize a machine learning model to improve the efficiency of inference operations. In one embodiment a trained convolutional neural network (CNN) model is processed into a trained CNN model via pruning, convolution window optimization, and quantization.","['G06N3/04', 'G06F9/3851', 'G06F9/3887', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06T1/20', 'G06N3/044', 'G06N3/045']"
CN110348357B,Rapid target detection method based on deep convolutional neural network,"The invention discloses a rapid target detection method based on a deep convolutional neural network. Firstly, training the preprocessed data by constructing a basic SSD detection model to obtain an original training model. Then, by measuring the importance of the convolution kernel, adopting a convolution kernel pruning strategy to remove unimportant convolution kernels, simplifying a feature extraction network in the detection model and obtaining a compression model. Specifically, by making the inputs formed to the subset of channels at the i +1 th layer as close as possible to the outputs at the i +1 th layer, it is possible to remove other channels at the i +1 th layer inputs and, in turn, remove the corresponding convolution kernels at the i-th layer, thereby achieving pruning of the model convolution kernels. And each convolution layer is removed, and then the compression model is subjected to fine adjustment so as to recover the precision of the detection model. And when all the convolutional layers are pruned, obtaining a final compression detection model. According to the invention, through model compression, the model can be deployed at the mobile terminal, the detection speed is improved, and the detection precision is maintained.","['G06N3/045', 'G06N3/084', 'G06V20/10']"
US11657264B2,Content-specific neural network distribution,Media content is received for streaming to a user device. A neural network is trained based on a first portion of the media content. Weights of the neural network are updated to overfit the first portion of the media content to provide a first overfitted neural network. The neural network or the first overfitted neural network is trained based on a second portion of the media content. Weights of the neural network or the first overfitted neural network are updated to overfit the second portion of the media content to provide a second overfitted neural network. The first portion and the second portion of the media content are sent with associations to the first overfitted neural network and the second overfitted to the user equipment.,"['G06N3/08', 'H04L65/612', 'H04L65/765', 'G06F7/588', 'G06N3/045', 'G06N7/01', 'H04L65/70']"
US11392829B1,Managing data sparsity for neural networks,"Approaches in accordance with various embodiments provide for the processing of sparse matrices for mathematical and programmatic operations. In particular, various embodiments enforce sparsity constraints for performing sparse matrix multiply-add instruction (MMA) operations. Deep neural networks can exhibit significant sparsity in the data used in operations, both in the activations and weights. The computational load can be reduced by excluding zero-valued data elements. A sparsity constraint is applied across all submatrices of a sparse matrix, providing fine-grained structured sparsity that is evenly distributed across the matrix. The matrix may then be compressed since a minimum number of elements of the matrix are known to have zero value. Matrix operations are then performed using these matrices.","['G06N3/08', 'G06N3/082', 'G06F17/16', 'G06N3/04', 'G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084']"
US12238343B2,Video coding with neural network based in-loop filtering,"An electronic apparatus performs a method of decoding video data, including: reconstructing, from a video bitstream, a picture frame that includes a luma component, a first and a second chroma components, and applying a trained neural network based in-loop filter to the reconstructed picture frame by: converting a first resolution of the samples of the at least one of the first and the second chroma components to a second resolution of the samples of the luma component when the first resolution is different from the second resolution; concatenating samples of at least one of the first and the second chroma components with the luma component; processing the concatenated samples using a convolutional neural network; and reconverting the samples of the at least one of the first and the second chroma components processed by the convolutional neural network from the second resolution back to the first resolution.","['H04N19/82', 'G06N3/045', 'G06N3/08', 'H04N19/117', 'H04N19/186', 'G06N3/044']"
US11728851B2,Compression and decompression of downlink channel estimates,"A network node determines parameters indicating a compression function for compressing downlink channel estimates, and a decompression function. The network node transmits the parameters, receives compressed downlink channel estimates, and decompresses the compressed downlink channel estimates using the decompression function. A terminal device receives the parameters, forms the compression function, compresses downlink channel estimates using the compression function, and transmits the compressed downlink channel estimates. The compression function comprises a first function formed based on at least some of the parameters, a second function which is non-linear, and a quantizer. The first function is configured to receive input data, and to reduce a dimension of the input data. The decompression function comprises a first function configured to receive input data and provide output data in a higher dimensional space than the input data, and a second function which is non-linear.","['H04B7/0452', 'H03M7/3059', 'H03M7/6047', 'H03M7/6052', 'H04B7/0456', 'H04L1/0026', 'H04L25/4927', 'H04W72/23']"
EP3534284A1,Classification of source data by neural network processing,"Example techniques described herein determine a classification of a variable-length source data such as an executable code. A neural network system that includes a convolution filter, a recurrent neural network, and a fully connected layer can be configured in a computing device to classify executable code. The neural network system can receive executable code of variable length and reduce its dimensionality by generating a variable-length sequence of features extracted from the executable code. The sequence of features is filtered, and applied to one or more recurrent neural networks and to a neural network. The output of the neural network classifies the data. Other disclosed systems include a system for reducing the dimensionality of command line input using a recurrent neural network. The reduced dimensionality of command line input may be classified using the disclosed neural network systems.","['G06F21/562', 'H03M7/4093', 'G06F8/74', 'G06N20/00', 'G06N3/08', 'G06N5/046']"
US12265898B2,Compression of machine-learned models via entropy penalized weight reparameterization,"Example aspects of the present disclosure are directed to systems and methods that learn a compressed representation of a machine-learned model (e.g., neural network) via representation of the model parameters within a reparameterization space during training of the model. In particular, the present disclosure describes an end-to-end model weight compression approach that employs a latent-variable data compression method. The model parameters (e.g., weights and biases) are represented in a “latent” or “reparameterization” space, amounting to a reparameterization. In some implementations, this space can be equipped with a learned probability model, which is used first to impose an entropy penalty on the parameter representation during training, and second to compress the representation using arithmetic coding after training. The proposed approach can thus maximize accuracy and model compressibility jointly, in an end-to-end fashion, with the rate-error trade-off specified by a hyperparameter.","['G06N3/084', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/044']"
CA3134773C,Compression of images having overlapping fields of view using machine-learned models,A machine-learned image compression model includes a first encoder configured to generate a first image code based at least in part on first image data. The first encoder includes a first series of convolutional layers configured to generate a first series of respective feature maps based at least in part on the first image. A second encoder is configured to generate a second image code based at least in part on second image data and includes a second series of convolutional layers configured to generate a second series of respective feature maps based at least in part on the second image and disparity-warped feature data. Respective parametric skip functions associated convolutional layers of the second series are configured to generate disparity -warped feature data based at least in part on disparity associated with the first series of respective feature maps and the second series of respective feature maps.,"['H04N19/597', 'G06N3/04', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'H04N19/20', 'H04N19/91']"
US11375941B2,Methods and systems for processing data via an executable file on a monitor to reduce the dimensionality of the data and encrypting the data being transmitted over the wireless network,Some embodiments include processing data via an executable file on a monitor to reduce the dimensionality of the data being transmitted over the wireless network. The output of the executable file also encrypts the data before being transmitted wireless to a remote server. The remote server receives the transmitted data and makes likelihood inferences based on the recorded data.,"['A61B5/02405', 'A61B5/7264', 'A61B5/361', 'A61B5/0006', 'A61B5/11', 'A61B5/257', 'A61B5/259', 'A61B5/28', 'A61B5/352', 'A61B5/4809', 'A61B5/6801', 'A61B5/6823', 'A61B5/6833', 'A61B5/7267', 'A61B5/746', 'G06F21/6245', 'G06N3/08', 'G16H50/20', 'G16H50/50', 'A61B2560/0209', 'A61B2560/0406', 'A61B2562/0219', 'A61B2562/164', 'A61B2562/166', 'A61B2562/168', 'A61B5/363']"
CN113420651B,"Light weight method, system and target detection method for deep convolutional neural network","The invention relates to a light-weight method and system for a deep convolutional neural network for target detection and a target detection method, belongs to the technical field of target detection, and solves the problem that the Faster RCNN model calculation and storage complexity is high in the existing target detection. Comprising the following steps: obtaining a trained MobileNet model as a pre-training model, building a FasterRCNN model with a depth-separable convolution structure, and obtaining an initial FasterRCNN model after training; performing sparse low-rank decomposition, channel cutting and training on a feature extraction backbone network in an initial fast RCNN model to obtain a preliminary lightweight fast RCNN model; performing Tensor-Train decomposition on a regional advice network in the primarily light-weighted fast RCNN model, and training to obtain a secondarily light-weighted fast RCNN model; and performing sparse low-rank decomposition, channel cutting and training on the recognition and classification network in the twice light fast RCNN model to obtain the final light fast RCNN model. The method realizes higher compression multiple of the target detection model and improves the speed and precision of target detection.","['G06F18/214', 'G06F18/24', 'G06N3/04', 'G06N3/082', 'Y02T10/40']"
US11449713B2,Attention based feature compression and localization for autonomous devices,"Systems, methods, tangible non-transitory computer-readable media, and devices associated with object localization and generation of compressed feature representations are provided. For example, a computing system can access training data including a target feature representation and a source feature representation. An attention feature representation can be generated based on the target feature representation and a machine-learned attention model. An attended target feature representation can be generated based on masking the target feature representation with the attention feature representation. A matching score for the source feature representation and the target feature representation can be determined. A loss associated with the matching score and a ground-truth matching score for the source feature representation and the target feature representation can be determined. Furthermore, parameters of the machine-learned attention model can be adjusted based on the loss.","['G06K9/6262', 'H04N19/91', 'G06F18/211', 'G06F18/217', 'G06F18/22', 'G06K9/6201', 'G06K9/6228', 'G06V10/454', 'G06V10/75', 'G06V10/82', 'G06V20/58']"
US11461583B2,Binary feature compression for autonomous devices,"Systems, methods, tangible non-transitory computer-readable media, and devices associated with object localization and generation of compressed feature representations are provided. For example, a computing system can access training data including a source feature representation and a target feature representation. An encoded target feature representation can be generated based on the target feature representation and a machine-learned encoding model. A binarized target feature representation can be generated based on the encoded target feature representation and lossless binarization operations. A reconstructed target feature representation can be generated based on the binarized target feature representation and a machine-learned decoding model. A matching score for the source feature representation and the reconstructed target feature representation can be determined. A loss associated with the matching score can be determined. Parameters of the machine-learned encoding model and the machine-learned decoding model can be adjusted based on the loss.","['G06N3/084', 'G06K9/6232', 'G06V10/7715', 'G06F18/214', 'G06F18/217', 'G06K9/6256', 'G06K9/6262', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N7/01', 'G06V10/454', 'G06V10/507', 'G06V20/56', 'G06V30/19127', 'G06V30/19147', 'G06V30/1916', 'G06V30/194', 'B60W60/001', 'G06N3/044']"
CN115136506B,Channel state information feedback using channel compression and reconstruction,"Systems and methodologies are described that facilitate robust Channel State Information (CSI) feedback, such as providing full CSI feedback or otherwise providing CSI feedback. CSI encoders and/or decoders used by network nodes may implement channel compression/reconstruction based on Neural Network (NN) training of the collected channels. With respect to CSI feedback, a structured payload having an interpretable payload portion and an unexplainable payload portion may be used. Channel compression provided in accordance with some aspects of the present disclosure supports feedback of robust CSI, including in some cases complete CSI as determined by a particular network node. Other aspects and features are also claimed and described.","['H04L1/0029', 'H04B7/0626', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0495', 'G06N3/088', 'G06N3/09', 'H04B7/0417', 'H04L1/0003', 'H04L5/0048', 'H04L5/0051', 'H04L5/0057', 'H04L1/0026', 'H04L1/003', 'H04L1/0036']"
US12190228B2,Generating and executing context-specific neural network models based on target runtime parameters,"The disclosed embodiments relate to a system that generates and executes a deep neural network (DNN) based on target runtime parameters. During operation, the system receives a trained original model and a set of target runtime parameters for the DNN, wherein the target runtime parameters are associated with one or more of the following for the DNN: desired operating conditions, desired resource utilization, and desired accuracy of results. Next, the system generates a context-specific model based on the original model and the set of target runtime parameters. The system also generates an operational plan for executing both the original model and the context-specific model to meet requirements of the target runtime parameters. Finally, the system controls execution of the original model and the context-specific model based on the operational plan.","['G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06V10/764', 'G06V10/768', 'H04L41/145', 'H04L41/16', 'G06N3/047']"
US11816568B2,Optimizing execution of a neural network based on operational performance parameters,"The disclosed embodiments relate to a system that optimizes execution of a DNN based on operational performance parameters. During operation, the system collects the operational performance parameters from the DNN during operation of the DNN, wherein the operational performance parameters include parameters associated with operating conditions for the DNN, parameters associated with resource utilization during operation of the DNN, and parameters associated with accuracy of results produced by the DNN. Next, the system uses the operational performance parameters to update the DNN model to improve performance and efficiency during execution of the DNN.","['G06N3/08', 'G06F16/9024', 'G06F17/18', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/082', 'G06N3/10', 'G06N5/04', 'H04L41/0816', 'H04L41/145', 'H04L41/16', 'G06N3/047', 'H04L41/142', 'H04L43/045']"
US20220264095A1,Method and apparatus for video encoding and decoding based on neural network implementation of cabac,"Methods and apparatuses for video coding and decoding are provided. The method of video encoding includes accessing a bin of a syntax element associated with a block in a picture of a video, determining a context for the bin of the syntax element associated with the syntax element and entropy encoding the bin of the syntax element based on the determined context wherein either the bin of the syntax element is based on the relevance of a prediction by a neural network of the syntax element or the probability associated to the context is determined by a neural network. A bitstream formatted to include encoded data, a computer-readable storage medium and a computer-readable program product are also described.","['H04N19/13', 'G06N3/02', 'H04N19/105', 'H04N19/11', 'H04N19/132', 'H04N19/176', 'H04N19/46', 'H04N19/70', 'H04N19/91', 'G06T9/002']"
US10832447B2,Artificial intelligence encoding and artificial intelligence decoding methods and apparatuses using deep neural network,"Provided is an artificial intelligence (AI) encoding apparatus including a memory storing one or more instructions, and a processor configured to execute the one or more instructions stored in the memory to obtain a first image by performing AI down-scaling on an original image through a deep neural network (DNN) for down-scaling, obtain artifact information indicating an artifact region in the first image, perform post-processing to change a pixel value of a pixel in the first image, based on the artifact information, and obtain image data corresponding to a result of encoding of the post-processed first image, and AI data including the artifact information.","['H04N19/132', 'H04N19/136', 'G06N3/04', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06T3/4046', 'G06T5/002', 'G06T5/20', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'H04N19/172', 'H04N19/184', 'H04N19/50', 'H04N19/85', 'H04N19/86', 'G06T2207/10004', 'G06T2207/10016', 'G06T2207/20021', 'G06T2207/20036', 'G06T2207/20084', 'G06T2207/20192', 'G06T9/002']"
CN111461291B,Long-distance pipeline inspection method based on YOLOv3 pruning network and deep learning dehazing model,"The invention belongs to an image processing technology based on deep learning, and particularly relates to a long-distance pipeline inspection method based on a YOLOv3 pruning network and a deep learning defogging model. The method comprises the following steps: step one: constructing and training an AOD-Net defogging network model; step two: designing a YOLOv3 backbone network and a loss function; step three: image data acquisition and training are carried out on the target area in an unmanned aerial vehicle inspection mode; step four: compressing and accelerating calculation of a YOLOv3 model by a pruning method based on a BN layer scaling factor gamma; step five: deploying the AOD-Net and YOLOv3 joint model to an unmanned aerial vehicle embedded module for target task detection; step six: and (5) transmitting the detection result of the inspection task of the long pipeline of the unmanned aerial vehicle back to the background system in real time. The invention is used for carrying out long-distance pipeline inspection work when deployed on the unmanned aerial vehicle embedded module, and greatly reduces the labor cost while ensuring high detection precision, good real-time performance and high efficiency.","['G06N3/045', 'G06F16/51', 'G06F18/23213', 'G06N3/082', 'G06T5/73', 'Y02T10/40']"
US12217834B2,Molecular graph generation from structural features using an artificial neural network,"Discovering molecules (which may be known or may never have been cataloged or ever synthesized) that have desired characteristics is addressed using a machine learning approach. As compared to a brute-force search of a database of known molecules, which may not be computationally feasible, the present machine learning approach renders identification of both known and unknown molecules computationally tractable. Furthermore, the computational effort is largely shifted to training of the machine learning system using a database of known molecules, and the generation of molecules to match any particular characteristics requires relatively little computation. The molecules using the present approach may be further studied, for example, with computer-based simulation or after physical synthesis using biological experimentation to ultimately yield useful chemical compounds.","['G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N5/022', 'G16C20/50', 'G16C20/70', 'G16C20/80', 'G16C20/30']"
CN111553916B,Image tampering area detection method based on various features and convolutional neural network,The invention relates to an image tampering area detection method based on various characteristics and a convolutional neural network. The invention aims to provide an image tampering area detection method based on various characteristics and a convolutional neural network. The technical scheme of the invention is as follows: the image tampering area detection method based on various characteristics and a convolutional neural network is characterized by comprising the following steps of: acquiring an image to be detected: tamper detection based on double compression trace features is carried out on the image to be detected; inputting an image to be detected into a double-flow convolution tampering detection network model with RGB flow and noise flow double-flow input for detection; performing copy-paste detection based on image matching on an image to be detected; outputting the detection result. The invention is suitable for the field of digital image evidence obtaining.,"['G06T7/0002', 'G06N3/045', 'G06T1/0042', 'G06T7/11', 'G06T7/136', 'G06T7/187', 'G06T7/90', 'G06V10/25', 'G06T2207/20084']"
US10909455B2,Information processing apparatus using multi-layer neural network and method therefor,"An information processing apparatus includes a learning unit configured to learn a plurality of multi-layer neural networks configured to carry out a plurality of tasks, a generation unit configured to generate a shared layer candidate at a predetermined layer between or among the plurality of multi-layer neural networks, a first relearning unit configured to relearn the plurality of multi-layer neural networks in a structure using the shared layer candidate, and a determination unit configured to determine whether to share the shared layer candidate at the predetermined layer with respect to each of the plurality of tasks based on an evaluation of the relearning.","['G06N3/08', 'G06F18/2414', 'G06K9/6273', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06V10/764', 'G06V10/82', 'G06F18/22', 'G06K9/6201']"
EP4465208A2,Network for detecting edge cases for use in training autonomous control systems,"Embodiments relate to the detection of edge cases through application of a neural network to predict future vehicle environment data and identifying an edge case when the prediction error exceeds a given threshold. This allows edge cases to be identified based on unexpected vehicle environmental conditions or conditions that otherwise cause the neural network to make inaccurate predictions. These edge cases can then be utilised to better train machine learning systems, for instance, to train autonomous vehicle control systems. Alternatively, the identification of an edge case can highlight the need for remedial action, and can therefore trigger an alert to a vehicle control system to take remedial action. Further methods and systems described herein improve environmental sensing by providing a computationally efficient and accurate means for fusing sensor data and using this fused data to control sensors to focus on areas that would most reduce the uncertainty in the sensing system.","['G06N3/04', 'B60W50/06', 'B60W40/09', 'G06N20/00', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/088', 'B60W2050/0075', 'B60W2050/0088', 'B60W2050/065', 'B60W2556/10', 'B60W2556/35', 'B60W2556/45', 'B60W2756/10', 'G05B13/027']"
US20190138606A1,Neural network-based translation method and apparatus,"Disclosed embodiments include a neural network-based translation method, including: splitting the unknown word in an initial translation into one or more characters, and inputting, into a first multi-layer neural network, a character sequence constituted by the one or more characters ; obtaining a character vector of each character in the character sequence by using the first multi-layer neural network, and inputting all character vectors in the character sequence into a second multi-layer neural network; encoding all the character vectors by using the second multi-layer neural network and a preset common word database, to obtain a semantic vector; and inputting the semantic vector into a third multi-layer neural network, decoding the semantic vector by using the third multi-layer neural network, and determining a final translation of the to-be-translated sentence based on the initial translation of the to-be-translated sentence.","['G06F17/289', 'G06N3/08', 'G06F17/2785', 'G06F17/2845', 'G06F40/30', 'G06F40/49', 'G06F40/58', 'G06N3/045', 'G06N3/0454']"
US12150766B2,Visual perception-based emotion recognition method,"The present disclosure relates to the field of emotion recognition technologies, and specifically, to a visual perception-based emotion recognition method. The method in the present disclosure includes the following steps: step 1: acquiring a face video by using a camera, performing face detection, and locating a region of interest (ROI); step 2: extracting color channel information of the ROI for factorization and dimension reduction; step 3: denoising and stabilizing signals and extracting physiological parameters including heart rate and breathing waveforms, and heart rate variability (HRV); step 4: extracting pre-training nonlinear features of the physiological parameters and performing modeling and regression of a twin network-based support vector machine (SVM) model; and step 5: reading a valence-arousal-dominance (VAD) model by using regressed three-dimensional information to obtain a specific emotional representation.","['G06V40/162', 'A61B5/0004', 'A61B5/0077', 'A61B5/0205', 'A61B5/02405', 'A61B5/02433', 'A61B5/165', 'A61B5/7203', 'A61B5/725', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'G06F18/2135', 'G06N20/10', 'G06N3/045', 'G06N3/084', 'G06V40/15', 'G06V40/168', 'G06V40/172', 'A61B2576/00', 'A61B5/7485', 'G06F2218/12']"
US10419773B1,Hybrid learning for adaptive video grouping and compression,Methods and apparatus are described in which both supervised and unsupervised machine learning are used to classify video content for compression using encoding profiles that are optimized for each type of video content.,"['H04N19/46', 'H04N19/147', 'G06N20/00', 'H04N19/102', 'H04N19/132', 'H04N19/14', 'H04N19/169', 'H04N19/179']"
CN110991690B,A multi-temporal wind speed prediction method based on deep convolutional neural network,"The invention discloses a multi-time wind speed prediction method based on a deep convolutional neural network, which is characterized by comprising the steps of firstly constructing a model input feature map, then constructing a prediction model based on the deep convolutional neural network, and finally carrying out multi-time advanced prediction of wind speed according to the constructed prediction model; the method has the advantages that a two-dimensional characteristic diagram is constructed from the historical actual measurement data and the prediction data of the numerical weather forecast model by using a sliding window mode, the input data in the form keeps the time sequence information of the original data and can participate in convolution operation, the constructed prediction model not only utilizes a one-dimensional convolution neural network to extract shallow local characteristics among all meteorological variables in adjacent time domains, but also utilizes the two-dimensional convolution neural network to excavate potential deep abstract characteristic information in the shallow local characteristics from shallow to deep, thereby providing effective depth characteristic data for a regression prediction layer and improving the overall prediction performance of the model.","['G06Q10/04', 'G06N3/045', 'G06Q50/26']"
US10701394B1,Real-time video super-resolution with spatio-temporal networks and motion compensation,"A method includes selecting a plurality of low-resolution frames associated with a video, performing a first motion estimation between a first frame and a second frame, performing a second motion estimation between a third frame and the second frame, generating a high-resolution frame representing the second frame based on the first motion estimation, the second motion estimation and the second frame using a sub-pixel convolutional neural network.","['H04N19/577', 'H04N19/59', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'H04N19/33', 'H04N19/43', 'H04N19/523']"
US11652959B2,Generating a 3D visual representation of the 3D object using a neural network selected out of multiple neural networks,"A method for generating a three dimensional (3D) visual representation of a sensed object that is three dimensional, the method comprises obtaining at least one 3D visual representation parameter, the visual representation parameters is selected out of a size parameter, a resolution parameter, and a resource consumption parameter; obtaining object information that represents the sensed object; selecting, based on the at least one parameter, a neural network for generating the visual representation of the sensed object; and generating the 3D visual representation of the 3D object by the selected neural network.","['H04N7/147', 'H04N7/157', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T13/40', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/20', 'G06T7/11', 'G06T7/251', 'G06T7/70', 'G06T7/73', 'H04N7/144', 'H04N7/152', 'G06N3/044', 'G06T19/00', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30196', 'G06T2207/30201', 'G06T2219/2004']"
US20210185066A1,Detecting anomalous application messages in telecommunication networks,"Method(s) and apparatus are provided for detecting anomalous application message sequences in an application communication session between a user device and a network node. The application communication session associated with an application executing on the user device. This involves receiving an application message sent between the user device and the network node, where the received application message is associated with a received application message sequence comprising application messages that have been received so far. An estimate of the next application message to be received is generated using traffic analysis based on techniques in the field of deep learning on the received application message sequence. The estimated next application message forms part of a predicted application message sequence. The received application message sequence is classified as normal or anomalous based the received application message sequence and a corresponding predicted application message sequence. An indication of an anomalous received application message sequence is sent in response to classifying the received application message sequence as anomalous.","['H04L63/1425', 'G06F16/9024', 'G06F18/22', 'G06K9/6215', 'G06N20/10', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04L63/1441', 'H04L63/168']"
CN107578453B,"Compressed image processing method, apparatus, electronic equipment and computer-readable medium","The embodiment of the invention provides compressed image processing method, apparatus, electronic equipment and computer-readable mediums, comprising: obtains the original image that format is JPEG, original image is carried out entropy decoding and inverse quantization is handled, obtains pretreated image；Pretreated image is subjected to neural network algorithm training again；Finally the parameter of the neural network for the pretreated image that training obtains infers original image, to obtain inferred results, it can be executed on GPU, the time that the pretreatment time and neural network for reducing data decompression required for training are inferred.",[]
US11853886B2,Recurrent neural network and training process for same,"In a computer system that includes a trained recurrent neural network (RNN), a computer-based method includes: producing a copy of the trained RNN; producing a version of the RNN prior to any training; trying to solve a control task for the RNN with the copy of the trained RNN and with the untrained version of the RNN; and in response to the copy of the trained RNN or the untrained version of the RNN solving the task sufficiently well: retraining the trained RNN with one or more traces (sequences of inputs and outputs) from the solution; and retraining the trained RNN based on one or more traces associated with other prior control task solutions, as well as retraining the RNN based on previously observed traces to predict environmental inputs and other data (which maybe consequences of executed control actions).","['G06N3/084', 'G06N3/08', 'G06N3/006', 'G06N3/044', 'G06N3/088']"
US20230206073A1,Neural network applications in resource constrained environments,Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the sensor data. The system may further include a second computing device located in the resource-constrained environment configured to provide the sensor data as input to the neural network structure. The second computing device may be further configured to determine a state of the resource-constrained environment based on the input of the sensor data to the neural network structure.,"['G06N3/08', 'G06N3/04', 'G06N3/063']"
US7450740B2,Image classification and information retrieval over wireless digital networks and the internet,"The invention provides a internet hosted system to find, compare, contrast and identify similar characteristics among two or more individuals or objects using a digital camera, cellular telephone camera, wireless device for the purpose of returning information regarding similar objects or faces to the user. The system features classification of images from a variety of Internet accessible sources, including mobile phones, wireless camera-enabled devices, images obtained from digital cameras or scanners that are uploaded from PCs, third-party applications and databases. Once classified, the matching person's name, or the matching object, image and associated meta-data is sent back to the user. The image may be manipulated to emphasize similar characteristics between the received facial image and the matching facial image. The meta-data sent down with the image may include sponsored links and advertisements.","['G06V40/172', 'G06V40/168', 'G06V40/171', 'Y10S707/99945', 'Y10S707/99948']"
US20230023870A1,Neural network applications in resource constrained environments,Systems and methods are disclosed for applying neural networks in resource-constrained environments. A system may include a sensor located in a resource-constrained environment configured to generate first sensor data and second sensor data of the resource-constrained environment. The system may also include a first computing device not located in the resource-constrained environment configured to produce a neural network structure based on the first sensor data. The system may also include a second computing device configured to determine a state of the resource-constrained environment based on input of the second sensor data to the neural network structure. The system may also include a controller located in the resource-constrained environment configured to control a device in the resource-constrained environment based on the state of the resource-constrained environment determined by the second computing device. The second computing device may be further configured to calculate an activation area for the neural network structure.,"['G06N3/08', 'G06N3/04', 'G06N3/063']"
US20210319286A1,Joint source channel coding for noisy channels using neural networks,"A communication system for conveying information from an information source across a communications channel using a joint source channel coding variational autoencoder, comprising an encoder neural network of the joint source channel coding variational autoencoder, the encoder neural network having an input layer having input nodes corresponding to a sequence of source symbols S={S1, S2, . . . , Sm}, the Si, taking values in a finite alphabet S, received at the input layer from the information source as samples thereof, and a channel input layer coupled to the input layer through one or more neural network layers, the channel input layer having nodes corresponding to a channel input distribution vector Zk={Z1, Z2, . . . , ZK}, the Zi, taking values for parameters defining a plurality of distributions, each distribution being sampleable to provide possible values for the Xi, of a channel input vector Xn={X1, X2, . . . , Xn}, the Xi taking values from the available input signal values of the communications channel, wherein the encoder neural network is configured through training to map sequences of source symbols Sm received from the information source directly to a representation as a plurality of distributions that provide possible values for the Xi, of a channel input vector Xn, usable to drive a transmitter to transmit a corresponding signal over the communications channel; a sampler, configured to produce a channel input vector Xn={X1, X2, . . . , Xn} in use by sampling the respective distribution for each channel input X defined by the channel input distribution vector Zk={Zi, Z2, . . . , ZK} output by the channel input layer of the encoder neural network; and a decoder neural network of the joint source channel coding variational autoencoder, the decoder neural network having a channel output layer having nodes corresponding to a channel output vector Yn received from a receiver receiving the signal Xn transmitted by the transmitter and transformed by the communications channel, and an output layer coupled to the channel output layer through one or more neural network layers, having nodes matching those of the input layer of the encoder neural network, wherein the decoder neural network is configured through training to map the representation of the source symbols as the channel output vector Yn transformed by the communications channel to a reconstruction of the source symbols Sm output from the output layer of the joint source channel coding variational autoencoder, the reconstruction of the source symbols Sm being usable to reconstitute the information source.","['G06N3/0454', 'H04L1/004', 'H04N19/30', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/0472', 'G06N3/088', 'H03M13/6312', 'H04L65/00', 'H04N19/94']"
US11856226B2,Multi-pass compression of uncompressed data,"Introduced here is a technique to create small compressed image files while preserving data quality upon decompression. Upon receiving an uncompressed data, such as an image, a video, an audio, and/or a structured data, a machine learning model identifies an object in the uncompressed data such as a house, a dog, a text, a distinct audio signal, a unique data pattern, etc. The identified object is compressed using a compression treatment optimized for the identified object. The identified object, either before or after the compression, is removed from the uncompressed data. The uncompressed data with the identified object removed is compressed using a standard compression treatment.","['H04N19/625', 'G06N3/045', 'G06N3/08', 'H04N19/103', 'H04N19/20', 'G06N3/084']"
CN106096670B,"Concatenated convolutional neural metwork training and image detecting method, apparatus and system","The present invention discloses a kind of concatenated convolutional neural metwork training and image detecting method, apparatus and system, wherein, the training method includes: that the image data of image to be learned at least regional area is processed into the image data of the different size of input area of N kind respectively, and N is the integer more than or equal to 2；Respectively using the image data of N kind input area as the input of convolutional neural networks at different levels in N grades of cascade convolutional neural networks, convolutional neural networks at different levels are trained；At least training result that convolutional neural networks at different levels are exported respectively is associated, and the training result after association is back to convolutional neural networks at different levels to adjust the parameter of neural networks at different levels.When training result is propagated to convolutional neural networks at different levels, the parameter of neural networks at different levels can be adjusted, concatenated convolutional neural network is enabled to reach the global optimization of neural network parameter in training.","['G06V30/194', 'G06N3/084', 'G06N3/086', 'G06T2207/20081', 'G06T2207/20084']"
US12033077B2,Learning compressible features,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for receiving, by a neural network (NN), a dataset for generating features from the dataset. A first set of features is computed from the dataset using at least a feature layer of the NN. The first set of features i) is characterized by a measure of informativeness; and ii) is computed such that a size of the first set of features is compressible into a second set of features that is smaller in size than the first set of features and that has a same measure of informativeness as the measure of informativeness of the first set of features. The second set of features if generated from the first set of features using a compression method that compresses the first set of features to generate the second set of features.","['G06N3/08', 'G06F17/15', 'G06F18/24', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/082']"
US20240108286A1,Wearable Appliance,"What is disclosed is a wearable appliance that includes a housing adapted to fit in an ear of a user, an optical transmitter disposed in the housing, an optical receiver disposed in the housing, a wireless network communication device disposed in the housing, an accelerometer disposed in the housing, a microphone disposed in the housing, and a speaker disposed in the housing.","['A61B5/681', 'A61B5/0006', 'A61B5/002', 'A61B5/0022', 'A61B5/02055', 'A61B5/1112', 'A61B5/1117', 'A61B5/296', 'A61B5/332', 'A61B5/384', 'A61B5/411', 'A61B5/4818', 'A61B5/4839', 'A61B5/6803', 'A61B5/6804', 'A61B5/7225', 'A61B7/00', 'A61B8/56', 'A61B8/565', 'G06Q50/22', 'G16H40/20', 'G16H40/67', 'A61B2503/08', 'A61B2560/0214', 'A61B2562/0219', 'A61B5/021', 'A61B5/02416', 'A61B5/02438', 'A61B5/0537', 'A61B5/0816', 'A61B5/11', 'A61B5/1135', 'A61B5/145', 'A61B5/14532', 'A61B5/14551', 'A61B5/165', 'A61B5/25', 'A61B5/369', 'A61B5/398', 'A61B5/4023', 'A61B5/4833', 'A61B5/4866', 'A61B5/4875', 'A61B5/721', 'A61B5/7214', 'A61B5/7232', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B5/7275', 'A61B7/003', 'A61B8/06', 'A61B8/0808', 'A61B8/4472']"
US11853903B2,SGCNN: structural graph convolutional neural network,"A computer-implemented method for learning structural relationships between nodes of a graph includes generating a knowledge graph comprising nodes representing a system and applying a graph-based convolutional neural network (GCNN) to the knowledge graph to generate feature vectors describing structural relationships between the nodes. The GCNN comprises: (i) a graph feature compression layer configured to learn subgraphs representing embeddings of the nodes of the knowledge graph into a vector space, (ii) a neighbor nodes aggregation layer configured to derive neighbor node feature vectors for each subgraph and aggregate the neighbor node feature vectors with their corresponding subgraphs to yield aggregated subgraphs, and (iii) a subgraph convolution layer configured to generate the feature vectors based on the aggregated subgraphs. Functional groups of components included in the system may then be identified based on the plurality of feature vectors.","['G06N5/022', 'G06F16/9024', 'G06F17/15', 'G06F18/21', 'G06F30/15', 'G06F30/20', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N5/046', 'G06Q10/04', 'G06Q50/01']"
US20230077379A1,Machine learning based video compression,"Systems and methods are disclosed for compressing a target video. A computer-implemented method may use a computer system that include one or more physical computer processors and non-transient electronic storage. The computer-implemented method may include: obtaining the target video, extracting one or more frames from the target video, and generating an estimated optical flow based on a displacement of pixels between the one or more frames. The one or more frames may include one or more of a key frame and a target frame.","['H04N19/139', 'H04N19/587', 'H04N19/149', 'H04N19/172', 'H04N19/436', 'H04N19/48', 'H04N19/503', 'H04N19/537', 'H04N19/54']"
US11843777B2,"Image encoding and decoding, video encoding and decoding: methods, systems and training methods","Lossy or lossless compression and transmission, comprising the steps of: (i) receiving an input image; (ii) encoding it to produce a y latent representation; (iii) encoding the y latent representation to produce a z hyperlatent representation; (iv) quantizing the z hyperlatent representation to produce a quantized z hyperlatent representation; (v) entropy encoding the quantized z hyperlatent representation into a first bitstream, (vi) processing the quantized z hyperlatent representation to obtain a location entropy parameter μy, an entropy scale parameter σy, and a context matrix Ay of the y latent representation; (vii) processing the y latent representation, the location entropy parameter μy and the context matrix Ay, to obtain quantized latent residuals; (viii) entropy encoding the quantized latent residuals into a second bitstream; and (ix) transmitting the bitstreams.","['H04N19/13', 'G06N3/045', 'G06N3/084', 'G06T9/002', 'G06V10/422', 'H04N19/124', 'H04N19/184', 'H04N19/19', 'H04N19/42', 'H04N19/59', 'H04N19/88', 'H04N19/91', 'G06T2207/20084']"
US20220012575A1,Methods and apparatus for localized processing within multicore neural networks,"Methods and apparatus for localized processing within multicore neural networks. Unlike existing solutions that rely on commodity software and hardware to perform “brute force” large scale neural network processing the various techniques described herein map and partition a neural network into the hardware limitations of a target platform. Specifically, the various implementations described herein synergistically leverage localization, sparsity, and distributed scheduling, to enable neural network processing within embedded hardware applications. As described herein, hardware-aware mapping/partitioning enhances neural network performance by e.g., avoiding pin-limited memory accesses, processing data in compressed formats/skipping unnecessary operations, and decoupling scheduling between cores.","['G06F17/16', 'G06F11/3024', 'G06F11/3433', 'G06F15/16', 'G06F15/7807', 'G06F16/901', 'G06F9/3001', 'G06F9/30036', 'G06F9/3016', 'G06F9/3802', 'G06F9/3818', 'G06F9/3836', 'G06F9/3838', 'G06F9/3851', 'G06F9/3885', 'G06F9/48', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/063', 'G06N3/10', 'H03M7/3082', 'H03M7/6023', 'H03M7/702', 'G06N3/08', 'G06N3/098']"
US20190279089A1,Method and apparatus for neural network pruning,"The present disclosure provides a method and an apparatus for neural network pruning, capable of solving the problem in the related art that compression, acceleration and accuracy cannot be achieved at the same time in network pruning. The method includes: determining (101) importance values of neurons in a network layer to be pruned based on activation values of the neurons; determining (102) a diversity value of each neuron in the network layer to be pruned based on connecting weights between the neuron and neurons in a next network layer; selecting (103), from the network layer to be pruned, neurons to be retained based on the importance values and diversity values of the neurons in the network layer to be pruned in accordance with a volume maximization neuron selection policy; and pruning (104) the other neurons from the network layer to be pruned to obtain a pruned network layer. With the above method, good compression and acceleration effects can be achieved while maintaining the accuracy of the neural network.","['G06N3/082', 'G06F17/16', 'G06N3/04', 'G06N3/048']"
US12062380B2,Speech coding using auto-regressive generative neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for coding speech using neural networks. One of the methods includes obtaining a bitstream of parametric coder parameters characterizing spoken speech; generating, from the parametric coder parameters, a conditioning sequence; generating a reconstruction of the spoken speech that includes a respective speech sample at each of a plurality of decoder time steps, comprising, at each decoder time step: processing a current reconstruction sequence using an auto-regressive generative neural network, wherein the auto-regressive generative neural network is configured to process the current reconstruction to compute a score distribution over possible speech sample values, and wherein the processing comprises conditioning the auto-regressive generative neural network on at least a portion of the conditioning sequence; and sampling a speech sample from the possible speech sample values.","['G10L19/00', 'G10L19/0204', 'G10L25/30', 'G10L19/02', 'G10L19/04']"
US10192001B2,Visualizing convolutional neural networks,"Convolutional neural networks can be visualized. For example, a graphical user interface (GUI) can include a matrix of symbols indicating feature-map values that represent a likelihood of a particular feature being present or absent in an input to a convolutional neural network. The GUI can also include a node-link diagram representing a feed forward neural network that forms part of the convolutional neural network. The node-link diagram can include a first row of symbols representing an input layer to the feed forward neural network, a second row of symbols representing a hidden layer of the feed forward neural network, and a third row of symbols representing an output layer of the feed forward neural network. Lines between the rows of symbols can represent connections between nodes in the input layer, the hidden layer, and the output layer of the feed forward neural network.","['G06F16/904', 'G06F17/30994', 'G06F16/26', 'G06F16/9024', 'G06F17/30572', 'G06F17/30958', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/105', 'G06T11/206', 'G06N3/048']"
US12008475B2,Transposed sparse matrix multiply by dense matrix for neural network training,"Machine learning systems that implement neural networks typically operate in an inference mode or a training mode. In the training mode, inference operations are performed to help guide the training process. Inference mode operation typically involves forward propagation and intensive access to certain sparse matrices, encoded as a set of vectors. Back propagation and intensive access to transposed versions of the same sparse matrices provide training refinements. Generating a transposed version of a sparse matrix can consume significant additional memory and computation resources. In one embodiment, two additional encoding vectors are generated, providing efficient operations on sparse matrices and also on transposed representations of the same sparse matrices. In a neural network the efficient operations can reduce the amount of memory needed for backpropagation and reduce power consumption.","['G06N3/08', 'G06N3/084', 'G06N3/045', 'G06N3/048']"
US11696119B2,Neural network configuration for wireless communication system assistance,"Methods, systems, and devices for wireless communications are described. Generally, the described techniques provide for communicating capability information (e.g., regarding neural network blocks supported by a user equipment (UE) and a base station). A base station may configure one or more neural network block parameters, and may transmit the neural network block parameters to the UE. The UE may configure or reconfigure a neural network block according to the neural network block parameters, and may process one or more signals, e.g., baseband signals, generated by the UE using the neural network block and the neural network block parameters.","['H04W24/02', 'H04W8/245', 'G06N3/008', 'G06N3/04', 'G06N3/044', 'G06N3/082', 'G06N5/025', 'H04W4/30', 'H04W72/23', 'H04W72/51', 'G06N3/045', 'G06N3/048', 'H04W8/24']"
CN117175588B,Electricity load forecasting method and device based on spatiotemporal correlation,"The invention provides a power consumption load prediction method and device based on space-time correlation, and belongs to the technical field of load prediction. The method comprises the following steps: performing space-time modeling based on historical electricity load data and historical environment data to obtain a multi-layer space-time model; each layer of model is a directed graph, and represents the space causal relation of fixed time, and directed edges between each layer of models represent the time causal relation; performing feature extraction and priori knowledge fusion on the multi-layer space-time model based on the interpretable space-time attention converter to obtain power consumption load space-time features; wherein the interpretable spatiotemporal attention converter includes a spatial causal attention network, a temporal attention network, and a spatial dependency comparison module; based on the power consumption load space-time characteristics, the real-time power consumption load data and the real-time environment data of the target power consumption node, a trained STEF-DHNet model is adopted for prediction, and the predicted power consumption load data of the target power consumption node is obtained. The invention can improve the prediction accuracy and the model applicability.","['G06F18/213', 'G06F18/214', 'G06F18/25', 'G06N3/0442', 'G06Q50/06', 'H02J3/00', 'Y04S10/50']"
US11062725B2,Multichannel speech recognition using neural networks,"This specification describes computer-implemented methods and systems. One method includes receiving, by a neural network of a speech recognition system, first data representing a first raw audio signal and second data representing a second raw audio signal. The first raw audio signal and the second raw audio signal describe audio occurring at a same period of time. The method further includes generating, by a spatial filtering layer of the neural network, a spatial filtered output using the first data and the second data, and generating, by a spectral filtering layer of the neural network, a spectral filtered output using the spatial filtered output. Generating the spectral filtered output comprises processing frequency-domain data representing the spatial filtered output. The method still further includes processing, by one or more additional layers of the neural network, the spectral filtered output to predict sub-word units encoded in both the first raw audio signal and the second raw audio signal.","['G10L25/30', 'G10L21/028', 'G10L15/16', 'G10L15/20', 'G10L19/008', 'G10L21/0388', 'G10L2021/02087', 'G10L2021/02166']"
CN108564169B,"Hardware processing unit, neural network unit, and computer usable medium","The invention relates to a hardware processing unit, a neural network unit and a computer usable medium. The hardware processing unit includes: an accumulator; a multiplier-adder for receiving on a first input and a second input respective first and second factors and receiving on a third input an addend, the multiplier-adder producing a sum of the product of the first and second factors and the addend and providing the sum on an output of the multiplier-adder; a first multiplexer that receives a first operand, a positive 1 and a negative 1 and selects one of them to provide as a first factor to the multiplier-adder; a second multiplexer that receives a second operand, a positive 1 and a negative 1 and selects one of them to provide as a second factor to the multiplier-adder; a third multiplexer receiving the first operand and the second operand and selecting one of them to be provided on an output of the third multiplexer; and a fourth multiplexer receiving the output of the third multiplexer and the sum and selecting one of them to provide to the accumulator.",['G06N3/063']
US10013652B2,Fast deep neural network feature transformation via optimized memory bandwidth utilization,"Deep Neural Networks (DNNs) with many hidden layers and many units per layer are very flexible models with a very large number of parameters. As such, DNNs are challenging to optimize. To achieve real-time computation, embodiments disclosed herein enable fast DNN feature transformation via optimized memory bandwidth utilization. To optimize memory bandwidth utilization, a rate of accessing memory may be reduced based on a batch setting. A memory, corresponding to a selected given output neuron of a current layer of the DNN, may be updated with an incremental output value computed for the selected given output neuron as a function of input values of a selected few non-zero input neurons of a previous layer of the DNN in combination with weights between the selected few non-zero input neurons and the selected given output neuron, wherein a number of the selected few corresponds to the batch setting.","['G06N3/08', 'G06N3/045', 'G06N3/0454', 'G10L15/16', 'G10L15/02', 'G10L2015/0635']"
CN115443614B,Configurable neural network for Channel State Feedback (CSF) learning,A method of wireless communication by a User Equipment (UE) includes receiving a plurality of neural network training configurations for Channel State Feedback (CSF). Each configuration corresponds to a different neural network framework. The method also includes training each of a group of neural network decoder/encoder pairs according to the received training configuration. A method of wireless communication by a base station includes transmitting a plurality of neural network training configurations for Channel State Feedback (CSF) to a User Equipment (UE). Each configuration corresponds to a different neural network framework. The method also includes receiving a neural network decoder/encoder pair trained in accordance with the training configurations.,"['G06N3/0455', 'G06N20/10', 'G06N3/02', 'G06N3/08', 'G06N3/09', 'H04B7/0417', 'H04B7/0626', 'G06N3/044', 'G06N3/0464', 'G06N3/048', 'G06N3/092', 'G06N3/098']"
CN110798506B,"Method, device and equipment for executing command","The embodiment of the invention discloses a method, a device, a terminal and a server for executing a command, which relate to the field of artificial intelligence, in particular to the fields of voice recognition, natural language processing and the like.","['G06F9/453', 'H04L67/51', 'G06F9/451', 'G06F3/0481', 'G06F3/0487', 'G06F3/0488', 'G06F3/04895', 'G06F3/167', 'G10L15/1822', 'G10L15/22', 'G10L15/26', 'H04L67/52', 'G10L2015/223', 'G10L2015/225', 'G10L2015/228']"
WO2024042508A1,Geosynchronization of an aerial image using localizing multiple features,"A georegistration (a.k.a. georectification) of an image captured by a camera in an aerial vehicle, such as a satellite, is based on identifying multiple features using descriptor sets, and sending to a ground station only the descriptors of the identified features and the associated locations in the captured image, without sending of the captured image itself, thus requiring a low communication bandwidth. Using a database of geosynchronized reference images, the ground station uses the received descriptors sets and the associated image locations to localize the features on a selected geosynchronized reference image from the database, and forms a mapping function that map any locations in the captured image to geographical coordinates on Earth. The mapping may be used to geosynchronize an additional feature identified in the aerial vehicle, or to geo synchronize a region that may be cropped from the captured image and sent to the ground station.","['G06V20/10', 'G06F16/29', 'G06V10/16', 'G06V10/46', 'G06V10/82', 'G06V20/13', 'G06V20/17', 'G06V20/52', 'G06V2201/10']"
US20240020968A1,Improving geo-registration using machine-learning based object identification,"A Geo-synchronization system involves a video camera in a vehicle, such as a drone, that captures aerial images of an area. The success rate and the accuracy of the geo-synchronization algorithms is improved by using a trained feed-forward Artificial Neural Network (ANN) for identifying dynamic objects, that changes overtime, in frames captured by the video camera. Such frames are tagged, such as by adding metadata. The tagged frames may be used in a geosynchronization algorithm that may be based on comparing with reference images or may be based on another or same ANN, by removing the dynamic object from the fame, or removing the tagged frame for the algorithm. A dynamic object may change over time due to environmental conditions, such as weather changes, or geographical changes. The environmental condition may change is in response to the Earth rotation, the Moon orbit, or the Earth orbit around the Sun.","['G06V20/17', 'G06F16/29', 'G06F16/51', 'G06F16/587', 'G06F16/7837', 'G06F16/787', 'G06V10/14', 'G06V10/40', 'G06V10/764', 'G06V10/82', 'G06V20/52']"
US11979565B2,Content-adaptive online training method and apparatus for post-filtering,"Aspects of the disclosure provide a method, an apparatus, and a non-transitory computer-readable storage medium for video decoding. The apparatus can include processing circuitry. The processing circuitry is configured to receive an image or video comprising one or more blocks. The processing circuitry can decode a first post-filtering parameter in the image or video corresponding to the one or more blocks to be reconstructed. The first post-filtering parameter applies to at least one of the one or more blocks and has been updated by a post-filtering module in a post-filtering neural network (NN) that is trained based on a training dataset. The processing circuitry can determine the post-filtering NN in a video decoder corresponding to the one or more blocks based on the first post-filtering parameter. The processing circuitry can decode the one or more blocks based on the determined post-filtering NN corresponding to the one or more blocks.","['H04N19/117', 'G06N3/04', 'G06N3/0464', 'G06N3/09', 'G06T9/002', 'H04N19/136', 'H04N19/176', 'H04N19/80', 'H04N19/85', 'H04N19/86', 'G06N3/0455']"
TWI806199B,"Method for signaling of feature map information, device and computer program","The present disclosure relates to an efficient signaling of feature map information for a system employing a neural network. In particular, at the decoder side, a presence indicator is parsed from a bitstream. Based on the value of the parsed presence indicator, further data related to a feature map region are parsed or the parsing is bypassed. The presence indicator may be, for instance a region presence indicator indicating whether feature map data is included in the bitstream, or may be a side information presence indicator indicating whether a side information related to the feature map data is included in the bitstream. Similarly, an encoding method, as well as encoding and decoding devices are provided. Accordingly, the feature map data may be processed more efficiently, including reduction of decoding complexity as well as reduction of the amount of transmitted data by applying the bypassing.","['H04N19/42', 'H04N19/70', 'G06N3/0464', 'G06T9/002', 'G06V10/82', 'G06V20/40', 'H04N19/119', 'H04N19/13', 'H04N19/136', 'H04N19/154', 'H04N19/167', 'H04N19/17', 'H04N19/176', 'H04N19/184', 'H04N19/36', 'H04N19/46', 'H04N19/463', 'H04N19/59', 'H04N19/60', 'H04N19/96', 'G06T2207/20084']"
US20230319617A1,Processing timeline considerations for channel state information,"A first wireless device, such as a user equipment, generates a message indicating a processing time for at least one of training a neural network for channel state information (CSI) derivation or for reporting the CSI based on a trained neural network. The first wireless device transmits the message indicating the processing time to a second wireless device. The second wireless device may be a network entity, such as a base station, a transmission reception point, or another UE.","['H04L25/0224', 'H04W24/10', 'G06N3/045', 'G06N3/08', 'H04L1/0026', 'H04L25/0254']"
CN111630787B,MIMO multi-antenna signal transmission and detection technology based on deep learning,"The invention relates to a MIMO multi-antenna signal transmission and detection technology based on deep learning, and provides a MIMO multi-antenna signal transmission and detection device based on deep learning, which comprises: the compression multiplexing module is used for carrying out compression dimensionality reduction processing on the modulated signals; the device transmitting terminal is used for transmitting the target signal processed by the compression multiplexing module through the transmitting antenna under the condition that the number of the transmitting antennas and the receiving antennas is given; the device receiving end is used for processing the received signal to realize the reconstruction of the received signal to a target signal, and comprises a first neural network signal processing module and a second neural network signal processing module, wherein the second neural network signal processing module is used for inputting a high-dimensional sparse signal theta solved from a low-dimensional target signal by the first neural network signal processing module by utilizing a first neural network model constructed by the first neural network signal processing module into a second neural network model constructed by the first neural network signal processing module to reconstruct an original signal x.","['H04B7/0413', 'G06N3/063', 'G06N3/084', 'H04L25/0254', 'Y02D30/70']"
US20190124346A1,Real time end-to-end learning system for a high frame rate video compressive sensing network,A real time end-to-end learning system for a high frame rate video compressive sensing network is described. The slow reconstruction speed of conventional compressive sensing approaches is overcome by directly modeling an inverse mapping from compressed domain to original domain in a single forward propagation. Through processing massive unlabeled video data such a mapping is learned by a neural network using data-driven methods. Systems and methods according to this disclosure incorporate a multi-rate convolutional neural network (CNN) and a synthesizing recurrent neural network (RNN) to achieve real time compression and reconstruction of video data.,"['H04N19/503', 'H04N19/105', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06T7/246', 'H04N19/137', 'H04N19/146', 'H04N19/172', 'H04N19/51', 'G06N3/048', 'G06N7/01', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T7/277']"
US20230069953A1,Learned downsampling based cnn filter for image and video coding using learned downsampling feature,"A method and apparatus are provided for processing with a trained neural network, and for training of such neural network for image modification, which relate to image processing and in particular to modification of an image using the processing such as the neural network. The processing is performed to generate an output image. The output image is generated by processing the input image with the neural network. The processing with the neural network includes at least one stage including image down-sampling and filtering of the down-sampled image and at least one stage of image up-sampling. The image down-sampling is performed by applying a strided convolution. According to the application, efficiency of the neural network is increased, which may lead to faster learning and improved performance.","['G06T5/80', 'G06T5/006', 'H04N19/50', 'G06N3/045', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06T3/4046', 'H04N19/59', 'H04N19/85']"
US11110895B2,Vehicle network intrusion detection system (IDS) using vehicle state predictions,"In one embodiment, a processor of a vehicle predicts a state of the vehicle using a behavioral model. The model is configured to predict the state based in part on one or more state variables that are available from one or more sub-systems of the vehicle and indicative of one or more physical characteristics of the vehicle. The processor computes a representation of a difference between the predicted state of the vehicle and a measured state of the vehicle indicated by one or more state variables available from the one or more sub-systems of the vehicle. The processor detects a malicious intrusion of the vehicle based on the computed representation of the difference between the predicted and measured states of the vehicle exceeding a defined threshold. The processor initiates performance of a mitigation action for the detected intrusion, in response to detecting the malicious intrusion of the vehicle.","['B60R25/34', 'H04L12/2803', 'B60R25/1004', 'B60R25/104', 'G06N20/00', 'G06N5/04', 'G06N7/01', 'B60R2325/40', 'G06F30/20', 'H04L2012/40215']"
US10999247B2,Density estimation network for unsupervised anomaly detection,"Systems and methods for preventing cyberattacks using a Density Estimation Network (DEN) for unsupervised anomaly detection, including constructing the DEN using acquired network traffic data by performing end-to-end training. The training includes generating low-dimensional vector representations of the network traffic data by performing dimensionality reduction of the network traffic data, predicting mixture membership distribution parameters for each of the low-dimensional representations by performing density estimation using a Gaussian Mixture Model (GMM) framework, and formulating an objective function to estimate an energy and determine a density level of the low-dimensional representations for anomaly detection, with an anomaly being identified when the energy exceeds a pre-defined threshold. Cyberattacks are prevented by blocking transmission of network flows with identified anomalies by directly filtering out the flows using a network traffic monitor.","['H04L63/0245', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06N7/01', 'H04L63/1425', 'H04L63/205']"
US12347445B2,"Audio coding and decoding method and apparatus, medium, and electronic device",An electronic device performs sub-band decomposition on a to-be-coded audio to obtain a to-be-coded low frequency signal corresponding to a low frequency band and a to-be-coded high frequency signal corresponding to a high frequency band. The device performs compression coding on the to-be-coded low frequency signal to obtain low frequency coded data of the to-be-coded low frequency signal. The device determines high frequency prediction information according to the to-be-coded low frequency signal. The device performs feature extraction on the to-be-coded high frequency signal to obtain high frequency feature information. The device determines high frequency compensation information of the to-be-coded high frequency signal according to a difference between the high frequency feature information and the high frequency prediction information. The device also performs encapsulation processing on the low frequency coded data and the high frequency compensation information to obtain audio coded data of the to-be-coded audio.,"['G10L19/00', 'G10L19/0204', 'G06N3/08', 'G10L19/02', 'G10L19/08', 'G10L25/18', 'G10L25/30', 'G10L25/51', 'G06N3/044', 'G06N3/0464', 'G10L19/04']"
CN110991340B,A Method of Human Motion Analysis Based on Image Compression,"The invention discloses a human body action analysis method based on image compression, which mainly comprises rope skipping video acquisition, video data preprocessing, video frame compression model establishment, coordinate point acquisition, coordinate point windowing weight recognition, characteristic sequence construction and action analysis model construction.","['G06V40/20', 'G06F18/241']"
US12192518B2,Video encoding by providing geometric proxies,"Compressing a frame of video includes receiving a frame of a video, identifying a three dimensional (3D) object in the frame, matching the 3D object to a stored 3D object, compressing the frame of the video using a color prediction scheme based on the 3D object and the stored 3D object, and storing the compressed frame with metadata, the metadata identifying the 3D object, indicating a position of the 3D object in the frame of the video and indicating an orientation of the 3D object in the frame of the video.","['G06T9/001', 'H04N19/597', 'G06T9/002', 'G06T9/004', 'H04N19/186', 'H04N19/20', 'H04N19/42', 'H04N19/593']"
US9070039B2,Temporal winner takes all spiking neuron network sensory processing apparatus and methods,"Apparatus and methods for contrast enhancement and feature identification. In one implementation, an image processing apparatus utilizes latency coding and a spiking neuron network to encode image brightness into spike latency. The spike latency is compared to a saliency window in order to detect early responding neurons. Salient features of the image are associated with the early responding neurons. An inhibitory neuron receives salient feature indication and provides inhibitory signal to the other neurons within an area of influence of the inhibitory neuron. The inhibition signal reduces probability of responses by the other neurons to stimulus that is proximate to the feature thereby increasing contrast within the encoded data. The contrast enhancement may facilitate feature identification within the image. Feature detection may be used for example for image compression, background removal and content distribution.","['G06K9/36', 'G06V10/451', 'G06K9/4623', 'G06N3/049']"
CN111641832B,"Encoding method, decoding method, device, electronic device and storage medium","The application discloses an encoding method, a decoding device, electronic equipment and a storage medium, and belongs to the technical field of data processing. The method comprises the following steps: dividing an image to be coded into a plurality of image blocks, performing feature transformation on a first image block in the plurality of image blocks through a transformation convolutional neural network to obtain a first transformation domain component corresponding to the first image block, and quantizing the first transformation domain component to obtain a quantization result of the first transformation domain component; determining a probability distribution of quantization results of the first transform domain components by a probability estimation network; the quantization result of the first transform domain component is encoded based on a probability distribution of the quantization result of the first transform domain component. The sizes of the plurality of image blocks may be different, and therefore, on the basis of feature change of the transformed convolutional neural network, after the image blocks of different sizes are encoded, the compression rate and the distortion rate of the encoded image can be further ensured.","['H04N19/176', 'H04N19/124']"
CN110310343B,Image processing method and device,"The disclosure provides an image processing method and device, relates to the technical field of image processing, and can solve the problem that the processing of images in the prior art cannot achieve both high-quality display and low occupied bandwidth. The specific technical scheme is as follows: inputting the target image into a preset saliency detection neural network to determine a key area and a non-key area of the target image; and obtaining image data corresponding to the key region after the image corresponding to the key region is coded, and generating image data corresponding to the non-key region through a preset generator for generating an countermeasure network. The present disclosure is useful for compromising high quality display with low bandwidth usage in image processing.",['G06T9/002']
US9836484B1,Systems and methods that leverage deep learning to selectively store images at a mobile image capture device,"The present disclosure provides an image capture, curation, and editing system that includes a resource-efficient mobile image capture device that continuously captures images. The mobile image capture device is operable to input an image into at least one neural network and to receive at least one descriptor of the desirability of a scene depicted by the image as an output of the at least one neural network. The mobile image capture device is operable to determine, based at least in part on the at least one descriptor of the desirability of the scene of the image, whether to store a second copy of such image in a non-volatile memory of the mobile image capture device or to discard a first copy of such image from a temporary image buffer without storing the second copy of such image in the non-volatile memory.","['G06F17/3028', 'G06V40/167', 'G06F16/51', 'G06F18/217', 'G06F18/24143', 'G06K9/00261', 'G06K9/6262', 'G06V10/454', 'G06V10/764', 'G06V40/172', 'G06V40/20', 'H04N1/2137', 'H04N23/611', 'H04N23/62', 'H04N23/632', 'H04N23/65', 'H04N23/667', 'H04N5/23219', 'H04N5/23245']"
US11068757B2,Analytic image format for visual computing,"In one embodiment, an apparatus comprises a storage device and a processor. The storage device stores a plurality of images captured by a camera. The processor: accesses visual data associated with an image captured by the camera; determines a tile size parameter for partitioning the visual data into a plurality of tiles; partitions the visual data into the plurality of tiles based on the tile size parameter, wherein the plurality of tiles corresponds to a plurality of regions within the image; compresses the plurality of tiles into a plurality of compressed tiles, wherein each tile is compressed independently; generates a tile-based representation of the image, wherein the tile-based representation comprises an array of the plurality of compressed tiles; and stores the tile-based representation of the image on the storage device.","['G06K9/726', 'G06V20/00', 'G06F18/211', 'G06K9/00624', 'G06K9/00993', 'G06K9/6228', 'G06T7/11', 'G06V10/771', 'G06V10/96', 'G06V30/274', 'G06F18/24323', 'G06K9/6282', 'G06K9/66', 'G06T2207/10016', 'G06T2207/20021', 'G06T2207/20084', 'G06T2207/20221', 'G06T7/20', 'G06V30/194', 'H04N19/12', 'H04N19/124', 'H04N19/167', 'H04N19/172', 'H04N19/176', 'H04N19/44', 'H04N19/48', 'H04N19/513']"
US11234006B2,Training end-to-end video processes,"Methods and systems for optimising the quality of visual data. Specifically, methods and systems for preserving visual information during compression and decompression. An example method for optimising visual data includes using a pre-processing neural network to optimise visual data prior to encoding the visual data in visual data processing; and using a post-processing neural network to enhance visual data following decoding visual data in visual data processing.","['H04N19/33', 'H04N19/117', 'G06T3/4053', 'H04N19/154', 'H04N19/17', 'H04N19/59', 'H04N19/85', 'H04N19/86']"
US11900260B2,"Methods, devices and media providing an integrated teacher-student system","Methods, devices and processor-readable media for an integrated teacher-student machine learning system. One or more teacher-student modules are trained as part of the teacher neural network training. Each student sub-network uses a portion of the teacher neural network to generate an intermediate feature map, then provides the intermediate feature map to a student sub-network to generate inferences. The student sub-network may use a feature enhancement block to map the intermediate feature map to a subsequent feature map. A compression block may be used to compress intermediate feature map data for transmission in some embodiments.","['G06N3/084', 'G06N3/088', 'G06N3/045', 'G06N3/08']"
US10728489B2,Low power framework for controlling image sensor mode in a mobile image capture device,"The present disclosure provides an image capture, curation, and editing system that includes a resource-efficient mobile image capture device that continuously captures images. In particular, the present disclosure provides low power frameworks for controlling image sensor mode in a mobile image capture device. On example low power frame work includes a scene analyzer that analyzes a scene depicted by a first image and, based at least in part on such analysis, causes an image sensor control signal to be provided to an image sensor to adjust at least one of the frame rate and the resolution of the image sensor.","['H04N5/77', 'G06F18/22', 'G06F18/24143', 'G06K9/00221', 'G06K9/00664', 'G06K9/4628', 'G06K9/6201', 'G06K9/6274', 'G06K9/66', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454', 'G06V10/82', 'G06V20/10', 'G06V30/19173', 'G06V40/16', 'H04N19/132', 'H04N19/136', 'H04N19/423', 'H04N19/426', 'H04N19/436', 'H04N19/46', 'H04N19/85', 'H04N23/611', 'H04N23/64', 'H04N23/65', 'H04N23/667', 'H04N5/23219', 'H04N5/23222', 'H04N5/23241', 'H04N5/23245', 'H04N9/8042', 'H04N9/8205', 'G06N3/044', 'G06N3/0445', 'G06N5/003', 'G06N5/01']"
CN110832860B,Method and apparatus for encoding/decoding images,"There is provided a method of encoding an image, the method comprising the steps of: determining subjective quality of an image when the image is compressed; determining at least one compression degree that changes subjective quality among compression degrees indicating the degree to which an image is compressed; and encoding the image by compressing a residual signal of the image based on compression information according to the determined degree of compression, wherein subjective quality of each frame of the image is determined by using a Deep Neural Network (DNN). An image decoding method and an image decoding apparatus are provided for performing an image decoding method for decoding an image by using information encoded according to an image encoding method.","['H04N19/196', 'H04N19/124', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N99/00', 'H04N19/117', 'H04N19/136', 'H04N19/154', 'H04N19/184', 'H04N19/61', 'H04N19/85']"
CN111742331B,Neural network accelerator,"A neural network accelerator tile for exploiting input sparsity is described. The tile comprises: a weight memory for supplying weight and weight selection metadata to each weight channel; an activation selection unit for receiving an input activation value set and rearranging the input activation value set to supply a rearranged activation value set to each activation channel; a set of multiplexers including at least one multiplexer per pair of an activation channel and a weight channel, wherein each multiplexer is configured to select a combined activation value for the activation channel from a set of activation channels of rearranged activation values based on the weight channel weight selection metadata; and a set of combining units comprising at least one combining unit per multiplexer, wherein each combining unit is configured to combine the active channel combination value with the weight channel weights to output a weight channel product.","['G06N3/063', 'G06F13/4282', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/084']"
CN111931905B,Graph convolution neural network model and vehicle track prediction method using same,"The invention discloses a graph convolution neural network model and a vehicle track prediction method using the model. Firstly, sampling a predicted vehicle and surrounding vehicles in a traffic scene at a frequency of 5Hz to obtain position coordinates and dynamic parameters of sampling points of each vehicle, wherein the position coordinates and the dynamic parameters comprise an abscissa and an ordinate, and a transverse and longitudinal vehicle speed and acceleration. Calculating collision time TTC between the predicted vehicle and each surrounding vehicle according to the coordinates and the vehicle speed of the predicted vehicle and the surrounding vehicles, and judging the vehicle behavior; and inputting the history track of each vehicle containing the information into a model, encoding time sequence interaction characteristics in the track and extracting space characteristics, summarizing the characteristics into context vectors, and inputting the context vectors into an LSTM decoder to generate future track coordinates of the vehicle. The method solves the problem that the characteristic information generated by vehicle interaction cannot be obtained by using the traditional recurrent neural network, and greatly improves the prediction accuracy of the vehicle track.","['G06N3/045', 'G06N3/049', 'G06N3/08', 'G06T7/207', 'G06T2207/10016', 'G06T2207/30248']"
US11409994B2,"Methods for image segmentation, computer devices, and storage mediums","Methods for image segmentation, computer devices, and storage mediums. The method includes acquiring a to-be-segmented image, inputting the to-be-segmented image into an input variable of a full convolution neural network and outputting a convolution characteristic pattern; inputting the convolution characteristic pattern into an input variable of a context-switchable neural network and outputting context expression information; and generating an intermediate characteristic pattern for image segmentation according to the convolution characteristic pattern and the context expression information.","['G06K9/6261', 'G06T7/11', 'G06F18/214', 'G06F18/2163', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/26', 'G06V10/751', 'G06T2207/10004', 'G06T2207/10028', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US10732809B2,Systems and methods for selective retention and editing of images captured by mobile image capture device,"The present disclosure provides an image capture, curation, and editing system that includes a resource-efficient mobile image capture device that continuously captures images. The mobile image capture device is operable to input an image into at least one neural network and to receive at least one descriptor of the desirability of a scene depicted by the image as an output of the at least one neural network. The mobile image capture device is operable to determine, based at least in part on the at least one descriptor of the desirability of the scene of the image, whether to store a second copy of such image and/or one or more contemporaneously captured images in a non-volatile memory of the mobile image capture device or to discard a first copy of such image from a temporary image buffer without storing the second copy of such image in the non-volatile memory.","['G06F3/04845', 'G06V10/82', 'G06F3/0482', 'G06F3/04842', 'G06F3/0485', 'G06F3/04883', 'G06K9/00677', 'G06K9/00684', 'G06K9/00718', 'G06T3/0018', 'G06T3/0093', 'G06T3/047', 'G06T3/18', 'G06V20/30', 'G06V20/35', 'G06V20/41', 'G06V40/161', 'H04N1/215', 'G06K2009/00738', 'G06K9/00288', 'G06T2200/24', 'G06T2210/22', 'G06V20/44', 'G06V40/172']"
US12315031B2,High fidelity interactive segmentation for video data with deep convolutional tessellations and context aware skip connections,Techniques related to automatically segmenting video frames into per pixel fidelity object of interest and background regions are discussed. Such techniques include applying tessellation to a video frame to generate feature frames corresponding to the video frame and applying a segmentation network implementing context aware skip connections to an input volume including the feature frames and a context feature volume corresponding to the video frame to generate a segmentation for the video frame.,"['G06T1/20', 'G06F18/241', 'G06F18/2413', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'G06T7/11', 'G06T7/174', 'G06T7/194', 'G06T9/002', 'G06V10/26', 'G06V10/764', 'G06V20/46', 'G06V20/49', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20221']"
US12008462B2,"Systems and methods for providing flexible, multi-capacity models for use of deep neural networks in mobile devices","Systems and methods are disclosed which allow mobile devices, and other resource constrained applications, to more efficiently and effectively utilize deep learning neural networks using only (or primarily) local resources. These systems and methods take the dynamics of runtime resources into account to enable resource-aware, multi-tenant on-device deep learning for artificial intelligence functions for use in tasks like mobile vision systems. The multi-capacity framework enables deep learning models to offer flexible resource-accuracy trade-offs and other similar balancing of performance and resources consumed. At runtime, various systems disclosed herein may dynamically select the optimal resource-accuracy trade-off for each deep learning model to fit the model's resource demand to the system's available runtime resources and the needs of the task being performed by the model. In doing so, systems and methods disclosed herein can efficiently utilize the limited resources in mobile systems to maximize performance of multiple concurrently running neural network-based applications.","['G06N3/063', 'G06F18/2148', 'G06F18/285', 'G06N3/045', 'G06N3/082', 'G06N3/10', 'G06V10/95', 'G06V20/40', 'G06N3/044']"
CN108734285B,Computational Optimization of Neural Networks,"One embodiment provides a computing device for performing a machine learning operation, the device comprising a decode unit to decode a single instruction into a decoded instruction specifying a plurality of operands including an input value and a quantization weight value associated with a neural network, an arithmetic logic unit comprising a barrel shifter, an adder, and an accumulator register, wherein to execute the decoded instruction, the barrel shifter shifts the input value by the quantization weight value to generate a shifted input value, and the adder adds the shifted input value to a value stored in the accumulator register and updates the value stored in the accumulator register.","['G06F5/015', 'G06F7/5443', 'G06F9/3001', 'G06F9/3851', 'G06F9/3887', 'G06F9/3888', 'G06F9/3893', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06F2207/4824']"
US12095983B2,Techniques for deep neural network based inter- frame prediction in video coding,"Video coding using neural network based inter-frame prediction is performed by generating a current reference frame by generating intermediate flows based on two input frames, performing backward warping of the input frames to generate reconstruction frames, and generating a fusion map and a residual map based on the input frames, the intermediate flows and the reconstruction frames. The video coding method further includes outputting an enhanced frame or a virtual reference picture by generating a feature map with different levels, based on the current reference frame, a first reference frame and a second reference frame, generating a predicted frame based on aligned features from the generated feature map by refining the current reference frame, the first reference frame, and the second reference frame, generating a final residual based on the predicted frame, and computing the enhanced frame as an output by adding the final residual to the current reference frame.","['H04N19/159', 'G06N3/045', 'G06T9/002', 'H04N19/105', 'H04N19/172', 'H04N19/182', 'H04N19/50', 'H04N19/577']"
CN111968618B,Speech synthesis method and device,"The application provides a voice synthesis method, a voice synthesis device, electronic equipment and a computer readable storage medium; the method comprises the following steps: decomposing the target text into a plurality of phonemes and determining a contextual characteristic of each phoneme; performing duration prediction processing on the context characteristics of each phoneme to obtain the predicted duration of each phoneme; performing expansion processing on the context characteristics of each phoneme based on the predicted time length of each phoneme to obtain expansion characteristics of each phoneme; carrying out acoustic feature prediction processing on the expansion feature of each phoneme to obtain acoustic features of each phoneme, and synthesizing the acoustic features of each phoneme into text acoustic features; the text acoustic features are converted into speech signals. The application can improve the efficiency of voice synthesis.","['G10L13/02', 'G10L13/08', 'G10L15/02', 'G10L15/183', 'G10L25/18', 'G10L25/24', 'G10L25/30', 'G10L2015/025']"
US10652565B1,Image compression and decompression using embeddings,"A processing device receives a representation of an image, wherein the image has a first size and the representation has a second size that is smaller than the first size, the representation having been generated from the image by a first portion of a first trained machine learning model. The processing device processes the representation of the image using a second portion of the trained machine learning model to generate a reconstruction of the image and then outputs the reconstruction of the image.","['G06N3/088', 'H04N19/463', 'G06K9/6232', 'G06N20/00', 'G06N3/045', 'G06T9/002', 'G06V10/764', 'G06V10/82', 'H04N19/115', 'G06N7/01']"
US11057646B2,Image processor and image processing method,"An image processor includes memory and circuitry. The circuitry performs processing of approximating a decompressed image to an original image by using a neural network model trained to approximate the decompressed image to the original image. The decompressed image is obtained as a result of compression of the original image and decompression of the compressed image. The neural network model includes one or more convolutional blocks, and includes one or more residual blocks. Each of the one or more convolutional blocks is a processing block including a convolutional layer. Each of the one or more residual blocks includes a convolutional group including at least one of the one or more convolutional blocks, inputs data which is input to the residual block to the convolutional group included in the residual block, and adds the data input to the residual block to data to be output from the convolutional group.","['H04N19/865', 'H04N19/80', 'G06T9/002', 'H04N19/85']"
US11615878B2,Systems and methods for integrating neural network image analyses into medical image viewing applications,"Systems for delivering one or more studies, where each of the one or more studies has a series of digital images associated with only one person and generated by an imaging modality, is disclosed. The systems include a syncing application that is configured to execute within a local area network and that is in data communication with imaging modalities and/or computing devices configured to display images generated by each of the imaging modalities. The systems also include a server adapted to be external to the local area network and in data communication with the syncing application and a client-side viewing application installed on one or more of the computing devices. The client-side viewing application is configured to acquire the studies, including unrendered data representative of the digital images of the series, locally render the unrendered data, and enable a user to manipulate the digital images.","['G16H30/20', 'G06F16/27', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G06T11/008', 'G06T7/0002', 'G06T7/0012', 'G16H30/40', 'G16H40/20', 'H04L67/1095', 'H04L67/1097', 'G06N20/10', 'G06N3/044', 'G06N3/047', 'G06N3/088', 'G06N7/01', 'G06T2200/16', 'G06T2200/24', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168', 'G16H50/20', 'G16H80/00']"
CN110705699B,"Super-resolution reconstruction method and device, electronic equipment and readable storage medium","The embodiment of the application provides a super-resolution reconstruction method, a super-resolution reconstruction device, electronic equipment and a readable storage medium. The method comprises the steps of firstly obtaining an original image to be reconstructed, denoising intensity and a decompression proportion, wherein the original image to be reconstructed is a low-resolution image which carries noise and is subjected to compression processing. And finally, performing super-resolution reconstruction on the original image to be reconstructed by using a super-resolution reconstruction model according to the de-noising sound intensity and the de-compression ratio to obtain a result image with high resolution. Therefore, the super-resolution reconstruction can be carried out on the images with the noises and the compression artifacts with different levels of intensities, and the applicability of the super-resolution reconstruction method is enlarged.","['G06T3/4053', 'G06N3/045', 'G06T17/00', 'G06T2207/20081', 'G06T2207/20084']"
US9123127B2,Contrast enhancement spiking neuron network sensory processing apparatus and methods,"Apparatus and methods for contrast enhancement and feature identification. In one implementation, an image processing apparatus utilizes latency coding and a spiking neuron network to encode image brightness into spike latency. The spike latency is compared to a saliency window in order to detect early responding neurons. Salient features of the image are associated with the early responding neurons. A inhibitory neuron receives salient feature indication and provides inhibitory signal to the other neurons within an area of influence of the inhibitory neuron. The inhibition signal reduces probability of responses by the other neurons to stimulus that is proximate to the feature thereby increasing contrast within the encoded data. The contrast enhancement may facilitate feature identification within the image. Feature detection may be used for example for image compression, background removal and content distribution.","['G06T1/20', 'G06K9/00986', 'G06K9/4623', 'G06N3/049', 'G06V10/451', 'G06V10/955']"
US11676278B2,Deep learning for dense semantic segmentation in video with automated interactivity and improved temporal coherence,"Techniques related to automatically segmenting video frames into per pixel dense object of interest and background regions are discussed. Such techniques include applying a segmentation convolutional neural network (CNN) to a CNN input including a current video frame, a previous video frame, an object of interest indicator frame, a motion frame, and multiple feature frames each including features compressed from feature layers of an object classification convolutional neural network as applied to the current video frame to generate candidate segmentations and selecting one of the candidate segmentations as a final segmentation of the current video frame.","['G06T7/11', 'G06F18/217', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06T7/12', 'G06T7/136', 'G06T7/174', 'G06T7/194', 'G06T7/20', 'G06T7/215', 'G06T7/70', 'G06T7/97', 'G06V10/25', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/42', 'G06V20/46', 'G06V20/49', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084']"
US11462003B2,Flexible accelerator for sparse tensors in convolutional neural networks,A system with a multiplication circuit having a plurality of multipliers is disclosed. Each of the plurality of multipliers is configured to receive a data value and a weight value to generate a product value in a convolution operation of a machine learning application. The system also includes an accumulator configured to receive the product value from each of the plurality of multipliers and a register bank configured to store an output of the convolution operation. The accumulator is further configured to receive a portion of values stored in the register bank and combine the received portion of values with the product values to generate combined values. The register bank is further configured to replace the portion of values with the combined values.,"['G06F17/16', 'G06V10/753', 'G06F17/153', 'G06F18/2137', 'G06K9/6251', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06V10/764', 'G06V10/7715', 'G06V10/82', 'G06V10/955', 'G06N3/084']"
US20250201098A1,Large ship security management system,"A large ship safety supervision system, configured to realize shipmen monitoring and ship safety supervision, wherein shipmen monitoring comprising monitoring of real time positions of shipmen in cabins and shipmen health data, and ship safety supervision comprises oceanic condition warning, on board devices running condition monitoring, ship navigation/construction monitoring and ship remote guidance. Data transmission in between ships and shores is realized by the hybrid self-adaptive compression technology based on model classification and the data transmission link intelligent selection technology based on fuzzy neural network creatively, in the meanwhile, real time safety management and supervision and ship remote work analysis and guidance can be realized.","['G08B21/0453', 'G06V20/53', 'G06F18/241', 'G06N3/043', 'G06V40/161', 'G08B21/0211', 'G08B21/0227', 'G08B21/0423', 'G08B21/0272', 'G08B25/016']"
CN117611015B,Real-time monitoring system for quality of building engineering,"The invention relates to the technical field of nondestructive detection, in particular to a real-time monitoring system for building engineering quality. According to the invention, through the combination of a K-means clustering algorithm and a genetic algorithm, load mode identification and iterative optimization are realized in load analysis, an automatic encoder and a convolutional neural network in data reconstruction analyze building structures, a deep reinforcement learning model is utilized in enhanced prediction, dynamic response prediction is optimized, digital twin and nonlinear analysis are combined with a dynamic Bayesian network and a mixed effect model, health state analysis is provided, main component analysis and independent component analysis in information compression simplify data processing, and a strategy-optimized particle swarm optimization algorithm and a state estimation dynamic Bayesian network improve decision efficiency and risk management capability.","['G06Q10/06395', 'G06F18/2135', 'G06F18/23213', 'G06F18/24', 'G06N3/006', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/084', 'G06N7/01', 'G06Q10/04', 'G06Q10/063', 'G06Q50/08', 'G06V10/454', 'G06V10/82']"
US11685403B2,Systems and methods for vehicle-to-vehicle communications for improved autonomous vehicle operations,"Systems and methods for vehicle-to-vehicle communications are provided. An example computer-implemented method includes obtaining from a first autonomous vehicle, by a second autonomous vehicle, a first compressed intermediate environmental representation. The first compressed intermediate environmental representation is indicative of at least a portion of an environment of the second autonomous vehicle. The method includes generating a first decompressed intermediate environmental representation by decompressing the first compressed intermediate environmental representation. The method includes determining, using one or more machine-learned models, an updated intermediate environmental representation based at least in part on the first decompressed intermediate environmental representation and a second intermediate environmental representation generated by the second autonomous vehicle. The method includes generating an autonomy output for the second autonomous vehicle based at least in part on the updated intermediate environmental representation.","['B60W60/0027', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G08G1/0104', 'G08G1/0112', 'G08G1/096725', 'G08G1/096741', 'G08G1/096791', 'G08G1/163', 'G08G1/22', 'H04W4/38', 'H04W4/46', 'B60W2556/65', 'G06N3/088']"
US8977582B2,Spiking neuron network sensory processing apparatus and methods,"Apparatus and methods for detecting salient features. In one implementation, an image processing apparatus utilizes latency coding and a spiking neuron network to encode image brightness into spike latency. The spike latency is compared to a saliency window in order to detect early responding neurons. Salient features of the image are associated with the early responding neurons. A dedicated inhibitory neuron receives salient feature indication and provides inhibitory signal to the remaining neurons within the network. The inhibition signal reduces probability of responses by the remaining neurons thereby facilitating salient feature detection within the image by the network. Salient feature detection can be used for example for image compression, background removal and content distribution.","['G06V10/462', 'G06K9/62', 'G06K9/4671', 'G06N3/049', 'G06N3/10']"
US10810486B2,Neural network computing systems for predicting vehicle requests,"Embodiments are described for minimizing a wait time for a rider after sending a ride request for a vehicle. An example computer-implemented method includes receiving a ride request, the request being for travel from a starting location to a zone in a geographic region during a specified timeslot. The method further includes predicting travel demand based on a number of ride requests in the zone during the specified timeslot. The method further includes requesting transport of one or more vehicles to the zone in response to the predicted number of ride requests when the travel demand is predicted to exceed a number of vehicles in the zone during the specified timeslot.","['G06N3/0454', 'G08G1/202', 'G06N3/045', 'G06Q30/0202', 'G06N3/044', 'G06N3/0445']"
US20220108157A1,Hardware architecture for introducing activation sparsity in neural network,"A hardware accelerator that is efficient at performing computations related to a sparse neural network. The sparse neural network may be associated with a plurality of nodes. An artificial intelligence (AI) accelerator stores, at a memory circuit, a weight tenor and an input activation tensor that corresponds to a node of the neural network. The AI accelerator performs a computation such as convolution between the weight tenor and the input activation tensor to generate an output activation tensor. The AI accelerator introduces sparsity to the output activation tensor by reducing the number of active values in the output activation tensor. The sparsity activation may be a K-winner approach, which selects the K-largest values in the output activation tensor and set the remaining values to zero.","['G06N3/063', 'G06F7/08', 'G06N3/045', 'G06N3/048', 'G06N3/084']"
NL2028745B1,Apparatus and method for efficient graphics processing including ray tracing,"Apparatus and method for efficient graphics processing including ray tracing. For example, one embodiment of a graphics processor comprises: execution hardware logic to execute graphics commands and render images; an interface to couple functional units of the execution hardware logic to a tiled resource; and a tiled resource manager to manage access by the functional units to the tiled resource, a functional unit of the execution hardware logic to generate a request with a hash identifier (ID) to request access to a portion of the tiled resource, wherein the tiled resource manager is to determine whether a portion of the tiled resource identified by the hash ID exists, and if not, to allocate a new portion of the tiled resource and associate the new portion with the hash ID.","['G06T15/06', 'G06F9/5016', 'G06T1/20', 'G06T1/60', 'G06T15/005', 'G06T9/001', 'G06T2210/21']"
US12120580B2,Selective triggering of neural network functions for positioning measurement feature processing at a user equipment,"In an aspect, a UE obtains information (e.g., UE-specific information) associated with a set of triggering criteria (e.g., from a server, a serving network, e.g., in conjunction with or separate from a set of neural network functions) for a set of neural network functions, the set of neural network functions configured to facilitate positioning measurement feature processing at the UE, the set of neural network functions being generated dynamically based on machine-learning associated with one or more historical measurement procedures. The UE obtains positioning measurement data associated with a location of the UE, and processes the positioning measurement data into a respective set of positioning measurement features based at least in part upon the positioning measurement data and at least one neural network function from the set of neural network functions that is triggered by at least one triggering criterion from the set of triggering criteria.","['H04W64/00', 'G01S5/0036', 'G01S5/012', 'G01S5/0278', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'H04W24/08', 'H04W24/10', 'H04W36/0085', 'H04W4/023', 'H04W4/029', 'H04W64/003', 'H04W36/08']"
US10692250B2,Generalized multi-channel MRI reconstruction using deep neural networks,A method for magnetic resonance imaging acquires multi-channel subsampled k-space data using multiple receiver coils; performs singular-value-decomposition on the multi-channel subsampled k-space data to produce compressed multi-channel k-space data which normalizes the multi-channel subsampled k-space data; applies a first center block of the compressed multi-channel k-space data as input to a first convolutional neural network to produce a first estimated k-space center block that includes estimates of k-space data missing from the first center block; generates an n-th estimated k-space block by repeatedly applying an (n−1)-th estimated k-space center block combined with an n-th center block of the compressed multi-channel k-space data as input to an n-th convolutional neural network to produce an n-th estimated k-space center block that includes estimates of k-space data missing from the n-th center block; reconstructs image-space data from the n-th estimated k-space block.,"['G06T11/005', 'G01R33/4826', 'G01R33/5608', 'G01R33/5611', 'G06N3/045', 'G01R33/4824', 'G06N3/04', 'G06N3/08']"
US11363302B2,Method and apparatus of neural network for video coding,"Method and apparatus of video encoding video coding for a video encoder or decoder using Neural Network (NN) are disclosed. According to one method, input data or a video bitstream are received for blocks in one or more pictures, which comprise one or more colour components. The residual data, prediction data, reconstructed data, filtered-reconstructed data or a combination thereof is derived for one or more blocks of said one or more pictures. A target signal corresponding to one or more of the about signal types is processed using a NN (Neural Network) and the input of the NN or an output of the NN comprises two or more colour components. According to another method, A target signal corresponding to one or more of the about signal types is processed using a NN and the input of the NN or an output of the NN comprises two or more colour components.","['H04N19/117', 'G06T9/002', 'H04N19/107', 'H04N19/176', 'H04N19/186', 'H04N19/33', 'H04N19/82', 'H04N19/86', 'H04N19/46', 'H04N19/70']"
US11076103B2,Photographic underexposure correction using a neural network,A method for image capture includes determining an exposure range and setting at least one camera parameter to capture an underexposed image outside the exposure range. The underexposed image is processed using a neural network to recover image details. Image defects due to camera or object motion blur can be reduced.,"['G06T5/73', 'H04N5/2352', 'G06F18/214', 'G06K9/6256', 'G06T5/002', 'G06T5/50', 'G06T5/60', 'G06T5/70', 'G06V10/82', 'H04N23/683', 'H04N23/72', 'H04N23/73', 'H04N23/75', 'H04N23/76', 'H04N23/81', 'H04N5/23267', 'G06T2207/10024', 'G06T2207/10081', 'G06T2207/10084', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'H04N23/741', 'H04N5/2355']"
CA3144511C,"Air microfluidics and air minifluidics enabled active compression device, apparel, and method","Air microfluidics and minifluidics enabled active compression apparel enhances mobility and quality of life for individuals by minimizing risks of injuries, enhancing rehabilitation, and maximizing comfort. Balloon actuators, integrated with a garment, provide active compression and augmenting forces to anatomical portions of the human body. The balloon actuators are actuated by fluidic pressurization hardware. The air microfluidics and minifluidics system miniaturizes fluidic pressurization hardware and makes it wearable, ultra lightweight, and ultra formfitting. The air microfluidics and minifluidics system includes micro and mini channels of various lengths, cross-sectional areas, and functions via principles of equivalent hydraulic resistance allowing for fluidic transportation, passive delay in pressurization of the balloon actuators, and digital soft fluidic actuation where the compression force is based on the number of inflated balloon actuators instead of their pressure.","['A41D13/1281', 'A61H9/0092', 'A41D13/018', 'A61F5/34', 'A61H1/006', 'A61H9/0078', 'B25J9/0006', 'A41D1/005', 'A61H2201/0103', 'A61H2201/1238', 'A61H2201/1409', 'A61H2201/1647', 'A61H2201/165', 'A61H2201/169', 'A61H2201/5007', 'A61H2201/5056', 'A61H2201/5058', 'A61H2201/5071', 'A61H2205/102', 'A61H2230/605', 'A61H2230/625']"
US12283197B2,Active learning for inspection tool,"A method can include receiving labeled images; acquiring unlabeled images; performing active learning by training an inspection learner using at least a portion of the labeled images to generate a trained inspection learner that outputs information responsive to receipt of one of the unlabeled images by the trained inspection learner; based at least in part on the information, making a decision to call for labeling of the one of the unlabeled images; receiving a label for the one of the unlabeled images; and further training the inspection learner using the label.","['G09B23/40', 'G01V99/00', 'G06F18/00', 'G06F18/2155', 'G06V10/7753', 'G06V10/778', 'G06V10/82', 'G06V20/05', 'G01V1/301', 'G06F18/217']"
US10983957B2,Distributed columnar data set storage,"An apparatus includes a processor to: instantiate collection threads, data buffers of a queue, and aggregation threads; within each collection thread, assemble a row group from a subset of the multiple rows, reorganize the data values row-wise to columnar organization, and store the row group within a data buffer of the queue; operate the buffer queue as a FIFO buffer; within each aggregation thread, retrieve multiple row groups from multiple data buffers of the queue, assemble a data set part from the multiple row groups, transmit, to storage device(s) via a network, the data set part; and in response to each instance of retrieval of a row group from a data buffer of the buffer queue for use within an aggregation thread, analyze a level of availability of at least storage space within the node device to determine whether to dynamically adjust the quantity of data buffers of the buffer queue.","['G06F16/137', 'G06F16/221', 'G06F12/0292', 'G06F16/1827', 'G06F16/22', 'G06F16/278', 'G06F21/602', 'G06F3/0604', 'G06F3/061', 'G06F3/064', 'G06F3/0643', 'G06F3/0644', 'G06F3/0659', 'G06F3/067', 'G06F9/5072', 'G06F9/5077', 'G06F9/542', 'G06N20/00', 'G06N3/084', 'H05K999/99', 'G06F2212/1016', 'G06F2212/1056', 'G06F2212/154', 'G06F2212/262', 'G06F2212/263', 'Y02D10/00']"
US10198532B2,"Reducing data storage, memory, and computational time needed for ad-hoc data analysis","A compressed data structure is disclosed for storing collected data and delivering ad-hoc data analysis. The compressed data structure can reduce hardware requirements, such as data storage requirements, and decrease processing requirements during ad-hoc data analysis. Raw data can be pre-aggregated to a base level of aggregation (base cell level) that is determined by the unique combination of attributes available for aggregation. Rather than storing the raw data, the entire distribution is stored at the base cell level along with a selection of pre-computed statistics of the raw data. At the time of ad-hoc analysis, pre-computed results based on the raw data can be retrieved or computed from the pre-computed statistics, or analysis of higher-level data can be computed on-demand based on the pre-aggregated base level data.","['G06F16/90335', 'G06F17/30979', 'G06F16/13', 'G06F16/1727', 'G06F16/2282', 'G06F16/283', 'G06F17/18', 'G06F17/30091', 'G06F17/30138']"
US8323188B2,Health monitoring appliance,A heart monitoring system for a person includes one or more wireless nodes forming a wireless network; a wearable sensor having a wireless transceiver adapted to communicate with the one or more wireless nodes; and a software module receiving data from the wireless nodes to detect changes in patient vital signs.,"['G16H40/67', 'A61B5/0006', 'A61B5/0008', 'A61B5/002', 'A61B5/0022', 'A61B5/01', 'A61B5/02055', 'A61B5/021', 'A61B5/02108', 'A61B5/0295', 'A61B5/0537', 'A61B5/1117', 'A61B5/14532', 'A61B5/14551', 'A61B5/165', 'A61B5/282', 'A61B5/291', 'A61B5/33', 'A61B5/347', 'A61B5/411', 'A61B5/4806', 'A61B5/4833', 'A61B5/4866', 'A61B5/6803', 'A61B5/681', 'A61B5/6814', 'A61B5/6816', 'A61B5/6887', 'A61B5/72', 'A61B5/7405', 'A61B5/742', 'A61B5/747', 'A61B8/4472', 'A61B8/52', 'A61B8/56', 'A61B8/565', 'G06F16/24', 'G06Q30/0269', 'G16H50/20', 'G16Z99/00', 'A61B2560/0412', 'A61B5/02416', 'A61B5/0265', 'A61B5/029', 'A61B5/0536', 'A61B5/086', 'A61B5/113', 'A61B5/1455', 'A61B5/318', 'A61B5/377', 'A61B5/389', 'A61B5/398', 'A61B5/4023', 'A61B5/4519', 'A61B5/4528', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B7/00', 'A61B8/06', 'A61B8/0808', 'G08B21/0453', 'G16H20/13']"
US10986356B2,Method for encoding/decoding image and device therefor,"Provided are an image compressing method including determining a compressed image by performing downsampling using a deep neural network (DNN) on an image; determining a prediction signal by performing prediction based on the compressed image; determining a residual signal based on the compressed image and the prediction signal; and generating a bitstream comprising information about the residual signal, wherein the DNN has a network structure that is predetermined according to training of a downsampling process using information generated in an upsampling process, and an image compressing device for performing the image compressing method. Also, provided are an image reconstructing method of reconstructing a compressed image by using a DNN for upsampling, the compressed image having been compressed by the image compressing method, and an image reconstructing device for performing the image reconstructing method.","['H04N19/85', 'H04N19/33', 'H04N19/14', 'H04N19/184', 'H04N19/50', 'H04N19/59', 'H04N19/80']"
US11798167B2,Long-term and continuous animal behavioral monitoring,"Systems and methods for continuous monitoring of the behavior of animals, such as small rodents, are provided. Monitoring can include video, audio, and other sensor modalities. In one embodiment, the system can include cameras, arena design, environmental sensors, and ultrasonic sensors. The system uniquely provides a continuous long-term monitoring system suitable for mouse behavioral study. Further provided is a neural network based tracker configured for use with video data acquired by the monitoring system. Three different neural network architectures have been tested to determine their performance on genetically diverse mice under varying environmental conditions. It has been observed that that an encoder-decoder segmentation neural network achieves high accuracy and speed with minimal training data. This general purpose neural network tracker can be easily extended to other experimental paradigms and even to other animals through transfer learning, thus forming a robust, generalizable solution for bio-behavioral research.","['G06T7/11', 'A01K29/005', 'A01K1/031', 'G06F18/2413', 'G06F18/28', 'G06T1/0007', 'G06T7/194', 'G06V10/141', 'G06V10/143', 'G06V10/25', 'G06V10/26', 'G06V10/454', 'G06V10/764', 'G06V10/772', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G06V20/40', 'G06V40/10', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232']"
US11797830B2,Flexible accelerator for sparse tensors in convolutional neural networks,"An apparatus includes a tensor compute cluster having a plurality of tensor compute units to process a plurality of sub-feature maps in a machine learning application and a tensor memory cluster having a plurality of tensor feature map memory units to store the plurality of sub-feature maps. The apparatus also includes circuitry to partition an input feature map into the plurality of sub-feature maps such that sparsity in each of the plurality of sub-feature maps satisfies a predetermined threshold, and assign each of the plurality of sub-feature maps to one of the plurality of tensor compute units and one of the plurality of tensor feature map memory units for processing in parallel.","['G06N3/045', 'G06N3/063', 'G06N3/04', 'G06N3/048', 'G06N3/08', 'G06V10/70']"
US12182900B2,"Unified architecture for BVH construction based on hardware pre-sorting and a parallel, reconfigurable clustering array","An apparatus comprising a sorting unit to sort primitives of a graphics image, the primitives to be grouped, each group to form a first level node of a hierarchical acceleration structure; a parallel reconfigurable clustering array to construct the hierarchical acceleration structure, the parallel reconfigurable clustering array comprising a plurality of processing clusters, each cluster comprising: parallel efficiency analysis circuitry to evaluate different groupings of the first level nodes for a next level of the hierarchical acceleration structure to determine efficiency values for the different groupings; and node merge circuitry to merge the first level nodes based on the efficiency values to form second level nodes.","['G06T1/20', 'G06F16/9027', 'G06F9/3877', 'G06F9/3891', 'G06F9/5077', 'G06T15/005', 'G06T15/06', 'G06T15/10']"
US20240119286A1,Adaptive artificial neural network selection techniques,"Computer-implemented techniques can include obtaining, by a client computing device, a digital media item and a request for a processing task on the digital item and determining a set of operating parameters based on (i) available computing resources at the client computing device and (ii) a condition of a network. Based on the set of operating parameters, the client computing device or a server computing device can select one of a plurality of artificial neural networks (ANNs), each ANN defining which portions of the processing task are to be performed by the client and server computing devices. The client and server computing devices can coordinate processing of the processing task according to the selected ANN. The client computing device can also obtain final processing results corresponding to a final evaluation of the processing task and generate an output based on the final processing results.","['G06F9/5044', 'G06F9/505', 'G06F9/5094', 'G06N3/045', 'G06N3/08', 'H04L67/01', 'H04L67/10', 'G06F2209/503', 'G06F2209/509', 'Y02D10/00']"
US11797862B2,Extreme language model compression with optimal sub-words and shared projections,"Provided is a knowledge distillation technique for training a student language model that, relative to a larger teacher language model, has a significantly smaller vocabulary, lower embedding dimensions, and/or hidden state dimensions. Specifically, aspects of the present disclosure are directed to a dual-training mechanism that trains the teacher and student language models simultaneously to obtain optimal word embeddings for the student vocabulary. In some implementations, this approach can be combined with learning shared projection matrices that transfer layer-wise knowledge from the teacher language model to the student language model. Example experimental results have also demonstrated higher compression efficiency and accuracy when compared with other state-of-the-art compression techniques, including the ability to compress the BERTBASE model by more than 60×, with only a minor drop in downstream task metrics, resulting in a language model with a footprint of under 7 MB.","['G06N3/088', 'G06F40/284', 'G06N3/045']"
US20210138249A1,System and method for neural stimulation using spike frequency modulation,"Embodiments may comprise receiving electrical and optical signals from electrophysiological neural signals of neural tissue from at least one read modality, wherein the electrophysiological neural signals are at least one of Spike frequency modulated or Spike frequency demodulated, encoding the received electrical and optical signals using a Fundamental Code Unit, automatically generating at least one machine learning model using the Fundamental Code Unit encoded electrical and optical signals, generating at least one optical or electrical signal to be transmitted to the brain tissue using the generated at least one machine learning model, wherein the generated signals are at least one of Spike frequency modulated or Spike frequency demodulated, and transmitting the generated at least one optical or electrical signal to the neural tissue to provide electrophysiological stimulation of the neural tissue using at least one write modality.","['A61B5/0031', 'A61B5/0084', 'A61B5/076', 'A61B5/1473', 'A61B5/37', 'A61B5/375', 'A61B5/4076', 'A61B5/6868', 'A61N1/36139', 'A61N1/37252', 'A61N5/0622', 'A61N5/067', 'B82Y10/00', 'G06F3/015', 'G06N3/049', 'G06N3/086', 'G16H10/60', 'G16H20/30', 'G16H20/40', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'A61B5/0024', 'A61B5/6815', 'A61N1/0531', 'A61N1/36067', 'A61N1/36071', 'A61N1/36082', 'A61N2005/0612', 'A61N2005/0626', 'A61N2005/063', 'A61N2005/0652', 'A61N2005/0663', 'A61N5/0601', 'A61N5/0618', 'B82Y30/00', 'B82Y5/00', 'G06N3/084', 'G06N3/088']"
US9317761B2,Method and an apparatus for determining vein patterns from a colour image,"The present invention is directed to a method of determining vein patterns from a color image for personal identification, the method comprising forming a counterpart of the color image by applying a functional relationship obtained from optimization on the color image, wherein the counterpart of the color image comprises the vein patterns. An apparatus for determining vein patterns from a color image is also disclosed.","['G06K9/00885', 'G06V40/10', 'A61B5/0077', 'A61B5/02007', 'A61B5/1128', 'A61B5/117', 'A61B5/1171', 'A61B5/489', 'A61B5/7267', 'G06T7/11', 'G06T7/136', 'G06K2009/00932', 'G06T2207/10024', 'G06T2207/20044', 'G06T2207/20084', 'G06T2207/30088', 'G06V40/14', 'G16H50/70']"
CN108416290B,Radar signal feature extraction method based on residual deep learning,"The invention relates to a radar signal feature extraction method based on residual deep learning, which can be used for deep feature extraction of radar radiation source signals in a complex electromagnetic environment through a designed residual deep learning network. The method comprises the following implementation steps: firstly, the existing radar data in a database is utilized to train the parameters of the residual error depth network. And then sending the intercepted data to a residual error depth network input end, outputting a result after mapping through a plurality of hidden layers, and taking the output result as the depth characteristic of the pulse train. And clustering the obtained depth features by using a clustering method again, and calculating the correlation degree of every two clustered radiation sources according to a correlation criterion for processing. And finally, calculating the parameters of each radiation source after fusion to finish sorting. The method can be used for mining the deep characteristics among data, has the advantage of high sorting precision, and can be used in the fields of target reconnaissance and interference source positioning.","['G06F2218/08', 'G01S7/02', 'G06F18/2321']"
US12125133B2,Speculative execution of hit and intersection shaders on programmable ray tracing architectures,"Apparatus and method for speculative execution of hit and intersection shaders on programmable ray tracing architectures. For example, one embodiment of an apparatus comprises: single-instruction multiple-data (SIMD) or single-instruction multiple-thread (SIMT) execution units (EUs) to execute shaders; and ray tracing circuitry to execute a ray traversal thread, the ray tracing engine comprising: traversal/intersection circuitry, responsive to the traversal thread, to traverse a ray through an acceleration data structure comprising a plurality of hierarchically arranged nodes and to intersect the ray with a primitive contained within at least one of the nodes; and shader deferral circuitry to defer and aggregate multiple shader invocations resulting from the traversal thread until a particular triggering event is detected, wherein the multiple shaders are to be dispatched on the EUs in a single shader batch upon detection of the triggering event.","['G06F9/3887', 'G06T1/60', 'G06T15/005', 'G06T15/06', 'G06T2210/21']"
CN105681920B,A kind of Network teaching method and system with speech identifying function,"The present invention provides a kind of Network teaching method and system, achieve double identification authentications of recognition of face and speech recognition, for the precision of speech signal collection in teaching process and Oral Training, test and examination process, using multi-model marking test and appraisal, improve the degree of accuracy of test and appraisal, so that the Web-based instruction more autonomous effectively, particularly being related to read aloud, hearing and when the teaching such as reciting, these functions that can pass through system improve the authenticity and validity of study.The method of the present invention combines recognition of face and Application on Voiceprint Recognition, before user carries out oral test or during system login, checks the identity of user, can preferably encourage user's true man's pronunciation test in use.","['H04N21/478', 'G09B5/06', 'G10L17/00', 'H04N21/2747', 'H04N21/4302', 'H04N21/4331', 'H04N21/47202', 'H04N21/6405', 'H04N21/8153', 'H04N21/8547', 'H04N5/76']"
US8364136B2,"Mobile system, a method of operating mobile system and a non-transitory computer readable medium for a programmable control of a mobile system","A mobile system and method of operation thereof, comprising a radio frequency system, adapted to derive information relating to a position within an environment, based on communications with at least one terrestrial or extraterrestrial transmitter, and remotely transmit to and receive radio frequency information-bearing communications; a memory adapted to store at least a vehicle itinerary or position-related information; a controller, receiving the derived information and controlling a communication of the information-bearing communications relating to at least the stored itinerary or position related information; and a user interface, having a functionality defined by the controller, adapted to interface a user for receipt or presentation of information relating at least one of the itinerary or position-related information and the communicated information.","['H04N21/42201', 'G05B15/02', 'G06Q30/0261', 'H04N21/4131', 'H04N21/44224', 'H04N21/4532', 'H04N21/47', 'H04N5/782', 'H04N5/913', 'H04N2005/91328', 'H04N2005/91364']"
US10454498B1,Fully pipelined hardware engine design for fast and efficient inline lossless data compression,"A hardware compression system is provided. The system includes a hardware pipeline having a plurality of stages arranged to receive pre-compression data into a data buffer, populate a first hash table and a second hash table, supply the pre-compression data to a hash lookup module to access the first hash table and the second hash table in parallel, supply a string match module with results from the hash lookup module so that the string match module compares pre-compression data from multiple locations in the data buffer in parallel, supply a match merge module with results from the string match module so that the match merge module generates literals and metadata for compression data, and supply an output encoding module with results from the match merge module so that the output encoding module encodes the compression data.","['H03M7/6029', 'H03M7/3084', 'H03M7/3086', 'H03M7/42', 'H03M7/6023']"
US10706498B2,Machine learning sparse computation mechanism,"An apparatus to facilitate processing of a sparse matrix is disclosed. The apparatus includes a plurality of processing units each comprising one or more processing elements, including logic to read operands, a multiplication unit to multiply two or more operands and a scheduler to identify operands having a zero value and prevent scheduling of the operands having the zero value at the multiplication unit.","['G06N20/00', 'G06F12/0207', 'G06F12/0811', 'G06F12/0815', 'G06F12/0831', 'G06F12/0888', 'G06F17/16', 'G06F18/2136', 'G06F9/3001', 'G06F9/3885', 'G06F9/4881', 'G06K9/6249', 'G06N3/04', 'G06N3/0442', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T1/20', 'G06T1/60', 'G06T15/005', 'H03M7/30', 'G06F2212/1024', 'G06F2212/302', 'G06F2212/401', 'G06F2212/621', 'G06T2200/28', 'Y02D10/00']"
US8498941B2,"Information record infrastructure, system and method","A data security apparatus and method for controlling access to records provided within automated electronic databases, each record having an associated set of access rules, comprising: receiving, by a security processor, a request for access to records associated with at least one of an entity, attribute, and datum from a requestor; determining a set of records associated with the requested entity, attribute, or datum, contained in the automated electronic databases; authorizing access to the records within the determined set of records based on compliance with the associated set of access rules; defining an economic compensation rule, satisfaction of which is required for qualification for access to the set of records; selectively permitting access to records in dependence on satisfaction of the compensation rule; communicating the access permissions to the host automated electronic databases; and logging the request for retrieval and a respective access of each record.","['G06F21/6245', 'G06Q10/10', 'G06Q20/367', 'G06Q20/3674', 'G06Q20/382', 'G16H10/60']"
US11527035B2,Real time ray tracing (RTRT)-based adaptive multi-frequency shading (AMFS),"Real time ray tracing-based adaptive multi frequency shading. For example, one embodiment of an apparatus comprising: rasterization hardware logic to process input data for an image in a deferred rendering pass and to responsively update one or more graphics buffers with first data to be used in a subsequent rendering pass; ray tracing hardware logic to perform ray tracing operations using the first data to generate reflection ray data and to store the reflection ray data in a reflection buffer; and image rendering circuitry to perform texture sampling in a texture buffer based on the reflection ray data in the reflection buffer to render an output image.","['G06T1/20', 'G06T15/06', 'G06T1/60', 'G06T15/005', 'G06T15/04', 'G06T15/80']"
US11350059B1,System and method for intelligent appearance monitoring management system for videoconferencing applications,"A system or method executing an intelligent appearance monitoring management system comprising a processor to execute code instructions of a multimedia multi-user collaboration application to join a videoconference session, a display screen, a speaker, a video camera, and a microphone where the video camera captures a videoframe of a user and the processor to input videoframe data, including the detected user's image, into a trained neural network of the intelligent appearance monitoring management system to generate optimized appearance filtering adjustments indicating detection of a user appearance anomaly in the user's image or altering a user's image in the captured videoframes in response to the user appearance anomaly and prepare those videoframes for transmission.","['H04N7/15', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T5/002', 'G06T5/70', 'G06T7/0002', 'G06V40/168', 'H04N23/60', 'H04N23/62', 'H04N23/695', 'H04N5/23216', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'G06T2207/30201', 'G06T2207/30232']"
US10699475B1,Multi-pass apparatus and method for early termination of graphics shading,"Multi-pass apparatus and method for ray tracing shading. For example, one embodiment of an apparatus comprises: graphics processing circuitry to execute a sequence of visibility testing operations related to texels within a texture domain to generate visibility results; a register or memory to store a texel mask; texel mask update circuitry/logic to update the texel mask based on the visibility results, the texel mask comprising a plurality of bits to indicate visibility of the texels within the texture domain, the texel mask update circuitry/logic to set a first bit to indicate whether any bits in the texel mask indicate a visible texel; a shader dispatcher to initiate conditional dispatch operations only if the first bit is set to indicate that at least one bit in the texel mask indicates a visible texel, wherein to perform the conditional dispatch operations, the shader dispatcher is to dispatch texel shaders for only those texels that the texel mask indicates may be visible; and a plurality of execution units (EUs) to execute the shaders dispatched by the shader dispatcher.","['G06T15/40', 'G06T15/005', 'G06T15/04', 'G06T15/06']"
RU2745298C1,"Device, method, or computer program for generating an extended-band audio signal using a neural network processor",FIELD: computer technology; processing audio signals.,"['G10L21/0388', 'G06N20/10', 'G06N3/063', 'G06N3/084', 'G10L19/005', 'G10L19/02', 'G10L21/02', 'G10L21/038', 'H04L65/80', 'G10L25/30']"
CN108133269B,Processor with memory array operable as cache memory or neural network unit memory,"A processor comprising a mode indicator, a plurality of processing cores, and a Neural Network Unit (NNU) comprising a memory array, an array of Neural Processing Units (NPUs), cache control logic circuitry, and selection logic circuitry configured to selectively couple the plurality of NPUs and the cache control logic circuitry to the memory array. When the mode indicator indicates a first mode, the selection logic circuitry enables the plurality of NPUs to read neural network weights from the memory array to perform calculations using the weights. When the mode indicator indicates the second mode, selection logic enables the plurality of processing cores to access the memory array as a cache memory through the cache control logic.","['G06F12/08', 'G06N3/08', 'G06F13/1668', 'G06N3/063', 'G06F12/0802', 'G06F12/0811', 'G06F12/0813', 'G06F12/084', 'G06F12/0846', 'G06F12/0897', 'G06F3/0607', 'G06F3/0634', 'G06F3/0656', 'G06F3/0658', 'G06F3/0689', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0499', 'G06F2212/1016', 'G06F2212/2515']"
CN111612708B,Image restoration method based on countermeasure generation network,"The invention relates to an image restoration method based on an countermeasure generation network, which comprises the following steps: s1, constructing an image restoration training network: adding the generated SE-RestNet network into the generated network, and adding the discrimination SE-RestNet network into the discrimination network to obtain an image restoration training network; s2, training: extracting a plurality of original images from a training data set, masking to obtain a plurality of training images, respectively using the SE-RestNet generating network in the generating network to generate training repair images, using the SE-RestNet discriminating network in the discriminating network to discriminate the true and false of the repair images, and taking the trained generating network as an image repair network after the discriminating network reaches an equilibrium state. According to the image restoration method based on the countermeasure generation network, the SE-RestNet network block is added in the countermeasure generation network, so that the restored image ensures the image structure and semantic consistency, the image restoration effect is better, and no restoration trace exists.","['G06T5/77', 'G06N3/045', 'G06N3/08', 'G06T2207/10004', 'G06T2207/20081', 'Y02T10/40']"
US10319115B2,Image compression device,"Provided is an image compression device including an object extracting unit configured to perform convolution neural network (CNN) training and identify an object from an image received externally, a parameter adjusting unit configured to adjust a quantization parameter of a region in which the identified object is included in the image on the basis of the identified object, and an image compression unit configured to compress the image on the basis of the adjusted quantization parameter.","['G06T9/002', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T7/11', 'G06T7/194', 'H04N19/124', 'H04N19/17', 'H04N19/189', 'H04N19/20', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084']"
EP3567857A1,Method for encoding/decoding image and device therefor,"Provided are an image compressing method including determining a compressed image by performing downsampling using a deep neural network (DNN) on an image; determining a prediction signal by performing prediction based on the compressed image; determining a residual signal based on the compressed image and the prediction signal; and generating a bitstream comprising information about the residual signal, wherein the DNN has a network structure that is predetermined according to training of a downsampling process using information generated in an upsampling process, and an image compressing device for performing the image compressing method. Also, provided are an image reconstructing method of reconstructing a compressed image by using a DNN for upsampling, the compressed image having been compressed by the image compressing method, and an image reconstructing device for performing the image reconstructing method.","['H04N19/117', 'G06N3/04', 'G06N3/08', 'G06T9/002', 'H04N19/132', 'H04N19/154', 'H04N19/172', 'H04N19/184', 'H04N19/33', 'H04N19/50', 'H04N19/80']"
US12347179B2,Privacy-preserving distributed visual data processing,"In one embodiment, an apparatus comprises a processor to: identify a workload comprising a plurality of tasks; generate a workload graph based on the workload, wherein the workload graph comprises information associated with the plurality of tasks; identify a device connectivity graph, wherein the device connectivity graph comprises device connectivity information associated with a plurality of processing devices; identify a privacy policy associated with the workload; identify privacy level information associated with the plurality of processing devices; identify a privacy constraint based on the privacy policy and the privacy level information; and determine a workload schedule, wherein the workload schedule comprises a mapping of the workload onto the plurality of processing devices, and wherein the workload schedule is determined based on the privacy constraint, the workload graph, and the device connectivity graph. The apparatus further comprises a communication interface to send the workload schedule to the plurality of processing devices.","['G06V10/82', 'G06F18/241', 'G06F18/24133', 'G06F21/604', 'G06F21/6245', 'G06F9/4881', 'G06F9/505', 'G06Q50/26', 'G06V10/44', 'G06V10/764', 'G06V20/52', 'G06V40/103', 'G08G1/091', 'G11B27/031', 'H04N7/181', 'G06F2209/506', 'G08G1/0116', 'G08G1/087']"
US11255282B2,"State detection system for internal combustion engine, data analysis device, and vehicle","A state detection system for an internal combustion engine is provided. Rotation waveform variables include information on a difference between cylinders in the rotational speed of a crankshaft during periods in which the respective cylinders generate combustion torque. An obtainment process obtains a value of the rotation waveform variables and a value of a road surface state variable based on an output of a sensor that detects a state of the road surface. A selection process selects, from a plurality of types of mapping data stored in the storage device, the mapping data that is associated with the road surface state variable as the detection mapping. A determination process determines whether the engine is in a predetermined operating state based on an output value of the selected detection mapping that takes the rotation waveform variables as inputs.","['F02D35/02', 'F02D41/1498', 'F02D41/0097', 'F02B77/086', 'F02D29/02', 'F02D41/1405', 'F02D41/1475', 'F02D41/1479', 'F02D41/22', 'F02D41/2438', 'F02D41/2445', 'F02D41/2451', 'F02D41/2454', 'F02D41/2477', 'F02P17/00', 'G01M15/05', 'G01M15/11', 'F02D2200/101', 'F02D2200/1015', 'F02D2200/702', 'F02D41/2422']"
US20240430037A1,Parity check decoding,"Apparatuses, systems, and techniques to decode encoded data. In at least one embodiment, parts of information for decoding the encoded data is provided to a plurality of processors, and parts of data decoded by the plurality of processors is combined.","['H03M13/1111', 'H04L1/0076', 'H03M13/1134', 'H03M13/1137', 'H03M13/114', 'H03M13/116', 'H03M13/6505', 'H03M13/6588', 'H04L1/0057', 'H04W28/04']"
US20200005154A1,Data encoding and classification,"In a method and apparatus for training a computer system for use in classification of an image by processing image data representing the image, image data are compressed and then loaded into a programmable quantum annealing device that includes a Restricted Boltzmann Machine. The Restricted Boltzmann Machine is trained to act as a classifier of image data, thereby providing a trained Restricted Boltzmann Machine; and, the trained Restricted Boltzmann Machine is used to initialize a neural network for image classification thereby providing a trained computer system for use in classification of an image.","['G06N10/60', 'G06N3/088', 'G06N20/10', 'G06N20/20', 'G06N3/0455', 'G06N3/047', 'G06N7/08', 'G06T3/4046', 'G06T9/002']"
US11113784B2,Sparse optimizations for a matrix accelerator architecture,"Embodiments described herein include, software, firmware, and hardware logic that provides techniques to perform arithmetic on sparse data via a systolic processing unit. Embodiment described herein provided techniques to skip computational operations for zero filled matrices and sub-matrices. Embodiments additionally provide techniques to maintain data compression through to a processing unit. Embodiments additionally provide an architecture for a sparse aware logic unit.","['G06F12/0806', 'G06F15/8007', 'G06F15/8046', 'G06F17/16', 'G06F7/5443', 'G06F9/3001', 'G06F9/30036', 'G06F9/3016', 'G06F9/3836', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/5027', 'G06N3/045', 'G06N3/048', 'G06N3/0481', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06T1/20']"
US11863495B2,Signaling for a channel state information reference signal (CSI-RS),"A user equipment (UE) receives, from a network entity, a message indicating a change in a set of downlink beams for channel state information reference signals (CSI-RSs), and a context associated with the change. The UE saves state values in an auto-encoder neural network in response to receiving the message and associates the saved state values in the auto-encoder neural network to the context in the received message. The UE also resets the state values in the auto-encoder neural network in response to receiving the message and estimates a channel state based on the CSI-RSs received on the changed set of downlink beams. The UE compresses the channel state with the auto-encoder neural network based on the reset state values and further sends to the network entity, the compressed channel state.","['H04B7/0626', 'H04L5/0057', 'G06N3/044', 'G06N3/045', 'H04L5/0023', 'H04L5/0048', 'H04L5/005', 'H04L5/0098', 'H04W16/28', 'H04B7/063']"
US12306771B2,Efficient data sharing for graphics data processing operations,"An apparatus to facilitate efficient data sharing for graphics data processing operations is disclosed. The apparatus includes a processing resource to generate a stream of instructions, an L1 cache communicably coupled to the processing resource and comprising an on-page detector circuit to determine that a set of memory requests in the stream of instructions access a same memory page; and set a marker in a first request of the set of memory requests; and arbitration circuitry communicably coupled to the L1 cache, the arbitration circuitry to route the set of memory requests to memory comprising the memory page and to, in response to receiving the first request with the marker set, remain with the processing resource to process the set of memory requests.","['G06F13/1605', 'G06F9/3004', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/5016', 'G06F9/5038', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06T1/20', 'G06T1/60', 'G06F2209/509', 'G06N3/048', 'G06N3/088', 'Y02D10/00']"
WO2021042665A1,Dnn-based method for protecting passport against fuzzy attack,"The present invention provides a DNN-based method for protecting a passport against the fuzzy attack. A DNN model is comprised. The ownership verification scheme of the DNN model comprises an embedding process, a fidelity evaluation process, a signature verification process, and a reversible process. During ownership verification, a private passport and a trigger set are embedded but not distributed, which comprises: embedding the passport and embedding a group of trigger images; detecting and declaring the ownership of a suspicious DNN model by remotely calling a service API; first, declaring the ownership in a black box mode, and then declaring the ownership of a trigger set image again in a white box mode by means of the passport verification, alternately minimizing the original task loss, and reducing a joint loss function containing passport constraints. The range of the network performance significantly changes from 3% to 80% for AlexNet and ResNet trained for classification tasks CIFAR10 and CIFAR100. The similarity between the accuracy of a DNN model providing a valid passport, and the accuracy of an original network exceeds 90%, and a classification accuracy rate of about 10% is achieved for the same DNN model using a fake passport.","['G06F21/55', 'G06N3/045', 'G06N3/08']"
CN109613002B,Glass defect detection method and device and storage medium,"The embodiment of the invention discloses a glass defect detection method, a glass defect detection device and a storage medium. The embodiment of the invention can acquire the detected glass image and determine the area to be detected in the detected glass image; acquiring color information of pixels in the region to be detected, and screening out candidate regions in the region to be detected according to the color information; detecting the defects of the candidate area by adopting a preset detection model; and if the defect is detected in the candidate area, acquiring the attribute information of the defect. Therefore, compared with the existing manual detection, the scheme realizes the automatic detection of the glass defects, greatly improves the efficiency of the glass defect detection, and reduces the probability of missed detection and false detection.","['G01N21/8851', 'G01N2021/8887']"
US11768504B2,Light weight and real time slam for robots,"Some aspects include a method for operating a cleaning robot, including: capturing LIDAR data; generating a first iteration of a map of the environment in real time; capturing sensor data from different positions within the environment; capturing movement data indicative of movement of the cleaning robot; aligning and integrating newly captured LIDAR data with previously captured LIDAR data at overlapping points; generating additional iterations of the map based on the newly captured LIDAR data and at least some of the newly captured sensor data; localizing the cleaning robot; planning a path of the cleaning robot; and actuating the cleaning robot to drive along a trajectory that follows along the planned path by providing pulses to one or more electric motors of wheels of the cleaning robot.","['G05D1/0274', 'G05D1/0248', 'B25J11/0085', 'B25J13/087', 'B25J9/1664', 'G05D1/0016', 'G05D1/0022', 'G05D1/0044', 'G05D1/0219', 'G05D1/024', 'G05D1/027', 'G05D1/0272', 'G06F9/5016', 'G06F9/5038', 'G06F9/5066', 'G06N3/006', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/082', 'G06N3/084', 'G06N3/088', 'G06N7/01', 'G05D2201/0215', 'G06F2209/509', 'G06N10/20', 'G06N5/01']"
US11151447B1,Network training process for hardware definition,"This disclosure describes methods, apparatuses, and systems for network training and testing for evaluating hardware characteristics and for hardware selection. For example, a sensor can capture a dataset, which may be transformed into a plurality of modified datasets to simulate changes to hardware. Each of the plurality of modified datasets may be used to individually train an untrained neural network, thereby producing a plurality of trained neural networks. In order to evaluate the trained neural networks, each neural network can be used to ingest an evaluation dataset to perform a variety of tasks, such as identifying various objects within the dataset. A performance of each neural network can be determined and compared. A performance curve can be determined for each characteristic under review, facilitating a selection of one or more hardware components and/or configurations.","['G06N3/08', 'G01S13/862', 'G01S13/865', 'G01S13/867', 'G01S13/931', 'G01S17/86', 'G01S17/931', 'G01S7/4021', 'G01S7/4091', 'G01S7/417', 'G06F16/211', 'G06N3/045', 'G01S2013/9323', 'G01S2013/9324', 'G01S2013/93271', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N5/01', 'G06N5/025', 'G06N7/01']"
US10776690B2,Neural network unit with plurality of selectable output functions,"A neural network unit includes a register programmable with a control value, a plurality of neural processing units (NPU), and a plurality of activation function units (AFU). Each NPU includes an arithmetic logic unit (ALU) that performs arithmetic and logical operations on a sequence of operands to generate a sequence of results and an accumulator into which the ALU accumulates the sequence of results as an accumulated value. Each AFU includes a first module that performs a first function on the accumulated value to generate a first output, a second module that performs a second function on the accumulated value to generate a second output, the first function is distinct from the second function, and a multiplexer that receives the first and second outputs and selects one of the two outputs based on the control value programmed into the register.","['G06N3/063', 'G06N3/04', 'G06F9/3001']"
US11445128B2,System and method for intelligent virtual background management for videoconferencing applications,"An intelligent video processing management method may comprise joining a videoconference session with multiple participants via a multimedia multi-user collaboration application, detecting a current central processing unit (CPU) consumption by the multimedia multi-user collaboration application and a current MMCA processor setting, associating each of the participants with an organizational ranking relative to the purpose of the videoconference session, inputting sensor data including the participant's organizational rankings, the current CPU consumption by the multimedia multi-user collaboration application, and the current MMCA processor setting to a trained neural network, outputting from the neural network an optimized boundary detection algorithm selection instruction predicted to adjust performance of the information handling system to meet a preset performance benchmark requirement, during the videoconference session, and applying a virtual background around a boundary of a user of the information handling system detected within an image captured by a camera according to the optimized boundary detection algorithm selection instruction.","['H04N5/272', 'G01S19/01', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T1/20', 'G06T7/13', 'H04N7/15', 'G06T2207/20084', 'G06T2207/30196']"
US11586601B2,Apparatus and method for representation of a sparse matrix in a neural network,"The present disclosure relates to a method and an apparatus for representation of a sparse matrix in a neural network. In some embodiments, an exemplary operation unit includes a buffer for storing a representation of a sparse matrix in a neural network, a sparse engine communicatively coupled with the buffer, and a processing array communicatively coupled with the sparse engine. The sparse engine includes circuitry to: read the representation of the sparse matrix from the buffer, the representation comprising a first level bitmap, a second level bitmap, and an element array; decompress the first level bitmap to determine whether a block of the sparse matrix comprises a non-zero element; and in response to the block comprising a non-zero element, decompress the second level bitmap using the element array to obtain the block of the sparse matrix. The processing array includes circuitry to execute the neural network with the sparse matrix.","['G06F16/2237', 'G06F16/1744', 'G06F16/901', 'G06F17/16', 'G06F9/30018', 'G06N3/02', 'G06N3/063', 'G06N3/082']"
WO2020054442A1,"Articulation position acquisition method and device, and motion acquisition method and device","The present invention allows for highly precise motion capture, which can be used as a substitute for optical motion capture technology, and which obviates the need for attaching optical markers or sensors on a subject. A subject having a poly-articular structure has a plurality of physical feature points including a plurality of articulations. Distances between the feature points are obtained. From one input image or a plurality of input images captured at the same time, a spatial distribution of likelihoods of the reliability of the positions of the feature points is acquired. Using the spatial distribution of likelihoods, one or a plurality of feature point candidate positions which correspond to each of the feature points are acquired. An optimization calculation is carried out based on inverse kinematics using the feature point candidate positions and the poly-articular structure of the subject. In this way, articulation angles of the subject are acquired, and a forward kinematic calculation is carried out using the articulation angles to acquire the positions of the feature points including the articulations of the subject.","['G06V20/64', 'G06T7/73', 'G06V10/242', 'G06V40/103', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/30196']"
CN108960230B,Lightweight target recognition method and device based on rotating rectangular frame,"The invention belongs to the technical field of image analysis, and particularly provides a light target identification method and device based on a rotation region. The method aims to solve the problems that in the prior art, a target identification algorithm is high in complexity and is difficult to identify a plurality of angle targets. The invention provides a light target identification method based on a rotating rectangular frame, which comprises the step of carrying out target identification on an input image based on a pre-constructed target identification network model to obtain a target category of the input image. The target recognition network model is constructed based on a convolutional neural network and comprises a target extraction module and a target recognition module. The invention reduces the network parameters and the algorithm complexity by merging and compressing the prior convolutional neural network.","['G06V10/25', 'G06F18/214', 'G06F18/24']"
US8892495B2,Adaptive pattern recognition based controller apparatus and method and human-interface therefore,"A system and method of predicting items likely to appeal to a user, based on data received from a remote site. One or more local systems are provided, along with a remote system, said local systems communicating with said remote system over a network connection. Each local system maintains a set of characterized items. A local processor predicts an appeal of an item to a user based on the comparison with the set of characterized items with, e.g., user preferences. The user may interact through graphical user interface. At least one user-preference predictive algorithm may be employed to present items predicted to appeal to the user.","['F24F11/0034', 'G06N7/06', 'F24F11/30', 'F24F11/62', 'G06F7/023', 'G06N20/00', 'G06N5/048', 'F24F2120/10', 'G05B2219/2642']"
US20220187841A1,Method of lightweight simultaneous localization and mapping performed on a real-time computing and battery operated wheeled device,"Some aspects include a method for operating a wheeled device, including: capturing, by a primary sensor coupled to the wheeled device, primary sensor data indicative of a plurality of radial distances to objects; transforming, by a processor of the wheeled device, the plurality of radial distances from a perspective of the primary sensor to a perspective of the wheeled device; generating, by the processor, a partial map of visible areas in real-time at a first position of the wheeled device based on the primary sensor data and some secondary sensor data, wherein: the partial map is a bird's eye view; and the processor iteratively completes a full map of the environment based on new sensor data captured by sensors as the wheeled device performs work within the environment and new areas become visible to the sensors; and executing, by the wheeled device, a movement path to a second position.","['G05D1/0242', 'G01C21/12', 'G05D1/0238', 'G05D1/0272', 'G05D1/0274', 'G05D1/246', 'G05D1/43', 'G05D2111/14']"
US12193434B2,Agricultural treatment control device,"The invention relates to a collaborative agricultural field processing control device intended to be mounted on an agricultural machine (1), composed of a set of detectors (2) for weeds or leaf symptoms of deficiencies or diseases collaborating in the decision to control the treatment devices (3) of the agricultural field.","['A01M7/0089', 'A01B79/005', 'A01M21/00', 'A01M21/043', 'G06V20/56', 'A01B69/001', 'A01M21/02', 'A01M21/046']"
CN112182412B,"Method, computing device, and computer storage medium for recommending physical examination items","The present disclosure relates to a method, computing device, and computer storage medium for recommending physical examination items. The method comprises the following steps: determining a plurality of target risk disease data in historical disease data with user attributes meeting predetermined conditions; generating triple data of a knowledge graph model based on the plurality of target risk disease data, the plurality of physical examination item data, and the plurality of user attributes; predicting the recommendation probability of the recommended physical examination item of the current user through a neural network model based on the acquired user data of the current user and the abnormal physical examination item data in the physical examination report, wherein the neural network model and the knowledge map model share an interactive compression unit; determining a plurality of target recommended physical examination items of the current user based on the recommendation probability; and querying a predetermined database based on the target recommended physical examination items to determine the matched target recommended physical examination items. The method and the system can avoid consuming a large amount of calculation and storage resources, and can quickly and accurately recommend the matched physical examination items to the user.","['G06F16/9535', 'G06F16/367', 'G06F16/9536', 'G16H20/00', 'G16H50/30']"
US11568545B2,Compressed content object and action detection,"Various embodiments of a framework which allow, as an alternative to resource-taxing decompression, efficient computation of feature maps using a compressed content data subset, such as video, by exploiting the motion information, such as a motion vector, present in the compressed video. This framework allows frame-specific object recognition and action detection algorithms to be applied to compressed video and other media files by executing only on I-frames in a Group of Pictures and linearly interpolating the results. Training and machine learning increases recognition accuracy. Yielding significant computational gains, this approach accelerates frame-wise feature extraction I-frame/P-frame/P-frame videos as well as I-frame/P-frame/B-frame videos. The present techniques may also be used for segmentation to identify and label respective regions for objects in a video.","['G06T7/20', 'G06F16/7867', 'G06F16/951', 'G06F3/04812', 'G06F3/0482', 'G06T7/174', 'G06T7/246', 'G06Q30/0643', 'G06T2207/20084']"
US11763141B2,Neural processing unit (NPU) direct memory access (NDMA) memory bandwidth optimization,A neural processing unit (NPU) is described. The NPU includes an NPU direct memory access (NDMA) core. The NDMA core includes a read engine having a read buffer. The NDMA core also includes a write engine having a write buffer. The NPU also includes a controller. The controller is configured to direct the NDMA core to perform hardware memory bandwidth optimization for reading/writing NDMA data in the read buffer and/or NDMA data in the write buffer. The NDMA core is also configured to transparently combine NDMA transaction requests for a data stripe to increase local access to available tensors in artificial neural networks.,"['G06N3/063', 'G06F13/28', 'G06F15/7825', 'G06N3/045', 'G06N3/084']"
US12282696B2,Method and system for semantic appearance transfer using splicing ViT features,"Using a pre-trained and fixed Vision Transformer (ViT) model as an external semantic prior, a generator is trained given only a single structure/appearance image pair as input. Given two input images, a source structure image and a target appearance image, a new image is generated by the generator in which the structure of the source image is preserved, while the visual appearance of the target image is transferred in a semantically aware manner, so that objects in the structure image are “painted” with the visual appearance of semantically related objects in the appearance image. A self-supervised, pre-trained ViT model, such as a DINO-VIT model, is leveraged as an external semantic prior, allowing for training of the generator only on a single input image pair, without any additional information (e.g., segmentation/correspondences), and without adversarial training. The method may generate high quality results in high resolution (e.g., HD).","['G06V10/82', 'G06F3/14', 'G06F18/2415', 'G06T7/11', 'G06T7/143', 'G06V10/422', 'G06V10/54', 'G06V10/56', 'G06V10/761', 'G06V20/70', 'G06T2207/20084']"
EP4242926A1,Systems and methods for securing artificial intelligence systems for edge computing systems,"Aspects of the present disclosure provide systems, methods, and computer-readable storage media that support security-aware compression of machine learning (ML) and/or artificial intelligence (AI) models, such as for use by edge computing systems. Aspects described herein leverage cybersecurity threat models, particularly models of ML/AI-based threats, during iterative pruning to improve security of compressed ML models. To illustrate, iterative pruning may be performed on a pre-trained ML model until stop criteria are satisfied. This iterative pruning may include pruning an input ML model based on pruning heuristic(s) to generate a candidate ML model, testing the candidate ML model based on attack model(s) to generate risk assessment metrics, and updating the heuristic(s) based on the risk assessment metrics. If the risk assessment metrics fail to satisfy the stop criteria, the candidate ML model may be provided as input to a next iteration of the iterative pruning.","['G06F21/577', 'G06N3/082', 'G06N3/0495', 'G06N3/094', 'H04L63/08', 'G06N3/048']"
US12235659B2,Obstacle recognition method for autonomous robots,"A method for operating a robot, including: capturing images of a workspace; capturing data indicative of movement of the robot; capturing LIDAR data as the robot moves within the workspace; generating a map of the workspace based on the LIDAR data; actuating the robot to drive; discriminating between an object on a floor surface along a path of the robot and the floor surface based on the captured images; actuating the robot to drive until determining all areas of the workspace are discovered and included in the map; and executing a cleaning function.","['G05D1/617', 'A47L9/0477', 'A47L11/4011', 'A47L11/4061', 'A47L11/4063', 'A47L9/28', 'A47L9/2826', 'A47L9/2847', 'A47L9/2852', 'A47L9/2857', 'A47L9/2873', 'A47L9/2894', 'A47L9/30', 'B25J9/1676', 'B25J9/1697', 'G01S17/87', 'G05D1/242', 'G05D1/2435', 'G05D1/245', 'G05D1/2464', 'G05D1/249', 'G05D1/622', 'G05D1/644', 'G05D1/6485', 'G05D1/661', 'G06V20/58', 'G06V40/28', 'A47L2201/02', 'A47L2201/022', 'A47L2201/024', 'A47L2201/028', 'A47L2201/04', 'A47L2201/06', 'G01S17/42', 'G01S17/89', 'G01S17/931', 'G01S7/4804', 'G05D2105/10', 'G05D2105/87', 'G05D2109/10', 'G05D2111/17', 'G05D2111/54', 'G06V10/82']"
US11927965B2,Obstacle recognition method for autonomous robots,"Provided is a method for operating a robot, including: capturing images of a workspace; capturing movement data indicative of movement of the robot; capturing LIDAR data as the robot performs work within the workspace; comparing at least one object from the captured images to objects in an object dictionary; identifying a class to which the at least one object belongs; generating a first iteration of a map of the workspace based on the LIDAR data; generating additional iterations of the map based on newly captured LIDAR data and newly captured movement data; actuating the robot to drive along a trajectory that follows along a planned path by providing pulses to one or more electric motors of wheels of the robot; and localizing the robot within an iteration of the map by estimating a position of the robot based on the movement data, slippage, and sensor errors.","['G05D1/617', 'A47L9/0477', 'G05D1/0214', 'A01D34/008', 'A47L11/4011', 'A47L11/4013', 'A47L11/4061', 'A47L11/4063', 'A47L9/28', 'A47L9/2826', 'A47L9/2847', 'A47L9/2852', 'A47L9/2857', 'A47L9/2873', 'A47L9/2894', 'A47L9/30', 'B25J9/1676', 'B25J9/1697', 'G05D1/0044', 'G05D1/0219', 'G05D1/0246', 'G05D1/0248', 'G05D1/249', 'G06F3/011', 'G06F3/013', 'G06F3/017', 'G06F3/0304', 'G06F3/04845', 'G06F3/04847', 'G06F3/04883', 'A47L2201/022', 'A47L2201/024', 'A47L2201/028', 'A47L2201/04', 'A47L2201/06', 'G06F2203/012', 'G06F2203/04806', 'G06F2203/04808']"
CN110383288B,Face recognition method and device and electronic equipment,"A face recognition method, device and electronic equipment can improve the safety of face recognition. The face recognition method comprises the following steps: acquiring a depth image of an identification target; and carrying out face anti-counterfeiting judgment based on the depth image to determine whether the recognition target is a three-dimensional face structure, wherein the face anti-counterfeiting judgment result is used for face recognition.","['G06N3/045', 'G06V20/64', 'G06V40/161', 'G06V40/168', 'G06V40/172']"
US11397133B2,"Misfire detection device for internal combustion engine, misfire detection system for internal combustion engine, data analysis device, and controller for internal combustion engine",A misfire detection device for an internal combustion engine is provided. A mapping takes time series data of instantaneous speed parameters as inputs. Each instantaneous speed parameter corresponds to one of a plurality of successive second intervals in a first interval. The instantaneous speed parameters correspond to the rotational speed of the crankshaft. The first interval is a rotational angular interval of the crankshaft in which compression top dead center occurs. The second interval is smaller than an interval between compression top dead center positions. The mapping outputs a probability that a misfire has occurred in at least one cylinder that reaches compression top dead center in the first interval. The mapping data defining the mapping has been learned by machine learning.,"['F02B77/08', 'F02D41/1497', 'F02D13/0234', 'F02D37/02', 'F02D41/0002', 'F02D41/008', 'F02D41/0097', 'F02D41/1405', 'F02D41/1498', 'F02D41/22', 'F02D41/2438', 'F02D41/2451', 'F02D41/30', 'F02D9/00', 'F02P5/1512', 'G01L3/00', 'G01M15/06', 'G01M15/11', 'G06N3/048', 'F02D2041/001', 'F02D2041/228', 'F02D2200/0411', 'F02D2200/1002', 'F02D2200/1004', 'F02D2200/101', 'F02D2200/1015', 'F02D2200/702', 'F02P5/152', 'G06N3/08']"
US20200371491A1,Determining Operating State from Complex Sensor Data,"A method of detecting an operating state of a process, system or machine based on sensor signals from a plurality of sensors is disclosed. The method comprises receiving sensor data, the sensor data based on sensor signals from the plurality of sensors and providing the sensor data as input to a neural network. The neural network comprises an encoder sub-network arranged to receive the sensor data as input and to generate a context vector based on the sensor data; and a decoder sub-network arranged to receive the context vector as input and to regenerate sensor data corresponding to at least a subset of the sensors based on the context vector. The method comprises comparing the context vector to at least one context vector classification; detecting an operating state in dependence on the comparison; and outputting a notification indicating the detected operating state.","['G05B19/406', 'G05B13/027', 'G06N3/045', 'G05B13/04', 'G06N3/044', 'G06N3/08', 'G06N3/084', 'G06N3/10', 'G07C3/00', 'G05B2219/31449', 'G05B23/0221']"
US11112791B2,Selective compression of image data during teleoperation of a vehicle,"Techniques are described for compressing image data for transmission to a computer system of a remote operator controlling a vehicle. A visual representation of a surrounding environment is generated from one or more images captured at the vehicle. One or more regions of interest in the visual representation are identified based at least on information received from the computer system of the remote operator, the information indicating a direction or area of focus of the remote operator. Regions of interest can be compressed to a lesser extent than regions located outside the regions of interest. The compressed visual representation is transmitted to the computer system for decompression and, ultimately, display on one or more display devices viewed by the remote operator.","['G05D1/0038', 'H04N19/167', 'G05D1/0022', 'H04N19/115', 'H04N19/164', 'H04N19/17']"
US11798131B2,Method for processing image for improving the quality of the image and apparatus for performing the same,"A method of processing an image for improving image quality is provided. The method includes inputting an image into a first artificial neural network as an input variable to create a feature map and inputting an image into a second artificial neural network as an input variable to create an estimated class probability distribution map for each of frequency channels. Further, the method may comprise determining a class for each of the frequency channels on the basis of a probability distribution included in the estimated class probability distribution map, creating an estimated class map that includes a determined class, converting the estimated class map into an estimated frequency map, combining the estimated frequency map with the feature map to create a combined feature map, and inputting the combined feature map into a third artificial neural network as an input variable to create an output image.","['G06T5/00', 'G06T5/73', 'G06T3/4046', 'G06N3/045', 'G06N3/08', 'G06T3/16', 'G06T5/003', 'G06T5/10', 'G06T5/20', 'G06T5/60', 'G06T2207/20081', 'G06T2207/20084']"
US10915816B2,System and method of executing neural networks,"A system and method of inferring a neural network (NN) on one or more target computing devices. The NN may include a plurality of layers, where at least one layer includes one or more kernels. Embodiments may include: receiving a data structure representing the NN; analyzing the data structure to produce one or more tasks, where each task may include computations pertaining to a kernel of the NN; selecting a sparse version of at least one kernel and replacing the at least one kernel with the sparse version; and compiling the one or more tasks to produce one or more respective tensor columns, The one or more tensor columns are adapted to fit in respective one or more cache memories of the one or more target computing devices, and include task instruction code that represents at least one computation of the kernel of the NN.","['G06N3/082', 'G06N3/08', 'G06F12/0875', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06F2212/1044', 'G06F2212/401', 'G06F2212/452', 'G06F2212/454']"
CN117807425B,Intelligent data analysis method and system,"The invention discloses an intelligent data analysis method and system in the technical field of data mining, and the method comprises the following steps: based on historical data of a database, a cyclic neural network and a long-short-term memory network method are adopted to analyze the historical data flow mode, and a time sequence analysis technology is utilized to predict future data flow trend so as to generate a data fluidity prediction model. In the invention, in the aspect of long-term prediction of data fluidity and complex pattern recognition, the accuracy of prediction is obviously improved by combining a cyclic neural network and a long-term and short-term memory network method. In the data environment with high variability and dynamic change, the prediction result is more accurate, and the complex decision process can be better supported. In the aspect of data storage optimization, the implementation of the invention can carry out high-efficiency dynamic optimization according to the access mode of data and storage resources, thereby improving the utilization efficiency of the storage medium and the performance of overall data processing.","['G06F18/213', 'G06F18/24', 'G06F21/604', 'G06N20/00', 'G06N3/0442', 'G06N3/092']"
US11436378B2,Block-based compression,"A method includes compressing data to generate compressed data having a first block size corresponding to a block-size requirement of a client device. The method further includes encrypting the compressed data to generate an encrypted data packet. The method further includes adding, by a processing device, a padding bit pattern to the encrypted data packet to generate a data block for storage, the data block having a second block size determined by a buffer size of a storage array.","['G06F21/78', 'G06F21/602', 'G06F21/606', 'G06F21/64', 'G06F3/0608', 'G06F3/0623', 'G06F3/064', 'G06F3/0661', 'G06F3/0664', 'G06F3/067', 'G06F3/0673', 'G06F3/0688', 'H04L63/0428', 'H04L67/1097', 'H04L69/04', 'H04L9/3239', 'H04L9/50', 'H04L2209/38']"
US20220121917A1,Hardware accelerator template and design framework for implementing recurrent neural networks,"Hardware accelerator templates and design frameworks for implementing recurrent neural networks (RNNs) and variants thereof are described. A design framework module obtains a flow graph for an RNN algorithm. The flow graph identifies operations to be performed to implement the RNN algorithm and further identifies data dependencies between ones of the operations. The operations include matrix operations and vector operations. The design framework module maps the operations of the flow graph to an accelerator hardware template, yielding an accelerator instance comprising register transfer language code that describes how one or more matrix processing units and one or more vector processing units are to be arranged to perform the RNN algorithm. At least one of the one or more MPUs, as part of implementing the RNN algorithm, is to directly provide or directly receive a value from one of the one or more VPUs.","['G06N3/063', 'G06N3/044', 'G06N3/0445']"
US20210081804A1,Tensor network machine learning system,"The invention is machine learning based method of, or system configured for, identifying candidate, small, drug-like molecules, in which a tensor network representation of molecular quantum states of a dataset of small, drug-like molecules is provided as an input to a machine learning system, such as a neural network system. The machine learning method or system may is itself configured as a tensor network. A training dataset may be used to train the machine learning system, and the training dataset is a tensor network representation of the molecular quantum states of small drug-like molecules.","['G06N3/088', 'G06N10/00', 'G06N3/045', 'G06N3/0454', 'G16B15/30', 'G16B40/30', 'G16B5/20', 'G06N3/044']"
US11521052B2,Hardware and neural architecture co-search,"Hardware and neural architecture co-search may be performed by operations including obtaining a specification of a function and a plurality of hardware design parameters. The hardware design parameters include a memory capacity, a number of computational resources, a communication bandwidth, and a template configuration for performing neural architecture inference. The operations further include determining, for each neural architecture among a plurality of neural architectures, an overall latency of performance of inference of the neural architecture by an accelerator within the hardware design parameters. Each neural architecture having been trained to perform the function with an accuracy. The operations further include selecting, from among the plurality of neural architectures, a neural architecture based on the overall latency and the accuracy.","['G06N3/063', 'G06N3/04', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N7/01']"
US12026845B2,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate augmented images. In at least one embodiment, one or more neural networks are used to modify one or more first objects in an image based at least in part upon a modification to be made to one or more second objects in the image.","['G06T19/20', 'G06T11/60', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06T19/006', 'G06T7/0002', 'G06T7/70', 'G06N3/048', 'G06N3/063', 'G06N5/046', 'G06T2207/20081', 'G06T2207/20084']"
US12288163B2,Training method for quantizing the weights and inputs of a neural network,"A method and processing unit for training a neural network to selectively quantize weights of a filter of the neural network as either binary weights or ternary weights. A plurality of training iterations a performed that each comprise: quantizing a set of real-valued weights of a filter to generate a corresponding set of quantized weights; generating an output feature tensor based on matrix multiplication of an input feature tensor and the set of quantized weights; computing, based on the output feature tensor, a loss based on a regularization function that is configured to move the loss towards a minimum value when either: (i) the quantized weights move towards binary weights, or (ii) the quantized weights move towards a ternary weights; computing a gradient with an objective of minimizing the loss; updating the real-valued weights based on the computed gradient. When the training iterations are complete, a set of weights quantized from the updated real-valued weights is stored as either a set of binary weights or a set of ternary weights.","['G06N3/084', 'G06N3/045', 'G06N3/048', 'G06N3/063']"
US11195096B2,Facilitating neural network efficiency,"Techniques that facilitate improving an efficiency of a neural network are described. In one embodiment, a system is provided that comprises a memory that stores computer-executable components and a processor that executes computer-executable components stored in the memory. In one implementation, the computer-executable components comprise an initialization component that selects an initial value of an output limit, wherein the output limit indicates a range for an output of an activation function of a neural network. The computer-executable components further comprise a training component that modifies the initial value of the output limit during training to a second value of the output limit, the second value of the output limit being provided as a parameter to the activation function. The computer-executable components further comprise an activation function component that determines the output of the activation function based on the second value of the output limit as the parameter.","['G06N3/084', 'G06N3/04', 'G06N3/048', 'G06N3/063']"
US20220383078A1,Data processing method and related device,"In a data processing method, a processing device obtains a first neural network model and an available resource state of a terminal device, and determines a second neural network model based on the first neural network model and the available resource state. An appropriate model size is determined based on the available resource state, and a part of the first neural network model is selected, based on the determined model size, as the second neural network model on which data processing is to be performed.","['G06N3/06', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/082', 'G06N3/09', 'G06N3/096', 'G06N3/10', 'G06N5/022', 'G06N3/0495', 'G06N5/04']"
US10515302B2,Neural network unit with mixed data and weight size computation capability,"In a neural network unit, each neural processing unit (NPU) of an array of N NPUs receives respective first and second upper and lower bytes of 2N bytes received from first and second RAMs. In a first mode, each NPU sign-extends the first upper byte to form a first 16-bit word and performs an arithmetic operation on the first 16-bit word and a second 16-bit word formed by the second upper and lower bytes. In a second mode, each NPU sign-extends the first lower byte to form a third 16-bit word and performs the arithmetic operation on the third 16-bit word and the second 16-bit word formed by the second upper and lower bytes. In a third mode, each NPU performs the arithmetic operation on a fourth 16-bit word formed by the first upper and lower bytes and the second 16-bit word formed by the second upper and lower bytes.","['G06N3/063', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454']"
US11544606B2,Machine learning based video compression,"Systems and methods for compressing target content are disclosed. In one embodiment, a system may include non-transient electronic storage and one or more physical computer processors. The one or more physical computer processors may be configured by machine-readable instructions to obtain the target content comprising one or more frames, wherein a given frame comprises one or more features. The one or more physical computer processors may be configured by machine-readable instructions to obtain a conditioned network. The one or more physical computer processors may be configured by machine-readable instructions to generate decoded target content by applying the conditioned network to the target content.","['H04N19/44', 'G06T9/002', 'G06N7/005', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N7/01', 'H04N19/124', 'H04N19/42', 'H04N19/46', 'H04N19/503', 'H04N19/91']"
US11216720B2,Neural network unit that manages power consumption based on memory accesses per period,"An apparatus includes a first memory, processing units that access the first memory, and a counter that, for each period of a sequence of periods, holds an indication of accesses to the first memory during the period; and control logic that, for each period of the sequence of periods, monitors the indication to determine whether it exceeds the threshold and, if so, stalls the processing units from accessing the first memory for a remaining portion of the period.","['G06N3/0481', 'G06N3/048', 'G06F9/3001', 'G06F12/0831', 'G06F9/30032', 'G06F9/30076', 'G06F9/30145', 'G06F9/3826', 'G06F9/3887', 'G06F9/3895', 'G06F9/5094', 'G06F9/544', 'G06F9/546', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/08', 'G06N3/082', 'G06N3/10', 'Y02D10/00']"
US10353862B2,Neural network unit that performs stochastic rounding,A neural network unit includes a random bit source that generates random bits and a plurality of neural processing units (NPU). Each NPU includes an accumulator into which the NPU accumulates a plurality of products as an accumulated value and a rounder that receives the random bits from the random bit source and stochastically rounds the accumulated value based on a random bit received from the random bit source.,"['G06F15/82', 'G06F1/10', 'G06F7/483', 'G06F7/49947', 'G06F9/3001', 'G06F9/30029', 'G06F9/30032', 'G06F9/3004', 'G06F9/30098', 'G06F9/30101', 'G06F9/30189', 'G06F9/321', 'G06F9/38', 'G06F9/3836', 'G06F9/3854', 'G06F9/3867', 'G06F9/3877', 'G06F9/3893', 'G06F9/44505', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/0635', 'G06N3/065', 'G06N3/08', 'G06N3/088']"
US11941721B2,Using watermark information and weight information to train an embedded neural network model,"A method and an apparatus for embedding watermark information are disclosed in the present disclosure. The method trains an embedded neural network model using weight information of a target neural network model and target watermark information that is to be embedded into the target neural network model, updates the weight information of the target neural network model according to target watermark embedded data provided by the embedded neural network model, and obtains a target neural network model embedded with the target watermark information. Since the embedded neural network model includes multiple neural network layers, this method increases the complexity of the watermark embedding process, and is able to avoid the problem that watermark information of existing neural network models has poor robustness to watermarking attacks such as overwriting attacks and model compression.","['G06F21/16', 'G06T1/0028', 'G06N3/045', 'G06N3/08', 'G06T1/005', 'G06T2201/0065', 'G06T2207/20084', 'G06T2207/20221', 'G06T5/50']"
US20220295116A1,Convolutional neural network loop filter based on classifier,Techniques related to convolutional neural network based loop filtering for video coding are discussed and include training a convolutional neural network loop filter for each of multiple classifications into which each region of a reconstructed video frame corresponding to input video are classified and selecting a subset of the trained convolutional neural network loop filter for use in coding the input video.,"['H04N19/117', 'H04N19/82', 'H04N19/124', 'H04N19/136', 'H04N19/176', 'H04N19/182', 'H04N19/186', 'H04N19/70', 'G06V10/454', 'H04N19/31', 'H04N19/86']"
US11887001B2,Method and apparatus for reducing the parameter density of a deep neural network (DNN),An apparatus and method are described for reducing the parameter density of a deep neural network (DNN). A layer-wise pruning module to prune a specified set of parameters from each layer of a reference dense neural network model to generate a second neural network model having a relatively higher sparsity rate than the reference neural network model; a retraining module to retrain the second neural network model in accordance with a set of training data to generate a retrained second neural network model; and the retraining module to output the retrained second neural network model as a final neural network model if a target sparsity rate has been reached or to provide the retrained second neural network model to the layer-wise pruning model for additional pruning if the target sparsity rate has not been reached.,"['G06N3/082', 'G06F17/16', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06N3/044']"
US20220366258A1,"Neural network, computer readable medium, and methods including a method for training a neural network","The present disclosure provides an artificial neural network communicatively-coupled to at least one computer having one or more processors, including a plurality of neurons arranged in layers. The artificial neural network is arranged to receive a new neuron into a layer of the artificial neural network during training; the new neuron being added to the neural network when no other neuron in that layer for a selected output can learn a relationship associated with an input vector of a data set being learnt. The new neuron is updated with both the relationship which could not be learnt by any other neuron in that layer and a modified data set from a last trained neuron in that layer that contributes to the selected output of the neural network, wherein the modified data set is formed by copying all learnt relationships from the last trained neuron into the new neuron and modifying the copied relationship based upon the relationship which could not be learnt by any other neuron in that layer; and, one or more output neurons are updated to accept input from the new neuron. Methods and computer-readable media are also disclosed.","['G06T1/20', 'G06N3/082', 'G05B13/00', 'G05B13/027', 'G06J1/00', 'G06N3/048', 'G06N3/0481', 'G06N3/088', 'G06T2207/20081', 'G06T2207/20084']"
US20190156214A1,Systems and methods for exchange of data in distributed training of machine learning algorithms,"Systems and methods may make exchanging data in a neural network (NN) during training more efficient. Exchanging weights among a number of processors training a NN across iterations may include sorting generated weights, compressing the sorted weights, and transmitting the compressed sorted weights. On each Kth iteration a sort order of the sorted weights may be created and transmitted. Exchanging weights among processors training a NN may include executing a forward pass to produce a set of loss values for processors, transmitting loss values to other processors, and at each of the processors, performing backpropagation on at least one layer of the NN using loss values received from other processors.","['G06V10/82', 'G06F18/217', 'G06F18/24133', 'G06N20/10', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N5/046', 'G06V20/00', 'G06V30/1916', 'G06V30/19173']"
US12223734B2,Systems and methods for training machine-learned models with deviating intermediate representations,Systems and methods for vehicle-to-vehicle communications are provided. An adverse system can obtain sensor data representative of an environment proximate to a targeted system. The adverse system can generate an intermediate representation of the environment and a representation deviation for the intermediate representation. The representation deviation can be designed to disrupt a machine-learned model associated with the target system. The adverse system can communicate the intermediate representation modified by the representation deviation to the target system. The target system can train the machine-learned model associated with the target system to detect the modified intermediate representation. Detected modified intermediate representations can be discarded before disrupting the machine-learned model.,"['G06V20/56', 'G01S17/931', 'G05D1/0088', 'G05D1/0221', 'G05D1/81', 'G06F18/2163', 'G06F18/217', 'G06F18/24', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/764', 'G06V10/82', 'G01S7/003', 'G06N3/044', 'G08G1/096791', 'G08G1/162']"
US10380481B2,Neural network unit that performs concurrent LSTM cell calculations,"An output buffer holds N words arranged as N/J mutually exclusive output buffer word groups (OBWG) of J words each of the N words. N processing units (PU) are arranged as N/J mutually exclusive PU groups. Each PU group has an associated OBWG. Each PU includes an accumulator and an arithmetic unit that performs operations on inputs, which include the accumulator output, to generate a first result for accumulation into the accumulator. Activation function units selectively perform an activation function on the accumulator outputs to generate results for provision to the N output buffer words. For each PU group, four of the J PUs and at least one of the activation function units compute an input gate, a forget gate, an output gate and a candidate state of a Long Short Term Memory (LSTM) cell, respectively, for writing to respective first, second, third and fourth words of the associated OBWG.","['G06N3/063', 'G06F7/483', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06F9/00', 'G06F9/3001']"
US20230081715A1,Neuromorphic Analog Signal Processor for Predictive Maintenance of Machines,"Systems, methods, and devices are provided for predictive maintenance of machines. An example apparatus includes a vibration sensor configured to sense vibrations of a vibration source and an analog circuit. The analog circuit comprises a plurality of operational amplifiers and a plurality of resistors. The analog circuit is coupled to the vibration sensor and configured to: receive an analog signal from the vibration sensor; and compute an output based on the analog signal, by performing a portion of a trained neural network.","['G06N3/0635', 'A61B5/1123', 'A61B5/0022', 'A61B5/02055', 'A61B5/7267', 'G06F18/24147', 'G06N3/044', 'G06N3/0442', 'G06N3/0445', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/065', 'G06V10/764', 'G06V10/82', 'G06V40/20', 'A61B2562/0204', 'A61B2562/0219', 'A61B5/02416', 'A61B5/0531', 'A61B5/1118', 'A61B5/165', 'G06N20/00']"
US11797855B2,System and method of accelerating execution of a neural network,"A system and method of accelerating execution of a NN model, by at least one processor may include: receiving a first matrix A, representing elements of a kernel K of the NN model and a second matrix B, representing elements of an input I to kernel K; producing from matrix A, a group-sparse matrix A′, comprising G tensors of elements. The number of elements in each tensor is defined by, or equal to a number of entries in each index of an input tensor register used for a specific Single Instruction Multiple Data (SIMD) tensor operation, and all elements of A′ outside said G tensors are null. The system and method may further include executing kernel K on input I, by performing at least one computation of the SIMD tensor operation, having as operands elements of a tensor of the G tensors and corresponding elements of the B matrix.","['G06N3/082', 'G06F17/16', 'G06F9/5027', 'G06N20/10', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
US10902651B2,Systems and methods for magnetic resonance image reconstruction,The disclosure relates to systems and methods for magnetic resonance imaging (MRI). A method may include obtaining k-space data associated with MR signals acquired by an MR scanner. The k-space data may corresponding to a first sampling rate. The method may also include generating one or more estimated images based on the k-space data and a target neural network model. The one or more estimated images may correspond to a second sampling rate that exceeds the first sampling rate. The method may further include determining one or more target images based on the one or more estimated images and the k-space data using a compressed sensing model. The compressed sensing model may be constructed based on the one or more estimated images.,"['G06T11/006', 'G06T11/003', 'G01R33/4818', 'G01R33/5608', 'G01R33/561', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T11/005', 'G06T5/10', 'G06N3/047', 'G06T2207/10088', 'G06T2207/20056', 'G06T2207/20081', 'G06T2207/20084', 'G06T2211/416', 'G06T2211/424']"
US20230161816A1,Short-term and long-term memory on an edge device,"Systems and methods are provided for distributed video storage and search over edge computing devices having a short-term memory and a long-term memory. The method may comprise caching a first portion of data on a first device. The method may further comprise determining, at a second device, whether the first device has the first portion of data. The determining may be based on whether the first piece of data satisfies a specified criterion. The method may further comprise sending the data, or a portion of the data, and/or a representation of the data from the first device to a third device.","['B60W40/09', 'G06F16/00', 'G06F16/71', 'G06F16/73', 'G06F16/7837', 'G06F16/7844', 'G06V20/48', 'G06V20/597', 'G06N20/00']"
US11188618B2,Sparse matrix multiplication acceleration mechanism,An apparatus to facilitate acceleration of matrix multiplication operations. The apparatus comprises a systolic array including matrix multiplication hardware to perform multiply-add operations on received matrix data comprising data from a plurality of input matrices and sparse matrix acceleration hardware to detect zero values in the matrix data and perform one or more optimizations on the matrix data to reduce multiply-add operations to be performed by the matrix multiplication hardware.,"['G06T1/20', 'G06F13/1673', 'G06F17/16', 'G06F5/06', 'G06F7/4876', 'G06F9/3001', 'G06F9/30036', 'G06F2207/3892', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08']"
US9501724B1,Font recognition and font similarity learning using a deep neural network,"A convolutional neural network (CNN) is trained for font recognition and font similarity learning. In a training phase, text images with font labels are synthesized by introducing variances to minimize the gap between the training images and real-world text images. Training images are generated and input into the CNN. The output is fed into an N-way softmax function dependent on the number of fonts the CNN is being trained on, producing a distribution of classified text images over N class labels. In a testing phase, each test image is normalized in height and squeezed in aspect ratio resulting in a plurality of test patches. The CNN averages the probabilities of each test patch belonging to a set of fonts to obtain a classification. Feature representations may be extracted and utilized to define font similarity between fonts, which may be utilized in font suggestion, font browsing, or font recognition applications.","['G06K9/66', 'G06V30/245', 'G06F18/28', 'G06K9/627', 'G06K9/6828', 'G06N3/045', 'G06N3/08', 'G06T3/40', 'G06V30/1914', 'G06N3/048', 'G06T2210/22']"
EP3745318A1,Training a neural network using selective weight updates,"Training one or more neural networks using selective updates to weight information of the one or more neural networks. In at least one embodiment, one or more neural networks are trained by at least updating one or more portions of weight information of the one or more neural networks based, at least in part, on metadata that indicate how recently the one or more portions of weight information has been updated.","['G06F18/23213', 'G06N3/06', 'G06N3/084', 'G06N3/086', 'G06F18/24', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06T2207/20081', 'G06T2207/20084', 'G10L15/16']"
US20220101113A1,Knowledge discovery using a neural network,"Apparatuses, systems, and techniques to identify one or more relationships among one or more words using one or more transformer-based language neural networks trained using domain-specific data.","['G06N5/04', 'G06F40/284', 'G06F40/30', 'G06F18/214', 'G06F40/263', 'G06F40/40', 'G06K9/6256', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/061', 'G06N3/08', 'G06N3/084', 'G06N5/027', 'G16B40/20', 'G16B40/30', 'G16H50/70', 'G16H70/40', 'G06F40/169', 'G06N3/063', 'G16H10/20']"
US10789691B2,Information processing apparatus and information processing method,"This information processing apparatus includes: a mechanical learning module that is a multiplier-accumulator circuit including a plurality of deep-learning neural network blocks hierarchized and synthesizes an algorithm having a filter characteristic for image processing by mechanical learning, the image processing being a target; a debug module that analyzes a digital filter characteristic in each of the deep-learning neural network blocks on the basis of input and output data in the mechanical learning module; and a grading module that develops an output image from an input image by performing gain control on the basis of a result of analysis of the debug module.","['G06F18/2413', 'G06K9/00973', 'G06K9/46', 'G06K9/4628', 'G06K9/627', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/0635', 'G06N3/065', 'G06N3/088', 'G06T5/00', 'G06T5/20', 'G06T5/60', 'G06V10/454', 'G06V10/764', 'G06V10/94', 'G06T2207/20081', 'G06T2207/20084']"
US10810723B2,System and method for single image object density estimation,"A method for object density monitoring includes receiving, by a processing server, an input image captured by an image sensor. The method further includes providing an annotated dataset with a target object to be identified in the input image, and providing, by the processing server as output, an object density map generated from the input image. The processing server provides the object density map by using a deep neural network having one or more pairs of a compression layer and a decompression layer connected by gated shortcuts.","['G06V10/82', 'G06F17/11', 'G06F18/24', 'G06K9/00771', 'G06K9/3233', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/084', 'G06T7/0002', 'G06V10/764', 'G06V20/52', 'G06T2207/30242']"
US20250181431A1,Accelerated fifth generation (5g) new radio operations,"Apparatuses, systems, and techniques to perform fifth generation (5G) new radio operations. In at least one embodiment, an application programming interface (API) is utilized to perform 5G new radio operations on one or more hardware accelerators through an API call.","['G06F9/54', 'G06F9/547', 'G06F9/545', 'H04M1/724', 'H04W24/08', 'H04W8/005', 'H04W84/042']"
US11630996B1,Spectral detection and localization of radio events with learned convolutional neural features,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training and deploying machine-learned classification of radio frequency (RF) signals. One of the methods includes obtaining input data corresponding to the RF spectrum; segmenting the input data into one or more samples; and for each sample of the one or more samples: obtaining information included in the sample, comparing the information to one or more labeled signal classes that are known to the machine-learning network, using results of the comparison, determining whether the information corresponds to the one or more labeled signal classes, and in response, matching, using an identification policy of a plurality of policies available to the machine-learning network, the information to a class of the one or more labeled signal classes, and providing an output that identifies an information signal corresponding to the class matching the information obtained from the sample.","['G06N3/08', 'H04B1/16', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/048', 'G06N3/088', 'G06N3/09']"
USRE49387E1,Ergonomic man-machine interface incorporating adaptive pattern recognition based control system,"An adaptive interface for a programmable system, for predicting a desired user function, based on user history, as well as machine internal status and context. The apparatus receives an input from the user and other data. A predicted input is presented for confirmation by the user, and the predictive mechanism is updated based on this feedback. Also provided is a pattern recognition system for a multimedia device, wherein a user input is matched to a video stream on a conceptual basis, allowing inexact programming of a multimedia device. The system analyzes a data stream for correspondence with a data pattern for processing and storage. The data stream is subjected to adaptive pattern recognition to extract features of interest to provide a highly compressed representation which may be efficiently processed to determine correspondence. Applications of the interface and system include a VCR, medical device, vehicle control system, audio device, environmental control system, securities trading terminal, and smart house. The system optionally includes an actuator for effecting the environment of operation, allowing closed-loop feedback operation and automated learning.","['G06Q30/02', 'G06V40/103', 'G05B19/42', 'G06F3/00', 'G06F3/011', 'G06F3/0338', 'G06F3/0346', 'G06F3/03547', 'G06F3/0482', 'G06F9/451', 'G06F9/453', 'G06Q10/10', 'G06Q30/0204', 'G06Q30/0261', 'G06V20/41', 'G16H40/67', 'H04L67/535', 'H04N21/25', 'H04N21/252', 'H04N21/422', 'H04N21/42201', 'H04N21/44008', 'H04N21/442', 'H04N21/44222', 'H04N21/44224', 'H04N21/45', 'H04N21/4532', 'H04N21/454', 'H04N21/466', 'H04N21/4666', 'H04N21/47214', 'H04N21/482', 'H04N7/16', 'H04N7/163', 'G06N20/00', 'G06N99/00', 'G16H10/60', 'G16H40/63', 'H04L67/306']"
US10595727B2,Machine learning-based segmentation for cardiac medical imaging,"For heart segmentation in magnetic resonance or other medical imaging, deep learning trains a neural network. The neural network, such as U-net, includes at least one long-short-term memory (LSTM), such as a convolutional LSTM. The LSTM incorporates the temporal characteristics with the spatial to improve accuracy of the segmentation by the machine-learnt network.","['A61B5/0044', 'A61B5/055', 'A61B5/7257', 'A61B5/7267', 'A61B6/032', 'A61B6/507', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T7/0012', 'G06T7/11', 'A61B6/503', 'A61B6/5211', 'G06N3/047', 'G06N3/048', 'G06N3/088', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/10121', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30048', 'G06T2207/30101', 'G16H50/70']"
US11604987B2,Analytic and empirical correction of biased error introduced by approximation methods,"Various embodiments include methods and neural network computing devices implementing the methods, for generating an approximation neural network. Various embodiments may include performing approximation operations on a weights tensor associated with a layer of a neural network to generate an approximation weights tensor, determining an expected output error of the layer in the neural network due to the approximation weights tensor, subtracting the expected output error from a bias parameter of the layer to determine an adjusted bias parameter and substituting the adjusted bias parameter for the bias parameter in the layer. Such operations may be performed for one or more layers in a neural network to produce an approximation version of the neural network for execution on a resource limited processor.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/063']"
US11475540B2,"Electronic device, control method thereof, and system","An electronic device is provided. The electronic device includes: a memory configured to include at least one instruction; and a processor configured to be connected to the memory to control the electronic device, and obtain an output image by upscaling an input image using an artificial intelligence model trained to upscale an image, wherein the processor is configured to control the electronic device to: obtain parameter information of the artificial intelligence model based on pre-processing related information performed on the input image, and upscale the input image using the artificial intelligence model corresponding to the obtained parameter information.","['G06N3/0455', 'H04N19/42', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'G06T9/002', 'H04N19/117', 'H04N19/59', 'H04N21/234', 'H04N21/44', 'H04N7/0127']"
US10880551B2,"Method and apparatus for applying deep learning techniques in video coding, restoration and video quality analysis (VQA)","Video quality analysis may be used in many multimedia transmission and communication applications, such as encoder optimization, stream selection, and/or video reconstruction. An objective VQA metric that accurately reflects the quality of processed video relative to a source unprocessed video may take into account both spatial measures and temporal, motion-based measures when evaluating the processed video. Temporal measures may include differential motion metrics indicating a difference between a frame difference of a plurality of frames of the processed video relative to that of a corresponding plurality of frames of the source video. In addition, neural networks and deep learning techniques can be used to develop additional improved VQA metrics that take into account both spatial and temporal aspects of the processed and unprocessed videos.","['H04N19/154', 'G06N20/10', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06T3/4046', 'G06T5/001', 'G06T7/0002', 'G06T7/254', 'G06T9/002', 'H04N19/103', 'H04N19/107', 'H04N19/124', 'H04N19/172', 'H04N19/174', 'H04N19/176', 'H04N19/19', 'H04N19/567', 'H04N21/23418', 'H04N21/2343', 'H04N21/236', 'G06N3/044', 'G06N5/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30168']"
US10594338B1,Adaptive quantization,"A compression system includes an encoder and a decoder. The encoder can be deployed by a sender system to encode a tensor for transmission to a receiver system, and the decoder can be deployed by the receiver system to decode and reconstruct the encoded tensor. The encoder receives a tensor for compression. The encoder also receives a quantization mask and probability data associated with the tensor. Each element of the tensor is quantized using an alphabet size allocated to that element by the quantization mask data. The encoder compresses the tensor by entropy coding each element using the probability data and alphabet size associated with the element. The decoder receives the quantization mask data, the probability data, and the compressed tensor data. The quantization mask and probabilities are used to entropy decode and subsequently reconstruct the tensor.","['H03M7/3073', 'H03M7/3066', 'G06F17/18', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'H03M7/02', 'H03M7/30', 'H03M7/4043', 'H04N19/124', 'H04N19/132', 'H04N19/167', 'H04N19/91', 'H03M7/4075']"
US11468266B2,Target identification in large image data,"A machine receives a large image having large image dimensions that exceed memory threshold dimensions. The large image includes metadata. The machine adjusts an orientation and a scaling of the large image based on the metadata. The machine divides the large image into a plurality of image tiles, each image tile having tile dimensions smaller than or equal to the memory threshold dimensions. The machine provides the plurality of image tiles to an artificial neural network. The machine identifies, using the artificial neural network, at least a portion of the target in at least one image tile. The machine identifies the target in the large image based on at least the portion of the target being identified in at least one image tile.","['G06K9/6257', 'G06V10/82', 'G06F18/2148', 'G06F18/217', 'G06K9/6262', 'G06V10/242', 'G06V20/00', 'G06V30/19173', 'G06V30/2504', 'G06V2201/07', 'G06V2201/10']"
US11948066B2,Processing sequences using convolutional neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing sequences using convolutional neural networks. One of the methods includes, for each of the time steps: providing a current sequence of audio data as input to a convolutional subnetwork, wherein the current sequence comprises the respective audio sample at each time step that precedes the time step in the output sequence, and wherein the convolutional subnetwork is configured to process the current sequence of audio data to generate an alternative representation for the time step; and providing the alternative representation for the time step as input to an output layer, wherein the output layer is configured to: process the alternative representation to generate an output that defines a score distribution over a plurality of possible audio samples for the time step.","['G06N3/047', 'G06F40/279', 'G06F40/44', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G10L13/04', 'G10L13/086', 'G10L15/16', 'G10L25/30', 'G06F17/18', 'G10H2250/311']"
TWI840316B,Methods and systems for compressing shape data for electronic designs,"Methods for compressing shape data for a set of electronic designs include inputting a set of shape data, where the shape data represents a set of shapes for a device fabrication process. A convolutional autoencoder is used on the set of shape data, the convolutional autoencoder having a pre-determined set of convolution layers including a kernel size and filter size for each convolution layer. The set of shape data is encoded to compress the set of shape data, using the pre-determined set of convolution layers of the convolutional autoencoder, to create a set of encoded shape data. The set of shape data comprises an SEM image, and the encoded set of shape data identifies a mask defect.","['G06T9/002', 'G06F30/398', 'G06N3/0455', 'G06T7/0006', 'G06T9/20']"
CN114565124B,Ship traffic flow prediction method based on improved graph convolution neural network,"The invention discloses a ship traffic flow prediction method based on an improved graph convolution neural network, which comprises a channel network, a ship flow extraction method and a ship traffic flow prediction method. The channel network and ship flow extraction method comprises the steps of firstly adopting a DP compression algorithm to obtain initial ship track feature points, and then adopting a DBSCAN algorithm to perform clustering denoising on the initial track feature points to obtain track feature point clusters. And then carrying out grid division on the research sea area, projecting the extracted track characteristic points into grids, taking the grids containing the characteristic points as nodes in the channel network, and sequentially connecting the nodes according to the ship running track to establish the channel network. And finally, sequentially counting the number of the ships passing through each node in different time periods to obtain the ship traffic flow of each graph node in different moments. The ship traffic flow prediction method is based on ship flow extracted by a channel network, and the ship flow of each node is predicted by adopting a GCN algorithm with multiple-graph convolution improvement.","['G06Q10/04', 'G06N3/045', 'G06Q50/26', 'G08G3/00', 'G08G3/02', 'Y02A10/40']"
CN111461089B,"Face detection method, and training method and device of face detection model","The application discloses a face detection method for protecting user privacy and improving information safety, which can be applied to the field of artificial intelligence, and comprises the following steps: acquiring a face image sequence; acquiring a noise image sequence according to the face image sequence; acquiring a face feature image sequence of a face image sequence through a first feature extraction network of a face detection model; acquiring a noise feature map sequence of the noise image sequence through a second feature extraction network of the face detection model; based on the human face feature map sequence and the noise feature map sequence, obtaining a classification probability value corresponding to the human face image through a full connection layer of a human face detection model; and determining a detection result according to the classification probability value. The application also provides a training method and a device of the face detection model. According to the method and the device, the semantic information of the face image sequence and the noise information of the noise image sequence are concerned at the same time, so that artifacts generated by counterfeiting the face can be effectively excavated, and the accuracy of face detection is improved.","['G06V40/168', 'G06N20/00', 'G06V40/172']"
US11182884B2,Enhanced high-dynamic-range imaging and tone mapping,"The various embodiments of the present disclosure are directed towards methods for tone mapping High-Dynamic-Range (HDR) image data, as well as controlling the brightness of the image encoded by HDR the image data and/or the tone-mapped image data. HDR image is captured. A tone mapping function for the HDR image data is generated. To generate the tone mapping function, control points are dynamically determined based on an analysis of the HDR image data. The tone mapping function is fit to the control points. The tone mapping function is a non-linear function, and is described by a curve in a plane. The shape of the curve is constrained by a line generated from a portion of the control points. The tone mapping function is applied to the HDR image data. A color-compression is applied to the tone mapped image data to generate Standard Dynamic Range or Low Dynamic Range image data.","['G06T5/92', 'G06T5/009', 'H04N23/741', 'H04N9/77', 'G06T2207/10024', 'G06T2207/20208', 'G06T2207/30252']"
US9274036B2,Method and apparatus for characterizing composite materials using an artificial neural network,"This invention relates to a method and apparatus for characterizing composite materials, and in particular, to utilizing an artificial neural network for predicting an impact resistance of a composite material. A method for predicting an impact resistance of a composite material in accordance with the present invention includes the steps of designing an artificial neural network including a plurality of neurons, training the artificial neural network to predict the impact resistance by adjusting an output of the plurality of neurons according to sample data and known results of the sample data, inputting data of the composite material into the artificial neural network, and utilizing the artificial neural network to predict the impact resistance of the composite material.","['G01N3/30', 'G06F17/5018', 'G06F30/23', 'G06N3/084', 'G01N2203/0212', 'G06F2113/26', 'G06F2217/44']"
US11631218B2,Efficient compression of data representing triangular mesh attributes,"Techniques of compressing triangular mesh data involve generating a neighborhood table (i.e., a table) of fixed size that represents a neighborhood of a predicted vertex of a triangle within a triangular mesh for input into a machine-learning (ML) engine. For example, such a neighborhood table as input into a ML engine can output a prediction for a value (e.g., a position) of a vertex. The residual between the prediction and the actual value of the vertex is stored in an array. The data in the array representing the residuals may be compressed and transmitted over a network. Upon receipt by a computer, the array may be decompressed by the computer. Obtaining the actual value involves the receiving computer generating the same neighborhood table, inputting that neighborhood table into the same ML engine to produce the predicted value, and adding the predicted value to the residual from the decompressed file.","['G06T9/002', 'G06T17/20', 'G06T9/001', 'G06T9/004']"
CN111932435B,Optimized computing hardware for machine learning operations,"The application discloses optimized computing hardware for machine learning operations. One embodiment provides a computing device for performing machine learning operations, the computing device comprising: a fetch unit to fetch a single instruction having a plurality of input operands, wherein the plurality of operands have unequal bit lengths, a first input having a first bit length and a second input having a second bit length; a decode unit to decode a single instruction into decoded instructions; an operand length unit to determine a smaller bit length of the first bit length and the second bit length; and a calculation unit for performing a matrix operation on the plurality of input operands to generate an output value having a bit length of smaller bit length.","['G06F9/3888', 'G06N3/084', 'G06T1/20', 'G06F17/16', 'G06F7/5443', 'G06F9/30014', 'G06F9/30036', 'G06F9/3016', 'G06F9/30181', 'G06F9/30192', 'G06F9/3851', 'G06F9/3887', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06F2207/382', 'G06N3/048']"
CN112417289B,Information intelligent recommendation method based on deep clustering,"The invention provides an information intelligent recommendation method based on deep clustering, which is used for respectively coding data with different sources in respective fields to obtain vector representation of the data in the respective fields; constructing a variational self-encoder based on a deep neural network, compressing a given vector to obtain embedded vector representation of multi-source data in a unified vector space, and reconstructing data; constructing a loss function by integrating reconstruction loss, parameter reconstruction constraint and clustering loss, training a variational self-encoder based on a deep neural network, determining the optimal combination of the number of layers, weight and weight of a network model and a clustering center based on the variational self-encoder; and determining the embedded vector representation of the given interesting information based on the trained variational self-encoder, and finishing the intelligent recommendation of the information according to the distance from the embedded vector of the interesting information to each clustering center. The invention improves the accuracy and efficiency of the recommendation of the associated information.","['G06F16/9535', 'G06F16/9536', 'G06F18/23', 'G06N3/045', 'G06N3/08', 'G06Q50/01', 'Y02A10/40']"
US10667725B2,Method for detecting and responding to falls by residents within a facility,"One variation of a method for detecting and responding to falls by residents within a facility includes: at a wearable device worn by a resident, writing sensor data from a sensor integrated into the wearable device to a buffer, inputting sensor data into a compressed fall detection model—defining a compressed form of a complete fall detection model and stored locally on the wearable device—to detect a fall event at a first time, and transmitting a corpus of sensor data from the buffer and a cue for confirmation of the fall event to a local wireless hub in response to detecting the fall event; and, remotely from the wearable device, inputting the corpus of sensor data into the complete fall detection model—stored remotely from the wearable device—to confirm the fall event and dispatching a care provider to assist the resident in response to confirming the fall event.","['A61B5/1117', 'A61B5/01', 'A61B5/11', 'A61B5/7264', 'G06F19/00', 'G08B21/043', 'G08B21/0446', 'G08B25/001', 'G08B25/016', 'G08B29/186', 'G16Z99/00', 'H04W4/023', 'A61B5/0022', 'G01P15/00', 'G01P15/0891', 'G16H50/20', 'H04M3/5116']"
US20220014723A1,Enhancing performance capture with real-time neural rendering,"Three-dimensional (3D) performance capture and machine learning can be used to re-render high quality novel viewpoints of a captured scene. A textured 3D reconstruction is first rendered to a novel viewpoint. Due to imperfections in geometry and low-resolution texture, the 2D rendered image contains artifacts and is low quality. Accordingly, a deep learning technique is disclosed that takes these images as input and generates more visually enhanced re-rendering. The system is specifically designed for VR and AR headsets, and accounts for consistency between two stereo views.","['G06T5/50', 'H04N13/111', 'G06K9/00362', 'G06K9/00979', 'G06K9/3233', 'G06K9/4671', 'G06N3/0464', 'G06N3/09', 'G06T5/60', 'G06T7/174', 'G06V10/25', 'G06V10/462', 'G06V10/95', 'G06V40/10', 'H04N13/117', 'H04N13/161', 'H04N13/243', 'H04N13/332', 'H04N13/366', 'G06N3/0455', 'G06N3/0495', 'G06N3/084', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'H04N13/194', 'H04N13/239', 'H04N13/305', 'H04N13/344']"
US12124954B1,Intelligent control with hierarchical stacked neural networks,"A method of processing information is provided. The method involves receiving a message; processing the message with a trained artificial neural network based processor, having at least one set of outputs which represent information in a non-arbitrary organization of actions based on an architecture of the artificial neural network based processor and the training; representing as a noise vector at least one data pattern in the message which is incompletely represented in the non-arbitrary organization of actions; and analyzing the noise vector distinctly from the trained artificial neural network.","['G06N3/08', 'B60W30/00', 'G01C21/3602', 'G06N3/04', 'G06N3/045', 'F02D41/1405', 'F03D7/046', 'G05B2219/25255', 'G05B2219/41054', 'G06N3/00', 'G06N3/02', 'G06N7/046', 'Y10S128/925']"
US11934949B2,Composite binary decomposition network,"Embodiments are directed to a composite binary decomposition network. An embodiment of a computer-readable storage medium includes executable computer program instructions for transforming a pre-trained first neural network into a binary neural network by processing layers of the first neural network in a composite binary decomposition process, where the first neural network having floating point values representing weights of various layers of the first neural network. The composite binary decomposition process includes a composite operation to expand real matrices or tensors into a plurality of binary matrices or tensors, and a decompose operation to decompose one or more binary matrices or tensors of the plurality of binary matrices or tensors into multiple lower rank binary matrices or tensors.","['G06N3/08', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
CN111754396B,"Face image processing method, device, computer equipment and storage medium","The application relates to a face image processing method, a face image processing device, a computer device and a storage medium. The method comprises the following steps: acquiring a first face image and a second face image, wherein the first face image and the second face image are images containing real faces; processing the first face image to generate a first updated face image having non-real face image characteristics; adjusting the color distribution of the first updated face image according to the color distribution of the second face image to obtain a first adjusted face image; acquiring a target face mask of the first face image, wherein the target face mask is generated by randomly deforming a face area of the first face image; and fusing the first facial image and the second facial image according to the target facial mask to obtain a target facial image. By adopting the method, various target face images can be generated.","['G06V10/774', 'G06T11/00', 'G06T3/04', 'G06T11/001', 'G06T11/60', 'G06T3/18', 'G06T3/40', 'G06T5/50', 'G06T5/70', 'G06T7/90', 'G06T9/002', 'G06V10/25', 'G06V10/772', 'G06V10/776', 'G06V10/803', 'G06V10/82', 'G06V20/95', 'G06V40/161', 'G06V40/171', 'G09G5/377', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30201', 'G09G2340/10']"
CN114503125B,"Structured pruning method, system and computer-readable medium","The present disclosure provides a structured pruning method, system, and computer-readable medium. The structured pruning method comprises the steps of receiving an input weight mode, obtaining an output weight mode from the input weight mode based on a block rank pruning method, wherein the block rank pruning method comprises the steps of dividing the input weight mode into a mesh network of sub-modes, each row of the input weight mode comprises a first number of sub-rows of the sub-modes, each column of the input weight mode comprises a second number of sub-columns of the sub-modes, pruning a corresponding one or more sub-columns from each sub-mode to achieve a predetermined column sparseness, and pruning a corresponding one or more sub-rows from each sub-mode under the constraint that at least one sub-row of the sub-mode in the corresponding row of the input weight mode is not pruned for each row of the input weight mode to achieve the predetermined row sparseness. Embodiments of the present disclosure reduce storage and computation costs associated with weight patterns.","['G06N3/082', 'G06N3/04', 'G06N3/0442', 'G06N3/0495', 'G06N3/044']"
WO2019101140A1,"Method for generating high-resolution picture, computer apparatus, and storage medium","The present application provides a method for generating a high-resolution picture, comprising: obtaining at least one deep neural network model; obtaining a low-resolution picture; determining a corresponding deep neural network model according to the low-resolution picture; and converting the low-resolution picture to a high-resolution picture by means of the deep neural network model, wherein the deep neural network model comprises a plurality of non-linear conversion convolutional layers alternately using different parameter matrices as convolutional template parameters.","['G06T3/4076', 'G06T3/4046', 'G06N3/045', 'G06N3/08', 'G06T3/4053', 'G06T5/92', 'G06N3/048']"
US20240212220A1,System and method for procedurally colorizing spatial data,"Systems and methods are described for compressing color information in point cloud data. In some embodiments, point cloud data includes point position information and point color information for each of a plurality of points. The point position information is provided to a neural network, and the neural network generates predicted color information (e.g. predicted luma and chroma values) for respective points in the point cloud. A prediction residual is generated to represent the difference between the predicted color information and the input point color position. The point position information (which may be in compressed form) and the prediction residual are encoded in a bitstream. In some embodiments, color hint data is encoded to improve color prediction.","['G06T9/001', 'G06N3/0455', 'G06N3/0464', 'G06N3/084', 'G06T17/00', 'G06T9/00', 'G06T9/002', 'H04N19/186', 'H04N19/593']"
US12026825B2,Apparatus and method for reduced precision bounding volume hierarchy construction,"Apparatus and method for efficient BVH construction. For example, one embodiment of an apparatus comprises: a memory to store graphics data for a scene including a plurality of primitives in a scene at a first precision; a geometry quantizer to read vertices of the primitives at the first precision and to adaptively quantize the vertices of the primitives to a second precision associated with a first local coordinate grid of a first BVH node positioned within a global coordinate grid, the second precision lower than the first precision; a BVH builder to determine coordinates of child nodes of the first BVH node by performing non-spatial-split binning or spatial-split binning for the first BVH node using primitives associated with the first BVH node, the BVH builder to determine final coordinates for the child nodes based, at least in part, on an evaluation of surface areas of different bounding boxes generated for each of the child node.","['G06T15/005', 'G06T15/10', 'G06T1/20', 'G06T1/60', 'G06T15/06', 'G06T17/20', 'G06T9/00', 'G06T9/001', 'G06T9/40', 'G06T2210/12']"
EP3754560A1,Weakly-supervised object detection using one or more neural networks,"Apparatuses, systems, and techniques to detect object in images including digital representations of those objects. In at least one embodiment, one or more objects are detected in an image based, at least in part, on one or more pseudo-labels corresponding to said one or more objects.","['G06V40/10', 'G06N3/084', 'G06F18/2113', 'G06F18/214', 'G06F18/217', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06V10/25', 'G06V10/454', 'G06V10/765', 'G06V10/7753', 'G06V10/82', 'G06V20/10', 'G06N3/047', 'G06N3/049', 'G06N3/082']"
US12192720B1,Audio noise determination using one or more neural networks,"Apparatuses, systems, and techniques are presented to reduce noise in audio. In at least one embodiment, one or more neural networks are used to determine a noise signal in one or more speech signals.","['H04R5/04', 'G10L21/0208', 'G06F18/214', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/046', 'G10L21/0232', 'G10L21/0272', 'G10L25/18', 'G10L25/30', 'G10L25/84', 'H04R3/04', 'H04R5/033', 'G10L2021/02087', 'H04R2225/43']"
US11029949B2,Neural network unit,"A hardware processing unit is provided. The hardware processing unit includes: an accumulator; a multiplier-adder receives first and second factors and receives an addend, the multiplier-adder generates a sum of the addend and a product of the first and second factors and provides the sum; a first multiplexer receives a first operand, a positive one, and a negative one and selects one of them for provision as the first factor to the multiplier-adder; a second multiplexer receives a second operand, a positive one, and a negative one and selects one of them for provision as the second factor to the multiplier-adder; a third multiplexer, having an output, that receives the first operand and the second operand and selects one of them for provision on its output; and a fourth multiplexer receives the third multiplexer output and the sum and selects one of them for provision to the accumulator.","['G06N3/063', 'G06F9/3001', 'G06F17/10', 'G06F7/00', 'G06F7/5443', 'G06F9/30021', 'G06F9/3004', 'G06F9/30076', 'G06F9/3881', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454']"
US20220300819A1,"System and method for designing efficient super resolution deep convolutional neural networks by cascade network training, cascade network trimming, and dilated convolutions","Apparatuses and methods of manufacturing same, systems, and methods are described. In one aspect, a method includes generating a convolutional neural network (CNN) by training a CNN having a plurality of convolutional layers, and performing cascade training on the trained CNN. The cascade training includes an iterative process of a plurality of stages, in which each stage includes inserting a residual block (ResBlock) and training the CNN with the inserted ResBlock.","['G06N3/082', 'G06N3/045', 'G06N3/0454', 'G06N3/088', 'G06T3/4053', 'G06T5/002', 'G06T5/70', 'G06N3/047', 'G06N3/048', 'G06T7/13']"
US11790221B2,Quantum optical neural networks,"Many of the features of neural networks for machine learning can naturally be mapped into the quantum optical domain by introducing the quantum optical neural network (QONN). A QONN can be performed to perform a range of quantum information processing tasks, including newly developed protocols for quantum optical state compression, reinforcement learning, black-box quantum simulation and one way quantum repeaters. A QONN can generalize from only a small set of training data onto previously unseen inputs. Simulations indicate that QONNs are a powerful design tool for quantum optical systems and, leveraging advances in integrated quantum photonics, a promising architecture for next generation quantum processors.","['G06N3/067', 'G02F1/35', 'G06N10/00', 'G06N10/60', 'G06N3/04', 'G06N3/045', 'G06N3/088', 'G02F2203/50', 'G06N3/006', 'G06N3/084', 'G06N3/086']"
US12106210B2,Scaling half-precision floating point tensors for training deep neural networks,"One embodiment provides for a machine-learning accelerator device a multiprocessor to execute parallel threads of an instruction stream, the multiprocessor including a compute unit, the compute unit including a set of functional units, each functional unit to execute at least one of the parallel threads of the instruction stream. The compute unit includes compute logic configured to execute a single instruction to scale an input tensor associated with a layer of a neural network according to a scale factor, the input tensor stored in a floating-point data type, the compute logic to scale the input tensor to enable a data distribution of data of the input tensor to be represented by a 16-bit floating point data type.","['G06N3/063', 'G06F5/012', 'G06F7/487', 'G06F7/5443', 'G06F9/30014', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06T1/20']"
US11537851B2,Methods and systems using improved training and learning for deep neural networks,"Methods and systems are disclosed using improved training and learning for deep neural networks. In one example, a deep neural network includes a plurality of layers, and each layer has a plurality of nodes. The nodes of each L layer in the plurality of layers are randomly connected to nodes of an L+1 layer. The nodes of each L+1 layer are connected to nodes in a subsequent L layer in a one-to-one manner. Parameters related to the nodes of each L layer are fixed. Parameters related to the nodes of each L+1 layers are updated. In another example, inputs for the input layer and labels for the output layer of a deep neural network are determined related to a first sample. A similarity between different pairs of inputs and labels is estimated using a Gaussian regression process.","['G06N3/0472', 'G06N3/063', 'G06F17/18', 'G06F18/22', 'G06K9/6215', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06T1/20']"
EP3723048A1,Method and apparatus for coding and decoding using a convolutional neural network,"Embodiments of this disclosure provide an image encoding method and apparatus and image decoding method and apparatus. The image encoding method includes: performing convolutional neural network encoding on image data to be processed to generate feature vectors or feature maps; quantizing the feature vectors or feature maps to generate discrete symbols to be encoded; estimating probabilities of the symbols to be encoded by using a multi-scale context model, wherein the probability estimator comprises multiple mask convolution layers of different scales; and performing entropy encoding according to the probabilities of the symbols to be encoded.","['G06T9/002', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06T3/4046', 'H04N19/124', 'H04N19/46', 'H04N19/91']"
US20220321919A1,Systems and methods for signaling neural network-based in-loop filter parameter information in video coding,A method of signaling neural network in-loop filter information for video data includes: signaling one or more syntax elements providing neural network in-loop filter information in an adaptation parameter set syntax structure.,"['H04N19/70', 'H04N19/117', 'H04N19/187', 'H04N19/42', 'H04N19/82']"
US11055549B2,"Network, system and method for image processing","A network for image processing is provided, and more particularly, for coarse-to-fine recognition of image processing. The network includes a shared convolution layer, and a first subnet and a second subnet both subsequent to the shared convolution layer; the first subnet comprises a first skipping module comprising one or more skip-dense blocks iteratively stacked with one or more transition layers, a first pooling layer subsequent to the first skipping module, and a first classification layer subsequent to the first pooling layer; the second subnet comprises a second skipping module comprising one or more skip-dense blocks iteratively stacked with one or more layers, a second pooling layer subsequent to the second skipping module, and a second classification layer subsequent to the second pooling layer; and wherein a skip-dense block of the second subnet is selected to guide a transition layer of the first subnet, and the level of the guiding skip-dense block is deeper than the level of the guided transition layer. This network is also related to a system and a method thereof.","['G06N3/063', 'G06K9/00979', 'G06F18/214', 'G06F18/21', 'G06F18/24', 'G06F18/24323', 'G06F18/2451', 'G06K9/6217', 'G06K9/6286', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06V10/764', 'G06V10/82', 'G06V10/95', 'G06N3/084']"
US12198221B2,Compute optimization mechanism for deep neural networks,"Embodiments provide mechanisms to facilitate compute operations for deep neural networks. One embodiment comprises a graphics processing unit comprising one or more multiprocessors, at least one of the one or more multiprocessors including a register file to store a plurality of different types of operands and a plurality of processing cores. The plurality of processing cores includes a first set of processing cores of a first type and a second set of processing cores of a second type. The first set of processing cores are associated with a first memory channel and the second set of processing cores are associated with a second memory channel.","['G06F9/45533', 'G06F9/5061', 'G06F9/5094', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06T1/20', 'G06F2009/45583', 'G06F8/41', 'Y02D10/00']"
US12008255B2,Aligning variable sized compressed data to fixed sized storage blocks,"Preparing data for deduplication including: generating, by a storage system for a compressed data block, a padded compressed data block by padding the compressed data block to conform to a fixed block size, wherein the fixed block size is greater than a size of the compressed data block; storing, in the storage system, the padded compressed data block beginning at a block boundary of a storage device in the storage system; and performing block-based deduplication on the storage system, wherein the block-based deduplication determines whether the padded compressed data block matches one or more other padded compressed data blocks stored in the storage system.","['G06F16/1752', 'G06F16/215', 'G06F21/602', 'G06F21/64', 'G06F3/0608', 'G06F3/0623', 'G06F3/0641', 'G06F3/067', 'G06F3/0673', 'H03M7/3068', 'H03M7/3093', 'H03M7/3095']"
US12334043B2,Time-varying and nonlinear audio processing using deep neural networks,"A computer-implemented method of processing audio data, the method comprising receiving input audio data (x) comprising a time-series of amplitude values; transforming the input audio data (x) into an input frequency band decomposition (X1) of the input audio data (x); transforming the input frequency band decomposition (X1) into a first latent representation (Z); processing the first latent representation (Z) by a first deep neural network to obtain a second latent representation (Z{circumflex over ( )}, Z1{circumflex over ( )}); transforming the second latent representation (Z{circumflex over ( )}, Z1{circumflex over ( )}) to obtain a discrete approximation (X3{circumflex over ( )}); element-wise multiplying the discrete approximation (X3{circumflex over ( )}) and a residual feature map (R, X5{circumflex over ( )}) to obtain a modified feature map, wherein the residual feature map (R, X5{circumflex over ( )}) is derived from the input frequency band decomposition (X1); processing a pre-shaped frequency band decomposition by a waveshaping unit to obtain a waveshaped frequency band decomposition (X1{circumflex over ( )}, X1.2{circumflex over ( )}), wherein the pre-shaped frequency band decomposition is derived from the input frequency band decomposition (X1), wherein the waveshaping unit comprises a second deep neural network; summing the waveshaped frequency band decomposition (X1{circumflex over ( )}, X1.2{circumflex over ( )}) and a modified frequency band decomposition (X2{circumflex over ( )}, X1.1{circumflex over ( )}) to obtain a summation output (X0{circumflex over ( )}), wherein the modified frequency band decomposition (X2{circumflex over ( )}, X1.1{circumflex over ( )}) is derived from the modified feature map; and transforming the summation output (X0{circumflex over ( )}) to obtain target audio data (y{circumflex over ( )}).","['G06N3/084', 'G06N3/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0499', 'G06N3/08', 'G10H1/0091', 'G10H1/12', 'G10H1/16', 'G10H3/187', 'G10L19/02', 'G10L21/038', 'G10L25/30', 'G06N3/048', 'G10H2210/215', 'G10H2210/281', 'G10H2210/311', 'G10H2250/025', 'G10H2250/311']"
US20200222010A1,System and method for deep mind analysis,"Embodiments of the present invention may provide techniques for brain interfacing, mapping neuronal structure, manipulating cellular structure, cognitive and brain augmentation via implants, and curing, not just managing, neurological disorders. For example, a method for deep mind analysis may comprise receiving electrical and optical signals from electrophysiological neural signals of brain tissue from at least one read modality, encoding the received electrical and optical signals using a Fundamental Code Unit, automatically generating at least one machine learning model using the Fundamental Code Unit encoded electrical and optical signals, generating at least one optical or electrical signal to be transmitted to the brain tissue using the generated at least one machine learning model, and transmitting the generated at least one optical or electrical signal to the brain tissue to provide electrophysiological stimulation of the brain tissue using at least one write modality.","['A61N5/0601', 'A61B5/04001', 'A61B5/24', 'A61B5/4836', 'A61B5/686', 'A61B5/7267', 'A61N1/0529', 'A61N1/3605', 'A61N1/36139', 'A61N5/0603', 'A61N5/0622', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/126', 'G06N5/01', 'G06N5/02', 'G06N7/01', 'G16H20/30', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/50', 'A61B5/0042', 'A61B5/053', 'A61B5/055', 'A61B5/11', 'A61B5/16', 'A61B5/369', 'A61B5/4803', 'A61B6/032', 'A61B6/037', 'A61N1/0531', 'A61N1/0536', 'A61N2/002', 'A61N2/006', 'A61N2005/0626', 'A61N2005/0651', 'G06N3/006', 'G06N3/044', 'G06N3/047']"
US20210256384A1,Computer-implemented methods and systems for achieving real-time dnn execution on mobile devices with pattern-based weight pruning,"PatDNN is an end-to-end framework to achieve real-time DNN execution on mobile devices. PatDNN includes two stages: a pattern-based pruning stage based on extended ADMM solution framework, and an optimized execution code generation stage including a high-level, fine-grained DNN layerwise representation and a set of architecture-aware optimizations. This design allows PatDNN to benefit from both high accuracy and hardware efficiency.","['G06N3/082', 'G06N3/04', 'G06N3/045', 'G06N3/126']"
US8897506B2,Image classification and information retrieval over wireless digital networks and the internet,"A method and system for matching an unknown facial image of an individual with an image of a celebrity using facial recognition techniques and human perception is disclosed herein. The invention provides a internet hosted system to find, compare, contrast and identify similar characteristics among two or more individuals using a digital camera, cellular telephone camera, wireless device for the purpose of returning information regarding similar faces to the user The system features classification of unknown facial images from a variety of internet accessible sources, including mobile phones, wireless camera-enabled devices, images obtained from digital cameras or scanners that are uploaded from PCs, third-party applications and databases. Once classified, the matching person's name, image and associated meta-data is sent back to the user. The method and system uses human perception techniques to weight the feature vectors.","['G06V40/173', 'G06V40/172', 'G06K9/00288', 'G06F16/5838', 'G06V20/52', 'G06V40/16', 'G06V40/168', 'G06V40/169', 'G06V40/171', 'G06V40/179', 'Y10S707/99948']"
US10860929B2,Machine-learning based video compression,An encoder system trains a compression model that includes an autoencoder model and a frame extractor model. The encoding portion of the autoencoder is coupled to receive a set of target frames and a previous state tensor for the set of target frames and generate compressed code. The decoding portion of the autoencoder is coupled to receive the compressed code and the previous state tensor for the set of frames and generate a next state tensor for the set of target frames. The frame extractor model is coupled to receive the next state tensor and generate a set of reconstructed frames that correspond to the set of target frames by performing one or more operations on the state tensor. The state tensor for the set of frames includes information from frames of the video that can be used by the frame extractor to generate reconstructed frames.,"['H04N19/42', 'G06F18/214', 'G06K9/00744', 'G06K9/6256', 'G06N3/045', 'G06N3/08', 'G06V10/774', 'G06V10/82', 'G06V20/46', 'H04N19/182', 'H04N19/517', 'G06F11/00', 'G06N20/00', 'G06N20/20', 'G06N3/084']"
EP3699825A2,Systems and methods for deploying and updating neural networks at the edge of a network,"Methods, devices and system for updating a neural network on an edge device that has low-bandwidth uplink capability include a centralized site/device that is configured to train and send the neural network to the edge device. In response, the centralized site/device may receive neural network information from the edge device that includes all or portions of a dataset, output activations, and/or overall inference result that is collected or generated in the edge device. The centralized site/device may use the received neural network information to update all or a part of the trained neural network, generate updated neural network information based on the updated neural network, and send the updated neural network information to the edge device.","['G06N3/08', 'G06F18/254', 'G06F18/285', 'G06F8/61', 'G06F8/658', 'G06N20/20', 'G06N3/045', 'G06N3/082', 'G06N3/049']"
CN111612144B,Pruning method and terminal applied to target detection,"The invention discloses a pruning method and a terminal applied to target detection, which train a preset target detection algorithm until convergence; determining a pruning proportion corresponding to each network layer according to the norm of the weight of each network layer in the converged deep neural network model of the target detection algorithm; clustering the weights of all channels in the network layer corresponding to the pruning proportion according to the pruning proportion, and determining a clustering center corresponding to each network layer; pruning channels in the network layer in which each network layer is located according to the clustering center and the pruning proportion corresponding to each network layer; the pruning of the channels of each network layer in the deep neural network model is realized based on the weight clustering of the norm, redundant channels can be deleted to realize the compression of the deep neural network model, the pruning process is simple, the time consumption is low, the dependence in the pruning process is low, the dependence on any parameter and a specific layer is not required, and meanwhile, the precision loss is reduced while the compression is ensured.","['G06N3/082', 'G06F18/23', 'G06N3/045']"
CN110782015B,"Training method, device and storage medium for network structure optimizer of neural network","The invention provides a training method and device of a network structure optimizer of a neural network, electronic equipment and a storage medium; the method comprises the following steps: extracting characteristics of a network structure of the neural network through the network structure optimizer to obtain characteristic information corresponding to the network structure; predicting the characteristic information through the network structure optimizer, and determining a plurality of optimization modes aiming at the network structure; updating the network structure of the neural network according to the optimization mode aiming at the network structure to obtain an optimized network structure; and performing performance evaluation on the optimized network structure, and updating parameters of the network structure optimizer according to an evaluation result. According to the invention, the network structure of the neural network can be optimized according to the network structure optimizer, and the calculation cost is saved.","['G06N3/04', 'G06N3/082', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G06N3/092', 'G06N3/084']"
US11410044B2,Application development platform and software development kits that provide comprehensive machine learning services,"The present disclosure provides an application development platform and associated software development kits (“SDKs”) that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (“API”) that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.","['G06N3/084', 'G06F18/214', 'G06F8/76', 'G06F9/541', 'G06K9/6256', 'G06N3/045']"
US10140574B2,Neural network unit with segmentable array width rotator and re-shapeable weight memory to match segment width to provide common weights to multiple rotator segments,"First/second memories hold rows of N weight/data words. The first memory address has log2 W bits and an extra bit. Each of N processing units (PU) of index J has first and second registers, an accumulator, an arithmetic unit performs an operation thereon to accumulate a result, first multiplexing logic for PUs 0 through (N/2)−1 receives first memory weight words J and J+(N/2) and for PUs N/2 through N−1 receives first memory weight words J and J−(N/2) and outputs a selected weight word to the first register, and second multiplexing logic receives second memory data word J and data word output by the second register of PU J−1 and outputs a selected data word to the second register. PU 0 second multiplexing logic also receives PU (N/2)−1 second register data word, and PU N/2 second multiplexing logic also receives PU N−1 second register data word.","['G06N3/082', 'G06F12/1009', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06F12/0292', 'G06F2212/656']"
US10565494B2,Neural network unit with segmentable array width rotator,"First/second memories hold rows of N weight/data words. Each of N processing units (PU) of index J have a register, an accumulator having an output, an arithmetic unit that performs an operation thereon to accumulate a result, the first input receives the output of the accumulator, the second input receives a respective first memory weight word, the third input receives a respective data word output by the register, and multiplexing logic receives a respective second memory data word and a data word output by the register of PU J−1 and outputs a selected data word to the register. PU J−1 for PU 0 is PU N−1. The multiplexing logic of PU 0 also receives the data word output by the register of PU (N/2)−1. The multiplexing logic of PU N/2 also receives the data word output by the register of PU N−1.","['G06N3/065', 'G06N3/063', 'G06F12/0862', 'G06F9/3001', 'G06F9/3893', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06F2212/6026']"
US10504020B2,System and method for applying a deep learning neural network to data obtained from one or more sensors,"An application provisioning system and method. A server provides an application provisioning service. A user of a client provides a schema defining an application. The application interacts with peripherals coupled to the client and receives input from sensors coupled to the peripherals. The sensor data is provided to the server for processing, including by neural networks. The application includes a workflow defining a finite state machine that traverses states at least partially based on the response to sensor data. The server may provide dynamic reallocation of compute resources to resolve demand for classifier training job requests; use of jurisdictional certificates to define data usage and sharing; and data fusion. Applications include manufacturing verification, medical diagnosis and treatment, genomics and viral detection.","['G06F8/30', 'G06F18/214', 'G06F18/285', 'G06F8/35', 'G06F8/36', 'G06F9/5027', 'G06K9/00', 'G06K9/00536', 'G06K9/6227', 'G06K9/6256', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'H04L41/5041', 'H04L67/12', 'H04L67/34', 'H04L67/42', 'G06F2209/5017', 'G06F2209/503', 'G06F2209/509', 'G06F2209/541', 'G06F2209/549', 'G06F2218/12']"
US20250046001A1,Multi-tile graphics processor rendering,"Embodiments are generally directed to multi-tile graphics processor rendering. An embodiment of an apparatus includes a memory for storage of data; and one or more processors including a graphics processing unit (GPU) to process data, wherein the GPU includes a plurality of GPU tiles, wherein, upon geometric data being assigned to each of a plurality of screen tiles, the apparatus is to transfer the geometric data to the plurality of GPU tiles.","['G06T15/005', 'G06T1/20', 'G06T1/60', 'G06T17/20']"
US10791333B2,Video encoding using hierarchical algorithms,"The present disclosure relates to encoding visual data comprising a plurality of layers using one or more hierarchical algorithms. According to an aspect, there is provided a method of encoding visual data using a plurality of layers wherein each layer encodes a different representation, and wherein one or more of the plurality of layers comprises one or more hierarchical algorithms, the method comprising the steps of: extracting one or more samples within each of the plurality of layers; and processing within each layer the one or more samples extracted in the layer; wherein in at least one of the plurality of layers the step of processing comprises applying the one or more hierarchical algorithms to the samples extracted in the layer in relation to any inter-layer prediction; and wherein the step of processing reduces a predetermined mathematical distortion between samples of a first layer and samples of a second layer.","['H04N19/187', 'H04N19/176', 'H04N19/103', 'H04N19/124', 'H04N19/149', 'H04N19/174', 'H04N19/196', 'H04N19/30', 'H04N19/31', 'H04N19/33']"
CN111582294B,Method for constructing convolutional neural network model for surface defect detection and application thereof,"The invention discloses a method for constructing a convolutional neural network model for surface defect detection and application thereof, wherein the method comprises the following steps: (1) collecting and importing original pictures; (2) Preprocessing an original picture, determining the preprocessed original picture as an original training sample and storing the original training sample; (3) Labeling the original training sample to generate a labeling sample; (4) Transforming the original training sample to generate a new training sample, so as to realize training sample enhancement; (5) Training samples are used as input data, and the samples are marked for corresponding processing and are used as reference output: and (5) until the accuracy rate of stable convergence is reached through multiple iterations, storing after the convolutional neural network model is generated. The invention overcomes a plurality of adverse effects caused by interference factors such as random product defect morphology, complex texture, low contrast and the like under the condition of inputting a small amount of samples, thereby improving the defect recognition rate.","['G06F18/241', 'G01N21/8851', 'G06F18/214', 'G01N2021/8887']"
US10452905B2,System and method for detecting objects in an image,"A method for cropping photos images captured by a user from an image of a page of a photo album is described. Corners in the page image are detected using corner detection algorithm or by detecting intersections of line-segments (and their extensions) in the image using edge, corner, or line detection techniques. Pairs of the detected corners are used to define all potential quads, which are then are qualified according to various criteria. A correlation matrix is generated for each potential pair of the qualified quads, and candidate quads are selected based on the Eigenvector of the correlation matrix. The content of the selected quads is checked using a salience map that may be based on a trained neuron network, and the resulting photos images are extracted as individual files for further handling or manipulation by the user.","['G06K9/00463', 'G06V30/40', 'G06K9/00442', 'G06K9/00456', 'G06K9/228', 'G06K9/3233', 'G06K9/4628', 'G06K9/4676', 'G06K9/66', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T3/4007', 'G06T5/009', 'G06T5/92', 'G06V10/25', 'G06V30/142', 'G06V30/413', 'G06V30/414', 'G06K2009/363', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20132', 'G06T2207/20164', 'G06T2207/30176', 'G06V10/247']"
US20240403031A1,Application Development Platform and Software Development Kits that Provide Comprehensive Machine Learning Services,"The present disclosure provides an application development platform and associated software development kits (“SDKs”) that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (“API”) that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.","['G06F8/65', 'G06F8/36', 'G06N20/00']"
US9928605B2,Real-time cascaded object recognition,"Various systems and methods for real-time cascaded object recognition are described herein. A system for real-time cascaded object recognition comprises a processor; and a memory, including instructions, which when executed on the processor, cause the processor to perform the operations comprising: accessing image data at the system, the image data of an environment around the system, the image data is captured by a camera system; determining a set of regions in the image data, the set of regions including candidate objects; transmitting a subset of the image data corresponding to the set of regions to a remote server, the remote server to analyze the subset of the image data and detect an object in the subset of the image data; and receiving at the system from the remote server, an indication of the object detected in the subset of the image data.","['H04N13/204', 'G06T7/2033', 'G06K9/66', 'G06T1/60', 'G06T7/0081', 'G06T7/0085', 'G06T7/11', 'G06T7/13', 'G06T7/246', 'G06V20/52', 'H04N13/0203', 'H04N13/271', 'H04N23/20', 'G06V40/174', 'G06V40/178']"
US20230019669A1,Systems and methods for enhanced feedback for cascaded federated machine learning,"Systems and methods are disclosed herein for enhanced feedback for cascaded federated machine learning (ML). In one embodiment, a method of operation of a server comprises, for a training epoch, receiving, from each of client device, information including a local ML model as trained at the client device and an estimated value of each parameter output by the local ML model. The method further comprises aggregating the local ML models to provide a global ML model and training a network ML model based on the estimated values of each of the parameters output by the local ML models and global data available at the server. The method further comprises providing, to each client device, information including the global ML model and feedback information related to a hidden neural network layer of the network ML model. The method further comprises repeating the process for one or more additional training epochs.","['H04L41/16', 'G06F9/54', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'H04L41/145', 'H04L41/147']"
CN108805792B,Programmable coarse-grained and sparse matrix computation hardware with advanced scheduling,"Programmable coarsening and sparse matrix computing hardware with advanced scheduling is provided. One embodiment provides a computing device that performs machine learning operations, the computing device including a decoding unit to decode a single instruction into decoded instructions that are to cause the computing device to perform complex machine learning computing operations.","['G06T1/20', 'G06F9/3001', 'G06F9/3017', 'G06F9/30196', 'G06F9/3851', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/3895', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/098']"
US11126869B2,Tracking after objects,"A method for tracking after an entity, the method may include tracking, by a monitor of a vehicle, a movement of an entity that appears in various images acquired during a tracking period; generating, by a processing circuitry of the vehicle, an entity movement function that represents the movement of the entity during the tracking period; generating, by the processing circuitry of the vehicle, a compressed representation of the entity movement function; and responding to the compressed representation of the entity movement function.","['H04N7/183', 'G06K9/00805', 'G05D1/0061', 'G05D1/0088', 'G05D1/0094', 'G05D1/0238', 'G05D1/0246', 'G05D1/0253', 'G05D1/0276', 'G05D1/0287', 'G06F18/211', 'G06F18/214', 'G06F18/23', 'G06F18/25', 'G06F18/28', 'G06K9/00369', 'G06K9/342', 'G06K9/6218', 'G06K9/6228', 'G06K9/6255', 'G06K9/6256', 'G06K9/6288', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T7/246', 'G06T7/70', 'G06T7/74', 'G06V10/255', 'G06V10/762', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G06V20/58', 'G06V40/103', 'G08G1/166', 'H04N7/185', 'H04W4/46', 'H04W4/48', 'G06K2209/23', 'G06T2207/10016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'G06T2207/30261', 'G06V2201/08', 'G08G1/162', 'G08G1/165', 'H04L67/12']"
US20210004589A1,Scene and user-input context aided visual search,"Provided is a technique for determining a context of an image and an object depicted by the image based on the context. A trained context classification model may determine a context of an image, and a trained object recognition model may determine an object depicted by the image based on the image and the context. Provided is also a technique for determining an object depicted within an image based on an input location of an input detected by a display screen. An object depicted within an image may be detected based on a distance in feature space between an image feature vector of an image and a feature vector of the object, and a distance in pixel-space between an input location of an input and location of the object within the image.","['G06K9/00624', 'G06V10/82', 'G06F18/254', 'G06K9/66', 'G06T5/00', 'G06V10/809', 'G06V30/19173', 'G06F3/013', 'G06F3/017', 'G06F3/041', 'G06F3/0488']"
US20220358627A1,High dynamic range image processing with fixed calibration settings,"In various examples, apparatuses, systems, and techniques to perform offline image signal processing of source image data to generate target image data. In at least one embodiment, data collection using exposure and calibration setting of an image sensor is performed to generate source image data, which is then processed by using offline image signal processing to generate target data.","['H04N5/77', 'G06T5/90', 'G06T5/92', 'G06T5/009', 'G06F9/3887', 'G06N3/08', 'G06N3/084', 'G06T1/20', 'G06T5/50', 'G06T5/60', 'H04N23/741', 'H04N5/2355', 'H04N5/91', 'G06N3/063', 'G06T2200/28', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208', 'G06T2207/30252']"
CN117633459B,High-precision distributed optical fiber sensing online monitoring device,"The invention relates to the technical field of optical measurement devices, in particular to a high-precision distributed optical fiber sensing on-line monitoring device which comprises a data acquisition module, a feature extraction module, a mode classification module, a trend analysis module, an anomaly detection module, a data compression and transmission module, a real-time monitoring module and a visual display module. According to the invention, a data acquisition module based on a multi-point optical fiber sensing technology adopts a dynamic acquisition algorithm, so that the accuracy and efficiency of real-time data acquisition are improved, the data quality is ensured by preliminary filtration, the characteristic extraction and pattern recognition are enhanced by an automatic encoder technology, the data analysis is deepened, the deep learning analysis is performed by a pattern classification module in combination with a convolutional neural network and a cyclic neural network, the accurate data classification is provided, the time sequence analysis is enhanced by a long-term and short-term memory network, the prediction and trend analysis are supported, the safety and the reliability of a system are improved by the abnormal detection of an isolated forest algorithm, the data storage and transmission are optimized by a waveform encoding technology, the cost is reduced, and the efficiency is improved.","['G01D5/353', 'G06F18/20', 'G06F18/213', 'G06F18/241', 'G06F18/24323', 'G06F18/2433', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/08']"
US20210063198A1,Map creation and localization for autonomous driving applications,"An end-to-end system for data generation, map creation using the generated data, and localization to the created map is disclosed. Mapstreams—or streams of sensor data, perception outputs from deep neural networks (DNNs), and/or relative trajectory data—corresponding to any number of drives by any number of vehicles may be generated and uploaded to the cloud. The mapstreams may be used to generate map data—and ultimately a fused high definition (HD) map—that represents data generated over a plurality of drives. When localizing to the fused HD map, individual localization results may be generated based on comparisons of real-time data from a sensor modality to map data corresponding to the same sensor modality. This process may be repeated for any number of sensor modalities and the results may be fused together to determine a final fused localization result.","['G01C21/3841', 'G01C21/32', 'G01C21/1652', 'G01C21/3811', 'G01C21/3815', 'G01C21/3867', 'G01C21/387', 'G01C21/3878', 'G01C21/3896', 'G01S13/86', 'G01S13/865', 'G01S13/867', 'G01S13/89', 'G01S13/931', 'G01S17/86', 'G01S17/89', 'G01S19/45', 'G01S7/417', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'G01S2013/9316', 'G06N3/063']"
CN114494195B,Small sample attention mechanism parallel twin method for fundus image classification,"The invention provides a small sample attention mechanism parallel twin method for fundus image classification, which classifies fundus lesion images of a patient to obtain classification results, and comprises the following steps: reading a medical fundus image dataset for preprocessing to obtain preprocessed picture data; by means of a few shots learning method based on a twin network Siamese, a dense connection network densenet which is pre-trained by using a dataset ImageNet is migrated by means of a feature-based migration learning method to extract features of two different images, a convolution block attention module CBAM is added on the basis of the network to select more critical image information, and similarity measurement of pictures is carried out through a comparison loss function, so that more accurate classification prediction results are obtained. The invention migrates a dense connection network, can effectively reduce the situation of overfitting in the study of small samples, and simultaneously effectively improves the efficiency and the accuracy of medical fundus image lesion classification data by means of CBAM attention mechanisms and a twin network.","['G06T7/0012', 'G06F18/214', 'G06F18/22', 'G06F18/2414', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06T3/4046', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'Y02T10/40']"
US20190311290A1,Deep Learning Based Test Compression Analyzer,"One or more machine-learning models are trained and employed to predict test coverage and test data volume. Input features for the one or more machine-learning models comprise the test configuration features and the design complexity features. The training data are prepared by performing test pattern generation and circuit design analysis. The design complexity features may comprise testability, X-profiling, clock domains, power domains, design-rule-checking warnings, or any combination thereof.","['G06N20/00', 'G06N3/084', 'G01R31/317', 'G01R31/31813', 'G01R31/31835', 'G06N20/20']"
US11166032B2,"Encoder, decoder, encoding method, and decoding method","An encoder includes circuitry and memory. Using the memory, the circuitry: encodes an original image and decodes the original image encoded, to generate a first bitstream and a local decoded image; encodes supplemental information and decodes the encoded supplemental information, to generate a second bitstream and local decoded supplemental information; inputs data based on the local decoded image and the local decoded supplemental information to a post processing network which is a neural network, to cause a reconstructed image to be output from the post processing network, the reconstructed image corresponding to the original image and being to be used to encode a following original image which follows the original image; and concatenates the first bitstream and the second bitstream to generate a concatenated bitstream.","['H04N19/184', 'H04N19/46', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'H04N19/124', 'H04N19/136', 'H04N19/85', 'G06N3/044']"
US11093579B2,FP16-S7E8 mixed precision for deep learning and other algorithms,"Disclosed embodiments relate to mixed-precision vector multiply-accumulate (MPVMAC) In one example, a processor includes fetch circuitry to fetch a compress instruction having fields to specify locations of a source vector having N single-precision formatted elements, and a compressed vector having N neural half-precision (NHP) formatted elements, decode circuitry to decode the fetched compress instruction, execution circuitry to respond to the decoded compress instruction by: converting each element of the source vector into the NHP format and writing each converted element to a corresponding compressed vector element, wherein the processor is further to fetch, decode, and execute a MPVMAC instruction to multiply corresponding NHP-formatted elements using a 16-bit multiplier, and accumulate each of the products with previous contents of a corresponding destination using a 32-bit accumulator.","['G06F7/483', 'G06F17/16', 'G06F7/5443', 'G06F9/30014', 'G06F9/30025', 'G06F9/30036', 'G06F9/30038', 'G06F9/30145', 'G06N3/04', 'G06N3/063', 'G06N3/08', 'G06N5/046', 'G06F2207/382']"
CN113515770B,Method and device for determining target service model based on privacy protection,"The embodiment of the specification provides a method and a device for determining a target service model based on privacy protection, which are characterized in that firstly, initial training is carried out on a selected complex service model to obtain an initial service model, then the initial service model is trimmed, and the trimmed service model is trained to obtain corresponding model indexes. And for the obtained multiple sub-models, determining each sampling probability corresponding to each service model by using a corresponding model index through an exponential mechanism of differential privacy, and sampling the multiple sub-models based on the sampling probabilities so as to select a target service model. Therefore, the compression model of the privacy protection can be obtained in a differential privacy mode, and the privacy protection is provided for the model on the basis of realizing model compression.","['G06F21/6245', 'G06N3/082']"
CN107710238B,Deep Neural Network Processing on Hardware Accelerator with Stacked Memory,A method for processing a deep neural network on an acceleration component is provided. The method includes configuring an acceleration component to perform forward propagation and backward propagation phases of the deep neural network. The acceleration component includes an acceleration component die and a memory stack disposed in an integrated circuit package. The memory stack has a memory bandwidth greater than about 50 GB/sec and a power efficiency greater than about 20 MB/sec/mW.,"['G06N3/084', 'G06F15/7803', 'G06N3/0499', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06F15/7821', 'G06N5/025', 'Y02D10/00']"
US20200160565A1,Methods And Apparatuses For Learned Image Compression,"A learned image compression system increases compression efficiency by using a novel conditional context model with embedded autoregressive neighbors and hyperpriors, which can accurately estimate the entropy rate for rate distortion optimization. Generalized Divisive Normalization (GDN) in Residual Neural Network is used in the encoder and decoder networks for fast convergence rate and efficient feature representation.","['G06T9/002', 'G06N3/088', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472', 'G06N3/048', 'H04N19/60', 'H04N19/90', 'H04N19/103', 'H04N19/12', 'H04N19/124', 'H04N19/182']"
US11902561B2,Convolutional-neutral-network based filter for video coding,"The present disclosure provides methods for convolutional-neural-network (CNN) based filter for video coding. An exemplary method includes: applying motion estimation to a target coding block, to determine a reference block of the target coding block; inputting, to a convolutional neural network (CNN) filter, image data associated with the target coding block and the reference block; and executing the CNN filter to determine a residual associated with the target coding block based on the input image data.","['H04N19/51', 'H04N19/513', 'G06N3/045', 'G06N3/08', 'H04N19/105', 'H04N19/176', 'H04N19/82', 'G06N3/048']"
US11375204B2,Feature-domain residual for video coding for machines,"An apparatus includes at least one processor; and at least one non-transitory memory including computer program code; wherein the at least one memory and the computer program code are configured to, with the at least one processor, cause the apparatus at least to: decode encoded data to generate decoded data, the encoded data having a bitrate lower than that of original data, and extract features from the decoded data; decode encoded residual features to generate decoded residual features; and generate enhanced decoded features as a result of combining the decoded residual features with the features extracted from the decoded data.","['H04N19/50', 'H04N19/146', 'G06T9/002', 'H04N19/103', 'H04N19/30', 'H04N19/436', 'H04N19/85']"
US20200405204A1,Detection of catecholamine levels inside the neurocranium,"Embodiments of the present invention may provide techniques that provide improved detection of catecholamines, such as dopamine. For example, in an embodiment, a method for catecholamine sensing may comprise outputting a signal responsive to a level of at least one catecholamine in neural tissue from a catecholamine sensor, analyzing the signal responsive to a catecholamine level in the neural tissue using circuitry connected to the catecholamine sensor, the circuitry comprising at least one computing device comprising a processor, memory accessible by the processor, and program instructions stored in the memory and executable by the processor, generating, using the circuitry, data representing the catecholamine level in the neural tissue, and transmitting the generated data representing the catecholamine level in the neural tissue using communication circuitry.","['A61B5/14503', 'A61B5/14546', 'A61B5/686', 'A61B5/6868', 'A61B5/72', 'A61B5/7267', 'B82Y15/00', 'A61B2562/0285', 'A61B5/167', 'A61B5/168', 'A61B5/4082', 'A61B5/4088', 'A61N1/0531', 'A61N1/3605', 'B82Y30/00']"
US11468355B2,Data compression and communication using machine learning,"A method of communicating information, comprising modeling a stream of sensor data, to produce parameters of a predictive statistical model; communicating information defining the predictive statistical model from a transmitter to a receiver; and after communicating the information defining the predictive statistical model to the receiver, communicating information characterizing subsequent sensor data from the transmitter to the receiver, dependent on an error of the subsequent sensor data with respect to a prediction of the subsequent sensor data by the statistical model. A corresponding method is also encompassed.","['G06N7/005', 'G06F16/1744', 'G06N7/01', 'G06F16/2474', 'G06F17/18', 'G06F30/27', 'G06N20/00', 'G06N20/10', 'G06N7/00', 'G06N3/08', 'G06N5/01']"
US20190278600A1,Tiled compressed sparse matrix format,"Approaches in accordance with various embodiments provide for the processing of sparse matrices for mathematical and programmatic operations. In particular, various embodiments utilize a tiling approach that divides a sparse matrix into submatrices, many of which will include only zero-value entities. These empty tiles can be ignored, and only the tiles with non-zero entries processed, which reduces resource and time requirements for the processing. An indexing approach can be used for each entity that is a combination of the tile identifier and an offset value, which enables the values to be multiplied correctly against, for example, values of a dense matrix. The tiles can be processed in parallel and the results accumulated to generate a matrix product. The matrix product can then be passed to the next step in a process or operation, such as to a next layer in a deep neural network.","['G06F9/30036', 'G06F17/16', 'G06F9/3877', 'G06F9/3885', 'G06N3/0418', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N3/084', 'G06N3/088']"
US10831444B2,Quantized neural network training and inference,"Training neural networks by constructing a neural network model having neurons each associated with a quantized activation function adapted to output a quantized activation value. The neurons are arranged in layers and connected by connections associated quantized connection weight functions adapted to output quantized connection weight values. During a training process a plurality of weight gradients are calculated during backpropagation sub-processes by computing neuron gradients, each of an output of a respective the quantized activation function in one layer with respect to an input of the respective quantized activation function. Each neuron gradient is calculated such that when an absolute value of the input is smaller than a positive constant threshold value, the respective neuron gradient is set as a positive constant output value and when the absolute value of the input is smaller than the positive constant threshold value the neuron gradient is set to zero.","['G06F7/523', 'G06F7/48', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/084', 'G06F2207/4824']"
US10621495B1,Method for training and refining an artificial intelligence,"One variation of a method for training and refining an artificial intelligence includes: training a neural network on a training set to identify objects in optical images; receiving a manual label attributed to an optical image—recorded by a road vehicle during its operation—by a human annotator; passing the optical image through the neural network to generate an automated label attributed to the optical image; in response to the manual label differing from the automated label, serving the optical image to a human annotator for manual confirmation of one of the manual label and the automated label; appending the training set with the optical image containing one of the manual label and the automated label based on confirmation received from the human annotator; and retraining the neural network, with the training set, to identify objects in optical images.","['G06N3/08', 'G01S17/86', 'G01S17/89', 'G01S17/931', 'G01S17/936', 'G06F18/41', 'G06K9/00805', 'G06K9/66', 'G06V10/7788', 'G06V10/82', 'G06V20/56', 'G06V20/58']"
US12094447B2,Neural text-to-speech synthesis with multi-level text information,A method and apparatus for generating speech through neural text-to-speech (TTS) synthesis. A text input may be obtained (1310). Phoneme or character level text information may be generated based on the text input (1320). Context-sensitive text information may be generated based on the text input (1330). A text feature may be generated based on the phoneme or character level text information and the context-sensitive text information (1340). A speech waveform corresponding to the text input may be generated based at least on the text feature (1350).,"['G10L13/08', 'G06F40/20', 'G06F40/205', 'G06F40/253', 'G06N20/20', 'G06N3/045', 'G10L13/047', 'G10L13/06', 'G10L25/30']"
US11593623B2,Spiking neural network accelerator using external memory,"System configurations and techniques for implementation of a neural network in neuromorphic hardware with use of external memory resources are described herein. In an example, a system for processing spiking neural network operations includes: a plurality of neural processor clusters to maintain neurons of the neural network, with the clusters including circuitry to determine respective states of the neurons and internal memory to store the respective states of the neurons; and a plurality of axon processors to process synapse data of synapses in the neural network, with the processors including circuitry to retrieve synapse data of respective synapses from external memory, evaluate the synapse data based on a received spike message, and propagate another spike message to another neuron based on the synapse data. Further details for use and access of the external memory and processing configurations for such neural network operations are also disclosed.","['G06N3/0481', 'G06N3/049', 'G06N3/048', 'G06F12/0868', 'G06N3/063', 'G06F2212/2146', 'G06F2212/6042']"
US11902705B2,Video prediction using one or more neural networks,"Apparatuses, systems, and techniques to enhance video are disclosed. In at least one embodiment, one or more neural networks are used to create, from a first video, a second video having one or more additional video frames.","['H04N7/0135', 'G06F18/214', 'G06F18/217', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T9/002', 'G06N3/047', 'G06N3/049', 'G06N3/063', 'G06N3/088']"
US11871011B2,Efficient lossless compression of captured raw image information systems and methods,"Systems and methods for efficient lossless compression of captured raw image information are presented. A method can comprise: receiving raw image data from an image capture device, segregating the pixel data into a base layer portion and an enhanced layer portion, reconfiguring the base layer portion expressed in the first color space values from a raw capture format into a pseudo second color space compression mechanism compatible format, and compressing the reconfigured base layer portion of first color space values. The raw image data can include pixel data are expressed in first color space values. The segregation can be based upon various factors, including a compression benefits analysis of a boundary location between the base layer portion and enhanced layer portion. The reconfiguring the base layer portion can include separating the base layer portion based upon multiple components within the raw data; and forming base layer video frames from the multiple components.","['H04N19/182', 'G06N3/02', 'G06T7/11', 'H04N1/413', 'H04N1/64', 'H04N19/186', 'H04N19/33', 'H04N23/85', 'H04N9/67']"
US20210142177A1,Synthesizing data for training one or more neural networks,"Apparatuses, systems, and techniques are presented to generate data useful for further training of a neural network. In at least one embodiment, one or more neural networks can be re-trained based, at least in part, on data generated by the one or more neural networks including data used to previously train the one or more neural networks.","['G06F18/214', 'G06N3/084', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/096', 'G06N5/04', 'G06N3/0464', 'G06N3/098', 'G06N3/0985']"
CN112052951B,"Pruning neural network method, system, equipment and readable storage medium","The embodiment of the application discloses a pruning neural network method, a system, equipment and a readable storage medium, wherein the method comprises the following steps: performing sparse training of a residual error module and a convolution channel on the YOLOv network original model; pruning unimportant residual modules in the network, and simultaneously pruning corresponding weights in the initial model weight file; determining gamma coefficient threshold values of the trimmed convolution layer channels according to importance ordering of the convolution layer channels and the proportion of the convolution layer channels planned to be trimmed, and trimming the convolution layer channels according to the determined threshold values; training and fine-tuning the weight of the trimmed model; the post-pruning model is evaluated for computational effort, frame rate, and accuracy. By trimming the relatively unimportant residual error module and the convolution layer channel, the model parameter quantity of the YOLOv model is reduced under the condition that the precision is basically unchanged, the required calculation force is greatly reduced, and the precision and real-time requirements of intelligent vehicle embedded equipment can be better met.","['G06N3/082', 'G06N3/045']"
US10691996B2,Hardware accelerator for compressed LSTM,"Hardware accelerator for compressed Long Short Term Memory (LSTM) is disclosed. The accelerator comprise a sparse matrix-vector multiplication module for performing multiplication operation between all sparse matrices in the LSTM and vectors to sequentially obtain a plurality of sparse matrix-vector multiplication results. A addition tree module are also included for accumulating a plurality of said sparse matrix multiplication results to obtain an accumulated result. And a non-linear operation module passes the accumulated results through an activation function to generate non-linear operation result. That is, the present accelerator adopts pipeline design to overlap the time of data transfer and computation for compressed LSTM.","['G06N3/0445', 'G06N3/063', 'G06N3/044', 'G06N3/082']"
US20250217418A1,Enhanced searching using fine-tuned machine learning models,"An advanced search system leverages a pre-trained large language model to enhance user query responses. The system, equipped with hardware processors, a search query via an interface and accesses a pre-trained large language model designed to respond to the search query. The system fine-tunes the model to generate a task-specific generative model. The system employs the task-specific generative model to generate a search result to the search query and analyzes the search result based on a performance metric associated with the task-specific generative model. The system refines the task-specific generative model based on the analyzing of the search result.","['G06F16/24575', 'G06F16/248', 'G06F16/345', 'G06F16/90328', 'G06F16/93', 'G06F16/9538', 'G06F16/9558']"
US12387430B2,Generating images of virtual environments using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to generate one or more images based, at least in part, upon one or more semantic features projected from a three-dimensional environment.","['G06T11/00', 'A63F13/52', 'A63F13/67', 'G06T15/00', 'G06T15/10', 'G06T17/05', 'G06T17/20', 'G06T7/12', 'G06V20/647', 'G06V20/70', 'G06T2207/20084', 'G06T2219/2004']"
US20220114698A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to adjust one or more aspect ratios of one or more objects of one or more images based, at least in part, on input from one or more users.","['G06T3/04', 'G06T3/4046', 'G06T7/11', 'G06T2200/24', 'G06T2207/20084']"
US12361221B2,Grammar transfer using one or more neural networks,"Apparatuses, systems, and techniques to transfer grammar between sentences. In at least one embodiment, one or more first sentences are translated into one or more second sentences having different grammar using one or more neural networks.","['G06F40/30', 'G06F18/241', 'G06F40/253', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G10L15/063', 'G10L15/16', 'G10L15/1815', 'G10L15/22', 'G06N20/10', 'G06N3/02', 'G06N3/044', 'G06N3/047', 'G06N3/088']"
US20200303060A1,Diagnostics using one or more neural networks,"Apparatuses, systems, and techniques are presented to analyze objects in images including digital representations of those objects. In at least one embodiment, one or more diagnostic processes are determined based, at least in part, on one or more neural networks used to identify one or more medical images.","['G06Q10/103', 'G06N20/00', 'G06N3/044', 'G06N3/0445', 'G06N3/063', 'G06N3/082', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/63', 'G16H40/67', 'G16H50/20']"
US20220237838A1,Image synthesis using one or more neural networks,"Apparatuses, systems, and techniques are presented to synthesize representations. In at least one embodiment, one or more neural networks are used to generate one or more representations of one or more objects based, at least in part, upon one or more structural features and one or more appearance features for the one or more objects.","['G06T11/60', 'G06T11/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/08', 'G06T1/20', 'G06T17/00', 'G06T19/00', 'G06V10/82', 'G06T2207/20084']"
US20220215232A1,View generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate images. In at least one embodiment, one or more neural networks are used to generate one or more first images based, at least in part, upon one or more second images having one or more different points of view.","['G06N3/0454', 'G06N3/006', 'G06T15/20', 'A63F13/35', 'A63F13/5252', 'A63F13/537', 'A63F13/67', 'A63F13/86', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T19/006', 'G06T7/20', 'G06T7/246', 'G06T7/70', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30241']"
NL2030226B1,"Methods, systems, articles of manufacture and apparatus to optimize resources in edge networks","Methods, apparatus, systems, and articles of manufacture are disclosed to optimize resources in edge networks. An example apparatus includes agent managing circuitry to invoke 5 an exploration agent to identify platform resource devices, select a first one of the identified platform resource devices, and generate first optimization metrics for the workload corresponding to the first one of the identified platform resource devices, the first optimization metrics corresponding to a first path. The example agent is to further select a second one of the identified platform resource devices, generate second optimization metrics for the workload 10 corresponding to the second one of the identified platform resource devices, the second optimization metrics corresponding to a second path. The example apparatus also includes benchmark managing circuitry to embed second semantic information to the workload, the second semantic information including optimized graph information and platform structure information corresponding to the second one of the identified platform resource devices, and 15 reconfiguration managing circuitry to select the first path or the second path during runtime based on (a) service level agreement (SLA) information and (b) utilization information corresponding to the first and second identified platform resource devices.","['H04L47/726', 'H04L41/145', 'G06F9/505', 'G06F9/5088', 'G06N3/045', 'G06N3/082', 'H04L41/0823', 'H04L41/5019', 'H04L47/2425', 'H04L47/765', 'H04L65/80', 'G06F2209/501', 'G06N3/047', 'H04L41/147', 'H04L41/16']"
CN109711532B,Acceleration method for realizing sparse convolutional neural network inference aiming at hardware,"The invention discloses an acceleration method for realizing sparse convolutional neural network inference aiming at hardware, which comprises a packet pruning parameter determination method facing a sparse hardware acceleration architecture, a packet pruning training method aiming at the sparse hardware acceleration architecture and a deployment method aiming at sparse convolutional neural network forward inference, wherein the method comprises the following steps of: determining the grouping length and pruning rate of grouping pruning according to the number of multipliers in a hardware architecture, clipping weights except the compression rate based on an order clipping mode, improving the network accuracy and the compression rate after pruning through an incremental training mode, storing the weight and index parameters of a non-pruning position after fine tuning of the pruned network, and sending the weight and index parameters into a computing unit under the hardware architecture, wherein the computing unit simultaneously acquires an activation value of the grouping length to finish sparse network forward inference. The invention sets the pruning parameters and pruning strategy of the algorithm layer based on the hardware architecture, is beneficial to reducing the logic complexity of the sparse accelerator and improving the overall efficiency of forward estimation of the sparse accelerator.",['Y02D10/00']
US11958529B2,Controlling position of robot by determining goal proposals by using neural networks,A framework for offline learning from a set of diverse and suboptimal demonstrations operates by selectively imitating local sequences from the dataset. At least one embodiment recovers performant policies from large manipulation datasets by decomposing the problem into a goal-conditioned imitation and a high-level goal selection mechanism.,"['B62D15/025', 'B62D15/0285', 'B25J1/02', 'B60W30/06', 'B60W60/0025', 'G05B13/027', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/088', 'G06N3/084', 'G06N7/01']"
US20210097691A1,Image generation using one or more neural networks,"Apparatuses, systems, and techniques are presented to generate or manipulate digital images. In at least one embodiment, a network is trained to generate modified images including user-selected features.","['G06T11/001', 'G06F18/214', 'G06F18/24133', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/063', 'G06N3/084', 'G06N3/088', 'G06T11/60', 'G06T3/4053', 'G06T7/11', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
RU2699687C1,Detecting text fields using neural networks,FIELD: computer equipment.,"['G06F40/131', 'G06F16/353', 'G06F40/216', 'G06F40/242', 'G06F40/279', 'G06F40/284', 'G06F40/30', 'G06N3/08']"
US11765391B2,Supplemental enhancement information messages for neural network based video post processing,"A method includes receiving, at a decoder, video data and a supplemental enhancement information (SEI) message corresponding to the video data, the SEI message including information indicating whether the received video data uses neural network based tools, and performing, at the decoder, post-processing of the received video data based on the information included in the SEI message.","['H04N19/70', 'H04N19/85', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'H04N19/117', 'H04N19/186', 'H04N19/46']"
US20210027426A1,"Method and device for processing image, and storage medium","A method for processing an image includes: an image to be processed with a first resolution is acquired; and the image to be processed is processed by a target neural network model to obtain a target image, the target image being a denoised image with a second resolution, the second resolution being higher than the first resolution, and the target neural network model including a first preset number of convolutional layers and a second preset number of sub-pixel up-sampling portions.","['G06T5/70', 'G06T3/4053', 'G06F18/214', 'G06K9/6256', 'G06N3/08', 'G06T3/4069', 'G06T5/002', 'G06T5/003', 'G06T5/73', 'G06T2207/20081', 'G06T2207/20084']"
US11445970B2,System and method for neural-network-based atrial fibrillation detection with the aid of a digital computer,"A system and method for neural-network-based atrial fibrillation detection with the aid of a digital computer are provided. Electrocardiography (ECG) features and annotated patterns of the features are maintained in a database, at least some of the patterns associated with atrial fibrillation. A classifier is trained based on the annotated patterns, the classifier implemented by a convolutional neural network. A representation of an ECG signal recorded by one or more ambulatory monitors is received. ECG features in the representation falling within each of the temporal windows are detected. The trained classifier is used to identify patterns of the ECG features. At least one matrix with weights for the patterns are generated. A value indicative of whether portions of the representation are associated the patient experiencing atrial fibrillation is calculated. That one or more of the portions are associated with the patient experiencing atrial fibrillation is determined.","['A61B5/361', 'A61B5/0006', 'A61B5/0022', 'A61B5/25', 'A61B5/257', 'A61B5/259', 'A61B5/28', 'A61B5/282', 'A61B5/316', 'A61B5/318', 'A61B5/33', 'A61B5/332', 'A61B5/333', 'A61B5/339', 'A61B5/349', 'A61B5/6823', 'A61B5/6832', 'A61B5/6833', 'A61B5/7203', 'A61B5/7264', 'A61B5/7267', 'A61B5/742', 'A61B5/748', 'G06N20/00', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G16H40/67', 'A61B2560/0487', 'A61B2562/08', 'A61B5/353', 'G16H50/70']"
US11069344B2,Complex evolution recurrent neural networks,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for speech recognition using complex evolution recurrent neural networks. In some implementations, audio data indicating acoustic characteristics of an utterance is received. A first vector sequence comprising audio features determined from the audio data is generated. A second vector sequence is generated, as output of a first recurrent neural network in response to receiving the first vector sequence as input, where the first recurrent neural network has a transition matrix that implements a cascade of linear operators comprising (i) first linear operators that are complex-valued and unitary, and (ii) one or more second linear operators that are non-unitary. An output vector sequence of a second recurrent neural network is generated. A transcription for the utterance is generated based on the output vector sequence generated by the second recurrent neural network. The transcription for the utterance is provided.","['G10L15/16', 'G06N3/02', 'G10H1/00', 'G10L15/02', 'G10L19/0212', 'G10H2210/036', 'G10H2210/046', 'G10H2250/235', 'G10H2250/311', 'G10L17/18', 'G10L25/30']"
US11074495B2,System and method for extremely efficient image and pattern recognition and artificial intelligence platform,"Specification covers new algorithms, methods, and systems for: Artificial Intelligence; the first application of General-AI (versus Specific, Vertical, or Narrow-AI) (as humans can do); addition of reasoning, inference, and cognitive layers/engines to learning module/engine/layer; soft computing; Information Principle; Stratification; Incremental Enlargement Principle; deep-level/detailed recognition, e.g., image recognition (e.g., for action, gesture, emotion, expression, biometrics, fingerprint, tilted or partial-face, OCR, relationship, position, pattern, and object); Big Data analytics; machine learning; crowd-sourcing; classification; clustering; SVM; similarity measures; Enhanced Boltzmann Machines; Enhanced Convolutional Neural Networks; optimization; search engine; ranking; semantic web; context analysis; question-answering system; soft, fuzzy, or un-sharp boundaries/impreciseness/ambiguities/fuzziness in class or set, e.g., for language analysis; Natural Language Processing (NLP); Computing-with-Words (CWW); parsing; machine translation; music, sound, speech, or speaker recognition; video search and analysis (e.g. tracking); image annotation; image or color correction; data reliability; Z-Number; Z-Web; Z-Factor; rules engine; playing games; control system; autonomous vehicles or drones; self-diagnosis and self-repair robots; system diagnosis; medical diagnosis; genetics; drug discovery; biomedicine; data mining; event prediction; financial forecasting (e.g., for stocks); economics; risk assessment; fraud detection (e.g., for cryptocurrency); e-mail management; database management; indexing and join operation; memory management; data compression; event-centric social network; social behavior; and Image Ad and Referral Networks.","['G06N3/0454', 'G06V10/82', 'G06F18/2413', 'G06K9/00281', 'G06K9/3233', 'G06K9/627', 'G06K9/66', 'G06N3/043', 'G06N3/0436', 'G06N3/045', 'G06V10/25', 'G06V10/764', 'G06V40/171', 'G06K9/4628', 'G06V10/454']"
RU2698402C1,Method of training a convolutional neural network for image reconstruction and a system for forming an image depth map (versions),FIELD: image processing means.,"['G06T7/593', 'G06N3/08', 'G06T3/02', 'G06T3/4007', 'G06T7/80', 'H04N13/128', 'H04N13/239', 'H04N13/271', 'G06T2207/10012', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'H04N2013/0081']"
US20250077277A1,Neural network processor capable of reusing memory address value,"A neural network processing unit (NPU) includes a processing element array, a SRAM memory configured to store at least one data of the artificial neural network model processed in the processing element array; and an NPU scheduler configured to control the processing element array and the SRAM memory based on predefined operation order information of the artificial neural network model processed by the processing element array and the NPU scheduler is configured to reuse a memory address value in which an operation value of a first layer of a first scheduling is stored as a memory address value corresponding to an input data of a second layer of a second scheduling, which is a next scheduling of the first scheduling.","['G06N3/045', 'G06F15/80', 'G06F7/5443', 'G06F9/4881', 'G06N3/04', 'G06N3/0463', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'Y02D10/00']"
US20210385502A1,Method and device for evaluating subjective quality of video,"Proposed are a method and apparatus for evaluating the quality of an image, the method including obtaining blocks each having a predetermined size by splitting a target image for evaluating a quality and a reference image that is to be compared with the target image, determining sensitivity information and quality assessment information of each of the blocks by inputting the blocks to a video quality assessment network, and determining a final image quality assessment score of the target image by combining the pieces of quality assessment information of the blocks with each other, based on the pieces of sensitivity information of the blocks.","['H04N19/46', 'G06N3/02', 'G06N3/045', 'G06N3/084', 'H04N19/132', 'H04N19/154', 'H04N19/184', 'H04N19/85']"
CN109451308B,"Video compression processing method and device, electronic device and storage medium","The embodiment of the invention discloses a video compression processing method and device, electronic equipment and a storage medium. The video compression processing method comprises the following steps: and performing video compression by using an end-to-end model obtained by training by adopting a single loss function to obtain video compression information.","['H04N19/139', 'H04N19/51', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'H04N19/105', 'H04N19/117', 'H04N19/124', 'H04N19/132', 'H04N19/137', 'H04N19/147', 'H04N19/172']"
WO2020063715A1,Method and system for training binary quantized weight and activation function for deep neural networks,"A method of training a neural network (NN) block for a neural network, including: performing a first quantization operation on a real-valued feature map tensor to generate a corresponding binary feature map tensor; performing a second quantization operation on a real-valued weight tensor to generate a corresponding binary weight tensor; convoluting the binary feature map tensor with the binary weight tensor to generate a convoluted output; scaling the convoluted output with a scaling factor to generate a scaled output, wherein the scaled output is equal to an estimated weight tensor convoluted with the binary feature map tensor, the estimated weight tensor corresponding to a product of the binary weight tensor and the scaling factor; calculating a loss function, the loss function including a regularization function configured to train the scaling factor so that the estimated weight tensor is guided towards the real-valued weight tensor; and updating the real-valued weight tensor and scaling factor based on the calculated loss function.","['G06N3/082', 'G06N3/08', 'G06F17/15', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/084', 'G06N3/044']"
US11470356B2,Method and apparatus of neural network for video coding,"A method and apparatus of video encoding video coding for a video encoder or decoder using Neural Network (NN) are disclosed. According to this method, the multiple frames in a video sequence comprises multiple segments, where each of the multiple segments comprises a set of frames. The NN (Neural Network) processing is applied to a target signal in one or more encoded frames of a target segment in the encoder side or to the target signal in one or more decoded frames of the target segment in the decoder side using one NN parameter set for the target segment. The target signal may correspond to reconstructed residual, reconstructed output, de-blocked output, SAO (sample adaptive offset) output, ALF (adaptive loop filter) output, or a combination thereof. In another embodiment, the NN processing is applied to a target signal only in one or more specific encoded or decoded frames.","['H04N19/70', 'G06N3/04', 'H04N19/82', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084']"
US20250086445A1,Inner product convolutional neural network accelerator,"A convolutional neural network (CNN) accelerator, including: a CNN circuit for performing a multiple-layer CNN computation, wherein the multiple layers are to receive an input feature according to an input feature map (IFM) and a weight matrix per output feature, wherein an output of a first layer provides an input for a next layer; and a mapping circuit to access a three-dimensional input matrix stored as a Z-major matrix; wherein the CNN circuit is to perform an inner-product direct convolution on the Z-major matrix, wherein the direct convolution lacks a lowering operation.","['G06N3/063', 'G06F16/17', 'G06F18/21', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V10/82', 'G06V10/955']"
US12114986B2,System and method for biometric data capture for event prediction,"A computer implemented system for automatically recording and generating predictive outputs relating to a medical procedure is described. The system is augmented with biometric sensory data from a biometric sensor coupled to a body of a healthcare practitioner. The biometric sensory data is processed to obtain one or more time-synchronized data objects providing a proxy to an estimated stress level associated with the healthcare practitioner, and the one or more time-synchronized data objects are utilized to identify abnormality-related durations of time encapsulated in the form of time-based metadata tags. The time-based metadata tags are utilized to automatically modify characteristics of the recording or generating of predictive outputs to temporarily consume more computational processing resources during the abnormality-related durations of time.","['A61B5/0077', 'A61B5/364', 'A61B5/02405', 'A61B5/352', 'G06F16/7834', 'G06F16/7867', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/043', 'G06N3/044', 'G06N5/048']"
US12079705B2,Deep learning for credit controls,Systems and methods are provided to identify abnormal transaction activity by a participant that is inconsistent with current conditions. Historical participant and external data are identified. A recurrent neural network identifies patterns in the historical participant and external data. A new transaction by the participant is received. The new transaction is compared using the patterns to the historical participant and external data. An abnormality score is generated. An alert is generated if the abnormality score exceeds a threshold.,"['G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06Q40/04']"
US10859657B2,"MRI reconstruction using deep learning, generative adversarial network and acquisition signal model","A method for diagnostic imaging includes measuring undersampled data y with a diagnostic imaging apparatus; linearly transforming the undersampled data y to obtain an initial image estimate {tilde over (x)}; applying the initial image estimate {tilde over (x)} as input to a generator network to obtain an aliasing artifact-reduced image x̆ as output of the generator network, where the aliasing artifact-reduced image x̆ is a projection onto a manifold of realistic images of the initial image estimate {tilde over (x)}; and performing an acquisition signal model projection of the aliasing artifact-reduced x̆ onto a space of consistent images to obtain a reconstructed image {circumflex over (x)} having suppressed image artifacts.","['G01R33/5608', 'A61B5/055', 'G01R33/4818', 'G01R33/483', 'G01R33/5611', 'G06T7/0012', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G06T2207/20081', 'G06T2207/20084']"
US10698766B2,Optimization of checkpoint operations for deep learning computing,"Systems and methods are provided to optimize checkpoint operations for deep learning (DL) model training tasks. For example, a distributed DL model training process is executed to train a DL model using multiple accelerator devices residing on one or more server nodes, and a checkpoint operation is performed to generate and store a checkpoint of an intermediate DL model. A checkpoint operation includes compressing a checkpoint of an intermediate DL model stored in memory of a given accelerator device to generate a compressed checkpoint, and scheduling a time to perform a memory copy operation to transfer a copy of the compressed checkpoint from the memory of the given accelerator device to a host system memory. The scheduling is performed based on information regarding bandwidth usage of a communication link to be utilized to transfer the compressed checkpoint to perform the memory copy operation, wherein the memory copy operation is performed at the scheduled time.","['G06F11/1407', 'G06F18/2148', 'G06F9/461', 'G06F9/4881', 'G06K9/6257', 'G06N20/00', 'G06N3/084', 'G06T1/20', 'G06T1/60', 'G06F2209/485', 'G06N3/045']"
US12106216B2,Fakecatcher: detection of synthetic portrait videos using biological signals,"Detection of synthetic content in portrait videos, e.g., deep fakes, is achieved. Detectors blindly utilizing deep learning are not effective in catching fake content, as generative models produce realistic results. However, biological signals hidden in portrait videos which are neither spatially nor temporally preserved in fake content, can be used as implicit descriptors of authenticity. 99.39% accuracy in pairwise separation is achieved. A generalized classifier for fake content is formulated by analyzing signal transformations and corresponding feature sets. Signal maps are generated, and a CNN employed to improve the classifier for detecting synthetic content. Evaluation on several datasets produced superior detection rates against baselines, independent of the source generator, or properties of available fake content. Experiments and evaluations include signals from various facial regions, under image distortions, with varying segment durations, from different generators, against unseen datasets, and under several dimensionality reduction techniques.","['G06N3/08', 'G06F18/2411', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V40/161', 'G06V40/169', 'G06V40/40', 'G06V40/45', 'G06N20/10', 'G06V40/15']"
CN110309847B,Model compression method and device,"The embodiment of the invention discloses a model compression method and a device, wherein the method comprises the following steps: the terminal acquires the global parameter of the kth training period sent by the server; the terminal updates a local model of the terminal according to the global parameter of the kth training period; the terminal trains the updated local model by using the training data set of the terminal to obtain a second local parameter of a (k +1) th training period of the trained local model; for the convolution kernel of at least one convolution layer of the local model of the terminal, the terminal determines the contribution degree of the convolution kernel on the convolution layer according to the second local parameter of the (k +1) th training period of the convolution kernel; and the terminal reports a second local parameter of the convolution kernel with the contribution degree meeting the set condition to the server as a first local parameter of the (k +1) th training period of the terminal.","['G06F18/214', 'G06F18/23', 'G06N3/045', 'G06N3/08']"
US12317297B2,Artificial intelligence capability reporting for wireless communication,"Various aspects of the present disclosure relate to reporting of AI capabilities between network nodes, such as between a user equipment (UE) and a base station. A UE, for instance, generates a capability report that specifies whether the UE supports AI-enabled functionality and/or specific supported and non-supported AI-enabled features. The UE communicates the capability report to a base station and supported AI features can be implemented in conjunction with wireless communication between the UE and the base station, such as by the UE, by the base station, and/or cooperatively between the UE and the base station.","['H04W72/51', 'G06N3/063', 'H04W48/14', 'H04W48/16', 'H04W8/22', 'H04W8/24', 'H04W24/02']"
CN116458103B,A neural network training method and related device,"A training method of a neural network and a related device are provided, wherein the method comprises the steps that a first device receives first channel sample information from a second device, the first device determines the first neural network, the first neural network is trained according to the first channel sample information, and the first neural network is used for reasoning to obtain second channel sample information according to the first channel sample information. By the method, the overhead of the air interface signaling can be effectively reduced, the channel environment can be adapted, and the communication performance is improved.","['G06N3/0455', 'H04L25/0224', 'H04L25/0254', 'G06N3/045', 'H04B7/0626', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/094', 'H04B7/0619', 'H04L27/2626', 'H04L27/2647', 'H04L5/0048', 'H04L5/0051', 'H04L5/0057']"
US11575938B2,Cascaded prediction-transform approach for mixed machine-human targeted video coding,"Data may be encoded to minimize distortion after decoding, but the quality required for presentation of the decoded data to a machine and the quality required for presentation to a human may be different. To accommodate different quality requirements, video data may be encoded to produce a first set of encoded data and a second set of encoded data, where the first set may be decoded for use by one of a machine consumer or a human consumer, and a combination of the first set and the second set may be decoded for use by the other of a machine consumer or a human consumer. The first and second set may be produced with a neural encoder and a neural decoder, and/or may be produced with the use of prediction and transform neural network modules. A human-targeted structure and a machine-targeted structure may produce the sets of encoded data.","['H04N19/619', 'H04N19/30', 'H04N19/124', 'H04N19/134', 'H04N19/176', 'H04N19/192']"
US11805091B1,Social topical context adaptive network hosted system,"Disclosed is a Social-Topical Adaptive Networking (STAN) system that can inform users of cross-correlations between currently focused-upon topic or other nodes in a corresponding topic or other data-objects organizing space maintained by the system and various social entities monitored by the system. More specifically, one of the cross-correlations may be as between the top N now-hottest topics being focused-upon by a first social entity and amounts of focus ‘heat’ that other social entities (e.g., friends and family) are casting on the same topics in a relavant time period.","['H04L51/52', 'G06Q10/10', 'H04L12/1818', 'H04L67/306', 'H04N21/8358', 'H04L67/02']"
US20200329233A1,"Hyperdata Compression: Accelerating Encoding for Improved Communication, Distribution & Delivery of Personalized Content","A system and method for coding, encrypting, and distributing personalized content with substantial improvements in perceptual quality while reducing coding times, file sizes for storage, bandwidth requirements for distribution and utilization. Incorporating feature selection, extraction, classification, detection, and attribution to facilitate authenticity, feature detection for multi-media communications, providing enhance encrypting and distributing of personalized content in for a myriad of application areas including, but not limited to, medicine, science, robotics. Artificial Intelligence, nanotechnology, quantum computing, biotechnology, the Internet of Things, The Network of Things, fifth-generation wireless technologies (5G), additive manufacturing/3D printing, fully autonomous vehicles, drones, digital education, personalized data, Smart Grids, Smart Cities, and Smart Venues.","['H04N19/105', 'H04N19/103', 'H04N19/136', 'H04N19/157', 'H04N19/169', 'H04N19/176', 'H04N19/463']"
US10726560B2,Real-time mobile device capture and generation of art-styled AR/VR content,"Various embodiments describe systems and processes for generating AR/VR content. In one aspect, a method for generating a 3D projection of an object in a virtual reality or augmented reality environment comprises obtaining a sequence of images along a camera translation using a single lens camera. Each image contains a portion of overlapping subject matter, including the object. The object is segmented from the sequence of images using a trained segmenting neural network to form a sequence of segmented object images, to which an art-style transfer is applied using a trained transfer neural network. On-the-fly interpolation parameters are computed and stereoscopic pairs are generated for points along the camera translation from the refined sequence of segmented object images for displaying the object as a 3D projection in a virtual reality or augmented reality environment. Segmented image indices are mapped to a rotation range for display in the virtual reality or augmented reality environment.","['G06T7/174', 'G06V20/70', 'G06F16/532', 'G06F16/5838', 'G06F16/738', 'G06F16/783', 'G06K9/00671', 'G06T3/4038', 'G06V20/20', 'H04N13/243', 'H04N13/279', 'H04N13/282', 'H04N23/698', 'H04N5/23238', 'H04N5/265']"
US12080024B2,Systems and methods for generating 3D models from drone imaging,A method comprising receiving a plurality of images of a scene captured by at least one drone; identifying features within the plurality of images; identifying similar images of the plurality of images based on the features identified within the plurality of images; comparing the similar images based on the features identified within the similar images to determine a proportion of features shared by the similar images; selecting a subset of the plurality of images that have a proportion of shared features that meets a predetermined range; generating a first 3D model of the scene from the subset of images using a first 3D model building algorithm; generating a second 3D model of the scene from the subset of images using a second 3D model building algorithm; computing errors for the first and second 3D models; and selecting as the model of the scene the first or second 3D model.,"['B64C39/024', 'G01C15/002', 'G05D1/0027', 'G05D1/104', 'G05D1/692', 'G05D1/695', 'G06N20/00', 'G06T17/10', 'G06T7/55', 'G06T7/579', 'G06T7/73', 'G06V20/17', 'G08G5/0013', 'G08G5/0026', 'G08G5/0039', 'G08G5/0043', 'G08G5/0069', 'G08G5/22', 'G08G5/26', 'G08G5/34', 'G08G5/55', 'G08G5/56', 'G08G5/57', 'H04B17/27', 'H04B17/318', 'H04B17/3913', 'H04B7/18504', 'H04W24/08', 'H04W28/24', 'H04W4/025', 'H04W4/029', 'H04W4/40', 'H04W64/003', 'H04W64/006', 'B64U10/13', 'B64U10/14', 'B64U2101/20', 'B64U2101/30', 'B64U2201/00', 'B64U2201/102', 'B64U80/86', 'G05D1/042', 'G05D1/46', 'G05D2109/20', 'G06T2207/10016', 'G06T2207/10032', 'G06T2207/20084', 'H04W84/047', 'H04W84/12']"
US11791871B2,Parallel precoding for downlink transmission,"Apparatuses, systems, and techniques to determine precoding weights for fifth-generation (5G) new radio (NR) downlink transmission in parallel. In at least one embodiment, a parallel processor includes one or more circuits to perform precoding for a 5G downlink signal using two or more processing threads in parallel.","['H04B7/0617', 'H04B7/0456', 'G06F17/16', 'G06F9/466', 'H04B7/043', 'H04B7/0452', 'H04W72/23']"
CN109284606B,Data Stream Anomaly Detection System Based on Empirical Features and Convolutional Neural Network,"The invention discloses a data flow anomaly detection system based on empirical characteristics and a convolutional neural network. The system comprises an empirical characteristic extraction module, a packet header identification module and a packet identifier module, wherein the empirical characteristic extraction module is used for identifying statistical characteristics and packet header characteristics with large data packet anomaly identification functions as characteristics based on artificial experience; the bit stream conversion picture module is used for converting the data stream into a two-dimensional gray picture form, and then extracting global high-level perception features through convolutional neural network perception; the fusion splicing module is used for fusing the modules as data stream characteristics and identifying abnormal data streams by utilizing a full connection layer of a neural network; a distillation model module to replace the complex network when actually deployed; the concept drift fine adjustment module updates the detection model for the concept drift; and updating the experience database module, and adding a new network attack or hidden attack instruction into the artificial experience database. The invention can accurately and efficiently detect abnormal behaviors such as network faults, user misoperation, network attacks and the like.","['G06F21/55', 'G06F18/2411', 'G06N3/045', 'G06N3/08']"
CN110796190B,Exponential modeling with deep learning features,"Aspects of the present disclosure enable artificially specified relationships to facilitate implementing a mapping that enables compression of an output structure of a machine learning model. An exponential model, such as a maximum entropy model, may utilize machine learning embedding and mapping to produce classification outputs. In this way, feature discovery functions of a machine learning model (e.g., a deep network) may be synergistically combined with relationships developed based on understanding of the structural properties of a human to-be-solved problem, enabling compression of the model output structure without significant loss of accuracy. These compression models improve the applicability of ""on-device"" or other resource-constrained scenarios.","['G06F18/2415', 'G06N3/084', 'G06F18/2431', 'G06N20/00', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/063', 'G06N3/082', 'G06N3/09', 'G06N20/10']"
US10509846B2,Accelerator for processing data,"An accelerator for increasing the processing speed of a processor. The accelerator operates in two distinct modes. In a first mode for dense layer processing, row data sets and column data sets are sent to a multiplier for multiplication. In a second mode for sparse layer processing compressed row data sets are received by a row multiplexer and compressed column data sets are received by a column multiplexer. Each multiplexer is configured to compare the indexes of data sets with one another to determine matching indexes. When indexes match, the matching data sets are selected and sent to the multiplier for multiplication. When indexes do not match, data sets are stored in memory devices for subsequent cycles.","['G06F17/16', 'G06F7/523', 'G06F7/5443', 'G06N3/04', 'G06N3/063', 'G06N3/08', 'G06F9/30007', 'G06N3/02']"
US11876949B2,Layered scene decomposition CODEC with transparency,"A system and methods for a CODEC driving a real-time light field display for multi-dimensional video streaming, interactive gaming and other light field display applications is provided applying a layered scene decomposition strategy. Multi-dimensional scene data including information on transparency of surfaces is divided into a plurality of data layers of increasing depths as the distance between a given layer and the display surface increases. Data layers are sampled using a plenoptic sampling scheme and rendered using hybrid rendering, such as perspective and oblique rendering, to encode light fields corresponding to each data layer. The resulting compressed, (layered) core representation of the multi-dimensional scene data is produced at predictable rates, reconstructed and merged at the light field display in real-time by applying view synthesis protocols, including edge adaptive interpolation, to reconstruct pixel arrays in stages (e.g. columns then rows) from reference elemental images.","['H04N19/597', 'H04N13/161', 'G06T15/06', 'G06T17/00', 'G06T7/557', 'H04N13/302', 'H04N19/119', 'H04N19/132', 'H04N19/146', 'H04N19/172', 'H04N19/187', 'H04N19/33', 'H04N2013/0088']"
US11017506B2,Video enhancement using a generator with filters of generative adversarial network,"Techniques for enhancing an image are described. For example, a lower-resolution image, for example from a video file, may be enhanced using a trained neural network by applying the trained neural network to enhance a middle lower-resolution image of a plurality of lower-resolution images using a generator with filters of a generative adversary network. In some examples, a plurality of sequential feature processing acts are performed on the lower-resolution images to generate a residual which is added to a filtered version of one of the lower-resolution images to generate an enhanced image.","['G06T5/005', 'G06T5/20', 'G06K9/00201', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/088', 'G06T5/60', 'G06T5/77', 'G06V10/764', 'G06V10/776', 'G06V10/82', 'G06V20/46', 'G06V20/64', 'G06N3/086', 'G06T2207/20084']"
US20250038816A1,Pre-processing for csi compression in wireless systems,"Systems, methods, and instrumentalities are disclosed herein for pre-processing for channel state information (CSI) compression in wireless system. A WTRU may receive configuration information that indicates a reference signal and a data processing model for channel state information (CSI) compression. The WTRU may determine CSI associated with a channel using the reference signal. The WTRU may determine a channel condition associated with pre-processing. The WTRU may select a pre-processing type from a plurality of pre-processing types based on the data processing model and the determined channel condition associated with pre-processing. The WTRU may pre-process the CSI associated with the channel based on the selected pre-processing type. The WTRU may generate compressed CSI by compressing the pre-processed CSI using the data processing model for CSI compression. The WTRU may send the compressed CSI to a network.","['H04B7/0417', 'H04B7/0658', 'G06N3/0455', 'H03M7/3059', 'H03M7/6076', 'H03M7/70', 'H04B7/0626', 'H03M7/3073']"
US11676310B2,System and methods for encoding octree structured point cloud data using an entropy model,"The present disclosure is directed encoding LIDAR point cloud data. In particular, a computing system can receive point cloud data for a three-dimensional space. The computing system can generate a tree-based data structure from the point cloud data, the tree-based data structure comprising a plurality of nodes. The computing system can generate a serial representation of the tree-based data structure. The computing system can, for each respective node represented by a symbol in the serial representation: determine contextual information for the respective node, generate, using the contextual information as input to a machine-learned model, a statistical distribution associated with the respective node, and generate a compressed representation of the symbol associated with the respective node by encoding the symbol using the statistical distribution for the respective node. The computing system can generate a compressed bitstream by sequentially ordering a plurality of compressed representations associated with the plurality of symbols.","['G06T9/40', 'B60W40/10', 'G01S17/89', 'G06N3/08', 'G06N3/084', 'G06N5/046', 'G06T17/005', 'G06T3/4046', 'G06T9/001', 'G06T9/002', 'G01S7/4808', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
CN111598026B,"Action recognition method, device, equipment and storage medium","The embodiment of the invention discloses a method, a device, equipment and a storage medium for identifying actions. Wherein the method comprises the following steps: the method comprises the steps of carrying out grouping processing on original compressed video data to obtain grouped video data, inputting the grouped video data into a first preset model, determining target grouped video data containing actions according to an output result of the first preset model, decoding the target grouped video data to obtain grouped video data to be identified, inputting the grouped video data to be identified into a second preset model, and determining action types contained in the grouped video data to be identified according to an output result of the second preset model. According to the technical scheme provided by the embodiment of the invention, before the compressed video is decompressed, the video segments containing the actions are roughly screened out by using the first preset model, and then the specific types of the actions contained are accurately identified by using the second preset model, so that the calculated amount can be effectively reduced on the premise of ensuring the identification precision, and the action identification efficiency is improved.","['G06N3/045', 'G06N3/08', 'G06V10/764', 'G06V10/7715', 'G06V10/806', 'G06V10/82', 'G06V20/40', 'G06V20/41', 'G06V20/44', 'G06V20/46', 'G06V20/49', 'G06V40/20', 'H04N19/172', 'H04N19/513', 'H04N19/52']"
US11862188B2,Method for detecting and classifying coughs or other non-semantic sounds using audio feature set learned from speech,"A method of detecting a cough in an audio stream includes a step of performing one or more pre-processing steps on the audio stream to generate an input audio sequence comprising a plurality of time-separated audio segments. An embedding is generated by a self-supervised triplet loss embedding model for each of the segments of the input audio sequence using an audio feature set, the embedding model having been trained to learn the audio feature set in a self-supervised triplet loss manner from a plurality of speech audio clips from a speech dataset. The embedding for each of the segments is provided to a model performing cough detection inference. This model generates a probability that each of the segments of the input audio sequence includes a cough episode. The method includes generating cough metrics for each of the cough episodes detected in the input audio sequence.","['G10L25/66', 'A61B5/0823', 'A61B5/4803', 'A61B5/6898', 'A61B5/7267', 'A61B5/7282', 'G10L15/02', 'G10L15/04', 'G10L15/063', 'G10L25/30', 'G10L25/51', 'G10L25/78', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H50/70', 'A61B5/0022']"
US11029685B2,Autonomous risk assessment for fallen cargo,"A method for detecting fallen cargo, the method may include receiving by a computerized system, sensed information related to driving sessions of multiple vehicles; applying a machine learning process on the sensed information to detect fallen cargo and to classify the fallen cargo to fallen cargo classes; estimating, from the sensed information, an impact of at least some of the fallen cargo classes on a behavior of at least some of the multiple vehicles; and determining, based on the impact, at least one suggested vehicle behavior as a response to a detection of at least some of the fallen cargo classes.","['B60W60/0025', 'G05D1/0061', 'B60W40/02', 'B60W50/14', 'B60W60/0017', 'G05D1/0044', 'G05D1/0088', 'G05D1/0214', 'G05D1/0293', 'G06F18/23', 'G06F18/23213', 'G06K9/00791', 'G06K9/00805', 'G06K9/00825', 'G06K9/00845', 'G06K9/6201', 'G06K9/6218', 'G06K9/6223', 'G06K9/628', 'G06N3/0427', 'G06N3/045', 'G06V10/255', 'G06V10/454', 'G06V20/58', 'G06V20/597', 'G08G1/056', 'G08G1/162', 'G08G1/165', 'G08G1/166', 'G08G1/22', 'B60W2040/0872', 'B60W2540/10', 'B60W2540/12', 'B60W2540/18', 'B60W2554/00', 'B60W2554/4023', 'B60W2554/4046', 'B60W2556/65', 'B60W30/09', 'B60W30/0956', 'B60W40/06', 'B60W40/08', 'B60W60/0011', 'B60W60/0016', 'B60W60/0051', 'G05B13/029', 'G05D1/225', 'G05D1/617', 'G05D1/695', 'G05D1/81', 'G05D2201/0213', 'G06F18/22', 'G06F18/2431', 'G06K2009/6213', 'G06N20/00', 'G06N3/042', 'G06N3/08', 'G06N5/04', 'G06T2207/30261', 'G06V10/759', 'G06V20/56', 'G06V20/584', 'G07C5/02', 'G08G1/048', 'G08G1/09626', 'H04W4/46']"
US11637762B2,MDL-based clustering for dependency mapping,"Systems and methods are provided for automatically discovering applications/clusters in a network and mapping dependencies between the applications/clusters. A network monitoring system can capture network flow data using sensors executing on physical and/or virtual servers of the network and sensors executing on networking devices connected to the servers. The system can determine a graph including nodes, representing at least the servers, and edges, between pairs of the nodes of the graph indicating the network flow data includes one or more observed flows between pairs of the servers represented by the pairs of the nodes. The system can determine a dependency map, including representations of clusters of the servers and representations of dependencies between the clusters, based on the graph. The system can display a first representation of a first cluster of the dependency map and information indicating a confidence level of identifying the first cluster.","['G06F9/45558', 'G06F16/122', 'G06F16/137', 'G06F16/162', 'G06F16/17', 'G06F16/173', 'G06F16/174', 'G06F16/1744', 'G06F16/1748', 'G06F16/2322', 'G06F16/235', 'G06F16/2365', 'G06F16/24578', 'G06F16/248', 'G06F16/285', 'G06F16/288', 'G06F16/29', 'G06F16/9535', 'G06F21/53', 'G06F21/552', 'G06F21/556', 'G06F21/566', 'G06F3/0482', 'G06F3/04842', 'G06F3/04847', 'G06N20/00', 'G06N99/00', 'G06T11/206', 'H04J3/0661', 'H04J3/14', 'H04L1/242', 'H04L41/046', 'H04L41/0668', 'H04L41/0803', 'H04L41/0806', 'H04L41/0816', 'H04L41/0893', 'H04L41/0894', 'H04L41/12', 'H04L41/16', 'H04L41/22', 'H04L41/40', 'H04L43/02', 'H04L43/026', 'H04L43/04', 'H04L43/045', 'H04L43/062', 'H04L43/08', 'H04L43/0805', 'H04L43/0811', 'H04L43/0829', 'H04L43/0841', 'H04L43/0858', 'H04L43/0864', 'H04L43/0876', 'H04L43/0882', 'H04L43/0888', 'H04L43/10', 'H04L43/106', 'H04L43/12', 'H04L43/16', 'H04L43/20', 'H04L45/306', 'H04L45/38', 'H04L45/46', 'H04L45/507', 'H04L45/66', 'H04L45/74', 'H04L47/11', 'H04L47/20', 'H04L47/2441', 'H04L47/2483', 'H04L47/28', 'H04L47/31', 'H04L47/32', 'H04L61/5007', 'H04L63/0227', 'H04L63/0263', 'H04L63/06', 'H04L63/0876', 'H04L63/1408', 'H04L63/1416', 'H04L63/1425', 'H04L63/1433', 'H04L63/1441', 'H04L63/145', 'H04L63/1458', 'H04L63/1466', 'H04L63/16', 'H04L63/20', 'H04L67/01', 'H04L67/10', 'H04L67/1001', 'H04L67/12', 'H04L67/51', 'H04L67/75', 'H04L69/16', 'H04L69/22', 'H04L7/10', 'H04L9/0866', 'H04L9/3239', 'H04L9/3242', 'H04W72/08', 'H04W72/54', 'H04W84/18', 'G06F2009/4557', 'G06F2009/45587', 'G06F2009/45591', 'G06F2009/45595', 'G06F2221/033', 'G06F2221/2101', 'G06F2221/2105', 'G06F2221/2111', 'G06F2221/2115', 'G06F2221/2145', 'H04L67/535']"
US10992331B2,Systems and methods for signaling for AI use by mobile stations in wireless networks,"A method in a user equipment (UE), involves configuring an artificial intelligence (AI) module in a UE to perform at least one task for wireless communications and then performing the task using the configured AI module. The AI module may be on a SIM card inserted into the UE, or part of an internal software implementation. Configuring the AI module can be based on default parameters stored in the UE, or based on signalling received from a network.","['H04B1/3816', 'G06N3/08', 'G06N3/045', 'G06N3/105', 'G06N5/02', 'H04L41/16', 'G06N20/10', 'G06N3/048', 'G06N7/01', 'H04W88/02']"
US10685235B2,Querying video data with reduced latency and cost,"A method can include classifying, using a compressed and specialized convolutional neural network (CNN), an object of a video frame into classes, clustering the object based on a distance of a feature vector of the object to a feature vector of a centroid object of the cluster, storing top-k classes, a centroid identification, and a cluster identification, in response to receiving a query for objects of class X from a specific video stream, retrieving image data for each centroid of each cluster that includes the class X as one of the top-k classes, classifying, using a ground truth CNN (GT-CNN), the retrieved image data for each centroid, and for each centroid determined to be classified as a member of the class X providing image data for each object in each cluster associated with the centroid.","['G06K9/00718', 'G06V20/70', 'G06F18/214', 'G06F18/23', 'G06F18/2411', 'G06F18/285', 'G06K9/00711', 'G06K9/6218', 'G06K9/6227', 'G06K9/6256', 'G06K9/6269', 'G06V10/762', 'G06V10/82', 'G06V10/87', 'G06V20/40', 'G06V20/41']"
CN110363294B,Representing a neural network with paths in the network to improve performance of the neural network,"An Artificial Neural Network (ANN) is a computing system that simulates a human brain by learning to perform tasks by taking into account examples. By representing the artificial neural network with respective paths that respectively connect the inputs of the ANN to the outputs of the ANN, the complexity of the ANN may be reduced, and the ANN may be trained and implemented in a much faster manner than an implementation using a fully connected ANN diagram.","['G06N3/088', 'G06N3/084', 'G06N3/063', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/082', 'G06N3/0895', 'G06N3/09', 'G06N3/092']"
TWI687063B,A communication system and codec method based on deep learning and channel state information,"A communication system and codec method based on deep learning and channel state information is disclosed. The communication system includes a first electronic apparatus and a second electronic apparatus. The first electronic apparatus includes a stored first link CSI and a CSI encoder with deep learning function. The second electronic apparatus includes a stored second link CSI and a CSI codec with deep learning function, and the first link CSI has a correlation or similarity with the second link CSI. The CSI encoder of the first electronic apparatus encodes or compresses the first link CSI into a first codeword to feedback the first codeword through a feedback-link to the second electronic apparatus. The CSI codec of the second electronic apparatus encodes or compresses the second link CSI into a second codeword, and decodes or restores the first link CSI of the first electronic apparatus according to the first codeword and the second codeword.","['H04B7/0626', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'H04B7/0417', 'H04B7/0478', 'H04B7/0658']"
WO2022022063A1,Three-dimensional human pose estimation method and related device,"A three-dimensional human pose estimation method and a related device, which relate to the field of artificial intelligence. Said method comprises: acquiring video frame sequences of n viewing-angles (110); extracting, on the basis of a neural network model, initialized pose estimation results of single video frames of the n viewing angles (120), the robustness of pose estimation of the neural network model being effectively utilized; performing single-frame and single-viewing-angle human pose estimation on the initialized pose estimation results, so as to obtain n single-viewing-angle pose estimation sequences respectively corresponding to the n viewing angles (130); according to single-viewing-angle pose estimation results having the same time stamp in the n single-viewing-angle pose estimation sequences, performing single-frame and multi-viewing-angle human pose estimation, so as to obtain multi-viewing-angle pose estimation sequences (140); and performing multi-frame and multi-viewing-angle human pose estimation on the multi-viewing-angle pose estimation results in the multi-viewing-angle pose estimation sequences, so as to obtain multi-viewing-angle and multi-frame pose estimation results (150). The present invention improves the accuracy of human pose estimation, avoiding the situation of single-frame and single-viewing-angle human pose estimation easily falling into a local extremum.","['G06V40/103', 'G06V40/10', 'G06N3/0464', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06V10/267', 'G06V10/803', 'G06V10/806', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/64']"
CN113450333B,Machine learning-based reinforced concrete column earthquake damage degree evaluation method,"The invention provides a reinforced concrete column earthquake damage degree evaluation method based on machine learning, which comprises the steps of firstly, obtaining an apparent earthquake damage parameter and a component parameter according to an apparent damage image of a whole process of a pseudo-static test of a reinforced concrete column component; then, establishing a comprehensive evaluation index of the earthquake damage degree of the reinforced concrete column, which has fixed upper and lower limits and can accurately reflect the nonlinear accelerated accumulation phenomenon of the member in the whole damage development process, according to the data of the pseudo-static test hysteresis curve of the reinforced concrete column member; and finally, establishing a deep neural network model of the comprehensive evaluation index of the apparent earthquake damage parameters, the component parameters and the earthquake damage degree, inputting the apparent damage parameters and the size information of the component into a trained machine learning model, directly predicting the earthquake damage degree of the component, finally realizing intelligent evaluation of the earthquake damage degree of the reinforced concrete column, and overcoming the defects of time and labor waste, insufficient accuracy and safety of a manual evaluation method based on expert experience.","['G06T7/0004', 'G06F30/27', 'G06N3/045', 'G06N3/08', 'G06F2119/04', 'G06F2119/14', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30132']"
US11582481B2,Encoding and decoding image data,"Certain aspects of the present disclosure provide techniques for encoding image data for one or more images. In one embodiment, a method includes the steps of downscaling the one or more images, and encoding the one or more downscaled images using an image codec. Another embodiment concerns a computer-implemented method of decoding encoded image data, and a computer-implemented method of encoding and decoding image data.","['H04N19/85', 'H04N19/59', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'H04N19/587', 'H04N19/80', 'G06N3/044', 'G06N3/049', 'H04N19/117', 'H04N19/147', 'H04N19/192']"
CN110069715B,"Information recommendation model training method, information recommendation method and device","The application discloses a method for training an information recommendation model, which comprises the following steps: acquiring data to be trained, wherein the data to be trained comprises first characteristic data and first label data; acquiring second characteristic data corresponding to the first characteristic data through an embedded layer in the information recommendation model to be trained, wherein the parameter of the embedded layer is a quantized parameter obtained by quantizing a full-precision parameter; acquiring second label data corresponding to the second characteristic data through a neural network in the information recommendation model to be trained; and training the information recommendation model to be trained according to the full-precision parameter, the first label data and the second label data to obtain the information recommendation model. The application also discloses an information recommendation method. The method and the device introduce the operation of the quantization embedding layer in the process of training the information recommendation model, effectively reduce the redundancy of parameters of the embedding layer, reduce the storage capacity and the transmission overhead of the model in a mode of quantizing the parameters, and are suitable for a large-scale online recommendation system.","['G06F16/9535', 'G06N3/08', 'G06Q30/0201']"
US11004560B2,Generating a map of a medical facility,"A computing device retrieves patient data for a plurality of patients assigned to healthcare unit of a medical facility, and scores a mortality risk of the patients from the patient data. The computing device then generates a map of the medical facility comprising an illustration of a layout of the medical facility, and a visual representation of an area within the illustration of the layout that indicates where the healthcare unit is located within the medical facility. The map further comprises a labeling of the healthcare unit with a visual indication of the mortality risk of the patients in the healthcare unit. The computing device then sends the map to a display device.","['G16H40/20', 'G16H10/60', 'G16H50/30', 'G16H20/10', 'G16H20/40']"
US12327404B2,Object detection apparatus using an image preprocessing artificial neural network model,An apparatus for recognizing an object in an image includes a preprocessing module configured to receive an image including an object and to output a preprocessed image by performing image enhancement processing on the received image to improve a recognition rate of the object included in the received image; and an object recognition module configured to recognize the object included in the image by inputting the preprocessed image to an input layer of an artificial neural network for object recognition.,"['G06V20/10', 'G06T7/11', 'G06V10/82', 'G06F18/2148', 'G06F18/217', 'G06F18/24', 'G06N3/045', 'G06N3/08', 'G06N5/041', 'G06T3/4015', 'G06T5/00', 'G06T5/60', 'G06T5/70', 'G06T5/73', 'G06T5/90', 'G06T5/92', 'G06T7/10', 'G06T7/74', 'G06V10/20', 'G06V10/7792', 'G06V10/95', 'G06V20/41', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US11140695B1,Wireless mesh network,"Among other things, aspects, features, and implementations of wireless mesh networks and wireless mesh network devices are described.","['H04W72/1257', 'H04W56/009', 'H04W72/535', 'H04W56/0045', 'H04W72/0433', 'H04W72/29', 'H04L12/4633', 'H04L5/1469', 'H04W84/18']"
US9095266B1,Method for treating a patient,"A signal processing method and system combines multi-scale decomposition, such as wavelet, pre-processing together with a compression technique, such as an auto-associative artificial neural network, operating in the multi-scale decomposition domain for signal denoising and extraction. All compressions are performed in the decomposed domain. A reverse decomposition such as an inverse discrete wavelet transform is performed on the combined outputs from all the compression modules to recover a clean signal back in the time domain. A low-cost, non-drug, non-invasive, on-demand therapy braincap system and method are pharmaceutically non-intrusive to the body for the purpose of disease diagnosis, treatment therapy, and direct mind control of external devices and systems. It is based on recognizing abnormal brainwave signatures and intervenes at the earliest moment, using magnetic and/or electric stimulations to reset the brainwaves back to normality. The feedback system is self-regulatory and the treatment stops when the brainwaves return to normal.","['A61B5/0476', 'A61B5/369', 'A61B5/0036', 'A61B5/0042', 'A61B5/0075', 'A61B5/246', 'A61B5/291', 'A61B5/316', 'A61B5/318', 'A61B5/377', 'A61B5/6803', 'A61B5/7203', 'A61B5/7235', 'A61N1/0408', 'A61N1/0476', 'A61N1/36021', 'A61N1/36025', 'A61N1/36031', 'A61N1/40', 'A61N2/006', 'A61N2/008', 'A61N2/02', 'A61N5/02', 'A61N5/10', 'A61N7/00', 'G16H20/40', 'G16H20/70', 'G16H50/20', 'G16Z99/00', 'A61B2560/0214', 'A61B2562/046', 'A61B2562/14', 'A61B2576/026', 'A61B5/165', 'A61B5/726', 'A61B5/7264', 'A61N1/0456', 'A61N1/0526']"
US11347994B2,Weight prefetch for in-memory neural network execution,"The present disclosure is directed to systems and methods of bit-serial, in-memory, execution of at least an nth layer of a multi-layer neural network in a first on-chip processor memory circuitry portion contemporaneous with prefetching and storing layer weights associated with the (n+1)st layer of the multi-layer neural network in a second on-chip processor memory circuitry portion. The storage of layer weights in on-chip processor memory circuitry beneficially decreases the time required to transfer the layer weights upon execution of the (n+1)st layer of the multi-layer neural network by the first on-chip processor memory circuitry portion. In addition, the on-chip processor memory circuitry may include a third on-chip processor memory circuitry portion used to store intermediate and/or final input/output values associated with one or more layers included in the multi-layer neural network.","['G06N3/04', 'G06N3/063', 'G06F12/0207', 'G06F12/0875', 'G06F3/061', 'G06F3/0655', 'G06F3/0683', 'G06N3/044', 'G06N3/0445', 'G06F2212/251']"
CN110197270B,Integrated circuit chip device and related product,"The present disclosure provides an integrated circuit chip device and related products, the device is used for training a neural network, the neural network comprises n layers, the value range of n is an integer greater than or equal to 2, the integrated circuit chip device comprises: a main processing circuit and a plurality of basic processing circuits; the main processing circuit includes a first mapping circuit, at least one of the plurality of basic processing circuits includes a second mapping circuit, and the first mapping circuit and the second mapping circuit are each configured to perform compression processing of respective data in a neural network operation. The technical scheme provided by the disclosure has the advantages of small calculation amount and low power consumption.","['G06N3/063', 'G06N3/08']"
US20230262448A1,Managing a wireless device that is operable to connect to a communication network,"Methods are provided for managing a wireless device that is operable to connect to a communication network comprising a Radio Access Network (RAN). One method, performed by a node of the communication network, comprises: selecting, on the basis at least of information about one or more of a behavior of the wireless device and a radio environment experienced by the wireless device, a machine-learning (ML) model from a plurality of candidate ML models to be downloaded to the wireless device, the candidate models providing outputs on the basis of which respective RAN operations performed by the wireless device are configured; and causing transmission of the selected ML model to the wireless device for execution by the wireless device.","['G06N3/08', 'H04W8/22', 'G06N20/00', 'G06N3/045', 'H04W64/006', 'H04W36/08', 'H04W48/20']"
US11729487B2,Image pickup apparatus and control method therefor,"An image pickup apparatus is configured to change a shooting process based on data on a shot image. The image pickup apparatus is configured to, when the image pickup apparatus changes the shooting process, assign greater weights to the data on the shot image based on an instruction from a user than to the data on the shot image automatically processed.","['H04N23/60', 'H04N23/62', 'G03B17/00', 'G03B15/00', 'G03B17/02', 'G03B17/56', 'G03B17/561', 'G03B5/00', 'G03B7/091', 'H04N23/50', 'H04N23/51', 'H04N23/54', 'H04N23/55', 'H04N23/56', 'H04N23/58', 'H04N23/61', 'H04N23/64', 'H04N23/667', 'H04N23/6812', 'H04N23/687', 'H04N23/69', 'H04N23/695', 'H04N23/80', 'G03B2205/0046']"
US11238331B2,System and method for augmenting an existing artificial neural network,"A novel and useful augmented artificial neural network (ANN) incorporating an existing artificial neural network (ANN) coupled to a supplemental ANN and a first-in first-out (FIFO) stack for storing historical output values of the network. The augmented ANN exploits the redundant nature of information present in an input data stream. The addition of the supplemental ANN along with a FIFO enables the augmented network to look back into the past in making a decision for the current frame. It provides context aware object presence as well as lowers the rate of false detections and misdetections. The output of the existing ANN is stored in a FIFO to create a lookahead system in which both past output values of the supplemental ANN and ‘future’ values of the output of the existing ANN are used in making a decision for the current frame. In addition, the mechanism does not require retraining the entire neural network nor does it require data set labeling.","['G06F12/0207', 'G06F12/02', 'G06F12/0646', 'G06F12/0692', 'G06F13/1663', 'G06F17/10', 'G06F30/27', 'G06F30/30', 'G06F5/01', 'G06F7/501', 'G06F7/523', 'G06F9/30054', 'G06F9/5016', 'G06F9/5027', 'G06K9/46', 'G06K9/62', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/082', 'Y02D10/00']"
US11537869B2,Difference metric for machine learning-based processing systems,"Systems and methods provide a learned difference metric that operates in a wide artifact space. An example method includes initializing a committee of deep neural networks with labeled distortion pairs, iteratively actively learning a difference metric using the committee and psychophysics tasks for informative distortion pairs, and using the difference metric as an objective function in a machine-learned digital file processing task. Iteratively actively learning the difference metric can include providing an unlabeled distortion pair as input to each of the deep neural networks in the committee, a distortion pair being a base image and a distorted image resulting from application of an artifact applied to the base image, obtaining a plurality of difference metric scores for the unlabeled distortion pair from the deep neural networks, and identifying the unlabeled distortion pair as an informative distortion pair when the difference metric scores satisfy a diversity metric.","['G06N3/08', 'G06F16/122', 'G06F16/54', 'G06N3/045', 'G06N3/0454']"
US8850048B2,Reciprocal addition of attribute fields in access control lists and profiles for femto cell coverage management,"Access management to femto cell service is provided through access control list(s) (e.g., white list(s), or black list(s)). White list(s) includes a set of subscriber station(s) identifier numbers, codes, or tokens, and also can include additional fields for femto cell access management based on desired complexity. White list(s) can have associated white list profile(s) therewith to establish logic of femto coverage access based on the white list(s). A mechanism for reciprocal addition of access field attributes in access control lists and white list profiles also is provided. The mechanism allows at least in part for a first subscriber to be added to a configured white list of a second subscriber, when the first subscriber configures a new white list, the second subscriber is reciprocally incorporated in the new white list. Such mechanism can be driven and facilitates generation of associations among groups of subscribers that share specific commonalities.","['G06Q20/1235', 'G06Q20/102', 'G06Q20/32', 'G06Q20/322', 'G06Q20/3223', 'G06Q20/387', 'G06Q20/405', 'G06Q30/02', 'G06Q30/0222', 'G06Q30/0261', 'G06Q30/0601', 'G07F9/001', 'G16H40/63', 'H04B1/3822', 'H04L41/0803', 'H04L5/0048', 'H04L63/04', 'H04L63/0853', 'H04L63/0876', 'H04L63/101', 'H04L63/102', 'H04L63/108', 'H04M15/73', 'H04W12/06', 'H04W12/08', 'H04W12/082', 'H04W12/088', 'H04W4/02', 'H04W4/023', 'H04W4/027', 'H04W4/029', 'H04W4/12', 'H04W4/14', 'H04W4/24', 'H04W4/40', 'H04W40/02', 'H04W48/02', 'H04W48/04', 'H04W48/08', 'H04W48/16', 'H04W48/20', 'H04W64/006', 'H04W68/02', 'H04W8/20', 'H04W8/22', 'H04W88/08', 'G05B2219/2614', 'G06F3/0484', 'H04L2209/80', 'H04W84/045', 'H04W88/02', 'H04W88/06']"
US11375527B1,Wireless mesh network,"Among other things, aspects, features, and implementations of wireless mesh networks and wireless mesh network devices are described.","['H04W72/1273', 'H04B7/15528', 'H04W84/18', 'H04W88/16']"
US20200219232A1,Method and apparatus for streaming data,"A terminal for receiving streaming data may receive information of a plurality of different quality versions of an image content; request, based on the information, a server for a version of the image content from among the plurality of different quality versions of the image content; when the requested version of the image content and artificial intelligence (AI) data corresponding to the requested version of the image content are received, determines whether to perform AI upscaling on the received version of the image content, based on the AI data; and based on a result of the determining whether to perform AI upscaling, performs AI upscaling on the received version of the image content through a upscaling deep neural network (DNN) that is trained jointly with a downscaling DNN of the server.","['G06T3/4046', 'H04L65/602', 'H04L65/607', 'H04L65/61', 'H04L65/70', 'H04L65/762', 'H04L65/80', 'H04N19/117', 'H04N19/132', 'H04N19/154', 'H04N19/172', 'H04N19/46', 'H04N19/463', 'H04N19/59', 'H04N19/80', 'H04N19/85', 'H04N21/234363', 'H04N21/23439', 'H04N21/251', 'H04N21/26258', 'H04N21/440263', 'H04N21/8193', 'H04N19/14', 'H04N19/146', 'H04N19/166']"
US11979350B1,Wireless mesh network,"Among other things, aspects, features, and implementations of wireless mesh networks and wireless mesh network devices are described.","['H04L5/005', 'H04J11/0073', 'G06N3/044', 'H04B7/0413', 'H04B7/0626', 'H04B7/0691', 'H04B7/0874', 'H04B7/088', 'H04J11/0079', 'H04L1/1819', 'H04L1/1822', 'H04L1/1854', 'H04L1/189', 'H04L25/0226', 'H04L41/16', 'H04L5/0023', 'H04L5/0053', 'H04L5/0062', 'H04W36/085', 'H04W80/02', 'G06N3/048', 'G06N3/084', 'H04L5/0007', 'H04L5/0055', 'H04W24/08', 'H04W36/083', 'H04W48/12', 'H04W72/54', 'H04W84/045', 'H04W84/18']"
US11822579B2,"Apparatus for functioning as sensor node and data center, sensor network, communication method and program","Provided is a sensor network capable of acquiring, from a data center, learning data composed of a pair of sensor data (input) and a classification label (output) necessary for adding/changing a classification label for updating a classifier while reducing the volume of communication between a sensor and the center. One aspect of the present invention relates to a sensor network, including one or more sensor nodes and a data center. The sensor node includes: an encoding unit for encoding sensor data by an encoder part of an autoencoder; and a transmission unit for transmitting the encoded data. The data center includes: a reception unit for receiving data encoded from sensor data by the encoder part of the autoencoder; a decoding unit for decoding the encoded data by a decoder part of the autoencoder; and a storage unit for storing the decoded data therein.","['G06F16/285', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G08C15/00', 'H03M7/30']"
US10565207B2,"Method, system and program product for mask-based compression of a sparse matrix","A method, system and program product includes examining elements of a first matrix in a sequential fashion. Values of the examined elements are determined. A corresponding bit of a first mask is set to a first value if a determined value is zero. A corresponding bit of a first mask is set to a second value if a determined value is non-zero. The non-zero values are packed in a first vector, wherein bits of at least the first mask determine operations on packed values.","['G06F16/24561', 'H03M7/30', 'H03M7/3066', 'H03M7/3082', 'H03M7/70']"
US20220369031A1,Deep neural network denoiser mask generation system for audio processing,"Techniques for providing an artificial intelligence denoiser related to audio processing are discussed herein. Some embodiments may include providing an audio signal sample associated with at least one microphone to a time-frequency domain transformation pipeline for a transformation period. Some embodiments may include providing the audio signal sample to a deep neural network (DNN) processing loop that is configured to determine a denoiser mask associated with a noise prediction for the audio signal sample. In a circumstance where the denoiser mask is determined prior to expiration of the transformation period, some embodiments may include applying the denoiser mask associated with the noise prediction to a frequency domain version of the audio signal sample associated with the time-frequency domain transformation pipeline to generate a denoised audio signal sample associated with the at least one microphone.","['H04R3/04', 'G10L21/0232', 'G10K11/1752', 'G10L21/028', 'H04R3/005']"
EP3943970A1,Methods and systems for detection of objects in a vicinity of a vehicle,A computer implemented method for detection of objects in a vicinity of a vehicle comprises the following steps carried out by computer hardware components: acquiring radar data from a radar sensor; determining a plurality of features based on the radar data; providing the plurality of features to a single detection head; and determining a plurality of properties of an object based on an output of the single detection head.,"['G01S7/417', 'G01S13/931', 'B60W60/001', 'G01S13/865', 'G01S13/867', 'G01S13/87', 'G01S7/2955', 'G01S7/41', 'G06F18/251', 'G06F18/253', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06V20/58', 'B60W2420/403', 'B60W2420/408', 'B60W2554/404', 'G01S17/931']"
EP3934254A1,Encoding and decoding of extracted features for use with machines,"Example embodiments relate to encoding and decoding of data for machine learning related applications or other non-human purposes. Feature maps extracted from input data may be adapted such that the features are more suitable for encoding by an encoder. A decoder may obtain the encoded data, reconstruct the input data, and cause execution of a machine based on the reconstructed input data. Apparatuses, methods, and computer programs are disclosed.","['H04N19/46', 'G06N3/045', 'G06N3/084', 'H04N19/85']"
CN108694694B,Abstract library for enabling scalable distributed machine learning,"One embodiment provides a non-transitory machine-readable medium storing instructions that, when executed by one or more processors, cause the one or more processors to perform operations comprising: an interface is provided for defining a neural network using machine learning domain-specific terms, wherein the interface enables selection of a neural network topology and abstracts low-level communication details of distributed training of the neural network.","['G06T1/20', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/60']"
CN115442515B,Image processing methods and equipment,"The application provides an image processing method and device, wherein the method is applied to an electronic device with a display screen and a camera, and comprises the following steps: acquiring N frames of original raw images; registering the N frames of original raw images; according to the neural network model, carrying out reconstruction processing on the N frames of original raw images subjected to registration processing to obtain a reconstructed image, wherein the reconstructed image is a frame of raw image subjected to noise reduction; performing color correction processing on the reconstructed image; and performing post-processing on the reconstructed image subjected to the color correction processing. The image denoising method and device can improve the image denoising effect.","['H04N23/632', 'G06T5/70', 'G06T5/50', 'G06T5/60', 'G06T5/94', 'G06T7/38', 'H04N23/62', 'H04N23/633', 'H04N23/64', 'H04N23/667', 'H04N23/741', 'H04N23/76', 'H04N23/81', 'H04N23/88', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221']"
US10895560B2,Electronic nose instrument for sensory quality evaluation of tobacco and tobacco product,"Provided is a sensory quality evaluation method for tobacco and tobacco products using an electronic nose instrument. The electronic nose instrument includes a gas sensor array module, an automatic smoke sampling system, a computer control and data analysis system, and an automatic ignition device. These components are integrated in a test box to make the instrument be structure miniaturization and work automation. The large tobacco data is established, in which the relationship between the responses of gas sensor array and the brand labels and sensory quality index scores by testing a large number of standard cigarette samples. A cascade type of modular neural networks is proposed with revised activation function and new decision-making and quantification rules to simulate the smoking and evaluating process of the professional panel. The electronic nose instrument and method realize on-site detection, discrimination and quality score estimation of a large number of tobacco and tobacco products.","['G01N33/0001', 'G01N33/0006', 'G01N27/12', 'G01N31/12', 'G01N33/0031', 'G01N33/0036', 'G01N33/0098', 'G01N35/00', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G01N1/24']"
CN108733051B,Autonomous Vehicle Advanced Sensing and Response,"The application discloses autonomous vehicle advanced sensing and response. One embodiment provides a computing device within an autonomous vehicle, the computing device comprising a wireless network device to enable a wireless data connection with an autonomous vehicle network, a set of multiple processors including a general purpose processor and a general purpose graphics processor to execute a computing manager to manage execution of computing workloads associated with the autonomous vehicle, the computing workloads being associated with autonomous operation of the autonomous vehicle, and offload logic configured to execute on the set of multiple processors to determine offloading of one or more of the computing workloads to one or more autonomous vehicles within range of the wireless network device.","['G07C5/008', 'G05D1/0214', 'B60W30/00', 'B60W50/0098', 'G01C21/34', 'G01C21/3415', 'G01C21/3492', 'G05D1/0088', 'G05D1/0276', 'G06F9/5027', 'G06N20/00', 'G06N20/10', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06T1/60', 'G08G1/012', 'H04L67/12', 'H04W4/40', 'B60W2050/0006', 'B60W2556/65', 'G01S19/13', 'G05D1/0257', 'G06F2209/509', 'G08G1/0112', 'G08G1/052', 'H04L43/0852', 'H04L43/16', 'Y02D10/00']"
CN111553483B,"Federal learning method, device and system based on gradient compression","The application discloses a method, a device and a system for federal learning based on gradient compression, wherein the system comprises: the federation server sends the initial model to all clients; the client trains the initial model to obtain updated gradients, carries out quantization treatment on the updated gradients to obtain quantized gradients of the updated gradients, and then sends the quantized gradients to the federal server; the federal server performs quantity statistics according to all the quantization gradients corresponding to each client according to different quantization values in the quantization gradients to obtain a statistical result, and returns the statistical result to each client; the client receives the statistical result sent by the federation server, calculates the global update gradient according to the statistical result, and continues training the model according to the global update gradient. The method and the device for the network transmission of the Federal learning system solve the problems that network transmission cost is high and data is unsafe in an existing Federal learning system.",['G06N20/00']
US11715004B2,Robustness against manipulations in machine learning,"A method comprising: receiving observed data points each comprising a vector of feature values, wherein for each data point, the respective feature values are values of different features of a feature vector. Each observed data point represents a respective observation of a ground truth as observed in the form of the respective values of the feature vector. The method further comprises learning parameters of a machine-learning model based on the observed data points. The machine-learning model comprises one or more statistical models arranged to model a causal relationship between the feature vector and a latent vector, a classification, and a manipulation vector. The manipulation vector represents an effect of potential manipulations occurring between the ground truth and the observation thereof as observed via the feature vector. The learning comprises learning parameters of the one or more statistical models to map between the feature vector, latent vector, classification and manipulation vector.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N7/023', 'G06N3/048', 'G06T2207/20081', 'G06V10/811', 'G06V10/82']"
CN116127186B,Knowledge-graph-based individual matching recommendation method and system for person sentry,"The invention discloses a personalized matching recommendation method and system based on a knowledge graph person post, wherein the method collects recruitment position information issued by recruitment enterprises, performs data processing, obtains recruitment position triples through relation extraction, obtains position knowledge graphs, collects historical job hunting behavior data including click browsing, comment and collection of users, obtains a user-preferred position data set, takes the user-preferred position data set as seeds, acquires multi-hop position information and relation thereof from the position knowledge graphs by applying RIPPLENET algorithm, obtains triples of entity interaction of users and the position knowledge graphs, builds and trains a multi-task recommendation model based on the knowledge graphs and integrating user preferences, and comprises a user-graph entity interaction module, a recommendation module and a position-graph entity interaction module, and obtains a position ordered list according to scores of the user and the position interaction. The invention can improve the recommendation result and give the recommendation requirement meeting the individuation of the user.","['G06F16/9535', 'G06F16/24578', 'G06F16/288', 'G06F16/367', 'G06F16/9536', 'G06F17/16', 'G06N3/049', 'G06N3/08', 'G06N3/084', 'G06Q10/1053', 'Y02D10/00']"
US11804851B2,"Methods, systems, articles of manufacture, and apparatus to decode zero-value-compression data vectors","Methods, systems, articles of manufacture, and apparatus are disclosed to decode zero-value-compression data vectors. An example apparatus includes: a buffer monitor to monitor a buffer for a header including a value indicative of compressed data; a data controller to, when the buffer includes compressed data, determine a first value of a sparse select signal based on (1) a select signal and (2) a first position in a sparsity bitmap, the first value of the sparse select signal corresponding to a processing element that is to process a portion of the compressed data; and a write controller to, when the buffer includes compressed data, determine a second value of a write enable signal based on (1) the select signal and (2) a second position in the sparsity bitmap, the second value of the write enable signal corresponding to the processing element that is to process the portion of the compressed data.","['H03M7/3082', 'G06F16/2237', 'G06F17/153', 'G06F17/16', 'G06N3/063', 'H03M7/3059', 'H03M7/3066', 'G06N3/04', 'G06N3/08']"
US11268469B2,"Misfire detection device for internal combustion engine, misfire detection system for internal combustion engine, data analysis device, controller for internal combustion engine, method for detecting misfire of internal combustion engine, and reception execution device",A misfire detection device for an internal combustion engine including a crankshaft mechanically connected to a motor generator includes a storage device and processing circuitry. The storage device stores mapping data. The mapping data is data specifying a mapping that outputs a misfire variable using a rotation waveform variable and a damping variable as an input. The misfire variable is a variable related to a probability that a misfire has occurred. The rotation waveform variable is a variable including information on a difference between values of instantaneous speed corresponding to short angular intervals differing from each other. The damping variable is a variable related to a state of a damping process that controls a torque of the motor generator to reduce vibration of a power transmission system of a vehicle.,"['F02B77/08', 'F02D41/1498', 'F02B63/04', 'F02D41/0002', 'F02D41/008', 'F02D41/009', 'F02D41/0097', 'F02D41/30', 'F02N11/0822', 'F02P5/1512', 'F02D2041/0022', 'F02D2200/101', 'F02D2200/1015', 'F02D2250/18', 'F02N11/04']"
US11190804B2,"Encoder, decoder, encoding method, and decoding method","The encoder includes processing circuitry, and memory. Using the memory, the processing circuitry: generates a predicted image of an input image that is a current image to be encoded, based on generated data output from a generator network in response to a reference image being input to the generator network, the generator network being a neural network; calculates a prediction error by subtracting the predicted image from the input image; and generates an encoded image by at least transforming the prediction error.","['H04N19/61', 'H04N19/107', 'H04N19/154', 'H04N19/176', 'H04N19/192', 'H04N19/196', 'H04N19/503', 'H04N19/593']"
CN110084365B,A system and method for providing services based on deep learning,"The invention belongs to the field of edge data information calculation, and discloses a service providing system and method based on deep learning, which can protect the privacy of training data and improve the service quality of an edge terminal. At a cloud server side, generating a compressed deep learning model of privacy by combining a differential privacy mechanism: generating a full-connection deep learning model with privacy protection in privacy dense training, and protecting the privacy of training data; in privacy compression training, a full-connection deep learning model with privacy protection is cut, so that a compression deep learning model with privacy protection is generated, and the privacy of training data is protected. The privacy compression model size can be reduced to 1/9 of the original model size, so that the privacy compression model is very suitable for embedding the edge server, and the adjacent mobile equipment can improve the edge service quality by accessing the edge server.","['G06N3/045', 'G06N3/08']"
CN112901449B,Air compressor system energy consumption optimization method based on machine learning,"The invention relates to an air compressor system energy consumption optimization method based on machine learning, which comprises the following steps: step S1: reading current working condition information, and calling or estimating the outlet flow of each air compressor; step S2: simulating a real-time energy efficiency curve model of each air compressor through machine learning, wherein the energy efficiency of the air compressor = the outlet flow/real-time power of the air compressor; and step S3: the method comprises the steps of obtaining real-time working conditions of an air compressor and demand information of an air compressor system, obtaining a real-time energy efficiency curve of the air compressor according to the real-time working conditions of the air compressor, optimizing a starting combination through the real-time energy efficiency curve of the air compressor and the demand information of the air compressor system, and obtaining an optimal energy-saving starting combination. The energy efficiency curve of the air compressor is fitted through the machine learning neural network model, the load of the air compressor is preferentially selected through the optimization algorithm according to the total demand of the compressed air flow, the group control mode of the air compressor is improved, and therefore the energy consumption of the air compressor system is reduced.","['F04B37/12', 'F04B49/06', 'F04B51/00', 'G06F30/27']"
TW202318275A,Methods and apparatus for artificial intelligence and machine learning for communication system,"An apparatus may include a receiver configured to receive a signal using a channel, a transmitter configured to transmit a representation of channel information relating to the channel, and at least one processor configured to determine a condition of the channel based on the signal, and generate the representation of the channel information based on the condition of the channel using a machine learning model. A method may include determining, at a wireless apparatus, physical layer information for the wireless apparatus, generating a representation of the physical layer information using a machine learning model, and transmitting, from the wireless apparatus, the representation of the physical layer information.","['G06N3/08', 'H04B7/0626', 'G06N3/0455', 'G06N20/00', 'G06N3/0495', 'G06N3/084', 'H04B7/0417', 'H04B7/0456', 'H04W24/08', 'G06N3/0442', 'G06N3/0464']"
US11775812B2,Multi-task based lifelong learning,"Methods, devices, and computer-readable media for multi-task based lifelong learning. A method for lifelong learning includes identifying a new task for a machine learning model to perform. The machine learning model trained to perform an existing task. The method includes adaptively training a network architecture of the machine learning model to generate an adapted machine learning model based on incorporating inherent correlations between the new task and the existing task. The method further includes using the adapted machine learning model to perform both the existing task and the new task.","['G06N3/082', 'G06N3/08', 'G06N3/04', 'G06N3/044', 'G06N3/045']"
US20220166955A1,Generating an avatar of a participant of a three dimensional (3d) video conference,"A method for generating an avatar of a participant of a three dimensional (3D) video conference, the method may include acquiring visual information, by a camera of a participant; generating an avatar of the participant as seen from a point of view of a virtual camera that is virtually located at a physical location of the camera; comparing between the avatar and the visual information to provide a comparison result; and amending the avatar or at least one building block of the avatar to compensate for one or more differences between the avatar and the visual information when the comparison results is indicative of the one or more differences.","['H04N7/157', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/024', 'G06T2219/2004', 'G06T2219/2012']"
US10602153B2,Ultra-high video compression,"Various of the disclosed embodiments relate to multiple video encoders that are used to simultaneously encode a video using encoders configured using different encoding parameters. A segment selector selects an encoded version of the encoded video segment using operational criteria such as video quality and bandwidth. A configuration determination module may analyze the video segment to make a decision about which encoding parameter configurations may be suitable for encoding the video segment. The configuration determination module may be trainable, based on past encoding results.","['H04N19/146', 'H04N19/395', 'H04N19/436', 'H04N19/90']"
US20250200718A1,"Image enhancement method and apparatus, device and medium","The present disclosure relates to an image enhancement method, apparatus, device, and medium. The method includes: obtaining an initial image to be processed; inputting the initial image into an image enhancement model obtained by pre-training, wherein the image enhancement model comprises a multi-scale feature fusion network; performing a multi-scale feature extraction on an input image through the multi-scale feature fusion network to obtain initial feature maps of multiple scales, performing a fusion based on the initial feature maps of the multiple scales to obtain multiple intermediate feature maps, and performing a fusion based on the multiple intermediate feature maps to obtain an output feature map of the multi-scale feature fusion network, wherein the input image is obtained based on the initial image; and obtaining an image of which an image quality is enhanced based on the output feature map of the multi-scale feature fusion network and the initial image.","['G06T3/4046', 'G06N3/04', 'G06N3/0464', 'G06T5/20', 'G06T5/50', 'G06T5/60', 'G06V10/774', 'G06V10/80', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US20230246912A1,"AI-Based Energy Edge Platform, Systems, and Methods Having an Adaptive Energy Data Pipeline","An AI-based platform for enabling intelligent orchestration and management of power and energy is disclosed. The AI-based platform includes an adaptive energy data pipeline configured to communicate data across a set of nodes in a network. Each node of the set of nodes is adapted to operate on an energy data set associated with at least one of energy generation, energy storage, energy delivery, or energy consumption. At least one node of the set of nodes is configured, by one or both of an algorithm or a rule set, to filter, compress, transform, error correct and/or route at least a portion of the energy data set based on at least one of a set of network conditions, data size, data granularity, or data content.","['G06Q50/06', 'G01R21/133', 'G05B13/0265', 'G05B13/04', 'G05B13/042', 'G05B19/042', 'G06F1/26', 'G06F18/213', 'G06F18/214', 'G06F18/2453', 'G06F30/27', 'G06N10/00', 'G06N10/80', 'G06N20/00', 'G06N3/04', 'G06N3/08', 'G06N5/043', 'G06Q10/04', 'G06Q10/067', 'G06Q30/018', 'G06Q50/02', 'G06Q50/26', 'G06Q99/00', 'G06V10/82', 'H02J13/00001', 'H02J13/00002', 'H02J3/004', 'H02J3/008', 'H02J3/144', 'H02J3/32', 'H04L41/0833', 'H04L41/145', 'H04L41/16', 'H04L9/3239', 'H04L9/50', 'G05B2219/2639', 'G06Q2220/00', 'H02J2203/10', 'H02J2203/20', 'H02J2300/40', 'H02J3/003', 'H02J3/381']"
US11765332B2,Virtual 3D communications with participant viewpoint adjustment,"A method for conducting a three dimensional (3D) video conference between multiple participants, the method may include receiving second participant metadata and first viewpoint metadata by a first unit that is associated with a first participant, wherein the second participant metadata is indicative of a pose of a second participant and an expression of the second participant, wherein the first viewpoint metadata is indicative of a virtual position from which the first participant requests to view an avatar of the second participant; generating, by the first unit, and based on the second participant metadata and the first viewpoint metadata, a second participant representation information; wherein the second participant representation information comprises a compact 3D model of the second participant and a second participant texture map; and determining, for the first participant and during the 3D video conference, a representation of virtual 3D video conference environment, wherein the determining is based on the second participant representation information.","['H04N13/111', 'G06T19/006', 'H04N7/157']"
CN113128110B,Thermal management optimization method for power battery of intelligent network-connected electric automobile in alpine region,"An intelligent network connection electric automobile severe cold area power battery thermal management optimization method belongs to the technical field of new energy automobile batteries. The invention aims to provide a thermal management optimization method for a power battery of an intelligent network-connected electric automobile in a severe cold region, which can effectively combine intelligent network-connected automobile speed prediction information and improve energy consumption economy in a heating process of the power battery. The method comprises the following steps: the method comprises the steps of constructing a future vehicle speed prediction model based on a BP neural network, predicting the future vehicle speed of a target vehicle in real time by using the BP neural network vehicle speed prediction model, establishing a battery pack electric thermal coupling model and a heat pump air conditioning system centralized parameter model as prediction models for model prediction control, introducing influence items of future vehicle speed change on battery heat generation and heat exchange of the heat pump air conditioning system into the prediction models, and adjusting a heating process. The invention shortens the heating time and reduces the energy consumption.","['G06F30/27', 'G06N3/084', 'H01M10/615', 'H01M10/625', 'H01M10/633', 'H01M10/635', 'H01M10/6567', 'H01M10/663', 'G06F2111/04', 'G06F2119/08', 'Y02E60/10']"
US11960996B2,Video quality assessment method and apparatus,"An operating method of a computing apparatus is provided. The operating method of the computing apparatus includes obtaining a reference image; obtaining a distorted image generated from a reference image; obtaining an objective quality assessment score of a distorted image that is indicative of a quality of a distorted image as assessed by an algorithm, by using a reference image and a distorted image; obtaining a subjective quality assessment score corresponding to a objective quality assessment score; and training a neural network, by using a distorted image and a subjective quality assessment score as a training data set.","['H04N17/02', 'G06N3/08', 'G06F18/2113', 'G06F18/285', 'G06N3/04', 'G06N3/045', 'G06T5/60', 'G06T7/0002', 'G06T7/20', 'G06V10/993', 'G06V20/40', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
CN108805795B,Hardware-implemented point-to-point communication primitives for machine learning,"One embodiment provides a system for computing and distributing data for distributed training of a neural network, the system comprising: a first memory storing a first set of instructions comprising a machine learning framework; a fabric interface that enables transmission and reception of data associated with the set of trainable machine learning parameters; a first set of general purpose processor cores executing a first set of instructions providing a training workflow for computation of gradients for trainable machine learning parameters and in communication with a second set of instructions facilitating transmission and reception of gradients via a fabric interface; and a graphics processor that performs computing operations associated with the training workflow to generate gradients for the trainable machine learning parameters.","['G06T1/20', 'G06N3/08', 'G06F9/547', 'G06N3/04', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'G06N3/098']"
US10719939B2,Real-time mobile device capture and generation of AR/VR content,"Various embodiments describe systems and processes for generating AR/VR content. In one aspect, a method for generating a three-dimensional (3D) projection of an object is provided. A sequence of images along a camera translation may be obtained using a single lens camera. Each image contains at least a portion of overlapping subject matter, which includes the object. The object is semantically segmented from the sequence of images using a trained neural network to form a sequence of segmented object images, which are then refined using fine-grained segmentation. On-the-fly interpolation parameters are computed and stereoscopic pairs are generated for points along the camera translation from the refined sequence of segmented object images for displaying the object as a 3D projection in a virtual reality or augmented reality environment. Segmented image indices are then mapped to a rotation range for display in the virtual reality or augmented reality environment.","['G06V20/70', 'G06T7/174', 'G06F16/532', 'G06F16/5838', 'G06F16/738', 'G06F16/783', 'G06F3/011', 'G06K9/00664', 'G06T3/4038', 'G06V20/10', 'H04N13/243', 'H04N13/279', 'H04N13/282', 'H04N23/698', 'H04N5/23238', 'H04N5/265']"
US10305766B1,Coexistence-insensitive presence detection,"A system and method include processing logic receiving, from a wireless transceiver of a first device, first data indicative of channel state information (CSI) of a first communication link between the wireless transceiver and a wireless transmitter of a second device, the first device and the second device being located in a building. The logic pre-preprocesses the first data to generate input vectors composed of statistical parameter values derived from sets of discrete samples of the first data. The logic processes, through a long short-term memory (LSTM) layer of a neural network, the input vectors to generate multiple hidden state values of the neural network. The logic processes, through a set of additional layers of the neural network, respective hidden state values of the multiple hidden state values to determine that a human is present in the building.","['H04B17/391', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/088', 'G08B21/0484', 'H04B17/318', 'H04B7/0626', 'H04L43/08', 'H04W4/029', 'H04W4/33', 'H04W64/003', 'G06N20/00', 'H04M1/724', 'H04M1/72403', 'H04M1/72519', 'H04M1/72522', 'H04W4/02', 'H04W64/00']"
US11805157B2,Sharing content during a virtual 3D video conference,"A method for sharing content during a virtual 3D video conference, the method may include inviting multiple participants to join a virtual 3D video conference; creating a shared folder dedicated for storing shared content items, wherein the shared content is accessible during at least during the virtual 3D video conference; enabling access, to the multiple participants, to the shared folder; wherein the access is governed by one or more access control rule; and conducting the virtual 3D video conference; wherein the conducting comprises sharing at least one of the content items.","['H04L65/4015', 'G06F3/013', 'G06N3/04', 'G06N3/045', 'G06T15/04', 'G06T15/20', 'G06T15/205', 'G06T17/20', 'G06T19/00', 'G06T19/20', 'G06T7/11', 'G06T7/70', 'H04L12/1818', 'H04L12/1822', 'H04L63/101', 'H04L63/102', 'H04L63/108', 'H04L65/1089', 'H04L65/1093', 'H04L65/403', 'H04L65/80', 'H04N7/144', 'H04N7/147', 'H04N7/152', 'H04N7/157', 'G06T2200/08', 'G06T2207/30201', 'G06T2219/2004']"
CN117235187B,Data storage method and system based on network teaching resources,"The invention relates to the technical field of information, in particular to a data storage method and system based on network teaching resources. The method comprises the following steps: the network teaching resource deep acquisition is carried out through a deep crawler technology, so that a teaching resource data set is obtained; performing format conversion on the teaching resource data set so as to obtain a standard teaching resource data set; subject classification is carried out on the standard teaching resource data set, so that a classified teaching resource data set is obtained; classifying the classified teaching resource data sets according to the difficulty, thereby obtaining difficulty level data sets; automatically labeling the teaching resource data sets of the corresponding categories and automatically generating wrong questions by using the difficulty level data sets, so as to obtain the classified teaching resource data sets and the corresponding intelligent wrong question data sets; the invention can realize the improvement of the storage and management efficiency of teaching resources.",['Y02D10/00']
US11398238B2,Speech recognition method in edge computing device,"Disclosed herein is a speech recognition method in a distributed network environment. A method of performing a speech recognition operation in an edge computing device includes receiving a natural language understanding (NLU) model from the cloud server, storing the received NLU model, receiving voice data spoken by a user from the client device, performing a natural language processing operation on the received voice data using the NLU model, performing speech recognition according to the natural language processing operation, and transmitting a result of the speech recognition to the client device.","['G10L15/18', 'G10L15/30', 'G10L15/063', 'G10L15/183', 'G10L15/34', 'G10L25/48', 'G10L25/30']"
WO2020239126A1,Methods and systems for relaying feature-driven communications,Methods and apparatuses for feature-driven communications are described. A set of features describing an observed subject is transmitted by a transmitting electronic device (ED) to a base station (BS). The BS translates the received features to another set of transmission features to be transmitted to a receiving ED. The receiving ED recovers information about the subject from the features received from the BS.,"['G06N3/084', 'G06N3/063', 'G06N3/08', 'H04W4/70', 'G06N3/042', 'G06N3/044', 'G06N3/045']"
US11734568B2,Systems and methods for modification of neural networks based on estimated edge utility,"The present disclosure provides systems and methods for modification (e.g., pruning, compression, quantization, etc.) of artificial neural networks based on estimations of the utility of network connections (also known as “edges”). In particular, the present disclosure provides novel techniques for estimating the utility of one or more edges of a neural network in a fashion that requires far less expenditure of resources than calculation of the actual utility. Based on these estimated edge utilities, a computing system can make intelligent decisions regarding network pruning, network quantization, or other modifications to a neural network. In particular, these modifications can reduce resource requirements associated with the neural network. By making these decisions with knowledge of and based on the utility of various edges, this reduction in resource requirements can be achieved with only a minimal, if any, degradation of network performance (e.g., prediction accuracy).","['G06N3/082', 'G06N20/20', 'G06N3/045', 'G06N3/084', 'G06N3/044', 'G06N3/049']"
CN108810538B,"Video coding method, device, terminal and storage medium","The application discloses a video coding method, a video coding device, a video coding terminal and a storage medium, and belongs to the technical field of video processing. The method comprises the following steps: acquiring a target video to be processed, wherein the target video comprises n target video frames which are sequentially arranged; performing target detection on the ith target video frame by adopting a target detection model to obtain a target area in the target video frame; and according to the target areas corresponding to the n target video frames, performing video coding by using a region of interest (ROI) coding algorithm to obtain a coded target video. According to the method and the device, the target detection model is adopted to carry out target detection on the target video frame, the target region, namely the ROI region, is dynamically determined along with the change of the video picture, so that the follow-up terminal can carry out video coding on the basis of the dynamically determined ROI region by adopting an ROI coding algorithm, the coding quality and stability of the target region are effectively guaranteed, meanwhile, the coding code rate of the target video is reduced, and the video coding efficiency is improved.","['H04N19/172', 'G06V10/25', 'G06V20/46', 'H04N19/167', 'H04N19/70']"
US11838151B1,Wireless mesh network,"Among other things, aspects, features, and implementations of wireless mesh networks and wireless mesh network devices are described.","['H04B7/15528', 'H04L25/0204', 'H04B7/15542', 'H04B7/15585', 'H04L25/0212', 'H04L25/022', 'H04L25/0224', 'H04L25/0242', 'H04L25/0246', 'H04L25/021', 'H04L25/025', 'H04W84/18']"
US20200193206A1,Scene and user-input context aided visual search,"Provided is a technique for determining a context of an image and an object depicted by the image based on the context. A trained context classification model may determine a context of an image, and a trained object recognition model may determine an object depicted by the image based on the image and the context. Provided is also a technique for determining an object depicted within an image based on an input location of an input detected by a display screen. An object depicted within an image may be detected based on a distance in feature space between an image feature vector of an image and a feature vector of the object, and a distance in pixel-space between an input location of an input and location of the object within the image.","['G06K9/3233', 'G06V20/20', 'G06F18/214', 'G06F18/24', 'G06K9/4604', 'G06K9/6256', 'G06K9/6267', 'G06T1/0014', 'G06T5/009', 'G06T5/92', 'G06V10/235', 'G06V20/70', 'H04N25/00', 'G06T2207/20132']"
US8328718B2,Health monitoring appliance,"A heart monitoring system for a person includes one or more wireless nodes; and a wearable appliance in communication with the one or more wireless nodes, the appliance monitoring cardiac abnormalities. Other implementations can monitor heart rate, heart rate variability, respiratory rate, fluid status, posture and activity.","['G16Z99/00', 'A61B5/0006', 'A61B5/0024', 'A61B5/0077', 'A61B5/0205', 'A61B5/021', 'A61B5/02108', 'A61B5/1112', 'A61B5/1113', 'A61B5/1117', 'A61B5/242', 'A61B5/318', 'A61B5/411', 'A61B5/4806', 'A61B5/4833', 'A61B5/6808', 'A61B5/681', 'A61B5/7214', 'A61B5/7225', 'A61B5/7264', 'A61B5/7275', 'A61B5/7282', 'A61B5/7405', 'A61B5/746', 'A61B7/04', 'A61B8/00', 'A61B8/565', 'G16H40/63', 'A61B2503/08', 'A61B2560/0412', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B5/7465']"
US11322248B2,"Operating room black-box device, system, method and computer readable medium for event and error prediction","A multi-channel recorder/encoder for collecting, integrating, synchronizing and recording medical or surgical data received as independent live or real-time data streams from a plurality of hardware units. The medical or surgical data relating to a live or real-time medical procedure. Example hardware units include a control interface, cameras, sensors, audio devices, and patient monitoring hardware. Further example systems may include a cloud based platform incorporating the encoder.","['G16H40/20', 'A61B5/0022', 'G06F1/12', 'G06F17/40', 'G06N20/00', 'G16H20/40', 'G16H30/20', 'G16H40/63', 'G16H40/67', 'G16H50/50', 'H04L63/0421']"
TWI821358B,"Electronic apparatus, method for controlling thereof, and method for controlling a server","An electronic apparatus, a method for controlling thereof, and a method for controlling a server are provided. The method for controlling an electronic apparatus includes receiving image data and information associated with a filter set that is applied to an artificial intelligence model for upscaling the image data from an external server; decoding the image data; upscaling the decoded image data using a first artificial intelligence model that is obtained based on the information associated with the filter set; and providing the upscaled image data for output.","['H04N21/2662', 'H04N21/440263', 'H04N21/234363', 'H04N21/440218', 'G06N3/045', 'G06T3/4007', 'G06T3/4046', 'H04N19/115', 'H04N19/117', 'H04N19/154', 'H04N19/157', 'H04N19/172', 'H04N19/33', 'H04N19/439', 'H04N19/46', 'H04N19/59', 'H04N19/82', 'H04N21/234309', 'H04N7/0117', 'G06T9/002']"
EP4517593A2,Diffusion models having improved accuracy and reduced consumption of computational resources,"A computer-implemented method for use of a diffusion model having improved accuracy comprises obtaining input data, the input data comprising one or more channels; providing the input data to a machine-learned diffusion model, the machine-learned diffusion model comprising: a noising model comprising a plurality of noising stages, the noising model configured to introduce noise to receive the input data and produce intermediate data in response to receipt of the input data; and a denoising model configured to reconstruct output data from the intermediate data; and receiving, by the computing system, the output data from the machine-learned diffusion model. The diffusion model can include a learned noise schedule. Additionally and/or alternatively, input to the denoising model can include a set of Fourier features. Additionally and/or alternatively, the diffusion model can be trained based at least in part on a continuous-time loss for an evidence lower bound.","['G06N3/088', 'G06N3/048', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/084', 'G10L21/0208']"
US11228767B2,"Apparatus, a method and a computer program for video coding and decoding","A method comprising: deriving a first prediction block (608) at least partly based on an output of a neural net (602) using a first set of parameters; deriving a first encoded prediction error block (614-620) through encoding a difference of the first prediction block and a first input block; encoding (620) the first encoded prediction error block into a bitstream; deriving a first reconstructed prediction error block (624) from the first encoded prediction error block; deriving a training signal (628) from one or both of the first encoded prediction error block and/or the first reconstructed prediction error block (624); retraining (630) the neural net (602) with the training signal (628) to obtain a second set of parameters for the neural net (602); deriving a second prediction block (608) at least partly based on an output of the neural net using the second set of parameters; deriving a second encoded prediction error block (614-620) through encoding a difference of the second prediction block and a second input block; and encoding (620) the second encoded prediction error block into a bitstream. The invention relates to image or video encoding or decoding, especially by online training a neural network (602) that is in the prediction loop.","['H04N19/149', 'H04N19/436', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04N19/103', 'H04N19/142', 'H04N19/159', 'H04N19/172', 'H04N19/174', 'H04N19/176', 'H04N19/188', 'H04N19/192', 'H04N19/30', 'H04N19/46', 'H04N19/65', 'H04N19/70', 'G06N3/044', 'G06N3/048', 'G06N3/082', 'H04N19/156']"
CN115560983B,Rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions,"The invention provides a rolling bearing fault diagnosis method and system based on federal feature transfer learning under different working conditions, and relates to the technical field of rolling bearing fault diagnosis. The method comprises the technical key points of performing wavelet transformation on rolling bearing time domain vibration data to obtain a time-frequency spectrogram, taking priori labeled public data as a source domain and multi-user label-free island privacy data as a target domain, introducing a multi-representation feature extraction structure to improve an original residual error network, extracting multi-representation features of the source domain and the target domain to respectively construct a multi-user local model, improving a parameter transfer strategy in a federal migration learning framework by using a model compression idea of a deep neural network, enhancing the safety of the federal framework and reducing communication expenditure, and constructing a federal global model which can be used for fault diagnosis of the rolling bearing under different working conditions at a server side. The island data knowledge can be integrated without multi-user sharing data, and the island data knowledge integration method has higher accuracy and stronger generalization.","['G01M13/04', 'G01M13/045', 'G06N20/00']"
CN110348541B,"Method, device and equipment for classifying fundus blood vessel images and storage medium","The invention provides a method, a device, equipment and a storage medium for classifying fundus blood vessel images; the method comprises the following steps: extracting an original characteristic map from the fundus blood vessel image; determining the probability value of each pixel point belonging to the blood vessel in the fundus blood vessel image based on the characteristics of each pixel point in the original characteristic image so as to form a blood vessel segmentation probability image of the fundus blood vessel image; distributing corresponding weight to each pixel point based on the distribution condition of the probability value of each pixel point in the blood vessel segmentation probability map; fusing the weight of each pixel point in the fundus blood vessel image with the characteristics of the corresponding pixel point in the original characteristic diagram to obtain a fused characteristic diagram; and determining the probability values of the pixels in the fundus blood vessel image belonging to the artery blood vessel and the vein blood vessel respectively based on the characteristics of the pixels in the fusion characteristic image to form a blood vessel classification probability image of the fundus blood vessel image. The invention can realize the blood vessel segmentation and the blood vessel classification automatically and with high precision.","['G06F18/2415', 'G06F18/253', 'G06T7/10', 'G06V10/40', 'G06T2207/10024', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30101']"
US12124383B2,Systems and methods for cache optimization,"Systems and methods for improving cache efficiency and utilization are disclosed. In one embodiment, a graphics processor includes processing resources to perform graphics operations and a cache controller of a cache memory that is coupled to the processing resources. The cache controller is configured to set an initial aging policy using an aging field based on age of cache lines within the cache memory and to determine whether a hint or an instruction to indicate a level of aging has been received. In one embodiment, the cache memory configured to be partitioned into multiple cache regions, wherein the multiple cache regions include a first cache region having a cache eviction policy with a configurable level of data persistence.","['G06F12/123', 'G06F12/0875', 'G06F12/0891', 'G06F12/126', 'G06T1/60', 'G06F2212/302']"
US12061814B2,Using data similarity to select segments for garbage collection,"A storage system performs garbage collection, with data compression, in storage memory. The system obtains hash results from data segments. The system determines similarity of content of data segments, based on the hash results. The system performs data compression of live data of two or more data segments that have similarity of content meeting a similarity threshold. The system writes the compressed live data of the two or more data segments into the storage memory.","['G06F12/0246', 'G06F12/04', 'G06F3/0608', 'G06F3/064', 'G06F3/0649', 'G06F3/0652', 'G06F3/0659', 'G06F3/0673', 'G06F3/0688', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/1044', 'G06F2212/1048', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'H03M7/30']"
CN110188705B,Remote traffic sign detection and identification method suitable for vehicle-mounted system,"The invention relates to a remote traffic sign detection and identification method suitable for a vehicle-mounted system, which comprises the following steps: 1. preprocessing a traffic sign image sample set; 2. constructing a lightweight convolutional neural network to complete the convolutional feature extraction of the traffic sign; 3. constructing an attention feature map through a channel-space attention module embedded into a lightweight convolutional neural network; 4. generating a candidate region of a target by adopting a region generation network RPN; 5. introducing context area information to a target candidate area generated by RPN, and enhancing the mark classification characteristics; 6. sending the characteristic vectors into a full connection layer, and outputting the types and positions of the traffic signs; 7. establishing an attention loss function, and training a FL-CNN model; 8. repeating the steps from 2 to 7 to finish the sample training of the FL-CNN model; 9. and repeating the steps from 2 to 6 to complete the detection and identification of the traffic signs in the actual scene. The invention realizes the detection and identification of the long-distance traffic sign with the accuracy reaching 92 percent.","['G06F18/214', 'G06N3/045', 'G06V20/582']"
US20220413434A1,Holographic Calling for Artificial Reality,"A holographic calling system can capture and encode holographic data at a sender-side of a holographic calling pipeline and decode and present the holographic data as a 3D representation of a sender at a receiver-side of the holographic calling pipeline. The holographic calling pipeline can include stages to capture audio, color images, and depth images; densify the depth images to have a depth value for each pixel while generating parts masks and a body model; use the masks to segment the images into parts needed for hologram generation; convert depth images into a 3D mesh; paint the 3D mesh with color data; perform torso disocclusion; perform face reconstruction; and perform audio synchronization. In various implementations, different of these stages can be performed sender-side or receiver side. The holographic calling pipeline also includes sender-side compression, transmission over a communication channel, and receiver-side decompression and hologram output.","['G03H1/0005', 'G03H1/26', 'G06F3/011', 'G06F3/012', 'G06F3/017', 'G06N20/00', 'G06N3/0455', 'G06T17/20', 'G06T7/11', 'G06T7/174', 'G06T7/194', 'G06T7/246', 'G06T7/55', 'G06V10/25', 'G06V10/26', 'G06V10/774', 'G06V20/20', 'G06V40/103', 'H04M3/567', 'H04M3/568', 'G03H2001/0088', 'G03H2001/0204', 'G06N3/0464', 'G06N3/09', 'G06T19/006', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196', 'H04M2203/359']"
US11195079B2,Reconfigurable neuro-synaptic cores for spiking neural network,"In one embodiment, a processor comprises a first neuro-synaptic core comprising first circuitry to configure the first neuro-synaptic core as a neuron core responsive to a first value specified by a configuration parameter; and configure the first neuro-synaptic core as a synapse core responsive to a second value specified by the configuration parameter.","['G06N3/04', 'G06N3/049', 'G06N3/063', 'G06N3/08', 'G06N3/088']"
US10403269B2,Processing audio waveforms,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for processing audio waveforms. In some implementations, a time-frequency feature representation is generated based on audio data. The time-frequency feature representation is input to an acoustic model comprising a trained artificial neural network. The trained artificial neural network comprising a frequency convolution layer, a memory layer, and one or more hidden layers. An output that is based on output of the trained artificial neural network is received. A transcription is provided, where the transcription is determined based on the output of the acoustic model.","['G10L15/16', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G10L15/142', 'G10L15/26']"
US10984530B1,Enhanced medical images processing method and computing device,"An enhanced medical images processing method and a computing device includes: acquiring series of enhanced medical images and detecting a phase of each enhanced medical image in the series of enhanced medical images using a pre-trained 3D convolutional neural network model. A plurality of target enhanced medical images from the enhanced medical image are selected according to the phases. A plurality of interest images is obtained by identifying and segmenting an interest region in each of the plurality of target enhanced medical images, and finally registering the plurality of interest images. The registered images have clear phase markers and are all spatially aligned, allowing a subsequent doctor or clinician to directly use the registered interest images for diagnosis without the need to rescan the patient.","['G06T7/0014', 'G06T7/11', 'G06T7/136', 'G06T7/32', 'G06T7/38', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/20128', 'G06T2207/30056', 'G06T2207/30096']"
US11482305B2,Artificial intelligence analysis of RNA transcriptome for drug discovery,A system and method may be provided to receive sample RNA reads from patients and generate lists of genes and their associated RNA expression levels in each patient. Some of the RNA reads may be matched to an RNA transcript or gene or gene family in terms of their match likelihood and other RNA reads may be matched to an RNA transcript or gene or gene family through the use of one or more machine learning classifiers. A machine learning classifier may be trained based on the plurality of the lists and a plurality of corresponding patients' clinical status data to identify gene patterns that recur with a high degree of frequency in the plurality of the lists. Those gene patterns can be capable of modifying a disease or treatment response and can be targeted for drug/treatment development.,"['G16B40/20', 'G16B20/00', 'G16B30/20', 'G16B50/50']"
US11836597B2,Detecting visual artifacts in image sequences using a neural network model,"Motivated by the ability of humans to quickly and accurately detect visual artifacts in images, a neural network model is trained to identify and locate visual artifacts in a sequence of rendered images without comparing the sequence of rendered images against a ground truth reference. Examples of visual artifacts include aliasing, blurriness, mosaicking, and overexposure. The neural network model provides a useful fully-automated tool for evaluating the quality of images produced by rendering systems. The neural network model may be trained to evaluate the quality of images for video processing, encoding, and/or compression techniques. In an embodiment, the sequence includes at least four images corresponding to a video or animation.","['G06T5/70', 'G06N3/045', 'G06N3/084', 'G06T5/002', 'G06T5/60', 'G06T7/0008', 'G06T2207/20084']"
US10679008B2,Knowledge base for analysis of text,"A knowledge base can include a dictionary associated with classes of a model, e.g., an ontology. A text segment that is not found in the dictionary can be received. Feature(s) can be determined for the text segment and, based partly on providing the feature(s) to a classifier, a set of values can be determined. The distribution can include values respectively corresponding to the classes. One of the values can be greater than a predetermined threshold. That value can correspond to a class. An indication identifying the class can be presented via a user interface having functionality to provide input that the text segment is associated with the class, is not associated with the class, or is associated with another class. Based at least partly on adding a new class to the ontology, a precedence table indicating priorities between motifs defining relationships between classes of the ontology can be updated.","['G06F40/30', 'G06F16/3347']"
US11544545B2,Structured activation based sparsity in an artificial neural network,"A novel and useful system and method of improved power performance and lowered memory requirements for an artificial neural network based on packing memory utilizing several structured sparsity mechanisms. The invention applies to neural network (NN) processing engines adapted to implement mechanisms to search for structured sparsity in weights and activations, resulting in a considerably reduced memory usage. The sparsity guided training mechanism synthesizes and generates structured sparsity weights. A compiler mechanism within a software development kit (SDK), manipulates structured weight domain sparsity to generate a sparse set of static weights for the NN. The structured sparsity static weights are loaded into the NN after compilation and utilized by both the structured weight domain sparsity mechanism and the structured activation domain sparsity mechanism. The application of structured sparsity lowers the span of search options and creates a relatively loose coupling between the data and control planes.","['G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06N3/0454', 'G06N3/0481']"
CN110222574B,"Production operation behavior identification method, device, equipment and system based on structured double-current convolutional neural network and storage medium","The application discloses a production operation behavior identification method, a device, equipment, a system and a storage medium based on a structured double-current convolutional neural network, wherein the production operation behavior identification method comprises the following steps: acquiring a monitoring video of a production environment, and decomposing the monitoring video into an image frame sequence and an optical flow sequence; inputting the image frame sequence and the optical flow sequence into a structured double-current convolution neural network to obtain the action category and the timestamp information of each frame of image; the structural double-current convolution neural network introduces an attention mechanism; and calculating to obtain a production action example according to the action type and the timestamp information. The production operation behavior identification method can quickly and accurately identify the production operation behavior in the video, and meets the requirement of intelligent manufacturing.","['G06N3/045', 'G06N3/08', 'G06V20/41', 'G06V40/20']"
US11803756B2,"Neural network system for reshaping a neural network model, application processor including the same, and method of operating the same","A method of operating a neural network system includes parsing, by a processor, at least one item of information related to a neural network operation from an input neural network model; determining, by the processor, information of at least one dedicated hardware device; and generating, by the processor, a reshaped neural network model by changing information of the input neural network model according to a result of determining the information of the at least one dedicated hardware device such that the reshaped neural network model is tailored for execution by the dedicated hardware device.","['G06N3/082', 'G06N3/08', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/063']"
CN110555450B,Face recognition neural network adjusting method and device,"A method and a device for adjusting and deploying a face recognition neural network are provided. The face recognition neural network includes at least a plurality of convolutional layers and at least one fully-connected layer, the last fully-connected layer is a classifier for classification, and the method includes: acquiring a neural network model to be trained; training the neural network model using fixed point quantization to obtain a trained fixed point quantized neural network model, wherein the last fully connected layer maintains floating points during training; and outputting the trained fixed-point quantized neural network model without the last fully-connected layer. Therefore, by utilizing the particularity of the face recognition network, through keeping the classifier layer with large influence on the overall accuracy of the network at the training stage and no longer inputting the classifier layer into the network, the trained fixed-point neural network has high accuracy and avoids the extra computational power requirement when the network is deployed.","['G06F18/214', 'G06F18/24', 'G06V40/172']"
WO2021258752A1,4-bit quantization method and system for neural network,"A 4-bit quantization method and system for a neural network. The method comprises: loading a pre-training model of the neural network (S1); in the pre-training model, collecting statistics about initial values of saturation activation layers satRelu (S2); adding pseudo quantization nodes to the neural network, and re-training the neural network by using the initial values of the satReLU to obtain a pseudo quantization model (S3); determining whether the precision of the pseudo quantization model converges to a set precision; (S4) if yes, performing reasoning preprocessing on the pseudo quantization model, and converting same into a 4-bit reasoning model that can be used for reasoning operation (S5); otherwise, returning to carry out re-training of the neural network. The system mainly comprises: a loading module, a statistics module, a re-training module, a determination module, and a conversion module. According to the method and system, the training efficiency can be effectively improved on the basis of ensuring the accuracy of the training result.","['G06N3/082', 'G06N3/045', 'G06N3/084']"
CN117892251B,Rigging forging process parameter monitoring and early warning method and device based on artificial intelligence,"The invention provides a method and a device for monitoring and early warning of a forging technological parameter of a rigging based on artificial intelligence, which relate to the technical field of data processing. The parameter monitoring model is constructed based on a classifier model constructed by a method of determining anchor points, a feature extraction model constructed by a neural network algorithm based on multi-direction communication simulation particle swarm optimization is used for carrying out feature extraction on a training sample set of a training classifier model, and a data dimension reduction model is used for carrying out dimension reduction on the training sample set. The invention can effectively process and analyze a large number of complex forging process parameters, improves the efficiency and accuracy of data processing, so as to more accurately predict potential risks and anomalies and ensure the safety and efficiency of the forging process.","['G06F18/2433', 'G06F18/213', 'G06N3/006', 'G06N3/04', 'G06N3/08']"
US10776659B2,Systems and methods for compressing data,"A method of compressing data in the context of a decision-making task includes receiving raw data, analyzing the raw data to determine content of the raw data, and adjusting one or more one data compression parameters in a compression algorithm. The adjustment of the one or more compression parameters is based on the content of the raw data and a received decision-making task to produce a modified compression algorithm. The raw data is thereafter compressed using the modified compression algorithm and output as compressed data.","['G06K9/6203', 'G06V20/13', 'G06F18/214', 'G06F18/24', 'G06K9/0063', 'G06K9/03', 'G06K9/3233', 'G06K9/6256', 'G06K9/6267', 'G06N5/02', 'G06V10/25', 'H04N19/103', 'H04N19/426', 'H04N23/69', 'H04N5/23296']"
CN110188795B,"Image classification method, data processing method and device","The application provides an image classification method and device, relates to the field of artificial intelligence, and particularly relates to the field of computational vision. The image classification method comprises the following steps: acquiring a convolution kernel parameter of a reference convolution kernel of a neural network and a mask tensor of the neural network, and carrying out Hadamard product operation on the reference convolution kernel of the neural network and the mask tensor corresponding to the reference convolution kernel to obtain a plurality of sub-convolution kernels; and carrying out convolution processing on the image to be processed according to the plurality of sub-convolution kernels, and classifying the image to be processed according to a convolution feature map finally obtained by convolution to obtain a classification result of the image to be processed. Because the mask tensor occupies smaller memory space relative to the convolution kernel, some devices with limited memory resources can be enabled to deploy a neural network comprising the reference convolution kernel and the mask tensor, so that classification of images is realized.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'Y02D10/00']"
US11947061B2,"Earthquake event classification method using attention-based convolutional neural network, recording medium and device for performing the method","An earthquake event classification method using an attention-based neural network includes: preprocessing input earthquake data by centering; extracting a feature map by nonlinearly converting the preprocessed earthquake data through a plurality of convolution layers having three or more layers; measuring importance of a learned feature of the nonlinear-converted earthquake data based on an attention technique in which interdependence of channels of the feature map is modeled; correcting a feature value of the measured importance value through element-wise multiply with the learned feature map; performing down-sampling through max-pooling based on the feature value; and classifying an earthquake event by regularizing the down-sampled feature value. Accordingly, main core features inherent in many/complex data are extracted through attention-based deep learning to overcome the limitations of the existing micro earthquake detection technology, thereby enabling earthquake detection even in low SNR environments.","['G01V1/01', 'G01V1/008', 'G06N3/082', 'G01V1/28', 'G06F18/21', 'G06F18/24', 'G06N3/045', 'G06N3/0464', 'G06V10/82']"
CN110222758B,"Image processing method, device, equipment and storage medium","The invention provides an image processing method, an image processing device, equipment and a storage medium, wherein the method comprises the following steps: acquiring a target image which needs resolution enhancement processing, and determining an image compression ratio matched with the target image; acquiring a first training sample image, and performing downsampling processing on the first training sample image to form a second training sample image, wherein the resolution of the second training sample image is lower than that of the first training sample image; compressing the second training sample image according to the image compression ratio to form a third training sample image; and training the image processing model through the first training sample image and the third training sample image so that the image processing model carries out resolution enhancement processing on the target image. The invention can eliminate noise points generated when the image processing model reconstructs the image, reduce peak signal-to-noise ratio of the reconstructed image and enhance resolution of the reconstructed image.","['G06F18/214', 'G06F18/22']"
CN118433198A,Data transmission method and system,"The invention discloses a data transmission method, which converts an input sequence into a potential spatial representation and converts the potential representation into an output representation through a neural network. The data is converted into the potential space representation, compression is realized in the conversion process, so that the cost of transmission and storage can be reduced, on the one hand, the potential space is subjected to compression coding or encryption coding through an algorithm, the potential space representation is transmitted instead of the feature vector, the original data is mapped to a new data space, and the problem of data privacy is well solved.","['H04L67/1078', 'G06N5/045', 'H04L63/0428']"
CN111402203B,Fabric surface defect detection method based on convolutional neural network,"The invention discloses a fabric surface defect detection method based on a convolutional neural network, which comprises the following steps: s1, collecting and marking a data set; s2, making a GroundTruth of a data set defect sample image; s3, constructing a convolutional neural network model; s4, training a convolutional neural network model to obtain an optimal model; s5, acquiring a defect image of the fabric on line, inputting the fabric image to be detected into the trained convolutional neural network model for image segmentation, and realizing on-line automatic detection through the convolutional neural network model so as to identify the defect on the surface of the fabric. The invention can overcome the defect of manual design defect characteristics, and can learn the characteristics from the pre-marked sample data set by utilizing the convolutional neural network, thereby quickly and accurately dividing, realizing accurate and automatic detection of the defects on the surface of the fabric, saving manpower and material resources and improving the quality of the fabric product.","['G06T7/0004', 'G06F18/241', 'G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T7/10', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30124', 'Y02P90/30']"
CN212305354U,Sensor suite and system for monitoring industrial environment and indoor agricultural facilities,"Sensor kits and systems configured for monitoring industrial environments and indoor agricultural facilities are provided, including kits having self-configuring sensor networks, communication gateways, and auto-configured backend systems.","['G05B19/042', 'H04L41/0803', 'G05B19/4183', 'G05B19/41845', 'G05B19/4185', 'G06N5/04', 'G16Y20/10', 'H04L41/0806', 'H04L41/0809', 'H04L41/0886', 'H04L41/16', 'H04L67/12', 'H04L67/125', 'H04L67/34', 'H04L67/565', 'H04L67/5651', 'H04L69/04', 'H04N19/136', 'H04W4/38', 'H04W4/70', 'H04W40/02', 'G05B2219/31449', 'G06F18/2193', 'G06N20/00', 'H04N19/50', 'H04W84/22', 'Y02P90/80']"
CN112990296B,Image-text matching model compression and acceleration method and system based on orthogonal similarity distillation,"The invention provides a method and a system for compressing and accelerating an image-text matching model based on orthogonal similarity distillation, wherein the method comprises the following steps: s1: acquiring a picture-text matching data set, and constructing a student network model and a teacher network model; s2: preprocessing and data loading are carried out on the image-text matching data set; s3: calculating a difference similarity matrix based on the similarity matrix of the student network model and the similarity matrix of the teacher network model; calculating a singular value based on the difference similarity matrix; constructing an orthogonal similarity soft distillation loss function and an orthogonal similarity hard distillation loss function based on the singular value; calculating a joint loss function; training a student network model based on a joint loss function; s4: performing performance test on the trained student network model to obtain a performance evaluation result of the image-text matching data set and the trained student network model; s5: and inputting the image or the text to be detected into the trained student network model, and outputting the text or the image.","['G06F18/22', 'G06F18/217', 'G06F18/41']"
CN113569667B,Inland ship target identification method and system based on lightweight neural network model,"The invention discloses a inland ship target identification method and system based on a lightweight neural network model, wherein the method comprises the following steps: s1, constructing a lightweight neural network model, and compressing a MobileNet 3 Largen network in a feature extraction network part to obtain a feature extraction network; on the algorithm prediction structure, utilizing a feature pyramid structure to perform multi-convolution layer feature fusion; and performing loss calculation by using a loss function fused with the distance measurement index; s2, screening and sorting inland ship images to form inland ship image data sets, and dividing training sets and test sets; s3, training the constructed lightweight neural network model; s4, identifying the inland ship targets by using the trained model. The method effectively improves the image target recognition precision of the inland ship, reduces the dependence of ship recognition on the calculation performance of hardware equipment, and effectively improves the processing capability of the inland environment ship video monitoring information.","['G06F18/214', 'G06F18/24', 'G06F18/253', 'G06N3/045']"
US12309526B2,"Video image transmission method, device, interactive intelligent tablet and storage medium","The present application relates to a video image transmission method, device, an interactive intelligent tablet and a storage medium. The method comprises: acquiring a video image captured by a first video communication end; acquiring semantic information in the video image; and sending the semantic information to a second video communication end, wherein the semantic information is used to reconstruct a reconstruction image of the video image at the second video communication end.","['H04N7/147', 'G06F18/251', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V10/82', 'G06V20/41', 'G06V40/107', 'G06V40/16', 'G06V40/174', 'H04N19/102', 'H04N19/169', 'H04N19/172', 'H04N19/39', 'H04N19/42', 'H04N19/44', 'H04N19/46', 'H04N19/70', 'H04N21/234', 'H04N21/4402', 'H04N21/4788', 'H04N7/141', 'H04N7/15', 'H04N7/155']"
US12287623B2,Methods and systems for automatically creating statistically accurate ergonomics data,"The systems and methods provide an action recognition and analytics tool for use in manufacturing, health care services, shipping, retailing and other similar contexts. Machine learning action recognition can be utilized to determine cycles, processes, actions, sequences, objects and or the like in one or more sensor streams. The sensor streams can include, but are not limited to, one or more video sensor frames, thermal sensor frames, infrared sensor frames, and or three-dimensional depth frames. The analytics tool can provide for analyzing ergonomic data from the one or more sensor streams.","['G05B19/4183', 'G05B19/41835', 'G06F11/0721', 'G06F11/079', 'G06F11/3452', 'G06F16/2228', 'G06F16/2365', 'G06F16/24568', 'G06F16/9024', 'G06F16/9035', 'G06F16/904', 'G06F30/20', 'G06F30/23', 'G06F30/27', 'G06F9/4498', 'G06F9/4881', 'G06N20/00', 'G06N3/008', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N7/01', 'G06Q10/06', 'G06Q10/063112', 'G06Q10/06316', 'G06Q10/06393', 'G06Q10/06395', 'G06Q10/06398', 'G06T19/006', 'G06V10/25', 'G06V10/454', 'G06V10/82', 'G06V20/52', 'G06V40/20', 'G09B19/00', 'B25J9/1664', 'B25J9/1697', 'G01M99/005', 'G05B19/41865', 'G05B19/423', 'G05B2219/32056', 'G05B2219/36442', 'G05B23/0224', 'G06F18/217', 'G06F2111/10', 'G06F2111/20', 'G06N3/006', 'G06Q10/083', 'G06Q50/26', 'G16H10/60', 'G16H40/20', 'Y02P90/02']"
US12111410B2,Techniques for radar data compression,"According to some aspects of the disclosure, techniques for compression techniques for the radar data that can be used in real-time applications for automated or self-driving vehicles. One or more compression techniques can be selected and/or configured based on information regarding operational conditions provided by a central (vehicle) computer. Operational conditions can include environmental data (e.g., weather, traffic), processing capabilities, mode of operation, and more. Compression techniques can facilitate transport of compressed radar data from a radar sensor to the central computer for processing of the radar data for object detection, identification, positioning, etc.","['G01S7/003', 'G01S7/03', 'G01S7/2922', 'G01S7/354', 'G06N3/08', 'G07C5/008', 'G06N3/044', 'G06N3/045']"
CN109154990B,Finding convolutional layers in convolutional neural networks,"An embodiment provides a processor including logic to accelerate convolutional neural network processing, the processor comprising: first logic to apply a convolution layer to an image to generate a first convolution result; and second logic to apply a find convolution layer to the first convolution result to generate a second convolution result, the second convolution result associated with a location of the first convolution result within a global filter kernel.","['G06V10/82', 'G06N3/063', 'G06F16/36', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/09', 'G06T7/73', 'G06V10/454', 'G06V20/10', 'G06V20/56', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/30244', 'G06T2207/30248']"
CN110826566B,Target slice extraction method based on deep learning,"The invention relates to a target slice extraction method based on deep learning, which comprises the following steps: determining a target to be extracted based on the original image, and building a deep convolutional neural network for the target and training; inputting an original image into a trained deep convolution neural network, and performing pixel-level target background separation on the original image containing a background through the deep convolution neural network to realize target segmentation; according to a target image obtained by separating the background and a preset slice size, acquiring a target slice image and adjusting the size of the target slice image; and judging whether the adjusted target slice image has missing pixels, if so, calculating the missing size and performing corresponding missing filling to obtain the final target slice. The method realizes automatic target retrieval and pixel segmentation, supports batch preparation of target slices, ensures that the target slices cannot be randomly cut and scaled in the extraction process, and realizes intellectualization and high efficiency of target slice extraction.","['G06V10/267', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V10/462']"
US10672387B2,Systems and methods for recognizing user speech,"The various implementations described herein include methods, devices, and systems for recognizing speech, such as user commands. In one aspect, a method includes: (1) receiving audio input data via the one or more microphones; (2) generating a plurality of energy channels for the audio input data; (3) generating a feature vector by performing a per-channel normalization to each channel of the plurality of energy channels; and (4) obtaining recognized speech from the audio input utilizing the feature vector.","['G10L15/16', 'G10L15/02', 'G10L19/26', 'G10L15/20', 'G10L2015/223', 'G10L25/18']"
CN106096531B,A kind of traffic image polymorphic type vehicle checking method based on deep learning,"The invention discloses a kind of traffic image polymorphic type vehicle checking method based on deep learning, the feature of neural network is combined with algorithm of generating layered regions first, Area generation and two processes of regional determination are realized simultaneously using the convolutional layer of neural network, then it carries out being determined as that Area generation provides additional reference frame for the moving region of the discrete series image of special scenes using background model, and the update for combining vehicle detection result to carry out point situation to background model is corrected, furthermore, it also proposed network model compression scheme to carry out model parameter and calculate the reduction of time, and propose the conventional non-maxima suppression scheme of the new testing result optimization means replacement calculated based on grouping error, improve overall detection accuracy.","['G06V20/52', 'G06V20/584']"
EP3745394A1,End-to-end text-to-speech conversion,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating speech from text. One of the systems includes one or more computers and one or more storage devices storing instructions that when executed by one or more computers cause the one or more computers to implement: a sequence-to-sequence recurrent neural network configured to: receive a sequence of characters in a particular natural language, and process the sequence of characters to generate a spectrogram of a verbal utterance of the sequence of characters in the particular natural language; and a subsystem configured to: receive the sequence of characters in the particular natural language, and provide the sequence of characters as input to the sequence-to-sequence recurrent neural network to obtain as output the spectrogram of the verbal utterance of the sequence of characters in the particular natural language.","['G06N3/08', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G10L13/04', 'G10L13/08', 'G10L15/16', 'G10L25/18', 'G10L25/30']"
US11632533B2,System and method for generating combined embedded multi-view interactive digital media representations,"Various embodiments describe systems and processes for capturing and generating multi-view interactive digital media representations (MIDMRs). In one aspect, a method for automatically generating a MIDMR comprises obtaining a first MIDMR and a second MIDMR. The first MIDMR includes a convex or concave motion capture using a recording device and is a general object MIDMR. The second MIDMR is a specific feature MIDMR. The first and second MIDMRs may be obtained using different capture motions. A third MIDMR is generated from the first and second MIDMRs, and is a combined embedded MIDMR. The combined embedded MIDMR may comprise the second MIDMR being embedded in the first MIDMR, forming an embedded second MIDMR. The third MIDMR may include a general view in which the first MIDMR is displayed for interactive viewing by a user on a user device. The embedded second MIDMR may not be viewable in the general view.","['H04N13/221', 'G06T17/00', 'G06T7/285', 'H04N13/117', 'H04N13/178', 'H04N13/189', 'H04N13/243', 'H04N13/275', 'H04N13/279', 'H04N13/344', 'H04N13/366', 'G06T2207/10021', 'G06T2207/30252', 'G06T2219/2008']"
US20230351157A1,Federated learning of autoencoder pairs for wireless communication,"Various aspects of the present disclosure generally relate to wireless communication. In some aspects, a client may determine, using a first client autoencoder, a feature vector associated with one or more features associated with an environment of the client. The client may determine a latent vector using a second client autoencoder and based at least in part on the feature vector. The client may transmit the feature vector and the latent vector. Numerous other aspects are provided.","['H04L41/16', 'G06N3/088', 'G06N3/0455', 'G06N3/045', 'G06N3/047', 'G06N3/098', 'H04L1/0026', 'G06N3/063', 'H04B17/336', 'H04B17/364', 'H04L1/0029', 'H04W24/02']"
US12165439B2,System and method for interactively reporting of roadway incidents on an AI device,"System and methods for including a system mounted to a vehicle for identifying incidents of a roadway and transmitting the incidents to a server, the server located remotely from the system, the system comprising: a device having: a camera for obtaining digital images; at least one sensor including a location based sensor; a memory and processor for executing image processing instructions for processing the digital images for automated detection of the incidents, generating object data based on the processing, generating incident data including the object data and the images; and a network interface for sending the incident data over a communications network to the server during operation of the vehicle on the roadway. Also included are both interactive and autonomous possesses for implementing the device.","['G06V10/82', 'G06N3/045', 'G06N3/08', 'G06V20/56', 'G06V20/58', 'G07C5/008', 'G07C5/085', 'G07C5/0866', 'G08G1/0112', 'G08G1/0133', 'H04N7/181', 'H04N7/185', 'G08G1/09623']"
US10819992B2,Methods and apparatuses for performing encoding and decoding on image,"Provided is a computer-recordable recording medium having stored thereon a video file including artificial intelligence (AI) encoding data, wherein the AI encoding data includes: image data including encoding information of a low resolution image generated by AI down-scaling a high resolution image; and AI data about AI up-scaling of the low resolution image reconstructed according to the image data, wherein the AI data includes: AI target data indicating whether AI up-scaling is to be applied to at least one frame; and AI supplementary data about up-scaling deep neural network (DNN) information used for AI up-scaling of the at least one frame from among a plurality of pieces of pre-set default DNN configuration information, when AI up-scaling is applied to the at least one frame.","['H04N19/30', 'H04N19/132', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06T3/4046', 'H04N19/146', 'H04N19/172', 'H04N19/182', 'H04N19/184', 'H04N19/42', 'H04N19/50', 'H04N19/59', 'H04N19/70', 'H04N19/85', 'G06N3/044', 'G06N3/048']"
US11288770B2,Apparatuses and methods for performing artificial intelligence encoding and artificial intelligence decoding on image,"An artificial intelligence (AI) decoding apparatus includes a memory storing one or more instructions, and a processor configured to execute the stored one or more instructions, to obtain image data corresponding to a first image that is encoded, obtain a second image corresponding to the first image by decoding the obtained image data, determine whether to perform AI up-scaling of the obtained second image, based on the AI up-scaling of the obtained second image being determined to be performed, obtain a third image by performing the AI up-scaling of the obtained second image through an up-scaling deep neural network (DNN), and output the obtained third image, and based on the AI up-scaling of the obtained second image being determined to be not performed, output the obtained second image.","['G06T3/4046', 'G06N3/084', 'G06N20/10', 'G06N3/045', 'G06N3/048', 'G06T3/4053', 'G06T9/002', 'H04N19/117', 'H04N19/132', 'H04N19/154', 'H04N19/172', 'H04N19/46', 'H04N19/463', 'H04N19/80', 'H04N19/85', 'H04N21/234363', 'H04N21/23439', 'H04N21/251', 'H04N21/26258', 'H04N21/4348', 'H04N21/440263', 'H04N21/8193', 'G06N3/063', 'G06T2207/20081', 'G06T2207/20084', 'H04N19/14', 'H04N19/146']"
US11457244B2,"Apparatus, a method and a computer program for video coding and decoding","A method comprising: obtaining a block of a picture or a picture in an encoder; determining if the block/picture is used for on-line learning; if affirmative, encoding the block/picture; reconstructing a coarse version of the block/picture or the respective prediction error block/picture; enhancing the coarse version using a neural net; fine-tuning the neural net with a training signal based on the coarse version; determining if the block/picture is enhanced using the neural net; and if affirmative, encoding the block/picture with enhancing using the neural net.","['H04N19/85', 'H04N19/395', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'H04N19/124', 'H04N19/172', 'H04N19/176', 'H04N19/59', 'G06N3/048', 'G06N3/088', 'G06N5/01']"
US11903741B2,Shockable heart rhythm classifier for defibrillators,"Neural network based heart rhythm classifiers are described. The neural network is configured to receive an electrocardiogram segment and to output an indication of whether the electrocardiogram segment represents a heart rhythm that is suitable for treatment by a defibrillation shock. Preferably, the received electrocardiogram segment is not transformed or processed prior to its reception by the neural network and no features of the electrocardiogram are identified to the neural network. In some embodiments, the received electrocardiogram segment is the sole input to the neural network. In various embodiments, the neural network is configured to classify electrocardiogram segments obtained while CPR was being performed on the patient. Classifiers that output a characteristic of CPR are also described. Such outputs may include an indication of whether CPR was being performed while the ECG was being detected, compression depth, etc. The described classifiers are well suited for use in defibrillators.","['A61B5/7267', 'A61B5/346', 'A61B5/361', 'A61B5/7264', 'A61N1/3904', 'A61N1/3956', 'G06N3/045', 'G06N3/084', 'A61B5/316', 'A61B5/366', 'A61B5/7203', 'A61B5/7221', 'A61N1/3987', 'G16H50/70']"
US11303802B2,"Image capturing apparatus, control method therefor, and storage medium","The present invention makes it possible to suppress, to the greatest extent possible, a situation where, in an image capturing apparatus that captures images automatically, the apparatus misses capturing a video that a user wishes to capture. An image capturing apparatus comprises an image capturing unit for capturing an object image and outputting image data, a control unit for controlling whether or not to carry out an image capturing operation of recording the image data output by the image capturing unit, and an obtaining unit for obtaining information pertaining to a frequency of the image capturing operation, wherein the control unit changes a threshold for determining whether or not to carry out the image capturing operation in accordance with the information pertaining to the frequency and total image capturing time.","['H04N23/66', 'H04N5/23218', 'G03B15/00', 'G03B7/00', 'H04N23/61', 'H04N23/617', 'H04N23/64', 'H04N23/65', 'H04N23/673', 'H04N23/6812', 'H04N5/232123', 'H04N5/23225', 'G06F3/167']"
US12017301B2,"Systems and methods for compression, management, and analysis of downbeam camera data for an additive machine","An example additive manufacturing apparatus includes an energy source to melt material to form a component in an additive manufacturing process, a camera aligned with the energy source to obtain image data of the melted material during the additive manufacturing process, and a controller to control the energy source during the additive manufacturing process in response to processing of the image data. The controller adjusts control of the energy source based on a correction determined by: applying an artificial intelligence model to image data captured by a camera during an additive manufacturing process, the image data including an image of a melt pool of the additive manufacturing process; predicting an error in the additive manufacturing process using an output of the artificial intelligence model; and compensating for the error by generating a correction to adjust a configuration of the energy source during the additive manufacturing process.","['B23K26/342', 'B22F10/36', 'B22F10/38', 'B22F10/85', 'B23K26/032', 'B23K26/0626', 'B23K26/073', 'B23K26/082', 'B23K31/003', 'B23K31/006', 'B33Y10/00', 'B33Y30/00', 'B33Y50/02', 'G06N3/045', 'B22F10/28', 'G06N3/044', 'G06N3/088', 'Y02P10/25']"
US20230281809A1,Connected machine-learning models with joint training for lesion detection,"Embodiments disclosed herein generally relate to connected machine learning models with joint training for lesion detection. Particularly, aspects of the present disclosure are directed to accessing a three-dimensional magnetic resonance imaging (MRI) image, wherein the three-dimensional MRI image depicts a region of a brain of a subject, wherein the region of the brain includes at least a first type of lesions and a second type of lesions; inputting the three-dimensional MRI image into a machine-learning model comprising a first convolutional neural network and a second convolutional neural network; generating a first segmentation mask for the first type of lesions using the first convolutional neural network that takes as input the three-dimensional MRI image; generating a second segmentation mask for the second type of lesions using the second convolutional neural network that takes as input the three-dimensional MRI image; and outputting the first segmentation mask and the second segmentation mask.","['G06T7/0012', 'G06T7/0014', 'G06N3/045', 'G06N3/0464', 'G06N3/084', 'G06T7/0016', 'G06T7/11', 'G06T7/136', 'G06T7/174', 'G06N3/044', 'G06N3/08', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30096', 'G06T2207/30242']"
US12267518B2,Generating images using neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating images using neural networks. One of the methods includes generating the output image pixel by pixel from a sequence of pixels taken from the output image, comprising, for each pixel in the output image, generating a respective score distribution over a discrete set of possible color values for each of the plurality of color channels.","['H04N19/50', 'G06F18/2113', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/56', 'G06V30/194', 'H04N19/52', 'H04N19/172', 'H04N19/182', 'H04N19/186']"
US11361248B2,Multi-stage machine learning-based chain diagnosis,"Various aspects of the disclosed technology relate to machine learning-based chain diagnosis. Faults are injected into scan chains in a circuit design. Simulations are performed on the fault-injected circuit design to determine observed failing bit patterns. Bit-reduction is performed on the observed failing bit patterns to construct first training samples. Using the first training samples, first-level machine-learning models are trained. Affine scan cell groups are identified. Second training samples are prepared for each of the affine scan cell groups by performing bit-filtering on a subset of the observed failing bit patterns associated with the faults being injected at scan cells in the each of the affine scan cell groups. Using the second training samples, second-level machine-learning models are trained. The first-level and second-level machine learning models can be applied in a multi-stage machine learning-based chain diagnosis process.","['G06N20/00', 'G01R31/318583', 'G01R31/31704', 'G01R31/3177', 'G01R31/318342', 'G06N3/045', 'G06N3/08', 'G06N7/005', 'G06N7/01']"
US11200702B2,"AI encoding apparatus and operation method of the same, and AI decoding apparatus and operation method of the same","Provided is an artificial intelligence (AI) decoding apparatus including a memory storing one or more instructions; and a processor configured to execute the one or more instructions to, when an image is input to a second DNN including a plurality of layers, obtain first result values based on an operation between the image and a first filter kernel and obtain second result values based on an operation between the image and a second filter kernel, from a first layer including the first and second filter kernels from among the plurality of layers, perform normalization by transforming the first result values into first values by using a first scale factor, and, perform normalization by transforming the second result values into second values by using a second scale factor, transform the first values and the second values into integer values included in a preset range.","['G06T3/4046', 'G06F18/214', 'G06K9/6232', 'G06K9/6256', 'G06N3/02', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/084', 'G06T9/002', 'G06V10/454', 'G06V10/7715', 'G06V10/82', 'H04N19/102', 'H04N19/117', 'H04N19/136', 'H04N19/154', 'H04N19/157', 'H04N19/192', 'H04N19/59', 'H04N19/80', 'H04N19/85', 'G06N3/044', 'G06T2207/20081', 'G06T2207/20084']"
CN111868751B,Using non-linear functions applied to quantization parameters in machine learning models for video coding,"Encoding the image block includes presenting the image block and a first value corresponding to a first quantization parameter to a machine learning model; obtaining a first mode decision parameter from a machine learning model; and encoding the image block using the first mode decision parameter. The first value is generated from a non-linear function using the first quantization parameter as an input. The machine learning model is trained to output the mode decision parameters using the training data. Each training data includes a training block encoded by a second encoder, a second mode decision parameter used by the second encoder to encode the training block, and a second value corresponding to a second quantization parameter. The second encoder encodes the training block using the second quantization parameter and the second value is generated from a nonlinear function using the second quantization parameter as an input.","['H04N19/124', 'H04N19/119', 'G06N3/048', 'G06N3/084', 'G06T9/002', 'H04N19/126', 'H04N19/147', 'H04N19/164', 'H04N19/176', 'H04N19/96']"
US10750161B2,Multi-view interactive digital media representation lock screen,"Various embodiments describe systems and processes for capturing and generating multi-view interactive digital media representations for display on a user device. In one aspect, a mobile device is provided which comprises a display, one or more processors, memory, and one or more programs stored in the memory. The one or more programs comprise instructions for locking the mobile device, and providing a lock screen on the display in a lock mode upon receiving user input for accessing the mobile device. The lock screen may display a multi-view interactive digital media representation (MIDMR) which provides an interactive three-dimensional representation of an object that is responsive to user interaction with the mobile device. The MIDMR may respond to spatial and movement sensors in the mobile device. The mobile device may be unlocked for use upon receiving user identification input, which may include maneuvering the MIDMR in a predetermined pattern.","['H04N13/349', 'G06F21/36', 'G06T11/60', 'H04N13/282']"
US11392838B2,"Method, equipment, computing device and computer-readable storage medium for knowledge extraction based on TextCNN","The application discloses a method for knowledge extraction based on TextCNN, comprising: S10, collecting first training data, and constructing a character vector dictionary and a word vector dictionary; S20, constructing a first convolutional neural network, and training the first convolutional neural network based on a first optimization algorithm, the first convolutional neural network comprises a first embedding layer, a first multilayer convolution, and a first softmax function connected in turn; S30, constructing a second convolutional neural network, and training the second convolutional neural network based on a second optimization algorithm, the second convolutional neural network comprises a second embedding layer, a second multilayer convolution, a pooling layer, two fully-connected layers and a second softmax function, the second embedding layer connected in turn; S40, extracting a knowledge graph triple of the to-be-predicted data according to an entity tagging prediction output by the first trained convolutional neural network and an entity relationship prediction output by the second trained convolutional neural network.","['G06N3/084', 'G06F16/36', 'G06F18/213', 'G06F18/214', 'G06F18/2163', 'G06F18/22', 'G06F18/25', 'G06F18/29', 'G06F40/30', 'G06K9/6201', 'G06K9/6232', 'G06K9/6256', 'G06K9/6261', 'G06K9/6288', 'G06K9/6296', 'G06N20/10', 'G06N3/045', 'G06N3/08', 'G06N5/02', 'G06N5/022', 'G06N5/025', 'G06F40/284', 'G06F40/295']"
US12237947B2,Federated learning for classifiers and autoencoders for wireless communication,"Various aspects of the present disclosure generally relate to wireless communication. In some aspects, a client may select, based at least in part on a classifier, an autoencoder of a set of autoencoders to be used for encoding an observed wireless communication vector to generate a latent vector. The client may transmit the latent vector and an indication of the autoencoder. Numerous other aspects are provided.","['G06N3/088', 'H04L25/0254', 'G06N3/044', 'G06N3/0455', 'G06N3/047', 'H04L25/03171']"
US9183351B2,Mobile system with network-distributed data processing for biomedical applications,"Adaptive system for medical monitoring distributes data processing among computing devices connected to a network to optimize usage of computational resources, network communication speed and user experience. Data processing is distributed into several levels with bi-directional communication between the levels (computing devices) to coordinate and adjust data compression, filtering, and analysis, as well as the size of buffered data available for transmission and/or receiving.","['G06F19/3418', 'A61B5/0022', 'A61B5/02055', 'A61B5/0452', 'A61B5/055', 'A61B5/349', 'A61B5/7203', 'G06F19/3443', 'G06F19/345', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'A61B5/04004', 'A61B5/0428', 'A61B5/30', 'A61B6/032', 'A61B6/5217']"
US12242389B2,Application-level memory control group memory reclamation,"An application-level memory control group of a first application may be created when the first application is opened. An anonymous page of the first application is added to a least recently used linked list of the application-level memory control group, and a file page of the first application is added to a global least recently used linked list. An application-level memory control group is created in a dimension of an application, and an anonymous page of the application is managed in a refined manner. In addition, a file page of the application-level memory control group may be managed based on a global least recently used linked list.","['G06F9/5016', 'G06F12/023', 'G06F12/0253', 'G06F12/08', 'G06F12/0882', 'G06F12/123', 'G06F12/1441', 'G06F12/1483', 'G06F12/1491', 'G06F9/5022', 'G06F2212/1032', 'G06F2212/1044']"
CN113222179B,A Federated Learning Model Compression Method Based on Model Sparsification and Weight Quantization,"The invention discloses a federal learning model compression method based on model sparsification and weight quantification, which comprises the following steps: step 1, a client performs local model training by using a local data set; step 2, the client performs model sparsification on the weight matrix generated by the local model training; step 3, the client performs weight quantization on the matrix after the sparsification; step 4, the client transmits the compressed model to the server through a wireless channel; and 5, decompressing the received weight matrix by the server, and finishing federal learning aggregation. The method has the advantages that the problem of insufficient resources in the federal learning training process is effectively solved, and the federal learning training precision is improved through an optimization algorithm.","['G06N20/20', 'Y02D30/70']"
US20230207061A1,Pathogenicity language model,"A system comprises chunking logic that chunks (or splits) a multiple sequence alignment (MSA) into chunks, first attention logic that attends to a representation of the chunks and produces a first attention output, first aggregation logic that produces a first aggregated output that contains those features in the first attention output that correspond to masked residues in the plurality of masked residues, mask revelation logic that produces an informed output based on the first aggregated output and a Boolean mask, second attention logic that attends to the informed output and produces a second attention output based on masked residues revealed by the Boolean mask, second aggregation logic that produces a second aggregated output that contains those features in the second attention output that correspond to masked residues concealed by the Boolean mask, and output logic that produces identifications of the masked residues based on the second aggregated output.","['G16B30/00', 'G16B20/20', 'G06F18/2111', 'G06F18/2148', 'G06F18/2155', 'G06N20/00', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/126', 'G16B10/00', 'G16B20/00', 'G16B20/40', 'G16B30/10', 'G16B40/00', 'G16B40/20', 'G16B40/30', 'G16B50/10', 'Y02A90/10']"
US11297084B2,Methods and apparatus to perform malware detection using a generative adversarial network,"Methods, apparatus, systems and articles of manufacture are disclosed to perform malware detection using a generative adversarial network. An example apparatus includes a first encoder network to encode an input sample into a first encoded sample, the first encoder network implemented using a multilayer perception (MLP) network, a generator network to reconstruct the first encoded sample to generate a reconstructed sample, a discriminator network to, in response to obtaining the first encoded sample and the reconstructed sample, generate a loss function based on the reconstructed sample and the input sample, and an optimization processor to, when the loss function satisfies a threshold loss value, classify the input sample as malicious.","['H04L63/1425', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06N20/00']"
CN109903228B,Image super-resolution reconstruction method based on convolutional neural network,"The invention discloses an image super-resolution reconstruction method based on a convolutional neural network, which comprises the steps of extracting shallow features by using two layers of convolutional layers, extracting and fusing multi-scale features by using a plurality of U-shaped networks, effectively enhancing useful features by using a residual channel attention mechanism, inhibiting noise, completing final reconstruction of an image by using one layer of convolutional layer, performing end-to-end training on the network by using an image training set and storing model parameters for testing. The invention obviously improves the image reconstruction quality and improves the resolution of the image under the condition of not improving the hardware cost.",[]
US10938413B2,Processing core data compression and storage system,"Methods and systems regarding the rapid and efficient compression and decompression of sparse data are disclosed. One method for compressing a set of data from a sparse matrix includes, evaluating a sequence of data entries from the set of data, extracting a sequence of sparse data values from the sequence, extracting a sequence of non-sparse data value run lengths from the sequence, formulating a set of row pointers from the sequence, storing the sequence of sparse data values in a first set of memory addresses, and storing the sequence of non-sparse data value run lengths in a second set of memory addresses. The set of row pointers identify a set of rows of the sparse matrix in both the first and second sets of memory addresses. Rapid decompression can be conducted using the row pointers.","['G06F17/16', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'H03M7/3066', 'H03M7/42', 'H03M7/46', 'H03M7/6052']"
US10748313B2,Dynamic multi-view interactive digital media representation lock screen,"Described are systems and processes for generating multi-view interactive digital media representations (MIDMR) for display on a user device. In one aspect, a mobile device is provided which comprises a display, one or more processors, memory, and one or more programs stored in memory. The one or more programs comprise instructions for locking the mobile device, and providing a lock screen on the display in a lock mode upon receiving user input for accessing the mobile device. The lock screen may display a dynamic MIDMR that dynamically changes without user input, which provides an interactive three-dimensional representation of an object that is responsive to user interaction with the mobile device. The dynamic MIDMR displayed is selected based on predetermined criteria, and may change based on a predetermined algorithm that includes weighted predetermined criteria factors as variables and recalculates the algorithm value to determine changes to the dynamic MIDMR.","['G06T5/77', 'G06T11/60', 'G06T5/005', 'H04N13/111']"
US12101142B2,"Method, device and computer readable medium of communication","Embodiments of the present disclosure relate to methods, devices and computer readable storage media of communication. A network device transmits, to a terminal device, channel state information reference signals associated with first number of ports at the network device; receives, from the terminal device, compressed channel state information generated based on capability of the terminal device; and recoveries, from the compressed channel state information, channel state information associated with second number of ports at the network device, the second number of ports being not less than the first number of ports. The terminal device receives, from the network device, the channel state information reference signals associated with the first number of ports at the network device; determines channel state information based on the channel state information reference signals; compresses the channel state information based on capability of the terminal device; and transmits the compressed channel state information to the network device for recovery of the channel state information associated with the second number of ports. As such, CSI can be acquired more accurately with reduced complexity and overhead.","['H04L27/261', 'H04B7/0456', 'H04L1/0026', 'H04L1/0029', 'H04L5/0057', 'H03M7/6047', 'H03M7/6052']"
EP3754548A1,A method for recognizing an object in an image using features vectors of an encoding neural network,"The present disclosure relates to a method for recognizing an object in an input image. The method comprises: providing an image encoder (120, 502, 601) configured to encode an image to provide a visual feature vector representing the image in an image space, the image encoder comprising a trained convolutional neural network (121), wherein the image space is defined by a fully connected layer of the convolutional neural network. Visual center of mass vectors (122, 123, 124, 504.1-M, 533.1-M) representing object classes in the image space may be provided. The image encoder (120, 502, 601) may encode the input image (505) to provide an input visual feature vector (506) representing the input image (505). The object may be recognized by selecting one of the visual center of mass vectors (504.1-M, 533.1-M) using a proximity criterion relative to the input visual feature vector (506).",['G06F18/24133']
CN113689954B,"Hypertension risk prediction method, device, equipment and medium","The invention relates to the field of medical science and technology, and provides a hypertension risk prediction method, device, equipment and medium, wherein the method comprises the steps of acquiring personal information and fundus images of a target to be detected; respectively inputting the fundus image into a preset arteriovenous segmentation model, a optic disc segmentation model and a lesion recognition model, and respectively extracting arteriovenous blood vessels, optic disc areas and fundus lesion characteristics in the fundus image; quantifying the tube diameters of the arteriovenous vessels in the video disc area to obtain quantized values of the vessel diameters corresponding to the arteriovenous vessels respectively; constructing a risk prediction model for predicting the target hypertension to be detected based on the blood vessel diameter quantized value, fundus lesion characteristics and personal information by using a machine learning regression method; and inputting the fundus image corresponding to the target to be detected into a risk prediction model for detection to obtain a hypertension prediction result of the target to be detected. Because the risk prediction model is trained by adopting a plurality of variable factors, the accuracy of hypertension risk prediction is greatly improved.","['G16H50/30', 'A61B3/12', 'A61B3/14', 'A61B5/7246', 'A61B5/7275', 'G06T5/90', 'G06T7/0012', 'G06T7/62', 'G16H10/60', 'G16H30/40', 'G16H50/20', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041', 'G06T2207/30096', 'G06T2207/30101', 'G06T2207/30104', 'Y02A90/10']"
US11783917B2,Artificial intelligence-based base calling,The technology disclosed processes input data through a neural network and produces an alternative representation of the input data. The input data includes per-cycle image data for each of one or more sequencing cycles of a sequencing run. The per-cycle image data depicts intensity emissions of one or more analytes and their surrounding background captured at a respective sequencing cycle. The technology disclosed processes the alternative representation through an output layer and producing an output and base calls one or more of the analytes at one or more of the sequencing cycles based on the output.,"['G16B40/20', 'G06K9/6218', 'G06F16/58', 'G06F16/907', 'G06F18/214', 'G06F18/217', 'G06F18/23', 'G06F18/23211', 'G06F18/24', 'G06F18/2415', 'G06F18/2431', 'G06K9/6222', 'G06K9/6232', 'G06K9/6256', 'G06K9/6262', 'G06K9/6267', 'G06K9/6277', 'G06K9/628', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N7/005', 'G06N7/01', 'G06V10/454', 'G06V10/751', 'G06V10/763', 'G06V10/764', 'G06V10/7715', 'G06V10/7784', 'G06V10/82', 'G06V10/993', 'G16B30/20', 'G16B40/00', 'G06N5/046']"
CN110867181B,Multi-target speech enhancement method based on joint estimation of SCNN and TCNN,"The invention provides a multi-target speech enhancement method based on SCNN and TCNN joint estimation. New stacked and time-series convolutional neural networks (STCNNs) were proposed based on SCNN and TCNN, with the Log Power Spectrum (LPS) as the main feature and input to SCNN to extract high-level abstract features. Secondly, a power function compressed Mel-cepstrum coefficient (PC-MFCC) more conforming to the auditory characteristics of human ears is proposed. The Time Convolutional Neural Network (TCNN) takes high-level abstract features extracted by a stacked convolutional neural network and the PC-MFCC as input, performs sequence modeling and performs joint estimation on clean LPS, the PC-MFCC and ideal proportion masking (IRM). Finally, in the enhancement stage, the different speech features are complementary in the synthesis of the speech. An IRM-based post-processing method is proposed to synthesize enhanced speech by adaptively adjusting the weights of the estimated LPS and IRM through speech presence information.","['G10L15/20', 'G10L15/02', 'G10L15/063', 'G10L21/0216', 'G10L21/0264', 'G10L25/03', 'G10L25/24', 'G10L25/30']"
US12058537B2,Cellular system,"A method for improving call performance in a wireless network includes applying AI techniques at the physical layer (PHY) to perform digital predistortion, channel estimation, and channel resource optimization including applying AI-based channel state information compression to compress feedback data from user equipment to a base station and applying AI-based fingerprinting processes to optimize positioning and localization in indoor environments and mapping disruptions to propagation patterns caused by individuals in a wireless environment; adjusting transceiver parameters during a call using an AI-based autoencoder design; and optimizing resource allocation and improving call quality between two devices by deploying AI at the PHY.","['H01Q3/46', 'H04B17/318', 'F21S8/086', 'F21V23/045', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G10L25/51', 'H01Q1/04', 'H01Q1/246', 'H01Q1/44', 'H01Q19/09', 'H01Q21/28', 'H01Q3/20', 'H01Q3/44', 'H04B7/024', 'H04B7/0617', 'H04W16/02', 'H04W16/28', 'H04W24/02', 'H04W4/027', 'H04W4/40', 'H04W4/44', 'F21W2131/103', 'G06V40/172', 'G06V40/25', 'H04B17/309', 'H04L67/10', 'H04L67/12', 'H04W4/38', 'H04W4/70']"
US12273232B2,Network device maintenance,"A method to access a device may include obtaining, at a first device, data over a short-range wireless network from a second device. The data may originate at a remote system that sends the data to the second device through a network connection over a wide area network. The method may also include in response to a fault at the second device, obtaining, at the first device from the remote system, a maintenance command for the second device. The maintenance command may be obtained by the first device over an analog voice network. The method may also include directing, from the first device to the second device, the maintenance command over the short-range wireless network to enable the second device to perform the maintenance command.","['H04L41/0661', 'H04L41/0816', 'H04L69/40', 'H04W24/04', 'H04W4/80', 'H04W76/18', 'H04W8/245', 'H04L41/145', 'H04L43/028', 'H04L43/10', 'H04W4/50', 'H04W88/04']"
CN108717866B,"Method, device, equipment and storage medium for predicting radiotherapy plan dose distribution","The invention discloses a method, a device, equipment and a storage medium for predicting radiotherapy plan dose distribution, and relates to the field of radiotherapy equipment and methods in medical equipment, wherein the method comprises the following steps: establishing a radiotherapy plan case database; carrying out preprocessing including data tagging and compressed dose map on input patient image information with contour drawing and structure information; and performing model training based on a deep learning algorithm, establishing a three-dimensional dose distribution model, and predicting three-dimensional dose distribution information of a new case by using the model. The embodiment of the invention can improve the overall speed and quality of the radiation treatment plan design, shorten the time for making the treatment plan, reduce the working intensity of radiotherapy doctors and physicists and improve the working efficiency.","['G16H30/20', 'G16H30/40', 'G16H50/20']"
US11609968B2,"Image recognition method, apparatus, electronic device and storage medium","An image recognition method, an apparatus, an electronic device, and a storage medium. The method may include extracting input matrices from a target image through input channels of a convolutional layer in a convolutional neural network model, obtaining first and second result matrices by traversing input matrices and performing input transformation and convolution kernel transformation, respectively, on the traversed input matrices through the row transformation reconstruction, performing matrix multiplication reconstruction on the first and second result matrices to obtain to-be-transformed matrices, performing output transformation on the to-be-transformed matrices through the row transformation reconstruction to obtain output matrices, splicing the output matrices and outputting the spliced output matrices through output channels of the convolutional layer to obtain a convolution result, and obtaining an image recognition result based on the convolution result into a pooling layer in the convolutional neural network model to perform an image recognition on the target image.","['G06F17/16', 'G06F18/21', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06V10/70', 'G06V10/82']"
US20210012575A1,Adjusting a digital representation of a head region,"Methods and devices for generating reference data for adjusting a digital representation of a head region, and methods and devices for adjusting the digital representation of a head region are disclosed. In some arrangements, training data are received. A first machine learning algorithm generates first reference data using the training data. A second machine learning algorithm generates second reference data using the same training data and the first reference data generated by the first machine learning algorithm.","['G06T19/20', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T7/337', 'G06N20/10', 'G06N3/047', 'G06N5/01', 'G06T2207/20081', 'G06T2219/2004', 'G06T2219/2012', 'G06T2219/2021']"
US12008497B2,Demand sensing and forecasting,The present invention provides a data processing system and method for demand sensing and forecasting. The invention includes generating hierarchical data set from historical data of one or more objects and processing the hierarchical data based on one or more forecasting data models created by an artificial engine to predict data trend. The invention determines required safety stock for each category of the one or more objects.,"['G06F16/215', 'G06F16/2365', 'G06F16/285', 'G06N3/044', 'G06N3/045', 'G06N3/088', 'G06Q10/06315', 'G06Q10/087', 'G06Q30/0201', 'G06Q30/0202']"
US20220037022A1,Ensemble machine-learning models to detect respiratory syndromes,"Provided is a process including: obtaining, with one or more processors, a set of data comprising a plurality of patient records, selecting a subset of the plurality of parameters for inputs into a machine learning system, generating a classifier using the machine learning system based on the training data and the subset of the plurality of parameters for inputs; receiving, with one or more processors, patient record of a first user; performing an analysis, with one or more processors, to identify acoustic measures from a voice sample of the first user.","['G06N20/20', 'G06N5/04', 'G16H10/60', 'G16H50/20', 'G06N3/082', 'G06N5/01', 'G10L25/66', 'H03M7/3059', 'H03M7/3082']"
US12067373B2,Hybrid filter banks for artificial neural networks,"The present disclosure advantageously provides a system including a memory, a processor, and a circuitry to execute one or more mixed precision layers of an artificial neural network (ANN), each mixed precision layer including high-precision weight filters and low precision weight filters. The circuitry is configured to perform one or more calculations on an input feature map having a plurality of input channels (cin) using the high precision weight filters to create a high precision output feature map having a first number of output channels (k), perform one or more calculations on the input feature map using the low precision weight filters to create a low precision output feature map having a second number of output channels (cout−k), and concatenate the high precision output feature map and the low precision output feature map to create a unified output feature map having a plurality of output channels (cout).","['G06F7/483', 'G06F7/5443', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06F2207/4824', 'G06N3/044', 'G06N3/048']"
US9153230B2,Mobile speech recognition hardware accelerator,A method for executing a mobile speech recognition software application based on a multi-layer neural network model includes providing to a hardware accelerator in the mobile device to classify one or more frames of an audio signal. The hardware accelerator includes a multiplier-accumulator (MAC) unit to perform matrix multiplication operations involved in computing the neural network output.,"['G10L15/16', 'G10L15/28']"
CN113688855B,"Data processing method, federated learning training method and related devices and equipment","The application provides a data processing method, a training method of federal learning, a related device and equipment, wherein the method is applied to a federal learning system, the federal learning system comprises a server and a plurality of terminals, the server stores a cooperative relationship corresponding to each terminal, the cooperative relationship is used for indicating the cooperative terminal corresponding to each terminal, and the method comprises the following steps: the method comprises the steps that a first terminal obtains a first machine learning model to be trained from a server; the first terminal is any one of a plurality of terminals; the first terminal trains a first machine learning model through local data stored by the first terminal, and trained model parameters are obtained; the first terminal determines a first cooperative terminal corresponding to the first terminal according to the cooperative relationship, and sends part or all of the model parameters trained by the first terminal to the server through the first cooperative terminal; the cooperative relationship is issued to the first terminal by the server. By implementing the method and the device, the security of data interaction between the server and the terminal can be improved.","['G06F18/214', 'G06N3/098', 'G06F21/60', 'G06F21/602', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/084', 'G06N3/09', 'H04L63/0428']"
US11206549B1,Wireless mesh network,"Among other things, aspects, features, and implementations of wireless mesh networks and wireless mesh network devices are described.","['H04W16/16', 'H04J11/0073', 'H04J11/0079', 'H04W36/06', 'H04W36/085', 'H04W72/1273', 'H04W72/1284', 'H04W72/21', 'H04J2011/0096', 'H04W48/12', 'H04W72/54', 'H04W74/0833', 'H04W74/0838', 'H04W84/045', 'H04W84/18', 'H04W92/10']"
US12127085B2,Systems and methods for mitigating vehicle pose error across an aggregated feature map,"Systems and methods for improved vehicle-to-vehicle communications are provided. A system can obtain sensor data depicting its surrounding environment and input the sensor data (or processed sensor data) to a machine-learned model to perceive its surrounding environment based on its location within the environment. The machine-learned model can generate an intermediate environmental representation that encodes features within the surrounding environment. The system can receive a number of different intermediate environmental representations and corresponding locations from various other systems, aggregate the representations based on the corresponding locations, and perceive its surrounding environment based on the aggregated representations. The system can determine relative poses between the each of the systems and an absolute pose for each system based on the representations. Each representation can be aggregated based on the relative or absolute poses of each system and weighted according to an estimated accuracy of the location corresponding to the representation.","['H04W4/46', 'B60W60/00272', 'B60W60/00276', 'G05D1/0088', 'G05D1/024', 'G05D1/0274', 'G05D1/246', 'G05D1/81', 'G06F18/2415', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N7/01', 'G06V10/454', 'G06V10/62', 'G06V10/82', 'G06V20/56', 'H04W4/38']"
US20190304054A1,Compute optimization mechanism,An apparatus to facilitate compute optimization is disclosed. The apparatus includes a mixed precision core to perform a mixed precision multi-dimensional matrix multiply and accumulate operation on 16-bit and/or 32 bit floating-point elements.,"['G06T1/20', 'G06F3/14', 'G06F9/3001', 'G06F9/30014', 'G06F9/3017', 'G06F9/3887', 'G06F9/3888', 'G06F9/3895', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/084', 'G06T15/005', 'G09G5/363', 'G06F9/3851', 'G06T15/04', 'G09G2360/06', 'G09G2360/08', 'G09G2360/121']"
US11893490B2,Incremental precision networks using residual inference and fine-grain quantization,One embodiment provides for a computer-readable medium storing instructions that cause one or more processors to perform operations comprising determining a per-layer scale factor to apply to tensor data associated with layers of a neural network model and converting the tensor data to converted tensor data. The tensor data may be converted from a floating point datatype to a second datatype that is an 8-bit datatype. The instructions further cause the one or more processors to generate an output tensor based on the converted tensor data and the per-layer scale factor.,"['G06N3/08', 'G06F9/46', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06N5/04', 'G06T15/005', 'G06F9/505', 'G06T15/04', 'G06T15/80', 'G06T17/10', 'G06T17/20', 'G06V10/94']"
CN111598762B,A generative robust image steganography method,"The invention provides a generating type robust image steganography method, which comprises the following steps: constructing an image data set, and preprocessing the image data set; constructing and initializing a deep learning network architecture; training a deep learning network architecture by adopting a joint-fine tuning method to obtain a network architecture model; and generating a secret pseudo-graph by using the network architecture model, and carrying out secret communication to complete the image steganography process. The image steganography method provided by the invention integrates the embedding process of secret information into the generating process of the image by utilizing the generating countering network StyleGAN, and constructs a generating image steganography framework which can bear secret information with larger capacity and has certain robustness, so that the obtained generating image steganography method has the advantages of larger embedding capacity, good generated image quality, strong carrying image statistics undetectability, high practicability and the like, and solves the problems of poor carrying image quality, low embedding capacity, low information extraction accuracy and the like of the traditional generating image steganography.","['G06T1/005', 'G06N3/045', 'G06N3/088']"
CN116168352B,Power grid obstacle recognition processing method and system based on image processing,"A method and a system for identifying and processing a power grid obstacle based on image processing are provided, wherein a monitoring image collected by a camera arranged on a power line tower is obtained, the monitoring image is subjected to image blocking processing to obtain a sequence of image blocks, each image block in the sequence of image blocks is respectively subjected to image resolution enhancement based on an automatic codec to obtain a sequence of enhanced image blocks, each enhanced image block in the sequence of enhanced image blocks is respectively subjected to convolution neural network model serving as a filter to obtain a sequence of image local semantic feature vectors, the sequence of image local semantic feature vectors is subjected to ViT model based on a converter to obtain an image global context semantic understanding feature vector, the image global context semantic understanding feature vector is subjected to a classifier to obtain a classification result, the classification result is used for indicating whether birds are contained in a monitoring range, and finally the stability of power transmission is ensured.","['G06V20/52', 'G06N3/08', 'G06V10/467', 'G06V10/764', 'G06V10/82', 'Y04S10/50']"
US11221990B2,Ultra-high compression of images based on deep learning,"A system for machine learning model parameters for image compression, including partitioning image files into a first set of regions, determining a first set of machine learned model parameters based on the regions, the first set of machine learned model parameters representing a first level of patterns in the image files, constructing a representation of each of the regions based on the first set of machine learned model parameters, constructing representations of the image files by combining the representations of the regions in the first set of regions, partitioning the representations of the image files into a second set of regions, and determining a second set of machine learned model parameters based on the second set of regions, the second set of machine learned model parameters representing a second level of patterns in the image files.","['G06F16/1744', 'G06T9/002', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/0472']"
US11587272B2,Intelligent interactive and augmented reality cloud platform,"Disclosed herein are methods and systems for an intelligent, interactive, and augmented reality (AR) cloud platform. The platform can be implemented in many applications, such as providing real-time intelligent and interactive control between user input data and the resulting AR data, providing real-time and effective AR-based communication, or providing real-time control of physical devices in a remote network.","['G06T11/60', 'G06F3/011', 'G06F16/00', 'G06F16/951', 'G06F3/01', 'G06F3/015', 'G06F3/017', 'G06N20/00', 'G06T11/00']"
US11841947B1,Methods and apparatus for machine learning based malware detection,"Apparatus and methods describe herein, for example, a process that can include receiving a potentially malicious file, and dividing the potentially malicious file into a set of byte windows. The process can include calculating at least one attribute associated with each byte window from the set of byte windows for the potentially malicious file. In such an instance, the at least one attribute is not dependent on an order of bytes in the potentially malicious file. The process can further include identifying a probability that the potentially malicious file is malicious, based at least in part on the at least one attribute and a trained threat model.","['G06F21/563', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N5/025', 'G06N7/01']"
US20210259560A1,Methods and systems for determining a physiological or biological state or condition of a subject,"The present disclosure provides methods, devices, and systems for determining a state or condition of a subject. A method for determining a state or condition of a heart of a subject may include using a monitoring device comprising a plurality of sensors comprising an electrocardiogram (ECG) sensor, an audio sensor, and other sensors to measure data including ECG data and audio data from an organ of the subject and transmitting the data wirelessly to a computing device. A trained algorithm may be used to process the data, such as the ECG data, the audio data, and other data to determine the state or condition of the organ of the subject. More specifically, the trained algorithm can be customized for a specific indication or condition. An output indicative of the state or condition of the heart of the subject may be provided on the computing device or monitoring device.","['A61B5/332', 'A61B5/0006', 'A61B5/02028', 'A61B5/28', 'A61B5/318', 'A61B5/6898', 'G16H10/40', 'G16H20/10', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'A61B2562/0219', 'A61B5/0022', 'A61B5/01', 'A61B5/024', 'A61B5/053', 'A61B5/0816', 'A61B5/085', 'A61B5/352', 'A61B5/363', 'A61B5/366', 'A61B5/7264', 'A61B5/7275', 'A61B7/04']"
US11698529B2,Systems and methods for distributing a neural network across multiple computing devices,"Disclosed herein is a method for using a neural network across multiple devices. The method can include receiving, by a first device configured with a first one or more layers of a neural network, input data for processing via the neural network implemented across the first device and a second device. The method can include outputting, by the first one or more layers of the neural network implemented on the first device, a data set that is reduced in size relative to the input data while identifying one or more features of the input data for processing by a second one or more layers of the neural network. The method can include communicating, by the first device, the data set to the second device for processing via the second one or more layers of the neural network implemented on the second device.","['G06N3/063', 'G02B27/017', 'G02B27/0093', 'G02B27/0172', 'G06F3/011', 'G06F3/013', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'H04N13/106', 'G02B2027/0138', 'G02B2027/014', 'G02B7/06', 'G02B7/09']"
CN104685516B,Apparatus and method for implementing event-based updates in spiking neuron networks,"Event-based updates in an artificial neuron network can be performed. Internal events may be defined to update the input connections of the neurons. Internal events may be triggered by external signals and/or internally by neurons. The reinforcement signal may be used to trigger an internal event of the neuron in order to perform a synaptic update without having a post-synaptic response. External events may be defined to convey the response of the neuron to a desired target. The external and internal events may be combined into a composite event configured to effectuate a connection update and deliver a spike to the post-synaptic target. The scope of the internal event may include each neuron, but does not extend to other neurons of the network. Conversely, the range of external events may extend to other neurons of the network, e.g., via post-synaptic spike transmission.","['G06N3/10', 'G06N3/049']"
US11893023B2,Deterministic searching using compressed indexes,"A computing or storage system constructs a table in memory, and constructs a summary table that summarizes the table. The summary table is for determining whether there is likely an entry for a value in the table. The summary table has buckets pointed to by address fields of values. The first bucket in the summary table is split into a second bucket and a third bucket. Prior to the split, the first bucket is pointed to by a first address field of a first value. After the split, the second bucket and the third bucket are pointed to by the first address field plus one extra bit derived from a remainder of the first value.","['G06F16/2455', 'G06F16/2255']"
US11663747B2,Methods and apparatuses for performing artificial intelligence encoding and artificial intelligence decoding on image,"Provided is an artificial intelligence (AI) decoding apparatus includes: a memory storing one or more instructions; and a processor configured to execute the one or more instructions stored in the memory, the processor is configured to: obtain AI data related to AI down-scaling an original image to a first image; obtain image data corresponding to an encoding result on the first image; obtain a second image corresponding to the first image by performing a decoding on the image data; obtain deep neural network (DNN) setting information among a plurality of DNN setting information from the AI data; and obtain, by an up-scaling DNN, a third image by performing the AI up-scaling on the second image, the up-scaling DNN being configured with the obtained DNN setting information, wherein the plurality of DNN setting information comprises a parameter used in the up-scaling DNN, the parameter being obtained through joint training of the up-scaling DNN and a down-scaling DNN, and wherein the down-scaling DNN is used to obtain the first image from the original image.","['G06T9/002', 'G06T3/4046', 'G06V10/82', 'H04N19/102', 'H04N19/134', 'H04N19/146', 'H04N19/192', 'H04N19/59', 'H04N19/80', 'H04N19/85', 'G06T2207/20081']"
EP3825916A2,Method and apparatus for retrieving image and computer-readable storage medium,"A method for retrieving an image is provided. The method includes: extracting (S101) a global feature and a local feature of an image to be retrieved, and a global feature and a local feature of an image to be recalled by employing a preset neural network model; determining (S102, S302) a candidate image set by matching the global feature of the image to be retrieved with the global feature of the image to be recalled and matching the local feature of the image to be retrieved with the local feature of the image to be recalled; and determining (S103, S406) a retrieval result from the candidate image set by performing local feature verification on the image to be retrieved and a candidate image in the candidate image set. An apparatus for retrieving an image, an electronic device, and a medium are further provided.","['G06F16/583', 'G06F18/231', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06V10/44', 'G06V10/454', 'G06V10/751', 'G06V10/7625', 'G06V10/82', 'G06V30/248', 'G06N3/08', 'Y02D10/00']"
CN114631133B,Method for simulating target food using artificial intelligence,Systems and methods for simulating a target food product using artificial intelligence are disclosed. The system can learn from both open source and proprietary databases. The predictive model may be trained using the characteristics of the source components to match the characteristics of a given target food product. A formulation including a combination of the most relevant source components and their proportions may be determined using a trained predictive model. The set of existing recipes can be used as a data set to train a Recurrent Neural Network (RNN) and/or other suitable model. RNN can be used to determine a recipe for a simulated target food product. The recipe may include a cooking process for a set of ingredients in the recipe and may be cooked by a cook. The recipe may be further modified if necessary based on manual feedback about the sensory descriptors.,"['G06F16/9035', 'G09B19/0092', 'G01N33/02', 'G01N33/025', 'G01N33/12', 'G06N20/20', 'G06N3/02', 'G06N3/04', 'G06N3/044', 'G06N3/0442', 'G06N3/0455', 'G06N3/06', 'G06N3/08', 'G06N3/09', 'G06N5/01', 'G06Q50/12', 'G16H20/60', 'G16Z99/00', 'G06N20/10']"
CN110674305B,Commodity information classification method based on deep feature fusion model,"The invention provides a commodity information classification method based on a deep feature fusion model, which uses two text information embedding modes of word embedding and word embedding to acquire shallow feature information of more commodity text titles; the self-attention mechanism, the convolutional neural network and the channel attention are combined to enhance the shallow text features and obtain deep enhanced features; and finally, fusing the deep enhanced features extracted by the two embedding methods, and determining the commodity category by a multi-classification logistic regression method softmax. According to the invention, two embedding modes are used for mapping the commodity text titles, and more information is obtained on the basis of no loss of original information; the commodity information features are extracted by using a convolutional neural network, shallow features and deep features are respectively enhanced by two attention mechanisms, and the classification accuracy is improved; the problem that rules still need to be set manually in the traditional expert rule classification method is solved, and the accuracy of classification results is improved.","['G06F16/353', 'G06F16/355']"
CN109829920B,"Image processing method and device, electronic equipment and storage medium","The present disclosure relates to an image processing method and apparatus, an electronic device, and a storage medium, the method including: performing feature extraction on an image to be processed to obtain a feature map of the image to be processed; performing first positioning and segmentation processing on the feature map, and determining a first segmentation result of a first target; performing second positioning and segmentation processing on the feature map, and determining a second segmentation result of a second target; and determining the segmentation result of the image to be processed according to the first segmentation result and the second segmentation result. The embodiment of the disclosure can realize the differentiation processing of the targets with different sizes in different areas in the image to be processed, and improve the precision of image processing.",[]
CN108804205B,Intelligent thread dispatch and vectorization of atomic operations,"Intelligent thread dispatch and vectorization of atomic operations is provided. A mechanism is described for facilitating intelligent dispatch and vectorization at an autonomous machine. The method of embodiments as described herein includes detecting a plurality of threads corresponding to a plurality of workloads associated with tasks involving a graphics processor. The method may further include determining a first set of threads of the plurality of threads that are similar to each other or have adjacent surfaces, and physically clustering the first set of threads together by using a first set of adjacent computing blocks.","['G06F9/3009', 'G06F9/466', 'G06F12/0862', 'G06F15/167', 'G06F15/17', 'G06F9/30036', 'G06F9/30038', 'G06F9/30145', 'G06F9/3836', 'G06F9/3867', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/5033', 'G06F9/5066', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/0895', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06T1/60', 'G06F2212/602', 'G06F2212/6028', 'Y02D10/00']"
US12231637B2,"Image encoding/decoding method and device for performing feature quantization/ de-quantization, and recording medium for storing bitstream","An image encoding/decoding method and apparatus are provided. An image decoding method may comprise obtaining, from a bitstream, a feature set extracted from an input image using an artificial neural network-based feature extraction method, first information on importance of each of a plurality of channels included in the feature set and second information on a quantization method of the feature set, decoding the feature set, the first information and the second information, and dequantizing the decoded feature set based on the decoded first information and the decoded second information. The second information may comprise the number of quantization bits of each of the plurality of channels, and the number of quantization bits may be determined based on the importance of each of the plurality of channels.","['G06N3/08', 'H04N19/119', 'H04N19/124', 'H04N19/13', 'H04N19/136', 'H04N19/172', 'H04N19/176', 'H04N19/186', 'H04N19/1883', 'H04N19/423', 'H04N19/503', 'H04N19/593']"
US11599280B2,Data reduction improvement using aggregated machine learning,"A method system, and computer program product for improving data reduction using aggregate machine learning systems comprising receiving, by an aggregating machine learning system from one or more machine learning systems associated with a set of one or more storage arrays, a first set of output parameters indicative of performance metrics for the set of the one or more storage arrays, aggregating, by the aggregating machine learning system, the first set of output parameters, resulting in a second set of output parameters, and sending, from the aggregating machine learning system, at least one member of the second set of output parameters as an input to at least one of the one or more machine learning systems associated with the set of the one or more storage arrays.","['G06F3/0631', 'G06F3/0641', 'G06F3/0608', 'G06F3/0685', 'G06F3/0688', 'G06N3/045', 'G06N3/0454', 'G06N3/08']"
TW202240199A,High end imaging radar,"According to various embodiments, a radar device is described comprising a processor configured to generate a scene comprising an object based on a plurality of receive wireless signals, generate a ground truth object parameter of the object and generate a dataset representative of the scene and a radar detector configured to determine an object parameter of the object using a machine learning algorithm and the dataset, determine an error value of the machine learning algorithm using a cost function, the object parameter, and the ground truth object parameter and adjust the machine learning algorithm values to reduce the error value.","['G01S7/417', 'G01S7/354', 'G01S13/34', 'G01S13/4454', 'G01S13/584', 'G01S13/726', 'G01S13/89', 'G01S13/931', 'G01S7/356', 'G01S7/40', 'H01Q21/06', 'G01S7/415', 'H01Q15/02']"
US10839475B2,Apparatus and method for compressing leaf nodes of a bounding volume hierarchy (BVH),"Apparatus and method for compressing an acceleration data structure such as a bounding volume hierarchy (BVH). For example, one embodiment of a graphics processing apparatus comprises: one or more cores to execute graphics instructions including instructions to perform ray tracing operations; and compression circuitry to compress lowest level nodes of a hierarchical acceleration data structure comprising a plurality of hierarchically arranged nodes, each of the lowest level nodes comprising pointers to leaf data; the compression circuitry to quantize the lowest level nodes to generate quantized lowest level nodes and to store each quantized lowest level node and associated leaf data without the pointers to the leaf data.","['G06F9/3877', 'G06T1/20', 'G06T15/005', 'G06T15/06', 'G06T17/10', 'G06T9/40', 'G06T2210/12', 'G06T2210/52']"
CN112990227B,Face geology detection method,"The application discloses a tunnel face geological condition detection method in a tunnel construction process. The method comprises the steps of training an image example segmentation neural network by utilizing a sample data set based on a deep learning algorithm to obtain an image example segmentation model, wherein the sample data set comprises a plurality of rock slag sample images with different geological levels, each rock slag sample image is provided with a geological class label, and the outlines of block rock slag and sheet rock slag are marked in the image. And calling an image instance segmentation model to analyze the rock slag image to be recognized to obtain profile data of each rock slag in the solid slag soil segmented in the rock slag image to be recognized and probability values of geological levels to which the solid slag soil belongs. The content values of the massive rock slag, the flaky rock slag and the rock powder in the solid slag soil are calculated according to the profile data, the geological grade of the tunnel face which is tunneling is determined by combining the initial classification result, the defect of manual detection of the geological condition of tunnel construction of the TBM is overcome, the geological analysis accuracy is not reduced, and the intelligent degree of tunnel construction is improved.","['G06F18/214', 'G06N3/045', 'G06T7/0002', 'G06T7/11', 'G06V10/44']"
US9456131B2,Video processing systems and methods,A smart camera system is disclosed. The camera can work with cloud data storage systems and compute cloud. A call center can access the cloud to provide security monitoring services.,"['H04N7/12', 'H04N5/2628', 'H04N5/23222', 'G06F3/005', 'G06N3/063', 'G06N3/084', 'H04N19/436', 'H04N23/64', 'H04N23/698', 'H04N5/23229', 'H04N5/23238', 'H04N5/265', 'H04N7/15', 'H04N7/181']"
US11410414B2,Systems and methods for detection and localization of image and document forgery,Systems and methods for detection and localization of image and document forgery. The method can include the step of receiving a dataset having a plurality of authentic images and a plurality of manipulated images. The method can also include the step of benchmarking a plurality of image forgery algorithms using the dataset. The method can further include the step of generating a plurality of receiver operating characteristic (ROC) curves for each of the plurality of image forgery algorithms. The method also includes the step of calculating a plurality of area under curve metrics for each of the plurality of ROC curves. The method further includes the step of training a neural network for image forgery based on the plurality of area under curve metrics.,"['G06V10/758', 'G06V10/82', 'G06F16/5838', 'G06F18/24143', 'G06F18/2415', 'G06K9/6274', 'G06K9/6277', 'G06N3/04', 'G06N3/08', 'G06V10/774', 'G06V20/95', 'G06V30/19173', 'G06V30/194', 'G06Q50/26']"
US10740897B2,Method and device for three-dimensional feature-embedded image object component-level semantic segmentation,"Embodiments of the present invention provide a method and a device for three-dimensional feature-embedded image object component-level semantic segmentation, the method includes: acquiring three-dimensional feature information of a target two-dimensional image; performing a component-level semantic segmentation on the target two-dimensional image according to the three-dimensional feature information of the target two-dimensional image and two-dimensional feature information of the target two-dimensional image. In the technical solution of the present application, not only the two-dimensional feature information of the image but also the three-dimensional feature information of the image are taken into consideration when performing the component-level semantic segmentation on the image, thereby improving the accuracy of the image component-level semantic segmentation.","['G06V10/82', 'G06F18/24143', 'G06K9/00', 'G06K9/00208', 'G06K9/00664', 'G06K9/6274', 'G06N3/045', 'G06N3/08', 'G06T7/10', 'G06T7/11', 'G06V10/764', 'G06V20/10', 'G06V20/647', 'G06V20/70', 'G06T2200/04', 'G06T2200/08', 'G06T2207/20081', 'G06T2207/20084']"
US10714078B2,Linear transformation for speech recognition modeling,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for speech recognition using complex linear projection are disclosed. In one aspect, a method includes the actions of receiving audio data corresponding to an utterance. The method further includes generating frequency domain data using the audio data. The method further includes processing the frequency domain data using complex linear projection. The method further includes providing the processed frequency domain data to a neural network trained as an acoustic model. The method further includes generating a transcription for the utterance that is determined based at least on output that the neural network provides in response to receiving the processed frequency domain data.","['G10L15/16', 'G10H1/00', 'G10L15/02', 'G10L19/0212', 'G10H2210/036', 'G10H2210/046', 'G10H2250/235', 'G10H2250/311', 'G10L17/18']"
TWI853095B,Apparatus and method for using alpha values to improve ray tracing efficiency,"Apparatus and method for encoding sub-primitives to improve ray tracing efficiency. For example, one embodiment of an apparatus comprises: a ray generator to generate a plurality of rays in a ray tracing graphics pipeline; a sub-primitive generator to subdivide each primitive of a plurality of primitives into a plurality of sub-primitives; a sub-primitive encoder to identify a first subset of the plurality of sub-primitives as being fully transparent and to identify a second subset of the plurality of sub-primitives as being fully opaque; and wherein the first subset of the plurality of primitives identified as being fully transparent are culled prior to further processing of each respective primitive.","['G06T15/06', 'G06F15/7807', 'G06T1/20', 'G06T15/005', 'G06T15/08', 'G06T17/10', 'G06T19/006', 'G06T3/40', 'G06T9/00', 'G06T2200/28']"
US7386372B2,Apparatus and method for determining presence of objects in a vehicle,"Vehicle including a first substructure and a second substructure arranged such that an interior space is defined by or between the first and second substructures, and an arrangement for determining whether an object is present in the interior space. The arrangement includes at least one ultrasonic transducer arranged on the second substructure and to transmit ultrasonic waves toward the first substructure and receive any waves reflected by objects in the interior space and a processor coupled to the ultrasonic transducer(s) and arranged to determine whether an object is present in the interior space based on reception of waves by the ultrasonic transducer(s). If the vehicle is an automobile and the interior space is the passenger compartment therein, the first substructure can be the passenger seat and the second substructure can be the A-pillar, in which case, the processor determines the presence or absence of a passenger in the passenger seat.","['B60R21/01536', 'B60R21/0152']"
US20240345566A1,Automated certificate systems and methods,"The systems and methods provide an action recognition and analytics tool for use in manufacturing, health care services, shipping, retailing and other similar contexts. Machine learning action recognition can be utilized to determine cycles, processes, actions, sequences, objects and or the like in one or more sensor streams. The sensor streams can include, but are not limited to, one or more video sensor frames, thermal sensor frames, infrared sensor frames, and or three-dimensional depth frames. The analytics tool can provide for automatic creation of certificates for each instance of a subject product or service. The certificate can string together snippets of the sensor streams along with indicators of cycles, processes, action, sequences, objects, parameters and the like captured in the sensor streams.","['G05B19/4183', 'G05B19/41835', 'G06F11/0721', 'G06F11/079', 'G06F11/3452', 'G06F16/2228', 'G06F16/2365', 'G06F16/24568', 'G06F16/9024', 'G06F16/9035', 'G06F16/904', 'G06F30/20', 'G06F30/23', 'G06F30/27', 'G06F9/4498', 'G06F9/4881', 'G06N20/00', 'G06N3/008', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N7/01', 'G06Q10/06', 'G06Q10/063112', 'G06Q10/06316', 'G06Q10/06393', 'G06Q10/06395', 'G06Q10/06398', 'G06T19/006', 'G06V10/25', 'G06V10/454', 'G06V10/82', 'G06V20/41', 'G06V20/52', 'G06V40/20', 'G09B19/00', 'B25J9/1664', 'B25J9/1697', 'G01M99/005', 'G05B19/41865', 'G05B19/423', 'G05B2219/32056', 'G05B2219/36442', 'G05B23/0224', 'G06F16/43', 'G06F18/217', 'G06F2111/10', 'G06F2111/20', 'G06N3/006', 'G06Q10/083', 'G06Q50/26', 'G16H10/60']"
US12387096B2,Image-to-image mapping by iterative de-noising,"A method includes receiving training data comprising a plurality of pairs of images. Each pair comprises a noisy image and a denoised version of the noisy image. The method also includes training a multi-task diffusion model to perform a plurality of image-to-image translation tasks, wherein the training comprises iteratively generating a forward diffusion process by predicting, at each iteration in a sequence of iterations and based on a current noisy estimate of the denoised version of the noisy image, noise data for a next noisy estimate of the denoised version of the noisy image, updating, at each iteration, the current noisy estimate to the next noisy estimate by combining the current noisy estimate with the predicted noise data, and determining a reverse diffusion process by inverting the forward diffusion process to predict the denoised version of the noisy image. The method additionally includes providing the trained diffusion model.","['G06V10/30', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06V10/80', 'G06V10/82']"
CN111753092B,"Data processing method, model training method, device and electronic equipment","The application relates to a data processing method, a model training device and electronic equipment, and belongs to the technical field of data processing. The data processing method comprises the following steps: acquiring a plurality of pieces of comment data related to a specified object in a webpage; and carrying out emotion classification on the comment data by using a neural network model trained in advance to obtain a classification result, wherein the neural network model is a student network obtained based on knowledge distillation, and the classification result comprises at least one result of positive evaluation, negative evaluation and neutral evaluation. In the embodiment of the application, the comment data is subjected to emotion classification by using the neural network model obtained based on knowledge distillation, and the accuracy of classification results is improved by adopting the knowledge distillation technology, and meanwhile, the time required by training can be saved.","['G06F16/35', 'G06F18/214', 'G06N3/045', 'Y02D10/00']"
US11157768B1,"Training a machine learning model for optimizing data levels for processing, transmission, or storage","Techniques are discussed for determining a data level for portions of data for processing. In some cases, a data level can correspond to a resolution level, a compression level, a bit rate, and the like. In the context of image data, the techniques can determine a region of first image data to be processed a high resolution and a region of second image data to be processed at a low resolution. The regions can be determined by a machine learned algorithm that is trained to output identifications of such regions. Training data may be determined by identifying differences in outputs based on the first and second image data. The image data associated with the determined regions and the determined resolutions can be processed to perform object detection, classification, segmentation, bounding box generation, and the like, thereby conserving processing, bandwidth, and/or memory resources in real time systems.","['G06K9/6228', 'G05D1/0088', 'G05D1/0231', 'G05D1/0246', 'G05D1/0276', 'G06F18/211', 'G06K9/6298', 'G06N20/00', 'G06N3/088', 'G06T1/20', 'G06V10/764', 'G06V10/82', 'G06V20/56', 'G05D2201/0213']"
US20240118892A1,"Apparatuses, methods, and systems for neural networks","Methods and apparatuses relating to processing neural networks are described. In one embodiment, an apparatus to process a neural network includes a plurality of fully connected layer chips coupled by an interconnect; a plurality of convolutional layer chips each coupled by an interconnect to a respective fully connected layer chip of the plurality of fully connected layer chips and each of the plurality of fully connected layer chips and the plurality of convolutional layer chips including an interconnect to couple each of a forward propagation compute intensive tile, a back propagation compute intensive tile, and a weight gradient compute intensive tile of a column of compute intensive tiles between a first memory intensive tile and a second memory intensive tile.","['G06F9/30145', 'G06F9/3004', 'G06F9/30043', 'G06F9/30087', 'G06F9/3834', 'G06F9/52', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
US20210203997A1,Hybrid video and feature coding and decoding,"The present disclosure relates to hybrid video and feature encoding and decoding, with the encoding and decoding of the image feature being performed independently or differentially. The video and feature are encoded and decoded in separate layers, e.g., base layer and enhancement layer. The feature is extracted for a frame of the video, providing a frame-based feature-video association. A feature is extracted from an uncompressed video encoded in an enhancement layer into a feature bitstream. The video is encoded into a video bitstream, with the feature bitstream being embedded into the video bitstream by multiplexing both streams into an output bitstream. The image feature, which may be a differential image feature, is included in a sequence enhancement information SEI message of a frame header information of the video. The output bitstream is provided as input bitstream to a decoder, which de-multiplexes the input bitstream into a video bitstream and feature bitstream, using the SEI message of the frame header. Both bitstreams are decoded in their respective layers, and the image feature is located in the video using the frame-based feature-video association.","['H04N19/50', 'G06K9/4671', 'G06T9/20', 'G06V10/454', 'G06V10/462', 'G06V10/764', 'G06V10/82', 'H04N19/184', 'H04N19/70', 'G06T7/10', 'G06V20/52', 'G06V20/56']"
CN105868467B,A kind of dynamic airborne model building method of stable state aero-engine,"The invention discloses a kind of dynamic airborne model building methods of stable state aero-engine, belong to Aeroengine control technology field.First with similarity criterion and and Taylor expansion principle carry out sampled data compression, sampled data output and time is greatly reduced；Then the airborne model of dynamic based on sparse autocoder and the airborne model of stable state based on BP neural network is respectively trained using the dynamic data and steady state data that compress in post-sampling data, the corresponding quasi-steady state decision logic of finally setting, sparse autocoder dynamic model is used in dynamic process, BP network steady-state models are used in steady-state process.Compared with prior art, the airborne model of aero-engine constructed by the present invention all has higher precision under dynamic and limit, and real-time is more preferable, and the requirement to data storage capacity is lower.","['G06F30/367', 'G06N3/045', 'G06N3/08']"
US20190197679A1,"Automated optical inspection method using deep learning and apparatus, computer program for performing the method, computer-readable storage medium storing the computer program,and deep learning system thereof","The present invention is an automated optical inspection method using deep learning, comprising the steps of: providing a plurality of paired image combinations, wherein each said paired image combination includes at least one defect-free image and at least one defect-containing image corresponding to the defect-free image; providing a convolutional neural network to start a training mode of the convolutional neural network; inputting the plurality of paired image combinations into the convolutional neural network, and adjusting a weight of at least one fully connected layer of the convolutional neural network through backpropagation to complete the training mode of the convolutional neural network; and performing an optical inspection process using the trained convolutional neural network.","['G06T7/0002', 'G06N3/084', 'G01N21/8851', 'G06N3/045', 'G06N5/046', 'G06T7/0004', 'G06T7/97', 'G01N2021/8887', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30141', 'G06T2207/30148']"
US12289603B2,"System, method, and apparatus for providing optimized network resources","Systems, methods, and apparatuses for providing optimization of network resources. The system is operable to monitor the electromagnetic environment, analyze the electromagnetic environment, and extract environmental awareness of the electromagnetic environment. The system extracts the environmental awareness of the electromagnetic environment by including customer goals. The system is operable to use the environmental awareness with the customer goals and/or user defined policies and rules to extract actionable information to help the customer optimize the network resources.","['H04W16/10', 'H04W24/02', 'H04W24/08', 'H04W28/0925', 'H04W28/0967', 'H04W72/0453', 'H04W16/14']"
US11200486B2,Convolutional neural networks on hardware accelerators,"A hardware acceleration component is provided for implementing a convolutional neural network. The hardware acceleration component includes an array of N rows and M columns of functional units, an array of N input data buffers configured to store input data, and an array of M weights data buffers configured to store weights data. Each of the N input data buffers is coupled to a corresponding one of the N rows of functional units. Each of the M weights data buffers is coupled to a corresponding one of the M columns of functional units. Each functional unit in a row is configured to receive a same set of input data. Each functional unit in a column is configured to receive a same set of weights data from the weights data buffer coupled to the row. Each of the functional units is configured to perform a convolution of the received input data and the received weights data, and the M columns of functional units are configured to provide M planes of output data.","['G06N3/063', 'G06F15/7803', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06N3/0464', 'G06F15/76']"
CN109802430B,Wind power grid control method based on LSTM-Attention network,"The invention relates to a wind power grid control method based on an LSTM-Attention network, which comprises the following steps: s1: preprocessing data aiming at different wind speed data; s2: establishing a total network model; s3: training a total network model by using historical data; s4: obtaining a wind power result by utilizing the trained network model; s5: and detecting a wind power result and carrying out different control operations on the wind power grid according to the wind power result corresponding measures. The prediction model is divided into two parts: attention is drawn to the LSTM network and SE CNN network of the mechanism. Firstly, normalizing original NWP data to be used as input of a prediction model; secondly, extracting the overall characteristics and the local characteristics of the time series NWP data by using an LSTM network and an SE _ CNN network of an attention mechanism respectively, then performing characteristic fusion, and predicting the wind speed by using a classifier; and finally, obtaining the wind power by utilizing the relation between the historical wind speed and the wind power. Compared with the prior art, the method has the advantages of high accuracy, high speed and the like.",['Y02A30/00']
US8768573B2,Technique for ensuring safe travel of a vehicle or safety of an occupant therein,"Vehicle with an occupant safety system includes an occupant safety system designed to reduce injury to an occupant during an accident involving the vehicle and a processor coupled to the safety system and that receives at least one inertial property of the vehicle and information about a portion of a road ahead of the vehicle in its travel direction. If the processor determines, based on the at least one inertial property and the information, that the vehicle is unlikely to safely travel that portion of the road, the processor initiates action to ensure safe travel of the vehicle or safety of the occupant. The inertial property of the vehicle may be provided by an inertial measurement unit (IMU) that measures acceleration in three orthogonal directions and angular velocity about three orthogonal axes, all at a substantially common location. The occupant safety system may include one or more inflatable airbags.","['G01G19/024', 'B60R21/0132', 'B60W40/06', 'G07C5/008', 'B60R2021/01325', 'B60R2021/01327']"
US10393842B1,Highly-scalable image reconstruction using deep convolutional neural networks with bandpass filtering,"A method for magnetic resonance imaging (MRI) scans a field of view and acquires sub-sampled multi-channel k-space data U. An imaging model A is estimated. Sub-sampled multi-channel k-space data U is divided into sub-sampled k-space patches, each of which is processed using a deep convolutional neural network (ConvNet) to produce corresponding fully-sampled k-space patches, which are assembled to form fully-sampled k-space data V, which is transformed to image space using the imaging model adjoint Aadj to produce an image domain MRI image. The processing of each k-space patch ui preferably includes applying the k-space patch ui as input to the ConvNet to infer an image space bandpass-filtered image yi, where the ConvNet comprises repeated de-noising blocks and data-consistency blocks; and estimating the fully-sampled k-space patch vi from the image space bandpass-filtered image yi using the imaging model A and a mask matrix.","['G01R33/5608', 'G01R33/5611', 'G01R33/56509', 'G01R33/56545', 'G01R33/4824', 'G06T2207/10088']"
US10922799B2,"Image processing method that performs gamma correction to update neural network parameter, image processing apparatus, and storage medium","An image processing method includes the steps of acquiring a training image and a correct image, inputting the training image into a multilayer neural network to generate an output image, performing a gamma correction for each of the correct image and the output image and calculating an error between the correct image after the gamma correction and the output image after the gamma correction, and updating a network parameter of the neural network using the error.","['G06T5/92', 'H04N1/6058', 'G06T5/009', 'G06N3/045', 'G06N3/084', 'G06T5/50', 'G06T5/73', 'G06T7/90', 'G06T9/00', 'H04N1/6027', 'G06N3/088', 'G06T2207/20081', 'G06T2207/20084']"
US8054203B2,Apparatus and method for determining presence of objects in a vehicle,"Vehicle including a first substructure and a second substructure arranged such that an interior space is defined by or between the first and second substructures, and an arrangement for determining whether an object is present in the interior space. The arrangement includes ultrasonic transducers arranged on the second substructure and to transmit ultrasonic waves toward the first substructure and receive any waves reflected by objects in the interior space and a processor coupled to the ultrasonic transducers and arranged to determine whether an object is present in the interior space based on reception of waves by the ultrasonic transducers. If the vehicle is an automobile and the interior space is the passenger compartment therein, the first substructure can be the passenger seat and the second substructure can be the A-pillar, in which case, the processor determines the presence or absence of a passenger in the passenger seat.","['B60C11/24', 'B60C19/00', 'B60N2/0022', 'B60N2/0025', 'B60N2/0028', 'B60N2/0029', 'B60N2/0033', 'B60N2/0035', 'B60N2/015', 'B60N2/02246', 'B60N2/0248', 'B60N2/0252', 'B60N2/0268', 'B60N2/0272', 'B60N2/0273', 'B60N2/0276', 'B60N2/0278', 'B60N2/067', 'B60N2/267', 'B60N2/2806', 'B60N2/2863', 'B60N2/66', 'B60N2/829', 'B60N2/853', 'B60N2/888', 'B60R16/037', 'B60R21/013', 'B60R21/0136', 'B60R21/01516', 'B60R21/0152', 'B60R21/01532', 'B60R21/01534', 'B60R21/01536', 'B60R21/01538', 'B60R21/01542', 'B60R21/01546', 'B60R21/01552', 'B60R21/01554', 'B60R22/20', 'B60R25/25', 'B60R25/252', 'B60R25/255', 'B60R25/257', 'E05F15/431', 'G01S15/04', 'G01S15/42', 'G01S15/87', 'G01S15/88', 'G01S17/04', 'G01S17/88', 'G01S7/417', 'G01S7/4802', 'G01S7/539', 'G06F3/0219', 'G06F3/0233', 'G06F3/0237', 'G06F3/0238', 'G06V20/593', 'G06V40/10', 'G07C5/008', 'G07C5/0808', 'G08B13/1427', 'G08B13/2462', 'G08B13/248', 'G08B21/0286', 'G08B25/08', 'G08B29/181', 'H01Q1/3233', 'H01Q1/3291', 'H01Q7/00', 'B60N2210/12', 'B60N2210/16', 'B60N2210/18', 'B60N2210/20', 'B60N2210/24', 'B60N2210/26', 'B60N2210/42', 'B60N2220/10', 'B60N2220/30', 'B60N2230/30', 'B60R2001/1223', 'B60R2001/1253', 'B60R2021/0027', 'B60R2021/01315', 'B60R2021/23153', 'B60R2021/26094', 'B60R2021/2765', 'B60R2022/208', 'B60R2022/288', 'B60R2022/4685', 'B60R2022/4825', 'B60R21/0134', 'B60R21/0153', 'B60R21/01544', 'B60R21/01548', 'B60R21/203', 'B60R21/21656', 'B60R21/276', 'B60R22/201', 'E05F2015/433', 'E05Y2900/542', 'E05Y2900/55', 'G01S13/04', 'G01S15/06', 'G01S17/89', 'G06V40/16', 'G10K2210/1282', 'G10K2210/3219']"
CN111317468B,"Electroencephalogram signal classification method, electroencephalogram signal classification device, computer equipment and storage medium","The application relates to an electroencephalogram signal classification method, an electroencephalogram signal classification device, computer equipment and a storage medium. The method comprises the following steps: acquiring an electroencephalogram signal to be classified; extracting signal characteristics of a plurality of target frequency bands from the electroencephalogram signals to be classified to obtain frequency band characteristics corresponding to the target frequency bands; the target frequency band is a frequency band corresponding to a target user identifier corresponding to the electroencephalogram signal to be classified; acquiring target weights corresponding to the frequency band characteristics, and acquiring target classification characteristics of target frequency bands corresponding to the frequency band characteristics respectively according to the target weights corresponding to the frequency band characteristics; and carrying out classification processing according to each target classification characteristic to obtain a classification result of the electroencephalogram signals to be classified corresponding to the target user identification. By adopting the method, the accuracy of electroencephalogram signal classification can be improved.","['A61B5/369', 'A61B5/7264']"
US9626845B2,Providing information to a user through somatosensory feedback,"A hearing device may provide hearing-to-touch sensory substitution as a therapeutic approach to deafness. Through use of signal processing on received signals, the hearing device may provide better accuracy with the hearing-to-touch sensory substitution by extending beyond the simple filtering of an incoming audio stream as found in previous tactile hearing aids. The signal processing may include low bitrate audio compression algorithms, such as linear predictive coding, mathematical transforms, such as Fourier transforms, and/or wavelet algorithms. The processed signals may activate tactile interface devices that provide touch sensation to a user. For example, the tactile interface devices may be vibrating devices attached to a vest, which is worn by the user. The vest may also provide other types of information to the user.","['G09B21/009', 'A61F11/04', 'A61F11/045', 'G06F3/016', 'G08B6/00', 'G09B21/003']"
US20200074997A1,Method and system for detecting voice activity in noisy conditions,"A voice activity detection method includes: training one or more computerized neural networks having a denoising autoencoder and a classifier, wherein the training is performed utilizing one or more models including Mel-frequency cepstral coefficients (MFCC) features, Δ features, ΔΔ features, and Pitch features, each model being recorded at one or more differing associated predetermined signal to noise ratios; recording a raw audio waveform and transmitting the raw audio waveform to the computerized neural network; denoising the raw audio wave utilizing the denoising autoencoder; and determining whether the raw audio waveform contains human speech; extracting any human speech from the raw audio waveform.","['G10L15/20', 'G10L25/78', 'G06N3/045', 'G06N3/084', 'G10L15/063', 'G10L15/16', 'G10L15/22', 'G10L21/0216', 'G10L25/30', 'G06N3/044', 'G10L15/26', 'G10L2015/0633', 'G10L21/0264']"
US10956854B2,Systems and methods for tracking goods carriers,"Provided are methods, devices, and computer-program products for tracking goods carriers from a particular source. According to some embodiments of the invention, a computer-implemented method includes training an artificial neural network to count the number of goods carriers from a particular source within an image. Further, the method includes receiving a first image file generated by a first imaging device; using the trained artificial neural network to determine a first number of goods carriers from the particular source in the first image; receiving a second image file generated by a second imaging device; using the trained artificial neural network to determine a second number of goods carriers from the particular source in the second image; and determining whether the first number of goods carriers from the particular source in the first image is equal to the second number of goods carriers from the particular source in the second image.","['G06Q10/0833', 'G06K9/00771', 'G06T7/0008', 'G06T7/292', 'G06V10/82', 'G06V20/52', 'G06V30/424', 'G06F18/24143', 'G06K9/6274', 'G06N3/084', 'G06T2207/30108']"
US11736764B2,Artificial intelligence inference on protected media content in a vision processing unit,Techniques related to securely providing artificial intelligence inference on protected video content in a vision processing unit are discussed. Such techniques include decrypting encrypted video via a neural network processor of the vision processing unit by providing the neural network processor direct memory access to a security engine of the vision processing unit and applying a machine learning model to the decrypted video content using the neural network processor such that a host and other components of the vision processing unit do not have access to the decrypted video content.,"['H04N21/4408', 'H04N21/2747', 'G06N20/00', 'G06N3/045', 'G06N3/063', 'H04N21/2187', 'H04N21/2347', 'H04N21/251', 'H04N21/2541', 'H04N21/26613', 'H04N21/41407', 'H04N21/4405', 'H04N21/44055', 'H04N21/4627', 'G06N3/044', 'G06N3/048']"
US11944385B2,Systems and methods for medical image analysis,"A surgical planning and assessment system is disclosed. The system may include a computing system having a processor, a data store, a patient specific planning and analysis module, and a display. The system may be configured to access a database storing a plurality of possible surgical plans. The computing system may store a target surgical plan including a plurality of patient specific inputs including at least one preoperative medical image of a spine of a target patient and analyze the target surgical plan to determine a predicted alignment of the spine of the target patient. The computing system may develop a plurality of predictive models including a predicted alignment of the spine of the target patient based on the target surgical plan and suggest at least one alternative surgical plan with respect to the target surgical plan.","['A61B34/10', 'A61B17/7032', 'A61B17/7077', 'A61B34/20', 'A61B34/25', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G16H10/20', 'G16H20/40', 'G16H30/40', 'G16H50/20', 'G16H50/50', 'G16H70/20', 'A61B17/7082', 'A61B2034/102', 'A61B2034/104', 'A61B2034/105', 'A61B2034/107', 'A61B2034/108', 'A61B2034/2048', 'A61B2034/254', 'A61B2034/256', 'A61B2090/376', 'A61B2090/3762', 'G06N20/00']"
CN111666836B,High-resolution remote sensing image target detection method of M-F-Y type light convolutional neural network,"A high-resolution remote sensing image target detection method of an M-F-Y type lightweight convolutional neural network belongs to the field of remote sensing. Firstly, constructing a characteristic pyramid network structure FPN on the basis of a lightweight Convolutional Neural Network (CNN) model MobileNet V3-Small, extracting and fusing multi-scale depth characteristics for a high-resolution remote sensing image, and constructing an M-F-Y lightweight convolutional neural network by jointly utilizing a YOLOv3tiny target detection frame; then, by constructing a complementary attention network structure, the complex background is restrained, and meanwhile, the attention to the spatial position information of the target is promoted; and finally, training a model by using a filter grafting strategy based on transfer learning to realize high-resolution remote sensing image target detection. The invention can improve the accuracy of detecting the target of the high-resolution remote sensing image, reduce the constraint on the high-speed computing power of the platform through less parameter quantity and lower delay, and provide technical accumulation for the practical use of the target detection of the high-resolution remote sensing image.","['G06V20/13', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V2201/07', 'Y02D10/00']"
US11544887B2,Method for generating facial animation from single image,"A method for generating a facial animation from a single image is provided. The method is mainly divided into four steps: generation of facial feature points in an image, global two-dimensional deformation of the image, optimization of details of a facial area, and generation of texture of an oral cavity area. The present disclosure can generate a facial animation in real time according to a change of the facial feature points, and the animation quality reaches a level of current state-of-art facial image animation technology. The present disclosure can be used in a series of applications, such as facial image editing, portrait animation generation based on a single image, and facial expression editing in videos.","['G06T13/80', 'G06F18/2193', 'G06K9/6265', 'G06T13/40', 'G06T15/04', 'G06T7/75', 'G06V10/764', 'G06V10/82', 'G06V20/597', 'G06V40/171', 'G06V40/176', 'G06T2207/20084', 'G06T2207/30268']"
US20240412720A1,Real-time contextually aware artificial intelligence (ai) assistant system and a method for providing a contextualized response to a user using ai,"An artificial intelligence (AI) assistant system and a method for providing a contextualized response to a user using AI are disclosed. The system comprises an audio input device for receiving voice input, an audio output device for providing output, a processor, a wireless communication device, a contextual memory unit for storing conversational context data on a sliding window basis, and a non-volatile system memory unit. The processor executes instructions to receive voice input, determine user identification, update conversational context data with user identification and a tokenized representation of the voice input, process the voice input using a transformer-based language model to generate a response, update the conversational context data with a tokenized representation of the generated response, and output the response via the audio output device. The method comprises receiving voice input, determining user identification, updating conversational context data, processing voice input, and generating and outputting a conversational response.","['G10L13/02', 'G06F40/35', 'G06F16/33295', 'G06F16/90332', 'G06F3/167', 'G10L17/22', 'G10L15/22']"
US11216459B2,Multi-layer semantic search,"A method for semantic search includes receiving a query vector including a semantic feature value for each of a plurality of semantic feature dimensions. A cluster is selected from a plurality of different candidate clusters held in a relatively fast memory, each candidate cluster including a plurality of compressed answer vectors. A subset of the plurality of compressed answer vectors are promoted as candidate answers. For each of the candidate answers, a corresponding uncompressed answer vector is retrieved from a relatively slower memory. A selected answer is promoted from among the candidate answers.","['G06F16/24542', 'G06F16/3347', 'G06F16/24578', 'G06F3/0611', 'G06F3/0644', 'G06F3/068']"
CN112418292B,"Image quality evaluation method, device, computer equipment and storage medium","The application discloses a method, a device, computer equipment and a storage medium for evaluating image quality, which belong to the technical field of artificial intelligence; receiving an image to be evaluated, and extracting image features of the image to be evaluated by using an image feature extractor; performing feature vector conversion on image features of the image to be evaluated, and converting the image features into feature vectors; and constructing a network regression function, calculating a regression value of the feature vector by using the network regression function, and determining the quality of the image to be evaluated according to the regression value of the feature vector. In addition, the application also relates to a blockchain technology, and an image to be evaluated can be stored in the blockchain. The application constructs the image quality evaluation system by simplifying the deep learning network and adopting a machine regression mode, and the image quality evaluation system is quickly suitable for various scenes.","['G06N3/045', 'G06F16/583', 'G06F18/214', 'G06F18/23', 'G06N3/084']"
US11423329B2,Sensing systems,"A system learns to automatically identify, and detect, contextual conditions that may serve as action triggers to help please a user (or avoid annoying a user). Among other features, a simple sensor arrangement is detailed which, in addition to producing a customary stream of high bandwidth sensor data, provides an output of low bandwidth data. This low-bandwidth data serves to identify a particular reference pattern with which the high-bandwidth sensor data is found to correspond. Such a sensor can employ reference patterns discovered through pseudo-random trials. A great number of other advantageous features and arrangements are also detailed.","['H04L67/125', 'G06N20/00', 'G06N20/10', 'G06N3/08', 'G11C7/1006', 'G06N3/045', 'G06N3/0454', 'G06N3/049', 'G06N3/126', 'G06N7/005', 'G06N7/01', 'G11C19/00', 'H04L67/327', 'H04L67/63', 'Y02D30/70']"
US20220310242A1,System and method for fleet management of portable oxygen concentrators,A system and method for prediction of the time to service components for a fleet of portable oxygen concentrators (POCs) is disclosed. Each of the POCs include a transmitter to transmit operational data. A network interface is configured to receive operational data from the POCs. A user database contains profiles of users associated with respective POCs. An analysis engine updates the profile of a user associated with a POC in the user database based on received operational data from the POC. The analysis engine determines a similar profile in the user database to the updated profile. The analysis engine predicts a service date for the component of the POC based on the similar profile and the updated profile.,"['G06N5/04', 'G16H40/40', 'A61M16/101', 'A62B27/00', 'B01D53/30', 'G06N20/00', 'G06N5/02', 'G06Q10/04', 'G06Q10/083', 'G06Q10/20', 'G06Q30/0185', 'G06Q30/0633', 'G16H40/67', 'G16H50/20', 'A61M2202/0208', 'A61M2205/3331', 'A61M2205/3553', 'A61M2205/3561', 'A61M2205/3584', 'A61M2209/01', 'B01D2253/108', 'B01D2253/116', 'B01D2256/12', 'B01D2257/102', 'B01D2259/4533', 'B01D2259/4541', 'B01D2259/455', 'B01D53/047', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N5/01', 'G06N7/01', 'G16H20/40']"
US11138378B2,Intelligently summarizing and presenting textual responses with machine learning,"This disclosure relates to methods, non-transitory computer readable media, and systems apply machine-learning techniques and computational sentiment analysis to summarize sentences extracted from a group of textual responses or to select representative-textual responses from the group of textual responses. By using a response-extraction-neural network to extract (and sometimes paraphrase) sentences from textual responses, the disclosed methods, non-transitory computer readable media, and systems can generate a response summary of textual responses based on sentiment indicators corresponding to the textual responses. By applying a machine-learning classifier to generate textual quality scores for textual responses, the disclosed methods, non-transitory computer readable media, and systems select representative-textual responses from a group of textual responses based on relevancy parameters and sentiment indicators corresponding to the textual responses. Such computational techniques generate response summaries and representative responses that provide an efficient snapshot of a group of textual responses analyzed by machine learners.","['G06F40/30', 'G06F16/3344', 'G06F16/345', 'G06F16/36', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N20/10', 'G06N20/20', 'G06N5/01']"
US10721471B2,Deep learning based quantization parameter estimation for video encoding,"Techniques related to quantization parameter estimation for video coding are discussed. Such techniques may include generating features using a picture of input video received for encoding and applying a neural network to a feature vector including the features, a target bitrate, and a resolution of the picture to generate an estimated quantization parameter for encoding the picture.","['H04N19/124', 'G06N3/04', 'G06N3/08', 'G06N3/10', 'H04N19/136', 'H04N19/159', 'H04N19/167', 'H04N19/172', 'H04N19/184', 'H04N19/59', 'G06N20/20', 'G06N5/003', 'G06N5/01']"
US12009843B2,Matrix compression accelerator system and method,A matrix compression/decompression accelerator (MCA) system/method that coordinates lossless data compression (LDC) and lossless data decompression (LDD) transfers between an external data memory (EDM) and a local data memory (LDM) is disclosed. The system implements LDC using a 2D-to-1D transformation of 2D uncompressed data blocks (2DU) within LDM to generate 1D uncompressed data blocks (1DU). The 1DU is then compressed to generate a 1D compressed superblock (CSB) in LDM. This LDM CSB may then be written to EDM with a reduced number of EDM bus cycles. The system implements LDD using decompression of CSB data retrieved from EDM to generate a 1D decompressed data block (1DD) in LDM. A 1D-to-2D transformation is then applied to the LDM 1DD to generate a 2D decompressed data block (2DD) in LDM. This 2DD may then be operated on by a matrix compute engine (MCE) using a variety of function operators.,"['H03M7/30', 'G06F13/28', 'G06F17/16', 'G06N3/063', 'H03M7/3082', 'H03M7/6029', 'H03M7/6064', 'G06N3/045']"
US11210306B2,"Dialogue system, a method of obtaining a response from a dialogue system, and a method of training a dialogue system","A method of obtaining a response to a query inputted by a user, the method comprising: receiving a user inputted query; representing the user inputted query as a sequence of embedding vectors using a first model; encoding the sequence of embedding vectors to produce a context vector using a second model; retrieving responses with associated response vectors; scoring response vectors against the context vector, wherein the scoring is a measure of the similarity between the context vector and a response vector; and outputting the responses with the closest response vectors, wherein the first model is configured to segment a user inputted query into a sequence of units from a vocabulary of units and represent each unit in the sequence as an embedding vector, wherein at least one of the units in the vocabulary is an incomplete word, and wherein the first model comprises parameters that are stored using eight bits per parameter; and wherein the second model has been trained using corresponding queries and responses such that an encoding is used that maximises the similarity between the response vector and context vector for a corresponding query and response.","['G06F40/284', 'G06F16/24578', 'G06F16/243', 'G06F16/3344', 'G06F40/216', 'G06F40/237', 'G06F40/35', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084']"
CN113966522B,Efficient training and accuracy improvement of imaging-based assays,"The present disclosure relates to apparatus, devices, and methods that improve the accuracy of image-based assays using imaging systems with uncertainty or bias (defects) compared to ideal imaging systems. One aspect of the invention is to add a monitoring marker on the sample holder, wherein at least one of the geometric and/or optical properties of the monitoring marker is predetermined and known, and take an image of the sample with the monitoring marker, and train the machine learning model using the image with the monitoring marker.","['G06F18/2148', 'G06T7/0012', 'G06N20/00', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/094', 'G06T5/50', 'G06T5/60', 'G06T7/0002', 'G06T7/10', 'G06T7/11', 'G06T7/62', 'G06T7/70', 'G06V10/22', 'G06T2207/10061', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30024', 'G06T2207/30204']"
US20210141798A1,"Dialogue system, a method of obtaining a response from a dialogue system, and a method of training a dialogue system","A method of obtaining a response to a query inputted by a user, the method comprising: receiving a user inputted query; representing the user inputted query as a sequence of embedding vectors using a first model; encoding the sequence of embedding vectors to produce a context vector using a second model; retrieving responses with associated response vectors; scoring response vectors against the context vector, wherein the scoring is a measure of the similarity between the context vector and a response vector; and outputting the responses with the closest response vectors, wherein the first model is configured to segment a user inputted query into a sequence of units from a vocabulary of units and represent each unit in the sequence as an embedding vector, wherein at least one of the units in the vocabulary is an incomplete word, and wherein the first model comprises parameters that are stored using eight bits per parameter; and wherein the second model has been trained using corresponding queries and responses such that an encoding is used that maximises the similarity between the response vector and context vector for a corresponding query and response. [FIG. 2]","['G06F16/24578', 'G06F16/3344', 'G06F16/243', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084']"
US11604584B2,Storage system,"In write processing of a data set group to be written to be one or more data sets to be written, a storage system performs encoding processing including processing for generating a data model showing regularity of the data set group to be written and having one or more input values as an input and the data set group as an output. In the write processing, the storage system writes the data model generated in the encoding processing and associated with a key of the data set group to be written.","['G06F3/0608', 'G06F11/1048', 'G06F12/0246', 'G06F3/061', 'G06F3/0638', 'G06F3/0641', 'G06F3/0665', 'G06F3/067', 'G06F3/0679', 'G06F2212/401', 'G06F2212/403']"
CN110246512B,"Sound separation method, device and computer readable storage medium","The invention discloses a sound separation method, which comprises the following steps: dividing an original audio and video sample into a plurality of audio and video segments, and extracting a video stream and an audio stream of each audio and video segment; determining the face characteristics in the video stream of each audio-video section; acquiring audio characteristics in an audio stream of each audio-video section by using an audio conversion compression method; combining the face features and the audio features of each audio-video segment to generate audio-visual features of each audio-video segment; taking the audio-visual characteristics of each audio-visual frequency section as the input of a sound separation model, and training the sound separation model to obtain a trained sound separation model; and taking the target audio-video data as the input of the trained sound separation model, and outputting the audio data of the person in the target audio-video data. The invention also proposes a sound separation device and a computer readable storage medium. The invention can realize accurate mapping of voice and speaker, and obviously improve the quality of voice separation.","['G06F18/241', 'G06V40/172', 'G10L21/0208', 'G10L21/0272', 'G10L25/30', 'G10L25/57', 'G10L2021/02087']"
US11494868B2,Contextual configuration adjuster for graphics,"An embodiment of a graphics apparatus may include a context engine to determine contextual information, a recommendation engine communicatively coupled to the context engine to determine a recommendation based on the contextual information, and a configuration engine communicatively coupled to the recommendation engine to adjust a configuration of a graphics operation based on the recommendation. Other embodiments are disclosed and claimed.","['G06T1/20', 'G06F9/30145', 'G06F9/3851', 'G06F9/3887', 'G06F9/3888', 'G06T15/005', 'Y02D10/00']"
US10713540B2,Deep learning system for recognizing pills in images,"A system and method is provided that utilizes deep learning, including convolutional neural networks, to identify subject objects in unconstrained user images such as unknown pills. An image of, e.g., a pill, may be captured and subsequently processed using deep learning models to identify the pill. The deep learning models may be optimized to have a small footprint (in terms of computational and memory resources) suitable for a resource-limited device such as a smartphone while retaining a high object recognition accuracy. Each such model may also be run on modified versions of the unconstrained image, for example on color, greyscale, and gradient images, to focus the models on different distinguishing features of the object.","['G06K9/6276', 'G06V10/764', 'G06F18/22', 'G06F18/24147', 'G06K9/6215', 'G06V10/82', 'G06V20/66', 'G06F18/2155', 'G06K9/6259']"
US12388649B2,Systems and methods for secure tokenized credentials,"Systems, devices, methods, and computer readable media are provided in various embodiments having regard to authentication using secure tokens, in accordance with various embodiments. An individual's personal information is encapsulated into transformed digitally signed tokens, which can then be stored in a secure data storage (e.g., a “personal information bank”). The digitally signed tokens can include blended characteristics of the individual (e.g., 2D/3D facial representation, speech patterns) that are combined with digital signatures obtained from cryptographic keys (e.g., private keys) associated with corroborating trusted entities (e.g., a government, a bank) or organizations of which the individual purports to be a member of (e.g., a dog-walking service).","['H04L9/3231', 'G06F18/251', 'G06F21/32', 'G06F21/33', 'G06N3/04', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06V10/803', 'G06V40/165', 'G06V40/172', 'G06V40/40', 'G10L17/00', 'H04L63/0861', 'H04L63/123', 'H04L9/0866', 'H04L9/3213', 'H04L9/3247', 'H04W12/06', 'H04W12/10']"
US20250101887A1,Processor-based organic rankine cycle system for predictively-modeled recovery and conversion of thermal energy,"Technologies and techniques for converting thermal energy into mechanical and/or electric energy using an integrated thermal energy recovery system. This system employs an Organic Rankine Cycle (ORC) with a propellant heat exchanger, an expander, and a condenser, coupled with heat exchangers for transferring waste heat from an engine to ORC propellant. Sensors generate data reflecting environmental and operational conditions. A control circuit, incorporating a predictive module trained on a neural network, identifies non-linear relationships and sequences for optimizing ORC performance. The control circuit analyzes sensor data to determine if target operational values for waste heat recovery and power generation can be achieved within a specific timeframe. If not, the circuit dynamically adjusts the system via control signals to optimize net power by managing heat flow between thermal fluids, engine jacket water, engine exhaust, and/or ORC propellant to maintain target values.","['F01K23/065', 'F01K13/00', 'F01K13/02', 'F01K23/101', 'F01K25/00', 'F01K25/08', 'F01K27/02', 'F01K25/10']"
US11620983B2,"Speech recognition method, device, and computer-readable storage medium","The disclosure provides a speech recognition method, a device and a computer-readable storage medium. The method includes obtaining a first voice signal collected from a first microphone in a microphone array and a second voice signal collected from a second microphone in the microphone array, the microphone array including at least two microphones, such as two, three or six microphones. The method further includes extracting enhanced features associated with the first voice signal and the second voice signal through a neural network, and obtaining a speech recognition result based on the enhanced features extracted.","['G10L15/16', 'G10L15/063', 'G10L21/0216', 'G10L15/02', 'G10L15/20', 'G10L25/03', 'G10L25/30', 'G10L2021/02166']"
US11282391B2,Object detection at different illumination conditions,"A method for image processing at different illumination conditions, the method may include acquiring an image of an environment of a vehicle; selecting a set of pixels located within a region of interest that is located at an upper part of the image; calculating an illumination condition indicator based on values of the set of pixels; selecting a selected machine learning process, out of a machine learning processes, based on the illumination condition indicator; wherein different machine learning processes are trained to different illumination conditions; and processing the image by the selected machine learning process to provide processing results.","['G06F18/214', 'G08G1/167', 'G06K9/00335', 'G06K9/00805', 'G06K9/66', 'G06K9/72', 'G06N20/00', 'G06N5/04', 'G06T5/70', 'G06V20/58', 'G06V40/20', 'G08G1/04', 'G08G1/16', 'B60W30/0956', 'B60W40/04', 'B60W60/0017', 'B60W60/0027']"
US10204286B2,Self-organizing discrete recurrent network digital image codec,"An invention based on learning a discrete recurrent neural network for a given signal domain is described. In one implementation to the domain of visual images, the method can be used to efficiently compress digital photographs and to devise a new perceptual distortion measure between images that well-matches data collected from a human psychophysics experiment. Other applications of the invention include unsupervised detection of recurrent patterns in high-dimensional data and Shannon-optimal error-correcting coding from few training examples.","['G06K9/6247', 'G06F18/2135']"
CN109214360B,Construction method and application of face recognition model based on Parasoft Max loss function,"The invention discloses a method for constructing a face recognition model based on a Parasoft Max loss function, which comprises the following steps: selecting a basic convolutional neural network model according to the application environment of the task; acquiring a specified number of face images marked with face identity information as a training data set; obtaining a decision edge parameter according to the angle difference of class centers of a difficult sample feature vector and a simple sample feature vector in the classification training of a training data set in a basic convolutional neural network model and the class centers of the simple sample feature vector and the class to which the simple sample feature vector belongs respectively; obtaining a ParaSoft Max loss function according to the decision edge parameters; setting the loss function at the last layer of the basic convolutional neural network model to form a face recognition model based on the loss function; and inputting a training data set into the face recognition model, and iteratively training model parameters by minimizing a loss function to obtain an optimal face recognition model. Therefore, the face recognition model can improve the accuracy of face recognition.",['G06V40/172']
US12089291B2,Machine learning model configuration in wireless networks,"Certain aspects of the present disclosure provide techniques and apparatus for determining neural network functions (NNFs) and configuring and using corresponding machine learning (ML) models for performing one or more ML-based wireless communications management procedures. An example method performed by a user equipment includes transmitting, to a base station (BS), UE capability information indicating at least one radio capability of the UE and at least one machine learning (ML) capability of the UE and receiving, from the BS based on the UE capability information, ML configuration information indicating at least one neural network function (NNF) and at least one ML model corresponding to the at least one NNF.","['H04L41/16', 'H04W8/24', 'G06N3/04', 'G06N3/08', 'H04L41/0803', 'H04W24/02', 'G06N3/0464', 'G06N3/084', 'G06N3/09']"
US12380287B2,Systems for controllable summarization of content,A method of generating summaries of content items using one or more large language models (LLMs) is disclosed. A first content item is identified. The first content item includes a set of sub-content items. A level of abstraction is determined for the content item. A prompt is automatically engineered for providing to the one or more LLMs. The prompt includes a reference to the first content item and the level of the abstraction for the first content item. A response to the prompt is received from the LLM. The response includes a second content item. The second content item includes a representation of the first content item that is generated by the LLM. The representation omits or simplifies one or more of the set of sub-content items based on the level of abstraction. The representation is used to control an output that is communicated to a target device.,"['G06F40/56', 'G06F16/345']"
US20250131788A1,"Systems, methods and devices for monitoring betting activities","A platform, device and process for capturing images of the surface of a gaming table and determining the quantity, identity, and arrangement of chips bet at a gaming table. Image data is captured corresponding to the one or more chips positioned in at least one betting area on a gaming surface of the respective gaming table and the data is processed to use a machine learning based approach to classify the chips using a combination of a depth information channel and at least one of a red channel, the green channel, and the blue channel.","['G07F17/3211', 'A63F3/00157', 'G06F18/213', 'G06F18/214', 'G06F18/24323', 'G06F18/25', 'G06F18/251', 'G06F18/253', 'G06T7/194', 'G06T7/50', 'G06T7/60', 'G06V10/141', 'G06V10/44', 'G06V10/462', 'G06V10/50', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V20/52', 'G07F17/322', 'G07F17/3227', 'G07F17/3237', 'G07F17/3239', 'G07F17/3241', 'G07F17/3288', 'A63F2003/00164', 'G06F2218/00', 'G06F2218/12', 'G06V20/64']"
US11153435B2,Method and system for automatically blocking robocalls,"A method and system for automatically blocking robocalls. A set of incoming call data is captured from the incoming call. The set of incoming call data, including captured audio data, is checked with plural different tests to determine if the robocall includes a voice call component. The plural different tests provide additional levels of detection for robocalls. The method and system automatically identify and process robocalls and help prevent call spoofing and neighbor spoofing by robocalls.","['H04M3/436', 'G06N5/022', 'H04M3/2218', 'H04M7/006', 'H04W4/16', 'H04W4/70', 'G06N20/00', 'G06N3/006', 'G06N3/084', 'G06N3/088', 'G06N7/01', 'H04M2203/2011', 'H04M2203/2027', 'H04M2203/553', 'H04M2203/6027', 'H04M3/42059', 'H04M3/53308']"
US11609224B2,Devices and methods for white blood cell analyses,"Among other things, the present invention is related to devices and methods of performing biological and chemical assays, such as but not limited to assay related to analysis of white blood cells.","['G01N33/49', 'B01L3/502761', 'B01L3/5055', 'G01N15/0227', 'G01N15/14', 'G01N15/1431', 'G01N15/1434', 'G01N21/6428', 'B01L2200/021', 'B01L2200/0647', 'B01L2200/16', 'B01L2300/0816', 'B01L2300/0887', 'B01L2300/163', 'B01L2400/086', 'G01N2015/0073', 'G01N2015/008', 'G01N2015/0084', 'G01N2015/012', 'G01N2015/016', 'G01N2015/018', 'G01N2015/1006', 'G01N2015/1486', 'G01N2015/1493', 'G01N2015/1497', 'G01N2021/6439']"
US12211117B2,Data parallelism and halo exchange for distributed machine learning,"One embodiment provides for a method of transmitting data between multiple compute nodes of a distributed compute system, the method comprising multi-dimensionally partitioning data of a feature map across multiple nodes for distributed training of a convolutional neural network; performing a parallel convolution operation on the multiple partitions to train weight data of the neural network; and exchanging data between nodes to enable computation of halo regions, the halo regions having dependencies on data processed by a different node.","['G06T1/20', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06T1/60', 'G06N3/044', 'G06T2207/20081', 'G06T2207/20084']"
US12387287B2,Abstraction layers for scalable distributed machine learning,"One embodiment provides for a method of transmitting data between multiple compute nodes of a distributed compute system, the method comprising creating a global view of communication operations to be performed between the multiple compute nodes of the distributed compute system, the global view created using information specific to a machine learning model associated with the distributed compute system; using the global view to determine a communication cost of the communication operations; and automatically determining a number of network endpoints for use in transmitting the data between the multiple compute nodes of the distributed compute system.","['G06T1/20', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/084']"
CN108694080B,Efficient thread group scheduling,"The invention relates to efficient thread group scheduling. Mechanisms for facilitating intelligent thread scheduling at an autonomous machine are described. As described herein, the method of an embodiment includes: dependency information is detected for a plurality of threads corresponding to a plurality of workloads associated with tasks related to a processor including a graphics processor. The method may further comprise: generating a tree of thread groups based on the dependency information, wherein each thread group includes a plurality of threads; and scheduling one or more of the thread groups associated with similar dependencies to avoid dependency conflicts.","['G06F9/4881', 'G06F9/3851', 'G06F9/3887', 'G06F9/5066', 'G06T1/20', 'G06F2209/483', 'G06F2209/484']"
US10896101B2,"Multiclient backup replication apparatuses, methods and systems","The Multiclient Backup Replication Apparatuses, Methods and Systems (“MBR”) transforms pairing request, replication data stream inputs via MBR components into pairing response, replication confirmation outputs. A replication notification for a snapshot of a backup volume at a source node is obtained. A source node named pipe for the snapshot is created. A priority for the snapshot is determined. When appropriate to send the snapshot to a replication target node, snapshot data is read from the source node named pipe and serialized into chunks Chunks associated with the snapshot and other snapshots are multiplexed into a replication data stream and sent to the replication target node via a persistent network connection. The replication data stream is received by the replication target node and chunks associated with the snapshot are deserialized. A replication target node named pipe for the snapshot is created and used to write snapshot data to a replication volume.","['G06F11/1451', 'G06F11/1464', 'G06F11/1466', 'G06F9/542', 'G06F11/1469', 'G06F2201/84']"
US11956412B2,Drone based capture of multi-view interactive digital media,"Various embodiments of the present disclosure relate generally to systems and methods for drone-based systems and methods for capturing a multi-media representation of an entity. In some embodiments, the multi-media representation is digital, or multi-view, or interactive, and/or the combinations thereof. According to particular embodiments, a drone having a camera is controlled or operated to obtain a plurality of images having location information. The plurality of images, including at least a portion of overlapping subject matter, are fused to form multi-view interactive digital media representations.","['H04N13/282', 'B64C39/024', 'B64U10/14', 'G05D1/0094', 'G05D1/0202', 'G05D1/652', 'G05D1/689', 'G06F16/51', 'G06F3/04815', 'G06F3/0488', 'G06T15/205', 'G06T17/00', 'G06V10/17', 'G06V20/10', 'G06V20/17', 'G06V20/70', 'H04N23/698', 'H04N5/2624', 'H04N7/185', 'B64U20/80', 'B64U2101/30', 'B64U2201/10']"
US12190483B2,Deep generative modeling of smooth image manifolds for multidimensional imaging,A method for visualization of dynamic objects using a generative manifold includes steps of: acquiring a set of measurements associated with the dynamic objects using sensors; estimating parameters of a generator using the set of measurements and estimating latent variables using the set of measurements; modeling using a computing device the dynamic objects as a smooth non-linear function of the latent variables using the generator such that points in a latent subspace are mapped to a manifold in a generative manifold model; and generating a visualization of the dynamic objects using the generative manifold model. The set of measurements may include multi-slice data. The generative manifold model may provide for modeling deformations.,"['G06N3/084', 'G06T5/70', 'G06N3/045', 'G06N3/08', 'G06T5/50', 'G06T2207/10076', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182', 'G06T2207/30048', 'G06T2207/30061']"
US11244191B2,Region proposal for image regions that include objects of interest using feature maps from multiple layers of a convolutional neural network model,Region proposal is described for image regions that include objects of interest. Feature maps from multiple layers of a convolutional neural network model are used. In one example a digital image is received and buffered. Layers of convolution are performed on the image to generate feature maps. The feature maps are reshaped to a single size. The reshaped feature maps are grouped by sequential concatenation to form a combined feature map. Region proposals are generated using the combined feature map by scoring bounding box regions of the image. Objects are detected and classified objects in the proposed regions using the feature maps.,"['G06K9/46', 'G06V10/82', 'G06F18/214', 'G06F18/2431', 'G06K9/3233', 'G06K9/6232', 'G06K9/6256', 'G06K9/628', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/082', 'G06V10/25', 'G06V10/764', 'G06V10/7715']"
US12373912B2,Prefetch status notification for memory prefetching,"Embodiments are generally directed to memory prefetching in multiple GPU environment. An embodiment of an apparatus includes multiple processors including a host processor and multiple graphics processing units (GPUs) to process data, each of the GPUs including a prefetcher and a cache; and a memory for storage of data, the memory including a plurality of memory elements, wherein the prefetcher of each of the GPUs is to prefetch data from the memory to the cache of the GPU; and wherein the prefetcher of a GPU is prohibited from prefetching from a page that is not owned by the GPU or by the host processor.","['G06F12/0862', 'G06T1/20', 'G06F12/084', 'G06F12/0842', 'G06F12/1009', 'G06F9/3802', 'G06F9/3877', 'G06T1/60', 'G06T15/005']"
US11709714B2,Thread group scheduling for graphics processing,"Embodiments are generally directed to thread group scheduling for graphics processing. An embodiment of an apparatus includes a plurality of processors including a plurality of graphics processors to process data; a memory; and one or more caches for storage of data for the plurality of graphics processors, wherein the one or more processors are to schedule a plurality of groups of threads for processing by the plurality of graphics processors, the scheduling of the plurality of groups of threads including the plurality of processors to apply a bias for scheduling the plurality of groups of threads according to a cache locality for the one or more caches.","['G06F9/5027', 'G06F12/0837', 'G06F9/3455', 'G06F9/3851', 'G06F9/3877', 'G06F9/3885', 'G06F9/3887', 'G06F9/3888', 'G06F9/38885', 'G06F9/4881', 'G06F9/5033', 'G06F9/5066', 'G06F9/545', 'G06F16/24569', 'G06F9/30178', 'G06T1/20', 'G06T1/60', 'G06T15/005']"
US11892950B2,Data prefetching for graphics data processing,"Embodiments are generally directed to data prefetching for graphics data processing. An embodiment of an apparatus includes one or more processors including one or more graphics processing units (GPUs); and a plurality of caches to provide storage for the one or more GPUs, the plurality of caches including at least an L1 cache and an L3 cache, wherein the apparatus to provide intelligent prefetching of data by a prefetcher of a first GPU of the one or more GPUs including measuring a hit rate for the L1 cache; upon determining that the hit rate for the L1 cache is equal to or greater than a threshold value, limiting a prefetch of data to storage in the L3 cache, and upon determining that the hit rate for the L1 cache is less than a threshold value, allowing the prefetch of data to the L1 cache.","['G06F12/0862', 'G06F12/0888', 'G06F12/0897', 'G06T1/20', 'G06T1/60', 'G06F2212/1024', 'G06F2212/502', 'G06F2212/602', 'G06F2212/608', 'G06F9/3802', 'Y02D10/00']"
US10783669B2,Texture coordinate compression using texture atlas,"An encoder may perform a method of compressing texture coordinates using texture atlas. In one example implementation, the method may include predicting texture coordinates of a corner of a triangle, the triangle being one of a plurality of triangles of a geometric mesh, the predicting based on a corresponding texture atlas and local information associated with the corner. The method further includes determining a residual vector based on the predicted texture coordinates, performing entropy encoding of the residual vector along with residual vectors of other corners of the geometric mesh, and generating compressed data based on the entropy encoding.","['G06T9/004', 'G06T9/001']"
US20250200157A1,Methods for providing information about a person based on facial recognition,"This disclosure provides methods for providing information about a person based on facial recognition and various applications thereof, including face-based check-in, face-based personal identification, face-based identification verification, face-based background checks, facial data collaborative network, correlative face search, and personal face-based identification. The disclosed methods are able to provide accurate information about a person in a real-time manner.","['G06F21/32', 'G06F16/51', 'G06F16/56', 'G06F16/951', 'G06F18/214', 'G06F21/6245', 'G06N3/04', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06V20/647', 'G06V30/19147', 'G06V40/16', 'G06V40/166', 'G06V40/172', 'G06V40/45', 'G06V40/50', 'G07C9/00563', 'G07C9/37', 'G06N20/00', 'G06N3/045', 'G07C9/38']"
CN113947589B,Missile-borne image deblurring method based on countermeasure generation network,"The invention discloses a missile-borne image deblurring method based on an countermeasure generation network, and belongs to the technical field of missile-borne computer vision. The invention utilizes an antagonism generation network to carry out deblurring treatment on a blurred missile-borne image, and designs a antagonism network model which is generated by depth convolution of a generator and a discriminator, wherein the generator adopts an encoding-decoding structure and constructs a joint loss function, the reconstruction is continuously trained to generate a restored image of the missile-borne blurred image, the discriminator is used for discriminating a clear image and an image forged by the generator, the generator approaches the clear image confusion discriminator, the network model reaches an expected index through two network antagonism training, and the network model after the antagonism training is transplanted to a missile-borne computer for deblurring the missile-borne image, so that the guidance precision is improved. In addition, the invention simulates different fuzzy sources by establishing a realistic synthesized motion fuzzy semi-physical simulation system, solves the problem of difficult actual acquisition of missile-borne image data, improves the training efficiency and saves the test cost.","['G06T7/0002', 'G06F18/214', 'G06N3/045', 'G06N3/08', 'G06T5/73', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
US20200244997A1,Method and apparatus for filtering with multi-branch deep learning,"Deep learning may be used in video compression for in-loop filtering in order to reduce artifacts. To reduce the computation complexity of the neural networks, in one embodiment, a multi-branch CNN is used. The multi-branch CNN may include multiple basic CNNs and an identify filter, where each basic CNN or the identity filter is considered as a branch. At the encoder side, the best branch can be chosen, for example, based on RDO. The best branch can be indicated to or be derived at the decoder side. For similar filtering performance, each basic CNN in the multi-branch CNN can use fewer layers than if the filter is done by a single-branch CNN. At the decoder side, the best branch is used for in-loop filtering. By breaking the symmetry at the encoding and decoding using the CNN, the computation complexity at the decoder side can be reduced.","['G06T9/002', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'H04N19/61', 'H04N19/82', 'G06N3/048', 'G06T2207/20084']"
US20210312725A1,Vehicle-data analytics,Provided is a system configured to determine and push adjustments to vehicle operations using machine-learning systems across multiple computing layers.,"['G06N3/08', 'B60W50/0098', 'G06N3/045', 'G07C5/008', 'G07C5/02', 'G07C5/0841', 'G08G1/0112', 'G08G1/0116', 'G08G1/0133', 'G08G1/0141', 'G08G1/096716', 'G08G1/096741', 'G08G1/096775', 'H04L67/12', 'H04Q9/00', 'H04W4/021', 'H04W4/44', 'G06N3/044', 'G06N3/047']"
CN113242469B,An adaptive video transmission configuration method and system,"The invention provides a self-adaptive video transmission configuration method and a self-adaptive video transmission configuration system, which can learn and select video transmission configuration in a self-adaptive manner gradually through a reinforcement learning method from the beginning without any prior knowledge under the condition of not using any pre-programmed model or specific hypothesis, so that a multi-task target of keeping lower transmission delay and enhancing the detection accuracy performance of a real-time video system for target detection is realized. The invention uses the neural network to represent the decision selection process of video coding, and the neural network maps abundant and diverse observation values to the video coding configuration decision of the next time slot in a dynamic and scalable mode by taking the observation values (estimated bandwidth and historical configuration) of the system and the speed of video picture change as input. After multiple times of iterative training, efficient video configuration decisions can be made, the target detection performance of the system is enhanced while the low transmission delay of the system is kept, and the generalization performance is good.","['H04N21/440281', 'G06F18/214', 'G06N3/04', 'G06N3/08', 'G06V20/40', 'G06V20/52', 'H04N21/440263', 'H04N21/44245', 'H04N21/4621', 'H04N7/18', 'G06V2201/07']"
US12412362B2,System and method for detecting and transmitting incidents of interest of a roadway to a remote server,"System and methods for automated incident identification and reporting while operating a vehicle on the road using a device. The device identifies incidents using artificial intelligence neural networks trained to detect, classify, segment, and/or extract other information pertaining to objects of interest representing incidents. Additionally, a system and method for further storing, transmitting, processing, organizing and accessing the information graphically with respect to incident type, location, date and time during operation of the vehicle along the road.","['G06V10/25', 'H04N7/181', 'G01B21/30', 'G06T5/70', 'G06T7/70', 'G06V10/82', 'G06V20/58', 'H04N7/185', 'G06N3/045', 'G06N3/08', 'G06T2207/20084', 'G06T2207/30261', 'G08G1/09623']"
US11564661B2,Method for optimizing ultrasonic imaging system parameter based on deep learning,"A method for optimizing an ultrasonic imaging system parameter based on deep learning, comprising the following steps: step 1: collecting samples for training neural networks, the samples comprising ultrasound image samples i, and a corresponding ultrasonic imaging system parameter vector sample p used by an ultrasonic imaging system when the ultrasonic image samples are collected; step 2: establishing a neural network model and training the neural networks to convergence by using the samples collected=in step 1, so as to obtain a trained neural network system onn; and step 3: taking the original ultrasonic imaging system parameter vector p or the original ultrasonic image as an input to be input into the neural network system onn trained in step 2, at this moment, a parameter obtained from an output end of onn being an optimized ultrasonic imaging system parameter vector ep=onn(p). By means of the method, the purpose of improving the ultrasonic image quality is realized by optimizing the ultrasonic imaging system parameter.","['G06N3/088', 'A61B8/5223', 'A61B8/54', 'A61B8/585', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06T7/0012', 'G16H30/40', 'G06T2207/10132', 'G06T2207/20081', 'G06T2207/20084']"
US20220332335A1,Vehicle-data analytics,Provided is a system configured to determine and push adjustments to vehicle operations using machine-learning systems across multiple computing layers.,"['H04W4/44', 'B60W50/045', 'B60W50/02', 'G06N3/08', 'G07C5/008', 'G07C5/0841', 'G08G1/0112', 'G08G1/0116', 'G08G1/0137', 'H04W4/021', 'B60W2050/0075', 'B60W2050/0215', 'B60W2540/106', 'B60W2556/10', 'B60W2556/45', 'G06N3/044', 'G06N3/045', 'G06N3/047']"
US11769228B2,Image enhancement via iterative refinement based on machine learning models,"A method includes receiving, by a computing device, training data comprising a plurality of pairs of images, wherein each pair comprises an image and at least one corresponding target version of the image. The method also includes training a neural network based on the training data to predict an enhanced version of an input image, wherein the training of the neural network comprises applying a forward Gaussian diffusion process that adds Gaussian noise to the at least one corresponding target version of each of the plurality of pairs of images to enable iterative denoising of the input image, wherein the iterative denoising is based on a reverse Markov chain associated with the forward Gaussian diffusion process. The method additionally includes outputting the trained neural network.","['G06T5/002', 'G06T5/70', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T3/4007', 'G06T5/50', 'G06T5/60', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084']"
CN110442684B,A text content-based recommendation method for similar cases,"The invention relates to a class case recommendation method based on text content, which comprises a pre-training part and a fine-tuning part, wherein the pre-training part adopts a transformer encoder as a main structure, trains a Chinese language model, learns Chinese language knowledge from other corpora and obtains a high-quality language model. The fine-tuning part three-tuple model is taken as a frame, preprocessed judicial documents are taken as training data, more knowledge about judgment is learned from the judicial field, and a better text vector representation is obtained. Compared with the traditional case recommendation method based on keywords and the case recommendation method based on the single-task neural network, the case recommendation method based on the content has better effect, and has better robustness based on the semantic training model, which shows that the method provided by the invention is effective and practical.","['G06F16/3344', 'G06F16/335', 'G06F16/35', 'G06F18/22', 'G06N3/045', 'G06N3/084']"
US8938113B2,Adaptive visualization for direct physician use,"A method of modifying a three dimensional (3D) volume visualization image of an anatomical structure in real time to separate desired portions thereof. The method includes providing a two dimensional (2D) image slice of a 3D volume visualization image of an anatomical structure, identifying portions of the anatomical structure of interest, and providing a prototype image of desired portions of the anatomical structure. The method then includes using an evolver to evolve parameters of an algorithm that employs a transfer function to map optical properties to intensity values coinciding with the portions of the anatomical structure of interest to generate an image that sufficiently matches the prototype image. If the parameters match the prototype image, the method then includes applying the transfer function to additional 2D image slices of the 3D volume visualization image to generate a modified 3D volume visualization image of the anatomical structure. The method includes using a pattern recognizer to assist the evolver, to classify whether a view is normal or abnormal, and to extract the characteristic of an abnormality if and when detected.","['G06T15/08', 'G06N3/086', 'G06T7/0014', 'G06T7/0081', 'G06T7/11', 'G06T7/143', 'G06V10/454', 'A61B5/055', 'A61B6/032', 'A61B6/466', 'G06T2207/10072', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20104', 'G06T2207/30004', 'G06V2201/031']"
CN108510985B,System and method for reducing principle bias in producing speech models,"Described herein are systems and methods for identifying and addressing sources of deviation in an end-to-end speech model. In one or more embodiments, the end-to-end model may be a recurrent neural network with two 2D convolutional input layers, followed by two bi-directional recursive layers and one fully connected layer before the softmax layer. In one or more embodiments, the CTC loss function is used to train end-to-end to directly predict a sequence of characters from the log spectrum of the audio. By optimizing the recursive layers and training with the alignment information, some undesirable bias in the configured model that is caused by using only a pure forward recursion can be removed.","['G10L15/16', 'G10L15/02', 'G10L15/04', 'G10L15/06', 'G10L15/063', 'G10L15/183', 'G10L15/22', 'G10L25/18']"
US11037531B2,Neural reconstruction of sequential frames,"In one embodiment, a computing system configured to generate a current frame may access a current sample dataset having incomplete pixel information of a current frame in a sequence of frames. The system may access a previous frame in the sequence of frames with complete pixel information. The system may further access a motion representation indicating pixel relationships between the current frame and the previous frame. The previous frame may then be transformed according to the motion representation. The system may generate the current frame having complete pixel information by processing the current sample dataset and the transformed previous frame using a first machine-learning model.","['G09G5/37', 'G06F3/147', 'G06N20/00', 'G06N3/045', 'G06N3/088', 'G09G5/363', 'G09G5/391', 'G06N7/01', 'G09G2310/0232', 'G09G2320/0686', 'G09G2320/10', 'G09G2340/0407', 'G09G2340/16']"
US11463980B2,Methods and apparatuses using sensing system in cooperation with wireless communication system,"Methods and systems are described which use a sensing system in cooperation with a wireless communication system. Coordinate information (which may be from the sensing system, from an electronic device, or from a network-side device) and signal-related information (which may be from the wireless system) are associated with each other. The associated information may be used for wireless communication management, such as beam management operations, among others.","['H04W64/003', 'H04W64/00', 'G01S1/042', 'G01S1/08', 'G01S5/0273', 'G01S5/0278', 'H04B7/0696', 'H04B7/088', 'H04W16/28', 'H04W4/025', 'H04W4/029', 'H04W76/11']"
CN111929542B,Power equipment diagnosis method and system,"The invention discloses a power equipment diagnosis method and a system, which are used for generating diagnosis information of power equipment by inputting an ultrasonic spectrum picture, a visible light image and an infrared thermal image into a convolutional neural network; the invention locates the equipment fault based on a plurality of different types of images, and generates the diagnosis information of the power equipment by adopting the convolutional neural network according to a plurality of different types of images, thereby improving the accuracy of fault location and solving the problem that the existing ultrasonic partial discharge detector only depends on ultrasonic signals as the input of the convolutional neural network, so that the accuracy is not high when the fault location is carried out.","['G01R31/1209', 'G01J5/0096', 'G01R31/088', 'G01R31/1227', 'G06N3/045', 'G01J2005/0077', 'Y04S10/50']"
US11556775B2,Systems and methods for trace norm regularization and faster inference for embedded models,"Described herein are systems and methods for compressing and speeding up dense matrix multiplications as found, for examples, in the fully connected and recurrent layers of neural networks for embedded large vocabulary continuous speech recognition (LVCSR). For compression, trace norm regularization technique embodiments were introduced and studied for training low rank factored versions of matrix multiplications. Compared to standard low rank training, the methods more consistently lead to good accuracy versus number of parameter trade-offs and can be used to speed-up training of large models. Faster inference may be further enabled on ARM processors through kernels optimized for small batch sizes, resulting in speed ups over the currently used library. Beyond LVCSR, the techniques are also generally applicable to embedded neural networks with large fully connected or recurrent layers.","['G06N3/08', 'G06F17/16', 'G06N3/044', 'G06N3/045', 'G06N5/04', 'G06N3/047', 'G06N3/048', 'G10L15/063', 'G10L15/16']"
WO2019179024A1,"Method for intelligent monitoring of airport runway, application server and computer storage medium","Disclosed is a method for intelligent monitoring of an airport runway, the method comprising: decomposing an airport runway video stored in a core switch into continuous frame images; using a full convolution network model to carry out feature extraction on the frame images to obtain an airport runway feature; using a pixel-based adaptive segmentation foreground detection algorithm to detect a moving target on the airport runway, and setting a first tracking frame for the detected first moving target; using a high-speed compression tracking algorithm to track the first tracking frame and obtaining a target tracking sequence of the first moving target; inputting the first moving target tracking sequence into a deep neural network model for classification; and when the target is an abnormal moving target, executing a warning operation. The present application also provides an application server and a computer readable storage medium. The method for intelligent monitoring of an airport runway, the application server and the computer readable storage medium provided by the present application can improve the reliability of intelligent monitoring of the airport runway.","['G06T7/73', 'G06V20/42', 'G06F18/213', 'G06F18/2136', 'G06F18/214', 'G06F18/2413', 'G06F18/24155', 'G06T7/246', 'G06V10/255', 'G06V10/267', 'G06V10/28', 'G06V10/454', 'G06V10/82', 'G06V20/49', 'G06V20/52', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30232', 'G06V10/62', 'G06V20/46']"
CN112734696B,Face changing video tampering detection method and system based on multi-domain feature fusion,"The invention discloses a face-changing video tampering detection method and system based on multi-domain feature fusion, wherein the method comprises the following steps: dividing a data set; framing a video, selecting a frame sequence to be detected, and extracting a region to be detected of each frame image; calculating RGB (red, green and blue) features, DFT (discrete Fourier transform) features and optical flow feature images of the detection area; constructing a convolution feature extraction module of a multi-path convolution neural network; inputting the convolution characteristics of each branch into an attention module to generate an attention guide characteristic diagram; multi-path attention-guided feature cascade fusion, and inputting a full connection layer for feature classification; inputting the characteristic image into a multi-path convolution neural network for training, and storing a network model and an optimal weight; and performing prediction classification by using the trained model, and outputting a face-changing video tampering detection result. The method can better combine the tampering information of the video in the spatial domain, the frequency domain and the time domain, improve the generalization capability of the model, and optimize the learning of the classification characteristics of multiple fields by utilizing the channel attention mechanism.","['G06T7/0002', 'G06F18/24', 'G06F18/253', 'G06N3/045', 'G06N3/084', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US11290686B2,Architecture for scalable video conference management,"In some implementations, an endpoint device captures video data during a network-based communication session. The endpoint devices processes a stream of user state data indicating attributes of a user of the endpoint device at different times during the network-based communication session. The endpoint device transmits the stream of user state data over a communication network to a server system. The endpoint device receives, over the communication network, (i) content of the network-based communication session and (ii) additional content based on user state data generated by the respective endpoint devices each processing video data that the respective endpoint devices captured during the network-based communication session. The endpoint device presents a user interface providing the received content of the network-based communication session concurrent with the received additional content that is based on the user state data generated by the respective endpoint devices.","['H04N7/152', 'G06K9/00718', 'G06V20/41', 'H04N7/147']"
US11785180B2,Management and analysis of related concurrent communication sessions,"In some implementations, a computer system identifies multiple sub-sessions of a network-based communication session in which multiple remote endpoint devices each provide media streams over a communication network. For each of the sub-sessions, the computer system can identify the endpoint devices included in the sub-session. The computer system can obtain user state data for each of the endpoint devices, the user state data for each endpoint device being generated based on analysis of face images of the user of the endpoint device. The computer system aggregates the user state data to determine a sub-session state for each of the sub-sessions. During the communication session, the computer system communicates over the communication network with a remote device associated with the communication session to cause a user interface of the remote device to indicate the sub-session states determined for one or more of the multiple sub-sessions.","['H04N7/152', 'G06V20/41', 'H04N7/147', 'H04N7/15', 'G06V40/174']"
US11425363B2,System and method for generating light field images,"A system and method can include receiving a set of views, encoding the set of views, and displaying the set of views such that they are perceived as a holographic image.","['H04N13/351', 'H04N13/156', 'G01B11/245', 'G02B27/0075', 'G02B30/27', 'G03H1/0005', 'G03H1/26', 'G06T3/4038', 'G06T7/557', 'H04N13/111', 'H04N13/161', 'H04N13/302', 'H04N13/307', 'H04N19/597', 'G01B2210/54', 'G03H2001/0088', 'H04N13/15', 'H04N13/239', 'H04N13/243']"
US11288577B2,Deep long short term memory network for estimation of remaining useful life of the components,"Example implementations described herein are directed to systems and methods for estimating the remaining useful life of a component or equipment through the application of models for deriving functions that can express the remaining useful life over time. In an aspect, the failure acceleration time point is determined for a given type of component, and a function is derived based on the application of models on the failure acceleration time point.","['G06N3/08', 'G05B23/0221', 'G05B23/0283', 'G06F11/008', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06F11/3006', 'G06F2201/81', 'G06F2201/835']"
US20250232363A1,Image processing arrangements,"Aspects of the detailed technologies concern training and use of neural networks for fine-grained classification of large numbers of items, e.g., as may be encountered in a supermarket. Mitigating false positive errors is an exemplary area of emphasis. Novel network topologies are also detailed—some employing recognition technologies in addition to neural networks. A great number of other features and arrangements are also detailed.","['G06Q30/0641', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06N3/045', 'G06V10/17', 'G06V10/462', 'G06V10/764', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V20/00', 'G06F16/906', 'G06N3/04', 'G06N3/08', 'G06V2201/09']"
US11886986B2,Architecture for a hardware based explainable neural network,"Explainable neural networks may be designed to be easily implementable in hardware efficiently, leading to substantial speed and space improvements. An exemplary embodiment extends upon possible hardware embodiments of XNNs, making them suitable for low power applications, smartphones, mobile computing devices, autonomous machines, server accelerators, Internet of Things (IoT) and edge computing applications amongst many other applications. The capability of XNNs to be transformed from one form to another while preserving their logical equivalence is exploited to create efficient, secure hardware implementations that are optimized for the desired application domain and predictable in their behavior.","['G06N3/082', 'G06N3/063', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'G06N3/044', 'G06N3/088']"
TWI779418B,Method of reading the output of an artificial recurrent neural network and computer-readable storage medium thereof,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for constructing and operating a recurrent artificial neural network. In one aspect, a method is for reading the output of an artificial recurrent neural network that includes a plurality of nodes and edges connecting the nodes. The method includes identifying one or more relatively complex root topological elements that each includes a subset of the nodes and edges in the artificial recurrent neural network, identifying a plurality of relatively simpler topological elements that each comprises a subset of the nodes and edges in the artificial recurrent neural network, wherein the identified relatively simpler topological elements stand in a hierarchical relationship to at least one of the relatively complex root topological elements, generating a collection of digits, wherein each of the digits represents whether a respective of the relatively complex root topological elements and the relatively simpler topological elements is active during a window, and outputting the collection of digits.","['G06N3/105', 'G06N3/049', 'G06N3/02', 'G06N3/044', 'G06N3/065', 'G06N3/084', 'G06N3/08']"
US11393100B2,Automatically generating a trimap segmentation for a digital image by utilizing a trimap generation neural network,"Methods, systems, and non-transitory computer readable storage media are disclosed for utilizing a plurality of neural networks in a multi-branch pipeline to generate image masks for digital images. Specifically, the disclosed system can classify a digital image as a portrait or a non-portrait image. Based on classifying a portrait image, the disclosed system can utilize separate neural networks to generate a first mask portion for a portion of the digital image including a defined boundary region and a second mask portion for a portion of the digital image including a blended boundary region. The disclosed system can generate the mask portion for the blended boundary region by utilizing a trimap generation neural network to automatically generate a trimap segmentation including the blended boundary region. The disclosed system can then merge the first mask portion and the second mask portion to generate an image mask for the digital image.","['G06T7/194', 'G06T3/40', 'G06T7/11', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20221']"
US11023804B2,Generating an output for a neural network output layer,"Systems, methods, and apparatus, including computer programs encoded on a computer storage medium for processing a network input through a neural network having one or more initial neural network layers followed by a softmax output layer. In one aspect, the methods include obtaining a layer output generated by the one or more initial neural network layers and processing the layer output through the softmax output layer to generate a neural network output. Processing the layer output through the softmax output layer includes determining, for each possible output value, a number of occurrences in the layer output values; for each possible output value occurring in the layer output values, determining a respective exponentiation measure; determining a normalization factor for the layer output by combining the exponentiation measures in accordance with the number of occurrences of the possible output values; and determining, for each of layer output values, a softmax probability value.","['G06N3/0454', 'G06N3/10', 'G06N3/063', 'G06N3/045', 'G06N3/047', 'G06N20/00', 'G06N3/04', 'G06N3/048', 'G06N7/005', 'G06N7/01']"
US10552944B2,Image upscaling with controllable noise reduction using a neural network,Systems and techniques for converting a low resolution image to a high resolution image include receiving a low resolution image having one or more noise artifacts at a neural network. A noise reduction level is received at the neural network. The neural network determines a network parameter based on the noise reduction level. The neural network converts the low resolution image to a high resolution image and removes one or more of the noise artifacts from the low resolution image during the converting by the using the network parameter. The neural network outputs the high resolution image.,"['G06T3/4046', 'G06F18/2413', 'G06F18/40', 'G06K9/6253', 'G06N3/045', 'G06N3/084', 'G06T3/4076', 'G06T5/002', 'G06T5/60', 'G06T5/70', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06F3/0482', 'G06T2200/24', 'G06T2207/20081', 'G06T2207/20084']"
US11681913B2,Method and system with neural network model updating,"A method of updating a neural network model by a terminal device, includes training a local model using a local data set collected by a terminal device to generate a trained local model; receiving, from a server, an independent identically distributed (i.i.d.) global data set, the i.i.d. global data set being a data set sampled for each class in a plurality of predefined classes; implementing the trained local model by inputting the i.i.d. global data set and transmitting final inference results of the implemented trained local model to the server; and receiving, from the server, a global model updated based on the final inference results of the inference.","['G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N5/04']"
US11645537B2,"Neural network training method, neural network training apparatus and electronic device","Disclosed are a neural network training method, a neural network training device and an electronic device. The neural network training method includes: training a first neural network to be trained by using sample data; determining an indicator parameter of the first neural network in a current training process; determining an update manner corresponding to a preset condition if the indicator parameter meets the preset condition; and updating a parameter of a batch normalization layer in the first neural network based on the update manner. In this way, sparsing of a feature map output by a neural network is implemented, thereby reducing an amount of data to be transmitted and improving computation speed of a chip.","['G06N3/084', 'G06N20/20', 'G06N3/045']"
CN106203624B,Vector quantization system and method based on deep neural network,"The present invention proposes a kind of Vector Quantization and method based on deep neural network, comprising: initial data is normalized normalization preprocessing module by normalization data, the preprocessed data after output normalization；Vector quantization coding module carries out vector quantization coding, outputting encoded data to the preprocessed data to receive preprocessed data and code book, and by code book；Neural network inverse quantization module is decoded inverse quantization to coded data by deep neural network, exports decoding data；Renormalization post-processing module carries out anti-normalization processing to decoding data by normalization data, the reduction initial data after exporting renormalization；And neural metwork training module carries out the training of neural network, exports deep neural network into neural network inverse quantization module by normalizing pretreated pretreatment training data and coding training data.The present invention can effectively solve the larger problem of quantization error of high-dimensional signal phasor quantization.","['G06N3/084', 'G06N3/088']"
TWI847965B,Image compression for digital reality,"A method of displaying images forming part of a digital reality stream, the method including, for each image to be displayed in one or more encoder processing devices, generating compressed image data by differentially compressing image data indicative of the image in accordance with system operation and the content of the digital reality stream so that different parts of the image are compressed using a different degree of compression, wirelessly transmitting the compressed image data to a display device using a wireless communications link, and, in one or more decoder processing devices associated with the display device, differentially decompressing the compressed image data to thereby generate image data indicative of the image to be displayed.","['H04N21/43637', 'H04N19/597', 'G02B27/0093', 'G02B27/017', 'G02B27/0172', 'G06F1/163', 'G06F3/011', 'G06F3/012', 'G06F3/013', 'G06F3/015', 'G06T9/20', 'H04N13/332', 'H04N13/344', 'H04N19/146', 'H04N19/162', 'H04N19/167', 'H04N19/176', 'H04N19/48', 'H04N21/234345', 'H04N21/816', 'G02B2027/0112', 'G02B2027/0123', 'G02B2027/0138', 'G06F2203/011', 'G06T19/006', 'H04N19/127']"
US11615297B2,Structured weight based sparsity in an artificial neural network compiler,"A novel and useful system and method of improved power performance and lowered memory requirements for an artificial neural network based on packing memory utilizing several structured sparsity mechanisms. The invention applies to neural network (NN) processing engines adapted to implement mechanisms to search for structured sparsity in weights and activations, resulting in a considerably reduced memory usage. The sparsity guided training mechanism synthesizes and generates structured sparsity weights. A compiler mechanism within a software development kit (SDK), manipulates structured weight domain sparsity to generate a sparse set of static weights for the NN. The structured sparsity static weights are loaded into the NN after compilation and utilized by both the structured weight domain sparsity mechanism and the structured activation domain sparsity mechanism. The application of structured sparsity lowers the span of search options and creates a relatively loose coupling between the data and control planes.","['G06F8/4434', 'G06N3/063', 'G06F8/41', 'G06N3/04', 'G06N3/084', 'G06F17/16', 'G06N3/048', 'G06N3/08', 'G06N3/082']"
US11138494B2,Storage controller acceleration for neural network training and inference,"A storage controller of a machine receives training data associated with a neural network model. The neural network model includes a plurality of layers, and the machine further including at least one graphics processing unit. The storage controller trains at least one layer of the plurality of layers of the neural network model using the training data to generate processed training data. A size of the processed data is less than a size of the training data. Training of the at least one layer includes adjusting one or more weights of the at least one layer using the training data. The storage controller sends the processed training data to at least one graphics processing unit of the machine. The at least one graphics processing unit is configured to store the processed training data and train one or more remaining layers of the plurality of layers using the processed training data.","['G06N3/063', 'G06N3/04', 'G06N3/084']"
US11551028B2,Structured weight based sparsity in an artificial neural network,"A novel and useful system and method of improved power performance and lowered memory requirements for an artificial neural network based on packing memory utilizing several structured sparsity mechanisms. The invention applies to neural network (NN) processing engines adapted to implement mechanisms to search for structured sparsity in weights and activations, resulting in a considerably reduced memory usage. The sparsity guided training mechanism synthesizes and generates structured sparsity weights. A compiler mechanism within a software development kit (SDK), manipulates structured weight domain sparsity to generate a sparse set of static weights for the NN. The structured sparsity static weights are loaded into the NN after compilation and utilized by both the structured weight domain sparsity mechanism and the structured activation domain sparsity mechanism. The application of structured sparsity lowers the span of search options and creates a relatively loose coupling between the data and control planes.","['G06N3/084', 'G06K9/6244', 'G06F18/21345', 'G06F18/231', 'G06F18/285', 'G06F9/3001', 'G06F9/30069', 'G06K9/6219', 'G06K9/6227', 'G06N20/10', 'G06N3/045', 'G06N3/063', 'G06N5/046', 'G06V10/7715', 'G06V10/82', 'G06V10/87', 'G06N3/082']"
US11696079B2,Hearing device comprising a recurrent neural network and a method of processing an audio signal,"A hearing device, e.g. a hearing aid or a headset, configured to be worn by a comprises an input unit for providing at least one electric input signal in a time-frequency representation; and a signal processor comprising a target signal estimator for providing an estimate of the target signal; a noise estimator for providing an estimate of the noise; and a gain estimator for providing respective gain values in dependence of said target signal estimate and said noise estimate. The gain estimator comprises a trained neural network, wherein the outputs of the neural network comprise real or complex valued gains, or separate real valued gains and real valued phases. The signal processor is configured—at a given time instance t—to calculate changes Δx(i,t)=x(i,t)−{circumflex over (x)}(i,t−1), and Δh(j,t−1)=h(j,t−1)−ĥ(j,t−2) to an input vector x(t) and to the hidden state vector h(t−1), respectively, from one time instance, t−1, to the next, t, and where {circumflex over (x)}(i,t−1) and ĥ(j,t−2) are estimated values of x(i,t−1) and h(j,t−2), respectively, where indices i, j refers to the ith input neuron and the jth neuron of the hidden state, respectively, where 1≤i≤Nch,x and 1≤j≤Nch,oh, wherein Nch,x and Nch,oh is the number of processing channels of the input vector x and the hidden state vector h, respectively, and wherein the signal processor is further configured to provide that the number of updated channels among said Nch,x and said Nch,oh processing channels of the modified gated recurrent unit for said input vector x(t) and said hidden state vector h(t−1), respectively, at said given time instance t is limited to a number of peak values Np,x, and Np,oh, respectively, where Np,x is smaller than Nch,x, and Np,oh, is smaller than Nch,oh.","['H04R25/453', 'H04R25/407', 'G06N3/044', 'G10L21/0208', 'H04R25/405', 'H04R25/507', 'G06N3/084', 'G10L2021/02082', 'G10L25/30', 'H04R2201/107', 'H04R2225/43', 'H04R2430/03', 'H04R2460/01', 'H04R2460/03', 'H04R25/554']"
CN109841226B,Single-channel real-time noise reduction method based on convolution recurrent neural network,"The disclosure discloses a single-channel real-time noise reduction method and device based on a convolution recurrent neural network, electronic equipment and a storage medium, and belongs to the technical field of computers. The method comprises the following steps: extracting acoustic features from received single-channel sound signals, carrying out iterative operation on the acoustic features in a pre-trained convolution recurrent neural network model, calculating a ratio film of the acoustic features, masking the acoustic features by adopting the ratio film, and synthesizing the masked acoustic features and the phase of the single-channel sound signals to obtain voice signals. The single-channel real-time noise reduction method and device based on the convolution recurrent neural network can reduce the number of parameters of the neural network, reduce the data storage capacity and the requirements on the system data bandwidth, and greatly improve the real-time performance of single-channel voice noise reduction while realizing good noise reduction performance.","['G10L21/0208', 'G10L25/30']"
US20210012537A1,Loop filter apparatus and image decoding apparatus,"Embodiments of this disclosure provide an apparatus to perform a loop filter function using a convolutional neural network (CNN) and an apparatus to perform image decoding. to perform the loop filter, the apparatus is to perform down sampling on a frame of an input reconstructed image to obtain first feature maps of N channels; perform residual learning on input first feature maps of N channels among the first feature maps to obtain second feature maps of N channels; and perform up sampling on input second feature maps of N channels among the second feature maps to obtain an image of original size of the reconstructed image. Functions of the loop filter are carried out by using CNN, which may reduce a difference between a reconstructed frame and an original frame, reduce an amount of computation, and save processing time of the CNN.","['G06T9/002', 'H04N19/82', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'H04N19/00', 'H04N19/117', 'H04N19/124', 'H04N19/132', 'H04N19/136', 'H04N19/159', 'H04N19/176', 'H04N19/44', 'H04N19/59', 'H04N19/60', 'H04N19/80', 'H04N19/86']"
CN111709489B,Citrus identification method based on improved YOLOv4,"The invention discloses a citrus identification method based on improved YOLOv4, which is characterized in that an upsampling module and a detection characteristic diagram sensitive to a small target are added by improving a YOLOv4 network model structure, citrus with smaller individuals can be better identified, the defects of large memory consumption, long identification time and the like caused by adding the module are overcome by performing sparse training, channel pruning and layer pruning on a trained network model, and a user obtains anchor frame parameter values more suitable for own data sets by clustering with a Canopy algorithm and a k-means + + algorithm. When the citrus is identified, the citrus data set is trained by adopting an improved YOLOv4 network structure, and the obtained model can accurately identify a smaller target of an individual; before the network model is trained, the depth and the width of the model are compressed by combining layer pruning and channel pruning, and the training speed is improved on the premise of not losing precision; the method has the advantages that the citrus on the trees in different periods is identified, the identification precision is high, the speed is high, and the requirement of real-time identification can be met.","['G06F18/23213', 'G06F18/24137', 'G06N3/045', 'G06N3/08']"
US11978548B2,Apparatus and method for processing medical image using predicted metadata,"The present disclosure relates to a medical image analysis method using a processor and a memory which are hardware. The method includes generating predicted second metadata for a medical image by using a prediction model, and determining a processing method of the medical image based on one of first metadata stored corresponding to the medical image and the second metadata.","['G16H30/20', 'A61B5/0013', 'A61B5/055', 'A61B6/032', 'A61B8/00', 'G06F18/214', 'G06N20/00', 'G06T7/0012', 'G06T7/70', 'G06V10/70', 'G06V10/75', 'G06V10/82', 'G06V30/166', 'G16H30/00', 'G16H30/40', 'G16H50/70', 'A61B2576/00', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004', 'G06T2207/30096', 'G06V2201/10']"
US11212076B2,Distributed platform for computation and trusted validation,"An example operation may include one or more of generating a data frame storing content of a simulation, compressing the simulation content within the data frame based on previous simulation content stored in another data frame to generate a compressed data frame, and transmitting the compressed data frame via a blockchain request to one or more endorsing peer nodes of a blockchain network for inclusion of the compressed data frame within a hash-linked chain of blocks of the blockchain network.","['H04L9/3239', 'H04L9/0643', 'G06F16/1805', 'G06F16/27', 'H04L63/123', 'H04L9/50', 'H04W72/0446', 'H04L2209/38']"
US12050845B2,Estimating physical parameters of a physical system based on a spatial-temporal emulator,"Apparatuses, methods, and systems for generating simulations of physical variables of a physical system are disclosed. A method includes fusing, by the one or more computing devices, the observation data and the numeric simulation data, including training a spatial-temporal emulator model for a physical numerical model using the observation data, the numeric simulation data, and the domain interpretable data. The method further includes estimating one or more physical parameters based on the trained spatial-temporal emulator model, compressing the trained spatial-temporal emulator model, including generating candidate mutations of an architecture of the trained spatial-temporal emulator model, evaluating a performance of each of the candidate mutations of the architecture on validation data using metrics, retaining a subset of candidate mutations exhibiting best performance on the metrics, iterating until convergence to a desired reduction in size, and deploying the compressed trained spatial-temporal emulator model to one or more edge devices.","['G06F30/20', 'G06F30/27', 'G06N20/00', 'G06N3/084', 'G06F2111/10', 'G06N3/045', 'G06N3/047']"
US12143578B2,Neural network based filter in video coding,"In one implementation, to perform in-loop filtering of a version of reconstructed samples of a block, only a single offset parameter is signaled in the bitstream. Based on the version of reconstructed samples, a pixel-wise weight mask is generated using a neural network. Because the neural network parameters are known at both the encoder and decoder, these parameters need not to be signaled in the bitstream. The single offset parameter scaled by the weighted mask is used to adjust the samples in the block. Thus, even though only a single offset parameter is used, the samples are adjusted by pixel-wise offsets. The neural network may also take other parameters, such as quantization parameters and picture types as input. Further, there can be multiple neural networks that generate different weight masks, where different offsets are signaled and one or more of the neural networks are to be selected for filtering.","['H04N19/117', 'G06N3/045', 'G06N3/08', 'H04N19/132', 'H04N19/147', 'H04N19/154', 'H04N19/172', 'H04N19/42', 'H04N19/61', 'H04N19/82', 'H04N19/85', 'H04N19/86', 'G06N3/048']"
CN108629224B,Information demonstrating method and device,"This application discloses information demonstrating methods and device.One specific embodiment of this method includes: the key frame detected in target video, wherein key frame is the frame that image entropy is greater than preset image entropy threshold in target video；In response to detecting key frame, the image of target item is detected from key frame；In response to detecting the image of target item from key frame, determine whether the number that the frame of image of target item is continuously presented after key frame is greater than scheduled frame number；If more than scheduled frame number, then the information to be presented with the images match of target item is obtained, and information to be presented is presented in the frame of image that target item is continuously presented.Information to be presented can be pointedly presented in the embodiment to the target item in target video, improve the accuracy rate of information push.","['G06V20/46', 'G06N3/0464', 'G06F18/214', 'G06F18/24155', 'G06N3/08', 'H04N21/2668', 'H04N21/431']"
US11107210B2,Image data generating apparatus generating image data for inspecting external appearance of product,"In an image data generating apparatus, an image processor acquires target output image data converted from target input image data by a pre-trained model. The target input image data represents a captured image of a target product. The target output image data represents an image of a target product free from defects. The pre-trained model performs data compression and data decompression on inputted image data. The image processor generates first data by performing a first generation process on the target input image data. The first generation process includes a luminosity adjustment process adjusting luminosity in image data. The image processor generates second data by performing a second generation process including the luminosity adjustment process on the target output image data. The image processor generates inspection image data by using a difference between the first data and the second data for inspecting an external appearance of the target product.","['G06T5/92', 'G06T5/002', 'G06T5/009', 'G06T5/40', 'G06T5/50', 'G06T5/70', 'G06T7/001', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30124', 'G06T2207/30144']"
US12155849B2,Method and system for image compressing and coding with deep learning,"An image processing system (100) and methods therein for compressing and coding an image and for optimizing its parameters are disclosed. The embodiments herein provide an improved system and simplified method with deterministic uniform quantization with integer levels based on Softmax function for image compression and coding. The embodiments herein produce exact discrete probability mass function for latent variables to be coded from side information. The embodiments herein enable training of the image processing system to minimize the bit rate through backpropagation at the same time. Moreover, the embodiments herein create the possibility to encode region of interest (ROI) areas during coding.","['H04N19/42', 'G06N3/045', 'G06N3/084', 'H04N19/124', 'H04N19/13', 'H04N19/147', 'H04N19/167', 'H04N19/182', 'H04N19/1883', 'H04N19/80', 'H04N19/86', 'H04N19/91']"
US12279092B2,Interactive system for hearing devices,"In an audio signal, one or more processing circuits recognize spoken content in a user's own speech signal using speech recognition and natural language understanding. The spoken content describes a listening difficulty of the user. The one or more processing circuits generate, based on the spoken content, one or more actions for hearing devices and feedback for the user. The one or more actions attempt to resolve the listening difficulty. Additionally, the one or more processing circuits convert the user feedback to verbal feedback using speech synthesis and transmit the one or more actions and the verbal feedback to the hearing devices via a body-worn device. The hearing devices are configured to perform the one or more actions and play back the verbal feedback to the user.","['H04R25/505', 'G06F3/165', 'G10L15/063', 'H04R25/407', 'H04R25/70', 'G10L2015/225', 'H04R2225/39', 'H04R2225/41', 'H04R2225/43', 'H04R2225/55', 'H04R25/30', 'H04R25/552', 'H04R25/554']"
US20230329646A1,Classifying biomedical acoustics based on image representation,"A method in an illustrative embodiment comprises obtaining an acoustic signal for a given individual, generating an image representation of at least a portion of the acoustic signal, processing the image representation in at least one neural network of an acoustics classifier to generate a classification for the acoustic signal, and executing at least one automated action based at least in part on the generated classification. The acoustic signal illustratively comprises, for example, at least one of a heart sound signal, a blood flow sound signal, a lung sound signal, a bowel sound signal, a cough sound signal, or other physiological sound signal of the given individual. Generating the image representation illustratively comprises generating at least one spectrogram. Additionally or alternatively, generating the image representation may comprise generating one or more recurrence plots, Markov transition field image representations and/or Gramian angular field image representations.","['G10L25/66', 'A61B5/7267', 'A61B7/00', 'A61B7/003', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'G10L21/0232', 'G10L25/30', 'G16H70/60']"
CN108629306B,"Human body posture recognition method and device, electronic equipment and storage medium","The disclosure provides a human body posture recognition method and device, electronic equipment and a computer readable storage medium, and belongs to the technical field of computer vision. The method comprises the following steps: acquiring an original image containing a human body posture; detecting human body key points in the original image, and connecting the human body key points to obtain limb identification; preprocessing an original image containing the limb identification, and highlighting the limb identification to obtain an input image; and processing the input image through a depth separable convolutional neural network model to obtain a classification result of the human body posture. The method and the device can reduce the calculation amount in the human body posture identification process, and save system hardware resources and processing time.","['G06V40/103', 'G06F18/214', 'G06F18/241', 'G06N3/045']"
CN106845547B,A kind of intelligent automobile positioning and road markings identifying system and method based on camera,"The invention discloses a kind of, and the intelligent automobile based on camera positions and road markings identifying system, including image capture module, fpga core control coding module and data processing module, described image acquisition module controls coding module with fpga core, and fpga core control coding module is connected with data processing module；Described image acquisition module is for being acquired vehicle periphery image information；The information that fpga core control coding module is used to acquire image capture module carries out lossless compression, and by compressed transmission of video to data processing module；Data processing module is split video to form picture frame, is extracted to the target area in picture frame, and vehicle, pedestrian and road markings information are identified respectively；According to the physical characteristic of target, judge target at a distance from this vehicle.Present system is compact-sized, is suitable for various types of vehicles, can be according to the further deep development of corresponding video information, and scalability is strong.","['G06V20/588', 'G06F18/214', 'G06F18/24', 'G06V20/582', 'G06V20/584', 'H04N7/18', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'G06T2207/30256', 'G06V2201/09']"
US20220335304A1,System and Method for Automated Design Space Determination for Deep Neural Networks,"There is provided a system and method of automated design space determination for deep neural networks. The method includes obtaining a teacher model and one or more constraints associated with an application and/or target device or process used in the application configured to utilize a deep neural network; learning an optimal architecture using the teacher model, constraints, a training data set, and a validation data set; and deploying the optimal architecture on the target device or process for use in the application.","['G06N3/088', 'G06F18/2115', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/006', 'G06N3/063']"
US20230325960A1,Neural network tracing arrangements,"A sequence of images depicting an object is captured, e.g., by a camera at a point-of-sale terminal in a retail store. The object is identified, such as by a barcode or watermark that is detected from one or more of the images. Once the object's identity is known, such information is used in training a classifier (e.g., a machine learning system) to recognize the object from others of the captured images, including images that may be degraded by blur, inferior lighting, etc. In another arrangement, such degraded images are processed to identify feature points useful in fingerprint-based identification of the object. Feature points extracted from such degraded imagery aid in fingerprint-based recognition of objects under real life circumstances, as contrasted with feature points extracted from pristine imagery (e.g., digital files containing label artwork for such objects). A great variety of other features and arrangements—some involving designing classifiers so as to combat classifier copying—are also detailed.","['G06T1/0021', 'G06F18/214', 'G06F18/2155', 'G06F18/2413', 'G06F21/16', 'G06V10/245', 'G06V10/774', 'G06V10/7753', 'G06V20/20']"
US20250086968A1,System and method of feature detection in satellite images using neural networks,"The present invention generally relates to systems and methods of classification and localization of features of interest in remote aerial images. It relates particularly to a system and method of classifying and localizing features of interest on satellite images by semantic segmentation using a trained deep learning convolutional neural network. Increasing the accuracy of classification and localization requires that the neural network to decipher the difference between the feature of interest and other features in the background. This invention addresses the problem of low accuracy in classifying and localizing pixels corresponding to the feature of interest by enabling the user to include more information together with the original pixel values in the satellite images. An exemplary embodiment of this invention is a system and method of locating mango trees in a plantation in Bataan province, Philippines using a U-net convolutional network.","['G06V20/188', 'G06F18/217', 'G06F18/24133', 'G06V10/82']"
CN112613532B,Moving target tracking method based on radar and cyclic neural network complement infrared fusion,"The invention discloses a moving target tracking method based on radar and cyclic neural network complement infrared fusion. The scheme is as follows: preprocessing radar data of the same target and multiple tracks with different motion states; training the constructed first and second cyclic neural network models respectively by utilizing the preprocessed data, determining the fitting relation between the attribute of radar data and time and the regression relation between the attribute of the radar data respectively, testing a new cyclic neural network formed by cascading the two trained cyclic neural network models, supplementing the distance information of the infrared data by using the network when the accuracy of the test meets the requirement, fusing the three information of the distance, azimuth angle and pitch angle of the infrared data and the radar data after the completion, and performing interactive extended Kalman filtering processing to finish the tracking of the target. The invention avoids the defect that infrared data lacks distance information, improves the accuracy of target tracking, and can be used for air defense, navigation and traffic control.","['G06F18/214', 'G01S13/66', 'G01S13/86', 'G06N3/045', 'G06N3/084']"
US11416742B2,Audio signal encoding method and apparatus and audio signal decoding method and apparatus using psychoacoustic-based weighted error function,"Provided is a training method of a neural network that is applied to an audio signal encoding method using an audio signal encoding apparatus, the training method including generating a masking threshold of a first audio signal before training is performed, calculating a weight matrix to be applied to a frequency component of the first audio signal based on the masking threshold, generating a weighted error function obtained by correcting a preset error function using the weight matrix, and generating a second audio signal by applying a parameter learned using the weighted error function to the first audio signal.","['G06N3/08', 'G10L19/032', 'G06N3/045', 'G06N3/082', 'G06N3/088', 'G10L19/008', 'G10L25/30', 'G10L25/69']"
US10228911B2,Apparatus employing user-specified binary point fixed point arithmetic,An apparatus includes a plurality of arithmetic logic units each having an accumulator and an integer arithmetic unit that receives and performs integer arithmetic operations on integer inputs and accumulates integer results of a series of the integer arithmetic operations into the accumulator as an integer accumulated value. A register is programmable with an indication of a number of fractional bits of the integer accumulated values and an indication of a number of fractional bits of integer outputs. A first bit width of the accumulator is greater than twice a second bit width of the integer outputs. A plurality of adjustment units scale and saturate the first bit width integer accumulated values to generate the second bit width integer outputs based on the indications of the number of fractional bits of the integer accumulated values and outputs programmed into the register.,"['G06F7/49947', 'G06F5/01', 'G06F7/49942', 'G06F7/5443', 'G06F7/57', 'G06F9/30014', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06F9/00']"
WO2022101515A1,Method for an explainable autoencoder and an explainable generative adversarial network,"An exemplary embodiment provides an autoencoder which is explainable. An exemplary explainable autoencoder may explain the degree to which each feature of the input attributed to the output of the system, which may be a compressed data representation. An exemplary embodiment may be used for classification, such as anomaly detection, as well as other scenarios where an explainable autoencoder is used as input to another machine learning system or when an explainable autoencoder is a component in an end-to-end deep learning architecture. An exemplary embodiment provides an explainable generative adversarial network that adds explainable generation, simulation and discrimination capabilities. The underlying architecture of an exemplary embodiment may be based on an explainable or interpretable neural network, allowing the underlying architecture to be a fully explainable white-box machine learning system.","['G06N3/08', 'G06N3/045', 'G06N3/047', 'G06N5/022', 'G06N5/045']"
US20210304854A1,Artificial intelligence engine architecture for generating candidate drugs,"A method is disclosed for using an artificial intelligence engine to generate candidate drug compounds, wherein the method comprises: generating candidate drug compounds comprising sequences via a creator module of the artificial intelligence engine. The method includes generating, via a descriptor module, a respective description for each of the candidate drug compounds at nodes in a knowledge graph, wherein the knowledge graph comprises a multi-dimensional representation of the candidate drug compounds and the respective description comprises drug compound structural information, drug compound activity information, and drug compound semantic information. The method includes determining a shape of the multi-dimensional representation of the candidate drug compounds; determining, based on the shape, a slice configured to be obtained from the representation; determining, using a decoder, which dimensions are included in the slice; and based on the dimensions, determining an effectiveness of a biomedical feature of the slice.","['G16C20/70', 'G06N20/00', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G16C20/50', 'G16C60/00']"
US12151516B2,System and method for feature extraction from real-time vehicle kinetics data for remote tire wear modeling,"A system and method are provided for efficiently estimating vehicle tire wear. Vehicle kinetics (first) data are provided via one or more sensors associated with the vehicle and/or at least one associated tire. The vehicle kinetics data are locally processed to compress or otherwise generate second data as a reduced subset thereof, said second data representative of the first data and comprising any one or more predetermined wear-specific features extracted therefrom. The second data are selectively transmitted via a communications network to a remote computing system, which processes the second data to estimate a wear characteristic for the at least one tire. Alternatively, the second data processed to generate third data as a reconstruction of the first data, and the third data and the any one or more extracted features are processed to estimate a wear characteristic for the at least one tire.","['B60W30/146', 'G06F30/15', 'B60C11/243', 'B60C11/246', 'B60C23/0479', 'B60C23/0486', 'B60C23/062', 'B60C99/006', 'B60T7/12', 'B60T8/171', 'B60W30/162', 'B60W40/064', 'B60W40/12', 'B60W50/14', 'G01M17/02', 'G06F17/142', 'G06F30/20', 'G06N3/045', 'G06N3/084', 'G06N7/01', 'G06Q10/20', 'G07C5/006', 'G07C5/008', 'G07C5/0808', 'G08G1/22', 'H04L12/40', 'H04L12/40013', 'H04W4/44', 'B60C2019/004', 'B60C23/0408', 'B60C23/0415', 'B60T2201/03', 'B60T2210/30', 'B60T2240/02', 'B60T2240/03', 'B60W2040/1392', 'B60W2050/146', 'B60W2420/905', 'B60W2520/105', 'B60W2520/125', 'B60W2530/20', 'B60W2555/00', 'B60W2556/10', 'B60W2556/45', 'B60W2756/10', 'B60W30/18172', 'G07C5/0841', 'H04L2012/40215', 'H04L2012/40273']"
US20230308465A1,System and method for dnn-based cyber-security using federated learning-based generative adversarial network,"The system comprises a FL-based generative adversarial network (GAN) for generating adversarial examples, wherein the GAN includes a generator for generating the adversarial examples and a discriminator for distinguishing the adversarial examples from the original data, wherein the FL network includes multiple clients, each having a local dataset and a local DNN model, and a central server for coordinating the training process; a DNN for classifying data, where the DNN is trained using the generated adversarial examples, wherein the training process includes exchanging the model updates between the client’s server and the central server; an evaluation module for measuring the adversarial accuracy and adversarial robustness of the DNN using appropriate metrics, including the adversarial accuracy, the adversarial loss, and the robustness to perturbations; and an adjustment module for adjusting the architecture or parameters of the DNN based on the evaluation results to improve its adversarial robustness.","['H04L63/1425', 'H04L63/205']"
US11120582B2,"Unified dual-domain network for medical image formation, recovery, and analysis",An apparatus and method for coupled medical image formation and medical image signal recovery using a dual domain network is disclosed. The dual-domain network includes a first deep neural network (DNN) to perform signal recovery in a sensor signal domain and a second DNN to perform signal recovery in an image domain. A sensor signal is acquired by a sensor of a medical imaging device. A refined sensor signal is generated from the received sensor signal using the first DNN. A first reconstructed medical image is generated from the received sensor signal. A second reconstructed medical image is generated from the refined sensor signal generated by the first DNN. An enhanced medical image is generated based on the both the first reconstructed medical image and the second reconstructed medical image using the second DNN. The enhanced medical image generated by the second DNN is displayed.,"['G06N3/084', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06T11/006', 'G06T3/4007', 'G06T5/001', 'G06N3/048', 'G06T2210/41', 'G06T2211/441']"
US20230412360A1,Distributed platform for computation and trusted validation,"An example operation may include one or more of obtaining data of a simulation, identifying checkpoints within the simulation data, generating a plurality of sequential data structures based on the identified checkpoints, where each data structure identifies an evolving state of the simulation with respect to a previous data structure among the sequential data structures, and transmitting the generated sequential data structures to nodes of a blockchain network for inclusion in one or more data blocks within a hash-linked chain of data blocks.","['G06F21/64', 'H04L9/0637', 'G06F21/57', 'G06F30/20', 'H04L41/145', 'H04L63/12', 'H04L67/104', 'H04L9/0643', 'H04L9/3236', 'G06N20/00', 'H04L9/50']"
US10810725B1,Automated detection of tampered images,A content analyzer determines whether various types of modification have been made to images. The content analyzer computes JPEG ghosts from the images that are concatenated with the image channels to generate a feature vector. The feature vector is provided as input to a neural network that determines whether the types of modification have been made to the image. The neural network may include a constrained convolution layer and several unconstrained convolution layers. An image fake model may also be applied to determine whether the image was generated using a computer model or algorithm.,"['G06T1/0028', 'G06F18/2148', 'G06F21/64', 'G06K9/46', 'G06K9/6257', 'G06N3/045', 'G06N3/084', 'G06T7/0002', 'G06T9/002', 'G06V10/764', 'G06V10/7747', 'G06V10/82', 'G06K2209/27', 'G06N20/10', 'G06N5/01', 'G06T2201/0053', 'G06T2201/0201', 'G06T2207/20084', 'G06T2207/30196', 'G06V2201/10']"
US20250031336A1,Data processing systems including optical communication modules,"A system includes a housing and a first circuit board positioned inside the housing. The housing has a top panel, a bottom panel, a left side panel, a right side panel, a front panel, and a rear panel. The front panel is at an angle relative to the bottom panel in which the angle is in a range from 30 to 150°. The first circuit board has a length, a width, and a thickness, in which the length is at least twice the thickness, the width is at least twice the thickness, and the first circuit board has a first surface defined by the length and the width. The first surface of the first circuit board is at a first angle relative to the bottom panel in which the first angle is in a range from 30 to 150°. The first surface of the first circuit board is substantially parallel to the front panel or at a second angle relative to the front panel in which the second angle is less than 60°. The system includes a first data processing module and a first optical interconnect module both electrically coupled to the first circuit board. The optical interconnect module is configured to receive first optical signals from a first optical link, convert the first optical signals to first electrical signals, and transmit the first electrical signals to the first data processing module.","['G02B6/428', 'H05K7/1487', 'G02B6/4206', 'G02B6/4278', 'G02B6/43', 'H04B10/27', 'H04B10/801', 'H05K1/141', 'G02B6/4216', 'G02B6/4249', 'Y02T10/70', 'Y02T10/7072']"
US11100643B2,Training strategy search using reinforcement learning,"In at least one embodiment, a reinforcement-learning-based searching approach is used to produce a training configuration for a machine-learning model. In at least one embodiment, 3D medical image segmentation is performed using learned image preprocessing parameters.","['G06N3/006', 'G06N3/08', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06T5/002', 'G06T5/70', 'G06T7/0012', 'G06T7/10']"
CN113269299B,Robot Control Using Deep Learning,"The invention discloses a robot control using deep learning, and particularly discloses a device, a system and a technology for performing complex multi-step tasks by using a neural network under the condition that a robot is not trained so as to promote the robot to perform. In at least one embodiment, a hierarchical model is trained to infer a logical state from a world state and to determine an executable action of a robot based on the logical state.","['G05B13/027', 'B60W60/001', 'G05D1/0088', 'G05D1/0221', 'G05D1/0246', 'G06N3/045', 'G06N3/0464', 'G06N3/049', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G06N5/04', 'B25J9/161']"
CN113467745B,Improving media engagement through deep learning,"The invention discloses a device, a system and a technology for improving media participation through deep learning, in particular to a device, a system and a technology for adjusting playback speed and volume based on environmental factors and other factors by using a neural network to promote understanding of media content. In at least one embodiment, playback of media content is slowed or accelerated if audio associated with the media content is difficult to understand based on background noise, accents, material difficulty, and other factors that reduce the understandability of the media content.","['G06F3/165', 'G06F40/30', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N3/09', 'G10L15/26', 'G10L21/0208', 'G10L25/30', 'G06F40/216', 'G10L15/16', 'G10L21/04', 'H03G3/3005', 'H03G3/3089', 'H03G3/32', 'H04R2430/01', 'H04R2499/13']"
CN118312922B,Multi-mode network content security intelligent auditing system and method thereof,"The invention provides a multimode network content security intelligent auditing system and a method thereof, belonging to the network content security field, wherein the system comprises: the data access and preprocessing module is used for receiving the multi-mode network content data from different sources and preprocessing the multi-mode network content data; the multi-mode analysis module is used for extracting the characteristics of different modes of content from the multi-mode network content data; the strategy management module is used for configuring and managing auditing strategies of different-mode contents; the auditing engine module is used for comprehensively utilizing the rule engine and the machine learning model and auditing the multi-mode network content data according to the characteristics of different-mode content and auditing strategies; the auditing result disposal module is used for outputting and storing auditing results and triggering corresponding manual auditing or automatic disposal flow according to the auditing results. The invention comprehensively utilizes a plurality of artificial intelligence technologies to comprehensively audit texts, pictures, videos and audios, thereby greatly improving the content security management and control capability.","['G06F18/253', 'G06F18/213', 'G06F18/214', 'G06F18/241', 'G06F18/256', 'G06F18/259', 'G06N3/042', 'G06N3/045', 'G06N3/0495', 'G06N3/092', 'G06N3/094', 'G06N3/096', 'G06N3/0985', 'G06N5/022', 'G06N5/045']"
US11592791B1,Systems and methods for flight control system using simulator data,"A system for flight control system using simulator data for an electric aircraft is presented. The system includes a computing device, the computing device configured to receive a plurality of measured flight data, simulate a plurality of aircraft performance model outputs as a function of a flight simulator and the plurality of measured flight data, determine a moment datum as a function of the plurality of measured flight data and the plurality of aircraft performance model outputs, generate an allocation command datum as a function of the moment datum and the plurality of aircraft performance model outputs, and perform a torque allocation on a flight component of a plurality of flight components as a function of the allocation command and the moment datum.","['G05D1/0072', 'G05B13/04', 'G05B13/041', 'G05B13/042', 'G05D1/0088', 'G05D1/0825', 'G05D3/1454', 'G06F18/214', 'G06N20/00', 'G08G5/21', 'G08G5/26', 'G08G5/30', 'G08G5/53', 'G08G5/55', 'G08G5/76']"
CN112052783B,High-resolution image weak supervision building extraction method combining pixel semantic association and boundary attention,"The invention provides a high-resolution image weak supervision building extraction method combining pixel semantic association and boundary attention, which comprises training data preparation, deep feature extraction, boundary feature fusion, pixel semantic association degree learning, loss function calculation and building pseudo-annotation generation; by designing the boundary attention module, the super-pixel prior information is combined with the boundary information extracted by the network, the boundary characteristics of the building are enhanced, semantic information among pixels is effectively propagated in an image by learning the semantic relevance among the pixels, and a pseudo tag with more complete and dense boundary and clearer boundary is generated. And meanwhile, the full convolution network model training is adopted in cooperation with the high-resolution remote sensing image, so that the automatic extraction of the building features is realized.","['G06V20/176', 'G06F18/214', 'G06N3/045', 'G06T3/4007', 'G06T7/194', 'G06V10/267', 'G06T2207/10032']"
US12394171B2,"Region recognition method, apparatus and device, and readable storage medium","This application discloses a region recognition method, apparatus, and device, and a readable storage medium, and relates to the field of artificial intelligence. The method includes: acquiring an input image, the input image including image content of a to-be-recognized region; acquiring a first rotation angle of the image content in the input image, the first rotation angle being estimated by using a recognition model; rotating a convolution kernel in the recognition model at the first rotation angle, and performing convolution processing on an image feature of the input image using the rotated convolution kernel to obtain a target feature; recognizing the target feature to obtain region data; and determining, in the input image by using the region data, a target region corresponding to the image content.","['G06V10/242', 'G06N3/045', 'G06N3/08', 'G06V10/20', 'G06V10/22', 'G06V10/25', 'G06V10/32', 'G06V10/82']"
US11347191B2,System and method to facilitate welding software as a service,"A weld production knowledge system for processing welding data collected from one of a plurality of welding systems, the weld production knowledge system comprising a communication interface communicatively coupled with a plurality of welding systems situated at one or more physical locations. The communication interface may be configured to receive, from one of said plurality of welding systems, welding data associated with a weld. The weld production knowledge system may comprise an analytics computing platform operatively coupled with the communication interface and a weld data store. The weld data store employs a dataset comprising (1) welding process data associated with said one or more physical locations, and/or (2) weld quality data associated with said one or more physical locations. The analytics computing platform may employ a weld production knowledge machine learning algorithm to analyze the welding data vis-à-vis the weld data store to identify a defect in said weld.","['G05B19/41875', 'B23K31/125', 'B23K9/0953', 'G05B13/0265', 'G05B23/0229', 'G05B23/024', 'G06N20/00', 'G06N5/04', 'G06N7/005', 'G06N7/01', 'G06Q10/06', 'H04L67/10', 'Y02P80/40', 'Y02P90/80']"
US12277640B2,Photorealistic real-time portrait animation,"Provided are systems and methods for portrait animation. An example method includes receiving, by a computing device, scenario data including information concerning movements of a first head, receiving, by the computing device, a target image including a second head and a background, determining, by the computing device and based on the target image and the information concerning the movements of the first head, two-dimensional (2D) deformations of the second head in the target image, applying, by the computing device, the 2D deformations to the target image to obtain at least one output frame of an output video, the at least one output frame including the second head displaced according to the movements of the first head, and filling, by the computing device and using a background prediction neural network, a portion of the background in gaps between the displaced second head and the background.","['G06T13/40', 'G06T11/001', 'G06T13/80', 'G06T3/02', 'G06T3/18', 'G06T7/174', 'G06T7/194', 'G06V40/167', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30201', 'G06T2210/44']"
US11386496B2,Generative network based probabilistic portfolio management,"A deep-learning neural network can be trained to model a probability distribution of the asset-price trends for a future time period using a training data set, which can include asset-price trends of a plurality of assets over a past time period and a latent vector sampled from a prior distribution associated with the asset-price trends of a plurality of assets. The training data set can represent a time series data. A portfolio optimization can be executed on the modeled probability distribution to estimate expected risks and returns for different portfolio diversification options.","['G06Q40/06', 'G06F16/904', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08']"
CN118709093B,Operation fault identification method and system of numerical control machine tool,"The invention relates to the technical field of data processing, and discloses an operation fault identification method and an operation fault identification system for a numerical control machine tool, which are used for improving the accuracy of the operation fault identification of the numerical control machine tool. The method comprises the steps of performing federal learning modeling and virtual environment verification on a characteristic data stream to obtain a machine tool normal operation digital twin model, performing data extraction on the machine tool normal operation digital twin model to obtain an operation data set, performing reinforcement learning on the operation data set to obtain a distributed fault mode library, performing edge calculation anomaly detection on the characteristic data stream to obtain preliminary fault diagnosis data with hierarchical collaboration, performing augmented reality auxiliary interactive validation on the preliminary fault diagnosis data with hierarchical collaboration to obtain validation data, performing fault matching on the validation data and a knowledge graph of the distributed fault mode library to obtain target fault data, and performing fault coping strategy analysis on the target fault data to obtain a target coping strategy corresponding to the target fault data.","['G06F18/2431', 'G05B19/406', 'G06F18/22', 'G06N3/092', 'G06N3/096', 'G06N3/098']"
US11210477B2,Systems and methods for transferring stylistic expression in machine translation of sequence data,"Embodiments of the present disclosure are directed to a system, methods, and computer-readable media for facilitating stylistic expression transfers in machine translation of source sequence data. Using integrated loss functions for style transfer along with content preservation and/or cross entropy, source sequence data is processed by an autoencoder trained to reduce loss values across the loss functions at each time step encoded for the source sequence data. The target sequence data generated by the autoencoder therefore exhibits reduced loss values for the integrated loss functions at each time step, thereby improving content preservation and providing for stylistic expression transfer.","['G06F40/58', 'G06F40/30', 'G06F40/44', 'G06F40/47']"
US20220296966A1,Cross-Platform and Connected Digital Fitness System,"A system and method for tracking physical activity of a user performing exercise movements and providing feedback and recommendations relating to performing the exercise movements is disclosed. The method includes receiving a stream of sensor data in association with a user performing an exercise movement over a period of time, processing the stream of sensor data, detecting, using a first classifier on the processed stream of sensor data, one or more poses of the user performing the exercise movement, determining, using a second classifier on the one or more detected poses, a classification of the exercise movement and one or more repetitions of the exercise movement, determining, using a third classifier on the one or more detected poses and the one or more repetitions of the exercise movement, feedback including a score for the one or more repetitions, the score indicating an adherence to predefined conditions for correctly performing the exercise movement, and presenting the feedback in real-time in association with the user performing the exercise movement.","['A63B24/0075', 'G16H20/30', 'A63B24/0062', 'G16H50/20', 'G16H50/30', 'G16H80/00', 'A63B2024/0065', 'A63B2024/0068', 'A63B2024/0071', 'A63B2220/806']"
US20220387748A1,System and method for inducing sleep by transplanting mental states,A method of replicating a mental state of a first subject in a second subject comprising: capturing a mental state of the first subject represented by brain activity patterns; and replicating the mental state of the first subject in the second subject by inducing the brain activity patterns in the second subject.,"['A61B5/7253', 'A61B5/055', 'A61B5/245', 'A61B5/369', 'A61B5/378', 'A61B5/38', 'A61B5/389', 'A61B5/4812', 'A61B5/486', 'A61M21/02', 'A61N1/36025', 'A61B5/291', 'A61B5/316', 'A61M2021/0016', 'A61M2021/0022', 'A61M2021/0027', 'A61M2021/0044', 'A61M2021/0055', 'A61M2021/0072', 'A61M2205/50', 'A61M2230/08', 'A61M2230/10', 'A61N1/0456', 'A61N1/36031', 'A61N2/006']"
WO2021222136A1,Model predictive control techniques for autonomous systems,"Apparatuses, systems, and techniques to infer a sequence of actions to perform using one or more neural networks trained, at least in part, by optimizing a probability distribution function using a cost function, wherein the probability distribution represents different sequences of actions that can be performed. In at least one embodiment, a model predictive control problem is formulated as a Bayesian inference task to infer a set of solutions.","['G06N3/084', 'G06N3/006', 'G05D1/0088', 'G06F17/18', 'G06F18/214', 'G06N3/047', 'G06N3/088', 'G06N5/04', 'G06N7/01', 'G06N3/045', 'G06N3/049', 'G06N3/063']"
US11833681B2,Robotic control system,"In at least one embodiment, under the control of a robotic control system, a gripper on a robot is positioned to grasp a 3-dimensional object. In at least one embodiment, the relative position of the object and the gripper is determined, at least in part, by using a camera mounted on the gripper.","['G06T7/73', 'B25J9/161', 'B25J9/1612', 'B25J9/163', 'B25J9/1669', 'G06N3/006', 'G06N3/045', 'G06N3/049', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T7/74', 'G05B2219/39543', 'G05B2219/40564', 'G06N3/044', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244']"
US20220087106A1,Harvester with automated capabilities,"Systems and methods here may include a vehicle with automated robotic subcomponents for harvesting delicate agricultural items such as berries. In some examples, the vehicle includes a targeting subcomponent and a harvesting subcomponent. Which may utilize multiple cameras to create three dimensional maps of foliage and targets. In some examples, the targeting subcomponent includes automated or semi-automated harvesting targets to be mapped and passed to the harvesting subcomponent. In some examples, the harvesting subcomponent includes vacuum features and padded spoons to detach the target agriculture from the stem.","['A01D46/30', 'A01D45/00', 'A01D46/005', 'A01D46/253', 'A01D46/28', 'B25J11/0045', 'B25J15/0226', 'B25J15/06', 'B25J15/0616', 'B25J19/023', 'B25J9/02', 'B25J9/163', 'B25J9/1697', 'G05B2219/45003']"
US11911903B2,Systems and methods for robotic picking and perturbation,"Various embodiments of the present technology generally relate to robotic devices and artificial intelligence. More specifically, some embodiments relate to a robotic device for picking items from a bin and perturbing items in a bin. The robotic device may include one or more picking elements and one or more perturbation elements for disturbing a present arrangement of items in the bin. In an exemplary embodiment, a perturbation element comprises a compressed air valve. In some implementations, the robotic device may also include one or more computer-vision systems. Based on image data from the one or more computer-vision systems, a strategy for picking up items from the bin is determined. When no strategies with high probability of success exist, the robotic device may perturb the contents of the bin to create new available pick-up points.","['B25J9/163', 'B25J9/161', 'B25J9/1697', 'G06N3/08', 'B25J15/0658', 'G05B2219/39508', 'G05B2219/40014', 'G05B2219/40053', 'G05B2219/45063', 'G06N3/045', 'G06N3/047']"
CN106338406B,The on-line monitoring of train traction electric drive system and fault early warning system and method,"The present invention provides a kind of on-line monitorings of train traction electric drive system and fault early warning system and method.The system comprises signal detection module, slave computer, host computer and monitoring and early warning result display modules；Signal detection module obtains the system state amount to be monitored, and slave computer is reached after Classifying Sum.Slave computer is filtered and pre-processes to system state amount.Extract the temporal signatures information and frequency domain character information of system.Then pass through fuzzy logic inference and carry out Feature Compression and dimensionality reduction by PCA pivot analysis, obtain the main feature information of traction electric drive system.By main feature information input to SOMNN fault pre-alarming modules, main feature information is calculated and handled using SOM neural network algorithms, the current state of on-line monitoring train traction electric drive system, and the failure in early warning future.The present invention quickly can carry out status monitoring and fault pre-alarming to the traction electric drive system of train in real time.","['G01M17/08', 'G06F18/2135', 'G06F18/25', 'G06N3/04', 'G06N3/088']"
US20200314382A1,"Video frame interpolation method, storage medium and terminal","The present application provides a video frame interpolation method. The method includes the steps of: 1) successively determining a current frame, a frame prior to the current frame and a frame after the current frame of a video to which a frame to be interpolated; 2) inputting the current frame, the frame prior to the current frame and the frame after the current frame of the video to which the frames to be interpolated into a pre-configured video frame interpolation model, wherein the video frame interpolation model is configured by training a pre-set convolutional neural network model with current frames, frames prior to the current frames and frames after the current frames in a training set; and 3) performing frame interpolation on the video to which the frames to be interpolated via the video frame interpolation model, and obtaining frame interpolated video.","['H04N19/85', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'H04N19/132', 'H04N19/80', 'H04N7/0135']"
US11947683B2,Replicating a storage system,"Creating a replica of a storage system, including: receiving, by a first storage system from a computing device, data to be stored on the first storage system; reducing, by the first storage system, the data using one or more data reduction techniques; sending, from the first storage system to the second storage system, the reduced data, wherein the reduced data is encrypted; and sending, from the second storage system to a third storage system, the reduced data, wherein the reduced data is encrypted.","['G06F11/1453', 'G06F21/602', 'G06F11/1464', 'G06F16/164', 'G06F16/1748', 'G06F16/1824', 'G06F21/6218', 'G06F21/6227', 'G06F3/0604', 'G06F3/0619', 'G06F3/062', 'G06F3/0622', 'G06F3/0623', 'G06F3/065', 'G06F3/0659', 'G06F3/067', 'G06F3/0673', 'H04L67/1095', 'H04L9/0816', 'H04L9/0894', 'H04L9/14', 'H04L9/3239', 'H04L9/50', 'G06F11/1469', 'G06F11/2094', 'G06F21/107', 'H04L2209/30', 'H04L67/1097']"
US20190355366A1,Speaker recognition,"A speaker recognition system comprises (i) at least one microphone operable to output data representing speech of a speaker and (ii) a controller. The controller is operable to: (a) receive the data output from the at least one microphone; (b) process the received data using a first artificial neural network to obtain first output data, the first artificial neural network having been trained based on outputs of a second artificial neural network, the second artificial neural network having been trained to perform speaker recognition; and (c) identify the speaker using the first output data. The first artificial neural network comprises fewer layers and/or fewer parameters than the second artificial neural network. The first artificial neural network is configured to emulate a result derivable using an output of the second artificial neural network.","['G10L17/18', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/084', 'G10L17/04', 'G06N3/048']"
US12390926B2,Machine learning model for task and motion planning,"Apparatuses, systems, and techniques are described that solve task and motion planning problems. In at least one embodiment, a task and motion planning problem is modeled using a geometric scene graph that records positions and orientations of objects within a playfield, and a symbolic scene graph that represents states of objects within context of a task to be solved. In at least one embodiment, task planning is performed using symbolic scene graph, and motion planning is performed using a geometric scene graph.","['B25J9/1664', 'B25J9/161', 'B25J9/163', 'B25J9/1635', 'B25J9/1697', 'G06N20/00', 'G06N3/063', 'G06N3/08', 'G05B2219/39311', 'G06N3/044', 'G06N3/045', 'G06N3/048']"
US20250148615A1,System and method for player reidentification in broadcast video,"A system and method of re-identifying players in a broadcast video feed are provided herein. A computing system retrieves a broadcast video feed for a sporting event. The broadcast video feed includes a plurality of video frames. The computing system generates a plurality of tracks based on the plurality of video frames. Each track includes a plurality of image patches associated with at least one player. Each image patch of the plurality of image patches is a subset of the corresponding frame of the plurality of video frames. For each track, the computing system generates a gallery of image patches. A jersey number of each player is visible in each image patch of the gallery. The computing system matches, via a convolutional autoencoder, tracks across galleries. The computing system measures, via a neural network, a similarity score for each matched track and associates two tracks based on the measured similarity.","['G06T7/20', 'G06V40/23', 'G06F18/2135', 'G06F18/214', 'G06F18/22', 'G06F18/2413', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06T7/246', 'G06T7/70', 'G06T7/73', 'G06T7/80', 'G06T7/97', 'G06V10/454', 'G06V10/761', 'G06V10/764', 'G06V10/82', 'G06V20/42', 'G06V20/46', 'G06V20/48', 'G06V20/49', 'G06V40/20', 'H04N21/23418', 'H04N21/2353', 'H04N21/26603', 'H04N21/44008', 'H04N21/84', 'H04N21/8456', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30221', 'G06T2207/30244', 'G06V20/44']"
CN112069459B,Accelerator for sparse-dense matrix multiplication,"The disclosed embodiments relate to accelerators for sparse-dense matrix instructions. In one example, a processor for executing sparse-dense matrix multiplication instructions includes: a fetch circuit to fetch a sparse-dense matrix multiplication instruction having fields for specifying an opcode, a dense output matrix, a dense source matrix, and a sparse source matrix having a sparseness of non-zero elements, the sparseness being less than one; a decoding circuit for decoding the fetched sparse-dense matrix multiplication instruction; execution circuitry to execute the decoded sparse-dense matrix multiplication instruction to, for each non-zero element at row M and column K of the specified sparse source matrix: generating a product of the non-zero element and each corresponding dense element at row K and column N of the specified dense source matrix; and generating an accumulated sum of each generated product and the previous value of the corresponding output element at row M and column N of the specified dense output matrix.","['G06F17/16', 'G06F7/5443', 'G06F9/3001', 'G06F9/30014', 'G06F9/30032', 'G06F9/30036', 'G06F9/30038', 'G06F9/30043', 'G06F9/30145', 'G06F9/3016', 'G06F9/383', 'G06F9/3887', 'G06F9/3888', 'G06N3/00', 'G06N3/063']"
CN110674805B,Insect identification method and system,"The invention provides an insect identification method and system, wherein the system comprises a client and a server, the client is connected with the server, and the method comprises the following steps: the method comprises the steps that a client side obtains an image photo which is shot by a target user and contains insects to be identified, obtains an insect region in the image photo, slices the insect region to obtain an insect picture, and sends the insect picture to a server; the server calls an insect species identification model deployed on the server to identify the insect picture, and sends an identification result to the client; and the client side pushes the identification result to the target user. By applying the scheme provided by the invention, the problems of high difficulty and low accuracy of insect identification in the prior art can be solved.","['G06V10/22', 'G06V40/10', 'G06F16/583', 'G06V10/25', 'G06V10/761', 'G06V10/774', 'G06V10/778', 'G06V10/82', 'G06V10/95']"
CN104679863B,It is a kind of based on deep learning to scheme to search drawing method and system,"The present invention relates to picture search technical field, there is provided it is a kind of based on deep learning to scheme the method for searching figure, wherein, calculate image category feature, the depth convolutional neural networks that use has been trained, to input picture extract characteristic of division；Image own coding feature is calculated, the autocoding algorithm for the deep learning that use has been trained, coding characteristic is extracted to input picture；Composite character coding compression, the comprehensive characteristic of division and image own coding feature, these features are encoded by deep learning autocoding algorithm；According to feature calculation image similarity and output of sorting.The present invention produces advanced features using depth convolutional neural networks, ensures similar in image category to scheme to search figure result；And the image coding characteristic of low level is produced using autocoding algorithm, ensure that image is similar in terms of content；Mixing own coding characterization method further merges characteristic of division, image own coding feature, reduces dimension so that search result is more quick, stablizes.",[]
CN107844469B,Text simplification method based on word vector query model,"The invention discloses a text simplification method based on a word vector query model, which is characterized in that on the basis of a sequence-to-sequence model, the hidden state of a decoder and the relevance of word vectors of all words are obtained by referring to an attention mechanism during decoding and are used as the measurement of the possibility of the words to be generated in the next step; the method comprises the following steps: designing a text encoder to compress an original text; designing a text simplified decoding generator, and circularly calculating a current hidden layer vector and a current context vector at each moment; obtaining the retrieval relevance of each word in the word list, outputting the predicted word at the current moment, and obtaining a section of complete simplified text; training to generate a model of the simplified text, and minimizing the log-likelihood of the predicted words and the actual target words; after training, the complete simplified text is generated. The invention can improve the quality and accuracy of the generated text, greatly reduce the number of parameters of the existing method and reduce the training time and the memory occupation.","['G06F40/186', 'G06F16/332', 'G06N3/04']"
US11106868B2,System and method for language model personalization,"A method, an electronic device, and computer readable medium is provided. The method includes identifying a set of observable features associated with one or more users. The method also includes generating latent features from the set of observable features. The method additionally includes sorting the latent features into one or more clusters. Each of the one or more clusters represents verbal utterances of a group of users that share a portion of the latent features. The method further includes generating a language model that corresponds to a specific cluster of the one or more clusters. The language model represents a probability ranking of the verbal utterances that are associated with the group of users of the specific cluster.","['G06F40/279', 'G06F40/20', 'G06F40/216', 'G06F40/30', 'G10L15/183', 'G10L15/197', 'G10L15/22', 'G10L15/30']"
US20240257445A1,Damage detection from multi-view visual data,"A plurality of images may be analyzed to determine an object model. The object model may have a plurality of components, and each of the images may correspond with one or more of the components. Component condition information may be determined for one or more of the components based on the images. The component condition information may indicate damage incurred by the object portion corresponding with the component.","['G01C21/32', 'G06F16/29', 'G06F17/18', 'G06F18/2414', 'G06F30/15', 'G06F9/453', 'G06N3/02', 'G06Q30/0278', 'G06Q40/08', 'G06T15/10', 'G06T15/205', 'G06T17/00', 'G06T19/003', 'G06T19/006', 'G06T7/0002', 'G06T7/0004', 'G06T7/001', 'G06T7/593', 'G06T7/70', 'G06V10/82', 'G06V20/64', 'H04N13/243', 'H04N13/271', 'H04N23/633', 'G06T2200/08', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30108', 'G06T2207/30156', 'G06T2207/30244', 'G06T2207/30248', 'H04N2013/0081']"
CN110709825B,Packaging objects by predicted lifetime in cloud storage,"A method (600) comprising: receiving a data object (200); determining a predicted lifetime for each data object (220); and instantiating a plurality of sharded files (250). Each sharded file (250) has an associated predicted life span (260). The method also includes: writing each data object into a corresponding shard file having an associated predicted lifetime range, the predicted lifetime range comprising a predicted lifetime of the respective data object; and storing the sharded file in a distributed storage system (140). The method also includes: based on the number of deleted data objects in each corresponding stored shard file, a determination is made as to whether any of the stored shard files meet the compression criteria (280). For each stored shard file that meets the compression criteria, the method also includes compressing the stored shard file by overwriting remaining data objects of the stored shard file with a new shard file.","['G06F12/0261', 'G06F16/122', 'G06F16/1734', 'G06F16/182', 'G06F16/2219', 'G06F3/0604', 'G06F3/0608', 'G06F3/061', 'G06N20/00', 'G06F3/0649']"
US10878313B2,Post synaptic potential-based learning rule,"A spike sent from a first artificial neuron in a spiking neural network (SNN) to a second artificial neuron in the SNN is identified, with the spike sent over a particular artificial synapse in the SNN. The membrane potential of the second artificial neuron at a particular time step, corresponding to sending of the spike, is compared to a threshold potential, where the threshold potential is set lower than a firing potential of the second artificial neuron. A change to the synaptic weight of the particular artificial synapse is determined based on the spike, where the synaptic weight is to be decreased if the membrane potential of the second artificial neuron is lower than the threshold potential at the particular time step and the synaptic weight is to be increased if the membrane potential of the second artificial neuron is higher than the threshold potential at the particular time step.","['G06N3/063', 'G06N3/049']"
GB2618936A,Vehicle-road collaboration-oriented sensing information fusion representation and target detection method,"A vehicle-road collaboration-oriented sensing information fusion representation and target detection method, comprising the following steps: providing a roadside lidar, and configuring a corresponding roadside computing device for the roadside lidar; calibrating extrinsic parameters of the roadside lidar; the roadside computing device calculating, according to positioning data of a self-driving vehicle and the extrinsic parameters of the roadside lidar, a relative position of the self-driving vehicle with respect to the roadside lidar; the roadside computing device deflecting, according to the relative position, roadside lidar point cloud detected by the roadside lidar into the coordinate system of the self-driving vehicle, so as to obtain a deflected point cloud; and the roadside computing device performing voxelization processing on the deflected point cloud to obtain a voxelized deflected point cloud. The self-driving vehicle performs voxelization processing on a vehicle-mounted lidar point cloud detected by a vehicle-mounted lidar to obtain a voxelized vehicle-mounted lidar point cloud; and the roadside computing device calculates voxel-level features of the voxelized deflected point cloud, to obtain voxel-level features of the deflected point cloud. The self-driving vehicle calculates voxel-level features of the voxelized vehicle-mounted lidar point cloud, to obtain voxel-level features of the vehicle-mounted lidar point cloud; and the point cloud voxel-level features are compressed and transmitted to the computing device, and a transmission device can be a self-driving vehicle, a roadside computing device or a cloud. The computing device performs data splicing and data aggregation on the voxel-level features of the vehicle-mounted lidar point cloud and the voxel-level features of the deflected point cloud to obtain aggregated voxel-level features; the computing device inputs the aggregated voxel-level features into a voxel-level feature based three-dimensional target detection network model to obtain a target detection result; and when the computing device is a roadside computing device or a cloud, finally the target detection result is sent to the self-driving vehicle.","['G01S7/40', 'G01S17/87', 'G01S17/89', 'G01S17/93', 'G01S17/931', 'G01S7/003', 'G01S7/4808', 'G01S7/4972', 'G06F18/20', 'G06V20/56', 'G08G1/0116', 'G08G1/0133', 'G08G1/0141', 'G08G1/0145', 'G08G1/04', 'G08G1/048', 'G08G1/164', 'G06F3/048', 'G06F9/451', 'G06T7/194']"
CN111556420B,Hearing devices including noise reduction systems,"The application discloses a hearing device comprising a noise reduction system, the hearing device comprising: an input unit for providing at least one electrical input signal representing k, m in time frequency, wherein k and m refer to frequency and time, respectively, and k represents a channel, said at least one electrical input signal representing sound and comprising a target signal component and a noise signal component; and a signal processor comprising an SNR estimator for providing a target signal-to-noise ratio, SNR, estimate of the at least one electrical input signal in time-frequency representation; an SNR-to-gain converter for converting the target signal-to-noise ratio estimate to a corresponding gain value expressed in time-frequency; wherein the signal processor comprises a neural network, wherein weights of the neural network have been trained with a plurality of training signals.","['H04R25/507', 'H04R25/00', 'G06N3/0442', 'G06N3/0464', 'G06N3/0495', 'G06N3/08', 'G06N3/09', 'G10L25/51', 'H04R25/552', 'H04R2225/43', 'H04R25/407']"
US10929503B2,Apparatus and method for a masked multiply instruction to support neural network pruning operations,"An apparatus and method for a masked multiply instruction to support neural network pruning operations. For example, one embodiment of a processor comprises: a decoder to decode a matrix multiplication with masking (GEMM) instruction identifying a destination matrix register to store a result, and source registers storing an A-matrix, a B-matrix, and a matrix mask; execution circuitry to execute the GEMM instruction, the execution circuitry to multiply a plurality of B-matrix elements with a plurality of A-matrix elements, each of the B-matrix elements associated with a mask value in the matrix mask, wherein if the mask value is set to a first value, then the execution circuitry is to multiply the B-matrix element with one or more of the A-matrix elements to generate a first partial result, and if the mask value is set to a second value, then the execution circuitry is to multiply an alternate B-matrix element with a one or more of the A-matrix elements to generate a second partial result.","['G06F17/16', 'G06F9/3001', 'G06F9/30018', 'G06F9/30036', 'G06F9/30038', 'G06N3/02', 'G06N3/063', 'G06N3/082', 'G06N3/048', 'G06N3/084']"
US11989822B2,Damage detection from multi-view visual data,"A plurality of images may be analyzed to determine an object model. The object model may have a plurality of components, and each of the images may correspond with one or more of the components. Component condition information may be determined for one or more of the components based on the images. The component condition information may indicate damage incurred by the object portion corresponding with the component.","['G06T15/205', 'G01C21/32', 'G01N21/9515', 'G06F16/29', 'G06F17/18', 'G06F3/011', 'G06F3/04815', 'G06F30/15', 'G06F9/453', 'G06N3/02', 'G06Q10/0837', 'G06Q10/20', 'G06Q30/0278', 'G06T15/04', 'G06T15/10', 'G06T17/00', 'G06T19/003', 'G06T19/006', 'G06T19/20', 'G06T3/00', 'G06T3/06', 'G06T7/0002', 'G06T7/0004', 'G06T7/001', 'G06T7/30', 'G06T7/593', 'G06T7/70', 'H04N13/221', 'H04N13/243', 'H04N13/25', 'H04N13/271', 'H04N23/633', 'H04N23/64', 'G01N2021/8887', 'G06N3/08', 'G06Q50/40', 'G06T2200/08', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30108', 'G06T2207/30156', 'G06T2207/30244', 'G06T2207/30248', 'G06T2219/2012', 'H04N2013/0081', 'H04N23/698']"
US20230077979A1,Data processing systems including optical communication modules,"A system includes a housing and a first circuit board positioned inside the housing. The housing has a top panel, a bottom panel, a left side panel, a right side panel, a front panel, and a rear panel. The front panel is at an angle relative to the bottom panel in which the angle is in a range from 30 to 150°. The first circuit board has a length, a width, and a thickness, in which the length is at least twice the thickness, the width is at least twice the thickness, and the first circuit board has a first surface defined by the length and the width. The first surface of the first circuit board is at a first angle relative to the bottom panel in which the first angle is in a range from 30 to 150°. The first surface of the first circuit board is substantially parallel to the front panel or at a second angle relative to the front panel in which the second angle is less than 60°. The system includes a first data processing module and a first optical interconnect module both electrically coupled to the first circuit board. The optical interconnect module is configured to receive first optical signals from a first optical link, convert the first optical signals to first electrical signals, and transmit the first electrical signals to the first data processing module.","['H04B10/25', 'H04B10/801']"
CN111415342B,Automatic detection method for pulmonary nodule images of three-dimensional convolutional neural network by fusing attention mechanisms,"The invention discloses an automatic detection method for a pulmonary nodule image of a three-dimensional convolutional neural network fused with an attention mechanism, and belongs to the field of medical image processing. According to the invention, the three-dimensional convolutional neural network (3D-CNN) and the attention mechanism are combined, and the first-order detector for detecting the pulmonary nodule image is built, so that the automatic and accurate detection of the pulmonary CT image is realized, and the detection precision and speed are effectively improved. The main object of the present invention is to calculate the probability that a feature object in an image is a lung segment, the whole method being based on the calculation of the feature object, i.e. the medical image itself. According to the invention, through combining the channel attention (channel attention) and the space attention (spatial attention) with the 3D CNN, useful information is enhanced, useless information is weakened, the expression capacity of a network is improved, and the efficient and accurate detection of the nodules is realized.","['G06T7/0012', 'G06N3/045', 'G06N3/08', 'G06T2207/10081', 'G06T2207/30061']"
CN112116601B,Compressed sensing sampling reconstruction method and system based on generation of countermeasure residual error network,"The invention discloses a compressed sensing sampling reconstruction method and a system based on a linear sampling network and a generation countermeasure residual error network, wherein the method comprises the following steps: acquiring a training image, and dividing the training image into a plurality of image blocks through dividing; constructing a linear sampling network to measure the image blocks to obtain measured values corresponding to the image blocks; in the generation of the reactive residual error network, firstly, carrying out linear mapping processing on measured values of each image block through a full-connection layer to obtain an initial reconstruction result; inputting an initial reconstruction result into a residual error network, and training to obtain residual error information; carrying out signal fusion on the initial reconstruction result and residual information, thereby obtaining a generation result of a generator; the generated result of the generator and the original image block are input into a discriminator together for judgment; and calculating a loss function, and performing iterative training on the linear sampling network and the generated countermeasure residual error network so as to obtain a final image reconstruction result. The invention can effectively improve the reconstruction effect under the low sampling rate.","['G06T7/11', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US10977520B2,Training data collection for computer vision,"Provided is a process that includes: determining that a training set lacks an image of an object with a given pose, context, or camera; composing, based on the determination, a video capture task; obtaining a candidate video; selecting a subset of frames of the candidate video as representative; determining that a given frame among the subset depicts the object from the given pose, context, or camera; and augmenting the training set with the given frame.","['G06K9/6256', 'G06V10/764', 'G06F18/21', 'G06F18/214', 'G06F18/217', 'G06F18/23', 'G06F18/40', 'G06F18/41', 'G06K9/00', 'G06K9/00013', 'G06K9/00744', 'G06K9/00765', 'G06K9/00912', 'G06K9/00919', 'G06K9/00926', 'G06K9/32', 'G06K9/46', 'G06K9/6217', 'G06K9/6218', 'G06K9/6253', 'G06K9/6254', 'G06K9/6262', 'G06T7/0002', 'G06V10/774', 'G06V10/82', 'G06V20/46', 'G06V20/47', 'G06V20/49', 'G06V40/50', 'G06V40/63', 'G06V40/67', 'G06T2207/10016', 'G06T2207/30168']"
US20240054594A1,Method for watermarking depth image based on mixed frequency-domain channel attention,"The present disclosure discloses a method for watermarking depth image based on mixed frequency-domain channel attention, relating to the field of artificial neural networks and digital image watermarking; the method includes: step 1: a watermark information processor generating a watermark information feature map; step 2: an encoder generating a watermarked image from a carrier image and a watermark information feature map; step 3: a noise layer taking the watermarked image as an input, and generating a noise image through simulated differentiable noise; step 4: a decoder down-sampling the noise image to recover watermark information; step 5: a countermeasure discriminator classifying the carrier image and the watermarked image such that the encoder generates a watermarked image with a high quality. The present disclosure combines the end-to-end depth watermark model with frequency-domain channel attention to expand an application range of the depth neural network in the field of image watermark.","['G06T1/0028', 'G06T3/40', 'G06V10/764', 'G06V10/771', 'G06V10/82']"
US11307998B2,Storage efficiency of encrypted host system data,"A storage controller coupled to a storage array comprising one or more storage devices that performs at least one data reduction operation on decrypted data, encrypts the reduced data using a second encryption key to generate a second encrypted data, and stores the second encrypted data on the storage array.","['G06F12/1408', 'G06F21/602', 'G06F21/6227', 'G06F3/0608', 'G06F3/0641', 'G06F3/067', 'G06F3/0683', 'G06F2212/1052']"
WO2020156259A1,"Memory management method and device, mobile terminal, and storage medium","Embodiments of the present application disclose a memory management method and device, a mobile terminal, and a storage medium. The method comprises: receiving a memory application request sent by a first tensor unit, the memory application request carrying a required memory space, and the first tensor unit being any one of a plurality of tensor units; detecting whether or not the required memory space is less than or equal to the capacity of a current largest available blank memory block in an already-allocated memory; and if not, performing a memory reorganization operation on the already-allocated memory. The embodiments of the present application are employed in a neural network algorithm framework to prevent wastage of memory.","['G06F12/02', 'G06N3/063', 'G06N3/08']"
US20220198254A1,Explainable transducer transformers,"An explainable transducer transformer (XTT) may be a finite state transducer, together with an Explainable Transformer. Variants of the XTT may include an explainable Transformer-Encoder and an explainable Transformer-Decoder. An exemplary Explainable Transducer may be used as a partial replacement in trained Explainable Neural Network (XNN) architectures or logically equivalent architectures. An Explainable Transformer may replace black-box model components of a Transformer with white-box model equivalents, in both the sub-layers of the encoder and decoder layers of the Transformer. XTTs may utilize an Explanation and Interpretation Generation System (EIGS), to generate explanations and filter such explanations to produce an interpretation of the answer, explanation, and its justification.","['G06N3/0635', 'G06N3/065', 'G06N3/084', 'G06F40/40', 'G06N3/04', 'G06N3/042', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06N3/086', 'G06N3/088', 'G06N3/092', 'G06N3/10', 'G06N5/01', 'G06N5/025', 'G06N5/042', 'G06N5/045', 'G06N3/047', 'G06N5/022']"
US11651211B2,Training of neural network based natural language processing models using dense knowledge distillation,"Techniques for training a first neural network (NN) model using a pre-trained second NN model are disclosed. In an example, training data is input to the first and second models. The training data includes masked tokens and unmasked tokens. In response, the first model generates a first prediction associated with a masked token and a second prediction associated with an unmasked token, and the second model generates a third prediction associated with the masked token and a fourth prediction associated with the unmasked token. The first model is trained, based at least in part on the first, second, third, and fourth predictions. In another example, a prediction associated with a masked token, a prediction associated with an unmasked token, and a prediction associated with whether two sentences of training data are adjacent sentences are received from each of the first and second models. The first model is trained using the predictions.","['G06F40/284', 'G06N3/045', 'G06N3/08', 'G10L15/16', 'G10L25/30']"
US9418551B2,"Position and/or distance measurement, parking and/or vehicle detection, apparatus, networks, operations and/or systems","The following are disclosed: Vehicle parking detection, sensors and an On-Board Device (OBD) to create a parking session. Radars, microwave antennas, rechargeable power supplies and their power management circuits. A localized communications protocol between the wireless nodes and repeaters within a wireless network is disclosed. Wireless sensors and wireline sensors. The networks and/or systems may support parking spot management/monitoring, vehicle traffic analysis and/or management of stationary and/or moving vehicles, monitor storage areas and/or manage production facilities. These networks and/or systems may be operated to generate reports of incorrectly parked vehicles, such as reserved parking spots for other vehicles, vehicles parked in multiple parking spots and/or overstaying the time they are permitted to park.","['G08G1/142', 'B60W30/06', 'G01S13/931', 'G08G1/146', 'G01S2013/9314']"
US11210608B2,"Method and apparatus for generating model, method and apparatus for recognizing information","A method and apparatus for generating a model, and a method and apparatus for recognizing information are provided. An implementation of the method for generating a model includes: acquiring a to-be-converted model, a topology description of the to-be-converted model, and device information of a target device; converting, based on the topology description and the device information, parameters and operators of the to-be-converted model to obtain a converted model applicable to the target device; and generating a deep learning prediction model based on the converted model. This embodiment enables the conversion of an existing model to a deep learning prediction model that can be applied to a target device.","['H04L67/303', 'G06N20/00', 'G06F18/214', 'G06N3/063', 'H04L67/34']"
CN110737986B,An intelligent optimization simulation system and method for unmanned ship energy efficiency,"The invention discloses an unmanned ship energy efficiency intelligent optimization simulation system and method, comprising the following steps: the ship end data acquisition unit can acquire ship end data of the ship in real time, and transmit the data to the shore-based energy efficiency monitoring unit while carrying out local backup storage; the shore-based energy efficiency monitoring unit can store ship end data, and simultaneously acquire and display an evaluation result corresponding to the ship end data; the shore-based energy efficiency intelligent decision simulation unit can store the received data and determine an intelligent decision result, namely the optimal navigational speed and the optimal navigational direction of the ship; meanwhile, the optimal control simulation of the ship speed and the ship course can be realized and real-time display can be performed. The invention can realize the dynamic simulation of the ship running state and the energy efficiency state under different running scenes and different control decisions, and can verify the validity and feasibility of the intelligent decision making method formulated under different conditions through simulation results, thereby laying a foundation for the research and application of the unmanned ship intelligent energy efficiency optimization management technology.","['G06F18/23', 'G06N3/04', 'G06N3/08']"
US20190260204A1,"Devices, systems and methods for the collection of meter data in a common, globally accessible, group of servers, to provide simpler configuration, collection, viewing, and analysis of the meter data","The present disclosure is directed to a machine learning system for use with a power distribution system. The machine learning system includes a data library, a machine learning module, and an action module. The data library stores a plurality of data samples, where at least a portion of the data samples are associated with one or more intelligent electronic devices (IEDs). The machine learning module processes data samples from the data library using at least one machine learning algorithm and outputs at least one recommendation and/or prediction based on the data samples received. The action module receives the at least one recommendation and/or prediction and performs at least one action based on the recommendation and/or prediction. The at least one action includes outputting at least one communication signal and/or at least one control signal to at least one client or at least one of the one or more IEDs.","['G06Q30/0206', 'H02J3/14', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N3/126', 'H02J3/003', 'G05B2219/2642', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N7/01', 'G06Q50/06', 'H02J2003/003', 'H02J2310/12', 'Y02B70/3225', 'Y04S20/222', 'Y04S50/14']"
US10922557B2,"Method for processing sensor data in multiple control units, preprocessing unit, and transportation vehicle","A method for processing sensor data in a number of controllers in a controller complex. The controllers are connected to at least one sensor via at least one communication bus, wherein the sensor data of the at least one sensor are processed by at least two different controllers in stages. At least one processing stage is concordant in the two controllers or is equivalent to the other stage at least in so far as the results of the processing are converted into one another by a conversion. Provision is made for a preprocessing unit to which the sensor data of the at least one sensor are supplied, wherein the processing of the sensor data in the at least one concordant processing stage is performed in the preprocessing unit, and the processed sensor data are forwarded to the at least two different controllers for individual further processing.","['B60W50/00', 'G01S15/931', 'G06K9/00791', 'B60R16/023', 'G01S17/86', 'G05D1/0246', 'G06K9/00798', 'G06K9/46', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V20/56', 'G06V20/588', 'G08G1/16', 'H04L12/40', 'H04L67/2823', 'H04L67/565', 'B60W2050/0043', 'B60W2050/0052', 'B60W2420/00', 'B60W2556/45', 'B60Y2400/30', 'G06T2207/10', 'H04L2012/40215', 'H04L2012/40241', 'H04L2012/40273']"
US11586930B2,Conditional teacher-student learning for model training,"Embodiments are associated with conditional teacher-student model training. A trained teacher model configured to perform a task may be accessed and an untrained student model may be created. A model training platform may provide training data labeled with ground truths to the teacher model to produce teacher posteriors representing the training data. When it is determined that a teacher posterior matches the associated ground truth label, the platform may conditionally use the teacher posterior to train the student model. When it is determined that a teacher posterior does not match the associated ground truth label, the platform may conditionally use the ground truth label to train the student model. The models might be associated with, for example, automatic speech recognition (e.g., in connection with domain adaptation and/or speaker adaptation).","['G10L15/063', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G10L15/16', 'G10L15/183', 'G06N3/044', 'G10L15/065', 'G10L15/07']"
US12340788B2,Generating expressive speech audio from text data,"A system for use in video game development to generate expressive speech audio comprises a user interface configured to receive user-input text data and a user selection of a speech style. The system includes a machine-learned synthesizer comprising a text encoder, a speech style encoder and a decoder. The machine-learned synthesizer is configured to generate one or more text encodings derived from the user-input text data, using the text encoder of the machine-learned synthesizer; generate a speech style encoding by processing a set of speech style features associated with the selected speech style using the speech style encoder of the machine-learned synthesizer; combine the one or more text encodings and the speech style encoding to generate one or more combined encodings; and decode the one or more combined encodings with the decoder of the machine-learned synthesizer to generate predicted acoustic features. The system includes one or more modules configured to process the predicted acoustic features, the one or more modules comprising a machine-learned vocoder configured to generate a waveform of the expressive speech audio.","['G10L13/027', 'G10L13/00', 'A63F13/53', 'A63F13/54', 'A63F13/60', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'A63F13/63', 'A63F2300/6018']"
US11392800B2,Computer vision systems and methods for blind localization of image forgery,Computer vision systems and methods for localizing image forgery are provided. The system generates a constrained convolution via a plurality of learned rich filters. The system trains a convolutional neural network with the constrained convolution and a plurality of images of a dataset to learn a low level representation of each image among the plurality of images. The low level representation is indicative of a statistical signature of at least one source camera model of each image. The system can determine a splicing manipulation localization by the trained convolutional neural network.,"['G06K9/6265', 'G06N3/08', 'G06F18/2148', 'G06F18/2193', 'G06K9/6257', 'G06N3/04', 'G06N3/045', 'G06N7/01', 'G06V10/30', 'G06V10/50', 'G06V10/764', 'G06V10/7796', 'G06V10/82', 'G06V20/40', 'G06V20/90']"
CN111583954B,Speaker independent single-channel voice separation method,"The invention discloses a single-channel voice separation method irrelevant to speakers, which comprises the following steps: preparing a data set and carrying out data preprocessing; establishing a single-track voice separation model based on the masking of a plurality of ideal floating values; when the single sound channel voice separation model is trained, sentence level replacement invariance training is adopted; and inputting the mixed voice data into the trained model for voice separation. The method effectively and accurately realizes the estimation of the complex ideal floating value masking through the sentence-level replacement invariance training, adopts a bidirectional long-short term memory neural network structure to estimate the complex ideal floating value masking, and further solves the problem of label ambiguity by utilizing the standard of the sentence-level replacement invariance training, thereby leading the separation of the single-channel voice to have better effect.",['G10L21/0272']
CN111868676B,Servicing I/O operations in a cloud-based storage system,"Servicing I/O operations in a cloud-based storage system includes: receiving, by the cloud-based storage system, a request to write data to the cloud-based storage system; storing the data in a solid state storage of a cloud-based storage system; storing the data in an object store of a cloud-based storage system; detecting that at least some portion of the solid state storage of the cloud-based storage system has become unavailable; identifying data stored in portions of the solid state storage of the cloud-based storage system that have become unusable; retrieving, from an object store of the cloud-based storage system, data stored in a portion of the solid state storage of the cloud-based storage system that has become unavailable; and storing the retrieved data in a solid state storage of the cloud-based storage system.","['G06F3/0659', 'G06F3/061', 'G06F3/0619', 'G06F3/064', 'G06F3/065', 'G06F3/0661', 'G06F3/067']"
CN113006999B,Control device and control method for internal combustion engine,"The invention provides a control device and a control method for an internal combustion engine, which can automatically adapt the control value or ignition time of an optimal combustion operating mechanism during operation and properly control the internal combustion engine even if the characteristics of the internal combustion engine change due to individual difference, time-varying change and the like of the internal combustion engine. In a control device and a control method for an internal combustion engine, a set value of a torque characteristic function is changed so that an output torque calculated using the torque characteristic function approaches an output torque calculated based on an actual value of an in-cylinder pressure, a plurality of output torques corresponding to a plurality of combustion control states are calculated using the torque characteristic function, respectively, and a set value of a combustion control target setting function is changed so that a target value of the combustion control state calculated using the combustion control target setting function approaches a maximum torque combustion control state in which the output torque becomes maximum.","['F02P5/1502', 'F02D35/024', 'F02D35/028', 'F02D37/02', 'F02D41/005', 'F02D41/1405', 'F02P5/045', 'F02P5/153', 'G01L1/183', 'G01L23/24', 'F02D2200/1002', 'F02D2200/101', 'F02D2200/1012', 'F02D2250/18', 'F02D2250/28', 'Y02T10/40']"
US11966670B2,Method and system for predicting wildfire hazard and spread at multiple time scales,"Apparatuses, methods, and systems for generating gridded predictions of a probability of wildfire spread for geographies are disclosed. One method includes sensing observational climate and earth surface data, obtaining historical data on wildfire spread events, obtaining gridded climate data, creating a set of input features, creating a gridded wildfire data set, training a model that learns one or more probabilistic mapping function emulators between the set of input features and the gridded wildfire data set, which predicts a first probability of wildfire occurrence and a rate and extent of wildfire spread within a geographical region and at a specified period of time, and generating gridded wildfire prediction data including a second probability of wildfire occurrence and spread within the geographical region, using the model and a new set of input features over the geographical region but for a different time period.","['G06F30/20', 'G06F18/2113', 'G06F18/214', 'G06F18/2415', 'G06F30/27', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06V10/25', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/13', 'G06F2111/10', 'G06N3/044', 'G06N3/047', 'G06N3/086']"
US11983210B2,Methods and systems for generating summaries given documents with questions and answers,"Described herein are systems and methods to enable generation of high-quality summaries of documents that have questions and answers. To help summarize such documents, parsing methods are disclosed that account for different document formats. Question-answer groups are transformed into declarative sentences. Sentence correction can be applied to the declarative sentences. Candidate summary sentences are identified from the declarative sentences, and a subset of the candidate summary sentences are selected for inclusion in a summary. Aspects, segmentation, and augmentation can help with generation and tailoring of summaries.","['G06F16/345', 'G06F16/335', 'G06F16/338', 'G06F16/35', 'G06F40/216', 'G06F40/289', 'G06F40/35', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06F40/42', 'G06F40/58']"
US11042775B1,Apparatus and methods for temporal proximity detection,"A data processing apparatus may utilize an artificial neuron network configured to reduce dimensionality of input data using a sparse transformation configured using receptive field structure of network units. Output of the network may be analyzed for temporally persistency that is characterized by similarity matrix. Elements of the matrix may be incremented when present activity unit activity at a preceding frame. The similarity matrix may be partitioned based on a distance measure for a given element of the matrix and its closest neighbors. Stability of learning of temporally proximal patterns may be greatly improved as the similarity matrix is learned independently of the partitioning operation. Partitioning of the similarity matrix using the methodology of the disclosure may be performed online, e.g., contemporaneously with the encoding and/or similarity matrix construction, thereby enabling learning of new features in the input data.","['G06K9/6215', 'G06N3/08', 'G06F18/22', 'G06N3/049', 'G06T7/246', 'G06V20/40', 'G06T2207/10016']"
CN111771135B,LIDAR positioning using RNN and LSTM for time smoothing in autonomous vehicles,"A method of time smoothing in positioning results of an autonomous vehicle comprising: a probability offset is created for each of a series of consecutive light detection and ranging (LIDAR) frames in the online point cloud, the probability offset representing an overall matching cost between a first set of keypoints from the online point cloud and a second set of keypoints from a pre-established point cloud map (1301). The method further comprises the following steps: compressing the probability offsets into a plurality of probability vectors in an X dimension, a Y dimension, and a yaw dimension (1303); providing each probability vector of probability offsets to a plurality of Recurrent Neural Networks (RNNs) (1305); and generating a trajectory of positioning results over a plurality of consecutive LIDAR frames by the RNN (1307).","['G06T9/001', 'G06T7/70', 'B60W60/001', 'G01S17/06', 'G01S17/89', 'G01S7/497', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06T17/05', 'G06T7/20', 'G06T9/002', 'G06V20/56', 'B60W2420/403', 'B60W2420/408', 'B60W2520/14', 'G06N3/048', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
US11588716B2,Adaptive storage processing for storage-as-a-service,"Adaptive storage processing for storage-as-a-service, including detecting, by a cloud-based monitoring system, a storage system state for a storage system by monitoring the storage system in real-time remotely via a network; selecting, by the cloud-based monitoring system based on the storage system state, an entry in a tunables repository, wherein the entry in the tunables repository comprises a tunable parameter for the storage system state; accessing, by the cloud-based monitoring system via the network, a gateway for the storage system; and modifying, by the cloud-based monitoring system via the gateway, the tunable on the storage system based on the tunable parameter for the storage system state.","['H04L12/12', 'G06F9/5088', 'G06F21/604', 'G06F3/0604', 'G06F3/0605', 'G06F3/061', 'G06F3/0622', 'G06F3/0635', 'G06F3/0653', 'G06F3/0659', 'G06F3/067', 'G06F9/455', 'G06F9/45558', 'G06F9/48', 'G06F9/4806', 'G06F9/4843', 'G06F9/485', 'G06F9/4856', 'G06F9/4881', 'G06F9/50', 'G06F9/5005', 'G06F9/5011', 'G06F9/5016', 'G06F9/5083', 'G06N20/00', 'G06N3/063', 'H04L41/0816', 'H04L41/0897', 'H04L43/065', 'H04L43/0817', 'H04L43/0876', 'H04L67/1097', 'H04L67/75', 'G06F2009/4557', 'G06F2206/1012', 'G06F9/5044', 'G06N10/60', 'G06N3/0442', 'G06N3/092', 'H04L12/46', 'H04L41/0895', 'H04L41/14', 'H04L41/16', 'H04L43/20']"
US11812184B2,Systems and methods for presenting image classification results,"An apparatus for performing image searches including a camera, storage devices storing a set of instructions, and a processor coupled to the at least one storage device and the camera. The instructions configure the at least one processor to perform operations including identifying attributes of the captured image using a classification model; identifying first results based on the identified attributes; selecting a subset of first results based on corresponding probability scores, generating a first graphical user interface including interactive icons corresponding to first results in the subset, an input icon, and a first button. The operations may also include receiving a selection of the first button, performing a search to identify second results, and generating a second graphical user interface displaying the second results.","['H04N5/272', 'G06F16/51', 'G06F16/535', 'G06F16/538', 'G06F18/24', 'G06F3/04817', 'G06F3/0482', 'G06F8/65', 'G06F9/451', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06N20/20', 'G06N3/048', 'G06N5/01', 'G06V2201/08']"
US12203872B2,Damage detection from multi-view visual data,Images of an object may be captured at a computing device. Each of the images may be captured from a respective viewpoint based on image capture configuration information identifying one or more parameter values. A multiview image digital media representation of the object may be generated that includes some or all of the images of the object and that is navigable in one or more dimensions.,"['G01N21/9515', 'G06F3/011', 'G06F3/012', 'G06F3/04815', 'G06F3/04845', 'G06F9/453', 'G06Q10/20', 'G06Q40/08', 'G06T15/205', 'G06T19/003', 'G06T3/00', 'G06T3/06', 'G06T7/0004', 'G06T7/001', 'G06T7/30', 'G06T7/70', 'H04N13/117', 'H04N13/282', 'H04N23/633', 'H04N23/64', 'G01N2021/8887', 'G06N3/08', 'G06T2200/08', 'G06T2200/24', 'G06T2207/10028', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'G06T2207/30156', 'G06T2207/30244', 'G06T2207/30248', 'H04N23/698']"
US9992641B2,"Electronic device, server, and method for outputting voice","According to an embodiment of the present disclosure, an electronic device may include a camera module obtaining image data of a user, a controller configured to detect at least one feature corresponding to an intention of the user from the image data obtained by the camera module, to obtain a pattern based on the at least one feature, to determine text data corresponding to the pattern, and to convert at least a portion of the text data into voice data, and an output module outputting the voice data. Other various embodiments of the pattern recognition are also provided.","['G10L15/26', 'G10L13/08', 'H04W4/14', 'G06K9/00288', 'G06K9/00302', 'G06K9/00355', 'G06V40/172', 'G06V40/174', 'G06V40/28', 'G10L15/24', 'G10L15/30', 'G10L25/30', 'G10L25/57', 'H04M1/724', 'H04M1/72475', 'H04M1/72519', 'H04M1/72588', 'G09B21/04', 'H04M1/663', 'H04M2250/52', 'H04M2250/74']"
US11340308B1,System and method for state determination of a battery module configured for used in an electric vehicle,"A system for state determination of a battery module configured for use in an electric vehicle. The system including a battery module including at least a battery cell, a sensor including a proximity sensor configured to detect a status datum corresponding to the battery module, a processor configured to receive the status datum from the sensor, generate a charge datum as a function of the status datum corresponding to the battery module, generate a health datum as a function of the status datum corresponding to the battery module, transmit the charge datum and the health datum, and a display configured to receive the charge datum and the health datum corresponding to the battery cell, and display the charge datum and the health datum corresponding to the battery cell.","['G01R31/392', 'B60L58/16', 'B60L3/0046', 'B60L58/12', 'G01R31/382', 'G01R31/396', 'H01M10/425', 'H01M10/48', 'H01M2010/4278', 'H01M2220/20', 'Y02T10/70']"
US10852379B2,Artifact reduction by image-to-image network in magnetic resonance imaging,"For artifact reduction in a magnetic resonance imaging system, deep learning trains an image-to-image neural network to generate an image with reduced artifact from input, artifacted MR data. For application, the image-to-image network may be applied in real time with a lower computational burden than typical post-processing methods. To handle a range of different imaging situations, the image-to-image network may (a) use an auxiliary map as an input with the MR data from the patient, (b) use sequence metadata as a controller of the encoder of the image-to-image network, and/or (c) be trained to generate contrast invariant features in the encoder using a discriminator that receives encoder features.","['G01R33/5608', 'G01R33/565', 'G01R33/4818', 'G01R33/56509', 'G06T11/008', 'G01R33/56518', 'G06T2210/41']"
US12165292B2,Generating an image mask for a digital image by utilizing a multi-branch masking pipeline with neural networks,"Methods, systems, and non-transitory computer readable storage media are disclosed for utilizing a plurality of neural networks in a multi-branch pipeline to generate image masks for digital images. Specifically, the disclosed system can classify a digital image as a portrait or a non-portrait image. Based on classifying a portrait image, the disclosed system can utilize separate neural networks to generate a first mask portion for a portion of the digital image including a defined boundary region and a second mask portion for a portion of the digital image including a blended boundary region. The disclosed system can generate the mask portion for the blended boundary region by utilizing a trimap generation neural network to automatically generate a trimap segmentation including the blended boundary region. The disclosed system can then merge the first mask portion and the second mask portion to generate an image mask for the digital image.","['G06T7/12', 'G06T5/75', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132']"
US10725934B2,Processor with selective data storage (of accelerator) operable as either victim cache data storage or accelerator memory and having victim cache tags in lower level cache wherein evicted cache line is stored in said data storage when said data storage is in a first mode and said cache line is stored in system memory rather then said data store when said data storage is in a second mode,"A first data storage holds cache lines, an accelerator has a second data storage that selectively holds accelerator data and cache lines evicted from the first data storage, a tag directory holds tags for cache lines stored in the first and second data storages, and a mode indicator indicates whether the second data storage is operating in a first or second mode in which it respectively holds cache lines evicted from the first data storage or accelerator data. In response to a request to evict a cache line from the first data storage, in the first mode the control logic writes the cache line to the second data storage and updates a tag in the tag directory to indicate the cache line is present in the second data storage, and in the second mode the control logic instead writes the cache line to a system memory.","['G06F12/082', 'G06F12/0833', 'G06F12/0868', 'G06F12/0897', 'G06F12/128', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/08', 'G06F2212/27']"
CN108171176B,Subway driver emotion identification method and device based on deep learning,"The invention provides a subway driver emotion identification method and device based on deep learning, wherein the method comprises the following steps: acquiring a driver emotion state database which comprises a face image and an emotion state corresponding to the face image; constructing a deep learning network model for emotion state identification; training the deep learning network model by using the driver emotion state database, solidifying the structure and parameters of the deep learning network model after training, acquiring a real-time working video of a subway driver by using an emotion state identification model, extracting continuous multi-frame images according to a preset frame rate, inputting the continuous multi-frame images into the emotion state identification model, and acquiring an emotion state identification result of the subway driver. The method adopts the deep learning network model based on the 3D convolutional neural network and the stacked self-encoder to monitor the emotional state of the subway driver in real time, has high identification precision, can discover the abnormal working state of the driver as soon as possible, and ensures the driving safety.","['G06V40/174', 'G06N3/045', 'G06N3/08']"
US11720727B2,Method and system for increasing the resolution of physical gridded data,"Apparatuses, methods, and systems for increasing a spatial resolution of gridded spatial-temporal data on weather and climate-related physical variables are disclosed. One method includes obtaining weather and climate data including at least a coarse resolution and a fine resolution, or observational data that includes physical data, pre-processing the weather and climate data, training one or more probabilistic downscaling mapping functions of the at least one of the gridded numeric simulation data or the observational data comprising applying interpolation filters to successively interpolate the pre-processed weather and climate data to generate output data having a resolution that is equal to the fine resolution, and generating high-resolution physical parameters for at least one of a plurality of applications utilizing the trained probabilistic downscaling mapping functions receiving different weather and climate input data that has different times or locations than the pre-processed weather and climate data used in the training.","['G06F30/27', 'G06F30/20', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N3/086', 'G06N3/088', 'G06F2111/04', 'G06F2111/08', 'G06F2111/10', 'G06N3/044', 'G06N3/084', 'Y02A90/10']"
US10915631B2,Deep learning on execution trace data for exploit detection,"Technologies disclosed herein provide for converting a first data of a first control flow packet to a first pixel, where the first data indicates one or more branches taken during a known execution of an application, generating an array of pixels using the first pixel and one or more other pixels associated with one or more other control flow packets generated from the known execution, transforming the array of pixels into a series of images, and using a machine learning algorithm with inputs to train a behavior model to identify a malicious behavior in an unknown execution of the application. The inputs include one or more images of the series of images and respective image labels assigned to the one or more images. More specific embodiments include extracting the first control flow packet from an execution trace representing at least part of the known execution.","['G06F21/552', 'G06F18/214', 'G06F18/217', 'G06F21/54', 'G06F21/56', 'G06F21/566', 'G06K9/325', 'G06K9/4628', 'G06K9/6256', 'G06K9/6262', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06V10/454', 'G06V20/62', 'G06F2221/034', 'G06N20/10', 'G06N3/044', 'G06N3/0445', 'G06N3/047', 'G06N3/0472']"
US8762583B1,Application aware intelligent storage system,This invention is a system and a method for operating a storage server that provides read or write access to a data in a data network using a new architecture. The method of processing I/Os in response to a request by a client of the storage server executes one or more services communicated by a policy engine. The I/Os received from the application are tagged and catalogued to create co-related I/O patterns. The policy engine is then updated with the results of processing the I/Os after executing services on those I/Os.,"['G06F3/0605', 'G06F3/0631', 'G06F3/0653', 'G06F3/0685', 'G06F3/0689']"
US20220027472A1,Ransomware detection and mitigation in a zoned storage device storage system,"Accesses of blocks of multiple zoned storage devices are monitored to detect one or more characteristics of the accesses of the blocks. A preventative action is performed in response to the detecting, wherein the preventative action includes sending an indication from the storage system upon determining that one or more of the accesses of the blocks are indicative of a malicious action based on the one or more characteristics.","['G06F21/568', 'G06F21/554', 'G06F21/566', 'G06F21/6218', 'G06F21/78', 'G06F3/0619', 'G06F3/064', 'G06F3/0659', 'G06N3/063', 'G06N3/08', 'G06F3/062', 'G06F3/065', 'G06F3/067', 'G06N10/40', 'G06N3/044', 'G06N3/045']"
US20240386015A1,Composite symbolic and non-symbolic artificial intelligence system for advanced reasoning and semantic search,"A semantic search system integrates with an AI platform to provide advanced search capabilities by leveraging automatically generated ontologies and knowledge graphs. The system employs natural language processing, machine learning, and large language models to create, update, and align ontologies from diverse data sources. It supports context-aware query interpretation, personalized results, and complex reasoning by incorporating user context, feedback, and domain knowledge. The system optimizes search performance and efficiency through indexing techniques, distributed computing, and continuous learning. With a modular architecture and scalable infrastructure, the semantic search system enables users to retrieve relevant, meaningful, and context-specific information from vast amounts of structured and unstructured data. The integration of the semantic search system with the AI platform's components, such as knowledge graphs and model blending, enhances the platform's overall reasoning, decision-making, and problem-solving capabilities, empowering users with intelligent and intuitive search experiences across various domains and applications.","['G06F40/30', 'G06F16/245', 'G06F16/248', 'G06F16/9024', 'G06N5/022', 'G06N5/04']"
US12204869B2,Natural language understanding for visual tagging,A tag characterizing a portion of a multi-view interactive digital media representation (MVIDMR) may be determined by applying a grammar to natural language data. The MVIDMR may include images of an object and may be navigable in one or more dimensions. An object model location for the tag identifying a location within a three-dimensional object model may be determined by applying the grammar to the natural language data. The tag may then be applied to the MVIDMR by associating it with two or more of the images at positions determined based on the object model location.,"['G06F40/211', 'G06F40/40', 'G06F40/284', 'G06F40/30', 'G06T7/77']"
US10347256B2,Channel-compensated low-level features for speaker recognition,"A system for generating channel-compensated features of a speech signal includes a channel noise simulator that degrades the speech signal, a feed forward convolutional neural network (CNN) that generates channel-compensated features of the degraded speech signal, and a loss function that computes a difference between the channel-compensated features and handcrafted features for the same raw speech signal. Each loss result may be used to update connection weights of the CNN until a predetermined threshold loss is satisfied, and the CNN may be used as a front-end for a deep neural network (DNN) for speaker recognition/verification. The DNN may include convolutional layers, a bottleneck features layer, multiple fully-connected layers and an output layer. The bottleneck features may be used to update connection weights of the convolutional layers, and dropout may be applied to the convolutional layers.","['G10L17/20', 'G10L17/02', 'G10L17/04', 'G10L17/18', 'G10L19/028']"
US12241953B2,Systems and methods for accelerated magnetic resonance imaging (MRI) reconstruction and sampling,"The following relates generally to accelerated magnetic resonance imaging (MRI) reconstruction. In some embodiments, a MRI machine learning algorithm is trained based on reference MRI data in non-Cartesian k-space. During the training, at each iteration of a plurality of iterations: (i) a non-Cartesian sampling trajectory ω may be optimized under the physical constraints, and/or (ii) an image reconstructor may be jointly iteratively optimized. Examples of the image reconstructor include a convolutional neural network (CNN) denoiser, a model-based deep learning (MoDL) image reconstructor, iterative image reconstructor, a regularizer, and an invertible neural network.","['G01R33/4826', 'G01R33/5608', 'G06T11/008', 'G06T5/20', 'G06T5/70', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2210/41']"
US11090017B2,Generating synthesized projection images for 3D breast tomosynthesis or multi-mode x-ray breast imaging,"Methods and systems for medical imaging including synthesizing virtual projections from acquired real projections and generating reconstruction models and images based on the synthesized virtual projections and acquired real projections. For example, first x-ray imaging data is generated from a detected first x-ray emission at a first angular location and second x-ray imaging data is generated from a detected second x-ray emission at a second angular location. Based on at least the first x-ray imaging data and the second x-ray imaging data, third x-ray imaging data for a third angular location relative to the breast may be synthesized. An image of the breast may be displayed or generated from the third x-ray imaging data.","['A61B6/502', 'A61B5/7267', 'A61B6/025', 'A61B6/032', 'A61B6/4028', 'A61B6/5235', 'A61B6/54', 'G06T11/003', 'G06T11/006', 'G06T5/50', 'G06T7/0012', 'G06T7/70', 'G06T2207/10081', 'G06T2207/10112', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30068', 'G06T2207/30168']"
US20220253734A1,Machine learning methods to optimize concrete applications and formulations,A method comprising: pulling a set of customer data and augment it with data sets designed to optimized machine learning operations; Selecting specified machine learning techniques from a specified machine learning database; taking into account a set of worksite context parameters; and optimizing and adjusting a concrete mix in real time to be able to deliver concrete products that meet requirements of project.,"['G06N7/005', 'G01N33/383', 'G06N7/01', 'G06F18/217', 'G06F18/24155', 'G06K9/6262', 'G06K9/6278', 'G06N20/20', 'G06N3/045', 'G06N3/084']"
US11907637B2,"Image processing method and apparatus, and storage medium","The present disclosure provides an image processing method and apparatus, and an electronic device, and relates to the field of artificial intelligence (AI). The method includes: obtaining an input image and extracting region features of image regions in the input image to obtain a first image feature; processing pixels in the first image feature according to a predetermined rule, and determining a second image feature according to the processed pixels; and determining, based on the second image feature and at least one word vector that is determined for the input image, word vectors corresponding to the region features of the image regions in the first image feature at different moments, predicting positions of the word vectors in a text description, and forming the text description corresponding to the input image according to the word vectors and the positions.","['G06F40/30', 'G06V10/40', 'G06F40/10', 'G06F18/214', 'G06F18/29', 'G06F40/40', 'G06V10/50', 'G06V10/82', 'G06V10/95']"
US20210396842A1,Multi-scale inspection and intelligent diagnosis system and method for tunnel structural defects,"A multi-scale inspection and intelligent diagnosis system and method for tunnel structural defects includes: a traveling section; a supporting section, disposed on the traveling section, and including a rotatable telescopic platform, where two mechanical arms working in parallel are disposed on the rotatable telescopic platform; an inspection section, mounted on the supporting section, and configured to perform multi-scale inspection on surface defects and internal defects in different depth ranges of a same position of a tunnel structure, and transmit inspected defect information to a control section; and the control section, configured to: construct a deep neural network-based defect diagnosis model; construct a data set by using historical surface defect and internal defect information, and train the deep neural network-based defect diagnosis model; and receive multi-scale inspection information in real time, and automatically recognize types, positions, contours, and dielectric attributes of the internal and surface defects.","['G01S7/41', 'B25J15/0019', 'B25J19/021', 'B25J5/005', 'B25J5/007', 'B25J9/161', 'B25J9/1697', 'G01M3/38', 'G01N21/88', 'G01N23/203', 'G01N29/043', 'G01N29/0618', 'G01N29/069', 'G01N29/225', 'G01N29/265', 'G01N29/4427', 'G01N29/4481', 'G01S13/862', 'G01S13/865', 'G01S13/885', 'G01S15/88', 'G01S17/88', 'G01S7/417', 'G05D1/0212', 'G05D1/646', 'G06N3/045', 'G06N3/08', 'B25J9/1625', 'F16L2101/30', 'G01N2223/628', 'G01N2223/646', 'G01N2291/0289', 'G05B2219/37206', 'G05B2219/39311', 'G05B2219/40298', 'G05B2219/40307', 'G05B2219/45066', 'G06N3/084']"
US20220276914A1,Interface for multiple processors,"Apparatuses, systems, and techniques to interface with an accelerator. In at least one embodiment, an application provides workloads to a logical device, and the logical device distributes the workloads across a plurality of accelerators.","['G06F9/544', 'G06F9/541', 'G06F9/4881', 'G06F9/5027']"
US11374952B1,Detecting anomalous events using autoencoders,"Techniques for monitoring a computing environment for anomalous activity are presented. An example method includes receiving a request to invoke an action within a computing environment, with the request including a plurality of request attributes and a plurality of contextual attributes. A normalcy score is generated for the received request by encoding the received request into a code in latent space of an autoencoder, reconstructing the request from the code, and generating a probability distribution indicating a likelihood that the reconstructed request attributes exist in a data set of non-anomalous activity. Based on the calculated normalcy score, one or more actions are taken to process the request such that execution of non-anomalous requests is allowed, and execution of potentially anomalous requests may be blocked pending confirmation.","['H04L63/1416', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'H04L63/1425', 'H04L63/0227']"
WO2019179285A1,"Speech recognition method, apparatus and device, and storage medium","Disclosed are a speech recognition method, apparatus and device, which fall within the field of speech recognition. The method comprises: acquiring speech information (201); determining start and end positions of a candidate speech segment in the speech information by means of a weighted finite state transducer network (202); capturing the candidate speech segment from the speech information according to the start and end positions of the candidate speech segment (203); and inputting the candidate speech segment into a machine learning model, and detecting whether the candidate speech segment contains a pre-set keyword by means of the machine learning model (204). A candidate speech segment subjected to coarse positioning of a weighted finite state transducer network is checked by means of a machine learning model to determine whether the candidate speech segment contains a pre-set keyword, thereby solving the problem in the relevant art that false wake-up occurs on account that speech information without semantics may be recognized as speech information with semantics, and improving the accuracy of speech recognition.","['G10L15/02', 'G06N3/045', 'G06N7/01', 'G10L15/04', 'G10L15/05', 'G10L15/08', 'G10L15/22', 'G10L25/30', 'G10L15/142', 'G10L15/16', 'G10L2015/025', 'G10L2015/088', 'G10L2015/223']"
US10339921B2,Multichannel raw-waveform neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using neural networks. One of the methods includes receiving, by a neural network in a speech recognition system, first data representing a first raw audio signal and second data representing a second raw audio signal, the first raw audio signal and the second raw audio signal for the same period of time, generating, by a spatial filtering convolutional layer in the neural network, a spatial filtered output the first data and the second data, generating, by a spectral filtering convolutional layer in the neural network, a spectral filtered output using the spatial filtered output, and processing, by one or more additional layers in the neural network, the spectral filtered output to predict sub-word units encoded in both the first raw audio signal and the second raw audio signal.","['G10L15/16', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G10L15/34', 'G10L15/20', 'G10L2021/02082', 'G10L21/0208']"
US12273220B2,Fifth generation (5G) new radio channel equalization,"Apparatuses, systems, and techniques to perform signal processing operations in a fifth generation (“5G”) radio signal. In at least one embodiment, one or more processors equalize, in parallel, one or more 5G radio signals.","['H04L25/03159', 'H04L25/0256', 'H04L25/0246', 'H04L25/0254', 'H04L25/03006', 'H04L25/03968', 'H04L2025/03426', 'H04L2025/03522']"
US11412225B2,Method and apparatus for image processing using context-adaptive entropy model,"Disclosed herein is a context-adaptive entropy model for end-to-end optimized image compression. The entropy model exploits two types of contexts. The two types of contexts are a bit-consuming context and a bit-free context, respectively, and these contexts are classified depending on the corresponding context requires the allocation of additional bits. Based on these contexts, the entropy model may more accurately estimate the distribution of each latent representation using a more generalized form of entropy models, thus improving compression performance.","['H04N19/91', 'H04N19/13', 'H04N19/149', 'H04N19/184', 'H04N19/196']"
CN106445939B,"Image retrieval, image information acquisition and image identification method, device and system","The application discloses an image retrieval method and device, a method and device for acquiring image information, an image identification method and device, an image identification system, a method and device for calculating an image characteristic value, and an electronic device. The image retrieval method comprises the following steps: extracting local features of an image to be retrieved; calculating the characteristic value of the local characteristic by adopting a pre-trained deep self-coding network model; matching the characteristic values with characteristic values of registered images in an image retrieval database; and selecting the registered image meeting the preset conditions as the retrieval result of the image to be retrieved according to the matching result. By adopting the method, the distance information and the discrimination capability between the characteristic values can be effectively maintained in the process of compressing and representing the local characteristics by the deep self-coding network, so that the accuracy of image retrieval can be effectively improved, the workload of rearrangement and filtration is reduced, and the retrieval efficiency is improved.","['G06F16/5838', 'G06F16/00', 'G06F16/50']"
US11790934B2,Deep learning based method and system for processing sound quality characteristics,"The present invention provides a deep learning based method and system for processing sound quality characteristics. The method comprises: obtaining data characteristics of an audio data to be processed by extracting features from user preference data including the audio data to be processed; based on the data characteristics, generating a sound quality processing result of the audio to be processed by using a trained baseline model; wherein the baseline model is a neural network model trained by using audio data behavioral data, and other relevant data from multiple users or a single user.","['G10L25/60', 'G06N3/04', 'G06N3/08', 'G10L15/063', 'G10L21/007', 'G10L21/0232', 'G10L25/30', 'G10L25/51', 'G10L25/84', 'H03G3/3005', 'H03G3/32', 'H03G5/165']"
CN108875608B,Motor vehicle traffic signal identification method based on deep learning,"The invention discloses a motor vehicle traffic signal identification method based on deep learning, which comprises the following specific steps: step one, pretreatment; secondly, positioning a traffic signal lamp; step three, identifying traffic signal lamps; step four, obtaining a result: and obtaining a final identification result through the first step to the third step, and representing the signal lamp state information of the final identification result by using a three-dimensional vector. The method adopts the convolutional neural network to position the traffic signal lamp, the positioning precision is higher, the acquired image is directly input into the trained network, the positioning is more convenient and faster, and the robustness and the generalization performance are better; the 10-layer convolutional neural network with the compression and expansion module greatly reduces the parameters of the network and reduces the size of a network model under the condition of ensuring the identification precision; the invention can not only identify the color of the traffic light, but also give the identification result of the direction and the color by combining all directions, and is suitable for identifying most motor vehicle traffic signals.","['G06V20/584', 'G06F18/214', 'G06F18/2411']"
US10852902B2,Automatic tagging of objects on a multi-view interactive digital media representation of a dynamic entity,"Various embodiments of the present disclosure relate generally to systems and methods for automatic tagging of objects on a multi-view interactive digital media representation of a dynamic entity. According to particular embodiments, the spatial relationship between multiple images and video is analyzed together with location information data, for purposes of creating a representation referred to herein as a multi-view interactive digital media representation for presentation on a device. Multi-view interactive digital media representations correspond to multi-view interactive digital media representations of the dynamic objects in backgrounds. A first multi-view interactive digital media representation of a dynamic object is obtained. Next, the dynamic object is tagged. Then, a second multi-view interactive digital media representation of the dynamic object is generated. Finally, the dynamic object in the second multi-view interactive digital media representation is automatically identified and tagged.","['G06T15/205', 'G06F16/5866', 'G06F16/7867', 'G06F3/0481', 'G06K9/00664', 'G06K9/22', 'G06V20/10']"
US10346347B2,Field-programmable crossbar array for reconfigurable computing,"For decades, advances in electronics were directly related to the scaling of CMOS transistors according to Moore's law. However, both the CMOS scaling and the classical computer architecture are approaching fundamental and practical limits. A novel memory-centric, reconfigurable, general purpose computing platform is proposed to handle the explosive amount of data in a fast and energy-efficient manner. The proposed computing architecture is based on a single physical resistive memory-centric fabric that can be optimally reconfigured and utilized to perform different computing and data storage tasks in a massively parallel approach. The system can be tailored to achieve maximal energy efficiency based on the data flow by dynamically allocating the basic computing fabric to storage, arithmetic, and analog computing including neuromorphic computing tasks.","['G06F15/7867', 'G11C13/0002', 'G11C7/1006', 'H03K19/177', 'G11C2213/70', 'G11C2213/77', 'Y02D10/00', 'Y02D10/12', 'Y02D10/13']"
CN109635882B,A salient object detection method based on multi-scale convolutional feature extraction and fusion,"The invention relates to a salient object detection method based on multi-scale convolution feature extraction and fusion, which comprises the steps of firstly enhancing data, simultaneously processing a color image and a corresponding artificial labeling image, and increasing the data volume of a training data set; extracting multi-scale features, and performing channel compression to optimize the computing efficiency of the network; then, fusing multi-scale features to obtain a predicted saliency map; finally, the optimal parameters of the model are learned by solving the minimum cross entropy loss; and finally, predicting the salient objects in the image by using the trained model network. The invention can obviously improve the detection precision of the obvious object.","['G06F18/253', 'G06F18/214', 'G06N3/045', 'G06N3/048']"
US12017387B2,Systems and methods for mass customization,"A method to reproduce an original object includes receiving a 3D model of the original object; forming a reformable master shape from the 3D model by using a computer controlled shape actuator; impressing the reformable master shape into a reformable material to form a custom mold, the reformable material having a material state that is reversible between a solid condition stable force-resisting state and a flowable state by addition of a transition liquid; pouring a material into the custom mold while the reformable material is in the stable force-resisting state and fabricating a copy; adding the transition liquid to the reformable material to change the state of the reformable material from the stable force-resisting state to the flowable state; and reusing the reformable material to form another custom sole once the reformable material is in the flowable state.","['A43B13/181', 'A43B3/34', 'A43D1/00', 'A43D1/02', 'A43D999/00', 'A61B5/1038', 'A61B5/112', 'A61B5/6807', 'B29C33/3835', 'B29D35/0009', 'B29D35/122', 'B33Y80/00', 'G16H50/70', 'A43D2200/60', 'B33Y10/00', 'Y10S12/00']"
EP3855741A1,"Interpolation filter training method and device, video image encoding method, video image decoding method, encoder, and decoder","Embodiments of this application disclose an interpolation filter training method and apparatus, a video picture encoding and decoding method, an encoder, and a decoder. According to the training method, a first sub-pixel picture obtained through interpolation by using a conventional interpolation filter is used as label data, to train a second interpolation filter, so that the second interpolation filter obtained through training can be directly used for a pixel value, obtained through interpolation, of a first fractional pixel position. Therefore, the label data is more accurate, and coding performance of a video picture is improved. According to the encoding method, during inter prediction, a target interpolation filter used for the current encoding picture block is determined from a set of candidate interpolation filters, and the encoder selects, according to content of the current encoding picture block, an appropriate interpolation filter to perform an interpolation operation. This can obtain a prediction block with higher prediction accuracy, reduce a quantity of bitstreams, and increase a compression rate of the video picture.","['H04N19/117', 'H04N19/51', 'H04N19/109', 'H04N19/147', 'H04N19/176', 'H04N19/184', 'H04N19/42', 'H04N19/503', 'H04N19/513', 'H04N19/587', 'H04N19/59', 'H04N19/80', 'H04N19/82']"
US12304166B2,Systems and methods for mass customization,A footwear having a sole customized to a wearer's anatomy by receiving a foot model; generating an elevated foot model with a heel at a predetermined heel height from a ground and determining a structure to support a foot arch and a ball area of the foot model; and fabricating a high heel sole with the optimized structure to support the foot.,"['A43B13/181', 'A43B13/187', 'A43B3/34', 'A43B7/088', 'A43D1/02', 'A61B5/1038', 'A61B5/6807', 'A61B5/7282', 'B29C33/3835', 'B29D35/12', 'B29D35/122', 'B29D35/128']"
US10698558B2,Automatic tagging of objects on a multi-view interactive digital media representation of a dynamic entity,"Various embodiments of the present disclosure relate generally to systems and methods for automatic tagging of objects on a multi-view interactive digital media representation of a dynamic entity. According to particular embodiments, the spatial relationship between multiple images and video is analyzed together with location information data, for purposes of creating a representation referred to herein as a multi-view interactive digital media representation for presentation on a device. Multi-view interactive digital media representations correspond to multi-view interactive digital media representations of the dynamic objects in backgrounds. A first multi-view interactive digital media representation of a dynamic object is obtained. Next, the dynamic object is tagged. Then, a second multi-view interactive digital media representation of the dynamic object is generated. Finally, the dynamic object in the second multi-view interactive digital media representation is automatically identified and tagged.","['G06V20/70', 'G06F16/5866', 'G06F16/587', 'G06F16/7867', 'G06F3/0481', 'G06K9/00664', 'G06K9/22', 'G06T15/205', 'G06V10/17', 'G06V20/10']"
US11790489B2,Systems and method of training networks for real-world super resolution with unknown degradations,"A method and apparatus are provided. The method includes generating a dataset for real-world super resolution (SR), training a first generative adversarial network (GAN), training a second GAN, and fusing an output of the first GAN and an output of the second GAN.","['G06T3/4046', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06T3/4053', 'G06T2207/20084']"
CN110348487B,A kind of hyperspectral image compression method and device based on deep learning,"The invention discloses a hyperspectral image compression method based on deep learning, which comprises the steps of firstly, selecting a training image, randomly cutting the size of the training image into 32 x 32 as a training set, and then inputting the training set into a built compression network model for training to obtain a compression model comprising an encoding network, a quantization network and a decoding network. The image to be compressed is input into a coding network, a coded feature map is obtained according to the calculation result of the coding network, the obtained feature map is input into a quantization network for quantization calculation to obtain a code stream, the quantized result is input into a decoding network, and the reconstructed image is obtained through calculation of a decoding network model. The invention can realize the compression of the hyperspectral image and improve the compression effect.","['G06F18/214', 'G06N3/045', 'G06T9/00', 'G06T9/008', 'G06T2207/20081']"
US20220224968A1,"Screen Projection Method, Electronic Device, and System","A screen projection method includes synthesizing, by a first electronic device first image data and second image data based on a selected screen projection manner to generate synthesized image data, and outputting, by the first electronic device, the synthesized image data to a second electronic device by using the screen projection port to trigger the second electronic device to display synthesized images corresponding to the synthesized image data based on the selected screen projection manner.","['G06F3/1423', 'H04N21/4312', 'G06F3/1454', 'G09G5/026', 'H04N21/4122', 'H04N21/43079', 'H04N21/4316', 'H04N21/43615', 'H04N21/43635', 'H04N21/43637', 'H04N21/4438', 'H04N21/4788', 'G09G2340/145', 'G09G2354/00']"
US11494417B2,Automated email classification in an information management system,"An improved information management system is described herein that can use artificial intelligence to classify data files (e.g., emails, documents, audio files, video files, etc.) and/or surface in a user interface the classification assigned to the data files. For example, a lightweight training or a heavyweight training can be employed to train classifiers to classify the data files. Use of artificial intelligence to classify data files may reduce the amount of computing resources that the information management system allocates to the data file review process because an auditor may be able to quickly identify those data files that meet the desired criteria using the classification and only request access to those data files. Thus, the information management system may be able to allocate more computing resources to normal or routine tasks, ensuring that such tasks are completed and/or completed in an appropriate amount of time.","['G06F16/285', 'G06N20/00', 'G06F16/13', 'G06F16/906', 'G06N5/04', 'H04L51/42']"
US11704775B2,Bright spot removal using a neural network,A method for image capture includes identifying a bright spot in an image. A neural network is used to recover details in bright spot area through a trained de-noising process. Post-processing of the image is conducted to match image parameters of recovered details in the bright spot area to another area of the image.,"['G06T5/77', 'G06T5/70', 'G06T5/002', 'G06N3/08', 'G06T3/4046', 'G06T5/005', 'G06T5/60', 'G06T5/94', 'G06T7/11', 'H04N23/64', 'H04N23/70', 'H04N23/71', 'H04N23/81', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US11423253B2,Systems and methods for generating graphical user interfaces,"A system for generating graphical user interfaces. The system may include processors and storage devices storing instructions. The instructions may configure the one or more processors to perform operations including identifying a plurality of attributes from an image captured with a client device, identifying a plurality of first results based on the attributes, generating a first graphical user interface for display in the client device. The first graphical user interface may include a plurality of result icons corresponding to a subset of the first results having confidence scores above a threshold, a plurality of filter icons displaying options, and a search button. The operations may also include receiving a selection of at least one of the result icons or at least one of the filter icons, performing a search, based on the selection, and generating a second graphical user interface.","['G06K9/6253', 'G06F8/38', 'G06F16/24578', 'G06F16/55', 'G06F16/9535', 'G06F16/9538', 'G06F18/40', 'G06F3/04817', 'G06F3/0482', 'G06F3/04847', 'G06F9/451', 'G06V10/20', 'G06V10/945', 'G06V20/20', 'G06F8/65', 'G06V10/32', 'G06V10/40', 'G06V2201/08']"
US11755916B2,System and method for improving deep neural network performance,"An improved computer implemented method and corresponding systems and computer readable media for improving performance of a deep neural network are provided to mitigate effects related to catastrophic forgetting in neural network learning. In an embodiment, the method includes storing, in memory, logits of a set of samples from a previous set of tasks (D1); and maintaining classification information from the previous set of tasks by utilizing the logits for matching during training on a new set of tasks (D2).","['G06N3/084', 'G06F18/24', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06N7/01', 'G06V10/764', 'G06V10/7788', 'G06V10/82']"
US12131056B2,Providing data management as-a-service,"Providing data management as-a-service, including: presenting one or more available data services to a user; receiving a selection of one or more selected data services; and applying, in dependence upon the one or more selected data services, one or more data services policies to a dataset associated with the user.","['G06F3/067', 'G06F3/0604', 'G06F3/0605', 'G06F3/0631', 'G06F3/0632', 'G06F3/0637', 'G06F3/0655', 'G06F3/0676', 'G06F3/0679', 'H04L41/0894', 'H04L41/0895', 'H04L41/5019', 'H04L41/5051', 'H04L63/102', 'H04L67/1097', 'G06F3/0617', 'H04L63/0428', 'H04L63/10', 'H04L63/145']"
CN112083498B,Multi-wave earthquake oil and gas reservoir prediction method based on deep neural network,"The invention discloses a multi-wave seismic oil and gas reservoir prediction method based on a deep neural network, which comprises the following steps: firstly, aiming at original data obtained from a longitudinal and transverse wave seismic attribute set, optimizing seismic attributes by adopting a cluster analysis method of particle swarm optimization and a kernel principal component analysis method, removing redundant information, and highlighting the characteristics of a multi-wave seismic oil and gas reservoir so as to obtain better deep neural network sample data; then, learning the obtained sample data through a deep neural network model and carrying out simulation prediction to obtain an oil and gas reservoir evaluation graph; and finally, performing image enhancement processing on the oil and gas reservoir evaluation graph to improve the detail information and edge identification degree of the image, thereby increasing the definition of the image. In the prediction of the oil and gas reservoir, the method can improve the description precision of the earthquake oil and gas reservoir and provides a new way for the identification and prediction of the oil and gas reservoir.","['G01V1/50', 'G01V2210/6169', 'G01V2210/624']"
CN108872988B,Inverse synthetic aperture radar imaging method based on convolutional neural network,"The invention discloses an inverse synthetic aperture radar imaging method based on a convolutional neural network, which comprises the following steps of: s1, constructing an inverse synthetic aperture radar data set; s2, obtaining a primary image through two-dimensional Fourier transform; s3, constructing a convolutional neural network; s4, constructing a training set and a verification set of the convolutional neural network; s5, updating the parameters of the convolutional neural network by adopting a supervised learning method; and S6, utilizing the trained convolutional neural network to realize inverse synthetic aperture radar down-sampling data imaging. The convolutional neural network can extract more characteristic information and effectively avoid the gradient dispersion phenomenon, so that a higher-quality inverse synthetic aperture radar image is reconstructed.","['G01S13/9064', 'G01S13/904']"
US20240265233A1,Scalable neural network processing engine,"Embodiments relate to a neural processor circuit with scalable architecture for instantiating one or more neural networks. The neural processor circuit includes a data buffer coupled to a memory external to the neural processor circuit, and a plurality of neural engine circuits. To execute tasks that instantiate the neural networks, each neural engine circuit generates output data using input data and kernel coefficients. A neural processor circuit may include multiple neural engine circuits that are selectively activated or deactivated according to configuration data of the tasks. Furthermore, an electronic device may include multiple neural processor circuits that are selectively activated or deactivated to execute the tasks.","['G06N3/04', 'G06F1/3296', 'G06F13/28', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06F2213/28', 'Y02D10/00']"
TWI855202B,Apparatus and method for motion blur with a dynamic quantization grid,"Apparatus and method for processing motion blur operations. For example, one embodiment of a graphics processing apparatus comprises: a bounding volume hierarchy (BVH) generator to build a BVH comprising hierarchically-arranged BVH nodes based on input primitives, at least one BVH node comprising one or more child nodes; and motion blur processing hardware logic to determine motion values for a quantization grid based on motion values of the one or more child nodes of the at least one BVH node and to map linear bounds of each of the child nodes to the quantization grid.","['G06T13/20', 'G06T17/10', 'G06T1/20', 'G06T15/005', 'G06T15/06', 'G06T15/08', 'G06T15/80', 'G06T17/005', 'G06T7/254', 'G06T2200/28', 'G06T2207/20201', 'G06T2210/12']"
US20230274839A1,Systems and methods for improving disease diagnosis,"The present invention relates to systems and methods for improving the accuracy of disease diagnosis and to associated diagnostic tests involving the correlation of measured analytes with binary outcomes (e.g., not-disease or disease), as well as higher-order outcomes (e.g., one of several phases of a disease). Methods of the present invention use biomarker sets, preferably those with orthogonal functionality, to obtain concentration and proximity score values for disease and non-disease states. The biomarker a set's proximity scores are graphed on an orthogonal grid, with one dimension for each biomarker. The proximity scores and orthogonal gridding is then used to calculate a disease state or non-disease state diagnosis for the patient.","['G16H50/20', 'G16B5/00', 'G16B5/20', 'G16H50/30', 'G16H50/50', 'Y02A90/10']"
US10985951B2,Integrating Volterra series model and deep neural networks to equalize nonlinear power amplifiers,The nonlinearity of power amplifiers (PAs) has been a severe constraint in performance of modern wireless transceivers. This problem is even more challenging for the fifth generation (5G) cellular system since 5G signals have extremely high peak to average power ratio. Nonlinear equalizers that exploit both deep neural networks (DNNs) and Volterra series models are provided to mitigate PA nonlinear distortions. The DNN equalizer architecture consists of multiple convolutional layers. The input features are designed according to the Volterra series model of nonlinear PAs. This enables the DNN equalizer to effectively mitigate nonlinear PA distortions while avoiding over-fitting under limited training data. The non-linear equalizers demonstrate superior performance over conventional nonlinear equalization approaches.,"['H04L25/03165', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'H03F1/32', 'H03F3/20', 'H04B1/16', 'G06N3/044', 'G06N3/048', 'H03F2200/451', 'H04L25/0224']"
US11674384B2,Controller optimization via reinforcement learning on asset avatar,A method can include receiving sensor data from a system; encoding the sensor data to a latent space representation via a trained encoder; generating a control action using the latent space representation; and issuing an instruction that corresponds to the control action for control of the system.,"['E21B47/12', 'G05B13/027', 'E21B43/2607', 'E21B47/008', 'G05B13/041', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'E21B2200/20', 'E21B2200/22']"
JP2024054204A,"Neural network learning method, program, medical image processing method, and medical device","To improve the image quality of a medical image.SOLUTION: A learning method of a neural network includes the step of making a neural network perform learning by using a data set of an input image being low-quality data and a target image being high-quality data. The target image is generated by acquiring a plurality of different images by executing a plurality of different reconstructions to medical data collected from a subject, extracting different feature regions from the plurality of acquired images and combining the extracted different feature regions into one image.SELECTED DRAWING: Figure 2A","['G06T5/70', 'G06F18/2115', 'G06F18/214', 'G06T11/008', 'G06T5/50', 'G06T5/60', 'G06V10/30', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/10104', 'G06T2207/10108', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30008', 'G06T2207/30061', 'G06T2207/30096', 'G06T2211/441', 'G06V2201/03']"
CN111598867B,"Method, apparatus, and computer-readable storage medium for detecting specific facial syndrome","The invention provides a method, a device and a computer readable storage medium for detecting specific facial syndromes, wherein the method comprises the following steps: acquiring a face image of an object to be detected; determining at least one key area image of the face image; inputting the face image into a trained global detection model to obtain a global detection result; inputting at least one key area image into a trained local detection model to obtain at least one local detection result; and determining the target detection probability that the object to be detected has the specific facial syndrome according to the global detection result and the at least one local detection result. By using the method, the rapid detection of the specific facial syndrome can be automatically completed without complex measuring equipment, the initial detection difficulty of the specific facial syndrome patient is obviously reduced, and the detection accuracy is improved.","['G06T7/0012', 'G06F18/25', 'G06N3/045', 'G06N3/08', 'G06T7/11', 'G06V40/169', 'G06V40/171', 'G06F18/259', 'G06T2207/30201']"
US11217076B1,Camera tampering detection based on audio and video,"Tampering with an audio/video (A/V) recording and communication device is detected based on audio data captured by a microphone and/or video data captured by a camera of the A/V recording and communication device. The detection of the tampering may be based on, for example, processing of the audio and/or video data. Additional data may be collected and/or other actions taken in response to detection of the tampering.","['G08B29/046', 'G06N20/00', 'G06N3/08', 'G08B13/1672', 'G08B13/19613', 'G08B13/19695', 'G10L15/02', 'G10L25/51', 'H04N7/181', 'H04N7/188', 'G08B29/186', 'G10L15/16', 'G10L15/20', 'G10L25/24', 'G10L25/30']"
US12210778B2,Sizing a virtual storage system,"Sizing a virtual storage system, including: determining a change to one or more resource demands; determining, based on the change to the one or more resource demands, one or more modifications to one or more virtual components included as part of a virtual storage system architecture of a virtual storage system within a cloud computing environment; and initiating, responsive to the change to the one or more resource demands, the one or more modifications to the one or more virtual components included as part of the virtual storage system architecture of the virtual storage system, including replacing one or more of the virtual components with a higher performance virtual component.","['G06F3/0605', 'G06F3/0619', 'G06F3/0631', 'G06F3/0653', 'G06F3/0664', 'G06F3/067', 'G06F3/0688', 'G06F9/5022', 'G06F9/5077']"
US11875576B2,Traffic sign recognition method based on lightweight neural network,"Provided is a traffic sign recognition method based on a lightweight neural network, which including: a lightweight neural network model is constructed for training and pruning to obtain a lightweight neural network model; the lightweight neural network model comprises a convolution feature extraction part and a classifier part; the convolution feature extraction part includes one layer of conventional 3×3 convolution and 16 layers of separable asymmetric convolution. The classifier part includes three layers of separable full connection modules.","['G06F18/241', 'G06V20/582', 'G06N3/045', 'G06N3/082', 'G06V10/26', 'G06V10/32', 'G06V10/764', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'Y02T10/40']"
CN111964908B,Bearing fault diagnosis method under variable working condition based on multi-scale weight distribution convolutional neural network model,"The invention discloses a variable working condition bearing fault diagnosis method based on MWDCNN, and aims to provide a variable working condition bearing fault diagnosis method which is strong in variable working condition adaptability and high in accuracy. The method comprises the following steps: setting the corresponding relation between the fault type and the label of the data set to be diagnosed, and dividing a training set and a testing set; constructing a multi-scale weight distribution convolutional neural network fault diagnosis model; and training the multi-scale weight distribution convolutional neural network fault diagnosis model by using the training set, and then performing fault diagnosis on the test set by using the trained multi-scale weight distribution convolutional neural network fault diagnosis model to output the type of the bearing fault. The multi-scale weight distribution convolutional neural network fault diagnosis model is composed of a feature extraction module, a multi-scale feature connection module and a classification module. The diagnosis method of the invention has the advantages of noise resistance, high load-variable self-adaptability and high accuracy.","['G01M13/045', 'G06F18/2415', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
CN109784474B,"Deep learning model compression method and device, storage medium and terminal equipment","The invention discloses a deep learning model compression method, a device, a storage medium and a terminal device, wherein the output of each layer of the deep learning model is calculated through a forward propagation algorithm, the output value of the deep learning model is finally obtained, and redundant parameters in the model are thinned by calculating the connection weight mean value of each node and deleting the nodes with the mean value of zero, so that the redundant parameters are removed. And the model precision is ensured through the loss function, and the model parameters are greatly reduced and the calculation amount in the training process is greatly reduced on the premise of ensuring that the model precision is not obviously reduced, so that the model can run on the edge computing equipment with limited resources. The deep learning model compression method solves the problem that the deep learning model is difficult to operate on resource-limited equipment due to the lack of a deep learning model compression method at present.",[]
US11816555B2,System and method for chaining discrete models,"Systems, computer program products, and computer-implemented methods for determining relationships between one or more outputs of a first model and one or more inputs of a second model that collectively represent a real world system, and chaining the models together. For example, the system described herein may determine how to chain a plurality of models by training an artificial intelligence system using the nodes of the models such that the trained artificial intelligence system predicts related output and input node connections. The system may then link related nodes to chain the models together. The systems, computer program products, and computer-implemented methods may thus, according to various embodiments, enable a plurality of discrete models to be optimally chained.","['G06N3/045', 'G06N3/044', 'G06N3/084', 'G06N5/04']"
US11238593B2,Multi-object image parsing using neural network pipeline,"Techniques are disclosed for parsing a source image, to identify segments of one or more objects within the source image. The parsing is carried out by an image parsing pipeline that includes three distinct stages comprising three respectively neural network models. The source image can include one or more objects. A first neural network model of the pipeline identifies a section of the source image that includes the object comprising a plurality of segments. A second neural network model of the pipeline generates, from the section of the source image, a mask image, where the mask image identifies one or more segments of the object. A third neural network model of the pipeline further refines the identification of the segments in the mask image, to generate a parsed image. The parsed image identifies the segments of the object, by assigning corresponding unique labels to pixels of different segments of the object.","['G06T7/11', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T3/4046', 'G06T7/194', 'G06V10/454', 'G06V10/56', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V40/10', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20112', 'G06T2207/30196']"
US8721530B2,Tendon-driven endoscope and methods of use,"A steerable, tendon-driven endoscope is described herein. The endoscope has an elongated body with a manually or selectively steerable distal portion and an automatically controlled, segmented proximal portion. The steerable distal portion and the segment of the controllable portion are actuated by at least two tendons. As the endoscope is advanced, the user maneuvers the distal portion, and a motion controller actuates tendons in the segmented proximal portion so that the proximal portion assumes the selected curve of the selectively steerable distal portion. By this method the selected curves are propagated along the endoscope body so that the endoscope largely conforms to the pathway selected. When the endoscope is withdrawn proximally, the selected curves can propagate distally along the endoscope body. This allows the endoscope to negotiate tortuous curves along a desired path through or around and between organs within the body.","['A61B1/00128', 'A61B1/00006', 'A61B1/00057', 'A61B1/0016', 'A61B1/0053', 'A61B1/0057', 'A61B1/01', 'A61B1/31', 'A61B5/065', 'A61B1/0058', 'A61B2034/301', 'A61B2034/741', 'A61B2034/742']"
EP3757789A1,Managed edge learning in heterogeneous environments,"Systems and methods are provided for managing machine learning processes within distributed and heterogeneous environments. The distributed and heterogeneous environments may include different types of devices that include different specifications, security, and privacy concerns. The devices participate in complex machine learning tasks while maintaining both privacy and autonomy. The systems and methods manage the lifecycle of how machine learning workloads are distributed.","['G06F9/5072', 'G06F18/214', 'G06F21/6245', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06N7/01']"
US11960984B2,Active learning framework for machine-assisted tasks,"An active learning framework is provided that employs a plurality of machine learning components that operate over iterations of a training phase followed by an active learning phase. In each iteration of the training phase, the machine learning components are trained from a pool of labeled observations. In the active learning phase, the machine learning components are configured to generate metrics used to control sampling of unlabeled observations for labeling such that newly labeled observations are added to a pool of labeled observations for the next iteration of the training phase. The machine learning components can include an inspection (or primary) learning component that generates a predicted label and uncertainty score for an unlabeled observation, and at least one additional component that generates a quality metric related to the unlabeled observation or the predicted label. The uncertainty score and quality metric(s) can be combined for efficient sampling of observations for labeling.","['G06N20/10', 'G06N3/047', 'G06N20/20', 'G06N3/045', 'G06N3/08']"
US9762611B2,Endpoint-based man in the middle attack detection using machine learning models,"A first node of a networked computing environment initiates each of a plurality of different types of man-in-the middle (MITM) detection tests to determine whether communications between first and second nodes of a computing network are likely to have been subject to an interception or an attempted interception by a third node. Thereafter, it is determined, by the first node, that at least one of the tests indicate that the communications are likely to have been intercepted by a third node. Data is then provided, by the first node, data that characterizes the determination. In some cases, one or more of the MITM detection tests utilizes a machine learning model. Related apparatus, systems, techniques and articles are also described.","['H04L63/1466', 'G06N20/00', 'G06N99/005', 'H04L63/123', 'H04L63/1425', 'H04L63/1433', 'H04L63/1475', 'H04L9/0643', 'H04W12/12', 'H04L2101/622', 'H04L61/103', 'H04L61/4511', 'H04L61/58']"
CN108734286B,Coordination and increased utilization of GPUs during inference,"A mechanism for facilitating inferred coordination and processing utilization of machine learning at an autonomous machine is described. As described herein, a method of an embodiment includes detecting information related to one or more tasks to be performed during training from a training data set related to a processor including a graphics processor. The method may further include analyzing the information to determine one or more portions of hardware associated with the processor that are capable of supporting the one or more tasks, and configuring the hardware to pre-select the one or more portions to perform the one or more tasks while other portions of the hardware remain available for other tasks.","['G06F9/46', 'G06N3/045', 'G06N3/0464', 'G06N3/063', 'G06N3/08', 'G06N3/09', 'G06N3/098', 'G06T1/20', 'G06N3/044', 'G06N3/084', 'Y02D10/00']"
US12353520B2,"Graphics security with synergistic encryption, content-based and resource management technology","Methods, apparatuses and system provide for technology that interleaves a plurality of verification commands with a plurality of copy commands in a command buffer, wherein each copy command includes a message authentication code (MAC) derived from a master session key, wherein one or more of the plurality of verification commands corresponds to a copy command in the plurality of copy commands, and wherein a verification command at an end of the command buffer corresponds to contents of the command buffer. The technology may also add a MAC generation command to the command buffer, wherein the MAC generation command references an address of a compute result.","['G06F21/105', 'G06F21/53', 'G06F21/602', 'G06F21/84', 'G06F8/65', 'G06F9/45558', 'G06F9/5027', 'G06N3/04', 'G06N3/08', 'G06T1/20', 'G06T1/60', 'H04L63/0428', 'H04L63/061', 'H04L9/085', 'H04L9/0866', 'H04L9/0891', 'H04L9/3242', 'H04L9/3247', 'H04L9/3263', 'G06F2009/45587', 'G06N3/063', 'H04L2209/603', 'H04L2463/081', 'H04L2463/101']"
US9842105B2,Parsimonious continuous-space phrase representations for natural language processing,"Systems and processes for natural language processing are provided. In accordance with one example, a method includes, at a first electronic device with one or more processors and memory, receiving a plurality of words, mapping each of the plurality of words to a word representation, and associating the mapped words to provide a plurality of phrases. In some examples, each of the plurality of phrases has a representation of a first type. The method further includes encoding each of the plurality of phrases to provide a respective plurality of encoded phrases. In some examples, each of the plurality of encoded phrases has a representation of a second type different than the first type. The method further includes determining a value of each of the plurality of encoded phrases and identifying one or more phrases of the plurality of encoded phrases having a value exceeding a threshold.","['G06F17/2785', 'G06F40/30', 'G06N3/088', 'G06F17/2705', 'G06F40/205', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G10L15/183']"
US11037072B2,Scalable complex event processing with probabilistic machine learning models to predict subsequent geolocations,"Provided is a process, including: obtaining a set of historical geolocations; segmenting the historical geolocations into a plurality of temporal bins; determining pairwise transition probabilities between a set of geographic places based on the historical geolocations; configuring a compute cluster by assigning subsets of the transition probabilities to computing devices in the compute cluster; receiving a geolocation stream indicative of current geolocations of individuals; selecting a computing device in the compute cluster in response to determining that the computing device contain transition probabilities for the received respective geolocation; selecting transition probabilities applicable to the received respective geolocation from among the subset of transition probabilities assigned to the selected computing device; predicting a subsequent geographic place based on the selected transition probabilities.","['G06N20/00', 'G06F16/29', 'G06N3/044', 'G06N3/0445', 'G06N7/005', 'G06N7/01']"
US12210417B2,Metadata-based recovery of a dataset,"Servicing I/O operations in a cloud-based storage system, including: receiving, by the cloud-based storage system, a request to write data to the cloud-based storage system; storing, in solid-state storage of the cloud-based storage system, the data; storing, in object storage of the cloud-based storage system, the data; detecting that at least some portion of the solid-state storage of the cloud-based storage system has become unavailable; identifying data that was stored in the portion of the solid-state storage of the cloud-based storage system that has become unavailable; retrieving, from object storage of the cloud-based storage system, the data that was stored in the portion of the solid-state storage of the cloud-based storage system that has become unavailable; and storing, in solid-state storage of the cloud-based storage system, the retrieved data.","['G06F11/1448', 'G06F16/2365', 'G06F3/0619', 'G06F3/064', 'G06F3/065', 'G06F3/0655', 'G06F3/067']"
US20240160387A1,Data Loss Management for Cloud-Based Storage Systems,"A distributed cloud-based storage system, where the distributed cloud-based storage system includes: receiving, by one or more storage controller applications of the cloud-based storage system, one or more storage operations; storing, among one or more cloud computing instances of the cloud-based storage system, the one or more storage operations; and distributing, among one or more cloud computing instances within respective one or more cloud computing environments within distinct geographic regions, one or more of the one or more storage operations.","['G06F3/067', 'G06F11/2071', 'G06F11/2092', 'G06F11/3034', 'G06F11/3409', 'G06F11/3447', 'G06F16/9035', 'G06F3/0607', 'G06F3/061', 'G06F3/0617', 'G06F3/0619', 'G06F3/0632', 'G06F3/064', 'G06F3/065', 'G06F3/0659', 'G06F3/0662', 'G06F3/0665', 'G06F3/0688', 'G06F9/45558', 'G06F9/5005', 'G06F9/545', 'H04L41/082', 'H04L67/1095', 'H04L67/1097', 'G06F2009/45562', 'G06F2009/4557', 'G06F2009/45595', 'G06F3/0658', 'Y02D10/00']"
US11178182B2,Automated access control management for computing systems,"Normalized access control policies associated with entities in an information technology (IT) infrastructure comprising a plurality of subsystems may be obtained based on a stored access control policy representation governing access to resources in the IT infrastructure. Based on the normalized access control policies, entity clusters associated with the entities may be determined. Further, derived access control policies corresponding to the at least one entity cluster may be determined. A set of non-compliant access control policies may be determined where the set of non-compliant access control policies may comprise: a subset of the normalized access control policies that are non-compliant with stated access control policies applicable to the entity clusters, and/or a subset of the derived access control policies that are non-compliant with the stated access control policies. Machine learning and/or Artificial Intelligence techniques may be used to determine, maintain, and audit policies for the IT infrastructure.","['H04L41/16', 'G06F8/38', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'H04L41/0894', 'H04L41/0895', 'H04L41/22', 'H04L41/40', 'H04L63/10', 'H04L63/102', 'H04L63/104', 'H04L63/20', 'G06F3/04817', 'G06F3/0482', 'G06N5/01', 'G06N5/046', 'H04L63/0263']"
RU2739896C1,Automated non-invasive assessment of poultry fertilization,"FIELD: agriculture.SUBSTANCE: group of inventions relates to automated non-invasive determination of poultry fertilization. Method comprises the following steps: sequential or parallel feeding a plurality of poultry eggs into an NMR apparatus, exposing poultry eggs to NMR measurement, for example, for generation of three-dimensional NMR image of at least part of each of said eggs, wherein said three-dimensional NMR image has spatial resolution in at least one measurement of 1.0 mm or less, preferably - 0.50 mm or less, wherein said egg part (14) comprises a germ disc of the corresponding egg, determining a fertilization prediction according to at least one of the following two procedures: (i) detecting at least one feature from each of said three-dimensional NMR images and using said at least one feature in a classifier based on the criteria for determining a fertility prediction, and (ii) using an in-depth training algorithm, and in particular an in-depth training algorithm based on convolutional neural networks, generative-adversarial networks, recurrent neural networks or neuron long-term memory networks.EFFECT: application of this group of inventions enables to treat a large number of eggs without damaging or changing eggs in any way.37 cl, 16 dwg","['A01K43/04', 'B07C5/344', 'G01N24/085', 'G01N33/08', 'G01R33/307', 'G01R33/3415', 'G01R33/483', 'G01R33/4835', 'G01R33/5608', 'G01R33/561', 'G01R33/5611']"
EP3798928A1,Deep learning implementations using systolic arrays and fused operations,"Disclosed embodiments relate to deep learning implementations using systolic arrays and fused operations. In one example, a processor includes fetch and decode circuitry to fetch and decode an instruction having fields to specify an opcode and locations of a destination and N source matrices, the opcode indicating the processor is to load the N source matrices from memory, perform N convolutions on the N source matrices to generate N feature maps, and store results of the N convolutions in registers to be passed to an activation layer, wherein the processor is to perform the N convolutions and the activation layer with at most one memory load of each of the N source matrices. The processor further includes scheduling circuitry to schedule execution of the instruction and execution circuitry to execute the instruction as per the opcode.","['G06F9/3867', 'G06F9/3001', 'G06F15/8046', 'G06F17/153', 'G06F9/30036', 'G06F9/30038', 'G06F9/30098', 'G06F9/3802', 'G06F9/3818', 'G06F9/382', 'G06F9/3836', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/048', 'G06N3/084']"
US11734169B2,Optimizing spool and memory space management,"A system establishes spools that have spool regions in first memory. The system communicates first spool insertions into the spools, and from the spools to the storage devices, to write into a first partition of second memory of the storage devices. The first spool insertions include data and are optimized towards a first spool insertion size. The system communicates second spool insertions into the spools, and from the spools to the storage devices, to write into a second partition of the second memory of the storage devices. The second spool insertions include metadata and are optimized towards a second spool insertion size.","['G06F12/0246', 'G06F11/108', 'G06F11/3034', 'G06F12/0207', 'G06F3/0605', 'G06F3/0608', 'G06F3/061', 'G06F3/0647', 'G06F3/0652', 'G06F3/0653', 'G06F3/0688', 'G06N3/02', 'G06F11/2094', 'G06F11/3433', 'G06F11/3485', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/1044', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208']"
US12066900B2,Managing disaster recovery to cloud computing environment,"Managing disaster recovery to a cloud computing environment, including: receiving recovery objectives associated with a dataset that is stored in a primary storage system; creating a cloud-based storage system; suspending the cloud-based storage system; and resuming, periodically and based on the recovery objectives, the cloud-based storage system, including refreshing a copy of the dataset that is maintained by the cloud-based storage system.","['G06F11/108', 'G06F11/1423', 'G06F11/1438', 'G06F11/1441', 'G06F11/1451', 'G06F11/1464', 'G06F11/1469', 'G06F11/2092', 'G06F11/2094', 'G06F11/3034', 'G06F11/3409', 'G06F11/3485', 'G06F2201/81', 'G06F2201/84']"
US12236110B2,Storage system with parallel writes,"A list of a available zones across respective SSD storage portions of a plurality of zoned storage devices of a storage system is maintained. Data is received from multiple sources, wherein the data is associated with processing a dataset, the dataset including multiple volumes and associated metadata. Shards of the data are determined such that each shard is capable of being written in parallel with the remaining shards. The shards are mapped to a subset of the available zones, respectively. The shards are written to the subset of the available zones in parallel.","['G06F3/0644', 'G06F3/0619', 'G06F3/0608', 'G06F3/061', 'G06F3/0613', 'G06F3/064', 'G06F3/0655', 'G06F3/0659', 'G06F3/0683', 'G06F3/0688']"
CN113256768B,Use text as avatar animation,"The present disclosure relates to using text as an avatar animation. The present invention provides a system and method for displaying an avatar in an animated manner. An exemplary method of animating an avatar includes, at an electronic device having a memory and one or more processors, receiving text, determining an emotional state, and generating, using a neural network, a speech dataset representing the received text and a set of parameters representing one or more actions of the avatar based on the received text and the determined emotional state.","['G06T13/00', 'G06F40/30', 'G06F40/20', 'G06F40/56', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/08', 'G06N3/09', 'G06T13/40', 'G06T13/80', 'G06N3/044']"
US11727255B2,Systems and methods for edge assisted real-time object detection for mobile augmented reality,"Systems and methods for edge assisted real-time object detection for mobile augmented reality are provided. The system employs a low latency offloading process, decouples the rendering pipeline from the offloading pipeline, and uses a fast object tracking method to maintain detection accuracy. The system can operate on a mobile device, such as an AR device, and dynamically offloads computationally-intensive object detection functions to an edge cloud device using an adaptive offloading process. The system also includes dynamic RoI encoding and motion vector-based object tracking processes that operate in a tracking and rendering pipeline executing on the AR device.","['G06N3/063', 'G06N3/045', 'G06N3/08', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G06V20/40']"
US10819724B2,Systems and methods for cyberbot network detection,"There is provided a neural network system for detection of domain generation algorithm generated domain names, the neural network system comprising: an input receiver configured for receiving domain names from one or more input sources; a convolutional neural network unit including one or more convolutional layers, the convolutional unit configured for receiving the input text and processing the input text through the one or more convolutional layers; a recurrent neural network unit including one or more long short term memory layers, the recurrent neural network unit configured to process the output from the convolutional neural network unit to perform pattern recognition; and a classification unit including one or more classification layers, the classification unit configured to receive output data from the recurrent neural network unit to perform a determination of whether the input text or portions of the input text are DGA-generated or benign domain names.","['H04L63/1425', 'G06F18/24', 'G06F40/126', 'G06K9/6267', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/082', 'G06N3/084', 'H04L61/3025', 'H04L63/1441', 'H04L2463/144', 'H04L61/1511', 'H04L61/4511']"
US12262287B2,Wireless signaling in federated learning for machine learning components,"Various aspects of the present disclosure generally relate to wireless communication. In some aspects, a base station may transmit, to a user equipment (UE), a federated learning configuration that indicates one or more parameters of a federated learning procedure associated with a machine learning component. The base station may receive a local update associated with the machine learning component from the UE based at least in part on the federated learning configuration. Numerous other aspects are provided.","['G06N3/08', 'H04W4/30', 'G06N20/00', 'G06N3/04', 'H04W72/21', 'H04W72/23', 'H04W88/02', 'H04W88/08']"
US10587776B2,Electronic device and method for controlling the electronic device,"A method for controlling an electronic device including at least one processor configured to encrypt an image and upload the encrypted image to an external server by using an artificial intelligence neural network model is provided. The method includes receiving a command to upload an image to the external server; acquiring, based on the command, a characteristic value corresponding to the image by inputting the image and a key of the electronic device into a neural network model trained to identify characteristic values based on an input image and an input key; and transmitting identification information of the image and the characteristic value to the external server.","['G06F21/602', 'H04N1/444', 'G06F21/46', 'G06F21/62', 'G06N3/08', 'G06T9/002', 'G06V10/761', 'H04N1/4413', 'H04N19/126', 'H04N21/2347', 'H04N21/4405', 'G06T2207/20081', 'G06T2207/20084']"
US20200293032A1,Extremely fast substation asset monitoring system and method,"embodiments are directed to a system, method, and article for monitoring a power substation asset. During an offline analysis mode, training data may be acquired and processing, and one or more classifiers may be generated for an online anomaly detection and localization mode. During the online anomaly detection and localization mode, power system related data may be received from field devices, a state of a substation system and of the power substation asset component and an unclassified state of one or instances may be generated based on the one or more classifiers. An alert may be generated to indicate the state of the substation system and of the power substation asset.","['G01R19/2513', 'G05B23/0254', 'G01R31/086', 'G05B15/02', 'G05B23/0208', 'G05B23/0221', 'G05B23/024', 'G05B23/027', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/084', 'G06N3/088', 'G06N5/04', 'H02J13/00', 'H02J13/00002', 'H02J13/00034', 'H02H1/0092', 'H02J13/00001', 'H02J2203/20', 'Y02B90/20', 'Y02E40/70', 'Y02E60/00', 'Y04S10/22', 'Y04S10/30', 'Y04S10/40', 'Y04S10/50', 'Y04S20/00', 'Y04S40/20']"
US20240049003A1,Managing a wireless device that is operable to connect to a communication network,"A method is disclosed for managing a wireless device that is operable to connect to a communication network. The communication network comprises a Radio Access Network (RAN), and the method is performed by a RAN node of the communication network. The method comprises determining, on the basis of information about an operating environment of the wireless device, configuration information for a Machine Learning (ML) model to be executed by the wireless device, and sending, to the wireless device, the determined configuration information. The ML model is operable to provide an output on the basis of which at least one RAN operation performed by the wireless device may be configured.","['H04W8/22', 'H04W24/02', 'G06N20/00', 'G06N3/0985', 'H04W8/24', 'G06N3/044', 'G06N3/045', 'G06N5/01']"
US11503414B2,Hearing device comprising a speech presence probability estimator,"A hearing device, e.g. a hearing aid, comprises a) a multitude of input units, each providing an electric input signal representing sound in the environment of the user in a time-frequency representation, wherein the sound is a mixture of speech and additive noise or other distortions, e.g. reverberation, b) a multitude of beamformer filtering units, each being configured to receive at least two, e.g. all, of said multitude of electric input signals, each of said multitude of beamformer filtering units being configured to provide a beamformed signal representative of the sound in a different one of a multitude of spatial segments, e.g. spatial cells, around the user, c) a multitude of speech probability estimators each configured to receive the beamformed signal for a particular spatial segment and to estimate a probability that said particular spatial segment contains speech at a given point in time and frequency, wherein at least one, e.g. all, of the multitude of speech probability estimators is/are implemented as a trained neural network, e.g. a deep neural network. The invention may e.g. be used in hearing aids or communication devices, such as headsets, or telephones, or speaker phones.","['H04R25/407', 'H04R25/405', 'H04R25/505', 'H04R25/507', 'H04R25/554', 'G10L15/08', 'H04R2225/43', 'H04R2225/51', 'H04R25/552']"
US10381017B2,"Method and device for eliminating background sound, and terminal device","The present disclosure provides a method and a device for eliminating background sound, and a terminal device. The method includes: obtaining an initial audio data set; performing background sound fusion processing on the initial audio data set to obtain training sample data; performing neural network training based on the training sample data and the initial audio data set to generate an initial neural network model for eliminating background sound; and performing background sound elimination on audio data to be processed based on the initial neural network model for eliminating background sound.","['G10L21/0208', 'G06N3/08', 'G10L15/20', 'G06N3/044', 'G06N3/045', 'G10L25/30']"
CN114677617B,A street lamp intelligent control method and device based on intelligent lighting,"The invention discloses a street lamp intelligent control method and device based on intelligent illumination, wherein the method comprises the steps of determining historical flow data related to a target street lamp by acquiring target position information of the target street lamp, wherein the historical flow data comprises historical flow data of a plurality of time periods; training a pre-constructed neural network model based on historical flow data to obtain a target neural network model, determining predicted flow data of a current period based on the target neural network model, and controlling a target street lamp according to the predicted flow data of the current period. Therefore, the invention can control the brightness of the street lamp according to the traffic condition of the road, realize intelligent control of the street lamp, is beneficial to ensuring road condition safety, can realize energy saving of the street lamp, effectively delay the service life of the street lamp, reduce the electricity expense of the street lamp and reduce the labor cost.","['G06N3/045', 'G06N3/08', 'G08G1/0129', 'H05B47/105', 'H05B47/165']"
US10956748B2,"Video classification method, information processing method, and server","A video classification method is provided for a computer device. The method includes obtaining a to-be-processed video, where the to-be-processed video has a plurality of video frames, and each video frame corresponds to one time feature; and sampling the to-be-processed video according to a time-feature sampling rule, and obtaining at least one video frame feature sequence. The time-feature sampling rule is a correspondence between time features and video frame feature sequences. The method also includes processing the video frame feature sequence by using a first neural network model, to obtain a feature representation result corresponding to the video frame feature sequence, where the first neural network model is a recurrent neural network model; and processing the feature representation result by using a second neural network model, to obtain a prediction result corresponding to the video frame feature sequence.","['G06V20/41', 'G06K9/00718', 'G06F16/735', 'G06F16/75', 'G06F16/783', 'G06F16/9535', 'G06F17/15', 'G06F18/00', 'G06F18/24', 'G06F18/2413', 'G06K9/6267', 'G06N3/044', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'G06V20/48']"
US12094457B2,Systems and methods for classifying sounds,"An electronic device has one or more microphones that pick up a sound. At least one feature extractor processes the audio signals from the microphones, that contain the picked up the sound, to determine several features for the sound. The electronic device also includes a classifier that has a machine learning model which is configured to determine a sound classification, such as artificial versus natural for the sound, based upon at least one of the determined features. Other aspects are also described and claimed.","['G10L15/16', 'G06N20/00', 'G06N3/006', 'G06N3/08', 'G10L25/51']"
US10516857B2,Method and apparatus of secured interactive remote maintenance assist,"A system and method for using the system comprising a head mounted device (HMD), a remote maintenance server (RMS), and a control section operable to identify the system under test (SUT) using an image recognition function, to identify a plurality of subsystems (PLoS) within the SUT in a data library, to create three dimensional models of the PLoS and displaying the same on a visual interface of the HMD using an augmented reality function, to connect to the RMS using an encryption algorithm via streaming video or images sent to the RMS, to collect SUT data and external (to the SUT) sensor data, to conduct a prognostics and/or health, maintenance, and/or management (HMM) service on the collected data to determine system health and projected health of the SUT and/or PLoS, to authenticate remote user access to the RMS, to update the data library, and to insert a plurality of (HMM) designators on the visual interface.","['H04N7/185', 'G06F11/0709', 'G06F11/0748', 'G06F11/0793', 'G06Q10/10', 'G06Q10/20', 'H04L63/0428', 'H04L63/08']"
US10049162B2,Knowledge discovery agent system,"A system and method for processing information in unstructured or structured form, comprising a computer running in a distributed network with one or more data agents. Associations of natural language artifacts may be learned from natural language artifacts in unstructured data sources, and semantic and syntactic relationships may be learned in structured data sources, using grouping based on a criteria of shared features that are dynamically determined without the use of a priori classifications, by employing conditional probability constraints.","['G06F16/951', 'G06F17/30864', 'G06F16/2425', 'G06F16/248', 'G06F16/907', 'G06F17/30395', 'G06F17/30554', 'G06F17/30997', 'G06N20/00', 'G06N3/08', 'G06N5/022', 'G06N99/005', 'H04N21/251', 'H04N21/466', 'H04N21/4662', 'H04N21/4668', 'H04N21/4826']"
US11754997B2,"Devices, systems and methods for predicting future consumption values of load(s) in power distribution systems","Devices, systems and methods for predicting future consumption values of load(s) in power distribution systems are provided. The present disclosure provides for receiving a request for a load prediction for at least one meter; extracting time series data relating to the at least meter; retrieving future weather conditions for a particular location based on the at least one meter; and providing the extracted data and the future weather conditions to a prediction model that predicts load usage for the at least one meter. Additionally, the present disclosure provides for performing at least one action based on the prediction, wherein the action includes outputting at least one of a communication signal and/or at least one control signal to at least one client or at least one meter.","['G05B19/4155', 'H04Q9/02', 'H04Q9/00', 'G05B2219/2639', 'H04Q2209/60', 'H04Q2209/823', 'H04Q2213/08']"
CN110414519B,Picture character recognition method and device and storage medium,"A picture character recognition method and a recognition device thereof, wherein the recognition method comprises the following steps: acquiring a text line picture to be identified, inputting the text line picture to be identified into a pre-established picture character identification model to identify characters in the text line picture to be identified, and outputting the characters in the text line picture to be identified; the picture character recognition model is obtained by training a depth neural network by utilizing a plurality of text line pictures for training, and the text line pictures for training are obtained by expanding and changing standard text line pictures. The text line pictures used for training are obtained by performing expansion change processing on standard text line pictures, so that a training sample set of the picture character recognition model is more suitable for practical application, and compared with training samples obtained by randomly combining characters, the number of the training samples is greatly reduced, and the efficiency of generating the training samples and the training model is greatly improved.","['G06F18/214', 'G06N3/045', 'G06N3/08', 'G06V30/153', 'G06V30/10']"
CN113940066B,Selectively enhance compressed digital content,"The present disclosure relates to systems, methods, and computer-readable media for selectively enhancing digital image and video content. For example, the system disclosed herein may encode the original video content to compress and decompress the original video content. The systems described herein may further identify information of a region of interest for identifying portions of decompressed video content to analyze and remove one or more compression artifacts found therein. The system described herein may further enhance decompressed video content by increasing display resolution. By identifying regions of interest and selectively enhancing digital video content, the systems described herein may reduce consumption of bandwidth and processing resources while maintaining high visual quality of the digital content.","['H04N19/117', 'G06F18/2155', 'G06F18/40', 'G06N20/00', 'G06T3/4046', 'G06T3/4053', 'G06T5/50', 'G06T5/70', 'H04N19/167', 'H04N19/186', 'H04N19/59', 'H04N19/86', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
CN113611323B,Voice enhancement method and system based on double-channel convolution attention network,"The invention discloses a voice enhancement method based on a double-channel convolution attention network, which comprises the following steps: firstly, windowing and framing time domain voice with noise, carrying out Fourier transform on a framing result to be converted into a time-frequency domain, and extracting logarithmic amplitude spectrum characteristics of the voice with noise to be used as input characteristics of a model; then, input features are respectively sent into a convolutional neural network channel and a long-short-time memory network channel for deep feature extraction, and a convolutional attention module and a spatial attention module are respectively added into the two channels for self-adaptive adjustment of feature graphs generated in the two channels; further completing the prediction of the logarithmic magnitude spectrum characteristics of the enhanced voice; finally, the prediction result and the phase of the voice with noise are combined to obtain the frequency domain representation of the enhanced voice, the frequency domain representation is converted back to the time domain through inverse Fourier transform, and then the integral synthesis of the enhanced voice is completed by utilizing an overlap-add method. The invention can effectively improve the quality and the intelligibility of the enhanced voice.","['G10L21/0216', 'G10L21/0224', 'G10L21/0232', 'G10L25/30', 'G10L25/45']"
CN111858072B,A resource management method and system for large-scale distributed deep learning,"The invention discloses a resource management method and a system for large-scale distributed deep learning, which realize the optimal management of memory resources aiming at intermediate data such as parameters, gradients and the like and ensure the reasonable configuration of distributed communication bandwidth resources during the training operation of a neural network. Re-realizing inter-layer memory multiplexing, and migrating intermediate data required by iterative computation and sparse communication into a CPU for main memory, and then migrating back as required to reduce inter-layer memory consumption; on the basis of reasonable migration of CPU-GPU data, intra-layer memory multiplexing is achieved, independence of intra-layer calculation and memory access operation is mined, and intra-layer memory consumption is reduced as much as possible. And the distributed parameter communication optimization is realized while the efficient utilization of the memory resources is ensured. The data access in the distributed parameter updating stage is reasonably redirected, the CPU is used as a mirror image access area to finish the data access to the parameters and the gradients, and the problems of gradient data deletion and parameter writing out-of-range are solved.","['G06F9/5027', 'G06F9/5016', 'G06N3/084']"
US11354352B1,Geo-visual search,"Performing a geo-visual search is disclosed. A query feature vector associated with a query tile is obtained. A lookup is performed at least in part by using a key derived from the query feature vector. A list of candidate feature vectors is obtained based at least in part on the lookup. Based at least in part on a comparison of the query feature vector against at least some of the candidate feature vectors in the obtained list, a tile that is visually similar to the query tile is determined. The determined tile is provided as output.","['G06F16/583', 'G06F16/29', 'G06F16/5854', 'G06F16/687', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06V10/44', 'G06V20/35']"
US11061776B2,"Prioritization and source-nonspecific based virtual machine recovery apparatuses, methods and systems","The Prioritization and Source-Nonspecific Based Virtual Machine Recovery Apparatuses, Methods and Systems (“MBR”) transforms backup configuration request, restore request inputs via MBR components into backup configuration response, restore response outputs. A backup configuration request to configure backups of a data storage volume of a source device is obtained. A paired backup device is determined. A recovery prioritization index is generated by determining a recovery priority ranking for each selected for backup data block of the data storage volume. A discrepancy hash for each selected for backup data block of the data storage volume that is available from at least one of a set of source-nonspecific locations is precalculated. The recovery prioritization index and the discrepancy hashes are periodically updated to account for data block use. Backup data including at least one of the recovery prioritization index and the discrepancy hashes is sent from the source device to the backup device.","['G06F11/1451', 'G06F11/1458', 'G06F11/1461', 'G06F11/1469', 'H04L9/3236', 'G06F2201/80', 'G06F2201/81', 'G06F2201/84']"
US11061713B2,"Prioritization and source-nonspecific based virtual machine recovery apparatuses, methods and systems","The Prioritization and Source-Nonspecific Based Virtual Machine Recovery Apparatuses, Methods and Systems (“MBR”) transforms backup configuration request, restore request inputs via MBR components into backup configuration response, restore response outputs. A restore request is obtained. A reestablishing virtual machine is booted. A recovery virtual machine configuration identifying source-nonspecific software is determined. A recovery prioritization index for data blocks of the associated backup disk image is determined. Essential data blocks of the backup disk image are prefetched to build a pseudo abridged virtual machine. User access to the reestablishing virtual machine is provided. A latent virtual machine is created inside the reestablishing virtual machine. Command data blocks are fetched for both the reestablishing virtual machine and the latent virtual machine when a user command is received. Remaining data blocks are fetched for the latent virtual machine in priority order. The reestablishing virtual machine is rebooted to boot the latent virtual machine.","['G06F11/1004', 'G06F9/45558', 'G06F21/575', 'G06F21/602', 'G06F3/0619', 'G06F3/065', 'G06F3/0659', 'G06F3/0664', 'G06F3/0673', 'G06F9/4406', 'G06F9/45533', 'G06F2009/45562', 'G06F2009/45566', 'G06F2009/4557', 'G06F2009/45575', 'G06F2009/45579', 'G06F2009/45583']"
CN110880361B,Personalized accurate medication recommendation method and device,"The embodiment of the invention provides a personalized accurate medication recommendation method and device, and relates to the technical field of pedestal operation and maintenance, wherein the method comprises the following steps: acquiring medical record data of a plurality of patients suffering from the same disease, wherein the medical record data comprises structured data, text data and image data; obtaining the medication information of the patient from the text data; screening a first medicine recommendation result of a target patient from the medicine information of a plurality of historical patients; combining the medical record data of the patients to obtain the disease condition characteristic information of the patients; screening at least one similar patient similar to the current disease characteristic information of the target patient from a plurality of historical patients; generating a second medicine recommendation result according to the medication information of the similar patients; and obtaining the personalized medicine recommendation result of the target patient according to the first medicine recommendation result and the second medicine recommendation result. The technical scheme provided by the embodiment of the invention can solve the problem of low medicine taking precision of patients in the prior art.","['G16H20/10', 'G16H10/60', 'G16H50/20']"
CN111933115B,"Speech recognition method, apparatus, device and storage medium","The application discloses a voice recognition method, a voice recognition device, voice recognition equipment and a storage medium, and belongs to the field of voice recognition. According to the technical scheme provided by the embodiment of the application, the voice recognition is carried out by adopting methods of attention coding and time sequence decoding, the attention coding is carried out on the voice characteristic matrix, and the parallel calculation of the GPU can be efficiently utilized. The coding vector is decoded according to the position of the coding vector in the coding matrix, the parameter quantity can be reduced, meanwhile, the memory characteristic of the speech recognition model is utilized, the prediction is carried out according to the coding vector related in time sequence, and the accuracy of speech recognition is improved.","['G10L15/02', 'G06F17/16', 'G06F18/253', 'G06N3/0442', 'G06N3/0455', 'G06N3/0464', 'G06N3/082', 'G06N3/084', 'G10L15/063', 'G10L15/16']"
US10063872B2,Segment based encoding of video,"A distributed video encoding system splits an input video into video segments. The video segments are encoded using multiple video encoding nodes. Prior to the process of splitting the sequence into video segments, the video is analyzed to generate a dependency map. Intelligent segmentation is performed using the dependency map so that each video segment includes all the video frames from which other video frames within that segment have been encoded in the input video. For example, picture headers are inspected to determine the temporal distance of the farthest past and future reference frames used for encoding frames of a video.","['H04N19/436', 'H04N19/395', 'H04N19/90', 'H04N21/2743', 'H04N21/8456']"
US11036422B2,"Prioritization and source-nonspecific based virtual machine recovery apparatuses, methods and systems","The Prioritization and Source-Nonspecific Based Virtual Machine Recovery Apparatuses, Methods and Systems (“MBR”) transforms backup configuration request, restore request inputs via MBR components into backup configuration response, restore response outputs. A restore request to build a recovery virtual machine using a backup disk image of a source device stored on a backup device is obtained. A virtual machine recovery environment comprising a guest virtual machine running a guest hypervisor is booted. A recovery virtual machine configuration identifying source-nonspecific software is determined. A recovery prioritization index for data blocks of the backup disk image is determined. Essential data blocks of the backup disk image are prefetched. An operating system of a nested guest abridged virtual machine is booted. Command data blocks are fetched when a user command is received. Remaining data blocks are fetched in priority order. The nested guest complete virtual machine is migrated to a non-nested guest virtual machine.","['G06F3/065', 'G06F3/0604', 'G06F3/0664', 'G06F3/0673', 'G06F9/4401', 'G06F9/45558', 'G06F2009/45562', 'G06F2009/45566', 'G06F2009/4557', 'G06F2009/45583', 'G06F8/63']"
EP4414902A2,"Computer-based systems, computing components and computing objects configured to implement dynamic outlier bias reduction in machine learning models",Systems and methods include processors for receiving training data for a user activity; receiving bias criteria; determining a set of model parameters for a machine learning model including: (1) applying the machine learning model to the training data; (2) generating model prediction errors; (3) generating a data selection vector to identify non-outlier target variables based on the model prediction errors; (4) utilizing the data selection vector to generate a non-outlier data set; (5) determining updated model parameters based on the non-outlier data set; and (6) repeating steps (1)-(5) until a censoring performance termination criterion is satisfied; training classifier model parameters for an outlier classifier machine learning model; applying the outlier classifier machine learning model to activity-related data to determine non-outlier activity-related data; and applying the machine learning model to the non-outlier activity-related data to predict future activity-related attributes for the user activity.,"['G06N20/20', 'G06F17/18', 'G06F18/214', 'G06F18/2433', 'G06F9/4881', 'G06N20/00', 'G06N3/08', 'G06N5/01', 'G06N7/01']"
CN111611472B,Binding recommendation method and system based on graph convolution neural network,"The embodiment of the invention provides a binding recommendation method and system based on a graph convolution neural network. The method comprises the following steps: acquiring historical interaction data of a user and binding, historical interaction data of the user and an article and subordinate relationship data of the binding and the article; inputting the recommendation result into the binding recommendation model to obtain a recommendation result of the possibility of the user interacting with the binding, which is output by the binding recommendation model; the binding recommendation model is obtained by constructing a unified iso-graph based on a user data set, a binding data set and an article data set, extracting article level graph convolution propagation characteristics and binding level graph convolution propagation characteristics, then carrying out joint prediction and characteristic connection, and training based on a difficult negative sample learning strategy. According to the embodiment of the invention, the interactive relationship and the subordinate relationship among the user, the binding and the article are reconstructed into the graph, and three associated entity representations are learned from a complex topological structure and high-order connectivity by utilizing the strong capability of the graph neural network, so that better recommendation performance can be achieved.","['G06F16/9535', 'G06N3/045', 'G06N3/084', 'G06Q30/0631']"
US12177493B2,Use of embedded signalling for backward-compatible scaling improvements and super-resolution signalling,"Certain examples described herein relate to methods for encoding and decoding signals. Certain examples relate to the control of signal processing operations that are performed at a decoder. These may comprise optional signal processing operations to provide an enhanced output signal. For video signals, the enhanced output signal may comprise a so-called “super-resolution” signal, e.g. a signal with improved detail resolution as compared to a reference signal. Certain examples described herein provide signalling for enhancement operations, e.g. so-called super-resolution modes, within user data of one or more tier-based hierarchical encoding and decoding schemes. The user data may be embedded within values of an enhancement stream, e.g. replace one or more values for a predefined set of transformed coefficients, and/or within supplementary enhancement information messages. The user data may have a defined syntax including header and payload portions. The syntax may differ for different frames of data, e.g. for a video encoding, instantaneous decoding refresh picture frames may carry different information from non-instantaneous decoding refresh picture.","['H04N19/117', 'H04N19/12', 'H04N19/124', 'H04N19/132', 'H04N19/136', 'H04N19/146', 'H04N19/154', 'H04N19/156', 'H04N19/159', 'H04N19/176', 'H04N19/18', 'H04N19/182', 'H04N19/184', 'H04N19/30', 'H04N19/33', 'H04N19/34', 'H04N19/46', 'H04N19/467', 'H04N19/59', 'H04N19/61', 'H04N19/70', 'H04N19/86']"
US20220094713A1,Malicious message detection,"In a natural language processing model such as a Bidirectional Encoder Representations from Transformers (BERT) model, transformer layers can be replaced with simplified adapters without significant loss of predictive ability. This compressed model may in turn be trained to perform security classification tasks such as detection of new phishing attacks in electronic mail communications.","['H04L63/1483', 'H04L63/1425', 'G06F18/214', 'G06K9/6256', 'H04L63/1416', 'H04L63/145']"
CN111554268B,"Language identification method based on language model, text classification method and device","The application relates to a language identification method based on a language model, a text classification method and device, computer equipment and a storage medium, wherein the method comprises the following steps: acquiring training word vectors corresponding to training sentences, and inputting the training word vectors into a first model to be trained and a trained second model respectively to obtain a feature matrix output by each first network layer of the first model and a feature matrix output by each second network layer of the second model; the first network layer and the second network layer are in one-to-one correspondence, and the number of the network layer layers of the first model is smaller than that of the second model; and performing similarity calculation on the feature matrix output by each first network layer and the feature matrix output by the second network layer corresponding to each first network layer to obtain each similarity, adjusting the model parameters of the first model based on each similarity until the updated target similarity meets the convergence condition to obtain a trained first model, and performing language identification through the first model. By adopting the method, the model training efficiency can be improved.","['G10L15/005', 'G06F16/35', 'G06N3/045', 'G06N3/08', 'G10L15/063', 'G10L15/18']"
CN112836773B,Hyperspectral image classification method based on global attention residual error network,"The invention discloses a hyperspectral image classification method based on a global attention residual error network, which comprises the following steps of: constructing an integral network, which comprises a multi-scale feature extraction network, a global attention module and an improved residual error network module; performing multi-scale feature extraction, and extracting the hierarchical features of the hyperspectral image; the global attention module is used for constructing a spatial and spectral dependency relationship of a global pixel point through the combination of the spatial attention module and the spectral attention module; fusing the improved residual error network module and the global attention module to form a novel global attention residual error network; and sending the output result into a classifier for final classification through global pooling, and outputting the result. According to the method, rich space-spectrum characteristics are obtained simultaneously by introducing the multi-scale large and small receptive fields and the global attention module, the problem of gradient disappearance is relieved by adding the improved residual error network, and network convergence is accelerated, so that the classification precision is improved, and a good and stable classification effect is ensured.","['G06F18/2453', 'G06F18/253', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'Y02A40/10']"
TW569570B,Multimedia sensor network,"A multimedia network includes a sensor network, a communication bridge and a user network (e.g., the Internet). The sensor network includes a set of interconnected sensors coupled to a control module. The control module receives a set of sensed data from the sensors and generates a homogenized data stream based on the sensed data. The communication bridge is coupled to the sensor network and buffers the homogenized data stream. The user network is coupled to the communication bridge and receives the homogenized data stream from the sensor network. The user network transmits data back to the control module through the communication bridge.","['G08B25/007', 'G01V1/22']"
US20220361840A1,Displaying blood vessels in ultrasound images,"A method and apparatus for identifying blood vessels in ultrasound images and displaying blood vessels in ultrasound images are described. In some embodiments, the method is implemented by a computing device and includes receiving ultrasound images that include a blood vessel, and determining, with a neural network implemented at least partially in hardware of the computing device, diameters of the blood vessel in the ultrasound images. The diameters include a respective diameter of the blood vessel for each ultrasound image of the ultrasound images. The method includes determining a blood vessel diameter based on the diameters of the blood vessel, selecting a color based on the blood vessel diameter, and indicating, in one of the ultrasound images, the blood vessel with an indicator having the color.","['A61B8/0891', 'A61B8/14', 'A61B8/42', 'A61B8/4427', 'A61B8/4472', 'A61B8/463', 'A61B8/469', 'A61B8/5223', 'G06T7/0016', 'G06T7/246', 'G06T7/62', 'G06T7/70', 'G06T7/74', 'G06T7/77', 'A61B2034/2048', 'A61B2090/364', 'A61B2090/372', 'A61B2090/378', 'A61B34/25', 'G06N20/10', 'G06N3/0442', 'G06T2207/10016', 'G06T2207/10132', 'G06T2207/20076', 'G06T2207/20084', 'G06T2207/30021', 'G06T2207/30101']"
US11025959B2,Probabilistic model to compress images for three-dimensional video,"A method includes receiving head-tracking data that describe one or more positions of people while the people are viewing a three-dimensional video. The method further includes generating a probabilistic model of the one or more positions of the people based on the head-tracking data, wherein the probabilistic model identifies a probability of a viewer looking in a particular direction as a function of time. The method further includes generating video segments from the three-dimensional video. The method further includes, for each of the video segments: determining a directional encoding format that projects latitudes and longitudes of locations of a surface of a sphere onto locations on a plane, determining a cost function that identifies a region of interest on the plane based on the probabilistic model, and generating optimal segment parameters that minimize a sum-over position for the region of interest.","['H04N19/86', 'H04N13/139', 'H04N13/368', 'H04N19/162', 'H04N19/167', 'H04N19/17', 'H04N19/597', 'H04N13/366']"
CN111445478B,An automatic detection system and method for intracranial aneurysm area for CTA images,"The invention discloses an automatic intracranial aneurysm region detection system and method for CTA images, comprising the following steps: the data enhancement module is used for enhancing the acquired CTA image data; the suspected region preselection module is used for carrying out model training on the enhanced CTA image data and determining the center coordinates of the suspected region; the fine target detection module is used for performing model training after cutting an original image according to the central coordinates, and labeling the area where the intracranial aneurysm is located on the original image; the multidimensional fusion module is used for performing model training after cutting a three-dimensional image according to the central coordinates, marking the area where the intracranial aneurysm is located on the three-dimensional image, and marking the area where the intracranial aneurysm is located on the original image by combining with a fine target detection result; and the incremental training module is used for acquiring the newly added CTA image and redefining the area where the intracranial aneurysm is located.","['G06T7/11', 'G06T5/50', 'G06T2207/10081', 'G06T2207/20081', 'Y02T10/40']"
US11610331B2,"Method and apparatus for generating data for estimating three-dimensional (3D) pose of object included in input image, and prediction model for estimating 3D pose of object","Provided is a method of generating data for estimating a three-dimensional (3D) pose of an object included in an input image, the method including acquiring the input image including at least one moving object, estimating location information about each joint of a plurality of joints of the object included in the input image using a prediction model pretrained to estimate the location information about each joint of the plurality of joints of the object, and generating animation data that represents a movement of the object based on the estimated location information.","['G06T7/73', 'G06T13/40', 'G06T7/70', 'G06V10/82', 'G06V10/98', 'G06V40/10', 'G06V40/103', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20224', 'G06T2207/30196']"
US20250240342A1,Content collection navigation and autoforwarding,"Systems and methods for communicating and displaying collections of image and video clip content are described. In one example embodiment, a device receives interface information about a group of content collections from a server computer system. When a user inputs a selection of a first content collection, the device displays images and video clips in a sequence defined by the content collection. Each piece of content (e.g. image or video clip) is displayed for less than a threshold display time. When the device finishes playing the first content collection, the device automatically begins playing a next content collection. Additional content collections generated from content submitted by other client devices can be received from the server computer system, with autoforward play of additional content collections continuing indefinitely. Some embodiments include content collections generated by the server computer system, as well as advertising elements or other system images presented between content collections.","['G06F16/17', 'H04L67/06', 'G06F16/4393', 'G06F16/739', 'G06F3/04845', 'G06F3/04883', 'H04L51/02', 'H04L51/10', 'H04L67/75']"
US20240386054A1,"Systems, apparatus, articles of manufacture, and methods for cross training and collaborative artificial intelligence for proactive data management and analytics","Methods, apparatus, systems, and articles of manufacture are disclosed for proactive data management and analytics. An example apparatus includes at least one memory, instructions, and processor circuitry to at least one of execute or instantiate the instructions to identify nodes in a network environment, identify ones of the nodes as data subscribers, ingest data from data sources, execute a machine learning model on the data to generate an output, and perform an action based on the output.","['G06F16/901', 'G06F16/9024', 'G06F16/907', 'G06F16/908', 'G06F21/6209', 'H04L45/16', 'H04L45/22']"
US20200281480A1,Personal monitoring system,"A system includes a processor; a cellular, WiFi, or Bluetooth transceiver coupled to the processor; an accelerometer or a motion sensor coupled to the processor; and a sensor coupled to the processor to sense mood, wherein text, image, sound, or video is rendered in response to the sensed mood.","['A61B5/0205', 'A61B5/0022', 'A61B5/165', 'A61B5/6802', 'A61B5/6813', 'A61B5/74', 'G16H40/67', 'H04B1/3827', 'H04W4/80', 'A61B2562/0219', 'A61B5/163', 'A61B5/4806', 'A61B5/7405', 'A61B5/742', 'A61B5/7455', 'A61B5/746', 'A61B5/749', 'H04W84/12']"
US20240211770A1,Communication method and apparatus,"A communication method and apparatus. A terminal receives first information from a network device. The terminal determines N pieces of training data based on the first information, and N is an integer. The terminal performs model training based on the N pieces of training data, to obtain a first AI model. The network device configures the first information used to determine the N pieces of training data for the terminal. The terminal performs model training based on the N pieces of training data autonomously. Separately configuring an AI model for the terminal is not necessary and air interface overheads are reduced.","['H04W24/02', 'G06N3/098', 'G06N3/045', 'G06N3/08', 'Y02D30/70']"
CN105578115B,A kind of Network teaching method with Speech Assessment function and system,"A kind of Speech Assessment Methods is provided and uses Network teaching method and the system of the method.According to the Speech Assessment Methods of the present invention, the phoneme state of voice is used to substitute traditional mel cepstrum coefficients (MFCC) training many gauss hybrid models out, and calculates posterior probability and zeroth order Baum Welch statistic as feature；Utilize the phoneme recognizer of polyglot to extract phonetic feature based on phoneme.Present invention demonstrates that this based on feature that polyglot extracts when catching the information of non-native pronunciation be complementary and based on phoneme duration feature be effective in the accent of automatic native country is assessed.After emerging system, the method for the present invention has reached the Spearman correlation coefficient of 0.5706 and 0.6089 in development set and test set.This correlation coefficient shows, the method that the present invention proposes is very accurate and effective in spoken language is assessed.","['H04N7/15', 'G06Q50/20', 'G09B5/06', 'G10L25/48', 'G10L25/69', 'H04N5/76', 'H04N7/155']"
US20220244465A1,Data processing systems including optical communication modules,"An apparatus includes: at least one of a circuit board or a substrate; and a first structure attached to the at least one of a circuit board or a substrate. The first structure is configured to enable an optical module with connector to be removably coupled to the first structure, and the optical module with connector is configured to enable an optical fiber connector to be removably coupled to the optical module with connector. For example, the circuit board or the substrate includes first electrical contacts, the first structure includes walls that define a first opening, the walls also define one or more retaining mechanisms such that when the optical module with connector is inserted into the first opening, the one or more retaining mechanisms on the walls of the first structure engage one or more latch mechanisms on the optical module with connector to secure the optical module with connector to the first structure, and second electrical contacts on the optical module with connector are electrically coupled to the first electrical contacts on the circuit board or the substrate.","['G02B6/43', 'G02B6/3608', 'G02B6/3825', 'G02B6/3869', 'G02B6/4292', 'H01L25/167', 'H04B10/801', 'H05K1/0274', 'H05K1/141', 'H05K1/181', 'G02B6/42', 'G02B6/4249', 'G02B6/4284', 'H05K1/0206', 'H05K1/0243', 'H05K2201/09072', 'H05K2201/10121']"
CN109242033B,"Wafer defect mode classification method and device, storage medium and electronic equipment","The present disclosure relates to the field of computer technologies, and in particular, to a method and an apparatus for classifying wafer defect modes, a storage medium, and an electronic device. The method comprises the following steps: acquiring a wafer image of a marked defect position; extracting the features of the wafer image by using a convolutional neural network to obtain feature data of the wafer image; encoding the feature data of the wafer image through an automatic encoder to generate a feature code of the wafer image; and clustering the feature codes of the plurality of wafer images, and classifying the defect mode of each wafer image based on the clustering result. This disclose great reduction artificial work load, and then great reduction the human cost, simultaneously also great improvement classification efficiency and categorised rate of accuracy, in addition, can with EDA system lug connection, improved the ability of handling mass data.","['G06V10/82', 'G01N21/9501', 'G01N21/956', 'G06F18/2155', 'G06F18/23', 'G06V20/00', 'G06F18/24']"
US11849196B2,Automatic data extraction and conversion of video/images/sound information from a slide presentation into an editable notetaking resource with optional overlay of the presenter,"A method and system to automatically convert a presentation with slide materials to a digitized notetaking resource, by inputting a media stream from a presentation to a compute server, converting the media stream by segmenting the video into smaller segments, transcribing audio of the presenter's speech into text. Time stamp metadata is associated to elements of the segmented video (and, if available, slide data), audio, and transcribed text, and the elements are time ordered. A user interface is provided displaying elements of the segmented video/slide data and transcribed text. The user interface enables playback of the elements of the segmented video/slide data, audio of the presenter's speech, and transcribed text, wherein playback items are time-matched. Different times can be selected by a user, wherein the selected elements are made prominent in the display, with the audio of the presenter's speech also being time-matched to the selection.","['H04N21/23418', 'H04N21/854', 'G06F3/0425', 'G06F3/048', 'G06F3/04883', 'G06F40/169', 'G10L15/26', 'H04N21/233', 'H04N21/234336', 'H04N21/8456']"
CN111126258B,Image recognition method and related device,"The embodiment of the application discloses an image identification method and a related device, wherein the method comprises the following steps: obtaining a target image, inputting the target image into a backbone network for feature extraction, obtaining a plurality of first feature images under different scales, performing post-processing through the plurality of first feature images, obtaining at least one target, determining spatial attention feature images corresponding to the plurality of first feature images, obtaining a plurality of first spatial attention feature images, determining a first region of interest feature image according to the plurality of first spatial attention feature images, inputting the first region of interest feature image into the backbone network for feature extraction, obtaining a plurality of second feature images under different scales, performing target attribute identification through the plurality of second feature images, determining at least one target attribute, and taking the at least one target and the at least one target attribute as target image identification results. By adopting the embodiment of the application, the image recognition precision and speed can be improved.","['G06V20/584', 'G06F18/241', 'G06F18/253', 'G06N3/045', 'G06N3/082', 'G06V10/20', 'G06V10/25', 'G06V10/267', 'G06V10/464', 'G06V20/625']"
US11546448B2,System and method for data compression based on data position in frames structure,"Method and system for lossless and stateless compression scheme is used with a fixed-length data such as frames. Frames having a payload of M bits length are mapped into a payload of N bits length, where N<M. The N bits payload of each received frame is extracted, and mapped using a memory, PLD, or a processor, to reconstruct the uncompressed M bits payload, and to form the original frame. The reconstruction may use a set of N coefficients that are each multiplied by the corresponding received payload bit, and summarized modulo-2 to obtain the original pre-compressed M payload bits. The method and system may be used with a vehicle bus, such as Controller Area Network (CAN). The compressed frames may use the same or different protocol than the uncompressed ones, and may further carry an additional code such as metadata, error detection or correction code, or authentication related code.","['H04L67/5651', 'H04L12/40', 'H04L69/04', 'H04L2012/40215', 'H04L2012/40273', 'H04L67/12', 'H04W4/48']"
US11278433B2,Powered ankle-foot prosthesis,"A powered ankle-foot prosthesis, capable of providing human-like power at terminal stance that increase amputees metabolic walking economy compared to a conventional passive-elastic prosthesis. The powered prosthesis comprises a unidirectional spring, configured in parallel with a force-controllable actuator with series elasticity. The prosthesis is controlled to deliver the high mechanical power and net positive work observed in normal human walking.","['A61F2/6607', 'A61F2/60', 'A61F2/68', 'B25J19/0008', 'A61F2/605', 'A61F2/64', 'A61F2002/5004', 'A61F2002/503', 'A61F2002/5033', 'A61F2002/5075', 'A61F2002/6818', 'A61F2002/701', 'A61F2002/704', 'A61F2002/7625', 'A61F2002/7635', 'A61F2002/764', 'A61F2002/7645']"
US10965948B1,Hierarchical auto-regressive image compression system,"The present application relates to a multi-stage encoder/decoder system that provides image compression using hierarchical auto-regressive models and saliency-based masks. The multi-stage encoder/decoder system includes a first stage and a second stage of a trained image compression network, such that the second stage, based on the image compression performed by the first stage, identify certain redundancies that can be removed from the bit string to reduce the storage and bandwidth requirements. Additionally, by using saliency-based masks, distortions in different sections of the image can be weighted differently to further improve the image compression performance.","['H04N19/20', 'G06T9/002', 'H04N19/124', 'H04N19/13', 'H04N19/167', 'H04N19/17', 'H04N19/33', 'H04N19/439', 'H04N19/91']"
US11610283B2,Apparatus and method for performing scalable video decoding,"Provided are a method and an apparatus for performing scalable video decoding, wherein the method and the apparatus down-sample input video, determine the down-sampled input video as base layer video, generate prediction video for enhancement layer video by applying an up-scaling filter to the base layer video, and code the base layer video and the prediction video, wherein the up-scaling filter is a convolution filter of a deep neural network.","['G06T3/4046', 'G06T9/002', 'H04N19/33', 'G06N3/04', 'G06N3/0464', 'G06N3/08', 'G06T3/4053', 'H04N19/117', 'H04N19/186', 'H04N19/59', 'G06T2207/20081', 'G06T2207/20084']"
WO2019013711A1,Mobile device platform for automated visual retail product recognition,"Disclosed is a mobile electronic device platform for automated visual product recognition. As part of the platform, a mobile electronic device comprising a processing element and computer-readable media performs automated product-recognition processes based on input image frames received from a photographic element. The non-transitory computer-readable media may include computer-readable instructions stored thereon, the instructions instructing the processing element of the mobile electronic device to complete the following data processing steps without sending or receiving the processed data over an active data connection to any other computing device: (1) pass an input image frame of the input image frames depicting a product through a convolutional neural network stored on the computer-readable media; (2) generate a product classification for the product based at least in part on passage of the image frame through the convolutional neural network; and (3) record product metadata corresponding to the product to a record of the automated product-recognition process. The convolutional neural network may be trained through adjustment of model parameters according to the output of multiple classification arms sharing upstream convolutional features and utilize network compression and/or quantization techniques described herein, resulting in significant performance gains.","['G07G1/0054', 'G06F16/164', 'G06F18/217', 'G06F18/241', 'G06F18/40', 'G06K7/1413', 'G06N3/08', 'G06Q20/208', 'G06Q20/322', 'G06K2007/10504']"
CN111465882B,"Optical device, apparatus and system for assay","An optical assembly for imaging a sample using a handheld imaging device having a light source, a single camera, and a computer processor, the optical assembly comprising: a housing; a cavity within the housing for receiving and positioning a sample within a field of view of a camera; and a lever within the cavity, wherein the lever comprises at least one optical element and is configured to be movable between a first position and a second position, wherein (i) in the first position, the imaging device is capable of imaging a sample in a bright field mode, and (ii) in the second position, the imaging device is capable of imaging a sample in a fluorescence excitation mode, and wherein the lever comprises a first planar region extending along a first plane and a second planar region laterally displaced from the first planar region along a first direction and extending along a second plane, the first plane being disposed at a different height along a second direction than the second plane, the second direction being perpendicular to the first direction. The present invention provides devices and methods for simple, rapid and sensitive assays.","['G01N21/8483', 'B01L3/502715', 'B01L9/52', 'G01N21/6458', 'G01N21/78', 'G01N21/84', 'G01N33/483', 'G02B21/0008', 'G02B21/0076', 'G02B21/12', 'G02B21/16', 'G02B21/24', 'G02B7/023', 'H04N23/51', 'H04N23/55', 'H04N23/56', 'H04N23/57', 'H04N23/67', 'B01L2200/025']"
US10911732B2,Free-viewpoint photorealistic view synthesis from casually captured video,"An estimated camera pose may be determined for each of a plurality of single plane images of a designated three-dimensional scene. The sampling density of the single plane images may be below the Nyquist rate. However, the sampling density of the single plane images may be sufficiently high such that the single plane images is sufficiently high such that they may be promoted to multiplane images and used to generate novel viewpoints in a light field reconstruction framework. Scene depth information identifying for each of a respective plurality of pixels in the single plane image a respective depth value may be determined for each single plane image. A respective multiplane image including a respective plurality of depth planes may be determined for each single plane image. Each of the depth planes may include a respective plurality of pixels from the respective single plane image.","['G06T15/005', 'H04N13/111', 'G06T15/08', 'G06T15/20', 'G06T15/205', 'G06T15/503', 'G06T7/0002', 'G06T7/50', 'G06T7/514', 'G06T7/557', 'G06T7/579', 'G06T7/70', 'G06V10/247', 'H04N13/229', 'H04N13/271', 'H04N23/632', 'H04N23/635', 'H04N23/64', 'H04N23/6811', 'H04N5/23222', 'H04N5/232945', 'G06T2207/10052', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244', 'G06T2215/16', 'H04N2013/0081']"
CN111357014B,A method and device for developing an AI model,"The embodiment of the application discloses a development method and a development device of an AI model, which relate to the technical field of AI and can develop the AI model meeting the running environment and performance requirements of a terminal at lower cost. The specific scheme is as follows: the development platform acquires platform indication information, service indication information and parameter requirement information of an AI model to be generated; selecting a plurality of available operators which correspond to the operation platform and execute the first service from an operator database; selecting operators from a plurality of available operators and completing parameter setting of the selected operators to generate a first candidate strategy; sample training is carried out on the first candidate strategy to obtain a first candidate AI model; invoking a simulator component of the operation platform to operate the first candidate AI model to execute the first service processing test data to obtain a first operation parameter; and if the first operation parameter is matched with the parameter requirement information, determining the first candidate AI model as a target AI model.","['G06N20/00', 'G06N3/105', 'G06N3/0464', 'G06N3/0495', 'G06N3/082', 'G06N3/09', 'G06N3/045', 'G06N3/048', 'G06N3/08']"
US11614880B2,Storage system with selectable write paths,"A storage system has a first memory, and a second memory that includes storage memory. The storage system has a processing device. The processing device is to select whether to write data to the first memory and write the data from the first memory to the second memory, or to write the data to the second memory bypassing the first memory. The processing device is to write portions of data for storage according to such selection.","['G06F3/0652', 'G06F3/0688', 'G06F3/0604', 'G06F3/0619', 'G06F3/0635', 'G06F3/0644', 'G06F3/0647', 'G06F3/0653', 'G06F3/0661', 'G06F3/067', 'G06F3/0689', 'G06F3/0641', 'G06F3/0685']"
US12120312B2,Video encoding rate control for intra and scene change frames using machine learning,"Techniques related to quantization parameter estimation for coding intra and scene change frames are discussed. Such techniques include generating features based on an intra or scene change frame including a proportion of smooth blocks and one or both of a measure of block variance and a prediction distortion, and applying a machine learning model to generate an estimated quantization parameter for encoding the intra or scene change frame.","['H04N19/124', 'H04N19/159', 'G06N3/08', 'G06N3/084', 'H04N19/146', 'H04N19/176', 'H04N19/179', 'H04N19/70', 'H04N19/30']"
WO2020034850A1,"Identification method for identification code, device, computer apparatus, and storage medium","The present application relates to an identification method for an identification code, a device, an apparatus, and a storage medium. The method comprises: acquiring an image under detection; detecting an identification code in said image to obtain a detection result, the detection result comprising target information of a target code corresponding to the identification code; sampling the target code according to the target information, and obtaining a sampling image; and decoding the sampling image, and obtaining an identification result corresponding to the identification code. After a detection image is acquired, operations, such as sampling and decoding, are not performed on the entire image under detection, but detection is performed on the entire image under detection, so as to obtain a detection result targeting an identification code, the detection result comprising target information of a target code corresponding to the identification code, and then operations such as sampling and decoding are performed with respect to the target code. The method of the invention can reduce interference from non-identification code regions in an image under detection, thereby improving the identification efficiency of identification codes.","['G06V10/25', 'G06V30/153', 'G06K7/1443', 'G06K7/1447', 'G06K7/1469', 'G06N3/08', 'G06T3/4007', 'G06T3/4069', 'G06T7/13', 'G06V10/454', 'G06V10/82', 'G06V20/66', 'G06V30/19173']"
US8684900B2,Health monitoring appliance,A heart monitoring system for a person includes one or more wireless nodes forming a wireless network; a wearable body sensor having a wireless transceiver adapted to communicate with the one or more wireless nodes.,"['G16H40/67', 'A61B5/0002', 'A61B5/002', 'A61B5/0022', 'A61B5/02028', 'A61B5/02055', 'A61B5/026', 'A61B5/0537', 'A61B5/1117', 'A61B5/14542', 'A61B5/242', 'A61B5/33', 'A61B5/372', 'A61B5/383', 'A61B5/411', 'A61B5/6814', 'A61B5/6816', 'A61B5/6887', 'A61B5/742', 'A61B5/7465', 'A61B8/00', 'A61B8/06', 'A61B8/4472', 'A61B8/488', 'A61B8/56', 'A61B8/565', 'A61B8/582', 'G16H40/40', 'G16H50/20', 'G16H50/50', 'A61B2560/0412', 'A61B5/0059', 'A61B5/01', 'A61B5/02042', 'A61B5/0265', 'A61B5/029', 'A61B5/0536', 'A61B5/086', 'A61B5/1075', 'A61B5/1116', 'A61B5/113', 'A61B5/14532', 'A61B5/1455', 'A61B5/318', 'A61B5/339', 'A61B5/352', 'A61B5/377', 'A61B5/389', 'A61B5/398', 'A61B5/4519', 'A61B5/4528', 'A61B5/4866', 'A61B5/4875', 'A61B5/681', 'A61B5/6826', 'A61B5/6831', 'A61B5/7225', 'A61B5/7257', 'A61B5/726', 'A61B5/7267', 'A61B5/746', 'A61B7/00', 'A61B8/0808', 'A61B8/0816', 'A61B8/58', 'G08B21/043', 'G08B21/0453', 'G08B21/0476', 'G08B21/0492', 'G16H20/13']"
US20250082173A1,Machine-learning-based visual-haptic system for robotic surgical platforms,"Embodiments described herein provide examples of a machine-learning-based visual-haptic system for constructing visual-haptic models for various interactions between surgical tools and tissues. In one aspect, a process for constructing a visual-haptic model is disclosed. This process can begin by receiving a set of training videos. The process then processes each training video in the set of training videos to extract one or more video segments that depict a target tool-tissue interaction from the training video, wherein the target tool-tissue interaction involves exerting a force by one or more surgical tools on a tissue. Next, for each video segment in the set of video segments, the process annotates each video image in the video segment with a set of force levels predefined for the target tool-tissue interaction. The process subsequently trains a machine-learning model using the annotated video images to obtain a trained machine-learning model for the target tool-tissue interaction.","['A61B1/00006', 'A61B1/000096', 'A61B34/25', 'A61B34/35', 'A61B34/37', 'A61B34/74', 'A61B34/76', 'G06N20/00', 'G06T7/0012', 'G16H20/40', 'G16H40/63', 'A61B1/04', 'A61B2034/302', 'A61B2034/305', 'A61B2034/743', 'A61B34/20', 'A61B90/361']"
US11030275B2,Modelling ordinary differential equations using a variational auto encoder,"A computer-implemented method comprising: from each of multiple trials, obtaining a respective series of observations y(t) of a subject over time t; using a variational auto encoder to model an ordinary differential equation, ODE, wherein the variational auto encoder comprises an encoder for encoding the observations into a latent vector z and a decoder for decoding the latent vector, the encoder comprising a first neural network and the decoder comprising one or more second neural networks, wherein the ODE as modelled by the decoder has a state x(t) representing one or more physical properties of the subject which result in the observations y, and the decoder models a rate of change of x with respect to time t as a function f of at least x and z: dx/dt=f(x, z); and operating the variational auto encoder to learn the function f based on the obtained observations y.","['G06N3/084', 'G06F17/13', 'G06F18/214', 'G06F18/2411', 'G06F18/2414', 'G06K9/6256', 'G06K9/6269', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06N3/08', 'G06V10/82', 'G06V20/698', 'G06N3/044']"
US20230124520A1,Task execution method and storage device,"Task execution methods and devices are provided. In an implementation, a method comprises: obtaining, by a central processing unit of a storage device, a data processing task, dividing, by the central processing unit, the data processing task into subtasks, and allocating, by the central processing unit, a first subtask in the subtasks to a first dedicated processor based on attributes of the subtasks, wherein the first dedicated processor is one of a plurality of dedicated processors of the storage device.","['G06F9/4881', 'G06F9/5061', 'G06F9/5066', 'G06F15/7821', 'G06F9/5027']"
US20190289282A1,Exposure coordination for multiple cameras,"In one embodiment, a computing system may determine a first target region within a first field of view of a first camera and a second target region within a second field of view of a second camera. The first field of view and the second field of view may be partially overlapping. The system may determine first lighting conditions of the first target region. The system may determine a first exposure time for at least the first camera and the second camera based at least in part on the determined first lighting conditions. The system may instruct the first camera and the second camera to take pictures using the determined first exposure time.","['H04N13/239', 'G05D1/0251', 'G06K9/00791', 'G06T7/593', 'G06T7/73', 'G06V20/56', 'H04N13/243', 'H04N13/296', 'H04N23/71', 'H04N23/73', 'H04N5/2351', 'H04N5/2353', 'G05D2201/0213', 'G06T2207/10012', 'G06T2207/10144', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US11865450B2,Systems and methods for predicting states by using a distributed game engine,"A method for reducing latency in execution of a game is described. The method includes receiving via a computer network a user input associated with the game and determining from the user input a current state of the game. While the current state of the game is being determined, the method includes predicting a next state of the game based on the user input and one or more predicted user inputs. The method further includes generating one or more predicted image frames from the next state, determining whether the one or more predicted user inputs are received via the computer network, and sending the one or more predicted image frames in response to receiving the one or more predicted user inputs to reduce the latency in execution of the game.","['A63F13/355', 'A63F13/577', 'A63F13/335', 'A63F13/358', 'A63F13/47', 'A63F13/50', 'A63F13/58', 'G06N20/00']"
KR101911061B1,System of product defect discrimination using an unsupervised learning based regional convolutional auto-encoder and Method of product defect discrimination using an unsupervised learning based regional convolutional auto-encoder,"The present invention relates to a system for discriminating a defect of a product using an unsupervised learning convolutional auto-encoder by defining an image and determining the defined image by region, and a method for discriminating the defect of the product using unsupervised learning based on a regional convolutional auto-encoder. The system of the present invention includes an image aligning unit for aligning a first product image provided from the outside according to a standard of the product; a regional convolutional auto-encoder receiving the first product image aligned by the image aligning unit; and a discrimination reference determining unit connected to the regional convolutional auto-encoder.","['G01N21/8851', 'G06T7/0004', 'G01N2021/8887', 'G06T2207/20081']"
US9814425B2,Health monitoring appliance,A monitoring system includes a wearable appliance; and a processor coupled to the wearable appliance to analyze vital data or wellness data.,"['A61B5/681', 'A61B5/0022', 'A61B5/0205', 'A61B5/021', 'A61B5/1112', 'A61B5/1117', 'A61B5/33', 'A61B5/7214', 'A61B5/7225', 'A61B7/04', 'A61B7/045', 'G16H40/67', 'G16Z99/00', 'A61B2503/08', 'A61B2560/0412', 'A61B5/0006', 'A61B5/0024', 'A61B5/0077', 'A61B5/0402', 'A61B5/1113', 'A61B5/318', 'A61B5/4806', 'A61B5/4833', 'A61B5/6803', 'A61B5/6808', 'A61B5/7257', 'A61B5/726', 'A61B5/7264', 'A61B5/7267', 'A61B5/7275', 'A61B5/7282', 'A61B5/7405', 'A61B5/746', 'A61B5/747', 'A61B8/565']"
US8968195B2,Health monitoring appliance,"A monitoring system includes a wearable eyeglass, band, belt, patch or bandage appliance; and a processor coupled to the wearable eyeglass, band, belt, patch or bandage appliance to analyze vital data or wellness data.","['A61B5/7465', 'A61B19/5202', 'A61B5/0022', 'A61B5/02055', 'A61B5/021', 'A61B5/0402', 'A61B5/1112', 'A61B5/1117', 'A61B5/681', 'A61B5/6814', 'A61B5/6816', 'A61B5/6887', 'A61B5/7214', 'A61B5/7225', 'A61B7/04', 'A61B8/00', 'A61B8/06', 'A61B8/4227', 'A61B8/565', 'A61B8/582', 'A61B90/30', 'G16H40/67', 'A61B2503/08', 'A61B2560/0412', 'A61B5/0006', 'A61B5/0024', 'A61B5/0077', 'A61B5/02438', 'A61B5/044', 'A61B5/0452', 'A61B5/0537', 'A61B5/1113', 'A61B5/1118', 'A61B5/112', 'A61B5/14532', 'A61B5/14551', 'A61B5/339', 'A61B5/349', 'A61B5/4806', 'A61B5/4833', 'A61B5/6808', 'A61B5/6815', 'A61B5/6898', 'A61B5/7257', 'A61B5/726', 'A61B5/7264', 'A61B5/7267', 'A61B5/7275', 'A61B5/7282', 'A61B5/741', 'A61B5/746', 'H04W4/80']"
CN111695420B,A gesture recognition method and related devices,"The embodiment of the application discloses a gesture recognition method and a related device, wherein a first point cloud data set is obtained by screening an original point cloud data set acquired by a radar device. The first point cloud data set comprises a plurality of frames of first sub point cloud data sets, the first sub point cloud data sets comprise first clustering centers, the first clustering centers are the clustering centers of a plurality of point cloud data in the first sub point cloud data sets, the maximum horizontal distance between any two first clustering centers meets a first preset condition, and the time length of the first point cloud data sets meets the first preset condition. Point cloud data of which the motion trail is inconsistent with the gesture motion can be effectively filtered. And gesture recognition is carried out by using the first point cloud data set obtained after screening, so that false triggering probability can be reduced, and man-machine interaction experience of a user is improved.","['G06V40/28', 'G06F3/017', 'G01S13/42', 'G01S13/584', 'G01S13/726', 'G01S13/88', 'G01S13/89', 'G01S7/417', 'G06F18/23', 'G06F18/241', 'G06N3/0442', 'G06N3/084', 'G06V10/7635', 'G06V10/82', 'G06V40/107', 'G06N3/045', 'G06N3/08', 'G06V2201/12']"
US11032513B2,Optimizing video conferencing using contextual information,"The present disclosure is directed toward systems and methods for optimizing video conferences. For instance, systems and methods described herein optimize both the transmission and display of one or more video conference data streams. Systems and methods described herein optimize the transmission and display of one or more video conference data streams by identifying a context associated with the one or more video conference data streams and optimizing the one or more video conference data streams based on the identified context.","['H04N7/147', 'H04L65/1089', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N19/85', 'H04N7/15', 'H04N19/115', 'H04N19/167', 'H04N19/174']"
US11151046B2,Programmable interface to in-memory cache processor,"The present disclosure is directed to systems and methods of implementing a neural network using in-memory mathematical operations performed by pipelined SRAM architecture (PISA) circuitry disposed in on-chip processor memory circuitry. A high-level compiler may be provided to compile data representative of a multi-layer neural network model and one or more neural network data inputs from a first high-level programming language to an intermediate domain-specific language (DSL). A low-level compiler may be provided to compile the representative data from the intermediate DSL to multiple instruction sets in accordance with an instruction set architecture (ISA), such that each of the multiple instruction sets corresponds to a single respective layer of the multi-layer neural network model. Each of the multiple instruction sets may be assigned to a respective SRAM array of the PISA circuitry for in-memory execution. Thus, the systems and methods described herein beneficially leverage the on-chip processor memory circuitry to perform a relatively large number of in-memory vector/tensor calculations in furtherance of neural network processing without burdening the processor circuitry.","['G06F12/0875', 'G06N3/063', 'G06F3/0604', 'G06F3/0629', 'G06F3/0673', 'G06F8/41', 'G06F9/45508', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06F2212/251']"
US20240062530A1,Deep perceptual image enhancement,"A system for training a neural network includes a neural network configured to receive a training input in an image space and produce an enhanced image. The system further includes an error signal generator configured to compare the enhanced image to a ground truth and generate an error signal that is communicated back to the neural network to train the neural network. Additionally, the system includes a neural input enhancer configured to modify the training input in response to receiving at least one of an output from the neural network or the error signal. Modifying the training input improves one of an efficiency or a training result of the neural network beyond the communication of the error signal to only the neural network.","['G06T5/00', 'G06T5/001', 'G06T5/50', 'G06V10/60', 'G06V10/7715', 'G06V10/774', 'G06V10/776', 'G06V10/82', 'G06V10/88', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20212']"
US11798535B2,On-device custom wake word detection,"Generally discussed herein are devices, systems, and methods for on-device detection of a wake word. A device can include a memory including model parameters that define a custom wake word detection model, the wake word detection model including a recurrent neural network transducer (RNNT) and a lookup table (LUT), the LUT indicating a hidden vector to be provided in response to a phoneme of a user-specified wake word, a microphone to capture audio, and processing circuitry to receive the audio from the microphone, determine, using the wake word detection model, whether the audio includes an utterance of the user-specified wake word, and wake up a personal assistant after determining the audio includes the utterance of the user-specified wake word.","['G10L15/063', 'G10L15/16', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10L17/24', 'G06N7/01', 'G10L15/07', 'G10L2015/088']"
US11430124B2,Visual object instance segmentation using foreground-specialized model imitation,"A method includes training, using at least one processor, a specialized teacher model to perform visual object instance segmentation in order to segment and classify objects in first training images. The first training images contain foreground objects without backgrounds. The method also includes training, using the at least one processor, a student model to perform visual object instance segmentation in order to segment and classify objects in second training images. The second training images contain the foreground objects and the backgrounds. Training the student model includes using selected outputs of the specialized teacher model. The method further includes deploying the trained student model to perform visual object instance segmentation in an external device.","['G06V10/25', 'G06F18/24', 'G06K9/6267', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T7/10', 'G06T7/11', 'G06V10/774', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084']"
US9792501B1,Method and device for visually impaired assistance,"A device, system, and method of assistance for visually impaired users. The system comprises a plurality of video cameras, often head mounted, computer processors and associated support devices and algorithms configured for computer vision, and a user worn haptic band comprising a plurality (two or more) of distantly spaced haptic transducers. This haptic band is worn such that user's hands are free for other tasks. The system uses its video camera, depth processing algorithms, and object recognition algorithms (hardware and/or software based) to identify a limited number of navigationally important objects. The spatial locations of each object deemed important is output to the user by varying output to the haptic transducers accordingly. The system is configured to identify and report objects as generic objects, identified objects, and potential obstacle objects. The system can also optionally provide audio information pertaining to these objects as well.","['H04N13/239', 'G06K9/00671', 'G06F18/24', 'G06F3/016', 'G06K9/6267', 'G06T7/593', 'G06V10/255', 'G06V20/20', 'G08B3/00', 'G08B6/00', 'H04N13/0239', 'H04N13/246', 'G06T2200/04', 'G06T2207/10012', 'H04N2013/0081']"
US20190294629A1,Systems and Methods of Building and Using an Image Catalog,"A method manages an image catalog at a server system. The system receives reduced-resolution versions of one or more images stored in an image database of an external service distinct from the system. For each received reduced-resolution version, the system creates an index entry in the image catalog. The system receives a query from a user and matches the query to an index entry in the catalog, which corresponds to an image stored as a full-resolution version in the image database. The system requests authorization from the owner of the image. When authorization is received, the system retrieves the full-resolution version from the image database, and temporarily stores the full-resolution version in temporary storage. The system then transmits the full-resolution version of the image to the user and releases the full-resolution version of the image from the temporary storage in response to the transmitting the full-resolution version.","['G06F16/5838', 'G06F16/50', 'G06F16/51', 'G06F16/53', 'G06F16/5846', 'G06F16/5854', 'G06F16/5866', 'G06K9/00288', 'G06K9/00362', 'G06K9/18', 'G06K9/4604']"
US11494331B2,Reconfigurable processor circuit architecture,"A representative reconfigurable processing circuit and a reconfigurable arithmetic circuit are disclosed, each of which may include input reordering queues; a multiplier shifter and combiner network coupled to the input reordering queues; an accumulator circuit; and a control logic circuit, along with a processor and various interconnection networks. A representative reconfigurable arithmetic circuit has a plurality of operating modes, such as floating point and integer arithmetic modes, logical manipulation modes, Boolean logic, shift, rotate, conditional operations, and format conversion, and is configurable for a wide variety of multiplication modes. Dedicated routing connecting multiplier adder trees allows multiple reconfigurable arithmetic circuits to be reconfigurably combined, in pair or quad configurations, for larger adders, complex multiplies and general sum of products use, for example.","['G06F15/7867', 'G06F15/80', 'G06F5/01', 'G06F7/487', 'G06F7/4876', 'G06F7/50', 'G06F7/52', 'G06F7/523', 'G06F7/5443', 'G06F9/30098', 'G06F9/3855', 'G06F9/3856', 'G06F9/3887', 'G06F9/4881', 'G06F9/54', 'H03K19/21', 'G06F2207/382', 'Y02D10/00']"
CN118095865B,AI large model driven emergency fire-fighting fire risk assessment and early warning method,"The invention provides an AI large-model emergency fire risk assessment and early warning method, aiming at improving the efficiency and accuracy of fire safety management. The environmental indexes of the key areas are monitored in real time through various sensors, and the acquired data are expanded through quantum state scheduling optimized generation countermeasure network, so that the generalization capability of the model is enhanced; feature extraction is carried out by utilizing a neural network algorithm imitating ocean tide process optimization, and feature dimension reduction is carried out by utilizing a self-coding neural network algorithm based on low-rank approximation, so that key information of data is effectively captured; and finally, classifying by adopting an extreme learning machine algorithm based on a rule strategy gradient so as to realize risk assessment of the new sample. The method not only solves the problems of insufficient data and over-fitting, but also improves the data processing speed and the accuracy of model prediction, is suitable for complex and changeable data sets, and provides an innovative technical means for fire risk assessment.","['G06Q10/0635', 'G06F18/213', 'G06F18/24', 'G06N3/0455', 'G06N3/092', 'G06Q50/265']"
US11861499B2,"Method, terminal-side device, and cloud-side device for data processing and terminal-cloud collaboration system","This application provides a method, a terminal-side device, and a cloud-side device for data processing and a terminal-cloud collaboration system. The method includes: sending, by the terminal-side device, a request message to the cloud-side device; receiving, by the terminal-side device, a second neural network model that is obtained by compressing a first neural network model and that is sent by the cloud-side device, where the first neural network model is a neural network model on the cloud-side device that is used to process the cognitive computing task, and a hardware resource required when the second neural network model runs on the terminal-side device is within an available hardware resource capability range of the terminal-side device; and processing, by the terminal-side device, the cognitive computing task based on the second neural network model.","['H04L67/10', 'G06N3/063', 'G06F9/5011', 'G06F9/5027', 'G06F9/5061', 'G06N3/04', 'G06N3/045', 'G06N3/0495', 'G06N3/082', 'H04L67/34', 'G06N3/0464']"
US11416165B2,Low synch dedicated accelerator with in-memory computation capability,"The present disclosure is directed to systems and methods of implementing a neural network using in-memory, bit-serial, mathematical operations performed by a pipelined SRAM architecture (bit-serial PISA) circuitry disposed in on-chip processor memory circuitry. The on-chip processor memory circuitry may include processor last level cache (LLC) circuitry. The bit-serial PISA circuitry is coupled to PISA memory circuitry via a relatively high-bandwidth connection to beneficially facilitate the storage and retrieval of layer weights by the bit-serial PISA circuitry during execution. Direct memory access (DMA) circuitry transfers the neural network model and input data from system memory to the bit-serial PISA memory and also transfers output data from the PISA memory circuitry to system memory circuitry. Thus, the systems and methods described herein beneficially leverage the on-chip processor memory circuitry to perform a relatively large number of vector/tensor calculations without burdening the processor circuitry.","['G06F3/0655', 'G06N3/063', 'G06F12/0802', 'G06F12/0875', 'G06F12/0897', 'G06F12/1081', 'G06F3/061', 'G06F3/0683', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06F2212/621', 'Y02D10/00']"
CN108898087B,"Training method, device and equipment for face key point positioning model and storage medium","The embodiment of the application discloses a training method, a device, equipment and a storage medium for a face key point positioning model. The method comprises the following steps: constructing a CNN model for positioning the key points of the face, wherein the number of convolution layers of the CNN model is greater than a first threshold value, and the number of channels of the convolution layers is less than a second threshold value; carrying out face key point positioning on the training sample by adopting a CNN model to obtain the predicted position of the face key point; the face key points comprise n types of classifications, wherein n is an integer larger than 1; respectively calculating the loss function values corresponding to the n classes according to the predicted position and the real position of the key point of the face of each class, and further calculating the loss function value of the CNN model; and when the loss function value of the CNN model is smaller than a preset threshold value, stopping training the CNN model and storing. According to the embodiment of the application, the size of the model is reduced on the premise that the positioning accuracy is not lost as far as possible by constructing the thin and long CNN model.","['G06V40/161', 'G06N3/045', 'G06V40/168', 'G06V40/172']"
US11630826B2,Real-time processing of a data stream using a graph-based data model,A method for processing of a data stream using a graph-based data model includes receiving a data stream including data messages; disassembling the data messages data elements and metadata; generating a structured data model comprising the set of data elements based on the type of the data elements and the pattern of the data messages; instantiating a workflow to process the structured data model; configuring a CPS-G model sub-graph to add to the CPS-G model based on the type of the data elements and the pattern of the data messages; adding the CPS-G model sub-graph to the CPS-G model to form the CPS-G dataset; and storing the CPS-G dataset including the CPS-G model sub-graph in a data store for further processing by streaming computation and machine learning algorithms.,"['G06F16/24568', 'G06F16/254', 'G06F16/9024', 'G06F9/541']"
US9186521B2,Windowing for identifying shock outcome,"A system for managing care of a person receiving emergency cardiac assistance is disclosed that includes one or more capacitors for delivering a defibrillating shock to a patient; one or more electronic ports for receiving signals from sensors for obtaining indications of an electrocardiogram (ECG) for the patient; and a patient treatment module executable on one or more computer processors using code stored in non-transitory media and to provide a determination of a likelihood of success from delivering a future defibrillating shock to the person with the one or more capacitors, using (a) a mathematical transform from a time domain to a frequency domain applied to the indication of the ECG, and (b) a tapered window for identifying the portion of the indications of the ECG on which the transform is performed.","['A61N1/3987', 'A61B5/0452', 'A61B5/053', 'A61B5/349', 'A61B5/4848', 'A61B5/7257', 'A61B5/7435', 'A61N1/3925', 'A61N1/3937', 'A61N1/3993']"
US11367433B2,End-to-end neural networks for speech recognition and classification,"Systems and methods are disclosed for end-to-end neural networks for speech recognition and classification and additional machine learning techniques that may be used in conjunction or separately. Some embodiments comprise multiple neural networks, directly connected to each other to form an end-to-end neural network. One embodiment comprises a convolutional network, a first fully-connected network, a recurrent network, a second fully-connected network, and an output network. Some embodiments are related to generating speech transcriptions, and some embodiments relate to classifying speech into a number of classifications.","['G10L15/16', 'G06F18/214', 'G06F18/24133', 'G06K9/6256', 'G06K9/6271', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G10L15/02', 'G10L15/063', 'G10L15/22', 'G10L15/30', 'G10L25/18', 'G10L25/24', 'G10L15/197', 'G10L2015/0635', 'G10L2015/081']"
US12190405B2,Direct memory writes by network interface of a graphics processing unit,"Examples described herein relate to a first graphics processing unit (GPU) with at least one integrated communications system, wherein the at least one integrated communications system is to apply a reliability protocol to communicate with a second at least one integrated communications system associated with a second GPU to copy data from a first memory region to a second memory region and wherein the first memory region is associated with the first GPU and the second memory region is associated with the second GPU.","['G06T1/20', 'G06F13/4282', 'G06F15/173', 'G06F15/17331', 'G06T1/60', 'H04L41/0803', 'G06F2213/3808']"
US20190247650A1,Systems and methods for augmenting human muscle controls,"Systems and methods are disclosed for physical assistance by: during a training phase, capturing muscle signals associated with a predetermined task and training a learning machine to associate the muscle signals with the task; during use, identifying a desired task to the learning machine to retrieve the muscle signals associated with the task; and applying functional electrical stimulation (FES) to actuate the muscle signals for the desired task.","['A61N1/3603', 'A61N1/025', 'A61N1/36003', 'A61N1/36007', 'A61N1/3625', 'A61N1/3704', 'G16H20/30', 'G16H40/63', 'G16H50/20', 'A61B2562/0219', 'A61B5/0022', 'A61B5/021', 'A61B5/318', 'A61B5/369', 'A61B5/389', 'A61B5/7267', 'A61N1/0484', 'Y02A90/10']"
CN109745062B,"CT image generation method, device, equipment and storage medium","The application discloses a method, a device and equipment for generating a CT image, wherein the method comprises the following steps: acquiring a first X-ray film and a second X-ray film, wherein the first X-ray film and the second X-ray film are X-ray films acquired for a target object by adopting two orthogonal visual angles; calling a generator to carry out three-dimensional reconstruction on the first X-ray film and the second X-ray film to obtain a three-dimensional model of the target object; and obtaining the CT image of the target object according to the three-dimensional model of the target object. According to the method and the device, the CT image of the target object is reconstructed by inputting the two orthogonal X-ray films into the generator, so that the medical image which is equivalent to or similar to the CT scanning equipment can be obtained only by the X-ray film machine, the radiation hazard to the target object is reduced, the inspection cost can be saved, and the time consumption of the inspection process is shortened.","['A61B6/5223', 'G06T11/006', 'A61B6/466', 'A61B6/5229', 'G06T9/002', 'A61B6/5205', 'G06T2211/436', 'G06T2211/441']"
US11030487B2,Noise-robust neural networks and methods thereof,"The exemplified methods and systems facilitate the training of a noise-robust deep learning network that is sufficiently robust in the recognition of objects in images having extremely noisy elements such that the noise-robust network can match, or exceed, the performance of human counterparts. The extremely noisy elements may correspond to extremely noisy viewing conditions, e.g., that often manifests themselves in the real-world as poor weather or environment conditions, sub-optimal lighting conditions, sub-optimal image acquisition or capture, etc. The noise-robust deep learning network is trained both (i) with noisy training images with low signal-to-combined-signal-and-noise ratio (SSNR) and (ii) either with noiseless, or generally noiseless, training images or a second set of noisy training images having a SSNR value greater than that of the low-SSNR noisy training images.","['G06K9/6257', 'G06T5/70', 'G06F18/2148', 'G06F18/2411', 'G06K9/6203', 'G06K9/6269', 'G06T5/002', 'G06T5/60', 'G06T7/0016', 'G06V10/30', 'G06V10/7515', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/10004', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
CN115294407B,Model compression method and system based on preview mechanism knowledge distillation,"The invention belongs to the field of computer vision image classification, and provides a model compression method and system based on preview mechanism knowledge distillation to solve the problems of poor accuracy and instability in image classification identification. Acquiring an image sample, marking a label of the image sample, and performing supervision training on a student network; enabling the student network and a pre-trained teacher network to perform output alignment, feature alignment, category center alignment and category center comparison learning; calculating difficulty scores of the image samples, and dynamically distributing weights of different image samples; obtaining a total loss function based on loss functions of supervision training, output alignment, feature alignment, category center alignment and category center comparison learning and weights of different image samples; and guiding the training of the student network according to the total loss function to obtain the trained student network which is used as an image classification model for carrying out class distribution prediction on the input image. Which improves the accuracy of the image recognition classification.","['G06V10/764', 'G06N3/082', 'G06N5/02', 'G06V10/7788', 'G06V10/82']"
US11657146B2,Compressibility metric-based detection of a ransomware threat to a storage system,"An illustrative method includes a data protection system determining a first compressibility metric associated with write traffic processed by a storage system, the first compressibility metric indicating an amount of storage space saved if the write traffic is compressed; determining a second compressibility metric associated with read traffic processed by a storage system, the second compressibility metric indicating an amount of storage space saved if the read traffic is compressed; determining, based on a comparison of the first compressibility metric with the second compressibility metric, that the write traffic is less compressible than the read traffic; determining, based on the write traffic being less compressible than the read traffic, that the storage system is possibly being targeted by a security threat; and performing, based on the determining that the storage system is possibly being targeted by the security threat, a remedial action with respect to the storage system.","['G06F21/552', 'G06F11/108', 'G06F11/1441', 'G06F11/1469', 'G06F11/2092', 'G06F11/2094', 'G06F11/3034', 'G06F11/34', 'G06F11/3409', 'G06F11/3485', 'G06F21/577', 'G06F21/602', 'G06F2201/81', 'G06F2201/84']"
CN118233936B,Integrated networking method and system based on satellite communication and short wave communication,"The invention discloses a fusion networking method and system based on satellite communication and short wave communication, comprising the following steps: acquiring demand data of an application scene, constructing a converged communication network, and configuring initial parameters of a system; collecting and preprocessing historical communication data of an application scene to form a training set, constructing a converged communication network optimization module and training, and updating initial parameters of the converged communication network after training is completed to obtain a converged communication network with optimized parameters; configuring a fusion communication network with optimized parameters, respectively estimating channel parameters of a current satellite communication system and a short wave communication system, and estimating channel quality according to the channel parameters; and adjusting a modulation and coding scheme by adopting an adaptive modulation and coding module according to the channel quality, performing cross-layer route optimization on the constructed converged communication network, and transmitting the packet data in a preset mode. Through fusion complementation of multi-level heterogeneous networks, global information transmission can be realized in a complex environment.","['H04W24/02', 'H04B17/373', 'H04B17/382', 'H04B7/18513', 'H04W24/06', 'H04W40/12', 'H04W84/06', 'H04W84/18', 'Y02D30/70']"
EP3955104A1,Screen projection method and system and related apparatus,"This application discloses a screen projection method, including: First, an electronic device displays M application interfaces on a display of the electronic device, where M is an integer greater than 1. Then, the electronic device receives a first selection operation, and determines N application interfaces based on the first selection operation, where the first selection operation is performed on the electronic device to determine the N application interfaces from the M application interfaces, and N is a positive integer less than or equal to M. Then, the electronic device sends first data to an external display device in response to the first selection operation, where the first data is used by the external display device to display the N application interfaces. In this way, when split-screen displaying a plurality of application interfaces, the electronic device can select one or more of the plurality of application interfaces and project the one or more application interfaces onto a large-screen display, to ensure that an application interface involving user privacy is projected only after a user agrees and confirms. This protects user privacy.","['G06F3/1454', 'G06F21/6245', 'G06F21/84', 'G06F3/04817', 'G06F3/0482', 'G09G5/14', 'G09G2340/10', 'G09G2340/12', 'G09G2354/00']"
US10527699B1,Unsupervised deep learning for multi-channel MRI model estimation,An MRI apparatus performs multi-channel calibration acquisitions using a multi-channel receiver array and uses a convolutional neural network (CNN) to compute an estimated profile map that characterizes properties of the multi-channel receiver array. The profile map is composed of orthogonal vectors and transforms single-channel image space data to multi-channel image space data. The MRI apparatus performs a prospectively subsampled imaging acquisition and processes the resulting k-space data using the estimated profile map to reconstruct a final image. The CNN may be pretrained in an unsupervised manner using subsampled simulated multi-channel calibration acquisitions and using a regularization function included in a training loss function.,"['G01R33/5612', 'G01R33/5611', 'G06N3/045', 'G06N3/088', 'G06N5/046', 'G01R33/5608']"
US10602163B2,Encoder pre-analyser,"The present disclosure relates to analysing input data, prior to encoding, using one or more hierarchical algorithms. According to a first aspect, there is provided a method for producing output data using one or more input data and one or more hierarchical algorithms, comprising the steps of applying the hierarchical algorithm to the one or more input data; and producing output data to be used by an encoder; wherein one of the one or more input data is uncompressed; and wherein the output data is used to modify a decision making process associated with the encoder.","['H04N19/30', 'H04N19/103', 'H04N19/119', 'H04N19/124', 'H04N19/139', 'H04N19/149', 'H04N19/159', 'H04N19/174', 'H04N19/176', 'H04N19/1883', 'H04N19/196', 'G06N5/04']"
US10163137B2,System and method for incentivizing participation in a market transaction,"A system and method providing for communication and resolution of utility functions between participants, wherein the utility function is evaluated based on local information at the recipient to determine a cost value thereof. A user interface having express representation of both information elements, and associated reliability of the information. An automated system for optimally conveying information based on relevance and reliability.","['G06Q30/0282', 'G06Q30/0207', 'G06Q30/08', 'G07F17/32', 'G07F17/323', 'G07F17/3237']"
US20240395267A1,System and method for enhancement of a degraded audio signal,"The present disclosure relates to the field of audio enhancement, and in particular to methods, devices and software for supervised training of a machine learning model, MLM, the MLM trained to enhance a degraded audio signal by calculating gains to be applied to frequency bands of the degraded audio signal. The present disclosure further relates to methods, devices and software for use of such a trained MLM.","['G10L21/02', 'G10L19/0208', 'G06N20/00', 'G10L19/005', 'G10L25/18', 'G10L25/21', 'G10L21/0232', 'H04M3/568']"
US20190294975A1,Predicting using digital twins,"In various examples there is a computer-implemented method performed by a digital twin at a computing device in a communications network. The method comprises: receiving at least one stream of event data observed from the environment. Computing at least one schema from the stream of event data, the schema being a concise representation of the stream of event data. Participating in a distributed inference process by sending information about the schema or the received event stream to at least one other digital twin in the communications network and receiving information about schemas or received event streams from the other digital twin. Computing comparisons of the sent and received information. Aggregating the digital twin and the other digital twin, or defining a relationship between the digital twin and the other digital twin on the basis of the comparison.","['G05B17/02', 'G06N5/022', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04L7/00', 'H04W56/00', 'G06N20/10', 'G06N20/20', 'G06N3/006', 'G06N5/01']"
US11810374B2,Training text recognition systems,"In implementations of recognizing text in images, text recognition systems are trained using noisy images that have nuisance factors applied, and corresponding clean images (e.g., without nuisance factors). Clean images serve as supervision at both feature and pixel levels, so that text recognition systems are trained to be feature invariant (e.g., by requiring features extracted from a noisy image to match features extracted from a clean image), and feature complete (e.g., by requiring that features extracted from a noisy image be sufficient to generate a clean image). Accordingly, text recognition systems generalize to text not included in training images, and are robust to nuisance factors. Furthermore, since clean images are provided as supervision at feature and pixel levels, training requires fewer training images than text recognition systems that are not trained with a supervisory clean image, thus saving time and resources.","['G06V20/62', 'G06F18/214', 'G06F18/2413', 'G06V10/764', 'G06V20/63', 'G06V30/153', 'G06V2201/01']"
US20250077308A1,"Distributed computing method, system and device, and storage medium","The present disclosure relates to the field of data processing. Provided is a distributed computing method, comprising: acquiring a data computing task; splitting the data computing task to obtain subtasks, deploying the subtasks to computing nodes, and configuring a parallel mode for each of the computing nodes in a distributed training universal frame; configuring a connection manner and a communication synchronization manner between the computing nodes; optimizing information synchronization efficiency for the computing nodes by using a gradient optimization algorithm or a non-gradient optimization algorithm; and aggregating intermediate results generated by the computing nodes, and outputting a corresponding final computing result. The present disclosure may reduce restriction from a hardware system, and by means of effective distributed algorithm design, a subtask training space is reduced, and the model training time is reduced, thereby effectively improving the accuracy of model training, and reducing the storage overhead of gradient and model parameter variables. Further provided are a distributed computing system, a distributed computing device, and a non-transitory computer-readable storage medium, which have the above beneficial effects.","['G06F9/52', 'G06F9/5066', 'G06F9/5061', 'G06F9/5083', 'G06N3/04', 'G06N3/08', 'G06F2209/5017', 'Y02D10/00']"
US20180268292A1,Learning efficient object detection models with knowledge distillation,"A computer-implemented method executed by at least one processor for training fast models for real-time object detection with knowledge transfer is presented. The method includes employing a Faster Region-based Convolutional Neural Network (R-CNN) as an objection detection framework for performing the real-time object detection, inputting a plurality of images into the Faster R-CNN, and training the Faster R-CNN by learning a student model from a teacher model by employing a weighted cross-entropy loss layer for classification accounting for an imbalance between background classes and object classes, employing a boundary loss layer to enable transfer of knowledge of bounding box regression from the teacher model to the student model, and employing a confidence-weighted binary activation loss layer to train intermediate layers of the student model to achieve similar distribution of neurons as achieved by the teacher model.","['G06V10/82', 'G06F18/21', 'G06F18/2185', 'G06F18/24143', 'G06K9/66', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06V10/70', 'G06V20/35', 'G06V30/19167', 'G06V30/19173']"
US11216698B2,Training a non-reference video scoring system with full reference video scores,"The disclosed technology teaches training a NR VMOS score generator by generating synthetically impaired images from FR video using filters tuned to generate impaired versions and applying a FR VMOS generator to pairs of unimpaired FR images from the FR video and the impaired versions of the FR images to create ground truth scores for the impaired versions. The disclosed method also includes training by machine learning model an image evaluation classifier using the ground truth scores and the impaired versions to generate NR VMOS scores, and storing coefficients of the image evaluation classifier for use as the NR VMOS score generator. Also disclosed is generating a NR VMOS score by invoking the trained NR VMOS score generator, with stored coefficients generated by feeding the trained NR VMOS score generator with images captured from scenes in a video to be scored, and evaluating the images to generate NR VMOS scores.","['G06K9/6262', 'G06T7/0002', 'G06F18/214', 'G06F18/217', 'G06K9/00718', 'G06K9/6256', 'G06N20/10', 'G06N3/045', 'G06N3/08', 'G06T5/20', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06N3/044', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/30168']"
US11836615B2,Bayesian nonparametric learning of neural networks,"In federated learning problems, data is scattered across different servers and exchanging or pooling it is often impractical or prohibited. A Bayesian nonparametric framework is presented for federated learning with neural networks. Each data server is assumed to provide local neural network weights, which are modeled through our framework. An inference approach is presented that allows us to synthesize a more expressive global network without additional supervision, data pooling and with as few as a single communication round. The efficacy of the present invention on federated learning problems simulated from two popular image classification datasets is shown.","['G06N3/082', 'G06N3/08', 'G06N3/047', 'G06N3/044', 'G06N3/045']"
US12405433B2,Communication systems having pluggable modules,"A system includes a housing having a front panel, a substrate that is positioned at a distance from the front panel, and a data processor mounted on the substrate. The system includes a pluggable module having an optical module, at least one first optical connector, a first fiber optic cable optically coupled between the optical module and the first optical connector, and a fiber guide positioned between the optical module and the first optical connector and provides mechanical support for the optical module and the first optical connector. The optical module receives optical signals from the first optical connector and generates electrical signals based on the received optical signals, and the electrical signals are transmitted to the data processor. The pluggable module has a shape that enables the pluggable module to pass through an opening in the front panel to enable the optical module to be coupled to the substrate.","['G02B6/4292', 'G02B6/4261', 'G02B6/4268', 'G02B6/428', 'G02B6/4285', 'G02B6/4278', 'H04B10/66']"
US11934791B2,On-device projection neural networks for natural language understanding,"The present disclosure provides projection neural networks and example applications thereof. In particular, the present disclosure provides a number of different architectures for projection neural networks, including two example architectures which can be referred to as: Self-Governing Neural Networks (SGNNs) and Projection Sequence Networks (ProSeqoNets). Each projection neural network can include one or more projection layers that project an input into a different space. For example, each projection layer can use a set of projection functions to project the input into a bit-space, thereby greatly reducing the dimensionality of the input and enabling computation with lower resource usage. As such, the projection neural networks provided herein are highly useful for on-device inference in resource-constrained devices. For example, the provided SGNN and ProSeqoNet architectures are particularly beneficial for on-device inference such as, for example, solving natural language understanding tasks on-device.","['G06F40/30', 'G06F40/253', 'G06N3/04', 'G06N3/044', 'G06N3/063', 'G06N3/082', 'G06N3/084', 'G06N3/045', 'G06N5/022', 'G06N7/01']"
US11449759B2,Medical imaging diffeomorphic registration based on machine learning,"For registration of medical images with deep learning, a neural network is designed to include a diffeomorphic layer in the architecture. The network may be trained using supervised or unsupervised approaches. By enforcing the diffeomorphic characteristic in the architecture of the network, the training of the network and application of the learned network may provide for more regularized and realistic registration.","['G06T7/33', 'G06F18/22', 'G06F18/2413', 'G06K9/6256', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06N3/088', 'G06T7/0012', 'G06V10/454', 'G06V10/75', 'G06V10/761', 'G06V10/764', 'G06F18/214', 'G06T2207/10072', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03']"
US20240355463A1,Method and system for computer-aided triage of stroke,"A system for computer-aided triage includes a router, a remote computing system, and a client application. Additionally or alternatively, the system 100 can include any number of computing systems, servers, storage, lookup table, memory, and/or any other suitable components. A method for computer-aided triage includes receiving a data packet associated with a patient and taken at a first point of care; checking for a suspected condition associated with the data packet; in an event that the suspected condition is detected, determining a recipient based on the suspected condition; and transmitting information to a device associated with the recipient.","['G06N3/045', 'G06N3/08', 'G06Q10/06311', 'G06T11/001', 'G06T7/0012', 'G06T7/11', 'G06T7/62', 'G16H10/20', 'G16H15/00', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/67', 'G16H50/20', 'G16H50/30', 'G16H80/00', 'G06N20/20', 'G06N5/01', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/30016', 'G06T2210/41']"
US11720691B2,Encryption indicator-based retention of recovery datasets for a storage system,"An illustrative method includes determining an encryption indicator for a first recovery dataset by determining a difference in an amount or percentage of incompressible data associated with the first recovery dataset compared to an amount or percentage of incompressible data associated with a second recovery dataset that temporally precedes the first recovery dataset, the encryption indicator representative of data within or represented by the first recovery dataset that cannot be compressed more than a threshold amount; and performing, based on the encryption indicator for the first recovery dataset, an action with respect to the second recovery dataset, wherein the second recovery dataset is usable to restore data maintained by a storage system to a second state corresponding to a second point in time that temporally precedes a first point in time corresponding to the first recovery dataset.","['G06F11/1458', 'G06F21/602', 'G06F11/1461', 'G06F11/1469', 'G06F11/2094', 'G06F21/554', 'G06F3/0608', 'G06F3/0652', 'G06F3/067', 'G06F2201/84', 'G06F2221/034', 'G06N10/00', 'G06N20/00', 'G06N3/063']"
US12182424B2,Optimizing data reduction for data in encrypted volumes,"A method of data reduction in a partially encrypted volume includes receiving data to be stored on a storage array, decrypting the data using a first encryption key to generate first decrypted data, and decrypting the data using a second encryption key to generate second decrypted data. The method further includes comparing, by a storage array controller, a first compressibility value of the first decrypted data to a second compressibility value of the second decrypted data. The method further includes storing the first decrypted data if the first compressibility value is greater than or equal to the second compressibility value. The method further includes storing the second decrypted data if the second compressibility value is greater than the first compressibility value.","['G06F3/0626', 'G06F3/0608', 'G06F3/062', 'G06F3/0661', 'G06F3/0662', 'G06F3/067', 'G06F3/0689', 'G06F9/45558', 'H04L9/14', 'G06F2009/45583', 'G06F2009/45587', 'H04L2209/30']"
US12079162B2,Snapshot management in a storage system,"An illustrative data storage system captures snapshots of a data structure based on snapshot creation schedules and sets retention periods for the snapshots based on snapshot retention schedules. The data storage system eradicates snapshots based on expirations of the retention periods. In certain examples, the data storage system determines a rule to use to capture a snapshot based on a state of snapshots within one or more lookback periods and/or based on a set of rules each defining a snapshot capture schedule and a snapshot retention schedule.","['G06F11/1471', 'G06F11/1451', 'G06F11/2094', 'G06F16/128', 'G06F16/27', 'G06F21/6218', 'G06F11/2097', 'G06F2201/815', 'G06F2201/84', 'G06F2201/88']"
US10970395B1,Security threat monitoring for a storage system,"An exemplary security threat monitoring system receives performance metric data representative of a performance metric for a storage system, applies the performance metric data as an input to an unsupervised machine learning model, and identifies, based on an output of the unsupervised machine learning model, an anomaly in the performance metric data.","['G06F21/566', 'G06F21/554', 'G06N20/00', 'G06F2221/034', 'G06N3/045', 'G06N3/08', 'G06N3/088']"
US12131502B2,Object pose estimation in visual data,"The pose of an object may be estimated based on fiducial points identified in a visual representation of the object. Each fiducial point may correspond with a component of the object, and may be associated with a first location in an image of the object and a second location in a 3D coordinate pace. A 3D skeleton of the object may be determined by connecting the locations in the 3D space, and the object's pose may be determined based on the 3D skeleton.","['G06T7/579', 'G06T7/75', 'G06N3/08', 'G06T7/596', 'G06T7/73', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30244', 'G06T2207/30248']"
EP4277207A2,Network telemetry collection with packet metadata filtering,"In embodiments, a telemetry exporter in a network establishes a tunnel between the telemetry exporter and a traffic analysis service. The telemetry exporter obtains packet copies of a plurality of packets sent between devices via the network. The telemetry exporter forms a set of traffic telemetry data by discarding at least a portion of one or more of the packet copies, based on a filter policy. The telemetry exporter applies compression to the formed set of traffic telemetry data. The telemetry exporter sends, via the tunnel, the compressed set of traffic telemetry data to the traffic analysis service for analysis.","['H04L63/1458', 'H04L63/306', 'G06N20/00', 'G06N5/04', 'H04L63/0428', 'H04L63/1425']"
US12373397B2,Managing directory-tree operations in file storage,"An illustrative data storage system establishes path sets that represent relationships between service layer entities and storage layer entities associated with service layer entities. The data storage system coordinates, based on the path sets and on operations applied to one or more of the service layer entities, implementation of the operations on the storage layer entities. The path sets may be used to support implementation of snapshots, space accounting, and/or other operations of the data storage system.","['G06F16/185', 'G06F16/128', 'G06F16/162', 'G06F16/1734', 'G06F16/1824', 'G06F16/184', 'G06F16/188']"
CN110751649B,"Video quality evaluation method and device, electronic equipment and storage medium","The embodiment of the application provides a video quality evaluation method and device, electronic equipment and a storage medium, and relates to the technical field of information processing. The method comprises the following steps: firstly, acquiring a video to be processed and a reference video corresponding to the video to be processed; then determining a residual video based on the video to be processed and the reference video; determining a space-time characteristic corresponding to each video frame to be processed in the video to be processed based on the video to be processed and the residual video; and determining the quality evaluation result of the video to be processed based on the space-time characteristics and the residual video corresponding to each video frame to be processed. According to the technical scheme, quality assessment is carried out through the space-time characteristics of the residual video and the video to be processed, the residual video reflects the difference between the video to be processed and the reference video, namely the distortion degree, the space-time characteristics of the video to be processed simultaneously consider two dimensions of time and space, the characteristic information is more comprehensive, the accuracy of quality assessment is improved, and the objective assessment of the video quality is realized.","['G06T7/0002', 'G06T2207/10016', 'G06T2207/30168']"
US11294756B1,Anomaly detection in a network,"Anomaly detection for one or more streams of time-series data can use an encoder/decoder pair, such as in a variational autoencoder (VAE) in combination with an aggregator or classifier, such as a random isolation forest (RIF). A particular application relates to detecting anomalies in network updates in a large number of network devices that can transmit the updates to a collector for analysis. The encoder/decoder pair can include a neural network with long short-term memory cells or similar type cells. Using the combination, a single anomaly score can be produced from multiple streams of the time-series data.","['G06F11/079', 'G06F11/3006', 'G06F11/0709', 'G06F11/0751', 'G06F11/3452', 'G06F11/3466', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'H04L41/064', 'H04L41/16']"
CN109859288B,Image coloring method and device based on generation countermeasure network,"The embodiment of the invention provides an image coloring method and device based on a generation countermeasure network, wherein the method comprises the following steps: inputting an image to be colored into an image coloring model based on a generated countermeasure network, and acquiring a color image output by the image coloring model based on the generated countermeasure network; the image coloring model based on the generation countermeasure network is obtained after training based on the image sample to be colored and the corresponding color image sample. According to the image coloring method and device based on the generation countermeasure network, provided by the embodiment of the invention, the restoration coloring model which can be suitable for all types of images can be quickly obtained by using the training data with strong generality and an end-to-end learning method, and the method and device are more universal and have a wider application range.",[]
CN111277826B,Video data processing method and device and storage medium,"The embodiment of the application discloses a video data processing method, a video data processing device and a storage medium, wherein the method comprises the following steps: acquiring a video sequence to be encoded associated with a video source; the video sequence to be coded comprises a first video sequence corresponding to the first video attribute parameter and a second video sequence corresponding to the second video attribute parameter; pre-coding the first video sequence to obtain a pre-coded video sequence, and acquiring video coding characteristics of the pre-coded video sequence; determining a first encoding parameter associated with the first video attribute parameter and a second encoding parameter associated with the second video attribute parameter according to the video encoding characteristics and the video attribute characteristics associated with the video sequence to be encoded; and obtaining a coded video sequence associated with the video sequence to be coded according to the first coding parameter, the first video sequence, the second coding parameter and the second video sequence. By adopting the embodiment of the application, the waste of computing resources can be reduced, and the efficiency of multi-channel transcoding can be improved.","['H04N21/44008', 'H04N19/149', 'H04N21/2187', 'H04N21/4334', 'H04N21/4402', 'H04N21/8455', 'H04N21/8456']"
EP4315673A1,Model-based determination of feedback information concerning the channel state,"A wireless transmit/receive unit (WTRU) may adapt an Al model, e.g., based on changes in computational resources, changes in a power status, etc. For example, a WTRU may determine first channel state information (CSI) feedback information using a first data processing model. The WTRU may determine that a triggering condition associated with use of the first data processing model has been met. The WTRU may determine, based on the determination that the triggering condition has been met, a data processing model to use to determine second CSI feedback information, where the data processing model is different than the first data processing model. The WTRU may transmit an indication of the determined data processing model. The WTRU may determine the second CSI feedback information using the determined data processing model. The WTRU may transmit an indication of the determined second CSI feedback information.","['H04L1/0026', 'H04L1/1812', 'H04L5/0055', 'H04L5/0057']"
CN111916215B,"Cluster/chronic disease early automatic alarm, preliminary feature analysis and risk assessment system","The invention discloses a cluster/chronic disease early automatic alarm, preliminary characteristic analysis and risk assessment system in the field of public health, which comprises a case information collection module, an activity track tracking module, an automatic alarm display module and a risk analysis and evaluation module; by timing scanning of a medical record database of a medical institution and automatic analysis of individual action tracks of patients, automatic alarm can be realized on emergent cluster diseases, the summary and the preliminary risk analysis and evaluation of the same case in unit time can be performed, and the control of the difference prevention and control measures of the chronic diseases in the region can be guided by analyzing the distribution characteristics of the cases in unit time.","['G16H50/70', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G16H10/60', 'G16H50/30']"
US11390129B1,Pneumatic vehicle suspension system,"A pneumatic suspension system may include, for each wheel of a vehicle, a strut and an adjustment cylinder in fluid communication with the strut. Adjustment cylinders associated with an end of the vehicle may be mechanically coupled while keeping the cylinders isolated pneumatically. A suspension control system can control fluid flow at each of the adjustment cylinders to selectively engage or disengage an anti-roll feature. By allowing fluid flow at the adjustment cylinders, the struts are free to oscillate in response to forces at the associated wheel, e.g., caused by an uneven road. By inhibiting fluid flow at the adjustment cylinders, forces experienced at the struts can be transferred between multiple struts. In some examples, the fluid flow at the adjustment cylinders can be controlled to vary the travel distance of the struts, to selectively provide a stiffer or looser suspension.","['B60G17/0155', 'B60G11/27', 'B60G17/0162', 'B60G17/0523', 'B60G17/06', 'B60G2400/204', 'B60G2400/821', 'B60G2400/842', 'B60G2401/14', 'B60G2401/142', 'B60G2401/174', 'B60G2401/176', 'B60G2500/10']"
US11122240B2,Enhanced video conference management,"Methods, systems, and apparatus, including computer-readable media storing executable instructions, for enhanced video conference management. In some implementations, a participant score for each participant in a set of multiple participants in the communication session. Each of the participant scores is based on at least one of facial image analysis or facial video analysis performed using image data or video data captured for the corresponding participant during the communication session. Each of the participant scores is indicative of an emotional or cognitive state of the corresponding participant. The participant scores are used to generate an aggregate representation of the emotional or cognitive states of the set of multiple participants. During the communication session, output data is comprising the aggregate representation of the emotional or cognitive states of the set of multiple participants is provided for display.","['H04N7/152', 'G06K9/00718', 'G06V20/41']"
US11662909B2,Metadata management in a storage system,"A system and method for efficiently maintaining metadata stored among a plurality of solid-state storage devices. A data storage subsystem supports multiple mapping tables. Records within a mapping table are arranged in multiple levels. Each level stores at least pairs of a key value and a physical pointer value. The levels are sorted by time. New records are inserted in a created new highest (youngest) level. No edits are performed in-place. A data storage controller determines both a cost of searching a given table exceeds a threshold and an amount of memory used to flatten levels exceeds a threshold. In response, the controller incrementally flattens selected levels within the table based on key ranges. After flattening the records in the selected levels within the key range, the records may be removed from the selected levels. The process repeats with another different key range.","['G06F3/0608', 'G06F12/0292', 'G06F12/023', 'G06F12/121', 'G06F3/0619', 'G06F3/0641', 'G06F3/0665', 'G06F3/0689', 'G06F12/0238', 'G06F2212/401', 'G06F2212/7201']"
US8500636B2,Health monitoring appliance,"A monitoring system for a person includes one or more wireless nodes; and a wearable patch or bandage appliance secured to the person' skin and in communication with the one or more wireless nodes, wherein the patch or bandage appliance monitors and transmits patient vital signs to the wireless nodes.","['A61B5/6833', 'A61B5/00', 'A61B5/0004', 'A61B5/0006', 'A61B5/0015', 'A61B5/002', 'A61B5/0022', 'A61B5/0024', 'A61B5/02405', 'A61B5/026', 'A61B5/11', 'A61B5/1112', 'A61B5/1113', 'A61B5/1117', 'A61B5/349', 'A61B5/4806', 'A61B5/4833', 'A61B5/4866', 'A61B5/6802', 'A61B5/681', 'A61B5/683', 'A61B5/7214', 'A61B5/746', 'A61B7/04', 'G16H40/67', 'H04M3/5116', 'A61B2560/0228', 'A61B2560/0412', 'A61B5/02055', 'A61B5/021', 'A61B5/02438', 'A61B5/14532', 'A61B5/7267', 'A61B5/743', 'A61B5/7465', 'H04M2203/1075', 'H04M2250/12']"
CN115100470B,Small sample image classification system and method thereof,"The invention relates to a small sample image classification system and a method, a multi-resolution module is used for learning feature embedding of images with different resolutions, generating depth local descriptors for input images and learning the feature embedding of the images with different resolutions, wherein the distribution of each query image and each support class can be represented on the level of the depth local descriptors; the global attention module amplifies the cross-dimension receiving area and captures important interaction characteristics of the global dimension; the self-adaptive fusion module is used for adaptively fusing the local relation and the global relation together by the weight vector obtained by joint learning, and a non-parameter nearest neighbor classifier is used as a dynamic classifier; and the self-distillation module is used for distilling the shallow network sharing the weight of the second-layer convolution module by taking the deep network classifier as a teacher network. The convolution neural network adopts a multi-resolution learning method, a global attention mechanism is integrated into a self-distillation method, and the problem of image space redundancy in a small sample learning task is solved.","['G06V10/764', 'G06N3/08', 'G06V10/774', 'G06V10/80', 'G06V10/82']"
CN118378912B,Emergency scene intelligent analysis and decision support method based on AI large model,"The invention provides an intelligent analysis and decision support method for an emergency scene based on an AI large model, which comprises six parts: multisource data integration and preprocessing, dynamic scenario modeling, decision perspective and behavior analysis, real-time data processing and feedback, adaptive decision support, and knowledge-driven learning and optimization. The method integrates the Bayesian network fusion depth belief network to preprocess the multi-source data, so that the information reliability and consistency are improved; by combining a dynamic scene modeling with a self-adaptive deep learning network and a graph neural network, the adaptability and generalization capability of the model are improved; the real-time data processing architecture ensures low delay of data processing, so that the system can rapidly respond to emergency; the self-adaptive decision support mechanism combines reinforcement learning, so that the flexibility and accuracy of decision making are improved. The invention provides scientific, strict and efficient support for emergency management, obviously enhances the capability of coping with emergency situations, and ensures the real-time performance and accuracy of decision making.","['G06Q10/0637', 'G06F18/213', 'G06F18/2411', 'G06F18/24155', 'G06F18/2431', 'G06N3/0442', 'G06N3/0475', 'G06N3/048', 'G06N3/084', 'G06N3/094', 'G06Q10/06313', 'G06Q50/26']"
US11438610B2,Block-level super-resolution based video coding,"A method of encoding video data into a bitstream comprising: determining from the plurality of video blocks of a video frame of a first resolution a current block and one or more reference blocks including reference samples for predicting original samples of the current block; determining predicted samples of the current block based on a downsampling scheme, the determining comprising computing samples of a first low-resolution block of a second resolution that is lower than the first resolution, and predicting samples of one or more second low-resolution blocks of the second resolution based on the samples of the first low resolution block, the samples of the first low-resolution block and the one or more second low-resolution blocks defining predicted samples of the current Block; and, determining residual samples of a residual block based on original samples of the current block and the predicted samples of the current block; transforming the samples of the residual block into a bitstream; and, embedding metadata associated with the current block in the bitstream for signalling a decoder apparatus that the predicted samples of the current block are based on the downsampling scheme.","['H04N19/59', 'H04N19/33', 'G06T3/4046', 'G06T9/002', 'H04N19/105', 'H04N19/11', 'H04N19/119', 'H04N19/132', 'H04N19/147', 'H04N19/159', 'H04N19/176', 'H04N19/177', 'H04N19/184', 'H04N19/30', 'H04N19/46', 'H04N19/593', 'H04N19/70']"
US11720786B2,"Information processing apparatus, information processing method, and program","According to the present disclosure, a weight parameter of a neural network is divided into a plurality of portions having a certain size and approximation is individually performed on the portions using a weighted sum of the codebook vectors.","['G06N3/045', 'G06N3/08', 'G06N3/0454', 'G06N3/084']"
CN111553484B,"Federal learning method, device and system","The application discloses a federal learning method, a federal learning device and a federal learning system, wherein the federal server sends initial models to all clients in a unified way, and the clients receive the initial models sent to all clients in the unified way and then train the models based on local data of the clients to obtain updated gradients; the client side sends the updated gradient to the federal server; the federation server receives the updated gradients sent by the clients, performs aggregation treatment on the updated gradients to obtain global updated gradients, and performs singular value decomposition on the global updated gradients; the client receives the global update gradient after singular value decomposition sent by the federation server, calculates the global update gradient according to the global update gradient after singular value decomposition, and continues to train the model according to the global update gradient. The application aims to solve at least one of the problems of high network transmission overhead and unsafe data in the existing federal learning system.","['G06N20/00', 'Y02D10/00']"
US10970819B2,"Image processing device, image processing method, and image processing program","An image processing device according to one embodiment includes a processor. The processor executes a step of acquiring an input image, a step of calculating a feature residual by processing the input image in a convolutional layer, a step of performing at least one convolution on the input image, a step of generating an output feature by applying the feature residual to the convolved input image, and a step of generating an image residual based on the output feature. The image residual is applied to the input image, and thereby a high-resolution image with higher resolution than the input image is generated.","['G06T3/4053', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06T3/4046']"
US10877924B2,"Instruction set processing method based on a chip architecture and apparatus, and storage medium","Embodiments of this application disclose an instruction set processing method based on a chip architecture and apparatus, and a computer-readable storage medium. The method includes compiling a deep learning model based on the architecture of the chip, to obtain a deep learning instruction set corresponding to the chip; compressing the deep learning instruction set, to obtain a compressed instruction set; and storing the compressed instruction set in an instruction set buffer of the chip by writing in a register, the compressed instructions executing a task.","['G06F9/4843', 'G06F15/7807', 'G06F9/30', 'G06F9/3867', 'G06N20/00', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06F8/41']"
US11025654B2,Machine learning-based traffic classification using compressed network telemetry data,"In one embodiment, a device in a network receives telemetry data regarding a traffic flow in the network. One or more features in the telemetry data are individually compressed. The device extracts the one or more individually compressed features from the received telemetry data. The device performs a lookup of one or more classifier inputs from an index of classifier inputs using the one or more individually compressed features from the received telemetry data. The device classifies the traffic flow by inputting the one or more classifier inputs to a machine learning-based classifier.","['H04L63/1416', 'G06N20/00', 'H04L47/2441', 'H04L63/1408', 'H04L63/145', 'H04L67/02']"
US9865176B2,Health monitoring system,"Systems and methods provide automatic messaging to a client on behalf of a healthcare treatment professional by setting up one or more computer implemented agents, each specializing in a disease state, with rules to respond to a client condition; during run-time, receiving a communication from the client and in response selecting one or more computer implemented agents to respond to the communication; and automatically generating a response to be rendered on a client mobile device to encourage healthy behavior.","['G09B19/0092', 'G09B5/00', 'G16H20/60']"
CN108268941B,Deep Convolutional Network Heterogeneous Architecture,"The present disclosure relates to deep convolutional network heterogeneous architectures. Embodiments are directed to a system on chip (SoC) implementing a deep convolutional network heterogeneous architecture. The SoC includes a system bus, a plurality of addressable memory arrays coupled to the system bus, at least one application processor core coupled to the system bus, and a configurable accelerator framework coupled to the system bus. The configurable accelerator framework is an image and Depth Convolutional Neural Network (DCNN) co-processing system. The SoC also includes a plurality of Digital Signal Processors (DSPs) coupled to the system bus, wherein the plurality of DSPs coordinate functions with the configurable accelerator framework to perform the DCNN.","['G06F30/327', 'G06F13/4022', 'G06F30/34', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/047', 'G06N3/0495', 'G06N3/084', 'G06N3/09', 'G06T1/20', 'G06F15/7817', 'G06F2115/08', 'G06F9/44505', 'G06N20/10', 'G06N3/04', 'G06N3/044', 'G06N3/063', 'G06N3/08', 'G06N7/01']"
US8684922B2,Health monitoring system,"A monitoring system for a person includes a processor coupled to one or more wireless nodes; a wearable mobile appliance in communication with the client and one or more wireless nodes; and one or more computer implemented agents with rules executed by the processor, the rules being selected to respond to a client communication relating to a predetermined health condition, each agent communicating with another computer implemented agent, the client or the treatment professional, and upon receiving a communication from the client, the processor selecting one or more computer implemented agents to reply with an instruction on healthy client behavior.","['G16H40/67', 'A61B5/0022', 'A61B5/02055', 'A61B5/021', 'A61B5/1117', 'A61B5/681', 'A61B5/6816', 'A61B5/6887', 'A61B5/7267', 'A61B5/7465', 'A61B8/4472', 'A61B8/56', 'A61B8/565', 'G09B19/00', 'G16H20/60', 'G16H50/20', 'G16H50/70', 'A61B2560/0233', 'A61B2560/0412', 'A61B5/0265', 'A61B5/029', 'A61B5/112', 'A61B5/1455', 'A61B5/25', 'A61B5/377', 'A61B5/7257', 'A61B5/726', 'A61B7/00', 'A61B8/06', 'G08B21/0453', 'G16H20/70']"
US7762580B2,Aspirated inflators,"Airbag inflator system includes an inflatable airbag, a flexible housing, and a gas generating system for generating gas which is directed from the housing to the interior of the airbag. The housing may be made by an extrusion process to provide it with its flexible cl of plastic. An aspirating structure or nozzle may be arranged between the gas generating system and an interior of the airbag, which nozzle is varied as a function of temperature. The aspirating structure or arrangement enables air from the passenger compartment of the vehicle to mix with the generated gas prior to being directed into the airbag.","['B60R21/16', 'B60R21/0132', 'B60R21/206', 'B60R21/213', 'B60R21/214', 'B60R21/232', 'B60R21/235', 'B60R21/26', 'B60R21/264', 'B60R21/30', 'B60R2021/0004', 'B60R2021/0006', 'B60R2021/23107', 'B60R2021/23153', 'B60R2021/23169', 'B60R2021/23192', 'B60R2021/23308', 'B60R2021/23316', 'B60R2021/23324', 'B60R2021/23504', 'B60R2021/23514', 'B60R2021/23519', 'B60R2021/23523', 'B60R2021/2612', 'B60R2021/2636', 'B60R21/2032', 'B60R21/233', 'B60R21/239']"
TWI684141B,Apparatus and method for accelerating multiplication with none-zero packets in artificial neuron,"An acceleration apparatus applied in an artificial neuron is disclosed. The acceleration apparatus comprises an AND gate array, a first storage device, a second storage device and a multiply-accumulate (MAC) circuit. The AND gate array with plural AND gates receives a first bitmap and a second bitmap to generate an output bitmap. The first storage device stores a first payload and outputs a corresponding non-zero first element according to a first access address associated with a result of comparing the first bitmap with the output bitmap. The second storage device stores a second payload and outputs a corresponding non-zero second element according to a second access address associated with a result of comparing the second bitmap with the output bitmap. The MAC circuit calculates a dot product of two element sequences from the first storage device and the second storage device.","['H03M7/6047', 'G06F17/16', 'G06F7/5443', 'G06N3/04', 'G06N3/063', 'H03K19/20', 'H03M7/30', 'H03M7/3066']"
US12175632B2,"Image processing method and apparatus, device, and video processing method","An image processing method and apparatus, a device, a video processing method and a storage medium are provided. The image processing method includes: receiving an input image; and processing the input image by using the convolutional neural network to obtain an output image. A definition of the output image is higher than a definition of the input image. Processing the input image by using the convolutional neural network to obtain the output image includes: performing feature extraction on the input image; concatenating the input image and the plurality of first images; performing the feature extraction on the first image group; fusing the plurality of second images and the plurality of first images; concatenating the input image and the plurality of third images to obtain a second image group; and performing the feature extraction on the second image group to obtain the output image.","['G06T5/50', 'G06N3/04', 'G06T3/4046', 'G06T3/4053', 'G06V10/40', 'G06V10/7747', 'G06V10/776', 'G06V10/803', 'G06V10/806', 'G06V10/82', 'H04N19/42', 'H04N7/015', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30168', 'G06V10/454']"
US11972134B2,Resource utilization using normalized input/output (‘I/O’) operations,"Tracking resource utilization using normalized Input/Output (‘I/O’) operations, including: selecting, for each storage device of one or more storage devices, a corresponding group of input/output (I/O) operations; calculating, for each storage device of the one or more storage devices, a normalized I/O operations per second (IOPS) value based on the corresponding group of I/O operations and a size scalar; and generating a report based on the normalized IOPS value for each storage device of the one or more storage devices.","['G06F3/0653', 'G06F3/0604', 'G06F3/0605', 'G06F3/061', 'G06F3/0613', 'G06F3/0641', 'G06F3/0659', 'G06F3/067', 'G06F3/0671', 'G06F3/0673', 'G06F3/0619', 'G06F3/065']"
US9547804B2,Retinal encoder for machine vision,"A method is disclosed including: receiving raw image data corresponding to a series of raw images; processing the raw image data with an encoder to generate encoded data, where the encoder is characterized by an input/output transformation that substantially mimics the input/output transformation of one or more retinal cells of a vertebrate retina; and applying a first machine vision algorithm to data generated based at least in part on the encoded data.","['G06K9/4619', 'G06T9/00', 'G06K9/4628', 'G06N3/049', 'G06T7/0012', 'G06T9/002', 'G06T9/007', 'G06V10/20', 'G06V10/449', 'G06V10/454', 'H04N19/60', 'H04N19/62', 'H04N19/85', 'G06K2209/05', 'G06T2207/20024', 'G06T2207/20048', 'G06T2207/20084', 'G06T2207/30041', 'G06V2201/03']"
US20210076002A1,Enhanced video conference management,"Methods, systems, and apparatus, including computer-readable media storing executable instructions, for enhanced video conference management. In some implementations, a computer system obtains participant data indicative of emotional or cognitive states of participants during communication sessions. The system also obtains result data indicating outcomes associated with the communication sessions. The system analyzes relationships among emotional or cognitive states of the participants and the outcomes indicated by the result data, and identifies an emotional or cognitive state that is predicted to promote or discourage the occurrence of a target outcome. The system provides output data indicating at least one of (i) the identified emotional or cognitive state predicted to promote or discourage occurrence of the particular target outcome, or (ii) a recommended action predicted to encourage or discourage the identified emotional or cognitive state in a communication session.","['H04N7/152', 'G06K9/00718', 'G06V20/41', 'G06V40/20', 'H04M3/565', 'H04N7/147', 'G06F2203/011', 'G06V40/174', 'G06V40/28', 'G10L25/63']"
US11636288B2,"Platform, device and process for annotation and classification of tissue specimens using convolutional neural network","Embodiments described herein provide a platform, device and process for digital pathology that enable multi-level annotation and visualization of histopathologic slides using a modular arrangement of deep convolutional neural networks (CNNs). The CNNs can be trained using pathology images (e.g., in some cases increasing the base of data by breaking larger fields of view into smaller ones) to learn features consistent with certain pathologies. The platform can use the CNNs to visually annotate pathology slides at an interface tool of a display device. The platform can automate the process of selection, as well as provide an opportunity for the pathologist to see a depiction of predicted results. The platform can use the CNNs to identify regions of interest on pathology slides. The interface tool can enable a predicted region of interest (ROI) type to be visually presented on a surface map showing the basis of the prediction. If the ROI primarily lands in part of the hyperdimensional space not occupied by any training set, then the interface tool is capable of marking it as an ROI of unknown type.","['G06K9/6267', 'G06N3/08', 'G06F18/211', 'G06F18/214', 'G06F18/24', 'G06F18/2413', 'G06K9/6228', 'G06K9/6256', 'G06N3/045', 'G06N3/0454', 'G06T7/0012', 'G06V10/25', 'G06V10/454', 'G06V10/764', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30096', 'G06V2201/03']"
CN111066326B,Machine learning video processing system and method,"The present disclosure relates to systems and methods for improving video encoding and/or video decoding. In an embodiment, a video encoding pipeline includes a main encoding pipeline that compresses source image data corresponding to an image frame by processing the source image data based at least in part on encoding parameters to generate encoded image data. In addition, the video encoding pipeline includes a machine learning block communicatively coupled to the main encoding pipeline in which the machine learning block analyzes the content of the image frames by processing the source image data based at least in part on machine learning parameters implemented in the machine learning block when the machine learning block is enabled by the encoding parameters; and the video encoding pipeline adaptively adjusts the encoding parameters based at least in part on the content desired to be present in the image frames in order to increase encoding efficiency.","['H04N19/159', 'H04N19/40', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N3/094', 'G06T9/002', 'H04N19/102', 'H04N19/117', 'H04N19/132', 'H04N19/136', 'H04N19/154', 'H04N19/172', 'H04N19/189', 'H04N19/46', 'H04N19/59', 'H04N19/86', 'H04N19/90', 'H04N19/436']"
US11353868B2,Barriers and synchronization for machine learning at autonomous machines,"One or more examples include an apparatus having a hardware barrier logic to detect thread groups relating to machine learning operations and facilitate barrier synchronization of the thread groups across multiple dies representing multiple processors, such that data processing using the threads groups across the multiple processors is synchronized and stall-free.","['G05D1/0088', 'G06T1/20', 'G06F9/522', 'G05D1/227', 'G06F9/4881', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/084', 'G06F9/46']"
US20200364953A1,Systems and methods for managing vehicle data,"The present disclosure provides methods and systems for managing autonomous vehicle data. The method may comprise: (a) collecting said autonomous vehicle data from the autonomous vehicle, wherein the autonomous vehicle data has a size of at least 1 terabyte; (b) processing the autonomous vehicle data to generate metadata corresponding to the autonomous vehicle data, wherein the autonomous vehicle data is stored in a database; (c) using at least a portion of the metadata to retrieve a subset of the autonomous vehicle data from the database, which subset of the autonomous vehicle data has a size less than the autonomous vehicle data; and (d) storing or transmitting the subset of the autonomous vehicle data.","['G06F16/2219', 'G07C5/085', 'G06N5/022', 'B60K35/00', 'B60K35/10', 'B60K35/22', 'B60K35/85', 'B60W60/001', 'G06F16/21', 'G06F16/2291', 'G06F16/24573', 'G06N20/00', 'G06N5/02', 'G06N5/04', 'G07C5/008', 'H04W4/40']"
US12087406B2,Methods using chromatin-related nucleic acid signals for performing clinical actions,"Processes to reveal biological attributes from nucleic acids are provided. In some instances, nucleic acids are used to develop frequency sequence signal maps, construct V-plots, and/or to train computational models. In some instances, trained computational models are used to predict features that reveal biological attributes.","['G16B40/20', 'C12Q1/6886', 'G16B20/00', 'G16B40/30']"
CN107688855B,Hierarchical quantization method and device for complex neural network,"The present invention relates to Artificial Neural Networks (ANN), such as Convolutional Neural Networks (CNN), and more particularly, to how to compress and accelerate artificial neural networks by fixed-point quantization of complex neural networks.","['G06N3/084', 'G06F18/241']"
US11328173B2,Switchable propagation neural network,"A temporal propagation network (TPN) system learns the affinity matrix for video image processing tasks. An affinity matrix is a generic matrix that defines the similarity of two points in space. The TPN system includes a guidance neural network model and a temporal propagation module and is trained for a particular computer vision task to propagate visual properties from a key-frame represented by dense data (color), to another frame that is represented by coarse data (grey-scale). The guidance neural network model generates an affinity matrix referred to as a global transformation matrix from task-specific data for the key-frame and the other frame. The temporal propagation module applies the global transformation matrix to the key-frame property data to produce propagated property data (color) for the other frame. For example, the TPN system may be used to colorize several frames of greyscale video using a single manually colorized key-frame.","['G06K9/6215', 'G06V10/82', 'G06F18/214', 'G06F18/22', 'G06K9/6256', 'G06N3/04', 'G06N3/08', 'G06T5/003', 'G06T5/009', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'G06T5/92', 'G06T7/10', 'G06T7/90', 'G06V10/454', 'G06V10/56', 'G06V20/46', 'G06N3/084', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20208']"
US12141699B2,Systems and methods for providing vector-wise sparsity in a neural network,"The present disclosure relates to systems and methods for providing vector-wise sparsity in neural networks. In some embodiments, an exemplary method for providing vector-wise sparsity in a neural network, comprises: dividing a matrix associated with the neural network into a plurality of vectors; selecting a first subset of non-zero elements from the plurality of vectors to form a pruned matrix; and outputting the pruned matrix for executing the neural network using the pruned matrix.","['G06F17/16', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'G06N3/044', 'G06N3/045', 'G06N3/084']"
US10951903B2,Video analytics encoding for improved efficiency of video processing and compression,"Embodiments are generally directed to video analytics encoding for improved efficiency of video processing and compression. An embodiment of an apparatus includes a memory to store data, including data for video streaming, and a video processing mechanism, wherein the video processing mechanism is to analyze video data and generate video analytics, generate metadata representing the video analytics and insert the generated video analytics metadata into a message, and transmit the video data and the metadata to a succeeding apparatus or system in a video analytics pipeline, the video data being compressed video data.","['H04N19/179', 'G06F16/7837', 'H04N19/136', 'H04N19/188', 'H04N19/70', 'H04N21/21805', 'H04N21/2187', 'H04N21/44008', 'H04N21/64322', 'H04N21/84']"
US20210056251A1,Automatic Data Extraction and Conversion of Video/Images/Sound Information from a Board-Presented Lecture into an Editable Notetaking Resource,"A method(s) and system(s) to automatically convert a presentation to a digitized notetaking resource, by inputting presentation multimedia to a compute server which converts the media stream by detecting in the video data at least a writing surface and displayed image. Also, detecting in the video data writing on the at least writing surface and displayed image. Removing artifacts and enhancing the writing. Identifying at least one of key frames and groups in the writing. Associating a time stamp metadata to one or more elements of the at least one key frames and groups. Time ordering one or more elements of the at least one key frames and groups and generating a composite user interface with panes for playing at least the video and audio data, and a pane for displaying the time ordered one or more elements of the at least one key frames and key groups.","['G06F40/171', 'G06F3/0425', 'G06F3/04847', 'G06F3/04883', 'G06F40/10', 'G06F40/169', 'G06F40/216', 'G06F40/30', 'G06K9/00718', 'G06K9/325', 'G06V20/41', 'G06V20/62', 'G06V30/333', 'G06V40/103', 'G06K2209/01', 'G06V30/10', 'G10L15/26']"
US20210374021A1,Automated media agent state management,"Described herein are techniques for automating media agent state management. For example, if a media agent is running poorly, then the media agent can be disabled and an alternate media agent can perform secondary copy job operations in place of the poorly running media agent. To determine whether a media agent is running poorly, a storage manager can determine whether the media agent has an anomalous number of failed jobs, pending jobs, and/or long running jobs and/or can determine whether the amount of resources used by the media agent is high or is increasing constantly, at a constant rate, or at a near constant rate.","['G06F3/061', 'G06F11/2094', 'G06F11/3055', 'G06F11/3409', 'G06F11/3485', 'G06F3/0604', 'G06F3/0634', 'G06F3/0659', 'G06F3/067', 'G06F11/1451', 'G06F11/1469', 'G06F11/2023', 'G06F11/2097', 'G06F2201/80', 'G06F2201/81', 'G06F2201/815', 'G06F2201/82', 'G06F2201/84', 'G06F2201/86', 'G06N20/00', 'G06N3/006', 'G06N3/08']"
CN110363290B,"Image recognition method, device and equipment based on hybrid neural network model","The invention discloses an image recognition method, device and equipment based on a hybrid neural network model and a computer readable storage medium, comprising the following steps: inputting an image to be identified into a convolution self-encoder for preprocessing; extracting image features of the preprocessed image to be identified by using a characteristic extractor constructed based on transfer learning; extracting internal time sequence characteristics of the preprocessed image to be identified by using a long-term and short-term memory network model; utilizing a feature fusion door and a feature screening door to fusion and screen the image features and the internal time sequence features to obtain target features of the identification image; and classifying the target features by using a softmax classifier to obtain a classification result of the image to be identified. The method, the device, the equipment and the computer readable storage medium provided by the invention can greatly reduce the number of images required by training the neural network model and improve the accuracy of image identification.","['G06F18/241', 'G06N3/045', 'G06N3/08', 'G06V10/40', 'Y02T10/40']"
CN110942100B,Working method of spatial modulation system based on deep denoising neural network,"The invention relates to a working method of a spatial modulation system based on a deep denoising neural network. A deep neural network scheme is provided on the basis, and simulation experiment results show that the detection algorithm based on the deep neural network has strong robustness. In terms of reliability, the performance is much better than the MRC scheme.","['G06N3/08', 'G06F18/214', 'G06F18/24', 'G06N3/084', 'H04B7/0413', 'H04B7/0452', 'Y02D30/70']"
US12380159B2,Prioritized device actions triggered by device scan data,"Systems, methods, devices, server computers, storage media, and instructions for prioritized device action triggered by device scan data are described. In one embodiment, a mobile device performs a method that involves executing a messaging application with an image capture interface and a scanning input. An associated scanning mode comprises capture of scan data from a plurality of input/output modules of the first client device, analyzes the scan data to identify one or more scan data patterns by matching at least a portion of the scan data against a set of data patterns, and selects a priority system action based on the results of the matching of the portion of the scan data against the set of data patterns. In some embodiments, the priority system action is selected based on a priority ranking for identified scan data types.","['G06F16/5866', 'G06F16/9038', 'G06F18/24', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06T1/0007', 'G06V10/751', 'G06V10/764', 'G06V10/82', 'H04N23/63', 'G06N5/022', 'G06V2201/09']"
WO2020147393A1,"Convolutional neural network-based text classification method, and related device","A convolutional neural network-based text classification method and a related device. The method comprises: acquiring a mapping relationship between words and word vectors and a mapping relationship between characters and character vectors (S101); acquiring a text to be classified, and according to the mapping relationship between words and word vectors and the mapping relationship between characters and character vectors, converting said text into word vectors and character vectors (S102); and inputting the word vectors and the character vectors into a convolutional neural network text classification model, and fusing the word vectors and the character vectors by means of the convolutional neural network text classification model to obtain the type of said text (S103). The method extracts word vectors a character vectors from a text to be classified, and inputs the word vectors and the character vectors into a convolutional neural network for fusion, effectively improving the accuracy of text classification.","['G06F16/35', 'G06N3/04', 'G06N3/08']"
CN111324870B,Outsourcing convolutional neural network privacy protection system based on safe two-party calculation,"The invention discloses an outsourcing convolution neural network privacy protection system based on safe two-party calculation. Two image components are input into two servers, information transmitted between the servers is hidden by utilizing triples of random data in the convolutional layer, a confusion circuit is designed in an active layer to realize a ReLU function, dimension reduction of the image is carried out through average pooling, finally two components of a prediction result are obtained by adopting a full connection layer of the triplet hidden information, and the two components are returned to a user to be combined, so that the required prediction result can be obtained. In order to improve the computing efficiency, asynchronous computing and parallel query methods are adopted, independent computing in the same query is carried out at the same time, different parts of a plurality of queries are processed at the same time, and the time of each query is greatly reduced.","['G06F21/14', 'G06N3/045']"
US12277500B2,"Neural network optimization method, electronic device and processor","The present invention discloses a neural network optimization method. An operator to be replaced is selected from multiple operators in a network layer according to a predetermined condition, and the operator to be replaced is replaced by multiple equivalent operators according to a calculation function corresponding to the operator to be replaced, wherein the multiple equivalent operators include a target operator. Pre-calculating is performed for a first operator among the multiple equivalent operators, and the calculation result is inputted into the target operator. A second operator is identified according to data change conditions of the multiple equivalent operators, and the second operator is combined with the target operator to complete optimization of a neural network model. The present invention can further perform lossless conversion of the operators in the neural network, further improving calculation performance on the basis of a simplified network structure.","['G06N3/045', 'G06N3/04', 'G06F11/0751', 'G06F11/0793', 'G06N3/044', 'G06N3/082', 'G06F18/2415', 'G06V10/267']"
US11080351B1,Automated content curation and communication,"Systems, devices, methods, media, and instructions for automated image processing and content curation are described. In one embodiment a server computer system receives a plurality of content communications from a plurality of client devices, each content communication comprising an associated piece of content and a corresponding metadata. Each content communication is processed to determine associated context values for each piece of content, each associated context value comprising at least one content value generated by machine vision processing of the associated piece of content. A first content collection is automatically generated based on context values, and a set of user accounts are associated with the collection. An identifier associated with the first content collection is published to user devices associated with user accounts. In various additional embodiments, different content values, image processing operations, and content selection operations are used to curate content collections.","['G06F16/55', 'G06F16/22', 'G06F16/24578', 'G06F16/51', 'G06F16/5854', 'G06F16/951', 'G06F16/9535', 'G06F16/954', 'G06N20/00', 'G06N3/04', 'G06V20/35', 'G06V20/41', 'H04L51/10', 'H04L51/52', 'H04W4/18', 'G06N3/045', 'G06N3/08', 'G06T2207/20084', 'G06T2207/30168', 'G06T7/0002', 'H04L51/222', 'H04L67/01', 'H04L67/26', 'H04L67/42', 'H04L67/55']"
CN111670580B,Progressive compressed domain computer vision and deep learning system,"Methods and systems for compressed domain progressive application of computer vision techniques. A method for decoding video data, comprising: a video stream encoded for multi-stage decoding is received. The method includes partially decoding a video stream by performing one or more stages of a multi-stage decoding. The method includes determining a decision whether a computer vision system can be identified based on the partially decoded video stream. In addition, the method includes generating a decision for the computer vision system based on the decoding of the video stream. A system for encoding video data includes a processor configured to receive video data from a camera, encode the video data received from the camera into a video stream for consumption by a computer vision system, and include metadata in the encoded video stream to indicate a decision whether the computer vision system can be identified from the metadata.","['H04N19/48', 'H04N19/102', 'H04N19/11', 'H04N19/167', 'H04N19/44', 'H04N19/46']"
CN110335587B,"Speech synthesis method, system, terminal device and readable storage medium","The application provides a voice synthesis method, a system, a terminal device and a readable storage medium, wherein text data and a real person recording are obtained, text vectors are generated according to the text data, and then the prosody of the real person recording is modeled to generate prosody vectors; and then generating target voice by combining the text vector and the prosody vector, thereby realizing the transfer of prosody in the real person recording to the synthesized voice. Meanwhile, the application also models the rhythm in the real person recording, and based on the method of global conditional probability generation, the synthesized voice has more similar rhythm with the input real person recording, and further has the effects of high fidelity and high naturalness.","['G10L13/02', 'G10L13/08', 'G10L25/30', 'Y02T10/40']"
CN111466115B,Intra prediction mode concept for block-by-block picture coding,"According to a first aspect, improved compression efficiency is achieved by having block-wise picture codec support a set of intra prediction modes from which an intra prediction signal for a current block of a picture is determined by applying a set of neighboring samples of the current block to a neural network. A second aspect of the present application is that, in addition to or instead of using neural network based intra-prediction modes, mode selection may be made more efficient by using a neural network dedicated to determining a ranking or probability value for each of a set of intra-prediction modes by applying a set of adjacent samples to the neural network, wherein the ranking or probability value is used to select one intra-prediction mode from a plurality of intra-prediction modes including or consistent with the set of intra-prediction modes.","['H04N19/11', 'G06N3/045', 'G06N3/048', 'G06N3/0499', 'G06N3/08', 'G06N3/09', 'G06T9/002', 'H04N19/109', 'H04N19/176', 'H04N19/593', 'H04N19/61', 'H04N19/70']"
US11603749B2,Field operations system,A method can include receiving multi-channel time series data of drilling operations; training a deep neural network (DNN) using the multi-channel time series data to generate a trained deep neural network as part of a computational simulator where the deep neural network includes at least one recurrent unit; simulating a drilling operation using the computational simulator to generate a simulation result; and rendering the simulation result to a display.,"['E21B44/00', 'E21B21/08', 'E21B49/003', 'G01V1/50', 'G01V11/00', 'G06F17/15', 'G06F17/16', 'G06F30/20', 'G06F30/27', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/047', 'G06N3/0472', 'G06N3/08', 'G06N7/00', 'G06N7/01', 'G01V2200/14', 'G01V2200/16', 'G06T13/80']"
US10936907B2,Training a deep learning system for maritime applications,"An object detection network can be trained with training images to identify and classify objects in images from a sensor system disposed on a maritime vessel. The objects in the images can be identified, classified, and heat maps can be generated. Instructions can be sent regarding operation of the maritime vessel. For some training images, water conditions, sky conditions, and/or light conditions in the image can be changed to generate a second image.","['G05D1/0206', 'G06K9/6256', 'G06F18/214', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06T11/40', 'G06T7/194', 'G06T7/50', 'G06V10/82', 'G06V20/00', 'G06N3/047', 'G06T2207/10012', 'G06T2207/20081', 'G06T2207/20228', 'G06T2207/30261']"
US10782691B2,Deep learning and intelligent sensing system integration,"Disclosed herein are systems, methods, and apparatuses for deep learning and intelligent sensing system integrations. A processor may be configured to receive a plurality of images from the sensor system, identify objects in the images in an offline mode, classify the objects in the images in the offline mode, generate heat maps in the offline mode, and send instructions regarding operation of the maritime vessel based on the objects that are identified. The visual sensor may be a stereoscopic camera. The processor may be further configured to perform stereoscopy. The instructions may include a speed or a heading of, for example, a maritime vessel.","['G05D1/0206', 'G06K9/00624', 'G06T7/593', 'G06V10/454', 'G06V10/82', 'G06V10/95', 'G06V10/955', 'G06V20/00', 'G06T2207/10012', 'G06T2207/20084', 'G06T2207/30261', 'G06V2201/07', 'H04N13/239', 'H04N2013/0081']"
US20210303522A1,Copying a File System,"An illustrative data storage system is configured to use pods to efficiently copy files systems constructed of block objects. In certain examples, the storage system generates, based on a pod that includes a file system constructed of block objects, a virtual copy of the pod such that modifications made to the pod (e.g., modifications to contents of the block objects by way of the pod) after the generation of the virtual copy of the pod are distinct from the virtual copy of the pod. In certain examples, the virtual copy of the pod is a writeable clone of the pod and modifications made to the clone (e.g., modifications to contents of the block objects by way of the clone) after the generation of the clone are distinct from the pod.","['G06F16/13', 'G06F16/178', 'G06F16/16', 'G06F16/188', 'G06F3/061', 'G06F3/064', 'G06F3/0643', 'G06F3/0688']"
US12235799B2,Optimizing a transfer of a file system,"An illustrative system is configured to optimize a transfer of a file system from a source storage system to a target storage system. For example, the system, in association with the transfer, determines that a copy of a collection of blocks containing data of block objects of the file system is already stored at the target storage system. In certain examples, an identifier referencing the collection of blocks is shared by the source and target storage systems and is used to determine that the copy of the collection of blocks containing data of block objects of the file system is already stored at the target storage system. The system uses the copy of the collection of blocks already stored at the target storage system instead of transferring the collection of blocks from the source storage system to the target storage system as part of the transfer.","['G06F16/119', 'G06F16/17']"
US11057414B1,Asynchronous hidden markov models for internet metadata analytics,"Implementations described and claimed herein provide systems, methods and computer-readable media with instructions for detecting anomalies in computer network traffic online, real-time, historical, forensic, and/or playback mode. The implementations can include monitoring network traffic metadata, parsing the metadata, constructing a multi-partite graph of nodes and edges based on a long-term incremental signal transformation or a short-term concurrent snapshot, and generating streaming analytics based on the multi-partite graph representing a likelihood that network traffic associated with a specified network component is infected with malware.","['H04L63/1425', 'G06F16/9024', 'G06N20/00', 'G06N5/022', 'G06N7/005', 'G06N7/01', 'H04L63/1416', 'G06N3/044', 'H03M7/3059', 'H04L63/1458']"
US12394520B2,Systems and methods for operations and incident management,"The present disclosure provides methods and systems for managing safety and risk in a remote workplace. The method may comprise: collecting, via a local network, data stream from one or more sensors and a user device; transmitting the data stream to an edge computing device via the local network, wherein the data stream is stored in a local database; processing, at the edge computing device, the data stream to identify a hazardous condition and a health condition of a user associated with the user device; and automatically generating a dynamic geofencing area in the remote workplace base at least in part on the hazardous condition and the health condition.","['G16H40/63', 'G06N20/00', 'G16H40/67', 'G16H50/20', 'H04L67/12', 'H04L67/52', 'H04Q9/00', 'H04Q2209/43']"
US12399869B2,Replicating a file system,"An illustrative data storage system is configured to replicate, from a source storage system to a target storage system, a pod that includes a file system constructed of block objects. The pod may be a storage system construct that groups storage entities within a namespace and supports operations on the storage entities as a group. The block objects may store metadata for individual files and directories of the file system and may support random read-write access to blocks of data associated with the files and directories of the file system.","['G06F3/061', 'G06F16/13', 'G06F16/16', 'G06F16/178', 'G06F3/0607', 'G06F3/0631', 'G06F3/0643', 'G06F3/065', 'G06F3/0688']"
CN107396322B,Indoor positioning method based on path matching and coding-decoding cyclic neural network,"The invention relates to an indoor positioning method, in particular to an indoor positioning method based on path matching and a coding and decoding recurrent neural network. The invention includes a training phase and a testing phase. In the training stage, a walking path is designed in an area to be positioned, and a signal receiving intensity dynamic time sequence from an AP (access point) when the mobile equipment walks on each path is collected; preprocessing an RSS time sequence; obtaining a corresponding position time sequence through interpolation; and establishing a coding and decoding cyclic neural network model, using long-term memory as a basic component of the model, and training the cyclic neural network model by using the preprocessed RSS time sequence and the corresponding position time sequence by using the positioning server. In the testing stage, online RSS data are obtained to obtain an RSS time sequence; and preprocessing the RSS time sequence, taking the preprocessed RSS time sequence as the input of a trained deep learning model, and taking the obtained output sequence as the path position estimation of the mobile equipment.","['G01C21/206', 'H04W64/00']"
US11755286B2,Neural network semiconductor device and system using the same,"A semiconductor device capable of performing product-sum operation is provided. The semiconductor device includes a first memory cell, a second memory cell, and an offset circuit. The semiconductor device retains first analog data and reference analog data in the first memory cell and the second memory cell, respectively. A potential corresponding to second analog data is applied to each of them as a selection signal, whereby current depending on the sum of products of the first analog data and the second analog data is obtained. The offset circuit includes a constant current circuit comprising a transistor and a capacitor. A first terminal of the transistor is electrically connected to a first gate of the transistor and a first terminal of the capacitor. A second gate of the transistor is electrically connected to a second terminal of the capacitor. A voltage between the first terminal and the second gate of the transistor is held in the capacitor, whereby a change in source-drain current of the transistor can be suppressed.","['G06F7/5443', 'G06N3/065', 'G06N3/04', 'H01L29/7869', 'H10D30/6755', 'G06F2207/4814']"
US11024009B2,Super resolution using a generative adversarial network,"A neural network is trained to process received visual data to estimate a high-resolution version of the visual data using a training dataset and reference dataset. A set of training data is generated and a generator convolutional neural network parameterized by first weights and biases is trained by comparing characteristics of the training data to characteristics of the reference dataset. The first network is trained to generate super-resolved image data from low-resolution image data and the training includes modifying first weights and biases to optimize processed visual data based on the comparison between the characteristics of the training data and the characteristics of the reference dataset. A discriminator convolutional neural network parameterized by second weights and biases is trained by comparing characteristics of the generated super-resolved image data to characteristics of the reference dataset, and where the second network is trained to discriminate super-resolved image data from real image data.","['G06T3/4053', 'G06N3/084', 'G06N3/045', 'G06N3/0454', 'G06N3/047', 'G06T3/4046', 'G06T2207/20081', 'G06T2207/20084']"
US10856087B2,Hearing device comprising an acoustic event detector,"A hearing device, e.g. a hearing aid, comprises an input unit; an output unit; an adaptive beamformer filtering unit configured to provide a spatially filtered signal based on a multitude of electric input signals from the input unit and an adaptively updated adaptation factor β; a memory, wherein A) a reference value REF, equal to or dependent on a value, βov, of said adaptation factor β determined when a voice of the user is present, or B) a set of parameters for classification based on logistic regression or a neural network, is stored; and an own voice detector configured to provide an estimate of whether or not, or with what probability, a given input sound originates from the voice of the user, and wherein said estimate is dependent on a) a current value of said adaptation factor β and said reference value REF, or on b) said set of parameters for classification based on logistic regression or a neural network, respectively.","['H04R25/407', 'H04R25/405', 'H04R25/43', 'H04R25/505', 'H04R25/507', 'H04R25/554', 'H04R29/001', 'H04R2225/41', 'H04R2225/43', 'H04R2430/23', 'H04R25/552', 'H04R3/005']"
US11759651B2,In vivo visualization and control of pathological changes in neural circuits,"Neurological Disease Mechanism Analysis for Diagnosis, Drug Screening, (Deep) Brain Stimulation Therapy design and monitoring, Stem Cell Transplantation therapy design and monitoring, Brain Machine Interface design, control, and monitoring.","['A61N5/0622', 'A61B5/0036', 'A61B5/0002', 'A61B5/055', 'A61B5/1468', 'A61B5/369', 'A61B5/4094', 'A61N5/062', 'G01R33/4806', 'A61B5/7232', 'A61N2005/0626', 'A61N2005/0663']"
US12192591B2,Training an encrypted video stream network scoring system with non-reference video scores,"At least three uses of the technology disclosed are immediately recognized. First, a video stream classifier can be trained that has multiple uses. Second, a trained video stream classifier can be applied to monitor a live network. It can be extended by the network provider to customer relations management or to controlling video bandwidth. Third, a trained video stream classifier can be used to infer bit rate switching of codecs used by video sources and content providers. Bit rate switching and resulting video quality scores can be used to balance network loads and to balance quality of experience for users, across video sources. Balancing based on bit rate switching and resulting video quality scores also can be used when resolving network contention.","['H04N21/23418', 'H04N21/64738', 'H04N21/64784', 'H04N21/8547']"
US11699236B2,Systems and methods for the segmentation of multi-modal image data,"There is provided a computer implemented method of automatic segmentation of three dimensional (3D) anatomical region of interest(s) (ROI) that includes predefined anatomical structure(s) of a target individual, comprising: receiving 3D images of a target individual, each including the predefined anatomical structure(s), each 3D image is based on a different respective imaging modality. In one implementation, each respective 3D image is inputted into a respective processing component of a multi-modal neural network, wherein each processing component independently computes a respective intermediate, and the intermediate outputs are inputted into a common last convolutional layer(s) for computing the indication of segmented 3D ROI(s). In another implementation, each respective 3D image is inputted into a respective encoding-contracting component a multi-modal neural network, wherein each encoding-contracting component independently computes a respective intermediate output. The intermediate outputs are inputted into a single common decoding-expanding component for computing the indication of segmented 3D ROI(s).","['A61B6/501', 'G06T7/11', 'A61B34/20', 'A61B34/32', 'A61B5/0042', 'A61B5/055', 'A61B5/4381', 'A61B5/7267', 'A61B6/032', 'A61B6/037', 'A61B6/466', 'A61B6/50', 'A61B8/5207', 'G01R33/5602', 'G01R33/5608', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06T2200/04', 'G06T2207/10088', 'G06T2207/10092', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/20156', 'G06T2207/30016', 'G06T2207/30081', 'G06T2207/30096']"
CN111428872B,"Systems, methods and program products for integrating knowledge from complex models into simple models","The present invention provides a system, method and computer program product for incorporating knowledge from a more complex model into a simpler model. The method may include obtaining first training data associated with a first set of features and second training data associated with a second set of features different from the first set of features, training a first model based on the first training data and the second training data, and training a second model based on the second training data using a loss function, the loss function being dependent on an output of an intermediate layer of the first model and an output of the second model.","['G06Q20/4016', 'G06N5/02', 'G06N3/0442', 'G06N3/045', 'G06N3/08', 'G06N3/09', 'G06N3/096', 'G06Q30/0185', 'G06N3/048', 'G06N3/084']"
US10872299B2,Memory augmented generative temporal models,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating sequences of predicted observations, for example images. In one aspect, a system comprises a controller recurrent neural network, and a decoder neural network to process a set of latent variables to generate an observation. An external memory and a memory interface subsystem is configured to, for each of a plurality of time steps, receive an updated hidden state from the controller, generate a memory context vector by reading data from the external memory using the updated hidden state, determine a set of latent variables from the memory context vector, generate a predicted observation by providing the set of latent variables to the decoder neural network, write data to the external memory using the latent variables, the updated hidden state, or both, and generate a controller input for a subsequent time step from the latent variables.","['G06N3/06', 'G06N20/00', 'G06N3/047', 'G06N3/044', 'G06N3/045', 'G06N3/0455', 'G06N3/049', 'G05B2219/33025', 'G06F16/908', 'G06N3/084']"
US11986860B2,Systems and methods for sorting recyclable items and other materials,"Systems and methods for sorting recyclable items and other materials are provided. In one embodiment, a system for sorting objects comprises: at least one imaging sensor; a controller comprising a processor and memory storage, wherein the controller receives image data captured by the image sensor; and at least one pusher device coupled to the controller, wherein the at least one pusher device is configured to receive an actuation signal from the controller. The processor is configured to detect objects travelling on a conveyor device and recognize at least one target item traveling on a conveyor device by processing the image data and to determine an expected time when the at least one target item will be located within a diversion path of the pusher device. The controller selectively generates the actuation signal based on whether a sensed object detected in the image data comprise the at least one target item.","['B07C5/3422', 'B07C1/04', 'B07C5/36', 'B07C5/367', 'B07C5/368', 'C08G61/122', 'C08G61/123', 'C08G61/126', 'G05B13/027', 'B07C2501/0054', 'C08G2261/1412', 'C08G2261/146', 'C08G2261/149', 'C08G2261/3223', 'C08G2261/3241', 'C08G2261/3243', 'C08G2261/3246', 'C08G2261/344', 'C08G2261/414', 'C08G2261/91', 'C08K3/045']"
US12192547B2,High-resolution video generation using image diffusion models,"In various examples, systems and methods are disclosed relating to aligning images into frames of a first video using at least one first temporal attention layer of a neural network model. The first video has a first spatial resolution. A second video having a second spatial resolution is generated by up-sampling the first video using at least one second temporal attention layer of an up-sampler neural network model, wherein the second spatial resolution is higher than the first spatial resolution.","['G06N3/045', 'G06T3/4053', 'G06T9/00', 'G06V10/24', 'G06V10/25', 'G06V10/82', 'G06V20/46', 'H04N21/234363', 'H04N7/0117']"
US12322101B2,Methods of analyzing microscopy images using machine learning,Disclosed herein are methods of utilizing machine learning methods to analyze microscope images of populations of cells.,"['G16B20/00', 'G06N20/00', 'G06T7/0012', 'G16B40/20', 'G16B40/30', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30024']"
US12086704B2,Machine learning model with depth processing units,"Representative embodiments disclose machine learning classifiers used in scenarios such as speech recognition, image captioning, machine translation, or other sequence-to-sequence embodiments. The machine learning classifiers have a plurality of time layers, each layer having a time processing block and a depth processing block. The time processing block is a recurrent neural network such as a Long Short Term Memory (LSTM) network. The depth processing blocks can be an LSTM network, a gated Deep Neural Network (DNN) or a maxout DNN. The depth processing blocks account for the hidden states of each time layer and uses summarized layer information for final input signal feature classification. An attention layer can also be used between the top depth processing block and the output layer.","['G06N3/048', 'G06F18/217', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G10L15/063', 'G10L15/16']"
US12310586B2,Method for adaptive control schemes for surgical network control and interaction,"A method for adaptive control of surgical network control and interaction is disclosed. The surgical network includes a surgical feedback system. The surgical feedback system includes a surgical instrument, a data source, and a surgical hub configured to communicably couple to the data source and the surgical instrument. The surgical hub includes a control circuit. The method includes receiving, by the control circuit, information related to devices communicatively coupled to the surgical network; and adaptively controlling, by the control circuit, the surgical network based on the received information.","['A61B17/07207', 'A61B1/00009', 'A61B1/000096', 'A61B1/00045', 'A61B1/051', 'A61B1/0661', 'A61B17/0682', 'A61B17/072', 'A61B17/1114', 'A61B17/1155', 'A61B17/1285', 'A61B17/320092', 'A61B18/1442', 'A61B18/1445', 'A61B34/20', 'A61B34/25', 'A61B34/32', 'A61B34/71', 'A61B5/0066', 'A61B5/0075', 'A61B5/0261', 'A61B6/5247', 'A61B90/35', 'A61B90/361', 'A61M1/73', 'A61M1/77', 'A61M1/79', 'B25J13/006', 'B25J9/1689', 'B25J9/1697', 'G06K19/07749', 'G06K7/10316', 'G16H10/60', 'G16H20/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H70/20', 'H01Q1/22', 'H04L63/0428', 'H04L63/08', 'H04L63/1416', 'H04L67/10', 'H04L67/12', 'H04N23/555', 'H04N5/272', 'H04N7/183', 'H04W12/06', 'H04W12/108', 'H05K1/028', 'H05K1/189', 'A61B17/0469', 'A61B17/07292', 'A61B18/14', 'A61B18/16', 'A61B2017/00017', 'A61B2017/00022', 'A61B2017/00026', 'A61B2017/0003', 'A61B2017/00039', 'A61B2017/00044', 'A61B2017/00057', 'A61B2017/00061', 'A61B2017/00075', 'A61B2017/00084', 'A61B2017/00097', 'A61B2017/00106', 'A61B2017/0011', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/00123', 'A61B2017/00128', 'A61B2017/00199', 'A61B2017/00203', 'A61B2017/00221', 'A61B2017/00225', 'A61B2017/00398', 'A61B2017/00402', 'A61B2017/00734', 'A61B2017/00809', 'A61B2017/00818', 'A61B2017/07257', 'A61B2017/07271', 'A61B2017/07278', 'A61B2017/07285', 'A61B2017/1132', 'A61B2017/32007', 'A61B2017/320074', 'A61B2017/320084', 'A61B2017/320095', 'A61B2017/320097', 'A61B2018/00541', 'A61B2018/00589', 'A61B2018/00595', 'A61B2018/00601', 'A61B2018/00607', 'A61B2018/0063', 'A61B2018/00642', 'A61B2018/00684', 'A61B2018/00791', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00898', 'A61B2018/00988', 'A61B2018/00994', 'A61B2018/1253', 'A61B2018/126', 'A61B2018/1273', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/256', 'A61B2034/258', 'A61B2034/301', 'A61B2034/305', 'A61B2090/064', 'A61B2090/0807', 'A61B2090/0809', 'A61B2090/309', 'A61B2217/005', 'A61B2217/007', 'A61B2218/002', 'A61B2218/007', 'A61B2218/008', 'A61B34/30', 'A61B34/37', 'A61B5/021', 'A61B90/30', 'A61B90/98', 'A61M1/80', 'A61M13/003', 'A61M2205/3306', 'A61M2205/3327', 'A61M2205/3331', 'A61M2205/3365', 'A61M2205/3368', 'A61M2205/3553', 'A61M2205/3561', 'A61M2205/3576', 'A61M2205/50', 'G05B2219/40174', 'G05B2219/45119', 'H04W12/63']"
US10755479B2,Systems and methods for synthesizing images of apparel ensembles on models,"Neural networks of suitable topology are trained with sets of images, where one image of each set depicts a garment and another pair of images of each set depicts an item of apparel from multiple viewpoints, and a final image of each set depicts a model wearing the garment and the other item of apparel. Once trained, the neural network can synthesize a new image based on input images including an image of a garment and a pair of images of another item of apparel. Quantitative parameters controlling the image synthesis permit adjustment of features of the synthetic image, including skin tone, body shape and pose of the model, as well as characteristics of the garment and other items of apparel.","['G06T19/00', 'G06V10/82', 'G06F18/214', 'G06K9/6256', 'G06N3/04', 'G06N3/08', 'G06N3/084', 'G06V10/454', 'G06T2207/20084', 'G06T2210/16']"
CN111489364B,Medical image segmentation method based on lightweight full convolution neural network,"The invention requests to protect a medical image segmentation method based on a lightweight full convolution neural network. Firstly, preprocessing a data set such as graying, normalization, Contrast Limited Adaptive Histogram Equalization (CLAHE), gamma correction and the like; then, randomly extracting a patch from the training set and sequentially extracting a patch diagram from the test set to complete data enhancement; then, a full convolution neural network architecture consisting of a contraction path (left side) and an expansion path (right side) is built, and a leave-one-out training method is designed for the data set with less image quantity; and finally, finishing the cutting of the BN channel model through channel sparse regularization training, cutting channels with the scaling factors smaller than a set threshold value and trimming the cut network to obtain a light-weight full convolution neural network, and inputting test data into the network to quickly test and finish image segmentation. The lightweight full-convolution neural network not only ensures the high segmentation precision advantage of the deep network, but also improves the testing speed of the image segmentation network.","['G06T7/11', 'G06N3/045', 'G06N3/08', 'G06T7/194', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30004']"
US11928845B2,Point cloud playback mechanism,"An apparatus to facilitate real-time playback of point cloud sequence data is disclosed. The apparatus comprises one or more processors to receive point cloud data of a captured scene, decompose the point cloud data into a plurality of point cloud patches, wherein each point cloud patch is associated with an object in the scene and includes contextual information regarding the point cloud patch, encode each of the point cloud patches via a deep-learning based algorithm to generate encoded point cloud patches, receive a viewpoint selection from a client, assign a priority to data chunks within each encoded point cloud patch based on the viewpoint selection and the contextual information and transmit the data chunks to the client based on the assigned priority.","['H04N19/127', 'G06T9/40', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/088', 'G06T1/20', 'G06T9/001', 'H04N19/162', 'H04N19/184', 'H04N19/20', 'H04N19/30', 'G06N3/047', 'G06N3/084']"
CN115017850B,A digital integrated circuit optimization method,"The invention discloses a digital integrated circuit optimization method. On the premise of meeting certain time sequence constraint, the circuit level, path level and gate unit level characteristics of the circuit are extracted, a leakage power consumption optimization model is constructed, an optimization data training model from a commercial circuit optimization tool is adopted, and the threshold voltage type of the gate unit after circuit optimization is predicted, so that the gate unit in the gate level netlist after wiring is subjected to threshold voltage adjustment to realize the optimization of the circuit, and the optimization target of reducing the leakage power consumption is achieved. Compared with a commercial circuit optimization tool, the digital integrated circuit optimization method provided by the invention can be applied to circuit optimization in engineering modification (ECO) stage, can obtain similar leakage power consumption optimization effect while greatly improving the optimization speed, and has important significance for accelerating the speed of optimizing the leakage power consumption of the digital integrated circuit.","['G06F30/337', 'G06F30/27', 'G06F30/327', 'G06F30/398', 'G06F2119/06', 'G06F2119/12', 'Y02D10/00']"
US11769159B2,System and method for human emotion and identity detection,"Disclosed is a distributed profile building system, gathering video data, audio data, electronic device identification data, and spatial position data from multiple input devices, performing human emotion and identity detection, and gaze tracking, and forming user profiles. Also disclosed is a method for building user profiles using a distributed profile building system by gathering video data, audio data, electronic device identification data, and spatial position data from multiple input devices, performing human emotion and identity detection, and gaze tracking, and forming user profiles. Also included is a targeted promotion system, which includes software for making real-time promotions for select products based on retail customers' individual characteristics. Additionally, a targeted digital coupon management system creates, delivers and facilitates redemption of various types of digital coupons according to the business rules set by the retailers.","['G06Q30/0201', 'G06F18/256', 'G06F40/295', 'G06N20/00', 'G06N5/04', 'G06Q20/202', 'G06V10/811', 'G06V20/40', 'G06V40/174', 'G06V40/18', 'G06V40/20', 'G10L25/63', 'G06F40/30', 'G06N3/044', 'G06N3/045', 'G06N5/01', 'G06N5/022', 'G06N7/01', 'G06V40/178']"
WO2023030513A1,Internet of things system,"Provided in the present disclosure is a method for implementing a sensor on the basis of the Internet of Things, and further provided is a method for calibrating a sensor on the basis of deep learning and a system thereof. The method comprises the steps of: a sensor collecting historical data according to a time sequence; by means of a standard sensor, collecting a numerical value of at least a part of the corresponding historical data; feeding the historical data and the numerical value into a Transformer model; the Transformer model training the historical data and the numerical value to obtain an original model; by means of deep learning pruning or knowledge distillation, performing multi-level compression optimization on the original model, so as to obtain a model after multi-stage compression optimization; and, according to the original model or the model after multi-stage compression optimization, calibrating raw data subsequently collected by the sensor. The sensor calibration method and the system thereof in the present disclosure can be respectively deployed in a sensor terminal device, a base station, and a cloud server, thereby achieving application in multiple types of sensor device and multiple scenarios thereof, and the multi-level collaborative calibration also achieves simple and efficient verification of the calibration result.","['G01D21/02', 'G01N27/416', 'G06F18/214', 'G06N3/08', 'H04L41/145', 'H04L41/16', 'H04L67/12', 'H04W4/38']"
US11281993B2,Model and ensemble compression for metric learning,"Systems and processes for metric learning distillation are disclosed herein. In accordance with one example, a method includes, at an electronic device, at an electronic device having one or more processors and memory, receiving a first plurality of vectors from a first model, receiving a second plurality of vectors from a second model, determining a first plurality of vector distances based on the first plurality of vectors, generating a first matrix based on the first plurality of vector distances, determining a second plurality of vector distances based on the second plurality of vectors, generating a second matrix based on the second plurality of vector distances, comparing the first matrix with the second matrix, and adjusting the second model based on the comparison of the first matrix and the second matrix.","['G06N20/00', 'G06F3/04883', 'G06N5/02', 'G06F3/04817']"
US20190046068A1,Protocol independent image processing with adversarial networks,"Systems and methods are provided for generating a protocol independent image. A deep learning generative framework learns to recognize the boundaries and classification of tissues in an MRI image. The deep learning generative framework includes an encoder, a decoder, and a discriminator network. The encoder is trained using the discriminator network to generate a latent space that is invariant to protocol and the decoder is trained to generate the best output possible for brain and/or tissue extraction.","['A61B5/055', 'G06F18/241', 'G06F18/24133', 'G06K9/6268', 'G06N3/045', 'G06N3/0454', 'G06N3/084', 'G06T11/003', 'G06T7/10', 'G06T7/11', 'G06T9/002', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06V2201/03']"
CN112052387B,"Content recommendation method, device and computer readable storage medium","The embodiment of the invention discloses a content recommendation method, a content recommendation device and a computer readable storage medium; the method comprises the steps of carrying out multidimensional feature extraction on historical browsing records and content to be recommended in a content to be recommended set after a user data set to be recommended and the content to be recommended set to obtain browsing behavior features of users to be recommended and content features of the content to be recommended, clustering the users to be recommended according to the browsing behavior features and the historical browsing records to obtain a plurality of user groups to be recommended and group browsing behavior features and group historical browsing records of the user groups to be recommended, screening initial content to be recommended corresponding to the user groups to be recommended from the content to be recommended according to similarity of the group browsing behavior features and the content features, determining target content to be recommended of the users to be recommended based on the group historical browsing records and the initial content to be recommended, and recommending the target content to be recommended to the users to be recommended; the scheme can greatly improve the accuracy of content recommendation.","['G06F16/9535', 'G06F16/334', 'G06F16/35']"
US11030722B2,System and method for estimating optimal parameters,"A method and system of generating an adjustment parameter value for a control parameter to enhance a new image, which includes configuring a neural network, trained to restore image quality for a derivative image, to that of an earlier version of the derivative image, to generate as an output the adjustment parameter value, for the control parameter in response to input of data derived from the new image, and changing a control parameter of the new image, by generating the adjustment parameter value by calculating an inverse of the output value, and applying the adjustment parameter value to the control parameter of the new image so as to generate an enhanced image.","['G06T5/001', 'G06N3/045', 'G06F18/214', 'G06K9/6256', 'G06K9/66', 'G06N3/00', 'G06N3/084', 'G06T5/60', 'G06N3/048', 'G06T2207/20081', 'G06T2207/20084']"
CN110956957B,Training method and system of speech enhancement model,"The embodiment of the invention provides a training method of a speech enhancement model. The method comprises the following steps: receiving pure voice and voice with noise corresponding to the pure voice; respectively extracting a first audio frequency spectrum characteristic of pure voice and a second audio frequency spectrum characteristic of noisy voice; compressing a second audio spectral feature of the noisy speech to generate a first deep speech feature; denoising the first depth voice feature to obtain a denoised second depth voice feature; performing audio spectrum recovery on the second deep voice characteristic to obtain a third audio spectrum characteristic of the voice with noise; and determining the characteristic mean square error of the first audio spectrum characteristic of the pure voice and the third audio spectrum characteristic of the noisy voice, training a voice enhancement model based on the mean square error until the characteristic mean square error accords with a preset threshold value, and determining the voice enhancement model. The embodiment of the invention also provides a training system of the voice enhancement model. The embodiment of the invention enables the voice enhancement model to have the capability of solving noise and far field and improves the recognition performance.","['G10L17/00', 'G10L15/063', 'G10L17/06', 'G10L17/18', 'G10L21/0208', 'G10L21/0216', 'G10L25/18', 'G10L25/24', 'G10L25/30']"
US11062490B2,Reinforcement learning for online sampling trajectory optimization for magnetic resonance imaging,"A magnetic resonance imaging scan performs an MRI acquisition using an undersampling pattern to produce undersampled k-space data; adds the undersampled k-space data to aggregate undersampled k-space data for the scan; reconstructs an image from the aggregate undersampled k-space data; updates the undersampling pattern from the reconstructed image and aggregate undersampled k-space data using a deep reinforcement learning technique defined by an environment, reward, and agent, where the environment comprises an MRI reconstruction technique, where the reward comprises an image quality metric, and where the agent comprises a deep convolutional neural network and fully connected layers; and repeats these steps to produce a final reconstructed MRI image for the scan.","['G06T11/006', 'G01R33/5608', 'A61B5/055', 'G01R33/4818', 'G01R33/561', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/088', 'G06N7/01', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084']"
CN110084757B,Infrared depth image enhancement method based on generation countermeasure network,"The invention discloses an infrared depth image enhancement method based on a generation countermeasure network, which comprises the following steps: selecting an image database of a training network; constructing and generating a confrontation network model; preprocessing an image; the training generates a confrontation network. According to the method, the generation countermeasure network in the deep learning algorithm is utilized to enhance the infrared depth image, the training of the generation countermeasure network is realized through the three-dimensional image quality database aiming at the difficulty of acquisition of the infrared depth image, the noise of the depth image with poor quality is removed, the quality of the depth image is improved, the obtained enhanced depth image can be used as a standard image for subsequent image processing, and the conditions of infrared depth image distortion and low quality are improved.","['G06T5/70', 'G06T5/80', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
WO2022088631A1,"Image encoding method, image decoding method, and related apparatuses","Disclosed in embodiments of the present application are an image encoding method, an image decoding method, and related apparatuses. The image decoding method comprises: obtaining an original residual block of a current coding block, the current coding block comprising a currently processed video frame or coding units obtained by dividing the currently processed video frame; obtaining transform features of the current coding block according to the original residual block and a pre-trained feature prediction model; quantizing the transform features of the current coding block to obtain quantized features of the current coding block; determining, by means of a pre-trained probability prediction model, the probability of each pixel in the quantized features of the current coding block; and generating a binary code stream of the current coding block using the probability of each pixel. According to the embodiments of the present application, adaptive dynamic residual compensation is implemented, and different forms of inter-frame residual information can be effectively encoded.","['H04N19/124', 'H04N19/149', 'H04N19/159', 'H04N19/176', 'H04N19/50', 'H04N19/94']"
US8989443B2,Method of improving orientation and color balance of digital images using face detection information,"A method of generating one or more new spatial and chromatic variation digital images uses an original digitally-acquired image which including a face or portions of a face. A group of pixels that correspond to a face within the original digitally-acquired image is identified. A portion of the original image is selected to include the group of pixels. Values of pixels of one or more new images based on the selected portion are automatically generated, or an option to generate them is provided, in a manner which always includes the face within the one or more new images. Such method may be implemented to automatically establish the correct orientation and color balance of an image. Such method can be implemented as an automated method or a semi automatic method to guide users in viewing, capturing or printing of images.","['G06V40/161', 'H04N9/68', 'G06K9/00221', 'G06K9/00228', 'G06K9/00234', 'G06K9/00281', 'G06K9/3208', 'G06K9/3241', 'G06V10/242', 'G06V40/16', 'G06V40/162', 'G06V40/171']"
CA3065094C,Integrated surveillance and control,"A method of managing oilfield activity with a control system is provided having a plurality of virtual sensors and integrating the virtual sensors into a virtual sensor network. The method includes determining interdependencies among the virtual sensors, obtaining operational information from the virtual sensors, and providing virtual sensor output to the control system based on the determined interdependencies and the operational information.","['E21B44/00', 'E21B21/08', 'E21B41/00', 'E21B43/00', 'E21B43/12', 'E21B43/2607', 'E21B47/12', 'G05B13/027', 'G05B13/04', 'G05B17/02', 'G05B19/41845', 'G05B19/4185', 'G05B19/41885', 'G05B23/0256', 'G06N20/00', 'H04L67/125', 'G05B2219/21086', 'G05B2219/24071', 'G05B2219/25064', 'G05B2219/37537', 'G06N3/08', 'G06N3/126', 'Y02P90/02']"
US11847816B2,Resource optimization based on video frame analysis,"Techniques are provided for processing video frames in a process flow that includes first and second computation engines. In an example, the first engine is an artificial intelligence based computation engine, and the second engine is a heuristics-based computation engine. A sequence of frames of a video includes a first and second frames that are two consecutive frames in the sequence. An analyzer determines whether the second frame has non-redundant information relative to the first frame. In response to the determination, the analyzer selects one of the first or second engine for processing at least a section of the second frame. For example, if the second frame has non-redundant information relative to the first frame, at least the section of the second frame is processed by the first engine. If the second frame does not include non-redundant information, the second frame is processed by the second engine.","['G06V10/764', 'G06F18/214', 'G06N3/08', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/44']"
US20230409963A1,Methods for training artificial intelligence components in wireless systems,"A method is described for using artificial intelligence (AI) components in association with first a transceiver node in a wireless network, where the first node is configured to send data over a wireless channel and to initiate a training procedure for an artificial intelligent component in a second node. The first node, having an encoder, transmits, to a decoder in the second node, a plurality of ordered training pairs, the transmission in response to a detection of a trigger condition based on a reconstruction loss value determined by the first node. The first node receives, from the second node, partially processed training information corresponding to the transmitted training pairs. The first node updates learnable parameters of the encoder based on the received partially processed training information to reduce the reconstruction loss value.","['G06N3/084', 'G06N20/00', 'G06N3/045', 'G06N3/088']"
CN113657349B,A human behavior recognition method based on multi-scale spatiotemporal graph convolutional neural network,"The invention relates to a human behavior recognition method based on a multi-scale space-time diagram convolutional neural network, and belongs to the technical field of neural networks. The method comprises the steps of extracting a human skeleton sequence to be identified to create a data set and preprocessing; creating a deep neural network model comprising a multi-scale map convolution module and a multi-time-length feature fusion module, so that the model can better extract the spatial features of human bones and the time sequence features of bone sequences; training and testing the deep neural network to obtain a human behavior recognition neural network model; and classifying the video images to be identified by using the trained model, and outputting classification results. The human body behavior recognition method provided by the invention can enable the neural network model to better extract the space-time characteristics of the skeleton sequence, realize the automatic recognition of human body behaviors and improve the accuracy of human body behavior recognition.","['G06F18/2415', 'G06N3/045', 'G06N3/047', 'G06N3/084']"
US11113800B2,Filtering image data using a neural network,"A method, computer readable medium, and system are disclosed for performing spatiotemporal filtering. The method includes identifying image data to be rendered, reconstructing the image data to create reconstructed image data, utilizing a filter including a neural network having one or more skip connections and one or more recurrent layers, and returning the reconstructed image data.","['G06T15/005', 'G06V10/82', 'G06F18/2414', 'G06K9/00986', 'G06K9/6273', 'G06K9/66', 'G06T1/20', 'G06T11/60', 'G06T15/506', 'G06T15/60', 'G06T5/002', 'G06T5/20', 'G06T5/60', 'G06T5/70', 'G06V10/955', 'G06V30/19173', 'G06V30/194', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20182']"
CN109389587B,"Medical image analysis system, device and storage medium","The invention provides a medical image analysis system, a medical image analysis apparatus and a storage medium. The system comprises an acquisition module, a region-of-interest determination module and a deformation type determination module. The acquisition module is used for acquiring a sample image and an image to be detected. The interested region determining module is used for inputting the image to be detected into a first detection model and determining at least one interested region of the image to be detected, wherein the first detection model is a deep learning model. The deformation type determining module is used for inputting the at least one region of interest into a second detection model and determining the deformation type of the image to be detected, wherein the second detection model is a deep learning model. The method applies the deep convolution neural network to the prediction of the image deformation type, and has short time consumption and high accuracy.","['G06T7/0012', 'G06F18/241', 'G06T7/136', 'G16H50/20', 'G06T2207/10088']"
CN113887487B,Facial expression recognition method and device based on CNN-transducer,"The invention discloses a facial expression recognition method and a facial expression recognition device based on CNN-transformers, which belong to the technical field of digital image signal processing, wherein the method comprises the steps of preprocessing an input picture to obtain a corrected face picture; calculating LBP characteristics of the face image, and sending the LBP characteristics as input into a pre-constructed CNN network to obtain local characteristics of the face; uniformly dividing a face image, and then sending the face image into a transducer to obtain global features of the face; information fusion is carried out on the global features and the local features, and fusion features are obtained; according to the invention, through the feature fusion module, the influence weight of the local features and the global features on the whole can be independently learned, and the complementarity between different features is effectively improved, so that the global features and the emotion information contained in the local features can be fully utilized, and the identification accuracy of emotion classification is further improved.","['G06F18/253', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G06T3/02', 'G06T5/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30201']"
US10965489B2,Artificial intelligence refrigerator and method for controlling the same,"Disclosed is an artificial refrigerator. The artificial refrigerator according to the present disclosure includes at least one sensor for sensing an operation state of the refrigerator and obtaining operation information about the operation state of the refrigerator and a processor that determines whether the operation state of the refrigerator is normal or abnormal using a deep-learning-based first diagnosis engine based on the operation information obtained using the at least one sensor and diagnoses, upon determination of the abnormality, a cause of the abnormality using a deep-learning-based second diagnosis engine. In the artificial refrigerator of the present invention, at least one of a user terminal or a server may be associated with an artificial intelligence module, a drone (Unmanned Aerial Vehicle, UAV) robot, an augmented reality (AR) device, a virtual reality (VR) device, a device related to a 5G service, and the like.","['F25D29/006', 'F25B31/008', 'F25B39/04', 'F25B41/043', 'F25B49/02', 'F25B5/02', 'F25D11/022', 'F25D29/005', 'G06N3/042', 'G06N3/045', 'G06N3/08', 'H04L12/2825', 'F25B2500/06', 'F25B2500/19', 'F25B2600/2511', 'F25B2700/02', 'F25B2700/2104', 'F25B2700/2106', 'F25D2700/12', 'H04L2012/285']"
CN114503108B,Adding adversarial robustness to trained machine learning models,"Methods and systems are provided for protecting a trained machine learning model by one or more processors in a computing system. By adding resistance protection to one or more trained machine learning models, one or more enhanced machine learning models may resist resistance attacks.","['G06F21/552', 'G06F11/1471', 'G06F21/577', 'G06N20/00', 'G06N3/045', 'G06N3/0464', 'G06N3/082', 'G06N3/088', 'G06N3/09', 'G06N3/094']"
US11521068B2,Method and system for neural network synthesis,"According to various embodiments, a method for generating one or more optimal neural network architectures is disclosed. The method includes providing an initial seed neural network architecture and utilizing sequential phases to synthesize the neural network until a desired neural network architecture is reached. The phases include a gradient-based growth phase and a magnitude-based pruning phase.","['G06N3/082', 'G06N3/04', 'G06N3/045']"
US11755751B2,Modify access restrictions in response to a possible attack against data stored by a storage system,"An illustrative method includes a data protection system determining that data stored by a storage system is under a possible attack, detecting a modify request with respect to the storage system while the data stored by the storage system is under the possible attack, determining that the modify request may be related to the possible attack, and performing, in response to determining that the modify request may be related to the possible attack, a remedial action with respect to the modify request.","['G06F21/604', 'G06F21/6218', 'G06F12/04', 'G06F21/566', 'G06F12/0246', 'G06F2212/1052', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'G06F2221/034']"
US11720714B2,Inter-I/O relationship based detection of a security threat to a storage system,"An illustrative method includes a data protection system identifying one or more input operations and one or more output operations performed between a source and a storage system, identifying an anomaly in a relationship between the one or more input operations and the one or more output operations, and determining, based on the identifying of the anomaly, that the storage system is possibly being targeted by a security threat.","['G06F21/6218', 'G06F21/78', 'G06F11/1448', 'G06F11/1469', 'G06F11/2056', 'G06F11/2089', 'G06F12/0246', 'G06F12/1408', 'G06F12/1433', 'G06F21/566', 'G06F21/577', 'G06F21/606', 'G06F3/0604', 'G06F3/0622', 'G06F3/0653', 'G06F3/0659', 'G06F3/067', 'G06F11/2069', 'G06F2201/84', 'G06F2212/1032', 'G06F2212/1052', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'G06F3/062']"
CN112070690B,Single Image Deraining Method Based on Convolutional Neural Network Dual-Branch Attention Generation,"The invention discloses a single image rain removing method based on convolutional neural network double-branch attention generation, which comprises the following steps: preprocessing an input image; constructing a U-shaped structure network; adding the attention of the weight channel into the first U-shaped network to obtain an added first U-shaped network; adding the spatial attention and the channel attention to a second U-shaped structure network to obtain an added second U-shaped network; the method comprises the steps of adding a processed image a obtained by processing an added first U-shaped network, adding a processed image b obtained by processing an added second U-shaped network and a preprocessed image, and convoluting to obtain a convolutional neural network model; training the convolutional neural network model by the preprocessed image, and restraining by using a loss function to obtain a trained rain-removing network model; and placing the image to be processed with rain into a trained rain removing network model, and finally outputting the image after rain removal, thereby improving the rain removing performance of a single image.","['G06T5/73', 'G06N3/045', 'G06N3/084', 'G06T2207/20081', 'G06T2207/20084', 'Y02A90/10']"
CN112733964B,Convolutional neural network quantization method for reinforcement learning automatic perception weight distribution,"The method comprises the steps of fusing parameters of each layer of batch processing operation and the weights of convolution operation to obtain fused weights and offsets, and obtaining the distribution information of each layer of fused weights in a floating point convolution neural network model; according to the distribution information reinforcement learning of each layer of weight, automatically searching the optimal weight scaling coefficient of each layer, and quantizing the floating point weight into INT8 type data based on the weight scaling coefficient of each layer; inputting a calibration data set, recording each layer of output feature map by each group of data, selecting mode as a scaling coefficient of each layer of output feature map, calculating the scaling coefficient of each layer of offset according to the scaling coefficient of each layer of weight and the scaling coefficient of each layer of output feature map so as to quantize the offset of floating point into the offset of INT32 type, and constructing a forward reasoning process based on the INT8 type data, the offset of INT32 type and the total scaling coefficient to complete quantization.","['G06F18/214', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06N5/04']"
US11131994B2,Debugging an autonomous driving machine learning model,"A method for improving an autonomous driving system for an autonomous vehicle is disclosed. The method includes sub-sampling a frame generated by an output of a sensor and transmitting, to a remote device, the sub-sampled frame and classification data corresponding to the sub-sampled frame. The method also includes receiving, from the remote device, an adjustment to the autonomous driving system in response to the transmitted sub-sampled frame and classification data. The method further includes controlling an action of the autonomous vehicle based on the adjusted autonomous driving system.","['B60W60/0015', 'G05D1/0088', 'G06K9/00805', 'G06N20/00', 'G06N3/006', 'G06N3/045', 'G06N3/084', 'G06V10/764', 'G06V10/82', 'G06V20/58', 'B60W2050/0075', 'B60W2420/403', 'B60W2556/20', 'B60W2556/45', 'B60W2556/55', 'G05D2201/0213']"
CN107967669B,"Picture processing method and device, computer equipment and storage medium","The application relates to a method for processing pictures, which comprises the following steps: the method comprises the steps of obtaining an image to be processed, segmenting the image to be processed to obtain a plurality of sub image blocks, calculating a module gradient value corresponding to each sub image block, classifying the sub image blocks into corresponding target module classes in a module class set according to the module gradient values, performing super-resolution processing on the sub image blocks according to an image processing algorithm corresponding to the target module classes, wherein each module class in the module class set corresponds to different module gradient value ranges respectively, and the larger the module gradient value included in the module gradient value range corresponding to the module class is, the higher the definition of the sub image block obtained by processing through the corresponding image processing algorithm is; and splicing the processed sub image blocks according to the positions before segmentation to obtain a target image. The method can meet the real-time display requirement of a user while ensuring the processing effect. In addition, a picture processing device, a computer device and a storage medium are also provided.","['G06T3/4053', 'G06T3/4007', 'G06T3/4038', 'G06T7/11']"
EP4244770A1,Architecture for explainable reinforcement learning,An exemplary embodiment may provide an explainable reinforcement learning system. Explanations may be incorporated into an exemplary reinforcement learning agent/model or a corresponding environmental model. The explanations may be incorporated into an agent's state and/or action space. An explainable Bellman equation may implement an explainable state and explainable action as part of an explainable reward function. An explainable reinforcement learning induction method may implement a dataset to provide a white-box model which mimics a black-box reinforcement learning system. An explainable generative adversarial imitation learning model may implement an explainable generative adversarial network to train the occupancy measure of a policy and may generate multiple levels of explanations. Explainable reinforcement learning may be implemented on a quantum computing system using an embodiment of an explainable Bellman equation.,"['G06N20/00', 'G06N3/08', 'G09B9/00', 'G06N3/042', 'G06N3/045', 'G06N3/047', 'G06N7/01']"
US20200342548A1,System and Method for Machine Learning and Augmented Reality Based User Application,"The invention synthesizes a social network, electronic commerce (including performance based advertisement and electronic payment), a mobile internet device (MID)/mobile wearable internet device, a topological data analysis (TDA) algorithm(s), an algorithm(s) based on game theory and a machine learning algorithm(s), utilizing a classical computer or an optical computer enhanced machine learning algorithm(s), utilizing an optical computer or a quantum computer enhanced machine learning algorithm(s), utilizing a quantum computer. The synthesized social commerce further dynamically integrates stored information, real time information and real time information/data/image(s) from an object/array of objects (Internet of Things (IoT)) and automated agents (bots). The machine learning algorithm(s), utilizing a classical computer can include a software agent, a fuzzy logic algorithm, a predictive algorithm, an intelligence rendering algorithm, a self-learning (including relearning) algorithm and an evolutionary algorithm.","['G06Q30/0631', 'G06F16/27', 'G06F16/953', 'G06N10/00', 'G06N10/60', 'G06N3/045', 'G06N3/0454', 'G06N3/067', 'G06N3/086', 'G06Q20/065', 'G06Q20/321', 'G06Q20/36', 'G06Q20/40145', 'G06Q30/0206', 'G06Q50/01', 'G06Q50/188', 'G07B15/02', 'G07C13/00', 'G07C9/257', 'H04L67/306', 'G06Q20/3278', 'H04W4/80']"
CN109741260B,Efficient super-resolution method based on depth back projection network,"The invention discloses a high-efficiency super-resolution method based on a depth back projection network, which comprises the following steps of: (1) acquiring a total training set and a test set; (2) preprocessing the total training set to complete data enhancement; (3) Scaling the images in the total training set in different scales; (4) The method is characterized in that the super-resolution reconstruction of the image is realized based on a convolutional neural network, and the convolutional neural network comprises 27 convolutional layers, and specifically comprises three parts, namely feature extraction, error back projection and image reconstruction. The invention replaces the traditional convolution redesigned iteration submodule with the combination of the group convolution and the 1 multiplied by 1 convolution, and the strategy can effectively reduce the model parameter number and improve the model efficiency; each iteration sub-module comprises an error feedback mechanism and timely performs error correction; in addition, the invention refers to a channel weighting module, so that the model efficiency can be further improved.",[]
CN111428556B,Traffic sign recognition method based on capsule neural network,"The invention relates to a traffic sign recognition method based on a capsule neural network, which is characterized in that the image is preprocessed by adopting methods such as image equalization, maximum stable extremum region segmentation, normalization and the like, factor interference such as motion blur, background interference, illumination, local shielding damage of traffic signs and the like is eliminated, and an image of a region of interest is segmented, so that the image of the region of interest can be effectively extracted, the recall ratio of a dim light condition is improved, and the robustness is enhanced; introducing a capsule neural network structure, adopting a convolutional layer bottom layer characteristic, packaging into a vectorized capsule unit after passing through a main capsule layer tensor vector, adopting dynamic routing clustering and back propagation to update weight parameters, realizing model training and outputting model weight parameters, having a faster training speed and reducing training time; finally, the classification of the images is realized according to the trained model weight parameters and the dynamic routing clustering, so that the recall ratio of the weak illumination pictures can be effectively improved, and the recognition rate of traffic signs can be improved.","['G06V10/25', 'G06F18/214', 'G06F18/241', 'G06T7/11', 'G06T7/136', 'G06T7/62', 'G06T7/90', 'G06V20/582']"
US11265549B2,Method for image coding using convolution neural network and apparatus thereof,"A method for image decoding performed by a decoding apparatus, according to the present disclosure, comprises the steps of: obtaining residual information for a current block from a bitstream; deriving a prediction sample for the current block; deriving a residual sample for the current block on the basis of the residual information; deriving a reconstructed picture on the basis of the prediction sample and the residual sample; and performing filtering on the reconstructed picture on the basis of a convolution neural network (CNN).","['H04N19/132', 'H04N19/176', 'G06N3/02', 'G06N3/045', 'H04N19/117', 'H04N19/182', 'H04N19/46', 'H04N19/82', 'H04N19/85']"
CN114266739B,Medical image segmentation method based on semi-supervised convolutional neural network based on contrastive learning,"The invention provides a medical image segmentation method of a semi-supervised convolutional neural network based on contrast learning, which mainly aims at positioning segmentation of specific tissue structure images in medical images, and specifically comprises the following steps of (1) inputting medical image data, preprocessing the medical image data, extracting positive and negative samples, and dividing a data set to obtain training set data, verification set data and test set data; the method comprises the steps of (1) constructing a contrast learning convolutional neural network segmentation model, (3) constructing a semi-supervised medical image segmentation network model based on contrast learning, and (4) predicting test set data by using the obtained training model to obtain a final segmentation prediction image. The invention effectively realizes the semi-supervised segmentation of medical image processing, solves the problem of segmentation of specific areas when the medical image data set is less to a certain extent, and better improves the accuracy of medical image segmentation.",['Y02T10/40']
US9704054B1,Cluster-trained machine learning for image processing,"Image classification and related imaging tasks performed using machine learning tools may be accelerated by using one or more of such tools to associate an image with a cluster of such labels or categories, and then to select one of the labels or categories of the cluster as associated with the image. The clusters of labels or categories may comprise labels that are mutually confused for one another, e.g., two or more labels or categories that have been identified as associated with a single image. By defining clusters of labels or categories, and configuring a machine learning tool to associate an image with one of the clusters, processes for identifying labels or categories associated with images may be accelerated because computations associated with labels or categories not included in the cluster may be omitted.","['G06K9/46', 'G06V10/454', 'G06F18/23', 'G06F18/24', 'G06F18/24317', 'G06K9/6218', 'G06K9/6267', 'G06V10/762', 'G06V10/764']"
CN107437096B,Image Classification Method Based on Parameter Efficient Deep Residual Network Model,"The invention discloses an image classification method based on a parameter efficient depth residual error network model, which is characterized in that an improved network model with parameter efficiency is established according to the depth, width, diversity and cardinality of a network and is used for efficiently classifying and identifying images; the method comprises the following steps: dividing the image data into training samples and testing samples; preprocessing a training sample image; constructing a depth residual error network model with parameter efficiency, and performing model training: the constructed network model comprises a depth pyramid residual error network model, a nested network model and a triangular network model; respectively training the network models by the preprocessed training samples to obtain trained network models; identifying the test samples to respectively obtain predicted classification labels; thereby realizing image classification recognition.",['G06F18/241']
CN111368685B,"Method and device for identifying key points, readable medium and electronic equipment","The disclosure relates to a method and a device for identifying key points, a readable medium and electronic equipment, and relates to the technical field of image processing, wherein the method comprises the following steps: the method comprises the steps of identifying an image to be processed according to a preset face recognition algorithm to obtain an initial face image, inputting the initial face image into a pre-trained image processing model to obtain a target face image output by the image processing model, inputting the target face image into a pre-trained key point identification model to obtain key points in the target face image output by the key point identification model, wherein the definition of the target face image is larger than that of the initial face image. According to the method and the device, the initial face image is firstly identified, then the target face image with higher definition is obtained by utilizing the image processing model, and finally the key points in the target face image are identified, so that the accuracy of key point identification can be improved.","['G06V40/161', 'G06V40/168', 'Y02T10/40']"
CN111462488B,Intersection safety risk assessment method based on deep convolutional neural network and intersection behavior characteristic model,"The invention discloses an intersection safety risk assessment method based on a deep convolutional neural network and an intersection behavior feature model, and belongs to the field of intelligent traffic. According to the method, an aerial view camera is used for obtaining image information, a deep convolutional neural network is used for identifying vehicles, the vehicle tracks are analyzed by using behavior characteristics of the vehicles at the intersection, the collision probability among the vehicles is calculated, and finally the safety risk of the intersection is evaluated. The method is suitable for vehicle online safety early warning under the intersection environment, is also suitable for real-time detection and early warning of potential traffic safety hidden dangers, can improve the safety level of intersection operation, and improves the accuracy rate of traffic accident prediction.","['G08G1/0104', 'G06F18/23', 'G06N3/045', 'G06N3/08', 'G06V20/52', 'G08G1/0125']"
AU2018102037A4,A method of recognition of vehicle type based on deep learning,"This patent is a specifically image recognized method based on deep learning. The image-based vehicle recognition system first captures the vehicle image from the video stream in camera, and then pattern recognition and computer vision are employed to attain the valuable information in order to carry out classification and recognition. This invention is mainly intended to preprocess images of various vehicles and then to divide all of the images into training set and testing set. The training set image is used for Deep Convolutional Neural Network training, and then the parameters between the layers of the Convolutional Neural Network are modified, which can be used in our testing set. After the training is completed, the neural network for testing is initialized with the parameters we get before to train a similar network as in training part. After that, the images for testing are putted into the Deep Neural Network to embody the identification and classification of the vehicle images. The invention does not require human participation and adjustment, and automatically performs the extraction and classification of features, providing a reliable high-performance image recognition technology based on deep learning. Standard Neural Net After Applying Dropout Figure 5","['G06V20/584', 'G06N3/0464', 'G06N3/084', 'G06V10/24']"
CN113786204B,Epileptic intracranial brain electrical signal early warning method based on deep convolution attention network,"The invention provides an epileptic intracranial brain electrical signal early warning method based on a deep convolution attention network, which is characterized in that an intracranial brain electrical signal (Intracranial electroencephalography, iEEG) signal at the anterior thalamus nucleus (Anterior Nucleus of the Thalamus, ANT) of an epileptic patient is collected and analyzed, the multi-scale time sequence characteristic and the multi-frequency spectrum characteristic of the intracranial brain electrical signal are extracted and fused, an attention mechanism is adopted, the most obvious characteristic of the epileptic brain electrical signal is focused, and the early warning accuracy of the network is obviously improved. In one embodiment of the invention, verification is performed on an intracranial brain electrical signal data set containing 5 epileptics, wherein the average epileptic early warning accuracy (Sn) of a single patient can reach 95.0%, the false alarm rate (False Predicting Rate, FPR) per hour is less than 0.15, and the method is superior to the existing epileptic early warning method in early warning effect and model generalization capability, realizes accurate and rapid early warning of epilepsia, and has important significance for diagnosis and nerve regulation of clinical epileptic diseases.","['A61B5/369', 'A61B5/374', 'A61B5/4094', 'A61B5/7203', 'A61B5/7235', 'A61B5/725', 'A61B5/7257', 'A61B5/7267']"
US10347293B1,"Detecting, redacting, and scoring confidential information in video","Provided is a process, including: obtaining screen-cast video; determining amounts of difference between respective frames; selecting a subset of frames based on the amounts; causing OCRing of each frame in the subset of frames; classifying text in each frame-OCR record as confidential or non-confidential; and forming a redacted version of the screen-cast video based on the classifying.","['G06F40/284', 'G06F17/277', 'G06F18/2433', 'G06F3/1454', 'G06F3/1462', 'G06F40/30', 'G06K9/00718', 'G06K9/6202', 'G06K9/6284', 'G06V20/41', 'G11B27/031', 'G11B27/28', 'G06K2209/01', 'G06V30/10', 'G06V30/19013']"
US20240202600A1,Machine learning model administration and optimization,"Systems and methods for a model inference service system that provides a technical solution for deploying and updating trained machine-learning models with support for specific use case deployments and implementations at scale with efficient processing. The model inference service system includes a hierarchical model registry for versioning models and model dependencies for each versioned model, a model inference service for rapidly deploying model instances in run-time environments, and a model processing system for managing multiple instances of deployed models. Changes to deployed models are captured as new versions in the hierarchical model registry.","['G06F16/3347', 'G06F16/3326', 'G06F16/334', 'G06F16/335', 'G06F16/338', 'G06F16/345', 'G06F40/20', 'G06F40/40', 'G06N20/00', 'G06N3/045', 'G06N3/0475', 'G06N3/092', 'G06N5/04', 'G06N3/063']"
US9037224B1,Apparatus for treating a patient,"A signal processing method and system combines multi-scale decomposition, such as wavelet, pre-processing together with a compression technique, such as an auto-associative artificial neural network, operating in the multi-scale decomposition domain for signal denoising and extraction. All compressions are performed in the decomposed domain. A reverse decomposition such as an inverse discrete wavelet transform is performed on the combined outputs from all the compression modules to recover a clean signal back in the time domain. A low-cost, non-drug, non-invasive, on-demand therapy braincap system and method are pharmaceutically non-intrusive to the body for the purpose of disease diagnosis, treatment therapy, and direct mind control of external devices and systems. It is based on recognizing abnormal brainwave signatures and intervenes at the earliest moment, using magnetic and/or electric stimulations to reset the brainwaves back to normality. The feedback system is self-regulatory and the treatment stops when the brainwaves return to normal. The braincap contains multiple sensing electrodes and microcoils; the microcoils are pairs of crossed microcoils or 3-axis triple crossed microcoils.","['A61B5/369', 'A61B5/0476', 'A61B5/0036', 'A61B5/4082', 'A61B5/4088', 'A61B5/4094', 'A61B5/4839', 'A61B5/7203', 'A61B5/7214', 'A61B5/7246', 'A61B5/726', 'A61B5/7264', 'A61F7/00', 'A61F7/007', 'A61M5/1723', 'A61N1/0476', 'A61N1/36025', 'A61N1/36031', 'A61N2/006', 'A61N2/008', 'A61N2/02', 'G06F3/015', 'G06N3/08', 'A61B5/389', 'A61F2007/0094', 'A61N1/0408', 'A61N1/0456', 'A61N1/0526', 'A61N1/303', 'G16H50/20']"
US11756202B2,Method for semantic segmentation based on knowledge distillation,"A knowledge distillation based semantic image segmentation method includes inputting an input image to a teacher network and a student network; normalizing a first feature vector corresponding to each pixel in a feature map of a last layer of the teacher network and normalizing a second feature vector corresponding to each pixel in a feature map of a last layer of the student network; generating the first channel and space association matrix and the second channel and space association matrix based on the normalized first feature vector and the normalized second feature vector, and defining a first loss function based on a Euclidean norm value of the difference between the first channel and space association matrix and the second channel and space association matrix.","['G06T7/11', 'G06N3/045', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06V20/41', 'G06V20/695', 'G06T2207/20081', 'G06T2207/20084']"
US11315013B2,Implementing parameter server in networking infrastructure for high-performance computing,"Techniques are provided for implementing a parameter server within a networking infrastructure of a computing system to reduce the communication bandwidth and latency for performing communication synchronization operations of the parameter server. For example, a method includes executing a distributed deep learning (DL) model training process to train model parameters of a DL model using a plurality of worker nodes executing on one or more server nodes of a computing system, and executing a parameter server within a networking infrastructure of the computing system to aggregate local model parameters computed by the plurality of worker nodes and to distribute aggregated model parameters to the plurality of worker nodes using the networking infrastructure of the computing system.","['G06N3/08', 'G06F8/31', 'G06F9/44505', 'G06F9/45541', 'G06F9/45558', 'G06N3/045', 'G06N3/084', 'H04L67/1095', 'G06F2009/45579', 'G06F2009/45595', 'G06N3/044']"
US20180239982A1,Satellite with machine vision,"In one embodiment, a satellite configured for machine vision includes, but is not limited to, at least one imager; one or more computer readable media bearing one or more program instructions; and at least one computer processor configured by the one or more program instructions to perform operations including at least: obtaining imagery using the at least one imager of the satellite; determining at least one interpretation of the imagery by analyzing at least one aspect of the imagery; and executing at least one operation based on the at least one interpretation of the imagery.","['G06K9/209', 'G06K9/00234', 'G06K9/0063', 'G06K9/00711', 'G06K9/2027', 'G06K9/342', 'G06K9/4652', 'G06T7/20', 'G06V10/147', 'G06V20/13', 'G06V20/40', 'G06V40/162', 'H04N23/21', 'H04N23/50', 'H04N23/60', 'H04N23/695', 'H04N23/698', 'H04N23/90', 'H04N5/23238', 'H04N7/181', 'G06K2009/00738', 'G06K2009/2045', 'G06T2207/10016', 'G06V20/44']"
US11818520B2,Intelligent subsystem,"An intelligent subsystem comprising a system-on-a-chip (that can include a microprocessor and a graphic/graphical processor), a foldable/stretchable display, radio modules/transceivers, a first set of computer implementable instructions for intelligent learning (that can include (i) artificial intelligence or an artificial neural network and (ii) fuzzy logic) and a second set of computer implementable instructions in natural language is disclosed. The intelligent subsystem can (i) respond to a user's interests and/or preferences and (ii) provide a peer-to-peer transaction. Furthermore, the intelligent subsystem can be sensor-aware or context-aware.","['H04Q11/0067', 'H01S3/101', 'H04B10/272', 'H04B10/5161', 'H04J14/0223', 'H04J14/0256', 'H04J14/0282', 'H04Q11/0005', 'H01S5/0265', 'H01S5/06256', 'H01S5/06258', 'H04Q2011/0016', 'H04Q2011/0032', 'H04Q2011/0064']"
US20180239948A1,Satellite with machine vision for disaster relief support,"In one embodiment, a satellite configured to provide machine vision for disaster-relief support includes, but is not limited to, at least one imager; one or more computer readable media bearing one or more program instructions; and at least one computer processor configured by the one or more program instructions to perform operations including at least: obtaining imagery using the at least one imager of the satellite; detecting at least one event by analyzing at least one aspect of the imagery; and executing at least one operation based on the at least one event.","['G06K9/0063', 'G06V20/13', 'G06K9/46', 'G06K9/66', 'G06T7/20', 'G01W1/00', 'G01W2203/00', 'G06T2207/10032', 'G06T2207/30192', 'G06V20/44']"
US12243534B2,Speaker attributed transcript generation,"A computer implemented method processes audio streams recorded during a meeting by a plurality of distributed devices. Operations include performing speech recognition on each audio stream by a corresponding speech recognition system to generate utterance-level posterior probabilities as hypotheses for each audio stream, aligning the hypotheses and formatting them as word confusion networks with associated word-level posteriors probabilities, performing speaker recognition on each audio stream by a speaker identification algorithm that generates a stream of speaker-attributed word hypotheses, formatting speaker hypotheses with associated speaker label posterior probabilities and speaker-attributed hypotheses for each audio stream as a speaker confusion network, aligning the word and speaker confusion networks from all audio streams to each other to merge the posterior probabilities and align word and speaker labels, and creating a best speaker-attributed word transcript by selecting the sequence of word and speaker labels with the highest posterior probabilities.","['H04L12/1831', 'G10L15/08', 'H04L65/403', 'H04M3/568', 'G10L15/26', 'G10L19/018', 'H04L12/1822', 'H04L51/10', 'H04M2201/40', 'H04M2201/41', 'H04M3/42221']"
CN109492698B,"Model training method, object detection method and related device","The invention discloses a model training method, which comprises the following steps: sending a picture marking instruction to a server; receiving a to-be-trained picture subset sent by a server, wherein the to-be-trained picture subset belongs to a to-be-trained picture set, the to-be-trained picture set comprises M to-be-trained pictures, and the to-be-trained picture subset comprises N to-be-trained pictures; acquiring label information corresponding to each picture to be trained in the picture subset to be trained, wherein the label information is used for identifying the object type in the picture to be trained; and sending the picture subset to be trained and the label information to a server, so that the server trains to obtain a target detection model according to the picture subset to be trained and the label information, wherein the target detection model is used for obtaining object detection information in the picture. The invention discloses an object detection method, a client and a server. According to the invention, users do not need to negotiate whether the picture to be labeled is repeated or omitted, so that the accuracy of labeling the picture is improved.","['G06F18/214', 'H04L67/14']"
US11824732B2,Techniques for artificial intelligence capabilities at a network switch,Examples include techniques for artificial intelligence (AI) capabilities at a network switch. These examples include receiving a request to register a neural network for loading to an inference resource located at the network switch and loading the neural network based on information included in the request to support an AI service to be provided by users requesting the AI service.,"['H04L41/16', 'G06F8/60', 'G06N3/04', 'G06N3/105', 'G06N5/04', 'H04L41/0816', 'H04L41/344', 'H04L41/5012', 'H04L41/5019', 'H04L41/5051', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N5/01']"
US10795949B2,Methods and systems for investigation of compositions of ontological subjects and intelligent systems therefrom,"Methods and systems are given for investigation of compositions of ontological subjects in accordance with various aspects of significance. Accordingly, the present invention provide a unified method and process of investigating the compositions of ontological subjects, modeling an unknown system, and obtaining as much worthwhile information and knowledge as possible about the system or the composition or the body of knowledge along with exemplary services utilizing such investigations. The data structures built and the knowledge acquired by a machine through executing the investigation methods of the present disclosure enables artificial intelligent systems, machines, and agents to perform intelligent tasks and jobs.","['G06F16/951', 'G06N5/02', 'G06F16/00', 'G06N3/08']"
US10902543B2,Neural network based insertion of watermark into images and tampering detection thereof,"Systems and methods for insertion of a watermark into images and tampering detection of the watermarked images by a Convolutional Neural Network (CNN) technique. The traditional systems and methods provide for detecting the tampering of the watermarked images by simply identifying a presence of an inserted watermark into an image but none them provide for inserting a random sequence into input image(s) and then detect the tampering by classifying the input image(s) by a neural network. Embodiments of the present disclosure provide for insertion of the watermark into the input image(s) and tampering detection of the watermarked images by training a Convolutional Neural Network (CNN) 201 to classify the images as tampered or non-tampered, extracting random noise, obtaining non-classified watermarked images from the random noise, and obtaining, from the non-classified watermarked images, classified watermarked images and detecting an absence or a presence of the tampering based upon the classified watermarked images.","['G06T1/005', 'G06F18/2411', 'G06K9/6269', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T1/0042', 'G06T2201/0065', 'G06T2201/0083', 'G06T2201/0201']"
US11625815B2,Image processor and method,"An image processing apparatus and a method are provided. The apparatus comprises a plurality of processing modules configured to operate in series to refine a raw image captured by a camera, the modules comprising a first module and a second module, each of which independently implements a respective trained artificial intelligence model, wherein: the first module implements an image transformation operation that performs an operation from the set comprising: (i) an essentially pixel-level operation that increases sharpness of an image input to the module, (ii) an essentially pixel-level operation that decreases sharpness of an image input to the module, (iii) an essentially pixel-block-level operation on an image input to the module; and the second module as a whole implements a different operation from the said set.","['G06T5/009', 'G06T5/92', 'G06T1/20', 'G06N3/084', 'G06T3/4015', 'G06T5/002', 'G06T5/003', 'G06T5/70', 'G06T5/73', 'G06T5/90', 'H04N23/88', 'H04N9/646', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US12386505B2,Cost considerate placement of data within a pool of storage resources,"Cost considerate placement of data within a pool of storage resources, including: receiving one or more data objects for storage; selecting, based at least upon a storage policy and upon one or more characteristics of storage data, one or more storage classes from among a plurality of storage classes of one or more data storage services, wherein the storage policy specifies parameters for one or more of: storage costs, storage operation response time, data resiliency, or service level agreement specifications; and storing the one or more data objects to the selected one or more storage classes of the one or more data storage services.","['G06F3/0604', 'G06F3/0638', 'G06F3/0652', 'G06F3/067', 'G06F3/0688', 'G06F3/0649']"
US20210311841A1,Data Recovery Service,"A method for storage system reliability using data recovery as a service, the method including: receiving, for storage data on a storage system, a specification for a particular recovery time objective (“RTO”) and recovery point objective (“RPO”) setting among a plurality of options for RTO/RPO settings; generating, in accordance with the particular RTO/RPO setting, a change stream of data in response to receiving data to be stored on the storage system; and transmitting, from the storage system to a cloud data recovery as a service endpoint, the change stream of data from which data on the storage system may be recovered up to a point in time corresponding to the particular RPO setting and within a time period corresponding to the particular RTO setting.","['H04L41/145', 'G06F11/1453', 'G06F11/1464', 'G06F11/1466', 'G06F11/1469', 'G06F11/203', 'G06F11/2056', 'G06F11/3006', 'G06F11/3041', 'G06F11/3409', 'H04L41/0886', 'H04L41/0895', 'H04L41/40', 'H04L41/5041', 'H04L41/5054', 'H04L41/5096', 'G06F2201/81', 'G06F2201/82', 'G06F2201/84', 'H04L41/0806', 'H04L41/0816', 'H04L41/0897', 'H04L41/142', 'H04L41/147', 'H04L41/149', 'H04L41/16', 'Y02D10/00']"
US11882179B2,Supporting multiple replication schemes across distinct network layers,"Supporting multiple replication schemes across distinct network layers, including: replicating, over a first type of network messaging layer, data between a first storage system and a second storage system; selecting a different messaging layer for data replication; and replicating, over a second type of network messaging layer, data between the first storage system and the second storage system.","['H04L67/1095', 'H04L41/0816', 'H04L41/0886', 'H04L41/0895', 'H04L67/1097', 'H04L69/16', 'H04L41/0266', 'H04L41/16', 'H04L69/40']"
US20230100253A1,Network-based artificial intelligence (ai) model configuration,"A method of wireless communication by a base station includes receiving a user equipment (UE) radio capability and a UE machine learning capability. The method also includes determining a neural network function (NNF) based on the UE radio capability. The method includes determining a neural network model. The neural network model includes a model structure and a parameter set, based on the NNF, the UE machine learning capability, and a capability of a network entity. The method also includes configuring the network entity with the neural network model.","['G06N3/04', 'H04L41/0806', 'G06N3/0464', 'H04L41/082', 'H04L41/16', 'H04W8/24', 'G06N20/00', 'G06N3/08', 'H04W24/02', 'H04W88/085']"
WO2020215241A1,Real-time object detection method deployed in platform having limited computing resource,"A real-time object detection method deployed in a platform having a limited computing resource. The method comprises: forming a Tinier-YOLO structure by means of improving on a YOLO-v3-tiny neural network, wherein the Tinier-YOLO structure retains the first five convolutional and pooling layers of the YOLO-v3-tiny network, and incorporates fire modules, a 1*1 bottleneck layer, and dense connection in SqueezeNet. The Tinier-YOLO structure can operate on embedded devices and mobile devices to perform object detection. Further disclosed are an object detection device employing image processing, and an application of said object detection method or device employing image processing in the field of automatic driving, security, or architecture.","['G06N3/063', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06V10/764', 'G06V10/82', 'G06V10/955']"
US10743107B1,Synchronization of audio signals from distributed devices,"A computer implemented method includes receiving audio signals representative of speech via multiple audio channels transmitted from corresponding multiple distributed devices, designating one of the audio channels as a reference channel, and for each of the remaining audio channels, determine a difference in time from the reference channel, and correcting each remaining audio channel by compensating for the corresponding difference in time from the reference channel.","['H04R3/005', 'H04R5/04', 'G06F3/165', 'G10L15/16', 'H04L65/60', 'H04R29/006', 'H04R3/04', 'H04R3/12', 'G10L2015/088', 'H04R2201/405', 'H04R2420/07']"
US12213767B2,Video-based method and system for accurately estimating human body heart rate and facial blood volume distribution,"Provided is a video-based method and system for accurately estimating heart rate and facial blood volume distribution, and the method mainly comprises the following steps: firstly, carrying out face detection of video frame containing human face, and extracting face image sequence and face key position points sequence in time dimension; secondly, compressing these sequence of face image and face key position points to obtain the facial signals in time dimension; thirdly, estimating facial blood volume distribution by facial signals mentioned in third step; finally, estimating heart rate values by using model based on deep learning technology and the spectrum analysis method respectively, then fusing the estimation results by Kalman filter to promote the accuracy of heart rate estimation.","['G06V40/172', 'A61B5/02416', 'A61B5/0295', 'A61B5/7232', 'A61B5/725', 'A61B5/7264', 'G06F18/214', 'G06F18/2415', 'G06N3/044', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06T7/0012', 'G06T7/0016', 'G06T7/11', 'G06T7/73', 'G06V10/25', 'G06V10/62', 'G06V10/774', 'G06V10/806', 'G06V10/82', 'G06V40/15', 'G06V40/161', 'G06V40/168', 'G06V40/171', 'G16H30/40', 'G16H50/20', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30076', 'G06T2207/30088', 'G06T2207/30201', 'G06V2201/03']"
US11875796B2,Audio-visual diarization to identify meeting attendees,"A computer implemented method includes receiving information streams on a meeting server from a set of multiple distributed devices included in a meeting, receiving audio signals representative of speech by at least two users in at least two of the information streams, receiving at least one video signal of at least one user in the information streams, associating a specific user with speech in the received audio signals as a function of the received audio and video signals, and generating a transcript of the meeting with an indication of the specific user associated with the speech.","['G10L15/26', 'G10L15/22', 'H04L65/403', 'H04N7/15', 'H04R1/406', 'G06Q10/10']"
US20190191988A1,Screening method for automated detection of vision-degenerative diseases from color fundus images,"Disclosed herein are methods and apparatuses for detecting vision-degenerative diseases. A first method comprises obtaining a dataset of fundus images, using a custom deep learning network to process the dataset of fundus images, and providing, as an output, a function for use in diagnosing a vision-degenerative disease. A computing device comprises memory storing a representation of the function produced by the first method, and one or more processors configured to use the function to assist in the diagnosis of the vision-degenerative disease. A second method is for determining a likelihood that a patient's eye has a vision-degenerative disease, the method comprising obtaining a fundus image of the patient's eye, processing the fundus image using the function obtained from the first method, and, based on the processing of the fundus image, providing an indication of the likelihood that the patient's eye has the vision-degenerative disease.","['A61B3/0025', 'A61B3/12', 'A61B3/1241', 'A61B3/14', 'A61B5/6898', 'A61B5/725', 'A61B5/7267', 'A61B5/7275', 'A61B5/7282', 'G06T7/0012', 'G06T7/0014', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G16H70/60', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30041']"
US20210379425A1,Personal protection and monitoring,"A personal protection device includes one or two elongate members for engaging into the nostrils of the nose of a user. The elongate members each includes gridded ports for allowing air to pass through the elongate member when breathing in and for allowing air to exit via the elongate member when breathing out. Sensors are placed in the air flow pathway to detect pathogen presence, and the primary air filter is positioned in the elongate member. In yet other embodiments, a disposable version is disclosed. The eyewear can also be used as part of an extended reality system, and when game playing, particularized scents can be rendered to the nose to enhance the gaming experience. In another aspect, systems and methods protect against pathogen by sampling an environment of a travel path with a plurality of pathogen detectors along the travel path to detect a presence of one or more pathogens, wherein at least one detector includes a nano-sensor with receptacles to bind to the pathogens and wherein the nano-sensor changes resistivity, inductance or capacitance upon pathogen binding; directing air towards said pathogen detectors; contact tracing a user mobile device having a mobile identification (ID) carried by each user, wherein the mobile device comprises a memory storing mobile IDs of all devices within a predetermined radius of the user mobile device; and performing deep learning with a neural network receiving data from the pathogen detectors and to the user mobile device to detect a presence of one or more pathogens.","['A62B23/06', 'A61B5/0022', 'A61B5/0205', 'A61B5/7264', 'A61B5/01', 'A61B5/024', 'A61B5/053', 'A61B5/0816', 'A61B5/107', 'A61B5/1118', 'A61B5/1176', 'A61B5/14532', 'A61B5/14542', 'A61B5/165', 'A61B5/318', 'A61B5/369', 'A61B5/4266', 'A61B5/6804', 'A61B5/6807', 'A61B5/681', 'A61B5/6819', 'A61B5/6898', 'A61B5/7203', 'A61B5/7257', 'A61B5/726', 'A61B6/03', 'A61B6/032', 'A61B7/006', 'A61B7/02', 'A61L2209/14', 'A61L9/20', 'A62B9/006']"
CN111324728B,"Text event abstract generation method and device, electronic equipment and storage medium","The invention provides a method and a device for generating a text event abstract, electronic equipment and a storage medium; the method comprises the following steps: coding the title in the text to obtain the attention weight and the context information of the title; performing attention processing on the text in the text to obtain the attention weight of the text; carrying out fusion processing on the attention weight of the title and the attention weight of the text to obtain the attention distribution of the text; carrying out vocabulary mapping processing on the context information of the title to generate vocabulary distribution of the title; carrying out fusion processing on the attention distribution of the text and the vocabulary distribution of the title to obtain key data of the text; and combining the key data of the text to obtain an event abstract corresponding to the text. According to the invention, the text and the title in the text can be fused, and the event abstract of the text can be accurately extracted.","['G06F16/345', 'Y02D10/00']"
US20220194400A1,System and method for enhancing vehicle performance using machine learning,"A machine learning algorithm, for example, a neural network, is trained to offer predictions, recommendations, and/or insights regarding vehicle components, products or services that are customized to a particular driver. The trained machine learning algorithm is subsequently deployed.","['B60W50/10', 'G06V10/82', 'B60W40/09', 'B60W50/14', 'G06F18/214', 'G06K9/6256', 'G06V20/56', 'B60W2050/146']"
US11801393B2,Determining initial treatments from spectral data,"This document presents a system for managing treatment for an emergency cardiac event. The system includes memory, one or more electronic ports for receiving ECG signals, and a treatment module executable on one or more processing devices. The module is configured to generate transform values for a time segment of ECG, obtain one or more previous values derived from one or more earlier time segments of the ECG, and determine, based on the generated transform values, and the one or more previous values, at least one of: a) a future therapeutic action for treating the emergency cardiac event, or b) a phase of the cardiac event. The module is further configured to cause one or more output devices to present an indication of at least one of the therapeutic action or the phase of the cardiac event.","['A61N1/3987', 'A61B5/316', 'A61B5/347', 'A61B5/7253', 'A61B5/7275', 'A61H31/004', 'A61H31/005', 'A61H31/006', 'A61H31/007', 'A61N1/3925', 'A61N1/3993', 'A61B5/7257', 'A61B5/726', 'A61H2201/501', 'A61H2201/5015', 'A61H2201/5043', 'A61H2201/5046', 'A61H2201/5058', 'A61H2201/5084', 'A61H2201/5097', 'A61H2230/105', 'G16H50/30']"
CN112914527B,Arterial blood pressure signal acquisition method based on pulse wave photoplethysmography,"The invention discloses an arterial blood pressure signal acquisition method based on pulse wave photoplethysmography, which comprises the following steps: firstly, constructing a mapping from pulse waves to arterial blood pressure waveforms, specifically adopting a neural network based on Wave-U-Net as a basic framework, wherein the whole network comprises: a downsampling path, an intermediate layer, an upsampling path, and an output layer; training the network, adjusting parameters to obtain an optimal model for converting the pulse wave signals into arterial blood pressure signals, wherein the training comprises the following steps: data acquisition, data preprocessing and network training. According to the invention, the noninvasive wearable pulse wave signals obtained from the fingertip positions are converted into high-quality arterial blood pressure signals which can be obtained by invasive invasion at present through the deep neural network, so that the complexity of collecting the high-quality arterial blood pressure signals is reduced, the possibility of noninvasive monitoring of the arterial blood pressure signals for a long time is provided, and the development of mobile health monitoring technology is promoted.","['A61B5/02108', 'A61B5/7235', 'G06N3/045', 'G06N3/08', 'Y02A90/10']"
CN113313156B,A method and system for identifying IoT devices based on time-series load flow fingerprint,"The invention discloses an internet of things equipment flow identification method and system based on time sequence load flow fingerprints. In the training stage, according to the message length sequence information and the message section sequence information of the marked class of the internet of things equipment flow, the learnable parameters in the neural network are trained, so that automatic internet of things equipment flow fingerprint extraction and internet of things equipment identification are realized. And in the classification stage, based on the trained neural network model, carrying out the fingerprint construction of the flow of the Internet of things equipment to be identified, and completing the flow identification of different Internet of things equipment. According to the method, network traffic generated by any Internet of things equipment is accurately depicted from different feature dimensions, so that the fingerprint of the Internet of things equipment traffic with more expressive capacity is formed, and the method has high accuracy, high generalization capacity and robustness in the process of identifying the Internet of things equipment traffic.","['G06F18/2414', 'G06F18/214', 'G06N3/04', 'G06N3/084', 'G06N5/041', 'G16Y30/10', 'G16Y40/20', 'Y02D30/50']"
CN107000272B,Method for controlling process steps performed automatically using a machine and method for producing particle foam parts,"The invention relates to a method for controlling a process step automatically performed by a machine. The invention is characterized in that the sensor is used to measure a characteristic variable for a step and having an exponential type process, and by means of a plurality of successive measurements of said characteristic variable, a time constant of exponential type change is determined, and said step is ended after said step has been performed for a time period corresponding to a predetermined multiple of said time constant.","['B29C44/60', 'B29C39/36', 'B29C44/3415', 'B29C44/3426', 'B29C44/445', 'B29K2023/06', 'B29K2023/12', 'B29K2025/06', 'B29K2067/046', 'B29K2075/00', 'B29K2079/08']"
US12412132B2,Smart contract management of licensing and apportionment using a distributed ledger,Transaction-enabled methods for providing provable access to a distributed ledger with a tokenized instruction set for polymer production processes are described. A method may include accessing a distributed ledger comprising an instruction set for a polymer production process and tokenizing the instruction set. The method may further include interpreting an instruction set access request and providing provable access to the instruction set. The method may further include providing commands to a production tool of the polymer production process and recording the transaction on the distributed ledger.,"['G06Q10/04', 'G05B19/00', 'G05B19/41865', 'G05B19/4188', 'G06F16/182', 'G06F16/1865', 'G06F16/23', 'G06F16/2365', 'G06F16/2379', 'G06F16/24', 'G06F16/27', 'G06F16/951', 'G06F18/2148', 'G06F18/2155', 'G06F21/105', 'G06F21/602', 'G06F30/27', 'G06F9/3836', 'G06F9/3891', 'G06F9/466', 'G06F9/4806', 'G06F9/4881', 'G06F9/50', 'G06F9/5005', 'G06F9/5016', 'G06F9/5027', 'G06F9/5072', 'G06F9/541', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/042', 'G06N3/043', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06N5/04', 'G06Q10/0631', 'G06Q10/06314', 'G06Q10/06315', 'G06Q10/067', 'G06Q20/06', 'G06Q20/065', 'G06Q20/0655', 'G06Q20/0855', 'G06Q20/12', 'G06Q20/123', 'G06Q20/145', 'G06Q20/29', 'G06Q20/308', 'G06Q20/367', 'G06Q20/38215', 'G06Q20/384', 'G06Q20/389', 'G06Q20/4016', 'G06Q20/405', 'G06Q30/0201', 'G06Q30/0202', 'G06Q30/0205', 'G06Q30/0206', 'G06Q30/0247', 'G06Q30/0273', 'G06Q30/06', 'G06Q40/04', 'G06Q40/10', 'G06Q50/04', 'G06Q50/06', 'G06Q50/184', 'H02J3/008', 'H02J3/14', 'H02J3/28', 'H02J3/388', 'H04L12/14', 'H04L47/783', 'H04L47/788', 'H04L47/83', 'H04L9/3239', 'H04L9/50', 'G05B2219/36542', 'G06F16/2457', 'G06F9/3838', 'G06N3/0418', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06N5/01', 'G06N5/022', 'G06N5/046', 'G06Q20/4015', 'G06Q2220/00', 'G06Q2220/12', 'G06Q2220/18', 'G06Q30/0254', 'G06Q30/0276', 'G06Q50/01', 'H02J3/003', 'H04L67/10', 'H04L67/12', 'H04L67/34', 'H04L9/0643', 'Y02B70/3225', 'Y02D10/00', 'Y02P90/02', 'Y02P90/845', 'Y04S10/50', 'Y04S20/222', 'Y04S40/20', 'Y04S50/10', 'Y04S50/12', 'Y04S50/14']"
CN114370696B,D-S evidence theory-based central air conditioner cooling tower water outlet temperature control method,"The invention discloses a method for controlling the outlet water temperature of a central air conditioner cooling tower based on a D-S evidence theory, which comprises the following steps: collecting different types of sensor parameters in the running process of a central air conditioning system, and taking the sensor parameters as original sample data reflecting the water outlet temperature of a cooling tower; preprocessing the original sample data, analyzing principal components and performing correlation analysis to obtain an input data set, and inputting the input data set into each intelligent prediction algorithm for training to obtain a plurality of corresponding cooling tower water outlet temperature prediction models; carrying out weight extraction and fusion on prediction results of the plurality of cooling tower water outlet temperature prediction models by adopting a D-S evidence theory to obtain a final cooling tower water outlet temperature prediction value; and comparing the predicted value of the water outlet temperature of the cooling tower with a set water outlet temperature value of the cooling tower, if the predicted value of the water outlet temperature of the cooling tower is inconsistent with the set water outlet temperature value of the cooling tower, taking the energy consumption of a cooling water system as an objective function, setting constraint conditions, and solving by adopting an intelligent optimizing algorithm to obtain the operation frequency combination of the cooling water pump and the cooling tower fan with optimal energy consumption so as to realize the control of the temperature.","['F24F11/64', 'F24F11/77', 'F24F11/84', 'F24F11/85', 'Y02B30/70']"
US12038927B2,Storage system having multiple tables for efficient searching,"A method for efficiently supporting deletion in a probabilistic data structure, and related computing or storage system are described. A processor, computing system or storage system constructs a table and a summary table for determining whether there is an entry for a value in the table. The summary table has buckets pointed to by address fields of values. Each bucket has a prefix table, a transit table, signature table and a first indicator. The system tracks deletion and addition of items of the table and summary table through the first indicators.","['G06F16/2255', 'G06F16/2455']"
US10375156B2,Using worker nodes in a distributed video encoding system,"Various of the disclosed embodiments relate to a distributed video encoding or transcoding system may utilize multiple encoding nodes to encode a video sequence by splitting the video into multiple smaller video segments. The assignment of video segments to the encoding nodes is performed to balance the use of the encoding nodes by selecting a node based on its encoding capabilities, e.g., whether the node employed a central processing unit (CPU) based encoding or a graphics processor unit (GPU) based encoding.","['H04L67/1008', 'H04N19/395', 'H04N19/436']"
US12067131B2,Transitioning leadership in a cluster of nodes,"Transitioning leadership in a cluster of nodes, including: initiating, by two or more nodes among a cluster of nodes, a leadership transition, wherein: a first node transmits a first secret key identifier to each of the other nodes in the cluster of nodes; and a second node transmits a second secret key identifier to each of the other nodes in the cluster of nodes; updating, by each node and based at least in part on a resolution policy, the current secret key identifier to be the second secret key identifier instead of the first secret key identifier; and transitioning, based at least in part on the second secret key identifier being selected to be the current secret key identifier, the second node to be a leader node of the cluster of nodes.","['G06F21/64', 'G06F21/602', 'G06F16/215', 'G06F16/2365', 'G06F16/2379', 'G06F21/78', 'H04L9/0643', 'H04L9/0891', 'H04L9/0894', 'H04L9/3239', 'G06F2221/2107']"
US12346613B2,Maintaining multiple redundancy schemes across different storage types,"Utilizing multiple redundancy schemes within a unified storage element, including: receiving, in a storage system at a unified storage element that integrates both fast durable storage and bulk durable storage, a data storage operation from a host computer; storing, in accordance with a first data resiliency technique that corresponds to a RAID N+R format, data corresponding to the data storage operation within the fast durable storage of the unified storage element; and responsive to determining that the complete RAID stripe has been written to the fast durable storage, moving a portion of the stored data from the fast durable storage to the bulk durable storage of the unified storage element, the bulk durable storage storing the data in accordance with a second data resiliency technique that corresponds to a RAID M+R format, wherein M is different from N.","['G06F3/0685', 'G06F3/0614', 'G06F11/0727', 'G06F11/0793', 'G06F11/1076', 'G06F11/1435', 'G06F11/1662', 'G06F11/2005', 'G06F11/2007', 'G06F11/2089', 'G06F11/2094', 'G06F11/3034', 'G06F11/3055', 'G06F3/061', 'G06F3/0611', 'G06F3/0616', 'G06F3/0617', 'G06F3/0638', 'G06F3/0647', 'G06F3/0659', 'G06F3/067', 'G06F3/0688', 'G06F3/0689', 'G06F11/1441', 'G06F11/2071', 'G06F2201/84', 'G06F2212/261']"
US11825553B2,UE capability for AI/ML,"This disclosure provides systems, devices, apparatus, and methods, including computer programs encoded on storage media, for a UE capability for AI/ML. A UE may receive a request from a network to report a UE capability for at least one of an AI procedure or an ML procedure. The UE may transmit to the network, based on the request to report the UE capability, an indication of one or more of an AI capability, an ML capability, a radio capability associated with the at least one of the AI procedure or the ML procedure, or a core network capability associated with the at least one of the AI procedure or the ML procedure.","['H04W8/24', 'G06N20/00', 'G06N3/04', 'H04B7/0626', 'H04L41/16', 'H04W24/02', 'H04W72/21', 'H04W76/25', 'G06N3/084', 'G06N3/10']"
US10890968B2,Electronic device with foveated display and gaze prediction,"An electronic device may have a foveated display, an eye-tracking system and a head movement detection system. The eye-tracking system may gather information on a user's point of regard on the display while the head movement detection system may capture information regarding the rotation of the observer's head. Based on the point-of-regard information, head rotation information, image data, the type of eye/head movement that is underway, and/or tiredness information, control circuitry in the electronic device may produce image data for a display, with areas of different resolutions and(or) visual quality. A full-resolution and(or) quality portion of the image may overlap the point of regard. One or more lower resolution portions of the image may surround the full-resolution portion. The control circuitry may include a gaze prediction system for predicting the movement of the user's gaze during a saccade.","['G06F3/013', 'G01D11/00', 'G02B27/0093', 'G02B27/0101', 'G02B27/017', 'G02B27/0172', 'G06F18/214', 'G06F3/011', 'G06F3/012', 'G06F3/016', 'G06F3/0346', 'G06N3/044', 'G06N3/045', 'G06V40/19', 'H04N13/366', 'H04N13/383', 'G02B2027/0138', 'G02B2027/0187']"
US20230161880A1,Cross-architecture automatic detection method and system for third-party components and security risks thereof,"The invention discloses a cross-architecture automated detection method and system for third-party components and security risks, comprising: identify and reverse the firmware of the IoT device, classify the resulting reverse products into binary and non-binary files; disassemble binary files to mine the semantic information in them; convert non-binary files into string text files; build a database containing third-party components and their known CVE; combine pattern matching to scan string text files automatically, collect third-party components in the firmware of IoT device, and collect and retrieve vulnerabilities of corresponding third-party components. Through organically combining the semantic information of the vulnerability assembly code and the semantic information of the firmware assembly code of IoT device, the similarity comparison across architectures and deep learning is realized, and the specific pattern vulnerability is mined and verified automatically. The invention does not require the acquisition of firmware source code, the detection process is automated, greatly reducing the difficulty and workload of manual analysis.","['G06F21/57', 'G06F21/577', 'G06F21/562', 'G06F21/563', 'G06F21/572', 'G06N3/044', 'G06N3/08', 'G06F2221/033']"
US11301727B2,Efficient image classification method based on structured pruning,"The present invention provides an efficient image classification method based on structured pruning, which incorporates a spatial pruning method based on variation regularization, including steps such as image data preprocessing, inputting images to neural network, image model pruning and retraining, and new image class predication and classification. The present invention adopts a structured pruning method that removes unimportant weight parameters of the original network model and reduces unnecessary computational and memory consumptions caused by the network model in image classification to simplify the image classifier, and then uses the sparsified network model to predict and classify new images. The simplified method according to the present invention improves the original network model in image classification efficiency by nearly two times, costs about 30% less memory consumption and produces a better classification result.","['G06N3/082', 'G06K9/6268', 'G06F18/214', 'G06F18/2163', 'G06F18/217', 'G06F18/241', 'G06K9/6256', 'G06K9/6261', 'G06K9/6262', 'G06N3/045', 'G06N3/084', 'G06T3/4023', 'G06V10/454', 'G06V10/82', 'G06V10/513']"
CN109345575B,Image registration method and device based on deep learning,"According to the image registration method and device based on deep learning, an image registration model is built by utilizing a capsule network, a vector feature representation and routing mechanism replaces a scalar representation and pooling mechanism in a traditional deep learning convolution network, and capsules of different layers are connected step by step to carry out feature combination; outputting a fused image with the same dimension size as the reference image as registration output by constructing an image fusion network based on capsule vectors; by constructing a loss function based on similarity measurement between images, training network parameters are fed back, a registration network of unsupervised learning is optimized, and image registration operation with high precision and high robustness is realized.","['G06T7/337', 'G06T2207/10088', 'G06T2207/10092', 'G06T2207/10116', 'G06T2207/20081', 'G06T2207/20084']"
US20230078763A1,"Image generation device, image generation method, recording medium generation method, learning model generation device, learning model generation method, learning model, data processing device, data processing method, inference method, electronic device, generation method, program and non-temporary computer readable medium","[Object]Training data is acquired using a computer graphics.[Solution]An image generation method includes acquiring a CG model or an artificial image generated based on the CG model and performing, by a processor, processing on the CG model or the artificial image and generating metadata of a processed image used for AI learning used for an image acquired by a sensor or the artificial image.","['G06V10/774', 'G06T15/00', 'G06N3/09', 'G06T11/00', 'G06T5/60', 'G06T5/80', 'G06V20/58', 'G06N3/0464', 'G06N7/01', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252', 'G06V2201/07', 'G06V2201/08']"
EP4117383A1,Method for performing multi-link communication in wireless communication system,"According to various embodiments, a multi-link device (MLD) operating in a plurality of links including a first link can transmit a request frame to a first AP of an AP MLD through a first STA (station), wherein the request frame includes an information field for requesting every element included in an element set designated for a second link. The MLD can, on the basis of the request frame, receive every element included in the element set designated for the second link.","['H04W12/041', 'H04W12/06', 'H04W28/08', 'H04W36/00692', 'H04W36/08', 'H04W74/002', 'H04W76/15', 'H04W76/19', 'H04W84/12', 'H04W88/10', 'H04W28/0247']"
WO2022225579A1,Variables & implementations of solution automation & interface analysis,"Variables relevant to implementing solution automation & interface analysis determine how different implementations can be found/generated/derived & filtered. Additionally, additional specific example implementations of components of solution automation & interface analysis (like example solution automation workflows, function types, and useful structures) to implement solution automation & interface analysis are included in the specification of this invention.","['G06N5/04', 'G06F16/245', 'G06F16/254', 'G06F16/258', 'G06F40/166', 'G06F40/20', 'G06F40/247', 'G06F40/30', 'G06F40/40', 'G06F9/453', 'G06N20/00', 'G06N3/02', 'G06N5/02', 'G06Q10/0633', 'G06Q10/10', 'G06N3/006']"
US10949978B2,Automatic background replacement for single-image and multi-view captures,"A segmentation of an object depicted in a first visual representation may be determined. The segmentation may include for each image a first respective image portion that includes the object, a second respective image portion that includes a respective ground area located beneath the object, and a third respective image portion that includes a background area located above the second respective portion and behind the object. A second visual representation may be constructed that includes the first respective image portion and a target background image portion that replaces the third respective image portion and that is selected from a target background image based on an area of the third respective image portion relative to the respective image.","['G06T11/00', 'G06T11/40', 'G06T5/005', 'G06T5/77', 'G06T7/11', 'G06T7/194', 'G06T7/55', 'G06T7/73', 'G06T2200/04', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30244']"
WO2021249255A1,Grabbing detection method based on rp-resnet,"The present invention relates to a grabbing detection method based on an RP-ResNet, which method belongs to the field of computer vision, and in particular relates to the recognition and positioning of a grabbing point of a mechanical arm. The method comprises: inputting a target object image; pre-processing data; performing data processing by means of an RP-ResNet model; and finally, generating a grabbing block diagram of a grabbing target. On the basis of a model ResNet-50, a region proposal network is used in the 30th layer of a network, fuzzy positioning is performed on the position of a grabbing point, feature information of high and low layers is fully fused to strengthen the utilization of information of low layers, and an SENet structure is added to the 40th layer of the network, thereby further increasing the detection accuracy of a grabbing point. By means of a grabbing detection framework based on ResNet-50, a residual network, a region proposal idea and SENet are combined, such that it is ensured that rapid target detection is realized, and the accuracy rate of target detection is further improved.","['G06N3/0464', 'G06N3/043', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/09', 'G06V10/25', 'G06V10/267', 'G06V10/454', 'G06V20/647']"
CN110969124B,Two-dimensional human body posture estimation method and system based on lightweight multi-branch network,"The invention relates to the field of attitude estimation, in particular to a two-dimensional human body attitude estimation method and a system based on a lightweight multi-branch network, which comprises the following steps: inputting an image, and preprocessing the image; transmitting the image into a backbone network for feature extraction and information encoding; decoding different encoding stages of a main network by using a lightweight upsampling unit to form a network structure with a plurality of decoding branches; solving the mean square loss of the characteristic diagram generated by each decoding branch and the real labeled thermodynamic diagram, and returning the sum of the losses to the neural network for iterative training; after training is finished, inputting the image containing the pedestrian into the trained neural network model to obtain the coordinate position of each joint point in the image, and visualizing the human posture. The invention can output the coordinates of all the joint points of the pedestrian pictures which are input randomly and carry out the visualization of the postures, and meanwhile, the invention is convenient for the arrangement of a mobile terminal due to lower calculation cost, thereby increasing the applicability of related products.","['G06V40/20', 'G06F18/213', 'G06N3/045', 'G06N3/08']"
US11065466B2,Shock determination based on prior shocks,"A system for managing care of a person receiving emergency cardiac assistance is disclosed that includes one or more capacitors for delivering a defibrillating shock to a patient; one or more electronic ports for receiving signals from sensors for obtaining indications of an electrocardiogram (ECG) for the patient; a patient treatment module executable on one or more computer processors to provide a determination of a likelihood of success from delivering a future defibrillating shock to the person with the one or more capacitors, using (a) information about a prior defibrillating shock, and (b) a value that is a function of current ECG signals from the patient.","['A61N1/3987', 'A61N1/39044', 'A61B5/053', 'A61B5/349', 'A61N1/3925', 'A61N1/3931', 'A61N1/3993', 'H01L23/53238', 'H01L23/53257', 'H01L2924/00', 'H01L2924/0002']"
US11531871B2,Stacked neuromorphic devices and neuromorphic computing systems,"A stacked neuromorphic device includes a logic die including a control circuit and configured to communicate with a host, and core dies stacked on the logic die and connected to the logic die via through silicon vias (TSVs) extending through the core dies. The core dies include a neuromorphic core die including a synapse array connected to row lines and column lines. The synapse array includes synapses configured to store weights and perform a calculation based on the weights and input data. The weights are included in layers of a neural network system. And the control circuit provides the weights to the neuromorphic core die through the TSVs and controls data transmission by the neuromorphic core die.","['G06N3/049', 'G06N3/063', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/065', 'G06N3/08', 'G06N3/088', 'H01L2224/16145', 'H01L2224/16227', 'H01L2224/17181', 'H01L2225/06513', 'H01L2225/06517', 'H01L2225/06541', 'H01L25/0652', 'H01L25/0657', 'H01L25/18']"
US12299842B2,Adaptive deep learning model for noisy image super-resolution,"Embodiments described herein are generally directed to an end-to-end trainable degradation restoration network (DRN) that enhances the ability of a super-resolution (SR) subnetwork to deal with noisy low-resolution images. An embodiment of a method includes estimating, by a noise estimator (NE) subnetwork of the DRN, an estimated noise map for a noisy input image; and predicting, by the SR subnetwork of the DRN, a clean upscaled image based on the input image and the noise map by, for each of multiple conditional residual dense blocks (CRDBs) stacked within one or more cascade blocks representing the SR subnetwork, adjusting, by a noise control layer of the CRDB that follows a stacked set of a multiple residual dense blocks of the CRDB, feature values of an intermediate feature map associated with the input image by applying (i) a scaling factor and (ii) an offset factor derived from the noise map.","['G06N3/088', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06T3/4046', 'G06T3/4053', 'G06N3/048', 'G06N3/063']"
US11138979B1,Speech audio pre-processing segmentation,"An apparatus includes processor(s) to: divide a speech data set into multiple data chunks that each represent a chunk of speech audio; derive a threshold amplitude based on at least one peak amplitude of the speech audio; designate each data chunk with a peak amplitude below the threshold amplitude a pause data chunk; within a set of temporally consecutive data chunks of the multiple data chunks, identify a longest subset of temporally consecutive pause data chunks; within the set of temporally consecutive data chunks, designate the longest subset of temporally consecutive pause data chunks as a likely sentence pause of a candidate set of likely sentence pauses; based on at least the candidate set, divide the speech data set into multiple data segments that each represent a speech segment of the speech audio; and perform speech-to-text conversion, to identify a sentence spoken in each speech segment.","['G10L15/26', 'G06N3/0454', 'G06N3/08', 'G10L15/02', 'G10L15/04', 'G10L25/30', 'G10L25/78', 'G06N3/044', 'G10L2025/783']"
NL2018758B1,Optical music recognition (OMR) assembly for converting sheet music,"The invention provides an optical music recognition (OMR) assembly for converting sheet music, representing a music part as a first temporal representation, into a machine-processable representation of said piece of music that represents at least a pitch and duration of notes that are graphically represented in said sheet music and form said music part as a second temporal representation, said assembly comprising a data processor system and software which, when running on said data processor system: -retrieves a machine-processable representation of said sheet music; - generate a series of time slices of said sheet music, by applying a sliding window on said over said machine-processable representation of at least part of said sheet music; - defines a sequence-to-sequence system, said sequence-to-sequence system compnsmg: * provide a convolutional neural network (CNN) for converting said time slices into a sequence of third representations of said sheet music, said CNN comprising an input layer and an output layer; * provide a first, encoder recurrent neural network (RNN) as an encoder on said sequence of third representations, for providing a hidden representation of said sheet music, said first RNN having an input layer that is functionally coupled to said output layer of said CNN, and an output layer; * provide a second, decoder recurrent neural network (RNN) as a decoder to said hidden representation, for converting said hidden representation into said machineprocessable representation, said second RNN having an input layer that is functionally coupled to said output layer of said first RNN, and an output for providing said machine-processable representation.","['G10H1/0058', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G10G1/04', 'G10H2210/066', 'G10H2210/076', 'G10H2210/081', 'G10H2210/086', 'G10H2220/015', 'G10H2220/451', 'G10H2240/311', 'G10H2250/311']"
TWI853134B,Deep learning based selection of samples for adaptive supersampling,"An apparatus to facilitate deep learning based selection of samples for adaptive supersampling is disclosed. The apparatus includes one or more processing elements to: receive training data comprising input tiles and corresponding supersampling values for the input tiles, wherein each input tile comprises a plurality of pixels, and train, based on the training data, a machine learning model to identify a level of supersampling for a rendered tile of pixels.","['G06T5/70', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N5/02', 'G06T1/20', 'G06T1/60', 'G06T11/40', 'G06T15/00', 'G06T15/005', 'G06T15/06', 'G06T2207/20081', 'G06T2207/20084']"
US20230076807A1,"Compositions, methods and systems for protein corona analysis and uses thereof","This disclosure provides methods and compositions for biomolecule corona analysis of biofluids. A biofluid may be contacted with a nanoparticle to form a biomolecule corona, and the composition of the resulting corona may be analyzed. Also provided are methods of preparing a biofluid for corona analysis by serial interrogation.","['G01N33/54346', 'G01N33/6848']"
US20240005590A1,Deformable neural radiance fields,"Techniques of image synthesis using a neural radiance field (NeRF) includes generating a deformation model of movement experienced by a subject in a non-rigidly deforming scene. For example, when an image synthesis system uses NeRFs, the system takes as input multiple poses of subjects for training data. In contrast to conventional NeRFs, the technical solution first expresses the positions of the subjects from various perspectives in an observation frame. The technical solution then involves deriving a deformation model, i.e., a mapping between the observation frame and a canonical frame in which the subject's movements are taken into account. This mapping is accomplished using latent deformation codes for each pose that are determined using a multilayer perceptron (MLP). A NeRF is then derived from positions and casted ray directions in the canonical frame using another MLP. New poses for the subject may then be derived using the NeRF.","['G06T15/205', 'G06T15/506', 'G06T15/20', 'G06T15/04', 'G06T15/55', 'G06T2207/20084']"
US12323240B2,Radio access network configuration for video approximate semantic communications,"An apparatuses for radio access network configuration for video approximate semantic communications includes a transceiver that receives from a transmitter a bitstream corresponding to a video coded data transmission wherein the received bitstream includes bitwise transmission errors and a processor that performs FEC decoding and correcting at least one bitwise transmission error of the video coded data transmission whereas at least one bitwise transmission error is left in a bit-inexact reception of the video coded data transmissions post FEC decoding, applies, by a smart video decoder in a video approximate semantic communications mode, semantic error correction to decoded video coded data transmissions to correct and conceal one or more video artifacts in response to the bit-inexact reception of the video coded data transmissions post FEC decoding, and reconstructs a video uncoded representation of concealed approximate semantic content relative to the received bitstream corresponding to the video coded data transmission.","['H04N19/44', 'H04L1/0056', 'H04L1/0041', 'H04L1/1671', 'H04N19/86', 'H04N19/89', 'H04N19/895', 'H04L1/1822', 'H04L1/1848']"
US10645366B2,Real time re-calibration of stereo cameras,"Described are image and video processing systems and methods for auto re-calibration of stereo camera devices. The auto re-calibration processes described herein transform image data into re-calibration data used to correct calibration errors in real time. The auto re-calibration processes leverage position data shifting, image data filtering, and disparity analysis to generate one or more calibration profiles that track the position of the camera modules included in stereo camera devices. Calibration profiles are then used to generate pixel shift parameters describing how to modify the position of image pixels and or camera modules to improve rectification and projection of 3D images and video frames. Additionally multi-camera systems implementing the auto re-calibration processes are disclosed.","['H04N13/246', 'G06T7/85', 'H04N13/111', 'H04N13/117', 'H04N13/122', 'H04N13/178', 'H04N13/189', 'H04N13/239', 'H04N13/296', 'H04N23/683', 'H04N23/698', 'H04N5/23238', 'H04N5/23267', 'H04N5/772', 'H04N5/907', 'H04N9/8205', 'H04N9/8227', 'H04N9/8715', 'H04N2013/0081']"
US20220104884A1,Image-Guided Surgery System,"An image-guided surgical system includes a processor, a display communicatively coupled to the processor, and an imaging system communicatively coupled to the processor. A memory device, communicatively coupled to the processor, stores instructions, executable by the processor, to cause the processor to receive, from the imaging system, real-time image data of an ophthalmological surgical field during an ophthalmological surgical procedure, and analyze the image data in real-time to identify an ocular tissue boundary present in the image data of the ophthalmological surgical field. The instructions cause the processor to provide real-time visual, auditory, and/or haptic feedback in response to the identified ocular tissue boundary.","['A61F9/00736', 'A61B1/000094', 'A61B1/000095', 'A61B1/000096', 'A61B34/20', 'A61B34/25', 'A61B34/72', 'A61B34/76', 'A61B90/20', 'G06T7/11', 'G06T7/12', 'A61B2017/00115', 'A61B2017/00119', 'A61B2034/2065', 'A61B2090/061', 'A61B2090/365', 'A61B2090/3735', 'A61B2090/502', 'A61B90/03', 'A61F9/007', 'G06T2207/10021', 'G06T2207/10101', 'G06T2207/20132', 'G06T2207/30041', 'G06T2210/41']"
US12165056B2,Auxiliary model for predicting new model parameters,"A computer-implemented method of training an auxiliary machine learning model to predict a set of new parameters of a primary machine learning model, wherein the primary model is configured to transform from an observed subset of a set of real-world features to a predicted version of the set of real-world features.","['G06N3/08', 'G06N3/045', 'G06N3/047']"
US11443416B2,Techniques for image content extraction,"Various embodiments are generally directed to techniques for image content extraction. Some embodiments include extracting contextually structured data from document images, such as by automatically identifying document layout, document data, document metadata, and/or correlations therebetween in a document image, for instance. Several embodiments include extracting contextually structured data from table images, such as gridded and non-gridded tables. For example, the contents of cells may be extracted from a table image along with structural context including the corresponding row and column information. Many embodiments are directed to generating and utilizing a document template database for automatically extracting document image contents into a contextually structured format. Several embodiments are directed to automatically identifying and associating document metadata with corresponding document data in a document image to generate a machine-facilitated annotation of the document image. In some embodiments, the machine-facilitated annotation may be used to generate a template for the template database.","['G06F16/93', 'G06F16/5854', 'G06F16/81', 'G06F3/04842', 'G06F40/169', 'G06F40/177', 'G06F40/186', 'G06F40/216', 'G06F40/284', 'G06T7/0002', 'G06V10/40', 'G06V10/95', 'G06V30/412', 'G06F18/24147', 'G06F18/40', 'G06K9/6253', 'G06K9/6276', 'G06T2207/30168', 'G06T2207/30176', 'G06V30/10', 'G06V30/248', 'G06V30/418']"
US11756561B2,Speech coding using content latent embedding vectors and speaker latent embedding vectors,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating discrete latent representations of input audio data. Only the discrete latent representation needs to be transmitted from an encoder system to a decoder system in order for the decoder system to be able to effectively to decode, i.e., reconstruct, the input audio data.","['G10L19/16', 'G10L25/30', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10L19/00', 'G10L19/032', 'G10L2019/0001']"
WO2018171596A1,"Video encoding method, video decoding method, and related device","Embodiments of the present invention disclose a video encoding method, a video decoding method, and a related device, for improving the compression efficiency of video frames. The method in the embodiments of the present invention comprises: acquiring a plurality of video frames, wherein redundant image content data exists between each of the plurality of video frames; reconstructing the plurality of video frames to obtain scene information and a reconstruction residual of each video frame, the scene information comprising data obtained by reducing the redundancy of the redundant data, and the reconstruction residual being used to represent a difference between the video frame and the scene information; and performing predictive encoding on the scene information and reconstruction residuals respectively to obtain scene feature predictive encoding data and residual predictive encoding data. In this way, a redundancy between video frames is reduced, and a volume of data obtained after compression is reduced. Furthermore, each video frame is reconstructed into scene features and a reconstruction residual. Reconstruction residuals are encoded based on residual encoding, producing a small volume of encoded data and a high compression ratio. In this way, the method of the embodiments of the present invention can effectively improve the compression efficiency of video frames.","['H04N19/503', 'H04N19/124', 'H04N19/179', 'H04N19/593', 'H04N19/61', 'H04N19/625', 'H04N19/85']"
US20240013462A1,Audio-driven facial animation with emotion support using machine learning,"A deep neural network can be trained to output motion or deformation information for a character that is representative of the character uttering speech contained in audio input, which is accurate for an emotional state of the character. The character can have different facial components or regions (e.g., head, skin, eyes, tongue) modeled separately, such that the network can output motion or deformation information for each of these different facial components. During training, the network can be provided with emotion and/or style vectors that indicate information to be used in generating realistic animation for input speech, as may relate to one or more emotions to be exhibited by the character, a relative weighting of those emotions, and any style or adjustments to be made to how the character expresses that emotional state. The network output can be provided to a renderer to generate audio-driven facial animation that is emotion-accurate.","['G10L21/10', 'G06T13/205', 'G06T13/40', 'G06T17/20', 'G10L15/16', 'G10L25/63', 'G10L2021/105']"
TWI748035B,Display system and electronic device,"A novel semiconductor device or display system is provided. The display system includes a correction circuit having a function of correcting an image signal by utilizing artificial intelligence. Specifically, learning by an artificial neural network enables the correction circuit to correct an image signal so as to alleviate the image discontinuity. Then, by making an inference (recognition) utilizing the artificial neural network which has finished the learning, the image signal is corrected and compensation for the image discontinuity can be made. In this manner, the junction can be inconspicuous on the displayed image, improving the quality of a high-resolution image.","['G09G5/14', 'G06N3/063', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'G09G3/2092', 'H10D86/40', 'H10D86/423', 'H10D86/60', 'G09G2320/02', 'G09G3/20', 'G09G3/22', 'G09G3/3233', 'G09G3/36', 'G09G3/3688']"
US20250016593A1,Methods and apparatuses for multi-resolution csi feedback for wireless systems,"Procedures, methods, architectures, apparatuses, systems, devices, and computer program products includes measuring Channel State Information (CSI) associated with at least one reference signal and determining a trained Artificial Intelligence (AI) model to generate at least a portion of a report that includes the CSI associated with the at least one reference signal. The report comprising the CSI associated with the at least one reference signal is transmitted.","['H04B7/0621', 'H04W24/10', 'G06N3/0455', 'G06N3/084', 'G06N3/088', 'G06N3/092', 'H04B7/0456', 'H04B7/0626', 'H04L25/0254', 'H04L5/005']"
US12093545B2,Storage system with selectable write modes,"A storage system has a first memory, a second memory that include solid-state storage memory, and a processing device. The processing device is to select a mode for each portion of data to be written. Selection of the mode is based at least on size of the portion of data. Selection of the mode is from among modes that include a first mode of writing the portion of data in mirrored RAID form to the first memory for later transfer from the first memory to the second memory, a second mode of writing the portion of data in parity-based RAID form to the first memory for later transfer from the first memory to the second memory, and a third mode of writing the portion of data to the second memory, bypassing the first memory. The processing device is to handle portions of data to be written according to such selection.","['G06F3/0656', 'G06F3/0634', 'G06F3/061', 'G06F3/0614', 'G06F3/0644', 'G06F3/0679', 'G06F3/0689']"
US20180365556A1,System and method for generating and using descriptors of artificial neural networks,"Systems and methods for generating and using descriptors of artificial neural networks are provided. For example, an artificial neural network may be obtained, the artificial neural network may be obtained, descriptors of the segments may be calculated, and a descriptor of the artificial neural network may be compiled. In some examples, a match score for a pair of artificial neural networks may be calculated (for example using the descriptors compiled for the two artificial neural networks), and actions may be selected based on the matching score.","['G06N3/0454', 'G06N20/00', 'G06F16/2379', 'G06F16/24565', 'G06F18/214', 'G06F18/217', 'G06F21/6218', 'G06F7/14', 'G06F9/505', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N5/022', 'G06N5/04', 'G06N5/046', 'G06N7/01', 'G06Q10/06311', 'H04L63/102', 'G06F16/285', 'G06K9/6262', 'G06N20/10', 'G06N3/044', 'G06N3/048', 'G06N3/082', 'H04L63/0823', 'H04N23/661']"
CN111988609B,"Image encoding device, probability model generating device, and image decoding device","The embodiment of the application provides an image encoding device, a probability model generating device and an image decoding device, wherein the image encoding device comprises: the first feature extraction unit is used for extracting features of the input image to obtain feature graphs of N channels; the second feature extraction unit is used for carrying out feature extraction on the input image with the adjusted K times of size to respectively obtain feature graphs of N channels; and a first connection unit that connects and outputs the feature maps of the N channels from the first feature extraction unit and the feature maps of the k×n channels from the second feature extraction unit. Thus, features of the image can be accurately extracted and a more competitive potential representation obtained.","['H04N19/91', 'G06F17/15', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'H04N19/13', 'H04N19/136', 'H04N19/172', 'H04N19/42', 'H04N19/44', 'G06T9/002']"
US20200167869A1,Real-time predictive analytics engine,"A computerized end-to-end platform configured to receive and process financial market data in real-time, the end-to-end platform comprising: a computer system, the computer system comprising a host processor and host memory; a price analytics engine configured to minimize credit pricing risk and enabling systematic monitoring of credit pricing in a plurality of currencies; a predictive issuance analytics engine configured to systematically identify at least one fixed income market opportunity, wherein the at least one fixed income market opportunity comprises at least one financial instrument, and to provide pre-issuance insights into the fixed income market, and a matching and discovery engine configured to match at least one target institutional buyer with the fixed income market opportunity using a classifier trained on historical and contemporaneous data.","['G06Q40/06', 'G06F18/214', 'G06K9/6256', 'G06Q30/0201', 'G06Q30/0206']"
US9209782B2,"Signal decomposition, analysis and reconstruction","The present invention provides a system and method for representing quasi-periodic (“qp”) waveforms comprising, representing a plurality of limited decompositions of the qp waveform, wherein each decomposition includes a first and second amplitude value and at least one time value. In some embodiments, each of the decompositions is phase adjusted such that the arithmetic sum of the plurality of limited decompositions reconstructs the qp waveform. These decompositions are stored into a data structure having a plurality of attributes. Optionally, these attributes are used to reconstruct the qp waveform, or patterns or features of the qp wave can be determined by using various pattern-recognition techniques. Some embodiments provide a system that uses software, embedded hardware or firmware to carry out the above-described method. Some embodiments use a computer-readable medium to store the data structure and/or instructions to execute the method.","['H03H17/0201', 'G06F18/00', 'A61B5/0006', 'A61B5/339', 'A61B5/347', 'G06K9/00523', 'G06F2218/08']"
CN111770706B,A bed with a snore detection feature,"The first bed includes a first mattress, a first pressure sensor, a first acoustic sensor, and a first controller in data communication with the first pressure sensor and the first acoustic sensor. The first controller is configured to receive a first pressure reading and a first acoustic reading. The first controller is also configured to transmit the first pressure reading and the first acoustic reading to a remote server. The second controller is configured to receive one or more snore classifiers. The second controller is further configured to run the received snore classifier at the second pressure reading and at the second sound reading to collect one or more snore votes from the running snore classifier. The second controller is further configured to determine a snoring status of the user on the second bed and operate the bed system according to the determined snoring status.","['A61G7/018', 'A47C21/003', 'A47C27/082', 'A47C27/084', 'A47C27/10', 'A61B5/0004', 'A61B5/4806', 'A61B5/4809', 'A61B5/4812', 'A61F5/56', 'A61G7/015', 'G06N20/00', 'A47C27/083', 'A47C31/008', 'A61B5/11', 'A61B5/4818', 'A61B5/6892', 'A61B5/7267', 'A61G7/05769']"
US12051439B2,Method and system for learning and using latent-space representations of audio signals for audio content-based retrieval,"A method and system are provided for extracting features from digital audio signals which exhibit variations in pitch, timbre, decay, reverberation, and other psychoacoustic attributes and learning, from the extracted features, an artificial neural network model for generating contextual latent-space representations of digital audio signals. A method and system are also provided for learning an artificial neural network model for generating consistent latent-space representations of digital audio signals in which the generated latent-space representations are comparable for the purposes of determining psychoacoustic similarity between digital audio signals. A method and system are also provided for extracting features from digital audio signals and learning, from the extracted features, an artificial neural network model for generating latent-space representations of digital audio signals which take care of selecting salient attributes of the signals that represent psychoacoustic differences between the signals.","['G10H1/0025', 'G06F16/65', 'G06F18/214', 'G06F3/165', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10L21/12', 'G10L21/14', 'G10L25/30', 'G10L25/54', 'G10H2210/031', 'G10H2210/061', 'G10H2210/076', 'G10H2240/131', 'G10H2250/215', 'G10H2250/311']"
US11645745B2,System and method for adverse event detection or severity estimation from surgical data,"Embodiments described herein may provide devices, systems, methods, and/or computer readable medium for adverse event detection and severity estimation in surgical videos. The system can train multiple models for adverse detection and severity estimation. The system can load selected models for real-time adverse event detection and severity estimation.","['G06T7/0012', 'G06K9/6268', 'G06F18/241', 'G06F18/24133', 'G06K9/6271', 'G06N20/10', 'G06N3/045', 'G06N3/0481', 'G06N3/084', 'G06T3/0093', 'G06T3/18', 'G06V10/70', 'G06V10/764', 'G06V10/82', 'G06V20/44', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084']"
US11043307B2,"Cognitive collaboration with neurosynaptic imaging networks, augmented medical intelligence and cybernetic workflow streams","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with cognitive collaboration, augmented medical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal cognitive communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms. It provides for both synchronous and asynchronous cognitive collaboration with multichannel, multiplexed imagery data streams during various stages of medical disease and injury management—detection, diagnosis, prognosis, treatment, measurement, monitoring and reporting, as well as workflow optimization with operational analytics for outcomes, performance, results, resource utilization, resource consumption and costs. The invention enables cognitive curation, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized medical intelligence.","['G06Q10/0633', 'G16H80/00', 'A61B34/30', 'G06F40/169', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16H30/20', 'G16H50/20', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/15', 'H04N7/152', 'H04L12/1813', 'H04M3/567']"
US11087077B2,Techniques for extracting contextually structured data from document images,"Embodiments are generally directed to techniques for extracting contextually structured data from document images, such as by automatically identifying document layout, document data, and/or document metadata in a document image, for instance. Many embodiments are particularly directed to generating and utilizing a document template database for automatically extracting document image contents into a contextually structured format. For example, the document template database may include a plurality of templates for identifying/explaining key data elements in various document image formats that can be used to extract contextually structured data from incoming document images with a matching document image format. Several embodiments are particularly directed to automatically identifying and associating document metadata with corresponding document data in a document image, such as for generating a machine-facilitated annotation of the document image. In some embodiments, the machine-facilitated annotation of a document may be used to generate a template for the template database.","['G06F16/93', 'G06F16/81', 'G06F3/04842', 'G06F40/169', 'G06F40/186', 'G06F40/284', 'G06K9/46', 'G06T7/0002', 'G06V10/95', 'G06V30/412', 'G06F18/24147', 'G06F18/40', 'G06K2209/01', 'G06T2207/30168', 'G06T2207/30176', 'G06V30/248', 'G06V30/418']"
US11899748B2,"System, method, and apparatus for a neural network model for a vehicle","A computing system comprises a data storage and at least one processor communicatively coupled to the data storage. The at least one processor is configured to execute program instructions to cause the system to perform the following steps. A deep neural network (“DNN”) model is trained using training data. Next, additional scenes are determined based on the DNN model and the training data. The determined scenes are generated, and then used to augment the training dataset. The DNN model is then retrained using the augmented training dataset and stored in a data storage for deployment.","['G05D1/0088', 'G05D1/024', 'G05D1/228', 'G05D1/247', 'G05D1/249', 'G06F18/214', 'G06N3/08', 'G06T7/11', 'G06V20/58', 'H04W36/14', 'G06F2216/03', 'G06T2210/12']"
US11569863B2,Acoustic sensing nodes and related systems and methods,"In an example, a system includes a plurality of acoustically coupled nodes. Each of the nodes includes a transducer, a communication circuit and a controller. The transducer is adapted to be mechanically coupled to a medium. The communication circuit is coupled to the transducer to send and receive acoustic signals via the medium according to at least one communication parameter. The controller is to adaptively configure the at least one communication parameter of the communication circuit based on an acoustic signal received from at least one other of the nodes.","['G01M5/0033', 'H04B1/40', 'G01M5/0066']"
US12335796B2,Device and method for performing handover in wireless communication system,"The present disclosure relates to a communication technique for fusing, with an IoT technology, a 5G communication system for supporting a higher a data transmission rate than a 4G system, and a system therefor. According to various embodiments of the present disclosure, a method performed by a base station of a serving cell in a wireless communication system may comprise the steps of: transmitting configuration information for an artificial intelligence (AI)-based handover to a terminal; receiving, from the terminal, a handover request to a target cell according to the AI-based handover; and transmitting, to the terminal, a configuration message for access to the target cell, in response to the handover request, wherein the target cell is identified on the basis of a neural network (NN) configured for the AI-based handover and a measurement result of the terminal.","['H04W36/008375', 'H04W36/26', 'H04W36/0058', 'H04W36/0061', 'H04W36/0064', 'H04W36/0085', 'H04W36/00835', 'H04W36/08', 'H04W36/302']"
CN114694220B,Double-flow face counterfeiting detection method based on Swin Transformer,"The invention relates to a double-flow face fake detection method based on a Swin Transformer, which utilizes deep learning to detect a face fake image. A deep learning network model is integrally built, and the network model is divided into three parts: a dual stream network, a feature extraction network, and a classifier. Since the presently disclosed face-counterfeit data sets are all video, the video needs to be cropped into a frame picture using OpenCV. In addition, since the frame picture contains a lot of background information, a face region needs to be cut out by using a face positioning algorithm. And then inputting the obtained face region image into a double-flow network and a feature extraction network to extract and learn features. And finally, inputting the learned characteristics into a classifier to identify the true and false of the face image. The invention is applied to solve the problem of weak generalization capability, which is a part of limitations of the existing face counterfeiting detection scheme, and simultaneously improves the compression resistance of the model through the double-flow framework, so that the model better accords with the common face video quality in daily life.","['G06F18/214', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
US11399063B2,Network authentication for a storage system,"A method of operating a storage system is provided. The method includes establishing a security context between a client and the storage system, the security context comprising a single ticket for multiple nodes within the storage system. The method includes distributing a first request to a first blade within the storage system and distributing a second request to a second blade within the storage system. The distributing the first request and the second request includes determining a node for handling the first request and the second request based on data within the single ticket.","['G06F13/4022', 'G06F11/1068', 'G06F11/1076', 'G06F11/108', 'G06F11/2092', 'G06F12/0246', 'G06F13/4282', 'G06F3/06', 'G06F3/0604', 'G06F3/061', 'G06F3/0611', 'G06F3/0613', 'G06F3/0622', 'G06F3/0635', 'G06F3/065', 'G06F3/0655', 'G06F3/0659', 'G06F3/067', 'G06F3/0685', 'G06F3/0688', 'G06F3/0689', 'G11C29/028', 'G11C29/52', 'H03M13/154', 'H04L12/40169', 'H04L49/10', 'H04L49/111', 'H04L67/1097', 'H04L67/16', 'H04L67/51', 'G06F2201/805', 'G06F2201/845', 'G06F2212/7206', 'G06F2212/7207', 'G11C2029/0409', 'G11C8/12', 'Y02D10/00']"
US20210133583A1,Distributed weight update for backpropagation of a neural network,"Speed of training a neural network is improved by updating the weights of the neural network in parallel. In at least one embodiment, after back propagation, gradients are distributed to a plurality of processors, each of which calculate a portion of the updated weights of the neural network.","['G06F9/505', 'G06N3/084', 'G01C21/3608', 'G06N3/04', 'G06N3/045', 'G06N3/063', 'G10L15/16', 'G10L15/22', 'G10L2015/223']"
US12348974B2,"System, method, and apparatus for providing optimized network resources","Systems, methods, and apparatuses for providing optimization of network resources. The system is operable to monitor the electromagnetic environment, analyze the electromagnetic environment, and extract environmental awareness of the electromagnetic environment. The system extracts the environmental awareness of the electromagnetic environment by including customer goals. The system is operable to use the environmental awareness with the customer goals and/or user defined policies and rules to extract actionable information to help the customer optimize the network resources.","['H04W16/10', 'H04W24/02', 'H04W24/08', 'H04W24/10', 'H04W28/24', 'H04W16/14', 'H04W24/04', 'H04W28/0268']"
US12328592B2,"System, method, and apparatus for providing optimized network resources","Systems, methods, and apparatuses for providing optimization of network resources. The system is operable to monitor the electromagnetic environment, analyze the electromagnetic environment, and extract environmental awareness of the electromagnetic environment. The system extracts the environmental awareness of the electromagnetic environment by including customer goals. The system is operable to use the environmental awareness with the customer goals and/or user defined policies and rules to extract actionable information to help the customer optimize the network resources.","['H04W16/10', 'H04W16/14', 'H04W24/02', 'H04W24/04', 'H04W24/08', 'H04W28/0925', 'H04W28/0967', 'H04W72/0453']"
US10997492B2,Automated methods for conversions to a lower precision data format,"Aspects of the present invention are directed to computer-implemented techniques for performing data compression and conversion between data formats of varying degrees of precision, and more particularly for improving the inferencing (application) of artificial neural networks using a reduced precision (e.g., INT8) data format. Embodiments of the present invention generate candidate conversions of data output, then employ a relative measure of quality to identify the candidate conversion with the greatest accuracy (i.e., least divergence from the original higher precision values). The representation can be then be used during inference to perform computations on the resulting output data.","['G06N3/04', 'H03M7/3059', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/049', 'G06N3/063', 'G06N3/10', 'G06N7/00', 'G06T9/002']"
US20220405582A1,Systems and methods for training neural networks with sparse data,"A method, computer readable medium, and system are disclosed for training a neural network model. The method includes the step of selecting an input vector from a set of training data that includes input vectors and sparse target vectors, where each sparse target vector includes target data corresponding to a subset of samples within an output vector of the neural network model. The method also includes the steps of processing the input vector by the neural network model to produce output data for the samples within the output vector and adjusting parameter values of the neural network model to reduce differences between the output vector and the sparse target vector for the subset of the samples.","['G06N3/08', 'G06N3/04', 'G06N3/063', 'G06N3/084', 'G06N5/04', 'G06T1/20', 'G06T1/60']"
WO2022012257A1,Communication method and communication apparatus,"The present application provides a communication method and a communication apparatus. The method may comprise: a first communication apparatus determines whether a first channel learning model is applicable, the first channel learning model being used for determining first channel information on the basis of target channel information, and the data amount of the first channel information being less than the data amount of the target channel information; and in the case that it is determined that the first channel learning model is not applicable, the first communication apparatus sends a first message, the first message being used for indicating that the first channel learning model is not applicable. According to the method provided in embodiments of the present application, the first communication apparatus can determine the applicability of the first channel learning model, without the assistance from a second communication apparatus, so that the interaction of signaling and the complexity of determining the applicability of the channel learning model can be reduced.","['H04B17/391', 'G06N20/00', 'G06N3/02', 'G06N3/04', 'G06N3/045', 'H04B17/382', 'H04B7/0413', 'H04B7/0417', 'H04B7/0456', 'H04L25/0202', 'H04L25/0254', 'H04W40/18', 'Y02D30/70']"
US10187568B1,Video smart phone,"A communication device includes a processor; a cellular transceiver coupled to the processor; an imager with multiple lens and multiple sensors therein to capture a 360 degree video; a plurality of graphic processing units to combine outputs from the sensors to form the 360 degree video, the processor and the graphic processing units operating to keep heat below a predetermined range; and a heat pipe coupled to the processor and the graphic processing units.","['H04N13/194', 'H04N5/23238', 'G06K9/00013', 'G06V20/10', 'H04M1/0264', 'H04M1/72412', 'H04M1/7253', 'H04N13/243', 'H04N13/257', 'H04N13/296', 'H04N23/57', 'H04N23/698', 'H04N23/90', 'H04N5/2257', 'H04M2250/52']"
US11676282B2,Enhanced semantic segmentation of images,"Enhanced methods and systems for the semantic segmentation of images are described. A refined segmentation mask for a specified object visually depicted in a source image is generated based on a coarse and/or raw segmentation mask. The refined segmentation mask is generated via a refinement process applied to the coarse segmentation mask. The refinement process correct at least a portion of both type I and type II errors, as well as refine boundaries of the specified object, associated with the coarse segmentation mask. Thus, the refined segmentation mask provides a more accurate segmentation of the object than the coarse segmentation mask. A segmentation refinement model is employed to generate the refined segmentation mask based on the coarse segmentation mask. That is, the segmentation model is employed to refine the coarse segmentation mask to generate more accurate segmentations of the object. The refinement process is an iterative refinement process carried out via a trained neural network.","['G06T7/11', 'G06N3/045', 'G06N3/084', 'G06T2207/10024', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US12197601B2,Hardware offload circuitry,"Examples described herein relate to offload circuitry comprising one or more compute engines that are configurable to perform a workload offloaded from a process executed by a processor based on a descriptor particular to the workload. In some examples, the offload circuitry is configurable to perform the workload, among multiple different workloads. In some examples, the multiple different workloads include one or more of: data transformation (DT) for data format conversion, Locality Sensitive Hashing (LSH) for neural network (NN), similarity search, sparse general matrix-matrix multiplication (SpGEMM) acceleration of hash based sparse matrix multiplication, data encode, data decode, or embedding lookup.","['G06F21/72', 'G06F21/62', 'G06F15/7807', 'G06F9/5027', 'G06F15/7821', 'G06F15/7889', 'G06F2209/509']"
US11734097B1,Machine learning-based hardware component monitoring,"An illustrative method includes identifying, based on an output of a machine learning model that receives data associated with an operation of a hardware component as an input, an anomaly in the data, determining that the anomaly is representative of an issue associated with the hardware component, and performing, based on the determining that the anomaly is representative of the issue associated with the hardware component, a remedial action that affects a performance of the operation of the hardware component.","['G06F11/079', 'G06F21/554', 'G06F11/0709', 'G06F11/0793', 'G06F11/3409', 'G06F11/3476', 'G06F21/566', 'G06F21/64', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06F2201/81', 'G06F2201/86', 'Y02D10/00']"
US12210829B2,"Entity recognition method, apparatus, electronic device and computer readable storage medium","An entity recognition method, apparatus, electronic device, and computer-readable storage medium are provided. The method includes: determining at least one entity boundary word corresponding to a text sequence; determining at least one entity candidate region in the text sequence based on the at least one entity boundary word; and performing entity recognition on the text sequence and identifying at least one entity in the text sequence based on the at least one entity candidate region.","['G06V30/416', 'G06F40/295', 'G06F16/35', 'G06F16/367', 'G06F40/205']"
CN112101190B,"A remote sensing image classification method, storage medium and computing device","The application discloses a remote sensing image classification method, a storage medium and a computing device, wherein a remote sensing image set is created, and standardized processing is carried out on the remote sensing image set to obtain a training sample set and a test sample set; setting a multi-scale feature extraction module, and generating a feature map of two scales by setting different cavity convolutions in two parallel convolution modules; an adaptive feature fusion module is arranged, and can adaptively select and fuse useful information in two generated features with different scales; building a whole neural network model; performing iterative training on the whole neural network model by using a training sample set; randomly selecting samples from the test samples as position category samples, and classifying unknown samples to be predicted by using a trained neural network. The method reduces redundant information, more flexibly selects multi-scale characteristics, improves the stability of the network, and further improves the classification capacity of the network model.","['G06V20/13', 'G06F18/2415', 'G06N3/045', 'G06N3/08', 'G06V10/464', 'Y02D10/00']"
US11069345B2,Speech recognition using convolutional neural networks,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for performing speech recognition by generating a neural network output from an audio data input sequence, where the neural network output characterizes words spoken in the audio data input sequence. One of the methods includes, for each of the audio data inputs, providing a current audio data input sequence that comprises the audio data input and the audio data inputs preceding the audio data input in the audio data input sequence to a convolutional subnetwork comprising a plurality of dilated convolutional neural network layers, wherein the convolutional subnetwork is configured to, for each of the plurality of audio data inputs: receive the current audio data input sequence for the audio data input, and process the current audio data input sequence to generate an alternative representation for the audio data input.","['G06N3/0464', 'G10L15/16', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G10L13/00', 'G10L15/02', 'G10L15/22', 'G10H2250/311', 'G10L2015/025']"
US11031135B2,Determination of cybersecurity recommendations,"A method and apparatus can include a system controller and a system processor. The system controller can retrieve a cybersecurity dataset from at least one database, the retrieved dataset including information associated with at least one element associated with at least one of network traffic and process monitoring of at least one process being implemented in at least one network element. The system processor can utilize multidimensional nonlinear manifold clustering on the at least one element of the retrieved cybersecurity dataset, assign a threat entity formulated from the at least one element of the retrieved dataset into a cybersecurity threat hyper-volume based on the multidimensional nonlinear manifold clustering, and formulate a recommended action to be taken based on the assignment of the threat entity into the cybersecurity threat hyper-volume.","['G16H50/20', 'G06F21/6245', 'G06N20/00', 'G06N3/042', 'G06N3/0427', 'G06N3/08', 'G06N3/088', 'G06N7/01', 'G16H20/10', 'G16H20/40', 'G16H20/70', 'G16H50/70', 'G16H70/00', 'H04L63/0407', 'H04L63/1433', 'H04L63/1441', 'H04L63/0428', 'Y02A90/10']"
US20240185074A1,Importance-aware model pruning and re-training for efficient convolutional neural networks,"Systems, apparatuses and methods may provide for conducting an importance measurement of a plurality of parameters in a trained neural network and setting a subset of the plurality of parameters to zero based on the importance measurement. Additionally, the pruned neural network may be re-trained. In one example, conducting the importance measurement includes comparing two or more parameter values that contain covariance matrix information.","['G06N3/082', 'G06F18/241', 'G06N3/045', 'G06V10/764', 'G06V10/82']"
US20240135259A1,Computer implemented method for generating a 3d object,"There is provided a method for a computer implemented method for generating a 3D object. The method comprises training a machine learning system to learn design parameter values that give rise to an optimally performing version of the 3D object; and processing, using the machine learning system, input data relating to the 3D object, in an unsupervised manner such that it can be used for generative purposes, such as the creation of novel geometries or other parameters of the 3D object.","['G06F30/17', 'G06N20/00', 'G06F30/27', 'G06F30/20']"
US11816609B2,Intelligent task completion detection at a computing device,"Computerized systems and methods are provided for automatically detecting an indication that a task has been completed and associated user interface functionality. These systems and methods improve existing technologies by automatically detecting indications that tasks have been completed via new logic or rules and improving the functionality and computing resource consumption relative to existing machine learning models. These systems also improve the way computers operate by reducing computing resource consumption, such as memory, network latency, I/O, and the like.","['G06F40/284', 'G06Q10/063114', 'G06F3/0482', 'G06F40/289', 'G06F40/30', 'G06N20/00', 'G06Q10/1097', 'H04L51/046']"
US20190049540A1,Image standardization using generative adversarial networks,Systems and methods are provided for synthesizing protocol independent magnetic resonance images. A patient is scanned by a magnetic resonance imaging system to acquire magnetic resonance data. The magnetic resonance data is input to a machine learnt generator network trained to extract features from input magnetic resonance data and synthesize protocol independent images using the extracted features. The machine learnt generator network generates a protocol independent segmented magnetic resonance image from the input magnetic resonance data. The protocol independent magnetic resonance image is displayed.,"['G01R33/5608', 'G01R33/543', 'G06N3/045', 'G06N3/047', 'G06N3/084']"
US20210061028A1,"Apparatus and method for vehicular monitoring, analysis, and control",A vehicle tire inflation system includes a central gas supply system configured for distribution of inflation gas to a vehicle tire and a distributed gas supply system configured for compressing gas and supplying the compressed gas to a vehicle tire.,"['B60C23/002', 'B60C23/00327', 'B60C23/00372', 'B60C23/009', 'B60C23/041', 'B60C23/0498', 'B60C23/127', 'B60C23/131', 'B60C23/16', 'B60R16/0307', 'G06N20/00']"
US20210061027A1,"Apparatus and method for vehicular monitoring, analysis, and control",A vehicle tire inflation system includes a vehicle-based compressed gas source for tire inflation and a controller configured to dynamically control the supply of compressed gas to a vehicle tire.,"['B60C23/002', 'B60C23/0498', 'B60C23/009', 'B60C23/041', 'B60C23/127', 'B60C23/131', 'B60C23/16', 'B60R16/0307', 'G06N20/00']"
US7648164B2,Airbag deployment control based on deployment conditions,"Method for controlling flow of gas into an airbag includes generating gas, directing the gas into the airbag, and controlling the flow of gas into the airbag based on conditions at the time of deployment such that the airbag is variably deployed dependent on ambient conditions. A related arrangement for controlling flow of gas into an airbag includes a system for generating gas, a system for directing the gas into the airbag and a system for controlling the flow of gas into the airbag based on conditions at the time of deployment such that the airbag is variably deployed dependent on ambient conditions.","['B60R21/20', 'B60N2/02246', 'B60N2/0272', 'B60N2/0276', 'B60N2/2863', 'B60R21/206', 'B60R21/214', 'B60R21/232', 'B60R21/233', 'B60R21/235', 'B60R21/264', 'B60R21/30', 'G07C5/008', 'G07C5/0808', 'B60R2021/0004', 'B60R2021/0006', 'B60R2021/23107', 'B60R2021/23153', 'B60R2021/23161', 'B60R2021/23169', 'B60R2021/23192', 'B60R2021/23308', 'B60R2021/23316', 'B60R2021/23504', 'B60R2021/23514', 'B60R2021/23519', 'B60R2021/23523', 'B60R2021/23557', 'B60R2021/2358', 'B60R2021/2359', 'B60R2021/2636', 'B60R21/2032', 'B60R21/239']"
US10436488B2,Method and apparatus for optimizing refrigeration systems,"A control system for controlling a refrigeration system having an operating point, comprising: a memory configured to store a relationship of at least an evaporator efficiency, an evaporator heat load, a refrigerant amount in the evaporator, and a variable dependent on a non-volatile liquid mixed with refrigerant in the evaporator an input port configured to receive a signal corresponding to at least a measured evaporator heat load during operation; an output port configured to present an output to selectively alter an operating point of the evaporator, by altering the refrigerant amount in the evaporator and thereby changing the variable; and a processor, configured to receive the signal, access the memory; and generate the output to selectively move toward an optimum operating point. A corresponding method and refrigeration system are provided.","['F25B49/02', 'F25B43/02', 'F25B45/00', 'G01N25/18', 'G06F17/5009', 'G06F17/5068', 'G06F30/20', 'G06F30/27', 'G06F30/39', 'F25B2500/16', 'F25B2500/19', 'F25B2600/05', 'G06F2119/18', 'G06F2217/12', 'Y02P90/02', 'Y02P90/265']"
US10884957B2,Pipeline circuit architecture to provide in-memory computation functionality,"Techniques and mechanisms for performing in-memory computations with circuitry having a pipeline architecture. In an embodiment, various stages of a pipeline each include a respective input interface and a respective output interface, distinct from said input interface, to couple to different respective circuitry. These stages each further include a respective array of memory cells and circuitry to perform operations based on data stored by said array. A result of one such in-memory computation may be communicated from one pipeline stage to a respective next pipeline stage for use in further in-memory computations. Control circuitry, interconnect circuitry, configuration circuitry or other logic of the pipeline precludes operation of the pipeline as a monolithic, general-purpose memory device. In other embodiments, stages of the pipeline each provide a different respective layer of a neural network.","['G06F13/1668', 'G06F13/28', 'G06N3/063', 'G06N20/00', 'Y02D10/00']"
US11490092B2,Event-based adaptation of coding parameters for video image encoding,"The present disclosure relates to encoding of video image using coding parameters, which are adapted based on events related to motion within the video image. Image content is captured by a standard image sensor and an event-triggered sensor, providing an event-signal indicating changes (e.g. amount and time-spatial location) of image intensity. Objects are detected within the video image, based on the event signal assessing motion of the object, and their textures extracted. The spatial-time coding parameters of the video image are determined based on the location and strength of the event signal, and the extent to which the detected objects moves.","['H04N19/132', 'H04N19/137', 'H04N19/124', 'H04N19/167', 'H04N19/17', 'H04N19/176', 'H04N25/47', 'H04N7/0127', 'H04N19/31', 'H04N19/33', 'H04N25/00', 'H04N5/335']"
US11045271B1,Robotic medical system,"A system includes a camera; an AI visual processor to classify and recognize human anatomical features, and a processor to control robot movement to reach a selected anatomical target.","['G16H40/67', 'A61B34/70', 'A61B18/1492', 'A61B34/30', 'A61B34/32', 'A61B34/37', 'A61B90/361', 'G06N20/00', 'G06N3/045', 'G16H20/40', 'G16H40/63', 'G16H50/20', 'G16H50/80', 'A61B2018/00351', 'A61B2018/00482', 'A61B2018/00577', 'A61B2018/126', 'A61B2018/143', 'A61B2034/2065', 'A61B2034/301', 'A61B2034/302', 'A61B2034/303', 'A61B2090/306', 'A61B2090/3612', 'A61B2090/3614', 'A61B2090/365', 'A61B2090/3735', 'A61B2090/378', 'G06N3/008', 'G06N3/047', 'G06N3/08', 'G06N5/022']"
US10740617B2,Protection and recovery of identities in surveillance camera environments,"A mechanism is described for facilitating protection and recovery of identities in surveillance camera environments according to one embodiment. An apparatus of embodiments, as described herein, includes detection and reception logic to receive a video stream of a scene as captured by a camera, wherein the scene includes persons. The apparatus may further include recognition and application logic to recognize an abnormal activity and one or more persons associated with the abnormal activity in a video frame of the video stream. The apparatus may further include identity recovery logic to recover one or more identities of the one or more persons in response to the abnormal activity, where the one or more identities are recovered from masked data and encrypted residuals associated with the one or more persons.","['H04N7/183', 'G06V20/40', 'G06K9/00711', 'G06K9/00288', 'G06K9/00302', 'G06K9/00335', 'G06K9/00362', 'G06K9/00771', 'G06V20/52', 'G06V40/10', 'G06V40/172', 'G06V40/174', 'G06V40/20', 'G06K2009/00738', 'G06V20/44']"
US20200233397A1,"System, method and computer-accessible medium for machine condition monitoring",A system for monitoring a condition of a machine includes an acoustic detector configured to capture an audio signal of the machine. A controller is communicatively coupled to the audio detector and configured to transmit the audio signal to a remote computing unit. The remote computing unit configured to generate a condition status signal based on at least one of an unsupervised machine learning process or a supervised machine learning process. The controller is configured to receive the condition status signal from the remote computing unit and communicate a condition status based on the received condition status signal.,"['G05B19/4184', 'G05B19/4065', 'G05B19/408', 'G05B23/024', 'G06F18/214', 'G06K9/6256', 'G06N3/045', 'G05B19/406', 'G05B2219/37269', 'G05B2219/37337', 'G05B2219/37433', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N7/01', 'Y02P90/02']"
US9047568B1,Apparatus and methods for encoding of sensory data using artificial spiking neurons,"Sensory encoder may be implemented. Visual encoder apparatus may comprise spiking neuron network configured to receive photodetector input. Excitability of neurons may be adjusted and output spike may be generated based on the input. When neurons generate spiking response, spiking threshold may be dynamically adapted to produce desired output rate. The encoder may dynamically adapt its input range to match statistics of the input and to produce output spikes at an appropriate rate and/or latency. Adaptive input range adjustment and/or spiking threshold adjustment collaborate to enable recognition of features in sensory input of varying dynamic range.","['G06N3/0472', 'G06N3/049', 'G06N3/047']"
US8488916B2,Knowledge acquisition nexus for facilitating concept capture and promoting time on task,"Described herein is an interactive digital software program and hardware that enables rapid acquisition of textual or audio subject matter, its conversion to editable text and immediate compression into a user understandable summary. The software program maximizes “time on task” while minimizing the time-consuming steps of “concept capture” and “compression”. The instant invention provides an accurate condensate of textual subject matter in a fraction of the time it would take to prepare such a document by manual note taking. In a single step, mobile devices such as cameras, camera phones, tablets, iPODs™, scanners and the like rapidly capture textual images convert them to OCR and to a user understandable summary in a fraction of the time it takes to process such a document by manual note taking. With more study time available for repetitious practice of the lesson, the user improves preparedness and performance on tests and presentations.","['G09B5/08', 'G06F40/211']"
US11715210B2,Method for generating a 3D physical model of a patient specific anatomic feature from 2D medical images,There is provided a method for generating a 3D physical model of a patient specific anatomic feature from 2D medical images. The 2D medical images are uploaded by an end-user via a Web Application and sent to a server. The server processes the 2D medical images and automatically generates a 3D printable model of a patient specific anatomic feature from the 2D medical images using a segmentation technique. The 3D printable model is 3D printed as a 3D physical model such that it represents a 1:1 scale of the patient specific anatomic feature. The method includes the step of automatically identifying the patient specific anatomic feature.,"['G06T7/11', 'B33Y50/00', 'G06F18/24', 'G06T17/20', 'G06T19/00', 'G06T7/0014', 'G06V10/26', 'G16H30/40', 'G16H50/50', 'G16H50/70', 'G06T2200/08', 'G06T2207/30004', 'G06T2210/41', 'G06T2219/028', 'G06V2201/03']"
US9767381B2,Similarity-based detection of prominent objects using deep CNN pooling layers as features,"A system and method provide object localization in a query image based on a global representation of the image generated with a model derived from a convolutional neural network. Representations of annotated images and a query image are each generated based on activations output by a layer of the model which precedes the fully-connected layers of the neural network. A similarity is computed between the query image representation and each of the annotated image representations to identify a subset of the annotated images having the highest computed similarity. Object location information from at least one of the subset of annotated images is transferred to the query image and information is output, based on the transferred object location information.","['G06V10/82', 'G06K9/6215', 'G06F16/54', 'G06F16/5854', 'G06F17/30259', 'G06F17/30274', 'G06F18/214', 'G06F18/22', 'G06F18/2431', 'G06K9/6256', 'G06K9/628', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06T7/10', 'G06T7/74', 'G06V10/255', 'G06V10/454', 'G06V10/7715', 'G06V20/63', 'G06K2209/15', 'G06T2207/20084', 'G06T2210/12', 'G06V20/625', 'G06V40/103']"
CN108335339B,Magnetic resonance reconstruction method based on deep learning and convex set projection,"The invention discloses a magnetic resonance reconstruction method based on deep learning and convex set projection, which relates to the technical field of magnetic resonance and comprises the following steps: s1: constructing a network according to an overlapping structure of a plurality of convolutional neural network modules and a plurality of convex set projection layers and shared data, wherein the shared data comprises acquired K space data and coil sensitivity information, and the convex projection layers are obtained based on the shared data; s2: after the network is constructed, training all network parameters through a back propagation process, and verifying the network parameters; s3: and determining the structure and the operational characteristics of the network according to the inspected network parameters, inputting known test set data, performing forward propagation of the network to obtain unknown mapping data, and completing reconstruction of magnetic resonance. The method solves the problem that the existing magnetic resonance reconstruction technology based on deep learning can only support single-channel magnetic resonance data and can not process multi-channel magnetic resonance data.","['G06T11/003', 'A61B5/055', 'G06T2207/10088']"
US20250238673A1,Intelligent control with hierarchical stacked neural networks,"A system and method of detecting an aberrant message is provided. An ordered set of words within the message is detected. The set of words found within the message is linked to a corresponding set of expected words, the set of expected words having semantic attributes. A set of grammatical structures represented in the message is detected, based on the ordered set of words and the semantic attributes of the corresponding set of expected words. A cognitive noise vector comprising a quantitative measure of a deviation between grammatical structures represented in the message and an expected measure of grammatical structures for a message of the type is then determined. The cognitive noise vector may be processed by higher levels of the neural network and/or an external processor.","['G06N3/08', 'G06F16/3344', 'G06F40/253', 'G06F40/30', 'G06N3/02', 'G06N3/045', 'G10L15/16', 'G06Q10/107']"
CN112381741B,A Tomographic Image Reconstruction Method Based on SPECT Data Sampling and Noise Characteristics,"The tomographic image reconstruction method based on SPECT data sampling and noise characteristics comprises the following steps: a, evaluating the noise level of SPECT original projection data, and selecting a first convolution neural network matched with the noise level to perform noise reduction processing on the SPECT original projection data; b, applying a statistical iterative reconstruction algorithm to the projection data subjected to noise reduction to obtain a preliminary reconstructed image; step C, applying a second convolutional neural network matched with the number of the sampling angles of the SPECT projection data to carry out post-processing on the primary reconstructed image; and D, further applying an image iterative reconstruction algorithm based on compressed sensing to obtain a final reconstructed image based on the reconstructed image after artifact removal and the SPECT original projection data. The reconstruction method can shorten the time for acquiring the SPECT tomography and improve the efficiency particularly for the sparsely sampled SPECT data.","['G06T5/70', 'G06N3/045', 'G06N3/08', 'G06T11/008', 'G06T2207/10108', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30004']"
US12339962B2,Methods and apparatus for detection of malicious documents using machine learning,"An apparatus for detecting malicious files includes a memory and a processor communicatively coupled to the memory. The processor receives multiple potentially malicious files. A first potentially malicious file has a first file format, and a second potentially malicious file has a second file format different than the first file format. The processor extracts a first set of strings from the first potentially malicious file, and extracts a second set of strings from the second potentially malicious file. First and second feature vectors are defined based on lengths of each string from the associated set of strings. The processor provides the first feature vector as an input to a machine learning model to produce a maliciousness classification of the first potentially malicious file, and provides the second feature vector as an input to the machine learning model to produce a maliciousness classification of the second potentially malicious file.","['G06F21/56', 'G06F18/214', 'G06F18/24', 'G06F21/562', 'G06F21/563', 'G06N20/20', 'G06N3/04', 'G06N3/045', 'G06N5/01']"
US12038794B2,Foldable electronic device including hinge assembly,"An electronic device is provided, which includes a first housing including at least one first electronic component, a second housing including at least one second electronic component, a hinge housing disposed between the first housing and the second housing, a hinge assembly assembled to the hinge housing to rotatably couple the first housing and the second housing, a flexible printed circuit board electrically coupling the first electronic component and the second electronic component via the hinge housing, and a flexible display, wherein the hinge assembly comprises a support portion located between the flexible printed circuit board and the flexible display, wherein, as the electronic device rotates from folded to 180-degree unfolded, the support portion moves into the flexible display, and wherein, as the electronic device rotates from 180-degree unfolded to folded, the support portion moves into the flexible printed circuit board to be spaced apart from the flexible display.","['G06F1/1681', 'G06F1/1616', 'G06F1/1641', 'G06F1/1652', 'H04M1/022', 'H05K1/147', 'H04M1/0268']"
US10922804B2,"Method and apparatus for evaluating image definition, computer device and storage medium","The present disclosure provides a method and apparatus for evaluating image definition, a computer device and a storage medium, wherein the method comprises: obtaining an image to be processed; inputting the image to be processed to a pre-trained evaluation model; obtaining an comprehensive image definition score outputted by the evaluation model, the comprehensive image definition score being obtained by the evaluation model by obtaining N image definition scores based on N different scales respectively, and then integrating the N image definition scores, N being a positive integer greater than one. The solution of the present invention can be applied to improve the accuracy of the evaluation result.","['G06T7/0002', 'G06N20/00', 'G06N3/08', 'G06T3/40', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30168']"
US12314862B2,Optimizing generative networks via latent space regularizations,"A method for image generation based on a Generative AI Network. The Generative AI Network includes a generator and an encoder. The method includes determining, by the encoder, a first encoding E(Y) of a target image Y; generating, by the generator, a generated image G(Z) corresponding to the target image Y, wherein the generated image G(Z) is located in a close vicinity of a target neighborhood of the target image Y, and outputs of the generator are mapped, by the encoder, to a latent space adaptable to manipulate at least one characteristics of images generated by the Generative AI Network; and generating, by the encoder, a second encoding E(G(Z)) of the generated image G(Z) corresponding to the target image Y, wherein the first and second encodings E(Y) and E(G(Z)) map the target image Y and the generated image G(Z) to the latent space.","['G06N3/084', 'G06F18/217', 'G06N20/00', 'G06N3/045', 'G06N3/047', 'G06T3/4053', 'G06T5/00', 'G06V10/776', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
US11704579B2,Earth modeling methods using machine learning,"Aspects of the present disclosure relate to earth modeling using machine learning. A method includes receiving detected data at a first depth point along a wellbore, providing at least a first subset of the detected data as first input values to a machine learning model, and receiving first output values from the machine learning model based on the first input values. The method includes receiving additional detected data at a second depth point along the wellbore, providing at least a second subset of the additional detected data as second input values to the machine learning model, and receiving second output values from the machine learning model based on the second input values. The method includes combining the first output values at the first depth point and the second output values at the second depth point to generate an updated model of the wellbore, the updated model comprising an earth model.","['G06N5/04', 'E21B41/00', 'E21B49/00', 'G01V1/282', 'G01V20/00', 'G01V99/005', 'G06N20/20', 'G06N3/084', 'G06N3/086', 'E21B2200/20', 'E21B2200/22', 'G01V2210/66', 'G06N3/044', 'G06N3/045', 'G06N3/048']"
US20240266074A1,"Cognitive Communications, Collaboration, Consultation and Instruction with Multimodal Media and Augmented Generative Intelligence","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with networked cognitive collaboration, augmented clinical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal clinical communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms, including augmented generative AI algorithms, models and systems. The invention enables cognitively-enriched, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized clinical intelligence.","['A61B34/30', 'G06F40/169', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G16H10/60', 'G16H15/00', 'G16H20/10', 'G16H20/40', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H50/70', 'G16H80/00', 'H04L12/1822', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/152', 'A61B2090/365', 'A61B2090/373', 'A61B2090/376', 'A61B2090/378', 'A61B34/25', 'A61B34/73', 'A61B90/361', 'H04L51/10', 'H04M3/561', 'H04M3/567', 'H04M7/0027']"
CN112052948B,"Network model compression method and device, storage medium and electronic equipment","The embodiment of the application discloses a network model compression method, a device, a storage medium and electronic equipment, wherein the method relates to a deep learning direction in the artificial intelligence field, and comprises the following steps: the method comprises the steps of obtaining a first generated type countermeasure network model after training is completed, initializing a second generated type countermeasure network model, respectively inputting training data into the first generated type countermeasure network model and the second generated type countermeasure network model for processing, obtaining a first output result and a second output result, generating cross discrimination loss based on the first output result and the second output result, iteratively updating network model parameters of the second generated type countermeasure network model based on the cross discrimination loss, and obtaining a compressed target generated type countermeasure network model. The scheme can obtain the second generation type countermeasure network model which effectively saves the capability of the first generation type countermeasure network model and greatly reduces the parameter quantity of the network model.","['G06N3/082', 'G06N3/045']"
US11917580B2,Method for transmitting and receiving paging signal in wireless communication system and apparatus therefor,"A method of receiving, by a user equipment (UE), a paging signal in a wireless communication system is disclosed. More specifically, the UE performs a registration to a plurality of networks, obtains a plurality of monitoring time points that has to check whether a paging message is received from each of the plurality of networks, when at least some of the plurality of monitoring time points overlap, transmits, to a first network, a change request of a first monitoring time point that has to check whether a first paging message is received from the first network of the plurality of networks, receives, from the first network, configuration information related to the request, and updates the first monitoring time point based on the configuration information.","['H04W68/02', 'H04W60/005', 'H04W8/183', 'H04W88/06']"
US11527068B2,Methods and systems for video processing,"A method for processing an online video stream may include determining a transmission performance of a network for a queue of video frames, wherein each video frame in the queue may be associated with a priority level. The method may also include determining a maximum discarding level based on the transmission performance of the network. The method may further include removing a target video frame of which the associated priority level is lower than or equal to the maximum discarding level from the queue.","['G06V20/41', 'H04N19/159', 'H04N19/114', 'H04N19/124', 'H04N19/132', 'H04N19/164', 'H04N19/172', 'H04N19/587', 'H04N19/89', 'H04N21/234381', 'H04N21/2402', 'H04N21/64769', 'G06V20/44']"
US10540704B2,System and method for machine learning based user application,"The invention synthesizes a social network, electronic commerce (including performance based advertisement and electronic payment), a mobile internet device and a machine learning algorithm(s), utilizing a classical computer or a quantum computer enhanced machine learning algorithm(s), utilizing a quantum computer. The synthesized social commerce further dynamically integrates stored information, real time information and real time information/data/image(s) from an object/array of objects (Internet of Things (IoT)). The machine learning algorithm(s), utilizing a classical computer can include a software agent, a fuzzy logic algorithm, a predictive algorithm, an intelligence rendering algorithm and a self-learning (including relearning) algorithm.","['G06Q20/308', 'G06F3/011', 'G06N10/00', 'G06N10/60', 'G06N20/00', 'G06N3/08', 'G06Q20/12', 'G06Q20/20', 'G06Q20/321', 'G06Q20/3278', 'G06Q20/386', 'G06Q30/02', 'G06Q30/06', 'G06Q30/0631', 'G06Q30/0639', 'G06Q50/01', 'G09G3/00', 'G09G3/001', 'G09G3/035', 'G16C99/00', 'H04W4/21', 'H04W4/23', 'H10F39/182', 'H10H20/018', 'H10H20/812', 'H10H20/8162', 'H10H20/825', 'H10H20/8512', 'H10H20/856', 'H10K50/115', 'G06F2203/011', 'G09G2380/08', 'G09G3/346', 'G10L15/22', 'G10L15/26', 'H01S5/02325', 'H01S5/18302', 'H10H20/872']"
US12067707B2,Multimodal safety systems and methods,"Multimodal systems are provided for managing safety in an industrial environment. The system comprises: (a) a computer vision component for generating a first output data; (b) a real-time locating component for generating a second output data about an object within the industrial environment and a mobile tag device deployed to the object; (c) a LIDAR component for generating a third output data; and (d) an edge computing device connected to the computer vision component, the real-time locating component and the LIDAR component via a local network, and is configured to: (i) receive a data stream including the first output data, the second output data and the third output data, (ii) process the data stream using a machine learning algorithm trained model to generate a safety related result and feedback data, and (iii) deliver the feedback data to the object via the mobile tag device.","['G06T7/0004', 'G01P13/00', 'G01S17/42', 'G01S17/86', 'G01S17/894', 'G01S7/4865', 'G06V20/52', 'G08B21/02', 'G08B21/043', 'G08B21/0446', 'G08B21/0453', 'G08B21/0476', 'G08B21/0492', 'G08B29/186', 'G08B31/00', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/30108']"
CN112116924B,"Abnormal sound detection system, false sound generation system, and false sound generation method","An abnormal sound detection system, a false sound generation system, and a false sound generation method capable of confirming what sound is under the constraint of a small amount of traffic that can be transmitted. An abnormal sound detection system having a pseudo sound generation function is provided with: a statistic calculation unit for calculating a set of statistics indicating the magnitudes of a DC component, an AC component, and a noise component of an amplitude time series of each frequency of the sound input from the terminal; a statistic transmission unit for transmitting a statistic group from the terminal to the server; a statistic receiving unit for receiving, by the server, a group of statistics; and a pseudo-tone reproduction unit for reproducing a pseudo-tone with a stable period based on the set of statistics received by the server.","['G10L25/51', 'G10L21/04', 'G10L25/24', 'G01M13/00', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/088', 'G06N3/09', 'G06N7/01', 'G10L25/30', 'G10L25/18']"
CN113781624B,Ray tracing hardware acceleration with selectable world space transforms,"Ray tracing hardware acceleration with optional world space transformation is disclosed. Enhanced techniques are disclosed for a ray tracing hardware accelerator for traversing hierarchical acceleration structures. For example, the traversal efficiency of such hardware accelerators is improved by transforming rays in the hardware from the coordinate space of the rays to two or more coordinate spaces at corresponding points in the traversal hierarchical acceleration structure. In one example, the hardware accelerator is configured to transform light rays received from the processor from world space to at least one alternate world space and then to an object space in the hardware before returning corresponding light ray pattern intersection results to the processor. The techniques disclosed herein facilitate using additional coordinate space to orient acceleration structures in a manner that more effectively approximates the space occupied by the underlying primitives for ray tracing.","['G06T15/06', 'G06F9/5027', 'G06T1/20', 'G06T1/60', 'G06T15/005', 'G06T15/08', 'G06T17/10', 'G06T2200/28', 'G06T2210/12']"
US10902318B2,Methods and systems for improved transforms in convolutional neural networks,"A system and method for convolutional layer in convolutional neural networks is provided. The convolution is performed via a transformation that includes relocating input, relocating convolution filters and performing an aggregate matrix multiply.","['G06N3/084', 'G06F17/153', 'G06K9/4628', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06V10/454', 'G06V10/82', 'G06F17/16', 'G06F18/21', 'G06K9/6217', 'G06N3/044', 'G06N3/048']"
US11210009B1,Staging data in a cloud-based storage system,"Staging data in a cloud-based storage system, including: receiving, at the cloud-based storage system integrating a first tier of cloud storage and a second tier of cloud storage, a data storage operation from a computer device; storing data corresponding to the data storage operation within the first tier of cloud storage in accordance with a first storage format; and responsive to detecting a condition for transferring data between the first tier of cloud storage and the second tier of cloud storage, transferring the data in the first storage format from the first tier of cloud storage to a second data format within the second tier of cloud storage.","['G06F3/0617', 'G06F3/0647', 'G06F11/1076', 'G06F11/1461', 'G06F11/1464', 'G06F11/2071', 'G06F11/2094', 'G06F3/0604', 'G06F3/0619', 'G06F3/064', 'G06F3/065', 'G06F3/067', 'G06F3/0685', 'G06F11/1466', 'G06F11/2028', 'G06F11/2082', 'G06F2201/815', 'G06F2201/85']"
CN112256860B,"Semantic retrieval method, system, equipment and storage medium for customer service dialogue content","The invention provides a semantic retrieval method, a semantic retrieval system, semantic retrieval equipment and a semantic retrieval storage medium for customer service dialogue contents, wherein a training stage in the method comprises the following steps: pre-training a language model, and pre-training through a Bert model; excavating keywords in the field of OTA customer service quality inspection; the new word discovery is carried out to mine the special word for OTA quality inspection, and the word is added into an OTA quality inspection word segmentation dictionary to replace a word segmentation device of the search server; pre-training a language model, and pre-training through a word vector model; vector index construction and incremental updating based on the full text in the database; constructing positive and negative samples for training to obtain a sequencing model of the text; the prediction using stage comprises the following steps: query understanding, retrieval using stage; inquiring text recall, and searching by using a search server; searching and recalling the query vector; the recall result is collected and fed back to the user; scoring is done by BM25 model in the search server. The invention can score the search results by using the sorting model, and improves the semantic retrieval efficiency of customer service conversations.","['G06F16/335', 'G06F16/3344', 'G06F40/205', 'G06F40/242', 'G06F40/284', 'G06F40/289', 'G06F40/35']"
US11568542B2,Body-mounted or object-mounted camera system,"An object or body-mounted camera apparatus for recording surgery is provided that is adapted for tracking a relevant visual field of an on-going operation. To help maintain visibility and/or focus of the visual field, specific machine learning approaches are proposed in combination with control commands to shift a physical positioning or a perspective of the camera apparatus. Additional variations are directed to tracking obstructions based on the visual field of the camera, which can be utilized for determining a primary recording for use when there are multiple cameras being used in concert.","['G06T1/0014', 'G06T7/10', 'A61B34/10', 'A61B90/361', 'F16M11/041', 'F16M11/123', 'F16M11/18', 'F16M11/2021', 'F16M13/04', 'G06T1/20', 'G06T1/60', 'G06T7/11', 'G06T7/73', 'H04N23/60', 'H04N23/685', 'H04N23/695', 'H04N5/765', 'A61B2034/2048', 'A61B2034/2065', 'A61B2090/3612', 'A61B2090/502', 'A61B90/53', 'G06T2207/20081', 'G06T2207/20084']"
US20210383878A1,Conserving bandwidth using efficient relocation of data between storage devices,A command including information associated with a relocation of data from a first storage device to a second storage device of multiple storage devices of a storage system is transmitted. The command causes the first storage device to relocate the data to the second storage device while bypassing a storage controller.,"['G06F11/1076', 'G11C16/3418', 'G06F11/0757', 'G06F11/076', 'G06F12/0246', 'G06F12/0253', 'G06F3/0617', 'G06F3/0619', 'G06F3/0647', 'G06F3/067', 'G06F3/0679', 'G06F3/0688', 'G06F2212/7208', 'G11C16/26']"
US12067032B2,Intervals for data replication,"A storage system performs data replication with a recovery point objective (RPO). The storage system replicates data at intervals through data transfers over a network. The storage system determines bandwidth of the network. The storage system determines the intervals for replicating the data, based on size of data transfers, network bandwidth, and the recovery point objective.","['H04L67/1097', 'G06F16/27', 'G06F11/1464', 'G06F11/1469', 'G06F11/2094', 'G06F16/275', 'H04L67/06', 'H04L67/10', 'H04L67/1095', 'G06F2201/84', 'H04L69/40']"
US11596482B2,System and method for surgical performance tracking and measurement,"Computer implemented methods and systems are provided for training a machine learning architecture for surgical performance tracking and measurement based on surgical procedure video data set. The methods and systems include, in a first aspect, a sequential relation architecture and a dimensionality reduction architecture. In a second aspect, the methods and systems include a surgical instrument instance segmentation architecture, a decomposition model, and a sequential relation architecture. The video data is processed on a frame level to generate compressed or reduced representations of the video data.","['G06N3/08', 'A61B34/20', 'A61B34/25', 'G06F18/214', 'G06K9/6256', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'H04N19/54', 'A61B2034/102', 'A61B90/361']"
US9720934B1,Object recognition of feature-sparse or texture-limited subject matter,"An object recognition system can be adapted to recognize subject matter having very few features or limited or no texture. A feature-sparse or texture-limited object can be recognized by complementing local features and/or texture features with color, region-based, shape-based, three-dimensional (3D), global, and/or composite features. Machine learning algorithms can be used to classify such objects, and image matching and verification can be adapted to the classification. Further, multiple modes of input can be integrated at various stages of the object recognition processing pipeline. These multi-modal inputs can include user feedback, additional images representing different perspectives of the object or specific regions of the object including a logo or text corresponding to the object, user behavior data, location, among others.","['G06F17/30247', 'G06F16/583', 'G06F17/30705', 'G06F18/22', 'G06F18/24', 'G06V10/40', 'G06V10/42', 'G06V10/75', 'G06V10/764']"
US12061929B2,Providing storage tailored for a storage consuming application,"Providing storage tailored for a storage consuming application, including: identifying, for an application that utilizes storage resources within a cloud-based storage system, one or more storage performance characteristics associated with the application; comparing the storage performance characteristics of the application that were identified with storage performance characteristics of storage resources of one or more cloud-based storage systems; and selecting, based on the comparing, one or more storage resources within the one or more cloud-based storage systems to provide storage services to the application.","['G06F9/5016', 'G06F11/2094', 'G05B23/0259', 'G06F11/108', 'G06F11/1629', 'G06F11/3034', 'G06F11/3442', 'G06F11/3485', 'G06F16/00', 'G06F3/061', 'G06F3/0631', 'G06F3/0653', 'G06F3/0664', 'G06F3/067', 'G06F3/0688', 'G06F9/50', 'G06F9/5011', 'G06F9/505', 'G06F11/2089', 'G06F11/3409', 'G06F2209/501']"
US11403000B1,Resiliency in a cloud-based storage system,"Providing highly available application-specific storage by a cloud-based storage system, including: detecting that a component within a cloud-based storage system that supports an application has become unavailable; and selecting a replacement component within the cloud-based storage system to support the application, wherein at least a portion of a dataset associated with the application is stored as blocks within block storage resources in the cloud-based storage system and also stored as objects within object storage resources in the cloud-based storage system.","['G06F11/2046', 'G06F11/1092', 'G06F11/2041', 'G06F11/302', 'G06F11/3409', 'G06F3/0617', 'G06F3/0631', 'G06F3/064', 'G06F3/0659', 'G06F3/0664', 'G06F3/067', 'G06F3/0683', 'G06F11/108', 'G06F11/2056', 'G06F11/2089', 'G06F11/3034', 'G06F2201/815']"
US10652674B2,Hearing enhancement and augmentation via a mobile compute device,"The presently disclosed subject matter includes a mobile compute device configure to produce a set of audiological assessment data based on a set of stimulus signals presented to a user via a source device and a set of response signals provided as a response to the set of stimulus signals. The mobile compute device identifies a personal audiological profile of the user at least based on a psychoacoustic model and the set of audiological assessment data. The mobile compute device builds a digital signal processing model including a set of audio digital signal processing functions. The mobile compute device executes the digital signal processing model to produce an output audio signal in response to an input audio signal received from the source device, the output audio signal is based on a modified version the input audio signal. The mobile compute device transmits the output audio signal via the source device.","['H04R25/554', 'A61B5/123', 'H04M1/6066', 'H04M1/72409', 'H04R25/04', 'H04R25/70', 'A61B5/6898', 'H04M1/6058', 'H04M1/72412', 'H04M1/72527', 'H04R2420/07', 'H04R2499/11', 'H04R25/505']"
US11961624B2,"Augmenting clinical intelligence with federated learning, imaging analytics and outcomes decision support","The invention integrates emerging applications, tools and techniques for machine learning in medicine with videoconference networking technology in novel business methods that support rapid adaptive learning for medical minds and machines. These methods can leverage domain knowledge and clinical expertise with networked cognitive collaboration, augmented clinical intelligence and cybernetic workflow streams for learning health care systems. The invention enables multimodal clinical communications, collaboration, consultation and instruction between and among heterogeneous networked teams of persons, machines, devices, neural networks, robots and algorithms. It provides for both synchronous and asynchronous cognitive collaboration with multichannel, multiplexed imagery data streams during various stages of medical disease and injury management—detection, diagnosis, prognosis, treatment, measurement, monitoring and reporting, as well as workflow optimization with operational analytics for outcomes, performance, results, resource utilization, resource consumption and costs. The invention enables cognitively-enriched, annotation and tagging, as well as encapsulation, saving and sharing of collaborated imagery data streams as packetized clinical intelligence.","['G16H80/00', 'G06F40/169', 'A61B34/30', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06Q10/0633', 'G16H10/60', 'G16H20/40', 'G16H30/20', 'G16H40/20', 'G16H50/20', 'H04L12/1822', 'H04L12/1827', 'H04L65/1069', 'H04L65/4015', 'H04L65/403', 'H04L65/80', 'H04N7/152', 'H04L12/1813', 'H04M3/561', 'H04M3/567']"
US11001256B2,Collision prediction and avoidance for vehicles,"A vehicle computing system may implement techniques to control a vehicle to avoid collisions between the vehicle and agents (e.g., dynamic objects) in an environment. The techniques may include generating a representation of a path of the vehicle through an environment as a polygon. The vehicle computing system may compare the two-dimensional path with a trajectory of an agent determined using sensor data to determine a collision zone between the vehicle and the agent. The vehicle computing system may determine a risk of collision based on predicted velocities and probable accelerations of the vehicle and the agent approaching and traveling through the collision zone. Based at least in part on the risk of collision, the vehicle computing system may cause the vehicle to perform an action.","['B60W30/09', 'B60W30/0953', 'B60W30/0956', 'B60W50/0097', 'B60W60/00276', 'G05D1/0088', 'G05D1/0289', 'G08G1/161', 'G08G1/166', 'B60W2554/4045']"
US10816693B2,"Methods, systems, apparatuses and devices for facilitating motion analysis in a field of interest","According to some embodiments, a system for performing motion analysis in a field of interest is disclosed. Further, the system may include a plurality of motion sensors configured to generate a plurality of motion data corresponding to at least one motion of at least one object in the field of interest. Further, the system may include a communication device configured for receiving configuration data associated with the field of interest from at least one data source. Further, the system may include a processing device configured for generating a digital model corresponding to the field of interest based on the configuration data using a simulation module and generating one or more of a plurality of motion signatures corresponding to a plurality of predetermined motions and a plurality of object signatures corresponding to a plurality of predetermined objects based on the digital model using the simulation module.","['G01V8/20', 'G06T7/292', 'G06N3/08', 'G06T17/00', 'G06T7/593', 'H04N23/90', 'H04N5/247', 'G06T2207/10016', 'G06T2207/10021', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232', 'G06T2207/30241']"
US11886542B2,Model compression using cycle generative adversarial network knowledge distillation,"Systems and processes for prediction using generative adversarial network and distillation technology are provided. For example, an input is received at a first portion of a language model. A first output distribution is obtained, based on the input, from the first portion of the language model. Using a first training model, the language model is adjusted based on the first output distribution. The first output distribution is received at a second portion of the language model. A first representation of the input is obtained, based on the first output distribution, from the second portion of the language model. The language model is adjusted, using a second training model, based on the first representation of the input. Using the adjusted language model, an output is provided based on a received user input.","['G06F18/2148', 'G06F18/22', 'G06F18/2413', 'G06N3/045', 'G06N3/0475', 'G06N3/08', 'G06V30/194']"
CN113227755B,Improved measurement accuracy,One aspect of the present invention is to provide a system and method for improving assay accuracy that includes at least one or more parameters each having a random error.,"['G01N15/1433', 'G02B21/34', 'G06F18/24143', 'G06T7/0012', 'G06V10/34', 'G06V10/44', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V20/69', 'G16H30/40', 'G16H40/60', 'B01L2200/143', 'B01L2200/148', 'B01L2300/0822', 'B01L2300/0893', 'G01N2015/1006', 'G06T2207/30004']"
US11524767B2,Methods and systems for flight control configured for use in an electric aircraft,"A system for flight control configured for use in an electric aircraft includes a sensor configured to capture an input datum. The system includes an inertial measurement unit (IMU) and configured to detect an aircraft angle and an aircraft angle rate. The system includes a flight controller including an outer loop controller configured to receive the input datum from the sensor, receive the aircraft angle from the IMU, and generate a rate setpoint as a function of the input datum. The system includes an inner loop controller configured to receive the aircraft angle rate, receive the rate setpoint from the outer loop controller, and generate a moment datum as a function of the rate setpoint. The system includes a mixer configured to receive the moment datum, perform a torque allocation as a function of the moment datum, and generate a motor command datum as a function of the torque allocation.","['B64C13/503', 'B64C13/16', 'B64C27/57', 'B64C29/0025', 'B64D27/34', 'B64D31/06', 'B64D31/16', 'B64D45/00', 'G05D1/0816', 'G05D1/0858', 'B64D27/24']"
CN108802812B,Well-seismic fusion stratum lithology inversion method,"The invention discloses a well-seismic fusion stratum lithology inversion method, and belongs to the field of seismic inversion. The method comprises the following steps: according to the logging curve, establishing a logging wave impedance data body and a logging lithology data body; establishing a seismic wave impedance data volume according to the seismic data and the logging wave impedance data volume; establishing a seismic lithology data volume according to the seismic wave impedance data volume; comparing the well logging lithology data body with the seismic lithology data body based on a neural network algorithm to determine a lithology fusion parameter body; and performing layered section weighted fusion on the well logging lithology data body and the seismic lithology data body by utilizing the lithology fusion parameter body to obtain an inversion lithology body. The inversion lithology obtained by the method can improve the longitudinal resolution of seismic lithology prediction, and has important significance for stratum lithology prediction.","['G01V1/282', 'G01V1/306', 'G01V2210/614', 'G01V2210/6226', 'G01V2210/642', 'G01V2210/643', 'G01V2210/6652']"
US12135777B1,Methods and apparatus for encoding passwords or other information,"In illustrative implementations, shape is used to encode computer passwords or other information. The passwords may be easy for a human to remember—and yet have an extremely high number of permutations (e.g., in some cases, greater than 1030 permutations, or greater than 10261 permutations, or greater than 106264 permutations). This combination of a password being easy for a human to remember—yet having a large number of permutations—offers many practical benefits. Among other things, the huge number of permutations makes the password extremely resistant to guessing attacks. In addition, in some cases, the passwords that are created with the shapes are highly resistant to attacks by keystroke logging, mouse logging, touch-gesture logging, screen logging, shoulder surfing, phishing, and social engineering. Alternatively, the shapes may be used to encode other information, such as information that uniquely identifies a product or a machine part.","['G06F21/36', 'G06F21/46', 'G06T17/20', 'G06T19/20', 'G06T2219/2004', 'H04L63/083']"
US10782378B2,Deep learning reconstruction of free breathing perfusion,"A method for reducing artifacts in magnetic resonance imaging (MRI) data includes acquiring a k-space dataset of an anatomical subject using a MRI scanner. An iterative compressed sensing reconstruction method is used to generate a reconstructed image based on the k-space dataset. This iterative compressed sensing reconstruction method uses (a) L1-norm based total variation constraints applied the temporal and spatial dimensions of the k-space dataset and (b) a low rank constraint. After the reconstructed image is generated, a deep learning network is used to generate an artifact image depicting motion artifacts present in the reconstructed image. The reconstructed image is subtracted from the artifact image to yield a final image with the motion artifacts removed.","['A61B5/055', 'A61B5/0402', 'A61B5/318', 'G01R33/5611', 'G01R33/56366', 'G01R33/56509', 'G06K9/0051', 'G06V10/30', 'G06V10/454', 'G06V10/764', 'G06V10/82', 'G06V10/993', 'G06V40/15', 'G16H30/40', 'A61B5/113', 'G01R33/4835', 'G06F2218/04', 'G06V2201/031']"
CN108460414B,"Generation method, device and the electronic equipment of training sample image","The present invention provides generation method, device and the electronic equipment of a kind of training sample image, which comprises identifies background image feature and foreground image feature from several original sample images；Several foreground features units are isolated from prospect characteristics of image；Based on the foreground features unit and several target sample images of the background image feature combination producing；By adding interference characteristic parameter into the target sample image, multiple training sample images are generated, the interference characteristic parameter is used to simulate the characteristic parameter of the shooting effect of shooting authentic specimen.The background image feature and a large amount of target sample image of foreground features unit combination producing that the present invention is isolated according to original sample image, by adding interference characteristic parameter into the target sample image, multiple training sample images are generated, so as to a large amount of training sample images of acquisition being simple and efficient.","['G06F18/214', 'G06V10/22', 'G06V10/44']"
US11250839B2,Natural language processing models for conversational computing,"In non-limiting examples of the present disclosure, systems, methods and devices for training conversational language models are presented. An embedding library may be generated and maintained. Exemplary target inputs and associated intent types may be received. The target inputs may be encoded into contextual embeddings. The embeddings may be added to the embedding library. When a conversational entity receives a new natural language input, that new input may be encoded into a contextual embedding. The new embedding may be added to the embedding library. A similarity score model may be applied to the new embedding and one or more embeddings for the exemplary target inputs. Similarity scores may be calculated based on the application of the similarity score model. A response may be generated by the conversational entity for an intent type for which a similarity score exceeds a threshold value.","['G10L15/063', 'G06F40/30', 'G06F40/242', 'G06N3/045', 'G06N3/08', 'G06N5/041', 'G10L15/197', 'G06N3/042', 'G06N3/044']"
CN112951000B,Large-scale vehicle blind area bidirectional early warning system,"The invention provides a large-scale vehicle blind area bidirectional early warning system, comprising: the front-end sensing module acquires images, videos and vehicle turning signals in a vehicle blind area setting range by using a sensor; the front-end analysis module identifies the barrier by using the AI model and tracks the movement track of the barrier; measuring the speed and the distance of the barrier, prejudging the movement track of the barrier, and transmitting a danger signal to a bidirectional early warning module to send out bidirectional early warning if the track of the barrier is judged to pass through the range of an inner wheel difference danger area; and the cloud management and control platform is used for storing and analyzing the data and the early warning events collected in the vehicle blind area to obtain an AI model and issuing a front-end analysis module of the edge side. The invention introduces the technical innovation of multi-sensor fusion, machine vision and the like in the field of unmanned driving into a blind area scene of a cart, summarizes and summarizes a universal installation scheme, improves the warning effect from two angles of a driver and an obstacle, prevents accidents and realizes a bidirectional early warning mechanism.","['G08G1/167', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/084', 'G06V10/25', 'G06V20/46', 'G06V20/58', 'H04L67/12', 'G06V2201/07', 'Y02T10/40']"
US9692964B2,Modification of post-viewing parameters for digital images using image region or feature information,A method of generating one or more new digital images using an original digitally-acquired image including a selected image feature includes identifying within a digital image acquisition device one or more groups of pixels that correspond to the selected image feature based on information from one or more preview images. A portion of the original image is selected that includes the one or more groups of pixels. The technique includes automatically generating values of pixels of one or more new images based on the selected portion in a manner which includes the selected image feature within the one or more new images.,"['H04N5/23229', 'G06T5/94', 'G06K9/00228', 'G06K9/00268', 'G06K9/3233', 'G06T11/60', 'G06T5/008', 'G06T7/194', 'G06V10/25', 'G06V40/161', 'G06V40/168', 'H04N23/61', 'H04N23/631', 'H04N23/635', 'H04N23/675', 'H04N23/84', 'H04N23/95', 'H04N9/045', 'H04N9/64', 'G06T2207/30201', 'G06T2210/22']"
US20210216633A1,Multi-Layer Security Threat Detection for a Storage System,"An illustrative method includes a data protection system performing, for a storage system, a first security threat detection process, determining, based on the performing of the first security threat detection process, that the storage system is possibly being targeted by a security threat, and performing a second security threat detection process, the second security threat detection process providing higher confidence threat detection than the first security threat detection process.","['G06F21/566', 'G06F21/554', 'G06F21/6218', 'G06F12/0246', 'G06F12/04', 'G06F2212/1052', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'G06F2221/034']"
US12067282B2,Write path selection,"A storage system has NVRAM (nonvolatile random-access memory), storage memory that includes SLC (single level cell) flash memory and QLC (quad level cell) flash memory, and a processor. The processor performs a method that includes selecting one of a plurality of write paths for incoming data, and writing the incoming data via the selected write path. A first write path includes writing to NVRAM, writing from NVRAM to SLC flash memory and writing from SLC flash memory to QLC flash memory. A second write path includes writing to NVRAM and writing from NVRAM to QLC flash memory, bypassing SLC flash memory. A third write path includes writing to SLC flash memory, bypassing NVRAM, and writing from SLC flash memory to QLC flash memory.","['G06F3/061', 'G06F3/0655', 'G06F3/0604', 'G06F3/0644', 'G06F3/0656', 'G06F3/0661', 'G06F3/0679', 'G06F3/0685', 'G06F3/0688', 'G06F3/0689']"
US10296829B2,Convolution processing apparatus and method,"A convolution processing apparatus and method are disclosed. The convolution processing apparatus may include a controller configured to load a pixel of an input image and skip a process associated with the pixel in response to a value of the loaded pixel being 0, a filter bank including at least one filter and configured to extract at least one kernel element corresponding to the pixel from the at least one filter based on an index of the pixel and an input channel of the pixel, and a multiplier-accumulator (MAC) configured to perform a convolution operation based on the value of the pixel and a value of the at least one kernel element and accumulatively store an operation result of the convolution operation, the operation result corresponding to an output image.","['G06N3/0464', 'G06N3/08', 'G06F7/5443', 'G06N3/045', 'G06N3/0454', 'G06N3/063']"
US12189975B2,Preventing applications from overconsuming shared storage resources,"Preventing applications from overconsuming shared storage resources, including: identifying one or more sub-regions of data stored on a storage device that are associated with an application of a known application type; compiling information describing the application's utilization of a storage system; determining that a storage system objective has not been met; and initiating, based on the information describing the application's utilization of the storage system, remediation actions.","['G06F12/0246', 'G06F16/00', 'G06F3/0604', 'G06F3/0605', 'G06F3/0631', 'G06F3/0643', 'G06F3/0653', 'G06F3/067', 'G06F3/0683', 'G06F2212/1056', 'G06F2212/7204', 'G06F2212/7208']"
US12335142B2,Network interface for data transport in heterogeneous computing environments,"A network interface controller can be programmed to direct write received data to a memory buffer via either a host-to-device fabric or an accelerator fabric. For packets received that are to be written to a memory buffer associated with an accelerator device, the network interface controller can determine an address translation of a destination memory address of the received packet and determine whether to use a secondary head. If a translated address is available and a secondary head is to be used, a direct memory access (DMA) engine is used to copy a portion of the received packet via the accelerator fabric to a destination memory buffer associated with the address translation. Accordingly, copying a portion of the received packet through the host-to-device fabric and to a destination memory can be avoided and utilization of the host-to-device fabric can be reduced for accelerator bound traffic.","['G06F12/1081', 'G06F13/28', 'G06F13/385', 'H04L45/60', 'H04L45/742', 'H04L49/9068', 'H04L69/321', 'G06F2212/1024']"
US12229437B2,Dynamic buffer for storage system,"A storage system has NVRAM (nonvolatile random-access memory), storage memory that includes SLC (single level cell) flash memory and QLC (quad level cell) flash memory, and a processor. The processor performs a method that includes determining that a size of a buffer of a storage system should be adjusted. The storage system comprises a non-volatile random-access memory (NVRAM), single level cell (SLC) flash memory, and quad level cell (QLC) flash memory. The buffer of the storage system comprises one or more of the NVRAM and a portion of the SLC flash memory. The method also includes adjusting the size of the buffer of the storage system to a first size.","['G06F3/061', 'G06F11/108', 'G06F11/1464', 'G06F11/2023', 'G06F11/2071', 'G06F11/2094', 'G06F11/3034', 'G06F11/3409', 'G06F11/3466', 'G06F3/0604', 'G06F3/0644', 'G06F3/0656', 'G06F3/0679', 'G06F3/0689', 'G06F2201/81']"
CN111523509B,Equipment fault diagnosis and health monitoring method integrating physical and depth expression characteristics,"The application discloses a device fault diagnosis and health monitoring method integrating physical and deep expression features. The proposed technology mainly comprises wavelet packet decomposition and Fourier transformation, and is used for extracting the frequency spectrum characteristic and time-frequency characteristic of an original signal; the lower branch extracts the deep expression characteristic, and the adopted technology is mainly a convolutional neural network. In the feature fusion stage, a compression-link-activation module (SCE module) is disclosed, and multi-feature comprehensive sensitivity analysis and weighted fusion can be realized under the condition of double-flow feature parallel input. The disclosed fusion method of the physical characteristics and the depth expression characteristics can more comprehensively and accurately describe the fault type of the equipment and monitor the health state of the equipment.","['G06F2218/12', 'G01M13/045', 'G06F18/2415', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06F2218/08']"
US11461458B2,Measuring data-breach propensity,"Provided is a process that includes: obtaining, with one or more processors, a set of user-authentication credentials of a plurality of users; accessing, with one or more processors, a repository of breached credentials and determining, with one or more processors, an amount of the obtained set of user-authentication credentials in the repository of breached credentials, wherein the repository includes credentials from a plurality of entities obtained after the entities suffered a breach; and determining, with one or more processors, a score based on the amount of the set of user-authentication credentials in the repository of breached credentials, wherein the score is indicative of effectiveness of cybersecurity practices of the entity and the users associated with the entity.","['G06F21/45', 'G06F21/31', 'G06F21/552', 'G06F21/554', 'G06F21/577', 'G06F21/6245', 'G06F2221/2127']"
US11019407B2,Systems and methods for providing watermarked content,"A content processing system obtains an identification associated with a device configured to receive content, generates a digital watermark reflecting the receiving device's identification, provides watermarked content by including the digital watermark in the content, and transmits the watermarked content from an edge computing device to the receiving device for the playback. The digital watermark is not visually observable during playback of the watermarked content, and it enables tracking of transmission of the watermarked content.","['H04N1/32149', 'G06F21/1063', 'G06F21/16', 'G06N3/045', 'G06N3/088', 'G06T1/0021', 'G06T1/0028', 'H04L9/0894', 'H04N21/2347', 'H04N21/2393', 'H04N21/2407', 'H04N21/251', 'H04N21/8358', 'G06N3/047', 'G06N3/084', 'G06T2201/0202']"
US11436065B2,System for efficient large-scale data distribution in distributed and parallel processing environment,"The present invention relates to a system for efficient large-scale data distribution in a distributed and parallel processing environment. In particular, the present invention relates to global Top-k sparsification for low bandwidth networks. The present invention verifies that gTop-k S-SGD has nearly consistent convergence performance with S-SGD and evaluates the training efficiency of gTop-k on a cluster with 32 GPU machines which are inter-connected with 1 Gbps Ethernet. The experimental results show that the present invention achieves up to 2.7-12× higher scaling efficiency than S-SGD with dense gradients, and 1.1-1.7× improvement than the existing Top-k S-SGD.","['G06F9/546', 'G06N3/084', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'H04L69/04', 'H04L9/40']"
US11205247B2,Method and apparatus for enhancing video frame resolution,"A method for enhancing video frame resolution according to one embodiment of the present disclosure may include loading video data including a plurality of frames having low resolution; selecting, from the group of artificial neural networks for image processing, artificial neural networks for image processing having different complexity to apply to two different frames of a video; and generating a high resolution frame by processing each frame of the video according to the selected artificial neural networks for image processing. A neural network for image processing according to one embodiment of the present disclosure may be a deep neural network generated via machine learning, and an input and output of the video may take place in an Internet of Things environment using a 5G network.","['H04N21/234381', 'G06N20/20', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06T3/4046', 'G06T3/4053', 'G06T5/50', 'G06T7/20', 'G06V20/40', 'H04N19/50', 'H04N5/147', 'G06T2207/10016', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084']"
US20230276264A1,Managing a wireless device that is operable to connect to a communication network,"A method is disclosed for managing a wireless device that is operable to connect to a communication network. The communication network comprises a Radio Access Network (RAN), and the method is performed by a first RAN node of the communication network. The method comprises receiving, from a second RAN node in the communication network, information indicating whether a wireless device is capable of executing a Machine Learning (ML) model that is operable to provide an output on the basis of which at least one RAN operation performed by the wireless device may be configured","['H04W24/02', 'G06N20/00', 'H04W36/0064', 'H04W8/22', 'G06N3/045', 'G06N3/047', 'G06N5/01']"
US11462031B2,Systems and methods for performing a 3D match search in a 3D database based on 3D primitives and a connectivity graph,"The present disclosure proposes a computer implemented of object recognition of an object to be identified using a method for reconstruction of a 3D point cloud. The method comprises the steps of acquiring, by a mobile device, a plurality of pictures of said object, sending the acquired pictures to a cloud server, reconstructing, by the cloud server, a 3D points cloud reconstruction of the object, performing a 3D match search in a 3D database using the 3D points cloud reconstruction, to identify the object, the 3D match search comprising a comparison of the reconstructed 3D points cloud of the object with 3D points clouds of known objects stored in the 3D database.","['G06T17/00', 'G06N20/00', 'G06T7/55', 'G06V10/462', 'G06V10/757', 'G06V20/647', 'G06T2207/10016', 'G06T2207/20072', 'G06T2207/20084', 'G06T2210/56']"
US11207025B1,Multi-sided PCB for contact sensing,"A wearable monitoring device can include an electronics module containing a printed circuit board (PCB) to which one or more sensors are coupled. The one or more sensors can include one or more contacting sensors and/or one or more non-contacting sensors. In some cases, the wearable monitoring device can include an onboard power supply (e.g., a battery) and a wireless communication antenna. The PCB can be constructed to specifically include the one or more sensors on a first side facing the skin of the user when the wearable monitoring device is being worn, allowing one or more processors, memory, and other components to be included on the opposite side facing away from the user. Certain components, such as the power supply and wireless communication antenna, can be spaced apart from the PCB and located opposite the PCB from the one or more sensors.","['A61B5/257', 'A61B5/6833', 'A61B5/0015', 'A61B5/0537', 'A61B5/08', 'A61B5/1102', 'A61B5/308', 'A61B5/4878', 'A61B5/6823', 'A61B5/7207', 'A61B5/742', 'A61B7/003', 'A61B7/04', 'A61B2560/0214', 'A61B2560/0242', 'A61B2560/0247', 'A61B2560/0443', 'A61B2562/0204', 'A61B2562/0219', 'A61B2562/0233', 'A61B2562/028', 'A61B2562/164', 'A61B2562/166']"
US11141129B1,Multi-sensor auscultation device,"A multi-sensor auscultation device is disclosed that can be applied to or worn by a user to monitor multiple physiological systems of the user. The multi-sensor auscultation device can make use of two or more acoustic sensors, such as accelerometer contact microphones (ACMs), to collect acoustic data from multiple locations on the user's body. The multi-sensor auscultation device can include electrodes for detecting cardiac electrical activity and/or assessing the user's bioimpedance. The multi-sensor auscultation device can provide useful data associated with the user's cardiovascular system, respiratory system, and/or electrical characteristics. The multi-sensor auscultation device can be in the form of a reusable electronics module couplable to a disposable patch adhesive.","['A61B7/04', 'A61B7/003', 'A61B5/6823', 'A61B5/6833', 'A61B5/7207', 'A61B5/7225', 'A61B5/7285', 'A61B2562/0204', 'A61B2562/0219', 'A61B2562/028', 'A61B2562/046']"
US11116448B1,Multi-sensor wearable patch,"A multi-sensor smart patch is disclosed that can be worn by a user to monitor multiple physiological systems of the user. The multi-sensor smart patch can make use of two or more acoustic sensors, such as accelerometer contact microphones (ACMs), to collect acoustic data from multiple locations on the user's body. The multi-sensor smart patch can include electrodes for detecting the heart's electrical activity and/or assessing the user's bioimpedance. The multi-sensor smart patch can provide useful data associated with the user's cardiovascular system, respiratory system, and electrical characteristics. The multi-sensor smart patch can be in the form of a reusable electronics module couplable to a disposable patch adhesive.","['A61B5/6833', 'A61B5/0006', 'A61B5/0205', 'A61B5/02416', 'A61B5/02438', 'A61B5/0816', 'A61B5/1102', 'A61B5/113', 'A61B5/14551', 'A61B5/257', 'A61B5/318', 'A61B5/6823', 'A61B7/003', 'A61B7/04', 'A61B2560/0443', 'A61B2562/0204', 'A61B2562/0209', 'A61B2562/0219', 'A61B2562/0271', 'A61B2562/029', 'A61B2562/06', 'A61B2562/166', 'A61B5/0008', 'A61B5/14532']"
US11816587B2,Explainable neural net architecture for multidimensional data,"An exemplary embodiment may describe a convolutional explainable neural network. A CNN-XNN may receive input, such as 2D or multi-dimensional data, a patient history, or any other relevant information. The input data is segmented into various objects and a knowledge encoding layer may identify and extract various features from the segmented objects. The features may be weighted. An output layer may provide predictions and explanations based on the previous layers. The explanation may be determined using a reverse indexing mechanism (Backmap). The explanation may be processed using a Kernel Labeler method that allows the labelling of the progressive refinement of patterns, symbols and concepts from any data format that allows a pattern recognition kernel to be defined allowing integration of neurosymbolic processing within CNN-XNNs. The optional addition of meta-data and causal logic allows for the integration of connectionist models with symbolic logic processing.","['G06N5/045', 'G06F18/2113', 'G06N3/042', 'G06N3/045', 'G06N3/049', 'G06N3/08', 'G06N20/00', 'G06N5/022']"
US20240267762A1,Communication method and apparatus,"A communication method and apparatus are provided. The method includes: obtaining N pieces of training data, where for one of the N pieces of training data, the training data corresponds to one piece of mark information, and the mark information indicates an attribute of the training data; and sending indication information to a terminal device, where the indication information indicates information about M artificial intelligence models, the artificial intelligence model is trained based on X pieces of training data in the N pieces of training data, and the X pieces of training data are determined based on the mark information. When the N pieces of training data are obtained, the N pieces of training data may be used for constructing training data corresponding to different mark information, to train the M artificial intelligence models or more artificial intelligence models, so that scenario-based artificial intelligence model training can be implemented.","['H04W24/02', 'H04L5/0058', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'H04B17/327', 'H04L5/0048', 'H04L5/0051', 'H04L5/0053', 'H04W56/0015', 'H04W72/0446', 'H04W72/0453', 'H04W72/046', 'Y02D30/70']"
CN103690240B,A kind of medical system,"This application provides a kind of medical system, wherein, described medical system comprises: the family doctor's module in handheld device, Electronic Health Record system, doctor terminal and medical diagnosis aid system, and described medical diagnosis aid system is used for communicating with the family doctor's module in handheld device with Electronic Health Record system; The vital signs information of patient received according to the family doctor's module in handheld device and/or the communicate information of doctor terminal, obtain patient information or Hospital Electronic Medical Record information from Electronic Health Record system; According to the vital sign information of patient, the communicate information of doctor terminal and patient information, or carry out data mining according to the vital sign information of patient, the communicate information of doctor terminal and Hospital Electronic Medical Record information.Therefore, the application can solve family doctor and carry out condition-inference and the result that provides assistance in diagnosis during consulting for object of seeking medical advice, and helps the problem of family doctor's decision-making.",[]
CN112594142B,Terminal cloud collaborative wind power operation and maintenance diagnosis system based on 5G,"The invention relates to the technical field of remote operation and maintenance diagnosis of wind power generation equipment, and provides a terminal cloud-coordinated wind power operation and maintenance diagnosis system based on 5G, which comprises: the system comprises a data acquisition gateway, a 5G-based edge computing network, a wind field control center system, a preposed data acquisition service and an operation and maintenance diagnosis cloud platform. Under the synergistic effect of the subsystems, the system realizes second-level acquisition, remote operation and maintenance and intelligent diagnosis of fan data, solves the problems of difficult fan inspection and difficult monitoring, improves the level of centralized control of fans in different places, reduces the fault rate of fan operation, ensures high-quality power generation efficiency of the fans, and creates considerable economic efficiency for wind farms.","['F03D17/00', 'H04W4/38', 'F05B2260/80', 'F05B2270/709', 'Y02D30/70']"
CN111091132B,"Image recognition method and device based on artificial intelligence, computer equipment and medium","The application provides an image identification method, an image identification device, computer equipment and a medium based on artificial intelligence, and belongs to the technical field of image processing. The method includes the steps that at least two third sample images obtained by preprocessing each second sample image after data enhancement processing are trained to obtain a certificate photo recognition model, the certificate photo recognition model with accurate recognition results can be obtained through training under the condition that the number of the sample images is small, at least two depth neural networks with different scales are input into the certificate photo recognition model to conduct prediction processing on at least two preprocessed images obtained after preprocessing an original image in parallel, the recognition results of the depth neural networks with different scales can be integrated for judgment, misjudgment of a single depth neural network is avoided, the original image is recognized as the certificate photo image under the condition that target probability meets a first preset condition, characters in the original image do not need to be recognized, recognition influence of the characters in a background is avoided, and recognition accuracy is improved.","['G06V30/153', 'G06F18/214', 'G06F18/2415', 'G06N3/045', 'G06N3/08']"
US10582191B1,Dynamic angle viewing system,"A system that generates a 3D environment from data collected by depth sensors (such as LIDAR) and color sensors (such as color video camera data) observing an area or activity, transmits versions of the 3D environment to various devices for display, and enables device users to dynamically alter a viewing angle of the 3D environment. The version of the 3D environment sent to each device may be optimized for the device's resolution and for the bandwidth of the connection to the device. Embodiments may enrich the 3D environment by detecting and tagging objects and their locations in the environment, and by calculating metrics related to motion or actions of these objects. Object tags and metrics may be transmitted to devices and displayed for example as overlays of images rendered from user-selected viewing angles. Embodiments of the system also enable 3D printing of an object as a memento for example.","['G06T17/20', 'B29C64/393', 'B33Y50/00', 'G06K9/00671', 'G06T13/40', 'G06T19/20', 'G06T7/292', 'G06T7/70', 'G06V10/44', 'G06V20/20', 'G06V20/42', 'G06V20/64', 'G06V40/25', 'H04N13/243', 'H04N13/279', 'H04N19/00', 'H04N19/90', 'G01S17/89', 'G06T2200/08', 'G06T2200/16', 'G06T2219/2012']"
US9805064B2,"System, apparatus, method, program and recording medium for processing image","An image processing system may include an imaging device for capturing an image and an image processing apparatus for processing the image. The imaging device may include an imaging unit for capturing the image, a first recording unit for recording information relating to the image, the information being associated with the image, and a first transmission control unit for controlling transmission of the image to the image processing apparatus. The image processing apparatus may include a reception control unit for controlling reception of the image transmitted from the imaging device, a feature extracting unit for extracting a feature of the received image, a second recording unit for recording the feature, extracted from the image, the feature being associated with the image, and a second transmission control unit for controlling transmission of the feature to the imaging device.","['G06T7/40', 'G06F16/5838', 'G06F17/30256', 'G06F16/40', 'G06F16/51', 'G06F16/583', 'G06F17/30017', 'G06K9/00268', 'G06K9/00288', 'G06K9/4647', 'G06K9/4652', 'G06K9/481', 'G06K9/6212', 'G06T1/00', 'G06T7/00', 'G06T7/70', 'G06V10/507', 'G06V10/56', 'G06V10/758', 'G06V40/168', 'G06V40/172', 'G06V40/178', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/30201', 'G06T2207/30242', 'H04N7/183']"
US20240013471A1,Query-specific behavioral modification of tree traversal,"Methods and systems are described in some examples for changing the traversal of an acceleration data structure in a highly dynamic query-specific manner, with each query specifying test parameters, a test opcode and a mapping of test results to actions. In an example ray tracing implementation, traversal of a bounding volume hierarchy by a ray is performed with the default behavior of the traversal being changed in accordance with results of a test performed using the test opcode and test parameters specified in the ray data structure and another test parameter specified in a node of the bounding volume hierarchy. In an example implementation a traversal coprocessor is configured to perform the traversal of the bounding volume hierarchy.","['G06T15/04', 'G06T15/06', 'G06T1/20', 'G06T15/005', 'G06T15/60', 'G06T17/005']"
US12407716B2,Threat mitigation system and method,"A threat mitigation platform includes: an agent subsystem configured to generate an initial notification concerning a security event within a computing platform; a generative AI-based planner subsystem configured to receive the initial notification and generate a mitigation plan to address, in whole or in part, the security event within the computing platform; an executor subsystem configured to iteratively process the mitigation plan using a generative AI model to generate an output; and an output formatter subsystem configured to format the output and generate a summarized human-readable report for the initial notification.","['G06F16/345', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06F40/103', 'G06F40/154', 'G06F40/56', 'G06N3/0475', 'H04L41/16', 'H04L63/1416', 'H04L63/1425', 'H04L63/1441', 'G06F2221/034']"
US11138738B2,Image processing method and image processing device,The embodiments of the present disclosure disclose an image processing method and device. The image processing method comprises transforming a first image to obtain a plurality of second images; obtaining feature maps of each of the second images by performing feature extraction on the second images using a first machine learning unit selected from a group including at least one first machine learning unit; and inputting the feature maps of each of the second images to a second machine learning unit to obtain a processing result of the first image.,"['G06V10/82', 'G06F18/214', 'G06F18/23', 'G06F18/2413', 'G06K9/00523', 'G06K9/46', 'G06K9/627', 'G06N3/02', 'G06N3/045', 'G06N3/08', 'G06T7/0002', 'G06T7/11', 'G06V10/40', 'G06V10/764', 'G06F2218/08', 'G06K2209/05', 'G06K9/4628', 'G06N20/10', 'G06N3/044', 'G06T2207/20076', 'G06T2207/20081', 'G06V10/454', 'G06V2201/03']"
US11593036B2,Staging data within a unified storage element,"Staging data on a storage element integrating fast durable storage and bulk durable storage, including: receiving, at a storage element integrating fast durable storage and bulk durable storage, a data storage operation from a host computer; storing data corresponding to the data storage operation within fast durable storage in accordance with a first data resiliency technique; and responsive to detecting a condition for transferring data between fast durable storage and bulk durable storage, transferring the data from fast durable storage to bulk durable storage in accordance with a second data resiliency technique.","['G06F3/0685', 'G06F11/0727', 'G06F11/0793', 'G06F11/1076', 'G06F11/1662', 'G06F11/2005', 'G06F11/2007', 'G06F11/2089', 'G06F11/2094', 'G06F11/3034', 'G06F11/3055', 'G06F3/061', 'G06F3/0616', 'G06F3/0617', 'G06F3/0647', 'G06F3/0659', 'G06F3/067', 'G06F11/1435', 'G06F11/1441', 'G06F11/2071', 'G06F2201/84', 'G06F2212/261']"
US11662228B2,Real-time surface shape sensing for flexible structures,A surface shape determination system includes a surface shape sensor in the form of a flexible and stretchable elastomeric substrate with strain/displacement sensing elements embedded in it. The sensor may be a single-core optical fiber with a series of fiber Bragg Gratings (FBGs) located at predetermined positions along its length. A light source provides an incident light spectrum at one end of the fiber. Each grating of the fiber has index modulation which causes particular wavelengths of the light spectrum that do not satisfy the Bragg condition to be reflected back in the fiber. The refractive index of each grating changes with strain on the substrate due to deflection of it. An interrogator captures the reflected wavelengths and retrieves signal information therefrom. A processor receives the output of the interrogator and performs non-linear regression analysis on the information using a neural network to reconstruct the surface morphology in real-time.,"['G01D5/35316', 'G06N20/00', 'G01B11/165', 'G01B11/18', 'G01B11/24', 'G01D5/268', 'G01D5/35367', 'G01L1/246', 'G02B6/02076', 'G06N3/084']"
US12387040B2,Model for textual and numerical information retrieval in documents,"The accuracy of existing machine learning models, software technologies, and computers are improved by using one or more machine learning models to predict a type of data that one or more numerical characters and/or one or more natural language word characters of a document correspond to. For instance, a Question Answering systems can be used to predict that a particular number value corresponds to a date, a billing amount, a page number, or the like.","['G06F40/295', 'G06F40/279', 'G06F16/93', 'G06F40/30', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/096', 'G06Q10/10', 'G06Q30/04', 'G06Q40/12', 'G06N3/0442']"
US20210256320A1,Machine learning artificialintelligence system for identifying vehicles,"An artificial intelligence system for identifying attributes in an image. The system may include a processor in communication with a client device; and a storage medium. The storage medium may store instructions that, when executed, configure the processor to perform operations including: extracting first features; categorizing the first images in a first group or a second group; modifying first metadata associated with each image in the first images to include a binary label; calculating a classification function; classifying a second plurality of images using the classification function; extracting second features from the second images classified in the first group; categorizing the second images in the first group by attribute; calculating an attribute identification function that identifies attributes of the second images; and identifying at least one attribute associated with a client image using the attribute identification function, the client image being received from the client device.","['G06N3/084', 'G06K9/6267', 'G06F16/583', 'G06F18/214', 'G06F18/24', 'G06K9/00671', 'G06K9/22', 'G06K9/46', 'G06K9/4628', 'G06K9/6256', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06V10/17', 'G06V10/454', 'G06V10/764', 'G06V10/774', 'G06V20/20', 'G06F18/23', 'G06K2209/27', 'G06K9/6218', 'G06N20/20', 'G06N5/003', 'G06N5/01', 'G06V2201/10']"
US11275374B2,Event-based data logging,"Techniques and methods for storing data. For instance, a vehicle can receive sensor data generated by one or more sensors. The vehicle can then detect that an event is occurring and/or has occurred using the sensor data. Based on detecting the event, the vehicle can flag a first portion of the sensor data as corresponding to the event. The vehicle can then store the first portion of the sensor data according to a first storage rule and a second portion of the sensor data according to a second storage rule. In some instances, the storage rules may indicate when sensor data is to be overwritten, lengths of time that the sensor data is to be stored, formats for storing the sensor data, and/or when the sensor data is to be sent to one or more computing devices.","['G01S17/931', 'G05D1/0088', 'B60W30/085', 'B60W30/09', 'B60W30/0956', 'G01S13/862', 'G01S13/865', 'G01S13/867', 'G01S13/931', 'G01S15/931', 'G01S17/04', 'G01S17/86', 'G06F9/542']"
US10989521B2,Apparatus and methods for distance estimation using multiple image sensors,"Data streams from multiple image sensors may be combined in order to form, for example, an interleaved video stream, which can be used to determine distance to an object. The video stream may be encoded using a motion estimation encoder. Output of the video encoder may be processed (e.g., parsed) in order to extract motion information present in the encoded video. The motion information may be utilized in order to determine a depth of visual scene, such as by using binocular disparity between two or more images by an adaptive controller in order to detect one or more objects salient to a given task. In one variant, depth information is utilized during control and operation of mobile robotic devices.","['G01B11/14', 'G06T7/593', 'G06T2207/10021', 'G06T2207/30196', 'G06T2207/30252', 'H04N19/51']"
AU2023258438B2,Systems and methods of speaker-independent embedding for identification and verification from audio,Embodiments described herein provide for audio processing operations that evaluate characteristics of audio signals that are independent of the speaker's voice. A neural network architecture trains and applies discriminatory neural networks tasked with modeling and classifying speaker-independent characteristics. The task-specific models generate or extract feature vectors from input audio data based on the trained embedding extraction models. The embeddings from the task-specific models are concatenated to form a deep-phoneprint vector for the input audio signal. The DP vector is a low dimensional representation of the each of the speaker-independent characteristics of the audio signal and applied in various downstream operations.,"['G06F21/32', 'G06F21/554', 'G06N20/00', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/0464', 'G06N3/08', 'G06N3/09', 'G06N7/01', 'G10L15/063', 'G10L15/16', 'G10L25/27', 'G10L25/51', 'G10L25/78', 'H04L63/0861', 'H04L63/1466', 'H04W12/06', 'H04W12/12', 'H04W12/65', 'G06N3/044', 'G10L17/00', 'H04W12/69']"
RU2691214C1,Text recognition using artificial intelligence,"FIELD: physics.SUBSTANCE: invention relates to systems and methods of character recognition using artificial intelligence. Such a result is achieved due to that the method includes obtaining a text image, wherein the text on the image contains one or more words in one or more sentences; obtaining a text image as first initial data for a set of trained models of machine learning, storing information on compatibility of words and frequency of their combined use in real sentences; obtaining one or more final output data from a set of trained machine learning models, as well as extracting from one or more final output data of one or more assumed sentences from text on an image. Each of one or more assumed sentences contains possible sequences of words.EFFECT: high efficiency of recognizing text by using a set of models of machine learning, which enable analysis of context of words of text on an image with high quality.21 cl, 27 dwg","['G06N5/00', 'G06V10/82', 'G06F18/214', 'G06F18/23', 'G06F40/126', 'G06F40/289', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06V10/40', 'G06V10/768', 'G06V30/153', 'G06V30/19147', 'G06V30/413', 'G06N20/10', 'G06N3/048', 'G06V30/10']"
US10657107B1,Many task computing with message passing interface,"An apparatus includes a processor to: receive a request from a remote device to perform a job flow; retrieve a job flow definition defining the job flow and each of a set of task routines to perform tasks of the job flow from a set of storage devices where each is stored as an undivided object within one storage device; and in response to determining that a data set is stored as multiple data object blocks, generate a container containing the job flow definition and set of task routines to enable each storage device to perform the job flow using a locally stored data object block of the data set as input to generate a corresponding data object block of a result report, provide a copy of the container to each storage device, and transmit the result report assembled from the data object blocks thereof to the remote device.","['G06F9/4881', 'G06F16/164', 'G06F16/1727', 'G06F16/182', 'G06F16/1827', 'G06F16/9014', 'G06F16/90344', 'G06F8/51', 'G06F9/46', 'G06N3/044', 'G06N3/045', 'G06N3/063', 'G06N3/08', 'G06N3/084', 'H04L63/102', 'H04L67/10', 'H04L67/02', 'H04L67/1097', 'H04L67/12', 'H04L67/34', 'H04L67/55']"
CN113609965B,"Training method and device of character recognition model, storage medium and electronic equipment","The disclosure relates to a training method and device of a character recognition model, a storage medium and electronic equipment, and relates to the technical field of machine learning, wherein the method comprises the following steps: constructing a data set according to the history image and the real character label of the history image, and inputting the history image in the data set into a trained teacher model to obtain a soft target label of the history image; inputting the historical images in the data set into a student model with the same output layer as the teacher model to obtain a soft prediction label and an actual prediction label of the historical images; constructing a first loss function according to the soft target label and the soft prediction label, and constructing a second loss function according to the real character label and the actual prediction label; and performing distillation training on the student model according to the first loss function and the second loss function to obtain a character recognition model after training. The present disclosure reduces the computational effort of the model.","['G06F18/2415', 'G06N3/047', 'G06N3/08']"
US11996939B2,Method and device for transmitting data in wireless LAN system,"A method and a device for transmitting data in a wireless LAN system are presented. Particularly, a transmission STA transmits information about a preamble puncturing pattern to a reception STA. The transmission STA transmits data to the reception STA through a 320 MHz band on the basis of the preamble puncturing pattern. The preamble puncturing pattern is determined on the basis of a first bandwidth unit in which a CCA is performed and a second bandwidth unit in which user specific information is repeated. At least one 20 MHz subchannel is punctured in the 320 MHz band on the basis of the preamble puncturing pattern.","['H04L1/0069', 'H04L1/00', 'H04L1/0041', 'H04L1/0072', 'H04L1/1621', 'H04L1/1628', 'H04L1/1635', 'H04L1/1896', 'H04L5/0044', 'H04L5/0096', 'H04W16/14', 'H04W72/0453', 'H04W74/0808', 'H04L1/0025', 'H04L1/0075', 'H04W84/12']"
CN110796619B,"Image processing model training method and device, electronic equipment and storage medium","The invention provides an image processing model training method, which comprises the following steps: processing the second set of training samples by a first image processing model to determine initial parameters of the first image processing model; processing the second set of training samples by a second image processing model to determine initial parameters of the second image processing model; processing the second image processing model through the output result of the first image processing model and the second training sample set, and determining the updating parameters of the second image processing model; and iteratively updating the generator parameters and the discriminator parameters of the second image processing model through the second training sample set according to the updating parameters of the second image processing model. The invention also provides a voice processing method, a voice processing device and a storage medium. The invention can improve the training precision and the training speed of the image processing model, so that the image processing model can adapt to different use scenes.","['G06T5/70', 'G06F18/214']"
US11587101B2,Platform for detecting abnormal entities and activities using machine learning algorithms,"The present disclosure generally relates to providing accurate and real-time insights into abnormal entities and activities using machine learning algorithms. An exemplary computer-enabled method comprises receiving a set of input data, wherein the set of input data is associated with an entity; automatically obtaining, based on the received set of input data, a set of derived data, wherein the set of derived data is associated with the entity; obtaining, based on the set of derived data, a plurality of feature values corresponding to a plurality of features; providing the plurality of feature values to an autoencoder-decoder to obtain a plurality of feature-specific reconstruction errors; selecting, based on the plurality of feature-specific reconstruction errors, one or more features from the plurality of features; outputting the selected one or more features and one or more textual descriptions associated with the selected one or more features.","['G06Q30/0185', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/088', 'G06Q40/025', 'G06Q40/03', 'G06Q40/08', 'G06N3/047']"
US10972641B2,"Optics, device, and system for assaying","The present invention provides, among other thing, devices and methods for simple, fast, and sensitive assaying, including imaging.","['H04N5/2252', 'G01N21/8483', 'H04N23/51', 'H04N23/55', 'H04N5/2254', 'H04N23/56', 'H04N23/57', 'H04N5/2256', 'H04N5/2257']"
WO2019200753A1,"Lesion detection method, device, computer apparatus and storage medium","A lesion detection method, comprising: inputting original CT image sample data into a segmentation model and performing a segmentation calculation, and outputting segmented liver image data (S1); inputting the original CT image sample data and the segmented liver image data into a recognition model and outputting a recognition result (S2), the segmentation model and recognition model being cascaded. The method employs two cascaded fully-convolutional neural networks, thereby improving lesion analysis accuracy. Also disclosed is a device, computer apparatus and storage medium for detecting a lesion.","['G16H50/20', 'G06N3/045', 'G16H30/20']"
US11900665B2,"Graphics neural network processor, method, and system","A graphics processor can include a processing cluster array including a plurality of processing clusters coupled with the plurality of memory controllers, each processing cluster of the plurality of processing clusters including a plurality of streaming multiprocessors, the processing cluster array configured for partitioning into a plurality of partitions. The plurality of partitions include a first partition including a first plurality of streaming multiprocessors configured to perform operations for a first neural network, The operations for the first neural network are isolated to the first partition. The plurality of partitions also include a second partition including a second plurality of streaming multiprocessors configured to perform operations for a second neural network. The operations for the second neural network are isolated to the second partition and protected from operations performed for the first neural network.","['G06V40/161', 'G06F16/5838', 'G06F16/784', 'G06F18/24143', 'G06V10/764', 'G06V10/82', 'G06V10/955', 'G06V40/10', 'G06V40/103', 'G06V40/23']"
US20220303331A1,Link performance prediction and media streaming technologies,"In one embodiment, a computing device for receiving a media stream includes processing circuitry to receive a link performance prediction for a network link between the computing device and a network, which indicates a predicted performance of the network link during a future timeframe. Based on the link performance prediction, the processing circuitry identifies a performance objective for the media stream. The performance objective is associated with media stream content that will be received in the media stream over the network link for playback during the future timeframe. Based on the link performance prediction and the performance objective, the processing circuitry adjusts one or more media streaming parameters for the media stream content to be played during the future timeframe. The processing circuitry then receives the media stream content to be played during the future timeframe over the network link based on the media streaming parameter(s).","['H04L65/752', 'H04N21/2402', 'H04L41/147', 'H04L43/0882', 'H04L65/612', 'H04L65/80', 'H04N21/23439', 'H04N21/26258', 'H04N21/41407', 'H04N21/44209', 'H04N21/462', 'H04N21/64738', 'H04N21/8456']"
US20240112033A1,Hardware ip optimized convolutional neural network,"In an example, an apparatus comprises at least one execution platform; and logic, at least partially including hardware logic, to receive a trained neural network model in a model optimizer and convert the trained neural network model to an optimized model comprising parameters that are fit to the at least one execution platform. Other embodiments are also disclosed and claimed.","['G06N3/082', 'G06T1/20', 'G06F8/52', 'G06F9/44552', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/105', 'G06N5/04', 'G06N3/044', 'G06N3/048', 'G06N3/084', 'G06N3/088']"
US10946864B2,Apparatus and method for fault diagnosis and back-up of advanced driver assistance system sensors based on deep learning,"An apparatus for fault diagnosis and back-up of advanced driver assistance system sensors based on deep learning, the apparatus including: an individual sensor diagnosis unit configured to quantitatively evaluate a reliability of an output result of each sensor at each moment on the basis of a model for an output of each sensor under a normal operation; an inter-sensor mutual diagnosis unit configured to extract shared representation between the sensors and quantitatively evaluate a normal-operation reliability of the output result of each sensor on the basis of the extracted shared representation; and an integrated diagnosis unit configured to quantitatively evaluate a final reliability of each sensor on the basis of output results of the individual sensor diagnosis unit and the inter-sensor mutual diagnosis unit.","['B60W50/0225', 'G06N3/08', 'B60W50/0205', 'B60W50/029', 'G01B11/22', 'G05B23/024', 'G06F11/0739', 'G06N20/00', 'G06N3/04', 'G06N3/044', 'G06N3/045', 'G06N5/02', 'G06N5/046', 'G07C5/0808', 'B60W2050/0215', 'B60W2050/0292', 'B60Y2306/15']"
US11101876B2,System for planetary-scale analytics,"A smart satellite system is capable of decision making and prioritization on the fly to optimize the use of downlink bandwidth to deliver prioritized data based upon opportunity and the resources of available payloads. By providing a satellite system with substantial processing power and a level of autonomy, the satellite is able to make decisions about capturing imagery data, including image data processing, object detection, image segmentation, and re-orientation of the satellite based upon the opportunity, from the satellite's perspective, for capturing image data of areas or objects of interest. Through the use of machine learning and in-orbit image analysis, the satellite may transmit only a subset of the captured images, portions of the captured images, or the result of image analysis, thereby efficiently using the downlink communication channel.","['H04B7/18513', 'G06T7/00', 'G06F18/214', 'G06K9/0063', 'G06K9/00637', 'G06K9/00657', 'G06K9/3233', 'G06K9/40', 'G06K9/46', 'G06N3/045', 'G06N3/08', 'G06V10/16', 'G06V10/25', 'G06V10/30', 'G06V10/40', 'G06V10/454', 'G06V20/13', 'G06V20/176', 'G06V20/188', 'G06V20/194', 'H04N7/183', 'G01C11/02', 'G06K9/34', 'G06T2207/10032', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/30181', 'G06V10/26']"
US11861188B2,System having modular accelerators,"A storage system, blades, removable modules, and method of configuring a storage system are described. The storage system has blades with computing resources and storage resources. At least one of the blades has, or has added, one or more removable modules.","['G06F1/3268', 'G06F3/0631', 'G06F1/189', 'G06F1/3287', 'G06F3/0604', 'G06F3/061', 'G06F3/0634', 'G06F3/067', 'G06N20/00', 'G06N3/02', 'G06F1/263', 'G06N3/08', 'Y02D10/00']"
US12412086B2,Neural network optimization mechanism,"An apparatus to facilitate optimization of a neural network (NN) is disclosed. The apparatus includes optimization logic to define a NN topology having one or more macro layers, adjust the one or more macro layers to adapt to input and output components of the NN and train the NN based on the one or more macro layers.","['G06T1/20', 'G06N3/08', 'G06N3/04', 'G06N3/045', 'G06N3/082', 'G06N3/063']"
CN112236779B,Image processing method and image processing device based on convolutional neural network,"The application discloses an image processing method and an image processing device based on a convolutional neural network in the field of artificial intelligence, wherein the method can comprise the steps of receiving an input image; the method comprises the steps of preprocessing an input image to obtain preprocessed image information, carrying out convolution operation on the image information by using a convolution neural network, and outputting a convolution operation result, wherein when the convolution operation is carried out on the image information by using an nth layer of convolution layer, after r auxiliary convolution kernels are obtained by m main convolution kernels of the convolution layer, carrying out convolution operation on the image information by using the m main convolution kernels and the r auxiliary convolution kernels of the convolution layer, and splicing the obtained multiple feature images to obtain the convolution operation result of the convolution layer. In the embodiment of the application, the image processing device can store the main convolution kernel of each convolution layer, and the auxiliary convolution kernel is generated by using the main convolution kernel of each convolution layer before the convolution operation is performed by using each convolution layer, so that the memory occupied by the convolution neural network can be reduced.","['G06N3/082', 'G06F17/15', 'G06F17/16', 'G06N3/04', 'G06N3/045', 'G06N3/0464', 'G06N3/0495', 'G06N3/063', 'G06N3/09', 'G06V10/454', 'G06V10/764', 'G06V10/82']"
EP4123513A1,Fixed-point method and apparatus for neural network,"The embodiments of the present application provide a fixed-point method and apparatus for a neural network, which performs at least one of the following low-bit quantizations on a neural network: performing a first low-bit quantization on input activation values of convolutional layers in the neural network, performing a second low-bit quantization on weights of convolution kernels of the convolutional layers in the neural network; for non-convolutional functional layers other than the convolutional layers in the neural network, performing a third low-bit quantization on input activation values of the non-convolutional functional layers; retraining the current low-bit quantized neural network; performing fixed-point processing based on each of low-bit quantization results in the retrained neural network; loading the fixed-point neural network; wherein the first low-bit, the second low-bit, and the third low-bit are within 1 to 8 bits. The embodiments of the present application enable the final activation values and/or weights of convolution kernels are represented by low-bit fixed-point, so that they can be easily transplanted into embedded platforms and application-specific integrated circuits.","['G06N3/063', 'G06N3/045', 'G06N3/0464', 'G06N3/048', 'G06N3/0495', 'G06N3/09']"
US20250117639A1,Loss-error-aware quantization of a low-bit neural network,"Methods, apparatus, systems and articles of manufacture for loss-error-aware quantization of a low-bit neural network are disclosed. An example apparatus includes a network weight partitioner to partition unquantized network weights of a first network model into a first group to be quantized and a second group to be retrained. The example apparatus includes a loss calculator to process network weights to calculate a first loss. The example apparatus includes a weight quantizer to quantize the first group of network weights to generate low-bit second network weights. In the example apparatus, the loss calculator is to determine a difference between the first loss and a second loss. The example apparatus includes a weight updater to update the second group of network weights based on the difference. The example apparatus includes a network model deployer to deploy a low-bit network model including the low-bit second network weights.","['G06N3/063', 'G06F18/2148', 'G06F18/217', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/082', 'G06N3/084']"
US11748850B2,Blended neural network for super-resolution image processing,"Embodiments relate to a super-resolution engine that converts a lower resolution input image into a higher resolution output image. The super-resolution engine includes a directional scaler, an enhancement processor, a feature detection processor, a blending logic circuit, and a neural network. The directional scaler generates directionally scaled image data by upscaling the input image. The enhancement processor generates enhanced image data by applying an example-based enhancement, a peaking filter, or some other type of non-neural network image processing scheme to the directionally scaled image data. The feature detection processor determines features indicating properties of portions of the directionally scaled image data. The neural network generates residual values defining differences between a target result of the super-resolution enhancement and the directionally scaled image data. The blending logic circuit blends the enhanced image data with the residual values according to the features.","['G06T1/20', 'G06T3/4053', 'G06N3/045', 'G06N3/08', 'G06T3/4007', 'G06T3/4046', 'G06T5/50', 'H04N23/815']"
CN105844330B,The data processing method and neural network processor of neural network processor,"The embodiment of the present invention provides the data processing method and neural network processor of a kind of neural network processor.This method comprises: input data is added with corresponding weight absolute value by adder, input data is the data of previous stage output, input data and weight absolute value are n member vector, and input data and corresponding weight absolute value n item data after being added are successively carried out the first Nonlinear Mapping of n times.Result after first Nonlinear Mapping is subjected to n times accumulation operations by accumulator, accumulation operations include the add operation and subtraction operation of weight sign bit control, the second Nonlinear Mapping of result progress after n times accumulation operations is obtained into processing result and carries out data output, the inverse mapping of rule and the first Nonlinear Mapping that the second Nonlinear Mapping is mapped according to Neural Network Based Nonlinear is formulated.To improve quantitative efficiency, storage demand and the bandwidth demand of data are reduced.",['G06N3/063']
US12062249B2,System and method for generating image landmarks,"A system, neural network, and corresponding method generate 3D landmarks associated with an object in a 2D image. An embodiment is a system comprising a neural network detector configured to produce planar coordinates of landmarks at points of the object in the 2D image and a depth coordinate estimator. The planar coordinates include planar coordinate pairs. The depth coordinate estimator is configured to receive the 2D image and the planar coordinates and to estimate a depth coordinate for each planar coordinate pair of each landmark to generate the 3D landmarks. The system reduces network parameters from MB to KB and has better performance relative to state-of-the-art methods. The system may be configured to apply the 3D landmarks for face alignment, virtual face makeup, face recognition, eye gaze tracking, face synthesis, or other face related application.","['G06V40/165', 'G06F18/21', 'G06N3/04', 'G06T7/50', 'G06T7/70', 'G06V10/454', 'G06V40/171', 'G06T2207/20084', 'G06T2207/30201']"
US12293579B2,Systems and methods for analyzing remote sensing imagery,"Disclosed systems and methods relate to remote sensing, deep learning, and object detection. Some embodiments relate to machine learning for object detection, which includes, for example, identifying a class of pixel in a target image and generating a label image based on a parameter set. Other embodiments relate to machine learning for geometry extraction, which includes, for example, determining heights of one or more regions in a target image and determining a geometric object property in a target image. Yet other embodiments relate to machine learning for alignment, which includes, for example, aligning images via direct or indirect estimation of transformation parameters.","['G06V20/176', 'G06F18/2413', 'G06V10/451', 'G06V10/764', 'G06V10/82', 'H04N23/10', 'H04N23/11']"
CN113673307B,A lightweight video action recognition method,"A lightweight video motion recognition method comprises the steps of firstly carrying out preprocessing such as image enhancement, guided filtering denoising and the like on an RGB video frame image subjected to framing processing, and simultaneously calculating an optical flow sequence and extracting an optical flow characteristic diagram by utilizing a video frame sequence. And then designing an LRDN model to realize light feature extraction, and repeatedly performing iterative training on the RGB video frame after preprocessing to optimize the performance of the RGB video frame. And finally, developing a light double-flow convolution cyclic neural network based on the trained LRDN network model to finish the identification and classification of video actions. The method comprises the steps of constructing a double-flow convolution neural network by utilizing a light-weight LRDN network to extract spatial feature information and time domain feature information of a video respectively, carrying out convolution fusion on the spatial feature information and the time domain feature information by utilizing a feature fusion network, and inputting space-time fusion features into a Bi-GRU network containing a soft attention mechanism to obtain global time domain information of the video, so that video action classification and identification are rapidly realized. The invention reduces the calculation loss in the video motion recognition.","['G06F18/214', 'G06F18/2415', 'G06F18/253', 'G06N3/045', 'G06N3/08']"
CN106548208B,"A kind of quick, intelligent stylizing method of photograph image","The invention discloses a kind of quick, intelligent stylizing methods of photograph image.This method is based on two kinds of nerual network techniques: CNN (convolutional network) and RNN (time Recursive Networks), is a kind of method for being automatically synthesized stylized photo.This method is by being iterated study to specific style image (such as van gogh's style, Picasso's style, animation style), generate the neural network model for representing style material, deep learning is carried out to the content of the photo of input again, to extract the advanced features for representing content, to carry out Intelligent Fusion with trained style material, it is final to generate new stylized image, to reach likeness in form and two targets alike in spirit.",['G06F18/24']
US12038881B2,Replica transitions for file storage,"Methods and systems for transitioning a replica of a file system are described. An illustrative method includes updating a replica file system on a target data repository to be a replica of a source file system as the source file system existed on the source data repository at a point in time, where the replica file system is constructed of block objects at the target data repository that store metadata for individual files and directories of the replica file system and support access to blocks of data associated with the files and directories of the target file system at the target data repository, and where the updating includes updating the block objects of the replica file system to be replicas of block objects of the source file system as the block objects of the source file system existed on the source data repository at the point in time.","['G06F16/178', 'G06F16/1844', 'G06F3/0619', 'G06F3/065', 'G06F3/067']"
US11687418B2,Automatic generation of recovery plans specific to individual storage elements,"An illustrative method includes a data protection system detecting a data corruption event that impacts data stored within a storage element of a storage system, identifying one or more attributes associated with the storage element, and determining, based on the one or more attributes associated with the storage element, a recovery plan for the storage element, the recovery plan specifying one or more operations configured to recover the data stored within the storage element from the data corruption event.","['G06F11/1469', 'G06F11/108', 'G06F11/1441', 'G06F11/2092', 'G06F11/2094', 'G06F21/6218', 'G06F2201/82', 'G06F2201/84']"
US11651075B2,Extensible attack monitoring by a storage system,"An illustrative method includes a storage system receiving attribute data representative of one or more attributes of a known attack against data maintained by a target system other than the storage system, updating an extensible attack monitoring process executed by the storage system with the attribute data, and monitoring, using the extensible attack monitoring process updated with the attribute data, storage operation requests of the storage system for one or more attributes that match the one or more attributes of the known attack.","['G06F21/564', 'G06F21/566', 'G06F11/1448', 'G06F11/1469', 'G06F11/2056', 'G06F11/2089', 'G06F11/3034', 'G06F21/57', 'G06F21/6218', 'H04L63/1416', 'H04L67/1097', 'G06F11/2069', 'G06F12/0246', 'G06F12/04', 'G06F12/1441', 'G06F12/1483', 'G06F2201/84', 'G06F2212/1052', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208']"
US11789638B2,Continuing replication during storage system transportation,"Continuing replication during storage system transportation, including: replicating, between a first storage system and a second storage system, a dataset; connecting, by the first storage system during movement of the first storage system to a new physical location, to a communication network available at one or more intermediate physical locations; and continuing the replicating of the dataset between the first storage system at one or more of the intermediate physical locations and the second storage system over the communication network available at one or more of the intermediate physical locations.","['G06F3/065', 'H04L41/0816', 'G06F3/0604', 'G06F3/0614', 'G06F3/0635', 'G06F3/0647', 'G06F3/067', 'G06F3/0683', 'H04L41/0894', 'H04L67/1095', 'H04L67/1097', 'H04L41/0266', 'H04L41/16', 'H04L43/0817', 'H04L69/40']"
US12050689B2,Host anomaly-based generation of snapshots,"An illustrative method includes a data protection system detecting a request provided by a host to perform an operation with respect to a storage system, detecting, based on the request, an anomaly associated with the host, and directing, based on the detecting the anomaly associated with the host, the storage system to generate a recovery dataset for data maintained by the storage system.","['G06F21/568', 'G06F11/108', 'G06F11/1441', 'G06F11/1469', 'G06F11/2092', 'G06F11/2094', 'G06F11/3034', 'G06F11/3409', 'G06F11/3485', 'G06F21/552', 'G06F21/554', 'G06F21/78', 'G06F3/0619', 'G06F3/0659', 'G06F3/067', 'G06F2201/81', 'G06F2201/84']"
US12067118B2,Detection of writing to a non-header portion of a file as an indicator of a possible ransomware attack against a storage system,"An illustrative method includes detecting a request to perform an overwrite operation with respect to a non-header portion of a file stored by a storage system and determining, based on the detecting the request, that data stored by the storage system is possibly being targeted by a security threat.","['G06F21/568', 'G06F11/108', 'G06F11/1435', 'G06F11/1441', 'G06F11/1464', 'G06F11/1469', 'G06F11/2092', 'G06F11/2094', 'G06F11/3034', 'G06F11/3409', 'G06F11/3485', 'G06F21/552', 'G06F21/554', 'G06F21/566', 'G06F21/78', 'G06N20/00', 'G06N3/08', 'G06F2201/81', 'G06F2201/84', 'G06N3/063']"
US11720692B2,Hardware token based management of recovery datasets for a storage system,"An illustrative method includes a data protection system detecting a request to perform a restricted operation with respect to a recovery dataset configured to be used by a storage system to recover from a data corruption event within the storage system, monitoring, in response to the request, for an occurrence of a predetermined set of one or more authorization events performed with one or more hardware tokens, and preventing the restricted operation from being executed until the each of the one or more authorization events included in the predetermined set occurs.","['G06F21/6218', 'G06F21/604', 'G06F11/108', 'G06F11/1446', 'G06F11/1469', 'G06F11/2056', 'G06F11/2089', 'G06F16/2365', 'G06F21/602', 'H04L9/0894', 'H04L9/30', 'H04L9/3213', 'H04L9/3234', 'H04L9/3239', 'H04L9/50', 'G06F11/2069', 'G06F12/0246', 'G06F2201/84', 'G06F2201/86', 'G06F2212/1032', 'G06F2212/1052', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'G06F3/0688']"
US12210762B2,Transitioning between source data repositories for a dataset,"Transitioning between replication sources for data replication operations, including: delaying a transition from using a first data repository as a source for data replication to using a second data repository as the source for data replication after detecting that one or more storage operations directed to the first data repository have not been replicated to the second data repository; and promoting the second data repository as the source for data replication such that storage operations received after completing the transition are directed to the second data repository.","['G06F3/065', 'G06F3/0619', 'G06F3/067', 'G06F3/0688']"
US11989645B2,Event-based extraction of features in a convolutional spiking neural network,"A system is described that comprises a memory for storing data representative of at least one kernel, a plurality of spiking neuron circuits, and an input module for receiving spikes related to digital data. Each spike is relevant to a spiking neuron circuit and each spike has an associated spatial coordinate corresponding to a location in an input spike array. The system also comprises a transformation module configured to transform a kernel to produce a transformed kernel having an increased resolution relative to the kernel, and/or transform the input spike array to produce a transformed input spike array having an increased resolution relative to the input spike array. The system also comprises a packet collection module configured to collect spikes until a predetermined number of spikes relevant to the input spike array have been collected in a packet in memory, and to organize the collected relevant spikes in the packet based on the spatial coordinates of the spikes, and a convolutional neural processor configured to perform event-based convolution using memory and at least one of the transformed input spike array and the transformed kernel.","['G06N3/045', 'G06N3/063', 'G06F18/241', 'G06N3/0464', 'G06N3/049', 'G06N3/08', 'G06N3/088', 'G06T3/4046', 'G11C11/41', 'G11C11/419', 'G11C11/54', 'G11C7/1006']"
US11934681B2,Data migration for write groups,"Managing storage device evacuation that includes a plurality of storage devices, including: detecting, by the storage system, an occurrence of a storage device evacuation event associated with a source storage device within a write group, wherein the write group is a subset of storage devices storing a data set; responsive to detecting the occurrence of the storage device evacuation event, identifying, by the storage system, a target storage device for receiving data stored on the source storage device; and migrating, by the storage system, the data stored on the source storage device to the target storage device.","['G06F3/0647', 'G06F3/0607', 'G06F3/0617', 'G06F3/067', 'G06F3/0683', 'G06F3/0688', 'G11C11/4074', 'G11C11/4096', 'G11C11/005', 'G11C16/105']"
US11500788B2,Logical address based authorization of operations with respect to a storage system,"An illustrative method includes a data protection system detecting a request provided by a source to perform an operation with respect to a storage system, the request including a logical address that comprises a logical element representative of a storage location within the storage system, determining whether the logical address further comprises an authorization element indicating that the source is authorized to initiate operations with respect to the storage system, and performing, based on the determining whether the logical address includes the authorization element, an action with respect to the operation.","['G06F12/1441', 'G06F12/0246', 'G06F12/1408', 'G06F21/31', 'G06F21/554', 'G06F21/6218', 'G06F21/64', 'G06F21/79', 'G06F2212/1052']"
US11244225B2,Neural network processor configurable using macro instructions,"Implementing a neural network can include receiving a macro instruction for implementing the neural network within a control unit of a neural network processor. The macro instruction can indicate a first data set, a second data set, a macro operation for the neural network, and a mode of operation for performing the macro operation. The macro operation can be automatically initiated using a processing unit of the neural network processor by applying the second data set to the first data set based on the mode of operation.","['G06N3/049', 'G06F17/15', 'G06F9/30036', 'G06F9/3017', 'G06N3/063']"
CN107182216B,A fast magnetic resonance imaging method and device based on deep convolutional neural network,"The present invention provides a kind of rapid magnetic resonance imaging method and device based on depth convolutional neural networks.The described method includes: step S1, constructs depth convolutional neural networks；Step S2, obtains offline magnetic resonance image data, and the training depth convolutional neural networks learn lack sampling magnetic resonance image and adopt the mapping relations between image entirely；Step S3 rebuilds magnetic resonance image using the depth convolutional neural networks learnt in the step S2.The rapid magnetic resonance imaging method and device based on depth convolutional neural networks of the embodiment of the present invention, learn an offline depth convolutional neural networks by using a large amount of collected MR datas, study lack sampling magnetic resonance image and the full mapping relations adopted between image, to make full use of a large amount of magnetic resonance image under line, develop its prior information, make its offline network that can restore more fine structures and characteristics of image in MR data from owing to adopt, and makes that magnetic resonance owes to adopt multiple and imaging precision increases.","['G01R33/5608', 'G06N3/0464', 'A61B5/055', 'G06N3/08', 'G06N3/09', 'G06T5/50']"
US10802992B2,Combining CPU and special accelerator for implementing an artificial neural network,"The present invention relates to artificial neural network (ANN), for example, convolutional neural network (CNN). In particular, the present invention relates to how to implement and optimize a convolutional neural network based on an embedded FPGA. Specifically, it proposes a CPU+FPGA heterogeneous architecture to accelerate ANNs.","['G06F13/102', 'G06F13/28', 'G06N3/045', 'G06N3/0454', 'G06N3/063', 'G06N3/082']"
TWI690196B,Method and apparatus of loop filtering for vr360 videos,"Methods and apparatus of processing 360-degree virtual reality (VR360) pictures are disclosed. A target reconstructed VR picture in a reconstructed VR picture sequence is divided into multiple processing units and whether a target processing unit contains any discontinuous edge corresponding to a face boundary in the target reconstructed VR picture is determined. If the target processing unit contains any discontinuous edge: the target processing unit is split into two or more sub-processing units along the discontinuous edges； and NN processing is applied to each of the sub-processing units to generate a filtered processing unit. If the target processing unit contains no discontinuous edge, the NN processing is applied to the target processing unit to generate the filtered processing unit. A method and apparatus for CNN training process are also disclosed. The input reconstructed VR pictures and original pictures are divided into sub-frames along discontinuous boundaries for the training process.","['H04N19/597', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'H04N19/119', 'H04N19/82', 'H04N19/96', 'G06N3/044']"
WO2021164772A1,"Method for training cross-modal retrieval model, cross-modal retrieval method, and related device","A method for training a cross-modal retrieval model, a cross-modal retrieval method, and a related device, relating to the field of artificial intelligence. The method comprises: determining a reference model by using unsupervised learning; performing knowledge distillation on the basis of the reference model and training data to obtain similar data of the training data; and performing supervised learning by using the similar data of the training data and the training data, so as to obtain a cross-modal retrieval model. High accuracy of a trained cross-modal retrieval model can be ensured, without manually tagging training data used for supervised learning.","['G06F16/90335', 'G06F16/907', 'G06F18/22', 'G06N3/045', 'G06N3/084', 'G06N3/088']"
US11973708B2,Method and apparatus for reporting channel state information,"Methods and systems for reporting CSI and selecting optimal beams using ML. The CSI report is sent to a gNB, which includes feedback parameters, computed and predicted using ML. The feedback parameters are computed using measurements performed using CSI-RS. Values of the feedback parameters likely at future, based on channel variation and the measurements, are pre-dieted using ML. The computed and predicted feedback parameters are included in the CSI report. Optimal CSI-RS resource allocation and optimal CSI reporting periodicity are determined using ML and sent to the gNB. The CSI report is encoded using the ML based model. The RSRP of the beams are predicted using ML for beam selection.","['G06N3/045', 'H04L5/0048', 'G06N3/04', 'G06N3/08', 'G06N3/09', 'H04B17/327', 'H04B17/373', 'H04B7/061', 'H04B7/0626', 'H04L5/0057']"
US11763563B2,Autonomous activity monitoring system and method,"A system for monitoring and recording and processing an activity includes one or more cameras for automatically recording video of the activity. A processor and memory associated and in communication with the camera is disposed near the location of the activity. The system may include AI logic configured to identify a user recorded within a video frame captured by the camera. The system may also detect and identify a user when the user is located within a predetermined area. The system may include a video processing engine configured to process images within the video frame to identify the user and may modify and format the video upon identifying the user and the activity. The system may include a communication module to communicate formatted video to a remote video processing system, which may further process the video and enable access to a mobile app of the user.","['G06V20/42', 'H04N23/611', 'H04N23/64', 'A63B24/0006', 'A63B24/0062', 'H04N23/80', 'H04N5/77', 'A63B2024/0025', 'A63B2024/0028', 'A63B2220/806']"
US20210117705A1,"Traffic image recognition method and apparatus, and computer device and medium","A traffic image recognition method and apparatus, and a computer device and a medium. An embodiment of the method comprises: acquiring a video stream collected by a vehicle, and extracting each frame of image in the video stream as a first image; inputting the first image into a de-interference autoencoder for pre-processing, to filter out an interference in the first image and output a second image, the de-interference autoencoder being obtained by training with at least two types of interference sample sets, and disturbance modes added to different types of interference sample sets including at least two of: noise, an affine transformation, filter blurring, a brightness transformation, or monochromatization; and inputting the second image into a traffic sign recognition model for recognition processing.","['G06K9/00818', 'G06V10/30', 'G06F18/214', 'G06K9/40', 'G06K9/6256', 'G06N3/04', 'G06N3/08', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06V20/582', 'G06T2207/20081', 'G06T2207/20084']"
US10846573B2,"Detecting, redacting, and scoring confidential information in images","Provided is a process, including: receiving a screen capture event from an operating system of a first client computing device of a first user, the screen capture event including, or being associated with, a bitmap image of at least part of a display of the first computing device; causing optical character recognition (OCRing) of text in the bitmap image; classifying each of the n-grams into two or more categories, the two or more categories including a category for confidential information; and for each of the n-grams classified in the category for confidential information, obfuscating the respective n-gram in the bitmap image to form a modified version of the bitmap image.","['G06F21/6245', 'G06K9/726', 'G06F18/2113', 'G06F18/217', 'G06F18/2413', 'G06F18/24323', 'G06F21/62', 'G06K9/00979', 'G06K9/344', 'G06K9/623', 'G06K9/6262', 'G06K9/627', 'G06K9/6282', 'G06V10/764', 'G06V10/95', 'G06V30/153', 'G06V30/274', 'H04L63/102', 'G06K2209/01', 'G06T11/001', 'G06T5/002', 'G06T5/70', 'G06V30/10']"
US11616834B2,Efficient replication of a dataset to the cloud,"Synchronizing snapshots between storage systems, including: receiving, from a source storage system, an identification of a snapshot to be replicated to a destination storage system, wherein the source storage system and the destination storage system are of different types; identifying, from hint information stored on the destination storage system, a most recent version of the snapshot that is stored on the destination storage system; issuing, to the source storage system, a request for an identification of the differences between the snapshot to be replicated to the destination storage system and the most recent version of the snapshot that is stored on the destination storage system; receiving, from the source storage system, the identification of the differences; and issuing a request to transfer, from the source storage system to the destination storage system, data associated with the differences.","['G06F3/0608', 'H04L67/1095', 'G06F11/108', 'G06F11/1451', 'G06F11/1456', 'G06F11/2064', 'G06F11/2094', 'G06F3/0619', 'G06F3/065', 'G06F3/0659', 'G06F3/067', 'H04L67/1097']"
WO2023048770A1,"Apparatus, articles of manufacture, and methods for data collection balancing for sustainable storage","Methods, apparatus, systems, and articles of manufacture are disclosed for data collection balancing for sustainable storage. An example apparatus includes at least one memory, machine executable instructions, and processor circuitry to at least one of execute or instantiate the machine executable instructions to orchestrate resources in an edge environment based on data ingested from a data source, execute a machine learning model based on the data to generate outputs, the outputs including at least one of a first value representative of data criticality or a second value representative of data quality of the data, reduce resource requirements associated with the resources of the edge environment based on the outputs to effectuate green data management of the edge environment, and cause an operation at a node of the edge environment based on at least one of the data or the outputs, the node associated with the data.","['G06F16/9024', 'G06N20/00', 'G06F11/3003', 'G06F16/215', 'G06F16/2365', 'G06F16/907', 'G06F18/214', 'G06F9/5005', 'G06Q30/018']"
US11249492B2,Methods and apparatus to facilitate autonomous navigation of robotic devices,"Methods and apparatus to facilitate autonomous navigation of robotic devices. An example autonomous robot includes a region model analyzer to: analyze a first image of an environment based on a first neural network model, the first image captured by an image sensor of the robot when the robot is in a first region of the environment; and analyze a second image of the environment based on a second neural network model, the second image captured by the image sensor when the robot is in a second region of the environment, the second neural network associated with the second region. The example robot further includes a movement controller to: autonomously control movement of the robot within the first region toward the second region based on the analysis of the first image; and autonomously control movement of the robot within the second region based on the analysis of the second image.","['G05D1/102', 'G06V10/82', 'G05D1/0011', 'G05D1/0088', 'G05D1/0246', 'G05D1/0282', 'G06K9/00', 'G06V10/764', 'G06V20/10']"
US20210150767A1,"Image filtering apparatus, image decoding apparatus, and image coding apparatus","To apply a filter to input image data in accordance with an image characteristic. A CNN filter includes a neural network configured to receive an input of one or multiple first type input image data and one or multiple second type input image data, and output one or multiple first type output image data, the one or multiple first type input image data each having a pixel value of a luminance or chrominance, the one or multiple second type input image data each having a pixel value of a value corresponding to a reference parameter for generating a prediction image and a differential image, the one or multiple first type output image data each having a pixel value of a luminance or chrominance.","['G06T9/002', 'H04N19/119', 'G06N3/045', 'G06N3/0454', 'G06T3/4046', 'H04N19/105', 'H04N19/117', 'H04N19/159', 'H04N19/176', 'H04N19/182', 'H04N19/186', 'H04N19/80', 'H04N19/82', 'G06N3/044']"
AU2025213705A1,Adaptive intelligence and shared infrastructure lending transaction enablement platform,"#$%^&*AU2025213705A120250828.pdf##### Abstract Systems, methods, and apparatus for automated execution of loan based activities are disclosed herein. An example system may include a blockchain service circuit to interpret access control features corresponding to parties associated with a loan; a data collection circuit to interpret entity information; a smart contract circuit to specify loan terms and conditions; and a loan management circuit. The loan management circuit may interpret loan related events and implement loan related activities in response to the entity information, the plurality of access control features, and the loan terms and conditions. Each of the blockchain service circuit, the data collection circuit, the smart contract circuit, and the loan management circuit further include a corresponding application programming interface (API) component to facilitate communication among the circuits of the system. Abstract Systems, methods, and apparatus for automated execution of loan based activities are disclosed herein. An example system may include a blockchain service circuit to interpret access control features corresponding to parties associated with a loan; a data collection circuit to interpret entity information; a smart contract circuit to specify loan terms and conditions; and a loan management circuit. The loan management circuit may interpret loan related events and implement loan related activities in response to the entity information, the plurality of access control features, and the loan terms and conditions. Each of the blockchain service circuit, the data collection circuit, the smart contract circuit, and the loan management circuit further include a corresponding application programming interface (API) component to facilitate communication among the circuits of the system. 5000 Al SYSTEMS LENDER PRIORITY COLLATERAL RELATED VALUATION VALUATION MODEL SMART 5028 EVENTS CIRCUIT IMPROVEMENT CONTRACT CIRCUIT CIRCUIT 5008 5064 5066 5068 LOAN TERMS & CONDITIONS COLLATERAL AUTOMATED CLUSTER 5029 ATTRIBUTES AGENT CIRCUIT CIRCUIT 5010 5070 5072 LOAN ACTIONS SENSOR 5004 5030 ENVIRONMENTAL 5062 DATA COLLATERAL 5012 LOAN EVENTS COLLATERAL LOANS 5032 5002 DATA SENSOR DATA SMART CONTRACT 5074 5014 5090 CONTROLLER 5022 5024 COLLATERAL TERMS & CONDITIONS 5018 DISTRIBUTED LEDGER IOT CIRCUIT LOAN ENTRY 5041 5020 5063 ENTITIES/PARTIES BORROWER LENDER MARKETPLACE 5040 5042 INFORMATION SOCIAL NETWORK INFORMATION PRICING 3RD PARTY COLLATERAL 5050 BLOCKCHAIN FINANCIAL CONDITION 5044 EQUIPMENT FINANCIAL DATA DATA 5060 5092 5054 5034 5038 5058 5048 FIG. 50 5000 Al SYSTEMS LENDER PRIORITY COLLATERAL RELATED VALUATION VALUATION MODEL SMART 5028 EVENTS CIRCUIT IMPROVEMENT CONTRACT 5008 CIRCUIT CIRCUIT 5064 5066 5068 LOAN TERMS WO 2020/092426 & CONDITIONS COLLATERAL AUTOMATED CLUSTER 5029 ATTRIBUTES AGENT CIRCUIT CIRCUIT 5010 5070 5072 SENSOR LOAN ACTIONS 5004 5030 ENVIRONMENTAL 5062 DATA COLLATERAL 5012 LOAN EVENTS COLLATERAL LOANS 5032 5002 DATA SENSOR DATA SMART CONTRACT 5074 5014 5090 CONTROLLER 5022 5024 29/89 COLLATERAL TERMS & CONDITIONS 5018 DISTRIBUTED LEDGER IOT CIRCUIT LOAN ENTRY 5020 5041 5063 ENTITIES/PARTIES BORROWER LENDER MARKETPLACE 5040 5042 INFORMATION SOCIAL NETWORK INFORMATION PRICING 3RD PARTY COLLATERAL/ 5050 BLOCKCHAIN 5044 EQUIPMENT PCT/US2019/058647 FINANCIAL CONDITION FINANCIAL DATA DATA 5060 5092 5054 5034 5038 5058 5048 FIG. 50 20 25 21 37 05 11 A ug 2 02 5 2 0 2 5 2 1 3 7 0 5 1 1 A u g 2 0 2 5 5 0 0 0 A l S Y S T E M S LENDER PRIORITY COLLATERAL RELATED V A L U A T I O N VALUATION MODELS M A R T 5 0 2 8 E V E N T S C I R C U I T I M P R O V E M E N T C O N T R A C T 5 0 0 8 C I R C U I T C I R C U I T 5 0 6 4 5 0 6 6 5 0 6 8 L O A N T E R M S W O 2 0 2 0 / 0 9 2 4 2 6 & C O N D I T I O N S C O L L A T E R A L A U T O M A T E D C L U S T E R 5 0 2 9 A T T R I B U T E S A G E N T C I R C U I T C I R C U I T 5 0 1 0 5 0 7 0 5 0 7 2 S E N S O R L O A N A C T I O N S 5 0 0 4 5 0 3 0 E N V I R O N M E N T A L 5 0 6 2 D A T A C O L L A T E R A L 5 0 1 2 L O A N E V E N T S C O L L A T E R A L L O A N S 5 0 3 2 5 0 0 2 D A T A S E N S O R D A T A SMART CONTRACT 5 0 7 4 5 0 1 4 5 0 9 0 C O N T R O L L E R 5 0 2 2 5 0 2 4 2 9 / 8 9 COLLATERAL TERMS & C O N D I T I O N S 5 0 1 8 DISTRIBUTED LEDGER I O T C I R C U I T L O A N E N T R Y 5 0 2 0 5 0 4 1 5 0 6 3ENTITIES/PARTIES B O R R O W E R L E N D E R M A R K E T P L A C E 5 0 4 0 5 0 4 2 I N F O R M A T I O N SOCIAL NETWORK I N F O R M A T I O N P R I C I N G 3 R D P A R T Y C O L L A T E R A L / 5 0 5 0 B L O C K C H A I N 5 0 4 4 E Q U I P M E N T P C T / U S 2 0 1 9 / 0 5 8 6 4 7 FINANCIAL CONDITION FINANCIAL DATA D A T A 5 0 6 0 5 0 9 2 5 0 5 4 5 0 3 4 5 0 3 8 5 0 5 8 5 0 4 8 F I G . 5 0","['G06Q10/04', 'G06Q20/202', 'G06Q20/389', 'G06Q30/02', 'G06Q40/03', 'G06Q50/06', 'H04L9/50', 'G06Q2220/00', 'Y02P90/90']"
CN110515811B,Terminal artificial intelligence performance benchmark test method and device,"The invention provides a terminal artificial intelligence performance benchmark test method and a device, wherein the method comprises the following steps: identifying at least one AI computing frame adapted by the terminal and providing the at least one AI computing frame to the user; receiving a test instruction fed back by a user, wherein the test instruction comprises an AI computing frame selected by the user from the at least one AI computing frame and a test item designated by the user; determining a neural network model to be tested according to an AI computing framework selected by a user, and determining a reference test reasoning set according to a test item designated by the user; forming a reference test case by the neural network model and the reference test reasoning set; and operating the reference test case on the terminal by using the AI computing framework selected by the user, and monitoring the operation result and the terminal hardware performance index in the test process. The invention enables the terminal to automatically identify, detect and adapt to a plurality of AI computing frames, monitor the hardware performance index of the terminal, and evaluate the artificial intelligence performance of the terminal from the whole machine angle.","['G06F11/3409', 'G06F11/3447']"
US11682198B2,Methods and systems for facial recognition using motion vector trained model,Systems and methods are provided for determining a candidate identity of a person in video data based on a biometric motion signature corresponding to motion of a face of the person in the video data. Motion information is obtained corresponding to motion of the face in the video data. The motion information is provided as input to a neural network and the neural network generates the biometric motion signature in response. The biometric motion signature is compared with a plurality of biometric signatures stored in data storage. The candidate identity of the person is determined as a result of a correspondence between the biometric motion signature and a stored biometric signature of the plurality of biometric signatures.,"['G06V10/82', 'G06F18/214', 'G06F21/32', 'G06N3/04', 'G06N3/08', 'G06V20/46', 'G06V30/19173', 'G06V40/168', 'G06V40/172', 'G06V40/20', 'G06V40/40']"
US10331490B2,Scalable cloud-based time series analysis,"Timestamped data can be read in parallel by multiple grid-computing devices. The timestamped data, which can be partitioned into groups based on time series criteria, can be deterministically distributed across the multiple grid-computing devices based on the time series criteria. Each grid-computing device can sort and accumulate the timestamped data into a time series for each group it receives and then process the resultant time series based on a previously distributed script, which can be compiled at each grid-computing device, to generate output data. The grid-computing devices can write their output data in parallel. As a result, vast amounts of timestamped data can be easily analyzed across an easily expandable number of grid-computing devices with reduced computational expense.","['G06F9/5016', 'G06F9/5072', 'G06F9/5083', 'G06F9/542', 'H04L67/10', 'G06F8/41']"
US20190385170A1,Automatically-Updating Fraud Detection System,The system may be configured to perform operations including receiving a transaction authorization request comprising transaction details; inputting the transaction details into a fraud scoring system comprising a fixed fraud detection model; inputting the transaction details into a neural network comprising an improvable fraud detection model; applying the fixed fraud detection model and the improvable fraud detection model to the transaction details; producing a fraud score in response to applying the fixed fraud detection model to the transaction details and a neural network fraud score in response to applying the improvable fraud detection model to the transaction details; analyzing the fraud score and the neural network fraud score; and/or sending an authorization response in response to analyzing the fraud score and the neural network fraud score.,"['G06Q20/4016', 'G06N3/08', 'G06N7/01']"
US10956987B2,Applying multi-dimensional variables to determine fraud,"The systems and methods herein may include receiving a plurality of transactions for a plurality of consumers, wherein each respective transaction of the plurality of transactions is between a consumer of the plurality of consumers and a merchant of a plurality of merchants; automatically inputting the plurality of transactions into a neural network; automatically analyzing the plurality of transactions over a plurality of iterations, wherein an iteration of the plurality of iterations comprises cycling through a consumer transaction history associated with the consumer, wherein the consumer transaction history has a consumer transaction sequence associated with the consumer; and automatically updating over the plurality of iterations, a previous fraud detection variable associated with the consumer and/or the merchant to generate updated fraud detection variables, in response to the analyzing the plurality of transactions.","['G06Q40/12', 'G06N3/08', 'G06N3/084']"
CN108267172B,Intelligent robot inspection system for mine,"The invention discloses a mining intelligent robot inspection system and a method, wherein the mining intelligent robot inspection system comprises a track circulating rotation subsystem, a robot perception subsystem, a wireless charging subsystem and a remote control and deep learning subsystem; the track circulating rotation subsystem is used for driving the robot sensing subsystem to rotate around the track in a circulating manner; the robot perception subsystem is used for detecting and communicating the surrounding environment; the remote control and deep learning subsystem is used for receiving the detected data and sending a control command to the track circulation rotation subsystem and the robot perception subsystem. According to the technical scheme, on the premise of meeting the coal mine explosion-proof standard, according to the collection of the environmental parameters, the unknown risk is predicted by utilizing deep learning, and the robot inspection system is controlled by utilizing remote control, so that automatic wireless charging is realized, the production safety is improved, and the reliability of the inspection process is ensured.","['G01D21/02', 'G05B19/0428', 'G05D1/02', 'G05B2219/2612']"
US11783170B2,Spatially sparse neural network accelerator for multi-dimension visual analytics,"Systems, apparatuses and methods may provide for technology that decodes data via an instruction that indicates a number of rulebooks to be processed, an input feature size, an output feature size, and a plurality of feature map base addresses, rearranges spatially distributed voxel output feature maps in the decoded data based on weight planes, and performs a channel-wise multiply-accumulate (MAC) operation on the rearranged spatially distributed voxel output feature maps to obtain an output, wherein the channel-wise MAC operation is performed as partial accumulations by a plurality of processing elements.","['G06N3/063', 'G06F18/2136', 'G06F18/253', 'G06F7/5443', 'G06N3/04', 'G06N3/045', 'G06N5/022', 'G06T1/60', 'G06V10/955', 'G06V20/64']"
CN114041161A,Method and device for training neural network model for enhancing image details,A neural network model training device for enhancing image details is provided. The apparatus comprises a memory and at least one processor configured to: obtaining low-quality input image blocks and high-quality input image blocks; obtaining low-quality output image patches by inputting the low-quality input image patches to a first neural network model; obtaining high quality output image patches by inputting the high quality input image patches to a second neural network model; and training the first neural network model based on a loss function arranged to reduce a difference between the low-quality output image patch and the high-quality input image patch and a difference between the high-quality output image patch and the high-quality input image patch. The second neural network model is the same as the first neural network model.,"['G06T3/4053', 'G06T5/70', 'G06F18/214', 'G06N3/045', 'G06N3/048', 'G06N3/084', 'G06T3/4046', 'G06T5/60', 'G06T5/73', 'G06V10/764', 'G06V10/774', 'G06V10/82', 'G06T2207/20081', 'G06T2207/20084']"
CN111002980B,Road obstacle trajectory prediction method and system based on deep learning,"The invention provides a track prediction method of a road obstacle based on deep learning, which comprises the following steps: collecting vehicle information, obstacle information around the vehicle and road information; converting vehicle information, obstacle information around the vehicle and road information into a Frenet coordinate system, and setting a record cache in the Frenet coordinate system; adding the vehicle information, the road information and the cached obstacle information around the vehicle to a database to obtain an image training data set; inputting the samples in the image training data set into a deep neural network model to generate an obstacle trajectory prediction model; the motion trajectory of an obstacle around the vehicle is predicted using the prediction model. The training sample acquired by the method is more real, and the movement track of the obstacles around the vehicle can be predicted more accurately based on the obstacle information with constantly changing road conditions; in addition, the obstacle trajectory prediction model obtained by the method is not single.","['B60W30/09', 'G06F18/214', 'G06V20/58']"
WO2021115159A1,"Character recognition network model training method, character recognition method, apparatuses, terminal, and computer storage medium therefor","A character recognition network model training method, a character recognition method, apparatuses, a terminal, and a computer storage medium therefor. The character recognition method comprises: standardizing a picture to be tested, and scaling same to a preset height H and a preset width W (A100); inputting said picture into a convolutional neural network, and extracting a convolutional feature of said picture, so as to obtain a depth feature map that includes the convolutional feature (A200); inputting the depth feature map into an attention mechanism module provided with multiple channels to obtain an attention weight of each channel, and rescaling each channel of the depth feature map by using the attention weight to obtain multiple attention feature maps (A300); respectively inputting each of the attention feature maps into a fully connected layer to obtain multiple attention feature vectors (A400); and performing feature fusion on the multiple attention feature vectors, and inputting same into a character category fully connected layer to perform character category prediction (A500).","['G06V30/413', 'G06F18/214', 'G06F18/253', 'G06V10/32', 'G06V30/10']"
US11816987B2,Emergency response vehicle detection for autonomous driving applications,"In various examples, audio alerts of emergency response vehicles may be detected and classified using audio captured by microphones of an autonomous or semi-autonomous machine in order to identify travel directions, locations, and/or types of emergency response vehicles in the environment. For example, a plurality of microphone arrays may be disposed on an autonomous or semi-autonomous machine and used to generate audio signals corresponding to sounds in the environment. These audio signals may be processed to determine a location and/or direction of travel of an emergency response vehicle (e.g., using triangulation). Additionally, to identify siren types—and thus emergency response vehicle types corresponding thereto—the audio signals may be used to generate representations of a frequency spectrum that may be processed using a deep neural network (DNN) that outputs probabilities of alert types being represented by the audio data. The locations, direction of travel, and/or siren type may allow an ego-vehicle or ego-machine to identify an emergency response vehicle and to make planning and/or control decisions in response.","['G08G1/0965', 'B60R11/0247', 'G06F18/2414', 'G06F18/2415', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/048', 'G06N3/08', 'G08B21/182', 'G08G1/096708', 'G10L19/02', 'G10L21/0208', 'G10L25/30', 'G10L25/51', 'H04R3/005', 'H04R2201/405', 'H04R2410/07', 'H04R2430/20', 'H04R2430/23', 'H04R2499/13']"
US11170543B2,MRI image reconstruction from undersampled data using adversarially trained generative neural network,A method of magnetic resonance imaging acquires undersampled MRI data and generates by an adversarially trained generative neural network MRI data having higher quality without using any fully-sampled data as a ground truth. The generative neural network is adversarially trained using a discriminative neural network that distinguishes between undersampled MRI training data and candidate undersampled MRI training data produced by applying an MRI measurement function containing an undersampling mask to generated MRI training data produced by the generative neural network from the undersampled MRI training data.,"['G01R33/5608', 'G06T11/006', 'G01R33/561', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'G06T5/10', 'G06N3/048', 'G06N3/084', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/41']"
US11577722B1,Hyper planning based on object and/or region,"A vehicle computing system may implement techniques to predict behavior of objects detected by a vehicle operating in the environment. The techniques may include determining a feature with respect to a detected objects (e.g., likelihood that the detected object will impact operation of the vehicle) and/or a location of the vehicle and determining based on the feature a model to use to predict behavior (e.g., estimated states) of proximate objects (e.g., the detected object). The model may be configured to use one or more algorithms, classifiers, and/or computational resources to predict the behavior. Different models may be used to predict behavior of different objects and/or regions in the environment. Each model may receive sensor data as an input, and output predicted behavior for the detected object. Based on the predicted behavior of the object, a vehicle computing system may control operation of the vehicle.","['G06V10/82', 'B60W30/0956', 'B60W50/0097', 'B60W60/00274', 'G05D1/0088', 'G05D1/0238', 'G06V20/56', 'G06V20/58', 'G06V40/161', 'G06V40/18', 'G06V40/28', 'B60W2050/0028', 'B60W2554/4029', 'B60W2554/4041', 'B60W2554/4042', 'B60W2554/4044', 'B60W2554/4045', 'B60W2554/4046', 'G05D2201/0213']"
US11670141B1,Cashierless system using deep learning processing of hand scan biometric feature data for labeling an identity of a tracked shopper,"A cashierless tracking system uses a biometric sensor disposed at the entry of a store or the entry of a shelf or an entry to a section of a store is configured to capture biometric feature aspects of a user. Cashierless shopping is enabled without requiring a user to supply mobile phone or device to identify themselves. Instead, processing and classification of biometric features occur via a neural network to identify at least one label representing classified features of the user, the label being used to identify a profile for the user. A plurality of sensors in the store produces data to identify a take of an item by a single user or by a group of users tied to a single account. Included tracking embodiments involve overlapping cameras, skeletal tracking, microphone input, feature extraction and/or feature engineering. The take of the item is chargeable to an electronic shopping cart of the user. Items may be charged or accounted for in relation to user activity, store membership, subscription, entitlement, direct debit, etc.","['G07G1/0072', 'G06Q20/12', 'G06Q20/327', 'G06Q30/0633', 'G06Q30/0635', 'H02N11/002', 'H04B1/3833', 'H04L67/10', 'H04W4/70', 'H04W4/80', 'H04W76/10', 'H04W76/14', 'H04B1/1607', 'H04L67/12', 'H04L67/125', 'H04W4/50', 'H04W84/12', 'H04W88/02', 'H04W88/06', 'Y02D30/70', 'Y04S40/18']"
US12164142B2,Communication systems having optical power supplies,"A system includes a housing including a front panel, a rear panel, an upper panel, and a lower panel. The system includes a first circuit board or substrate, at least one data processor coupled to the first circuit board or substrate and configured to process data, and at least one optical module coupled to the first circuit board or substrate. Each optical module is configured to perform at least one of (i) convert input optical signals to electrical signals that are provided to the at least one data processor, or (ii) convert electrical signals received from the at least one data processor to output optical signals. The system includes at least one inlet fan mounted near the front panel and configured to increase an air flow across a surface of at least one of (i) the at least one data processor, (ii) a heat dissipating device thermally coupled to the at least one data processor, (iii) the at least one optical module, or (iv) a heat dissipating device thermally coupled to the at least one optical module. The system includes at least one laser module configured to provide optical power to the at least one optical module.","['G02B6/428', 'G02B6/0085', 'G02B6/262', 'G02B6/3885', 'G02B6/4206', 'G02B6/4257', 'G02B6/4261', 'G02B6/4269', 'G02B6/4292', 'H04B10/503']"
US12344979B2,Jeans with laser finishing patterns created by neural network,"Software and lasers are used in finishing apparel to produce a desired wear pattern or other design. A technique includes using machine learning to create or extract a laser input file for wear pattern from an existing garment. Machine learning can be by a generative adversarial network, having generative and discriminative neural nets. The generative adversarial network is trained and then used to create a model. This model is used generate the laser input file from an image of the existing garment with the finishing pattern. With this laser input file, a laser can re-create the wear pattern from the existing garment onto a new garment.","['D06B11/0096', 'A41B1/08', 'A41D1/02', 'A41D1/04', 'A41D1/089', 'A41D1/14', 'A41D27/00', 'A41D27/08', 'A41D3/00', 'A41H43/00', 'B23K26/36', 'D03D1/00', 'D03D15/43', 'D06C23/02', 'D06M10/00', 'D06M10/005', 'D06P5/15', 'D06P5/2011', 'G06F18/214', 'G06N3/002', 'G06N3/02', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06N3/088', 'A41B2500/20', 'A41D1/06', 'A41D2500/20', 'D06P1/228', 'D10B2501/04']"
US10621779B1,Artificial intelligence based generation and analysis of 3D models,Artificial intelligence based techniques are used for analysis of 3D objects in conjunction with each other. A 3D model of two or more 3D objects is generated. Features of 3D objects are matched to develop a correspondence between the 3D objects. Two 3D objects are geometrically mapped and an object is overlayed on another 3D object to obtain a superimposed object. Match analysis of 3D objects is performed based on machine learning based models to determine how well the objects are spatially matched. The analysis of the objects is used in augmented reality applications.,"['G06T17/00', 'G06F18/214', 'G06F18/22', 'G06F18/253', 'G06K9/6256', 'G06K9/629', 'G06N3/045', 'G06N3/08', 'G06N5/00', 'G06T7/50', 'G06T7/62', 'G06V10/761', 'G06V10/7715', 'G06V10/82', 'G06V20/20', 'G06V20/653', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30196']"
US12316535B2,Methods and systems for infrastructureless communication networks,"Embodiments of the present invention may provide a decentralized infrastructure including efficient wireless communication, an infrastructureless communication network, a decentralized private network, securely communicating in a decentralized network perhaps using distributed ledger technology (62), named data networking (63), neural networks (85), or the like. Further embodiments may include consensus processing (150), dynamic smart contracts (151), universal artificial neural network multiplex asset class (3), and perhaps even an artificial neural network multiplex identification system.","['H04L45/44', 'H04L41/122', 'H04W28/084']"
CN112446429B,CGAN (Carrier grade Access network) -based routing inspection image data small sample expansion method,"The invention relates to a routing inspection image data small sample expansion method based on CGAN. Firstly, collecting inspection images, judging defect types corresponding to the inspection images, marking, and using an abnormal detection algorithm to remove abnormal images in an inspection image data set; then, preprocessing the cleaned inspection image data set by using a traditional image processing algorithm, and then training a condition based on a convolutional neural network by using the inspection image data set to generate a countermeasure network so as to obtain a CGAN model capable of generating inspection image data with a given defect type; secondly, sampling and generating a large amount of inspection image data by using a generator of the trained CGAN model; and screening the generated images with the truth degrees larger than a given truth degree threshold value according to the image truth degrees output by the discriminator, and adding the screened images into the inspection image data set to obtain an expanded inspection image data set.","['G06F18/2411', 'G06F18/214', 'G06N3/045', 'G06N3/08']"
US11449771B2,Systems and methods for processing vehicle data,"Systems and methods include accessing streams of sensor data; constructing a corpus of seed sample data; initializing a first instance of a trained model using the corpus of seed sample data that: generates predictions of predicted sensor values; computing error values based on calculated differences between the actual sensor values and the predicted sensor values; transmitting the computed error values; initializing a second instance of the trained model based on an input of the corpus of the seed sample data, wherein the second instance of the trained model is identical to the first instance of the trained model, and wherein the second instance: generates inferences of predicted sensor values for each of the sensors based on the input of the corpus of seed sample data; reconstructing estimates of the actual sensor values based on a reconstruction computation with the parallel predicted sensor values and the error values.","['G06N5/04', 'H03M7/3073', 'G06N20/00', 'G06N20/20', 'G07C5/008', 'G07C5/0808', 'H03M7/30', 'H03M7/6023', 'G06N20/10', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G06N5/01', 'G06N5/025', 'G06N7/01', 'H04N19/136', 'H04N19/162']"
US11610139B2,System and method for the latent space optimization of generative machine learning models,"A system and method for optimizing the latent space in generative machine learning models, and applications of the optimizations for use in the de novo generation of molecules for both ligand-based and pocket-based generation. The ligand-based optimizations comprise a tunable reward system based on a multi-property model and further define new measurable metrics: molecular novelty and uniqueness. The pocket-based optimizations comprise an initial multi-property optimization followed up by either a seed-based optimization or a relaxed-based optimization.","['G06N3/088', 'G06F16/951', 'G06F18/22', 'G06K9/6215', 'G06N3/0442', 'G06N3/045', 'G06N3/0455', 'G06N3/047', 'G06N3/0475', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/092', 'G06N5/022', 'G06N7/01', 'G06V10/751', 'G06V10/82', 'G16B15/00', 'G16B15/30', 'G16B40/00', 'G16B40/20', 'G16B45/00', 'G16B50/10', 'G16C20/50', 'G16C20/70', 'G06N3/044', 'G06N3/048', 'G06N3/096', 'G16C20/30', 'G16C20/90']"
US11561540B2,Augmenting autonomous driving with remote viewer recommendation,"Autonomous vehicles are an exciting prospect to the future of driving. However, concerns about the decision-making made by the AI controlling a vehicle has been of concern, particularly in light of high-profile accidents. We can alleviate some concern, introduce better decisions, and also train an AI to make better decisions by introducing a remote viewer's, e.g., a human's, reaction to a possibly complex environment surrounding a vehicle that includes a potential threat to the vehicle. One or more remote viewer may provide a recommended response to the threat that may be incorporated in whole or in part in how the vehicle reacts. Various ways to engage and utilize remote viewers are proposed to improve the likelihood of receiving useful recommendations, including modifying how the environment is presented to a remote viewer to best suit the remote viewer, e.g., perhaps present the threat in a game.","['G08G1/16', 'G05D1/0088', 'B60W30/09', 'B60W40/02', 'B60W50/00', 'B60W60/0015', 'B60W60/00274', 'G05D1/0033', 'G05D1/0038', 'G05D1/0214', 'G05D1/0221', 'G05D1/222', 'G05D1/223', 'G05D1/228', 'G05D1/617', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'B60W2050/0002', 'G05D2201/0213']"
US11521389B2,"Method for generating special effect program file package, method for generating special effect, electronic device, and storage medium","A method for generating a special effect program file package and a method for generating a special effect are provided. The method for generating a special effect program file package includes: importing a sub-material; obtaining a parameter value of a playback parameter of the sub-material and establishing a correspondence between a display position of the sub-material and at least one predetermined key point; and generating a special effect program file package according to the sub-material, the correspondence and the parameter value. The method for generating a special effect includes: importing a special effect program file package; obtaining a parameter value of a playback parameter of a sub-material in the special effect program file package; performing key point detection on a video image; and generating a special effect of the sub-material on the video image based on the detected key point and the parameter value of the playback parameter.","['H04L67/131', 'G06V40/176', 'G06T11/60', 'G06F18/2413', 'G06F3/01', 'G06F8/38', 'G06T13/00', 'G06V10/462', 'G06V10/764', 'G06V10/82', 'G06V20/46', 'G06V40/103', 'G06V40/107', 'G06V40/165', 'G06V40/20']"
CN111292337B,"Image background replacement method, device, equipment and storage medium","The embodiment of the invention discloses an image background replacement method, an image background replacement device, image background replacement equipment and a storage medium. The method comprises the following steps: acquiring a current video frame, and selecting a target portrait area in the current video frame; acquiring an initial mask corresponding to a target portrait area of the current video frame; performing segmentation optimization treatment and inter-frame smoothing treatment on the initial mask to obtain a target mask; and replacing the background of the current video frame with a new background according to the target mask, and generating a synthesized frame corresponding to the current video frame. According to the technical scheme, the calculated amount of the portrait segmentation of the real-time video is reduced, the portrait segmentation precision is improved, and the portrait background replacement of the real-time video is realized.","['G06T7/11', 'G06T5/50', 'G06T7/194', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/20221', 'G06T2207/30196']"
CN112269769B,"Data compression method, device, computer equipment and storage medium","The application relates to a data compression method, a data compression device, computer equipment and a storage medium, in particular to the field of data processing. The method comprises the following steps: acquiring target data; according to the compressed data information corresponding to the ith-1 target data segment, updating the compression parameters corresponding to the ith-1 target data segment through a parameter updating model to obtain the compression parameters corresponding to the ith target data segment; the parameter updating model is obtained by a reinforcement learning mode according to the historical compression parameters and the compression data information corresponding to the historical compression parameters; and carrying out data compression on the ith target data segment according to the compression parameters corresponding to the ith target data segment. According to the scheme, the parameter updating model is updated according to the historical compression parameters and the compression information corresponding to the historical compression parameters through the artificial intelligence technology, and the compression parameters are adjusted through the updated parameter updating model, so that the compression efficiency is improved under the condition that the compression accuracy is ensured.","['G06F16/1744', 'G06F16/16', 'Y02D10/00']"
US12322249B2,Management system,"A management system includes a card distributing device configured to determine a win/loss result of a game using chips on a game table, a dealer chip determining device that specifies type and the number of chips held in a chip tray, a measuring device that measures position, type, and the number of chips on the game table, and a management control device that has a function of transmitting a signal or performing display on a display device depending on a comparison result between a collection amount and an increase amount and a comparison result between a payment amount and a decrease amount, and changes the signal or an output content of the display depending on a content of inconsistency when the inconsistency is determined in the comparison results.","['G07F17/3248', 'A63F1/06', 'A63F3/00157', 'G07F17/3206', 'G07F17/3209', 'G07F17/322', 'G07F17/3225', 'G07F17/3234', 'G07F17/3237', 'G07F17/3241', 'G07F17/3244', 'G07F17/3276', 'G07F17/3293']"
US11967074B2,Method and system for computer-aided triage,"A system for computer-aided triage can include a router, a remote computing system, and a client application. A method for computer-aided triage can include determining a parameter associated with a data packet, determining a treatment option based on the parameter, and transmitting information to a device associated with a second point of care.","['G06T7/0012', 'A61B5/4064', 'G06T7/11', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H50/20', 'G16H80/00', 'H04L67/12', 'A61B5/002', 'A61B5/02007', 'A61B5/7264', 'G06T2207/10016', 'G06T2207/10081', 'G06T2207/10088', 'G06T2207/20072', 'G06T2207/20076', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30016', 'G06T2207/30101', 'G06T2207/30172']"
JP2021182442A,How to detect falsification of ID card,"To provide a method, computer-readable storage device, storage medium, and system for detecting digital or physical tampering of imaged physical credentials.SOLUTION: A method for a system provided herein comprises: receiving a digital image representing a physical credential having one or more high value regions, the digital image including an array of pixels; processing the digital image with a tamper detector to generate an output corresponding to an intrinsic characteristic of the digital image, the tamper detector being configured to perform a pixel-level analysis of the high value regions of the digital image with respect to a predetermined tampering signature; and determining, based on the output from the tamper detector, whether the digital image has been digitally tampered with.SELECTED DRAWING: Figure 8","['G06V30/40', 'G06F18/24', 'G06V10/225', 'G06V10/993', 'G06V30/412']"
US11501171B2,Method and platform for pre-trained language model automatic compression based on multilevel knowledge distillation,"Disclosed are an automatic compression method and platform for a pre-trained language model based on multilevel knowledge distillation. The method includes the following steps: step 1, constructing multilevel knowledge distillation, and distilling a knowledge structure of a large model at three different levels: a self-attention unit, a hidden layer state and an embedded layer; step 2, training a knowledge distillation network of meta-learning to generate a general compression architecture of a plurality of pre-trained language models; and step 3, searching for an optimal compression structure based on an evolutionary algorithm. Firstly, the knowledge distillation based on meta-learning is studied to generate the general compression architecture of the plurality of pre-trained language models; and secondly, on the basis of a trained meta-learning network, the optimal compression structure is searched for via the evolutionary algorithm, so as to obtain an optimal general compression architecture of the pre-trained language model independent of tasks.","['G06F40/30', 'G06F16/35', 'G06F40/40', 'G06N3/045', 'G06N3/082', 'G06N3/086', 'G06N3/047', 'G06N3/084']"
CN111508498B,"Conversational speech recognition method, conversational speech recognition system, electronic device, and storage medium","The invention relates to the technical field of voice recognition, and provides a conversational voice recognition method, a conversational voice recognition system, electronic equipment and a storage medium. The conversational speech recognition method includes: the method comprises the steps of obtaining double-channel audio of conversational voice, compressing, restoring and separating the double-channel audio to obtain single-channel original audio; carrying out frame division processing on the original audio to obtain a plurality of audio frames, and cutting the original audio according to the energy of each audio frame to obtain a plurality of effective audio segments; extracting mel cepstrum features and tone features of the effective audio segment and speaker features of a channel in which the effective audio segment is located, inputting a voice recognition model, and obtaining a recognition result of the effective audio segment; and generating a voice recognition result of the original audio according to the recognition result of each effective audio segment. The invention can realize the accurate cutting of the two-channel conversational voice and accurately recognize the conversational voice under the condition of shielding surrounding noise.","['G10L15/02', 'G10L15/04', 'G10L15/144', 'G10L25/78', 'Y02D30/70']"
WO2022151931A1,"Speech synthesis method and apparatus, synthesis model training method and apparatus, medium, and device","A speech synthesis method and apparatus (600), a synthesis model training method and apparatus (700), a medium, and a device (800). The speech synthesis method comprises: obtaining speech feature information corresponding to text to be synthesized (S101); inputting the speech feature information into a speech synthesis model to obtain predicted waveform point information corresponding to said text (S102), the speech synthesis model comprising an acoustic submodel and a vocoder, and the speech synthesis model being obtained by directly performing joint training on the acoustic submodel and the vocoder; and performing μ-law expansion on the predicted waveform point information to obtain audio information (S103). By this way, the efficiency of speech synthesis can be improved, the error accumulation in related art generated by training an acoustic submodel and a vocoder separately is effectively reduced, and the accuracy of speech synthesis is improved. In addition, the problem that generated audio information cannot adapt to special pronunciation requirements due to the fact that acoustic features do not have universality can also be avoided, and the speech synthesis effect is improved. Additionally, a training period of models is short, and the rhythm fidelity of the models is better.","['G10L13/04', 'G10L25/03', 'G10L25/30']"
US10911266B2,Machine learning for channel estimation,"Systems and methods are disclosed for performing training using superimposed pilot subcarriers to determine training data. The training includes starting with a training duration (T) equal to a number of antennas (M) and running a Convolutional Neural Network (CNN) model using training samples to determine if a testing variance meets a predefined threshold. When the testing variance meets a predefined threshold, then reducing T by one half and repeating the running Convolutional Neural Network (CNN) model until the testing variance fails to meet the predefined threshold. When the testing variance fails to meet the predefined threshold, then multiplying T by two and using the new value of T as the new training duration to be used. Generating a run-time model based on the training data, updating the run-time model with new feedback data received from a User Equipment (UE), producing a DL channel estimation from the run-time model; and producing an optimal precoding matrix from the DL channel estimation.","['H04L25/0254', 'H04L25/0204', 'H04L25/0224', 'H04L25/0256', 'H04B7/0413', 'H04W24/00']"
US10833751B2,Facilitation of user equipment specific compression of beamforming coefficients for fronthaul links for 5G or other next generation network,"Precoding coefficients can be compressed based on user equipment signal interference to noise ratio or path loss in front haul cloud radio access network systems. For example, a baseband unit can compute a precoder matrix from an estimated channel associated with an uplink signal. Once the baseband unit computes the channel, it can determine the coefficients for the linear combination of the basis vectors, which are known at the baseband unit and the radio unit as well. The baseband unit can estimate the path loss and the signal interference to noise ratio and determine the basis vectors. The baseband unit can then compress the coefficients and transmit the coefficients to the radio unit. When the radio unit receives the compressed coefficients, the radio unit can reconstruct the precoder matrix and apply to reference signals and data traffic channels.","['H04B7/0478', 'H04B7/043', 'H04B7/0456', 'H04B7/0626', 'H04B7/0658', 'H04B7/0663', 'H04B7/0857', 'H04L25/00', 'H04L25/0224', 'H04L25/03343', 'H04L25/0391', 'H04W52/242', 'H04B17/336', 'H04W72/0413', 'H04W72/21']"
CN111488489B,"Video file classification method, device, medium and electronic equipment","The application provides a video file classification method, a video file classification device, a computer readable storage medium and electronic equipment; relates to the technical field of video processing; comprising the following steps: when the uploaded video file is detected, descriptive information and user information corresponding to the video file are acquired, and the video file is decoded to obtain corresponding audio content and a video frame set; text recognition is carried out on the audio content to obtain text information corresponding to the audio content, and word segmentation is carried out on the text information and the description information to obtain word segmentation sets; generating a first classification result corresponding to the video file according to the video frame set and the word segmentation set, generating a second classification result corresponding to the video file according to the audio content, and generating a third classification result corresponding to the video file according to the user information; and classifying the video files according to the classification result. The method can identify the video file through the multidimensional information of the video file so as to improve the identification accuracy of the video file.","['G06F16/75', 'G06F16/783']"
US20210315580A1,"Method of hub communication, processing, display, and cloud analytics","A method of displaying an operational parameter of a surgical system is disclosed. The method includes receiving, by a cloud computing system of the surgical system, first usage data, from a first subset of surgical hubs of the surgical system; receiving, by the cloud computing system, second usage data, from a second subset of surgical hubs of the surgical system; analyzing, by the cloud computing system, the first and the second usage data to correlate the first and the second usage data with surgical outcome data; determining, by the cloud computing system, based on the correlation, a recommended medical resource usage configuration; and displaying, on respective displays on the first and the second subset of surgical hubs, indications of the recommended medical resource usage configuration.","['H04L67/10', 'A61B1/00009', 'A61B1/000096', 'A61B1/00011', 'A61B1/00045', 'A61B1/00059', 'A61B1/051', 'A61B1/0661', 'A61B17/0206', 'A61B17/0682', 'A61B17/072', 'A61B17/07207', 'A61B17/1155', 'A61B17/1285', 'A61B17/320092', 'A61B18/1442', 'A61B18/1445', 'A61B34/10', 'A61B34/20', 'A61B34/25', 'A61B34/32', 'A61B34/71', 'A61B5/0066', 'A61B5/0075', 'A61B5/0261', 'A61B6/5247', 'A61B90/35', 'A61B90/361', 'A61B90/90', 'A61B90/94', 'A61B90/96', 'A61B90/98', 'A61M1/73', 'A61M1/79', 'B25J13/006', 'B25J9/1689', 'B25J9/1697', 'G06K19/07749', 'G06K7/10316', 'G16H10/60', 'G16H20/40', 'G16H40/20', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H70/20', 'H01Q1/22', 'H04L63/1416', 'H04L67/12', 'H04N23/555', 'H04N5/272', 'H04N7/183', 'H05K1/028', 'H05K1/189', 'A61B17/1114', 'A61B2017/00017', 'A61B2017/00022', 'A61B2017/00026', 'A61B2017/0003', 'A61B2017/00039', 'A61B2017/00044', 'A61B2017/00057', 'A61B2017/00061', 'A61B2017/00075', 'A61B2017/00084', 'A61B2017/00097', 'A61B2017/00106', 'A61B2017/0011', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/00128', 'A61B2017/00199', 'A61B2017/00203', 'A61B2017/00207', 'A61B2017/00221', 'A61B2017/00225', 'A61B2017/00398', 'A61B2017/00402', 'A61B2017/0046', 'A61B2017/00473', 'A61B2017/00734', 'A61B2017/00809', 'A61B2017/00818', 'A61B2017/00973', 'A61B2017/07228', 'A61B2017/07235', 'A61B2017/07257', 'A61B2017/07271', 'A61B2017/07278', 'A61B2017/07285', 'A61B2017/1132', 'A61B2017/32007', 'A61B2017/320074', 'A61B2017/320084', 'A61B2017/320095', 'A61B2017/320097', 'A61B2018/00541', 'A61B2018/00589', 'A61B2018/00595', 'A61B2018/00601', 'A61B2018/00607', 'A61B2018/0063', 'A61B2018/00642', 'A61B2018/00684', 'A61B2018/00791', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00988', 'A61B2018/00994', 'A61B2018/1253', 'A61B2018/126', 'A61B2018/1273', 'A61B2034/105', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/256', 'A61B2034/301', 'A61B2034/305', 'A61B2090/064', 'A61B2090/066', 'A61B2090/0803', 'A61B2090/0804', 'A61B2090/0808', 'A61B2090/0809', 'A61B2090/0811', 'A61B2090/309', 'A61B2090/365', 'A61B2090/371', 'A61B2090/3966', 'A61B2217/005', 'A61B2217/007', 'A61B2218/002', 'A61B2218/007', 'A61B2218/008', 'A61B34/30', 'A61B34/37', 'A61B5/021', 'A61B90/30', 'A61M1/80', 'A61M13/003', 'A61M2205/18', 'A61M2205/3306', 'A61M2205/3327', 'A61M2205/3331', 'A61M2205/3365', 'A61M2205/3368', 'A61M2205/3553', 'A61M2205/50', 'A61M2205/502', 'A61M2230/205', 'G05B2219/40174', 'G05B2219/45119', 'H04L67/1097']"
CN110473538B,Detecting triggering of a digital assistant,"The present disclosure relates to detecting a trigger of a digital assistant. Systems and processes for operating intelligent automated assistants are provided. According to one example, a method includes: at an electronic device having one or more processors, memory, and a plurality of microphones, sampling an audio signal at each of the plurality of microphones of the electronic device to obtain a plurality of audio signals; processing the plurality of audio signals to obtain a plurality of audio streams; and determining whether any of the plurality of audio signals corresponds to a voice trigger based on the plurality of audio streams. The method further comprises the steps of: in accordance with a determination that the plurality of audio signals correspond to the voice trigger, initiating a session of the digital assistant; and in accordance with a determination that the plurality of audio signals do not correspond to the voice trigger, forgoing initiating a session of the digital assistant.","['G10L15/22', 'G10L15/28', 'G10L15/04', 'G10L15/08', 'G10L15/18', 'G10L15/30', 'G10L21/0216', 'H04R1/406', 'H04R3/00', 'H04R3/005', 'G10L15/1822', 'G10L2015/088', 'G10L2015/228', 'G10L2021/02166', 'G10L25/51', 'H04R2227/003', 'H04R2499/11', 'H04R27/00']"
CN112215337B,Vehicle track prediction method based on environment attention neural network model,"The invention discloses a vehicle track prediction method based on an environmental attention neural network model, which constructs a model for increasing attention to each element in the environment and an environmental attention network (EA-Net) model. The model provided by the invention is laterally expanded on the basis of the structure of the LSTM encoder-decoder connected in series with the convolution social pool, and a parallel structure is formed by the graphic annotation neural network and the convolution social pool containing the SE module. The invention captures the characteristic information updated by the continuous edges of all nodes in the graph structure formed by the vehicle and the surrounding environment in the running process and the characteristic information in the spatial position structure in the surrounding environment through the novel parallel structure. Compared with a convolution social pool model, the novel model structure provided by the invention has the advantages that the effect of extracting environment interaction information is greatly improved, and meanwhile, the track prediction effect better than that of other existing models is achieved.","['G06N3/045', 'G01C21/343', 'G01C21/3446', 'G06N3/044', 'G06N3/048', 'G06N3/08', 'G06T7/20', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30241']"
US11574097B2,Deep learning based identification of difficult to test nodes,"Techniques to improve the accuracy and speed for detection and remediation of difficult to test nodes in a circuit design netlist. The techniques utilize improved netlist representations, test point insertion, and trained neural networks.","['G06F30/327', 'G06F18/24', 'G06K9/6267', 'G06N3/0418', 'G06N3/045', 'G06N3/063', 'G06N3/084', 'G06N7/005', 'G06N7/01', 'G06V10/426', 'G06V10/764', 'G06V10/82', 'G06V10/955']"
US12411629B2,Virtual volume-based replication,"Synchronous replication between storage systems with virtualized storage includes: assigning a virtual volume datastore to a pod, the pod including a management object, the virtual volume datastore including virtual machine data; stretching the pod from a first storage system to a second storage system, including copying the virtual machine data from the first storage system to the second storage system; and synchronously replicating access operations of the virtual machine data of the pod between the first and second storage systems.","['G06F3/065', 'G06F3/0604', 'G06F3/067', 'G06F3/0688']"
US20230333926A1,Managing An Application's Resource Stack,"A method for managing an application's resource stack is disclosed. The method includes identifying, by a storage system, a root cause of an anomaly predicted at the external component that affects a performance of the storage system based on a relationship between metrics of the storage system and metrics of a component external to the storage system; and reconfiguring the external component based on the identified root cause.","['G06F11/1076', 'G06F11/0793', 'G06F11/0727', 'G06F11/0751', 'G06F11/079', 'G06F11/108', 'G06F11/1446', 'G06F11/3409', 'G06F9/45558', 'G06F9/4856', 'G06F11/2089', 'G06F11/3034', 'G06F11/3419', 'G06F2009/4557', 'G06F21/568', 'G06F2201/815', 'G06F2201/84', 'G06F2221/033']"
US11861235B2,Maximizing data throughput in a cloud-based storage system,"Maximizing data throughput in a cloud-based storage system, including: receiving a plurality of write operations directed to a cloud-based storage system; coalescing the plurality of write operations into one or more coalesced write operations, wherein each of the coalesced write operations are configured to effect two or more of the first plurality of write operations; and performing, based on a service tier associated with the cloud-based storage system, the plurality of coalesced write operations on the storage volume.","['G06F3/0659', 'G06F13/28', 'G06F3/061', 'G06F3/0616', 'G06F3/0638', 'G06F3/0656', 'G06F3/067', 'G06F3/0688', 'H04L67/566']"
US11888846B2,Configuring storage systems in a fleet of storage systems,"Secure cloud-based storage system management that includes: establishing, within a cloud-based services provider and based on one or more user credentials, a cloud-based user session to execute one or more commands on a remote storage system that includes physical storage devices; determining one or more data storage operations corresponding to the physical storage devices to implement the one or more commands on the storage system; and extending, based on using an access token based on the one or more user credentials to securely issue the one or more data storage operations to the remote storage system, the cloud-based user session to the remote storage system.","['H04L63/0853', 'G06F21/6218', 'H04L67/1097', 'H04L67/141']"
US12282686B2,Performing low latency operations using a distinct set of resources,"A first set of physical units of a storage device of a storage system is selected for performance of low latency access operations, wherein other access operations are performed by remaining physical units of the storage device. A determination as to whether a triggering event has occurred that causes a selection of a new set of physical units of the storage device for the performance of low latency access operations is made. A second set of physical units of the storage device is selected for the performance of low latency access operations upon determining that the triggering event has occurred.","['G06F3/0659', 'G06F11/2094', 'G06F11/0727', 'G06F11/0751', 'G06F11/1076', 'G06F11/108', 'G06F11/3409', 'G06F11/3419', 'G06F11/3485', 'G06F12/0804', 'G06F12/0866', 'G06F3/061', 'G06F3/0611', 'G06F3/0613', 'G06F3/0619', 'G06F3/0629', 'G06F3/0634', 'G06F3/0653', 'G06F3/0655', 'G06F3/0685', 'G06F3/0688', 'G06F11/3034', 'G06F11/3055', 'G06F2201/81', 'G06F2201/885', 'G06F2212/262', 'G06F2212/502']"
US12137140B2,Scale out storage platform having active failover,"A storage system that has blades and fabric modules connects to a customer legacy network that has a first, active switch and a second, passive switch. A first link aggregation group (LAG) is configured active and includes ports of the first, active switch that connect via links to the first and second fabric modules of the storage system. A second LAG is configured passive and includes ports of the second, passive switch that connect via links to the first and second fabric modules. A multi-chassis link aggregation group (MLAG, MCLAG or MC-LAG) is configured and includes ports of the first and second fabric modules that connect via links to the first and second switches.","['H04L45/245', 'G06F11/201', 'G06F11/2028', 'G06F11/2041', 'G06F11/2048', 'G06F11/2092', 'G06F12/0246', 'G06F3/0604', 'G06F3/0607', 'G06F3/061', 'G06F3/0611', 'G06F3/0613', 'G06F3/0635', 'G06F3/065', 'G06F3/0655', 'G06F3/0659', 'G06F3/067', 'G06F3/0688', 'G06F3/0689', 'G11C29/52', 'H03M13/154', 'H04L47/125', 'H04L49/10', 'H04L49/111', 'H04L49/15', 'H04L67/1097', 'H04L67/51', 'G06F11/108', 'G06F11/2089', 'G06F11/3034', 'G06F2201/805', 'G06F2201/845', 'G06F2212/7206', 'G06F2212/7207', 'H03M13/1102', 'H03M13/1515', 'H03M13/3761', 'Y02D30/50']"
US12135878B2,Programming frequently read data to low latency portions of a solid-state storage array,"A storage array controller may receive data to be programmed to a solid-state storage device of a plurality of solid-state storage devices. The storage array controller may identify a type of the data and determine whether to program the data to a low latency portion of the solid-state storage device based on the type of the data. In response to determining to program the data to the low latency portion of the solid-state storage device, the storage array controller may program the data to the low latency portion of the solid-state storage device.","['G06F12/0246', 'G06F12/0868', 'G06F3/0607', 'G06F3/0611', 'G06F3/064', 'G06F3/0647', 'G06F3/0658', 'G06F3/0685', 'G11C11/4085', 'G11C11/5628', 'G11C16/10', 'G11C7/1015', 'G06F2212/7202', 'G06F3/0649', 'G11C2207/2272', 'G11C2211/5641', 'G11C5/025']"
US12204787B2,Replication among storage systems hosting an application,"In a particular embodiment, a dataset that is synchronously replicated across a plurality of storage systems is stored on a particular storage system. The storage system identifies input/output (I/O) requests directed to the dataset. The one or more I/O requests are initiated by an application hosted on a platform of the first storage system. The storage system services the one or more I/O requests directed to the dataset.","['G06F16/275', 'G06F3/0604', 'G06F3/0617', 'G06F3/0619', 'G06F3/065', 'G06F3/067']"
US12175124B2,Enhanced data access using composite data views,A storage system has storage devices and a storage controller that includes a processing device. The processing device is to receive a request for portions of data stored at locations of one or more storage devices. The processing device is to generate a file at a storage device. The file corresponds to a view of the portions of data stored at the locations of the one or more storage devices. The processing device is to identify the portions of data that are stored at the locations of the one or more storage devices. The processing device is to provide the view comprising the portions of data.,"['G06F3/0659', 'G06F3/0644', 'G06F11/108', 'G06F11/1448', 'G06F11/1464', 'G06F11/1469', 'G06F11/2066', 'G06F11/2071', 'G06F3/0604', 'G06F3/0605', 'G06F3/0664', 'G06F3/0665', 'G06F3/067', 'G06F3/0689', 'G06F11/1453', 'G06F11/3433', 'G06F11/3495', 'G06F2201/815']"
US12124725B2,Managing host mappings for replication endpoints,"A method of managing host mappings for replication endpoints, the method including: identifying a target storage system replicating a source dataset of a source storage system, wherein a first host is mapped to the source dataset on the source storage system; providing, to the target storage system and in dependence upon a mapping of the first host to the source dataset, configuration information for connecting to a second host; and implementing, in response to a triggering event, a mapping of the second host to a replica dataset on the target storage system.","['G06F16/27', 'G06F3/065', 'G06F16/1734', 'G06F16/184', 'G06F3/0617', 'G06F3/0629', 'G06F3/0664', 'G06F3/067', 'G06F9/45558', 'G06F2009/45595']"
US11539793B1,Responding to membership changes to a set of storage systems that are synchronously replicating a dataset,"Determining active membership among a set of storage systems, including: determining, by a cloud-based storage system among the set of storage systems, that a membership event corresponds to a change in membership to the set of storage systems synchronously replicating the dataset; applying, in dependence upon the membership event, one or more membership protocols to determine a new set of storage systems to synchronously replicate the dataset; and for one or more I/O operations directed to the dataset, applying the one or more I/O operations to the dataset synchronously replicated by the new set of storage systems.","['G06F3/0619', 'G06F11/2076', 'G06F16/178', 'G06F3/064', 'G06F3/065', 'G06F3/067', 'H04L67/1095', 'H04L67/1097']"
US20240193182A1,Checkpoint-based data replication,"Continuous data protection, including sending, to a target data repository from a source data repository, metadata describing one or more updates to one or more datasets stored within the source data repository; generating, based on the metadata describing the one or more updates to the one or more datasets, an ordered log of metadata describing an ordered application of the one or more updates to the one or more datasets; and generating, on the source data repository and based on the ordered log of metadata, the one or more datasets in accordance with the one or more updates corresponding to a specified point in time.","['G06F11/2071', 'G06F16/273', 'G06F11/1471', 'G06F16/2379', 'G06F11/2074', 'G06F11/2076', 'G06F2201/84', 'G06F2201/855']"
US12381934B2,Cloud-based storage management of a remote storage system,"Secure cloud-based storage system management that includes: extending a cloud-based storage management session by using cloud-based user credentials to securely manage a remote storage system, and executing, on the remote storage system, data storage operations generated from commands issued via the cloud-based storage management session.","['H04L9/3213', 'G06F11/201', 'G06F11/2089', 'G06F21/31', 'H04L63/0807', 'H04L63/083', 'H04L63/10', 'H04L63/126', 'H04L67/025', 'H04L67/1097', 'H04L67/133', 'H04L67/14', 'H04L67/141', 'H04L67/51', 'H04L9/0863', 'G06F11/108', 'G06F11/1453', 'G06F21/6218']"
US20250258607A1,Reducing variable latency in storage systems through proactive device operations,"A computer system comprising: a data storage medium comprising a plurality of storage devices configured to store data; and a data storage controller coupled to the data storage medium; wherein the data storage controller is configured to: determine a target number of storage devices in a group of storage devices in a storage system that may exhibit variable I/O response times; detect one or more conditions associated with the group of storage devices; and after detecting the one or more conditions, change the target number of storage devices that may exhibit variable I/O response times.","['G06F3/0611', 'G06F13/20', 'G06F11/0751', 'G06F11/076', 'G06F11/1076', 'G06F11/30', 'G06F12/00', 'G06F3/06', 'G06F3/061', 'G06F3/0613', 'G06F3/0617', 'G06F3/0619', 'G06F3/0634', 'G06F3/0659', 'G06F3/0665', 'G06F3/0688', 'G06F3/0689']"
US12248379B2,Using mirrored copies for data availability,"Ensuring resiliency to storage device failures in a storage system, including: determining a number of storage device failures within a particular write group that are to be tolerated by the storage system; for a plurality of datasets stored within the storage system, writing each dataset to at least a predetermined number of storage devices within the particular write group, wherein the predetermined number of storage devices is greater than the number of storage device failures within the particular write group that are to be tolerated by the storage system; and responsive to recovering from a system interruption: determining a number of readable storage devices that contain a copy of the dataset; and if the number of readable storage devices that contain a copy of the dataset is not greater than the number of failures that are to be tolerated, writing the dataset to one or more additional storage devices.","['G06F11/0727', 'G06F11/076', 'G06F11/1441', 'G06F11/1461', 'G06F11/1469', 'G06F11/2023', 'G06F11/2028', 'G06F11/2041', 'G06F11/2058', 'G06F11/2064', 'G06F11/2071', 'G06F11/2094', 'H04L67/1097', 'G06F11/1466']"
US11748030B1,Storage system metric optimization for container orchestrators,"An illustrative method includes receiving, by an integrated storage manager from an operating system level virtualization service, a request to perform an operation with respect to one or more storage systems; determining, by the integrated storage manager, multiple versions of a performance impact among the one or more storage systems based on potentially implementing the request in multiple ways; and implementing, by the integrated storage manager based on the determining of the multiple versions of the performance impact, the request in a particular way that improves one or more storage system metrics of the one or more storage systems.","['G06F3/0659', 'G06F11/34', 'G06F11/3485', 'G06F3/0604', 'G06F3/0629', 'G06F3/0653', 'G06F3/0664', 'G06F3/067', 'G06F9/45533', 'G06F11/2089', 'G06F11/3433', 'G06F11/3442', 'G06F2201/815', 'G06F3/0608']"
US11354058B2,Local relocation of data stored at a storage device of a storage system,"A storage system includes solid-state storage devices and a storage controller operatively coupled to the solid-state storage devices, the storage controller including a processing device, the processing device to receive, from a solid-state storage device of the solid-state storage devices, an indication of an occurrence of triggering event associated with data stored at a first data block of the solid-state storage device. In response to receiving the indication of the occurrence of the triggering event, a second data block of the solid-state storage device is identified for storage of the data. A command in transmitted to the solid-state storage device that includes address information associated with the second data block of the solid-state storage device for storage of the data, wherein the command causes the solid-state storage device to program the data to the second data block.","['G06F3/0647', 'G06F3/0688', 'G06F11/0727', 'G06F11/076', 'G06F11/1076', 'G06F11/2028', 'G06F11/2048', 'G06F11/2092', 'G06F11/3006', 'G06F11/3034', 'G06F11/3055', 'G06F11/3447', 'G06F3/0604', 'G06F3/061', 'G06F3/0616', 'G06F3/065', 'G06F3/0673', 'G06F11/2094', 'G06F2201/81', 'G06F2201/815', 'G06F2201/88', 'Y02D10/00']"
US11652884B2,Customized hash algorithms,"A storage system determines source addresses, and destination addresses in a storage system, for network traffic. The storage system determines a hash algorithm, from a plurality of hash algorithms. The hash algorithm is to be used across the source addresses for load-balancing the network traffic to the destination addresses. The storage system determines that the hash algorithm more closely meets one or more load-balancing criteria than at least one other hash algorithm, of the plurality of hash algorithms. The storage system distributes the network traffic from the source addresses to the destination addresses in the storage system, with load-balancing according to the determined hash algorithm.","['G06F3/0607', 'G06F11/1068', 'G06F11/1076', 'G06F11/201', 'G06F11/2028', 'G06F11/2041', 'G06F11/2048', 'G06F11/2092', 'G06F12/0246', 'G06F3/06', 'G06F3/0604', 'G06F3/061', 'G06F3/0611', 'G06F3/0613', 'G06F3/0635', 'G06F3/065', 'G06F3/0655', 'G06F3/0659', 'G06F3/067', 'G06F3/0685', 'G11C29/52', 'H03M13/154', 'H04L45/245', 'H04L47/125', 'H04L49/10', 'H04L49/111', 'H04L67/1004', 'H04L67/1097', 'H04L67/51', 'G06F11/108', 'G06F11/2089', 'G06F11/3034', 'G06F2201/805', 'G06F2201/845', 'G06F2206/1012', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/1056', 'G06F2212/154', 'G06F2212/214', 'G06F2212/7201', 'G06F2212/7205', 'G06F2212/7206', 'G06F2212/7207', 'G06F3/0688', 'G06F3/0689', 'G11C2029/0409', 'G11C29/4401', 'G11C29/74', 'G11C29/765', 'H03M13/1102', 'H03M13/1515', 'H03M13/3761', 'Y02D30/50']"
US10735298B2,"Method, apparatus, server and system for vital sign detection and monitoring","Methods, apparatus and systems for detecting and monitoring vital signs and other periodic motions of an object are disclosed. In one example, a system for monitoring object motion in a venue is disclosed. The system comprises a transmitter, a receiver, and a vital sign estimator. The transmitter is located at a first position in the venue and configured for transmitting a wireless signal through a wireless multipath channel impacted by a pseudo-periodic motion of an object in the venue. The receiver is located at a second position in the venue and configured for: receiving the wireless signal through the wireless multipath channel impacted by the pseudo-periodic motion of the object in the venue, and obtaining at least one time series of channel information (TSCI) of the wireless multipath channel based on the wireless signal. The vital sign estimator is configured for: determining that at least one portion of the at least one TSCI in a current sliding time window is associated with the pseudo-periodic motion of the object in the venue, and computing a current characteristics related to the pseudo-periodic motion of the object in the current sliding time window based on at least one of: the at least one portion of the at least one TSCI in the current sliding time window, at least one portion of the at least one TSCI in a past sliding time window, and a past characteristics related to the pseudo-periodic motion of the object in the past sliding time window.","['G16H40/67', 'H04L43/12', 'A61B5/0022', 'A61B5/0816', 'A61B5/7253', 'H04L25/0242', 'H04L25/4902', 'H04L7/042', 'H04W56/001', 'A61B5/112', 'A61B5/113', 'A61B5/4806', 'A61B5/6898', 'H04L25/0228']"
US10884636B1,Presenting workload performance in a storage system,"Presenting workload performance in a storage system, including: receiving, via a user interface, information describing a potential change to an execution environment of the storage system; and displaying, via the user interface and in dependence upon a load model and predicted characteristics of one or more workloads executing on the storage system, predicted performance load on the storage system that would result from implementing the potential change.","['G06F3/0631', 'G06F11/3447', 'G06F11/3409', 'G06F3/061', 'G06F11/3433', 'G06F11/3457', 'G06F2206/1008', 'G06F3/0605', 'G06F3/0653', 'G06F3/067', 'Y02D10/00']"
US10990480B1,Performance of RAID rebuild operations by a storage group controller of a storage system,"A storage system includes a plurality of solid-state storage devices and a storage group controller. The storage group controller receives, from a central storage controller, a command comprising information associated with a RAID rebuild operation to reconstruct data stored at the set of solid-state storage devices. In response to receiving the information associated with the RAID rebuild operation, the storage group controller reads other data and parity data stored associated with the data to be reconstructed at the set of solid-state storage devices based on the information associated with the RAID rebuild operation. Upon reading the other data and the parity data stored at the set of solid-state storage devices, the storage group controller reconstructs the data based on the other data, the parity data and the information associated with the RAID rebuild operation and transmits, to the central storage controller, the reconstructed data.","['G06F11/1092', 'G06F12/0246', 'G06F11/108', 'G06F11/2069', 'G06F12/0253', 'G06F3/0619', 'G06F3/0632', 'G06F3/065', 'G06F3/0685', 'G06F3/0688', 'G06F3/0689', 'G06F11/1446', 'G06F11/2092', 'G06F21/56', 'G06F2201/81', 'G06F2201/84', 'G06F2212/1032', 'G06F2212/262', 'G06F2212/7205', 'G06F2212/7208']"
US12164393B2,Taking recovery actions for replicated datasets,"Taking recovery actions for replicated datasets, including: determining whether a request to modify a dataset that is synchronously replicated among a plurality of storage systems has been applied on a particular storage system of the plurality of storage systems, wherein the plurality of storage systems is synchronously replicating the dataset by acknowledging the request as being complete when each storage system has modified its copy of the dataset; and applying a recovery action based on whether the request to modify the dataset has been applied on the particular storage system of the plurality of storage systems.","['G06F11/1469', 'G06F11/1451', 'G06F11/2094', 'G06F11/2097', 'H04L67/1097', 'G06F2201/82']"
US11797403B2,Maintaining a synchronous replication relationship between two or more storage systems,"Maintaining a synchronous replication relationship between two or more storage systems, including: receiving, by at least one of a plurality of storage systems across which a dataset will be synchronously replicated, timing information for at least one of the plurality of storage systems; and establishing, based on the timing information, a synchronous replication lease describing a period of time during which the synchronous replication relationship is valid, wherein a request to modify the dataset may only be acknowledged after a copy of the dataset has been modified on each of the storage systems.","['G06F11/2076', 'G06F3/0616', 'G06F11/0727', 'G06F11/0751', 'G06F11/1464', 'G06F11/2064', 'G06F11/2082', 'G06F11/2094', 'G06F11/2097', 'G06F12/0684', 'G06F12/1072', 'G06F16/178', 'G06F16/182', 'G06F16/1844', 'G06F16/27', 'G06F16/275', 'G06F3/0604', 'G06F3/061', 'G06F3/0632', 'G06F3/065', 'G06F3/0659', 'G06F3/0683', 'G06F3/0688', 'G06F9/44505', 'H04L45/12', 'G06F11/2053', 'G06F2003/0697', 'G06F3/06', 'G06F3/067', 'H04L45/38', 'H04L47/125', 'H04L67/1095', 'H04L67/1097']"
US11714572B2,Optimized data resiliency in a modular storage system,"A redundant array of independent drives (RAID) stripe is formed across a set of storage controllers of a plurality of storage controllers, wherein the RAID stripe comprises two or more of a plurality of modular storage devices of at least one of the set of storage controllers. The RAID stripe is written across the set of storage controllers.","['G06F3/0688', 'G06F3/0659', 'G06F3/061', 'G06F3/0614', 'G06F3/0617', 'G06F3/0644', 'G06F3/0652', 'G06F3/0653', 'G06F3/0658', 'G06F3/067', 'G06F3/0689']"
US12131044B2,Intelligent application placement in a hybrid infrastructure,"Application placement for distributed applications, including: identifying, from amongst a plurality of disparate storage environments, a storage environment that contains data that can be utilized by a portion of a distributed application; and initiating execution of the portion of the distributed application in an execution environment that is communicatively coupled to the storage environment.","['G06F3/0644', 'G06F11/108', 'G06F11/1453', 'G06F11/1464', 'G06F11/1469', 'G06F11/2028', 'G06F11/203', 'G06F11/2048', 'G06F11/2071', 'G06F11/2094', 'G06F11/2097', 'G06F11/3006', 'G06F11/3034', 'G06F11/3409', 'G06F11/3447', 'G06F11/3466', 'G06F3/0604', 'G06F3/0614', 'G06F3/0647', 'G06F3/0659', 'G06F3/067', 'G06F9/5072']"
US12373126B2,Uniform model for distinct types of data replication,"A uniform model for distinct types of data replication, including receiving, at a source data repository, an update to a dataset; generating, based on the update to the dataset, both metadata describing the update to the dataset and also a metadata representation of the dataset; and initiating, based on the same metadata describing the update to the dataset and also based on the same metadata representation of the dataset, either a first type of data replication or a second type of data replication from among a plurality of types of data replication.","['G06F16/178', 'G06F3/065', 'G06F11/108', 'G06F11/1435', 'G06F11/1451', 'G06F11/1458', 'G06F11/1484', 'G06F11/2094', 'G06F11/2097', 'G06F16/128', 'G06F16/1844', 'G06F16/1858', 'G06F16/2379', 'G06F16/27', 'G06F16/383', 'G06F3/0614', 'G06F3/0616', 'G06F3/0656', 'G06F3/067', 'G06F3/0679', 'G06F2201/84']"
US11838359B2,Synchronizing metadata in a cloud-based storage system,"Symmetric storage using a cloud-based storage system, including: receiving, at a cloud-based storage system among storage systems synchronously replicating a dataset, an I/O operation directed to the dataset; determining, in dependence upon the I/O operation, a metadata update describing a mapping of segments of content to an address within a storage object, wherein the storage object includes the dataset; and synchronizing metadata on another storage system of the storage systems by sending the metadata update from the cloud-based storage system to the other storage system to update a metadata representation on the second storage system in accordance with the metadata update.","['G06F3/0619', 'H04L67/1095', 'G06F3/0613', 'G06F3/0626', 'G06F3/064', 'G06F3/065', 'G06F3/067', 'G06F3/0688', 'H04L61/4552', 'H04L61/457', 'H04L67/1097', 'H04L49/356']"
US20240420792A1,Multiple thresholds for managing flash memory,"A method of tracking flash memory in a storage system is provided. The method includes initializing a bad blocks threshold value and marking one or more planes or logical unit numbers (LUNs) of flash memory as bad, responsive to determining that bad blocks in the one or more planes or LUNs meet the bad blocks threshold value. The method includes adjusting the bad blocks threshold value, responsive to exceeding a threshold number or rate of retiring planes or LUNs of flash memory, and repeating the marking and the adjusting, with the bad blocks threshold value capped at a maximum threshold value.","['G11C29/44', 'G11C29/028', 'G11C29/38', 'G11C29/4401', 'G11C2029/0409', 'G11C2029/4402', 'G11C29/702']"
US12373396B2,Ensuring the resiliency of redundancy data in a cloud-based storage system,"Data resiliency in a cloud-based storage system, including: receiving, for storage within a first tier of cloud storage of the cloud-based storage system, one or more segments of data; generating, for each of one or more shards of data of the one or more segments of data, self-describing information for recoverability of the one or more shards of data; and storing, within a second tier of cloud storage of the cloud-based storage system, both the one or more shards of data and the generated self-describing information for recoverability of the one or more shards of data.","['G06F16/1844', 'G06F11/1076', 'G06F11/1464', 'G06F11/1469', 'G06F11/2094', 'G06F11/2097', 'G06F3/0614', 'G06F3/0617', 'G06F3/064', 'G06F3/065', 'G06F3/0655', 'G06F3/067']"
US11632360B1,Remote access to a storage device,"An exemplary access control system controls access to a computing system such as a data storage system. For example, the exemplary access control system includes a cloud storage platform that authorizes a user to access the cloud storage platform. After access to the cloud storage platform is authorized, the cloud storage platform receives, from the user, a request to access, through the cloud storage platform, an application executing on a remote storage device. The cloud storage platform obtains an access token in response to receiving the request from the user. The cloud storage platform transmits the access token to the storage device for use by the storage device to validate the user and grant the user access, through the cloud storage platform, to the application executing on the storage device.","['H04L63/08', 'H04L9/0894', 'G06F3/0622', 'G06F3/0637', 'G06F3/067', 'H04L63/0807', 'H04L63/083', 'H04L63/104', 'H04L9/3213', 'H04L9/50', 'H04L2209/88', 'H04L67/1097']"
US12001688B2,Utilizing data views to optimize secure data access in a storage system,"A storage system has filtered views of data. The storage system receives a read request for a filtered view of data in memory. The read request is associated with one or more permissions for viewing the data. The storage system identifies a subset of the data, based on the one or more permissions. The storage system provides the filtered view. The filtered view includes the subset of the data.","['G06F3/0622', 'G06F3/0644', 'G06F11/108', 'G06F11/1453', 'G06F11/1464', 'G06F11/1484', 'G06F11/2066', 'G06F11/2071', 'G06F3/0604', 'G06F3/0637', 'G06F3/0653', 'G06F3/0659', 'G06F3/0665', 'G06F3/067', 'G06F3/0689', 'G06F11/1435', 'G06F11/3433', 'G06F11/3495', 'Y02D10/00']"
US11995336B2,Bucket views,"A method of operating an object-based storage system, practiced by the storage system, is provided. The method includes establishing a plurality of buckets for objects, in the storage system and establishing a plurality of bucket views in the storage system, each bucket view supporting access to objects of one of the plurality of buckets. The method includes accessing an object of a bucket through one of the plurality of bucket views.","['G06F3/0665', 'G06F3/065', 'G06F11/1076', 'G06F11/1453', 'G06F11/2066', 'G06F11/2071', 'G06F3/061', 'G06F3/0644', 'G06F3/0652', 'G06F3/0679', 'G06F3/0689', 'G06F11/3433', 'G06F11/3495']"
US20210182190A1,Intelligent die aware storage device scheduler,"A scheduling system for a memory controller is provided. The system includes operation queues and a scheduler. The scheduler receives operation requests, prioritizes each operation request according to one or more policies, and inserts each operation request into an operation queue.","['G06F12/0269', 'G06F12/0246', 'G06F13/1642', 'G06F3/0659', 'G06F3/0679', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/702', 'G06F2212/7205', 'G06F2212/7208']"
US12039165B2,Utilizing allocation shares to improve parallelism in a zoned drive storage system,Storage bandwidth for a storage system process is adjusted responsive to an input output (I/O) write request to write data to a zoned storage device. The storage bandwidth is adjusted by calculating an allocation share for the storage system process requesting to write the data and opening a new zone for the storage system process upon determining that an open zone usage by the storage system process is under the allocation share for the storage system process.,"['G06F3/061', 'G06F12/0246', 'G06F3/0631', 'G06F3/0644', 'G06F3/0655', 'G06F3/0688', 'G06F2206/1012', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208']"
US20250173079A1,Voltage threshold adjustment of storage devices by an external controller,"A method for read voltage levels in flash memory is provided. The method includes determining to which set of pages or blocks of a flash memory device a word line connects, according to a flash memory device architecture. The method includes determining one or more optimum read voltage levels, for one or more pages of the flash memory device that are accessed by activating the word line, according to a specified number of bits per cell and the flash memory device architecture, and using the one or more optimum read voltage levels to access further pages in the set of pages or blocks of the flash memory device to which the word line connect.","['G06F3/0634', 'G06F3/0619', 'G06F3/0679', 'G11C29/021', 'G11C29/028', 'G11C29/44', 'G11C29/52']"
US11630593B2,Inline flash memory qualification in a storage system,Reading data stored at a free block of a storage device is read prior to allocating the free block for storage of data. A determination as to whether a number of bit flips of the data stored at the free block is below a threshold is made. The free block is added to a pool of active free blocks to be allocated for the storage of data upon determining that the number of bit flips of the data stored at the free block is below the threshold.,"['G06F3/0679', 'G06F3/064', 'G06F11/0727', 'G06F11/0754', 'G06F3/0619', 'G06F3/0631', 'G06F3/0644', 'G06F3/0652', 'G06F3/067', 'G06F2201/81']"
US11869586B2,Increased data protection by recovering data from partially-failed solid-state devices,"A storage system includes a central storage controller and a solid-state storage device operatively coupled to the central storage controller, the solid-state storage device including a processing device, the processing device to determine whether a die of the solid-state storage device is likely to fail. In response to determining that the die of the solid-state storage device is likely to fail, the processing device is further to mark the die of the solid-state storage device as likely to fail and transmit, to the central storage controller, an indication that the die of the solid-state storage device has been marked as likely to fail.","['G06F11/3037', 'G11C13/0035', 'G06F11/0727', 'G06F11/0754', 'G06F11/108', 'G06F3/0616', 'G06F3/0653', 'G06F3/0679', 'G06F3/0688']"
US11822807B2,Data replication in a storage system,"A method of replication in a distributed storage system, performed by the distributed storage system is provided. The method includes managing a first index for data or metadata in a first storage system, the first storage system having a first partitioning scheme. The method includes managing a second index for data or metadata in a second storage system, the second storage system having a second partitioning scheme. The method includes replicating the data or metadata from the first storage system to the second storage system, translating an identifier of the data or metadata from the first storage system, and mapping the replicated data or metadata into the second partitioning scheme, via the translating of the identifier of the data or metadata from the first storage system.","['G06F3/065', 'G06F12/0246', 'G06F12/0868', 'G06F12/10', 'G06F3/0604', 'G06F3/0619', 'G06F3/0644', 'G06F3/067', 'G06F2212/1016', 'G06F2212/1032', 'G06F2212/1048', 'G06F2212/154', 'G06F2212/214', 'G06F2212/222', 'G06F2212/2228', 'G06F2212/286', 'G06F2212/312', 'G06F2212/7204', 'G06F2212/7205', 'G06F2212/7208', 'Y02D10/00']"
CN118539441B,Power grid topology optimization method and system based on search ordering,"The invention discloses a power grid topology optimization method and system based on search sequencing, wherein the method comprises the steps of obtaining power grid topology structure data and constructing an action space based on the power grid topology structure data; the power grid topological structure data comprises a node set, an edge set and an attribute set; acquiring real-time power grid state data, constructing a self-adaptive double-tower model based on the real-time power grid state data and an action space, and calculating to obtain a candidate action set; constructing a graph attention network and a time sequence graph neural network based on the candidate action set to obtain a sorted candidate action list; and performing multi-objective optimization and decision making based on the ordered candidate action list to obtain the optimal action. The invention not only improves the overall effect of power grid topology optimization, but also enhances the adaptability and decision quality of the system, realizes the rapid optimization of a large-scale power grid system and provides powerful support for practical application by organically combining innovative algorithm construction and various methods.","['G06N3/042', 'G06F18/24323', 'G06F18/253', 'G06F18/259', 'G06N20/20', 'G06N3/0455', 'G06N3/049', 'G06N3/082', 'H02J3/00', 'H02J3/0075', 'H02J2203/10', 'H02J2203/20', 'Y04S10/50']"
US11481261B1,Preventing extended latency in a storage system,"Ensuring the fair utilization of system resources using workload based, time-independent scheduling, including: determining whether an amount of available system resources in the storage system has reached a predetermined reservation threshold; and responsive to determining that the amount of available system resources in the storage system has reached the predetermined reservation threshold: determining whether one or more entities in the storage system have utilized system resources in excess of their fair share by a predetermined threshold during one or more time-independent periods; and responsive to determining that one or more entities in the storage system have utilized system resources in excess of their fair share by the predetermined threshold during the time-independent period, limiting the one or more entities from issuing additional I/O requests to the storage system.","['G06F13/16', 'G06F9/505', 'G06F13/1642', 'G06F3/0611', 'G06F3/0613', 'G06F3/0635', 'G06F3/0659', 'G06F3/0665', 'G06F3/067', 'G06F3/0689', 'G06F9/4881', 'G06F9/4887', 'G06F9/5011', 'G06F9/5038', 'G06F2209/504', 'G06F3/061']"
US7466840B2,Soft error decoding of steganographic data,"Soft error decoding is used to decode steganographic messages embedded in image and audio signals. Content signals with auxiliary embedded data are analyzed to make determinations about changes made to the signals to embed the data. These determinations are weighted based on the confidence that they are correct and input to an error correcting process. In this manner, error correction of the auxiliary data takes advantage of soft error weighting to more effectively recover the steganographic message from content signals that undergo distortion and/or loss transformations after being embedded with steganographic data.","['G10L19/018', 'G06T1/0028', 'G06T1/005', 'G06V30/40', 'H04N1/00005', 'H04N1/00037', 'H04N1/00079', 'H04N1/32149', 'H04N1/32154', 'H04N1/32203', 'H04N1/32229', 'H04N1/32288', 'H04N1/32352', 'H04N21/23892', 'H04N21/8358', 'G06T2201/0064', 'G06T2201/0065', 'H04N1/32122', 'H04N2201/3205', 'H04N2201/3207', 'H04N2201/3225', 'H04N2201/3226', 'H04N2201/3233', 'H04N2201/327', 'H04N2201/3271', 'H04N2201/3274', 'H04N2201/3284']"
US8023695B2,Methods for analyzing electronic media including video and audio,"The present disclosure includes methods and apparatus for analyzing audio and video. One claim recites: a method including at a network access point, and using a programmed electronic processor, analyzing data representing audio or video to extract identifying information therefrom, the analyzing operates on data representing audible portions of the audio or operates on data representing picture elements of the video; using the identifying information, determining whether to allow the audio or video to be communicated through the network access point; and providing details associated with said act of determining. Of course, other combinations are provided and claimed as well.","['G06T1/0064', 'G06F16/955', 'G06K19/06037', 'G06K19/06046', 'G06K19/14', 'G06K19/18', 'G06K7/1417', 'G06K7/1447', 'G06Q20/1235', 'G06Q20/341', 'G06Q20/40145', 'G06T1/0021', 'G06V30/40', 'G07C9/253', 'G07D7/0032', 'G07D7/0034', 'G07D7/004', 'G07F7/08', 'G07F7/086', 'G07F7/1008', 'G07F7/1016', 'G07F7/12', 'G10L19/018', 'G11B20/00086', 'G11B20/00094', 'G11B20/00166', 'G11B20/0021', 'G11B20/00884', 'G11B20/00891', 'H04B1/665', 'H04K1/00', 'H04N1/00005', 'H04N1/00037', 'H04N1/00079', 'H04N1/32122', 'H04N1/32144', 'H04N1/3216', 'H04N1/32203', 'H04N1/32208', 'H04N1/32251', 'H04N1/32288', 'H04N1/32352', 'H04N19/00', 'H04N19/467', 'H04N21/23892', 'H04N21/8358', 'H04N5/913', 'G06K2019/06253', 'G06T2201/0052', 'H04L2463/103', 'H04L63/10', 'H04N2005/91321', 'H04N2005/91335', 'H04N2201/3205', 'H04N2201/3207', 'H04N2201/3225', 'H04N2201/3226', 'H04N2201/323', 'H04N2201/3233', 'H04N2201/3235', 'H04N2201/3246', 'H04N2201/327', 'H04N2201/3271', 'H04N2201/3274', 'H04N2201/328', 'H04N2201/3281']"
US11270204B2,Systems and methods for barcode annotations for digital images,"A content-based image retrieval (CBIR) system and method is presented herein. The CBIR system generates a relatively short vector or array of data, referred to as a barcode, from an input image. The short vector or array data can be used to represent the content of the image for image retrieval purposes. The system obtains the image and applies a transform to the image to generate a plurality of image transform values. The system thresholds the plurality of image transform values to obtain compact image transform values. The system generates a barcode in accordance with the compact image transform values and representative of the image. The system may then transmit the barcode to a database for storage or draw the barcode on a display. The system may also compare barcodes to find and retrieve similar images associated with similar barcodes.","['G06N3/08', 'G06F16/51', 'G06F16/583', 'G06K7/1439', 'G06K19/06028']"
US12019764B2,Modifying encryption in a storage system,"A method of modifying encryption of a storage system includes: receiving an instruction to rekey data on a storage system, wherein the instruction identifies first encryption information and second encryption information; determining that the instruction is authorized; decrypting, by a processing device of a storage system controller, the data using a current key included in the first encryption information to generate decrypted data; and encrypting, by the processing device of the storage system controller, the decrypted data using the second encryption information to generate encrypted data.","['H04L9/0894', 'G06F21/602', 'G06F12/1408', 'G06F21/6218', 'G06F21/78', 'H04L67/1095', 'H04L67/1097', 'H04L9/0822', 'H04L9/0891', 'G06F2212/1052', 'G06F2212/402', 'G06F2221/2107']"
US11809267B2,Root cause analysis of computerized system anomalies based on causal graphs,"An embodiment for root cause analysis of computerized system anomalies is provided. The embodiment may include monitoring key performance indicators (KPIs) for a computerized system, wherein KPI values of the monitored KPIs form respective timeseries. The embodiment may include detecting an anomaly in the computerized system based on the monitored KPIs. The embodiment may include determining a troubleshooting time window extending over a given time period. The embodiment may include identifying a strict subset of the monitored KPIs based on portions of the respective timeseries spanning the given time period. The strict subset comprises abnormal KPIs (aKPIs) and potential explanatory KPIs (xKPIs). The embodiment may include obtaining a causal graph of vertices mapping KPIs of the strict subset by running a causality algorithm to evaluate weights of directed edges connecting the vertices and accordingly obtain one or more directed paths. The embodiment may include returning the obtained causal graph.","['G06F11/079', 'G06F11/0709']"
US12101129B2,Communication systems having optical power supplies,"A distributed data processing system includes a first data processing system and a second data processing system. The first data processing system includes a first housing, a first data processor, and a first optical module that is configured to convert output electrical signals from the first data processor to output optical signals that are provided to a first optical fiber cable. The second data processing system includes a second housing, a second data processor, and a second optical module that is configured to convert output electrical signals from the second data processor to output optical signals that are provided to a second optical fiber cable. An optical power supply includes at least one laser that is configured to provide a first light source to the first optical module through a first optical link and to provide a second light source to the second optical module through a second optical link.","['G02B6/43', 'H04B10/807', 'G02B6/4216', 'G02B6/4246', 'G02B6/4278', 'G02B6/428', 'G02B6/4293', 'H04B10/801', 'G02B6/4249']"
US11833422B2,Providing automated user input to an application,"This document relates to techniques for addressing disruptions that prevent applications from receiving user input, prevent users from providing input to an application, and/or prevents or impacts users from receiving application output. One example method involves detecting a disruption to an interactive application during interaction by a user with the interactive application, generating automated user inputs, and providing the automated user inputs to the interactive application during the disruption to the interactive application.","['A63F13/35', 'A63F13/44', 'A63F13/422', 'A63F13/355', 'A63F13/358', 'A63F13/40', 'G06N20/00', 'A63F2300/534', 'A63F2300/535', 'A63F2300/572']"
WO2023016537A1,"Database management system, data processing method, and device","Disclosed in the present application are a database management system, a data processing method, and a device. The system comprises: an optimizer including n models; a training data collector; a model manager; and a model evaluator. The optimizer is used to obtain a target physical plan by means of the n models according to an SQL statement; the training data collector is used to construct m training sets according to operating data of a database process; the model manager is used to fine-tune a first target model (which belongs to the n models and needs to meet a preset requirement, e.g. a performance reduction) by using a target training set (which belongs to the m training sets), so as to obtain a second target model; and the model evaluator is used to evaluate the performance of the second target model, and update the first target model to the second target model when the performance meets a preset requirement (e.g. a performance improvement). The present application is combined with machine learning, so as to realize the function of automatically executing database tuning and updating and other database management tasks that are traditionally executed by a DBA, without manual intervention.","['G06F11/07', 'G06F11/34', 'G06F16/00', 'G06F16/21', 'G06F16/2453', 'G06F18/21', 'G06F18/214', 'G06F18/241', 'G06F18/2415', 'G06N3/0442', 'G06N3/0455', 'G06N3/047', 'G06N3/092']"
US11125844B2,Deep learning based methods to accelerate multi-spectral imaging,"A method for magnetic resonance imaging reconstructs images that have reduced under-sampling artifacts from highly accelerated multi-spectral imaging acquisitions. The method includes performing by a magnetic resonance imaging (MRI) apparatus an accelerated multi-spectral imaging (MSI) acquisition within a field of view of the MRI apparatus, where the sampling trajectories of different spectral bins in the acquisition are different; and reconstructing bin images using neural network priors learned from training data as regularization to reduce under-sampling artifacts.","['G01R33/5608', 'G01R33/5611', 'G01R33/56536', 'G01R33/56545']"
CN111681166B,Image super-resolution reconstruction method of stacked attention mechanism coding and decoding unit,"The invention relates to an image super-resolution reconstruction method of a stacked attention mechanism coding and decoding unit, which specifically comprises the following steps: the coding and decoding unit is used as a network basic unit and consists of a down-sampling part, an up-sampling part and a feature fusion part; a channel attention mechanism is integrated in the up-sampling and down-sampling parts to serve as an improved coding and decoding unit to serve as an improved network unit, wherein the down-sampling consists of residual convolution blocks, the up-sampling is completed by deconvolution, and the characteristic fusion is completed by channel splicing and the channel attention mechanism; finally, the same improved coding and decoding structures are stacked together to form a main body part of the whole network, so that the characteristics of different coding and decoding structures are better fused, and the HR image is finally obtained by performing upsampling on the sub-pixel convolution layer. Due to the successful performance of the coding and decoding structure in the image recovery, the invention can effectively remove the noise of the image and realize the super-resolution reconstruction of the noise image.","['G06T3/4053', 'G06T5/70', 'G06T2207/20081', 'G06T2207/20084', 'Y02T10/40']"
CN104899571B,A kind of random sample production method for complex script identification,"The present invention relates to field of image recognition, in particular to a kind of random sample production method for complex script identification.In complex script identification, the reason of by analysis Character complexity, the great amount of samples comprising picture noise model and distortion character model to be identified that is generated on the basis of standard character similar with character to be identified using random sample generator.Include the noise and torsional deformation of various complexity in the training sample that random sample generator automatically generates, can satisfy the needs of various complex script identifications；Using above-mentioned random sample as in training sample input deep neural network, trained deep neural network be can solve come the problem of needing a large amount of artificial marks when identifying text, so that the automatic identification of complex script image is become simpler easy, saves considerably relevant cost of labor.","['G06V30/333', 'G06F18/10', 'G06N3/02', 'G06V10/758', 'G06V30/10']"
US11487954B2,Multi-turn dialogue response generation via mutual information maximization,"Machine classifiers in accordance with embodiments of the invention capture long-term temporal dependencies in the dialogue data better than the existing recurrent neural network-based architectures. Additionally, machine classifiers may model the joint distribution of the context and response as opposed to the conditional distribution of the response given the context as employed in sequence-to-sequence frameworks. Further, input data may be bidirectionally encoded using both forward and backward separators. The forward and backward representations of the input data may be used to train the machine classifiers using a single generative model and/or shared parameters between the encoder and decoder of the machine classifier. During inference, the backward model may be used to reevaluate previously generated output sequences and the forward model may be used to generate an output sequence based on the previously generated output sequences.","['G06F40/30', 'G06F18/2148', 'G06F18/217', 'G06F18/2413', 'G06F40/284', 'G06F40/35', 'G06F40/56', 'G06K9/6257', 'G06K9/6262', 'G06N20/00', 'G06N3/045', 'G06N3/048', 'G06N3/049', 'G06N3/08', 'G10L15/063', 'G10L15/16', 'G10L15/22', 'G10L2015/0631', 'G10L2015/228']"
US20230189049A1,Managing a wireless device that is operable to connect to a communication network,"A method is disclosed for managing a wireless device that is operable to connect to a communication network. The communication network comprises a Radio Access Network (RAN), and the method is performed by a RAN node of the communication network. The method comprises receiving, from the wireless device, information indicating whether the wireless device is capable of executing a Machine Learning (ML) model that is operable to provide an output on the basis of which at least one RAN operation performed by the wireless device may be configured.","['H04W28/0231', 'H04W8/22', 'G06N20/20', 'G06N3/045', 'G06N5/01']"
US12293293B2,Machine learning using structurally regularized convolutional neural network architecture,"Machine learning architectures to perform pattern recognition such as a structurally regularized convolutional neural network architecture, along with corresponding methods of operation, are provided. One such architecture includes a memory, and a processor coupled to the memory, where the processor receives data including a pattern to be recognized, decomposes the data into of sub-bands, and processes each of the sub-bands with a respective convolutional neural network (CNN) to generate outputs, where each of the CNNs operates independently of the other CNNs. The processor aggregates the outputs of the CNNs, and trains, using the aggregated output, the CNNs to recognize the pattern.","['G06N3/084', 'G06F18/214', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06V10/454', 'G06V10/52', 'G06V10/82', 'G06N3/048']"
US11593987B2,Dynamic culling of matrix operations,"An output of a first one of a plurality of layers within a neural network is identified. A bitmap is determined from the output, the bitmap including a binary matrix. A particular subset of operations for a second one of the plurality of layers is determined to be skipped based on the bitmap. Operations are performed for the second layer other than the particular subset of operations, while the particular subset of operations are skipped.","['G01C21/20', 'G06T15/08', 'G01C21/30', 'G05D1/0214', 'G05D1/0274', 'G05D1/246', 'G05D1/617', 'G06F17/16', 'G06F9/30029', 'G06N3/04', 'G06N3/045', 'G06N3/0454', 'G06T1/20', 'G06T1/60', 'G06T15/06', 'G06T17/005', 'G06T17/05', 'G06T19/00', 'G06T19/006', 'G06T7/50', 'G06T7/579', 'G06T7/593', 'G06T7/75', 'G06V20/13', 'G06V20/17', 'G06V20/64', 'G06N3/048', 'G06N3/0481', 'G06T2200/04', 'G06T2200/28', 'G06T2207/10032', 'G06T2207/20016', 'G06T2207/20084', 'G06T2207/30244', 'G06T2207/30261', 'G06T2210/08', 'G06T2210/36', 'G06T2219/004']"
US10853116B2,Machine learning prediction of virtual computing instance transfer performance,"The disclosure provides an approach for preventing the failure of virtual computing instance transfers across data centers. In one embodiment, a flow control module collects performance information primarily from components in a local site, as opposed to components in a remote site, during the transfer of a virtual machine (VM) from the local site to the remote site. The performance information that is collected may include various performance metrics, each of which is considered a feature. The flow control module performs feature preparation by normalizing feature data and imputing missing feature data, if any. The flow control module then inputs the prepared feature data into machine learning model(s) which have been trained to predict whether a VM transfer will succeed or fail, given the input feature data. If the prediction is that the VM transfer will fail, then remediation actions may be taken, such as slowing down the VM transfer.","['G06F9/45558', 'G06F11/004', 'G06F11/008', 'G06F11/203', 'G06F11/3419', 'G06F11/3447', 'G06F11/3452', 'G06F18/2411', 'G06K9/6269', 'G06N20/00', 'G06N3/02', 'G06N7/005', 'G06N7/01', 'G06F2009/4557', 'G06F2009/45591', 'G06F2201/815']"
US12271807B2,Convolutional neural network computing method and system based on weight kneading,"Disclosed embodiments relate to a convolutional neural network computing method and system based on weight kneading, comprising: arranging original weights in a computation sequence and aligning by bit to obtain a weight matrix, removing slack bits in the weight matrix, allowing essential bits in each column of the weight matrix to fill the vacancies according to the computation sequence to obtain an intermediate matrix, removing null rows in the intermediate matrix, obtain a kneading matrix, wherein each row of the kneading matrix serves as a kneading weight; obtaining positional information of the activation corresponding to each bit of the kneading weight; divides the kneading weight by bit into multiple weight segments, processing summation of the weight segments and the corresponding activations according to the positional information, and sending a processing result to an adder tree to obtain an output feature map by means of executing shift-and-add on the processing result.","['H03M7/4037', 'G06F17/15', 'G06F17/16', 'G06F5/01', 'G06F7/50', 'G06F7/5443', 'G06N3/04', 'G06N3/045', 'G06N3/048', 'G06N3/063', 'G06N3/082', 'H03M7/3059', 'H03M7/40', 'H03M7/70', 'G06F2207/386', 'G06N3/08']"
US11184615B2,Image coding method and apparatus and image decoding method and apparatus,"Embodiments of this disclosure provide an image coding method and apparatus and an image decoding method and apparatus. The image coding method includes: performing feature extraction on to-be-processed image data by using a convolutional neural network, to generate feature maps of the image data; quantizing the feature maps to generate discrete feature maps; preprocessing the discrete feature maps to generate preprocessed data, an amount of data of the preprocessed data being less than an amount of data of the discrete feature maps; calculating probabilities of to-be-coded data in the discrete feature maps according to the preprocessed data; and performing entropy coding on the to-be-coded data according to the probabilities of the to-be-coded data.","['H04N19/94', 'H04N19/91', 'H04N19/124', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'H04N19/13', 'H04N19/136', 'H04N19/42', 'H04N19/44', 'G06N3/02']"
US10452995B2,Machine learning classification on hardware accelerators with stacked memory,"A method is provided for processing on an acceleration component a machine learning classification model. The machine learning classification model includes a plurality of decision trees, the decision trees including a first amount of decision tree data. The acceleration component includes an acceleration component die and a memory stack disposed in an integrated circuit package. The memory die includes an acceleration component memory having a second amount of memory less than the first amount of decision tree data. The memory stack includes a memory bandwidth greater than about 50 GB/sec and a power efficiency of greater than about 20 MB/sec/mW. The method includes slicing the model into a plurality of model slices, each of the model slices having a third amount of decision tree data less than or equal to the second amount of memory, storing the plurality of model slices on the memory stack, and for each of the model slices, copying the model slice to the acceleration component memory, and processing the model slice using a set of input data on the acceleration component to produce a slice result.","['G06N20/00', 'G06F9/46', 'G06F9/50', 'Y02D10/00', 'Y02D10/22']"
CN108764031B,"Method, device, computer equipment and storage medium for recognizing human face","The method for recognizing the human face comprises the following steps: selecting a corresponding first feature extraction mode from a face recognition model trained based on a Capsule network structure according to a first shooting angle of the acquired face image; extracting the feature of a first face corresponding to the first shooting angle according to the first feature extraction mode, and converting the feature of the first face into a first feature vector of a face image of a front face in the face recognition model according to a spatial position relation in the face recognition model; judging whether the similarity of the first feature vector and a preset feature vector is smaller than a preset threshold value or not; and if the number of the acquired face images is smaller than the preset feature vector, judging that the acquired face images and the face images corresponding to the preset feature vector are the face images of the same person. The human face recognition method and the human face recognition system can recognize any five sense organs of the human face from any one angle, and the human face recognition can be carried out more flexibly, efficiently and humanized.","['G06V40/172', 'G06F18/214', 'G06F18/22', 'G06V40/165']"
US7486799B2,Methods for monitoring audio and images on the internet,"An Internet monitoring method identifies content on the Internet through embedded data and pattern matching, determines the owners of the content and notifies the owners of this use of their audio or images on the Internet.","['G06T1/0064', 'H04N1/32144', 'G06T2201/0051', 'H04N2201/323']"
US9820657B2,Mobile wireless appliance,A wireless system for a person includes a wearable appliance with an accelerometer; a wireless device in communication with the wearable appliance; and a remote computer coupled to the wireless device to provide information to an authorized remote user.,"['A61B5/0205', 'A61B5/0002', 'A61B5/0022', 'A61B5/0024', 'A61B5/021', 'A61B5/1112', 'A61B5/1118', 'A61B5/14542', 'A61B5/4806', 'A61B5/681', 'A61B5/6816', 'A61B5/6826', 'A61B5/6898', 'A61B5/742', 'A61B5/7455', 'A61B5/7475', 'A61B8/02', 'A61B8/06', 'A61B8/565', 'G16H40/67', 'G16Z99/00', 'H04M3/42042', 'H04Q9/14', 'A61B2505/03', 'A61B2560/0242', 'A61B2562/0204', 'A61B5/02438', 'A61B8/4427', 'A61B8/488']"
US10970629B1,Encodings for reversible sparse dimensionality reduction,The present disclosure is directed to reducing model size of a machine learning model with encoding. The input to a machine learning model may be encoded using a probabilistic data structure with a plurality of mapping functions into a lower dimensional space. Encoding the input to the machine learning model results in a compact machine learning model with a reduced model size. The compact machine learning model can output an encoded representation of a higher-dimensional space. Use of such a machine learning model can include decoding the output of the machine learning model into the higher dimensional space of the non-encoded input.,"['G06N3/08', 'G06N3/084', 'G06N3/04', 'G06N3/045', 'G06N7/01', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N5/01']"
WO2021047286A1,"Text processing model training method, and text processing method and apparatus","A text processing model training method, and a text method and apparatus in the field of natural language processing in the field of artificial intelligence. The training method comprises: obtaining training text (510); respectively inputting the training text into a teacher model and a student model to obtain sample data output by the teacher model and predicted data output by the student model, wherein the teacher model and the student model each comprises an input layer, an output layer, and one or more intermediate layers, the sample data comprises a sample semantic feature output by the intermediate layer of the teacher model and a sample label output by the output layer of the teacher model, the predicted data comprises a predicted semantic feature output by the intermediate layer of the student model and a prediction label output by the output layer of the student model, and the teacher model is a pre-trained language model for text classification (520); and training model parameters of the student model on the basis of the sample data and the predicted data to obtain a target student model (530). The method enables a student model to effectively carry out knowledge transfer, so that the accuracy of text processing results of the student model is improved.","['G06F40/216', 'G06F16/35', 'G06F16/355', 'G06F18/214', 'G06F18/241', 'G06F18/24133', 'G06F40/166', 'G06F40/279', 'G06F40/30', 'G06N3/042', 'G06N3/045', 'G06N3/0455', 'G06N3/084', 'G06N3/096']"
CN113506300B,Picture semantic segmentation method and system based on rainy day complex road scene,"The invention discloses a picture semantic segmentation method and a picture semantic segmentation system based on a rainy day complex road scene, and the invention constructs an end-to-end rain removing algorithm network structure which can reduce the rain removing time, improve the rain removing efficiency, completely does not need human intervention, and can greatly improve the quality of pictures for segmentation, thereby improving the segmentation precision; the invention constructs a semantic segmentation network, adopts an improved resnet structure as a backbone network to extract characteristics, adds a SEnet network into each resnet block, pays attention to the relation among channels, learns the importance degree of the characteristics among the channels, and gives different weights to each channel; in the up-sampling process, a feature alignment module FAM is introduced in consideration of the difference caused by different resolutions, and the module can learn the movement of pixel points between adjacent features, so that the information loss is avoided to the greatest extent. The invention adopts the offline pre-training semantic segmentation network, thereby improving the safety of the system.","['G06T7/10', 'G06F18/241', 'G06N3/045', 'G06N3/08', 'G06T5/73', 'G06T2207/10016']"
US11023514B2,"Methods and systems for generation, curation, and presentation of media collections","Systems and methods are provided for receiving, at a server computer, a plurality of content messages from a plurality of content sources, each content message comprising media content and associated with a predetermined media collection, for each of the plurality of content messages received, analyzing each of the plurality of content messages to determine a quality score for each of the plurality of content messages, and storing each of the plurality of content messages in a database along with the quality score for each of the plurality of content messages. The systems and methods further provided for receiving, from an operator device, a threshold percentage for the media collection, determining a subset of the plurality of content messages associated with the media collection to be made available to the operator device based on the threshold percentage received from the operator device and the quality score for each of the plurality of content messages, and causing only the subset of the plurality of content messages associated with media collection to be displayed on the operator device for the media collection.","['G06F16/435', 'G06F16/24578', 'G06F16/438', 'G06Q50/01']"
CN110228484B,Low-delay intelligent remote driving system with auxiliary driving function,"The invention relates to a low-delay intelligent remote driving system with an auxiliary driving function, which comprises a system front end, a system rear end and an auxiliary driving subsystem; the system front end collects the surrounding environment information of the driving tool and transmits the surrounding environment information back to the system rear end, so that a driver can observe events around the driving tool and remotely control the driving tool; the system front end sends the collected image information of the surrounding environment of the driving tool to the auxiliary driving subsystem, the auxiliary driving subsystem analyzes the surrounding environment of the driving tool, and when the auxiliary driving subsystem analyzes that a dangerous situation possibly occurs, a driver is prompted to remotely control the driving tool to make a corresponding evasive action in an alarm mode or the auxiliary driving subsystem directly sends a command to control the driving tool to make an evasive action. The auxiliary driving subsystem is added, so that the acquired information can be processed in real time; the overall delay of the loop for information return and control signal transmission is kept at a very low level by the 5G network as its carrier.","['B60W50/00', 'G06V10/25', 'G06V10/267', 'G06V20/56', 'B60W2050/0064']"
US11367281B2,Systems and methods for augmented reality navigation,"An augmented reality system including processors and storage devices storing instructions. The instructions may configure the processors to perform operations including determining a location of a mobile device, identifying a facility based on the location, requesting mapping data from a facility server, the mapping data comprising a plurality of vehicles, vehicle location data, and landmarks, identifying one location attribute in a video feed captured by an augmented reality viewer displayed in the mobile device, and determining whether the one location attribute matches the plurality of vehicles or the landmarks. The operations may also include identifying qualified vehicles from the vehicles based on qualification criteria, determining whether the qualified vehicles is in a field of view of the augmented reality viewer based on object attributes and the vehicle location data, and generating a modified video feed by providing an indication associated with qualified vehicles in the field of view.","['G06Q30/0281', 'G01C21/005', 'G01C21/20', 'G01S19/39', 'G01S5/16', 'G06F1/1686', 'G06F18/24', 'G06F3/011', 'G06F3/0304', 'G06K7/1417', 'G06K9/6267', 'G06N3/04', 'G06N3/045', 'G06Q10/087', 'G06Q30/0625', 'G06Q30/0643', 'G06Q40/025', 'G06Q40/03', 'G06T19/006', 'G06T19/20', 'G06T7/74', 'G06T7/90', 'G06V10/46', 'G06V20/20', 'G08G1/017', 'G06F3/04817', 'G06F3/0482', 'G06N20/10', 'G06N3/08', 'G06T2200/24', 'G06T2207/10016', 'G06T2207/20084', 'G06T2207/30252', 'G06T2219/2012', 'G06V20/63', 'G06V2201/08']"
US10218976B2,Quantization matrices for compression of video,"Provided is a process including: obtaining video data; forming a transform matrix; dynamically forming a first modified quantization matrix; quantizing the first transform matrix with the modified quantization matrix; serializing the first quantized transform matrix to form a first sequence of values; compressing the first sequence of values with entropy coding to produce compressed video data; and forming a video bitstream that includes the compressed video data and a header, the header containing a parameter that instructs a decoder to decode the first block with a quantization matrix different from the modified quantization matrix.","['H04N19/124', 'H04N19/126', 'H04N19/176', 'H04N19/18', 'H04N19/184', 'H04N19/44', 'H04N19/46', 'H04N19/625', 'G10L19/012']"
US20220300273A1,Over-the-air (ota) mobility services platform,"An over-the-air (OTA) mobility service platform (MSP) is disclosed that provides a variety of OTA services, including but not limited to: updating software OTA (SOTA), updating firmware OTA (FOTA), client connectivity, remote control and operation monitoring. In some exemplary embodiments, the MSP is a distributed computing platform that delivers and/or updates one or more of configuration data, rules, scripts and other services to vehicles and IoT devices. In some exemplary embodiments, the MSP optionally provides data ingestion, storage and management, data analytics, real-time data processing, remote control of data retrieving, insurance fraud verification, predictive maintenance and social media support.","['G05B23/0243', 'G06F8/65', 'H04L67/125', 'H04L67/34', 'G05B2219/24065', 'G06F8/60', 'G06F8/61', 'G06F8/658', 'H04L67/10', 'H04L67/60']"
US12032048B2,Machine learning for simultaneously optimizing an under-sampling pattern and a corresponding reconstruction model in compressive sensing,"Systems and methods are disclosed for optimizing a sub-sampling pattern for efficient capture of a sub-sampled image to be reconstructed to form a high-resolution image, in a data-driven fashion. For example, Magnetic Resonance Imaging (MRI) scans can be accelerated by under-sampling in k-space (i.e., the Fourier domain). Since the reconstruction model's success depends on the sub-sampling pattern, optimization of the sub-sampling pattern can be combined with optimization of the model, for a given sparsity constraint, using an end-to-end learning operation. A machine-learning model may be trained using full-resolution training data that are under-sampled retrospectively, yielding a sub-sampling pattern and reconstruction model that are customized to the type of images represented in the training data. The disclosed Learning-based Optimization of the Under-sampling PattErn (LOUPE) operations may implement a convolutional neural network architecture, appended with a forward model that encodes the under-sampling process.","['A61B5/055', 'A61B5/7203', 'A61B5/7267', 'G01R33/5608', 'G01R33/561', 'G06N3/045', 'G06N3/088', 'A61B2576/026', 'A61B5/4064', 'A61B5/4585', 'G06N3/048', 'G06N7/01']"
WO2022161000A1,"Training method and training apparatus for machine learning model, and evaluation system","A training method and training apparatus for a machine learning model for evaluating the performance of a 3D-printed member, an evaluation system for evaluating the performance of a 3D-printed member, a computer device, and a computer-readable storage medium. In the training method for a machine learning model, variables that affect the printing quality of a printed member are pre-determined, different printing parameters are set for different printed member models to perform actual printing and simulated printing so as to obtain training data, measured values of the performance of the printed member in an actual printing environment in a training data set are taken as output, and equivalent relaxation time data and/or residual stress data are/is taken as input, such that after training is completed, the machine learning model can evaluate the performance of the printed member on the basis of the equivalent relaxation time data and/or the residual stress data of the printed member, and thus printing parameters of printed members of different types can be associated with printing quality.","['G06F30/23', 'G06F30/27', 'G06N20/00', 'G16C10/00', 'G16C60/00', 'G06F2111/06', 'G06F2113/10', 'G06F2119/10', 'G06F2119/14']"
CN112232232B,Target detection method,"The application relates to a target detection method, wherein the method comprises the steps of obtaining an image; inputting the image into a feature extraction network, and obtaining a shallow feature map, a middle feature map and a deep feature map of the image through a plurality of residual error modules in the feature extraction network; and inputting the shallow feature map, the middle feature map and the deep feature map into a prediction network for fusion to obtain the position of the target to be detected in the image, the size of a surrounding frame of the target to be detected and the confidence coefficient. By the method, after the network is deepened and widened in the feature extraction part and the initial extraction of the features is completed, the features of multiple adjacent scales are fused, so that the local context information of three scales is aggregated by the penultimate feature fusion unit, more semantic information is obtained, more detailed information is contained, and the feature extraction precision of the model is improved.","['G06V20/40', 'G06N3/045', 'G06N3/08', 'G06V10/44', 'G06V10/464', 'G06V2201/07']"
US10692185B2,Generative methods of super resolution,"A method for training an algorithm to process at least a section of received visual data using a training dataset and reference dataset. The method comprises an iterative method with iterations comprising: generating a set of training data using the algorithm; comparing one or more characteristics of the training data to one or more characteristics of at least a section of the reference dataset; and modifying one or more parameters of the algorithm to optimise processed visual data based on the comparison between the characteristic of the training data and the characteristic of the reference dataset. The algorithm may output the processed visual data with the same content as the at least a section of received visual data. Some aspects and/or implementations provide for improved super-resolution of lower quality images to produce super-resolution images with improved characteristics (e.g. less blur, less undesired smoothing) compared to other super-resolution techniques.","['H04N19/59', 'G06T3/4076', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/08', 'G06T3/4046', 'G06T3/4053', 'G06N20/10', 'G06N20/20', 'G06N3/048', 'G06N5/01', 'G06T2207/20081']"
US9359018B2,Modular intelligent transportation system,"A modular intelligent transportation system, comprising an environmentally protected enclosure, a system communications bus, a processor module, communicating with said bus, having a image data input and an audio input, the processor module analyzing the image data and/or audio input for data patterns represented therein, having at least one available option slot, a power supply, and a communication link for external communications, in which at least one available option slot can be occupied by a wireless local area network access point, having a communications path between said communications link and said wireless access point, or other modular components.","['H04W40/02', 'B62D41/00', 'G07C5/008', 'G01S3/80', 'G07C5/0891', 'G08G1/205', 'H04L65/61', 'G01C21/26', 'H04M7/006', 'H04W84/12']"
CN111785257B,Empty pipe voice recognition method and device for small amount of labeled samples,"The invention relates to the field of civil aviation air traffic control and voice recognition, in particular to an air traffic control voice recognition method and device aiming at a small number of labeled samples. The method and the device train the recognition model backbone network by using the unlabeled data based on the neural network, can obtain the air traffic control voice recognition model with good recognition accuracy and high efficiency under the condition of labeling a small amount of samples, can accurately and quickly output corresponding air traffic control instruction text information based on the air traffic control voice recognition model after inputting the air traffic control voice, and improve the usability of the application of the air traffic control voice recognition technology and the expandability under a new scene.","['G10L15/063', 'G08G5/56', 'G10L15/02', 'G10L15/16', 'G10L15/22', 'G10L15/26', 'Y02T10/40']"
US7953270B2,Methods and arrangements employing digital content items,"Methods and arrangements for identifying content, and employing such identification, are detailed. One method embeds a plural-bit digital watermark into content, but first checks to see if the content is previously watermarked. Another method applies a digital watermark detection procedure to only a sub-portion of a digital content item. Yet another arrangement involves plural-portion content, where one portion is watermarked with first data governing its rights management, and another portion is watermarked with second data governing its rights management. Still another method concerns distribution of content items, where each is watermarked with a unique ID as part of the distribution process. Yet another method concerns deriving an identifier from content, and using the content to access related metadata from a remote computer system. Still other methods concern arrangements for recognizing content, and then providing links to information about the content creator, etc., in response. A variety of other technologies and improvements are also detailed.","['H04N1/32144', 'G06V30/40', 'H04N1/32352', 'H04N21/23892', 'H04N21/8358', 'H04N1/32122', 'H04N2201/3249']"
US7788008B2,Eye monitoring system and method for vehicular occupants,"System and method for determining the location of the eyes of a vehicular occupant includes one or more wave-receiving transducers each arranged to receive waves from the passenger compartment generated or modified by the occupant, and a processor coupled to the transducer(s) for analyzing the waves and determining the location of the occupant's eyes relative to the passenger compartment based on the analysis of the received waves. The processor may include a trained pattern recognition algorithm which has been trained using data about known locations of the eyes of occupants in different positions and waves received from the passenger compartment when the occupants in the different positions are present. The location of the eyes of the occupant relative to the passenger compartment may be used to control one or more components, each of which has a variable or adjustable operation based on the location of the eyes of the occupant.","['B60W40/08', 'G01G23/3728', 'B60R21/01', 'B60W2040/0809', 'B60W2040/0818', 'B60W2040/0872', 'B60W2040/0881', 'B60W2050/143', 'B60W2050/146', 'B60W2420/408']"
US20220114693A1,Image-based pose determination,"A steganographic digital watermark signal is decoded from host imagery without requiring a domain transformation for signal synchronization, thereby speeding and simplifying the decoding operation. In time-limited applications, such as in supermarket point-of-sale scanners that attempt watermark decode operations on dozens of video frames every second, the speed improvement allows a greater percentage of each image frame to be analyzed for watermark data. In battery-powered mobile devices, avoidance of repeated domain transformations extends battery life. A great variety of other features and arrangements, including machine learning aspects, are also detailed.","['G06T1/0092', 'G06T1/0064', 'G06T3/0006', 'G06T3/02', 'G06T7/32', 'G06T7/74', 'G06T2201/0051', 'G06T2201/0052', 'G06T2201/0061', 'G06T2201/0065', 'G06T2201/0601', 'G06T2207/20021', 'G06T2207/20048', 'G06T2207/20081', 'G06T2207/30244']"
CN110917529B,Transformer substation fire-fighting robot and operation method thereof,"The utility model provides a transformer substation fire-fighting robot and an operation method thereof, and the transformer substation fire-fighting robot comprises a mobile chassis and a fire-extinguishing mechanism, wherein the fire-extinguishing mechanism is arranged on the mobile chassis and comprises a dry powder spraying mechanism and an automatic spraying mechanism, the dry powder spraying mechanism comprises a plurality of dry powder tanks, the outlets of the dry powder tanks are connected to a spray head through pipelines, the spray head is arranged on a rotary head, and the rotary head is arranged on the mobile chassis through a lifting mechanism, so that the height and the angle of the dry powder spraying are adjustable; the self-spraying mechanism comprises at least one water inlet pipe, one end of the water inlet pipe is used for being connected with a fire-fighting water nozzle, the other end of the water inlet pipe is connected with a vertical pipe, the other end of the vertical pipe is provided with a rotary joint, and the rotary joint is provided with a spraying nozzle.","['A62C3/16', 'A62C27/00', 'A62C31/07', 'A62C31/12', 'A62C37/04']"
WO2022143128A1,"Video call method and apparatus based on avatar, and terminal","The embodiments of the present application are applicable to the technical field of terminals. Provided are a video call method and apparatus based on an avatar, and a terminal. The method is applied to a first terminal, and comprises: a first terminal collecting image data and audio data of a user during a call process; the first terminal extracting multiple frames of target feature information from the image data, wherein the multiple frames of target feature information comprise feature information for representing a facial expression and a head action of the user; and the first terminal transmitting the multiple frames of target feature information and the audio data to a second terminal, wherein the second terminal is used for mapping the multiple frames of target feature information into a preset target avatar, so as to generate a video call image, and the video call image contains the target avatar having the facial expression and the head action. By means of the method, the problem of it not being possible to use an avatar in a video call when a network condition is relatively poor can be solved.","['H04N7/141', 'G06T13/40', 'G06V40/16', 'H04N21/43', 'H04N21/4307', 'H04N21/8547', 'H04N7/14', 'H04N7/147']"
US11936654B2,Cloud-based user authorization control for storage system access,"Providing authorization and authentication in a cloud for a user of a storage array includes: receiving, by a storage array access module from a client-side array services module, a token representing authentication of user credentials and authorized access privileges defining one or more storage array services accessible by the user, where the token is generated by a cloud-based security module upon authentication of the user credentials and identification of authorized access privileges for the user; receiving, by the storage array access module from the user, a user access request to one or more storage array services; and determining, by the storage array access module, whether to grant the user access request in dependence upon the authorized access privileges represented by the token.","['G06F21/6218', 'H04L63/101', 'G06F9/45533', 'H04L63/0428', 'H04L63/0807', 'H04L63/0815', 'H04L67/1097', 'H04L9/3242', 'H04L9/3247', 'H04L9/50', 'H04L2209/24', 'H04L2209/72']"
US12014065B2,Multi-cloud orchestration as-a-service,"Multi-cloud orchestration as a service, including: receiving a provisioning request for one or more cloud computing resources; identifying, based on a first one or more metrics, a particular cloud computing environment from a plurality of cloud computing environments to satisfy the provisioning request; and provisioning, in the particular cloud computing environment, the one or more cloud computing resources.","['G06F3/0647', 'G06F11/3006', 'G06F11/302', 'G06F11/3075', 'G06F11/3409', 'G06F11/3447', 'G06F3/0605', 'G06F3/0614', 'G06F3/0631', 'G06F3/067', 'G06F11/3034', 'G06F11/3433']"
US12216927B2,Storing data for machine learning and artificial intelligence applications in a decentralized storage network,"Storing data for machine learning and artificial intelligence applications in a decentralized storage network, including: identifying a plurality of decentralized storage networks that a storage system can utilize for storing data, each of the plurality of decentralized storage networks comprising a collection of network connected computers operating as cooperative participants without employing dedicated servers for the storage of data; selecting, based characteristics of each decentralized storage network, one or more decentralized storage networks for storing the data; and initiating storage of the data on the selected one of more decentralized storage networks.","['G06F11/1076', 'G06F3/0604', 'G06F3/0647', 'G06F3/0653', 'G06F3/067', 'H04L67/1095', 'H04L67/1097', 'G06F11/2094', 'G06F2201/84']"
US20220008719A1,Biological co-processor (bcp),"Embodiments may provide a general-purpose, relatively inexpensive, AI-driven implant that is able to adapt to and modulate any given neuron, circuit, or region in the brain, as well as individual cells of any type of tissue. For example, in an embodiment, a method for interacting with living tissue may comprise attaching a device to living brain tissue of a person or animal, the device adapted to be implanted within a body of the person or animal, the device comprising an array of sensors in contact with the living brain tissue, receiving by sensors neural signals from the living brain tissue, processing the received signals by the device; and transmitting the processed signals.","['A61N1/0529', 'B82Y15/00', 'A61L27/383', 'A61N5/0622', 'G01N21/1702', 'G01N27/4145', 'A61B5/0093', 'A61N1/0531', 'A61N2005/0611', 'A61N2005/063', 'A61N5/06', 'A61N5/067', 'B82Y5/00']"
US9294074B2,Physiological signal denoising,"Physiological signals are denoised. In accordance with an example embodiment, a denoised physiological signal is generated from an input signal including a desired physiological signal and noise. The input signal is decomposed from a first domain into subcomponents in a second domain of higher dimension than the first domain. Target subcomponents of the input signal that are associated with the desired physiological signal are identified, based upon the spatial distribution of the subcomponents. A denoised physiological signal is constructed in the first domain from at least one of the identified target subcomponents.","['H03H17/0248', 'G06F17/14', 'A61B5/04017', 'A61B5/0452', 'A61B5/316', 'A61B5/33', 'A61B5/347', 'A61B5/349', 'G06F18/2134', 'G06F18/2135', 'G06K9/0051', 'G06K9/0053', 'A61B5/7253', 'G06F2218/04', 'G06F2218/10']"
US7887089B2,Vehicular occupant protection system control arrangement and method using multiple sensor systems,"Arrangement and method for controlling an occupant protection system in a vehicle which protects an occupant of a vehicular compartment during a crash involving the vehicle includes a first sensor system for obtaining information about the occupant, a second sensor system for determining a position of the occupant or a part thereof which enables a determination of the position of the occupant relative to the occupant protection system, and a processor coupled to the first and second sensor systems for controlling deployment of the occupant protection system based on the information about the occupant obtained by the first sensor system and the position of the occupant determined by the second sensor system. The first sensor system may include one or more optical imaging devices which obtain images of an area of the compartment occupied by the occupant, the information about the occupant being obtained by analysis of the images.","['B60R21/01534', 'B60R21/0152', 'B60R21/01536', 'B60R21/01538', 'B60R21/01542', 'B60R21/01552']"
US11265540B2,Apparatus and method for applying artificial neural network to image encoding or decoding,"The present disclosure relates to video encoding or decoding and, more specifically, to an apparatus and a method for applying an artificial neural network (ANN) to video encoding or decoding. The apparatus and the method of the present disclosure are characterized by applying a CNN-based filter to a first picture and at least one of a quantization parameter map and a block partition map to output a second picture.","['H04N19/117', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'H04N19/124', 'H04N19/157', 'H04N19/176', 'H04N19/82', 'H04N19/86']"
US20230117143A1,Efficient learning and using of topologies of neural networks in machine learning,"A mechanism is described for facilitating learning and application of neural network topologies in machine learning at autonomous machines. A method of embodiments, as described herein, includes monitoring and detecting structure learning of neural networks relating to machine learning operations at a computing device having a processor, and generating a recursive generative model based on one or more topologies of one or more of the neural networks. The method may further include converting the generative model into a discriminative model.","['G06N3/08', 'G06N7/01', 'G06N3/044', 'G06N3/045', 'G06T1/20']"
US10902183B2,Automated tagging of text,"A computer-implemented method of tagging a text, comprises: determining a value for each of a plurality of locations in a first vector; processing (402), by a trained first neural network component, the first vector to generate a second vector; processing (404), at a trained second neural network component, the second vector to generate a probability score for each of at least ten predetermined tags; determining (406) if each probability score meets a criterion; if the criterion is met, assigning (408) the tag corresponding to the probability score to the text. Each of the locations may correspond to a respective predetermined word, each value relating to existence and/or frequency of the corresponding word in the text, and the number of locations may be between 600 and 20000. The number of locations in the second vector may be fewer than the number of locations in the first vector and is from 100 to 5000.","['G06F16/313', 'G06F16/93', 'G06F40/117', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N7/005', 'G06N7/01']"
CN113966451B,"Information processing method, information processing device and program","The following processing is performed by the information processing apparatus: an operation setting based on conditions related to a situation at the time of operation of the air-conditioning apparatus, the comfort at the time of operation of the air-conditioning apparatus, and the power consumption at the time of operation of the air-conditioning apparatus is determined from a data set including a combination of information indicating the situation at the time of operation of the air-conditioning apparatus, information related to user comfort, and information related to power consumption.","['F24F11/47', 'H04Q9/00', 'F24F11/64', 'F24F11/70', 'F24F11/74', 'F24F11/79', 'F24F11/86', 'F24F11/871', 'F25B13/00', 'F25B49/02', 'G05B13/0265', 'F24F11/46', 'F24F2110/12', 'F24F2110/22', 'F24F2110/50', 'F24F2120/10', 'F24F2120/14', 'F24F2120/20', 'F24F2130/10', 'F24F2130/20', 'F24F2130/30', 'F24F2140/60', 'F25B2313/0293', 'F25B2313/0294', 'F25B2500/12', 'F25B2500/19', 'F25B2600/024', 'F25B2600/025']"
US11681640B2,Multi-channel communications between controllers in a storage system,"Enabling multi-channel communications between controllers in a storage array, including: creating a plurality of logical communications channels between two or more storage array controllers; inserting, into a buffer utilized by a direct memory access (‘DMA’) engine of a first storage array controller, a data transfer descriptor describing data stored in memory of the first storage array controller and a location to write the data to memory of a second storage array controller; retrieving, in dependence upon the data transfer descriptor, the data stored in memory of the first storage array controller; and writing, via a predetermined logical communications channel, the data into the memory of the second storage array controller in dependence upon the data transfer descriptor.","['G06F13/28', 'G06F12/023', 'G06F2212/254']"
US12273273B2,Mobile management system,"Mobile management method, system and client. The method includes receiving a DNS query for a host name from an application on a client; retrieving reputation data associated with the host name from a local cache on the client; determining a policy for the host name, which is associated with the host name and the reputation data associated with the host name; based on the determined policy for the host name, blocking attempted network flows to a host corresponding to the host name; sending at least attempted network flow metadata related to the blocked attempted network flows to a collector on the client; and transmitting the attempted network flow metadata in the collector to a VPN server pool via a VPN tunnel.","['G06N20/00', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'H04L12/4633', 'H04L12/4641', 'H04L61/4511', 'H04L63/1408', 'H04L63/1425', 'H04W12/66', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'H04L47/20', 'H04L63/0281', 'H04L63/20', 'H04W12/03', 'H04W12/12']"
US12105584B2,Acquiring failure information,An indication is received from a storage device that an attempt to read a portion of data from a block of the storage device has failed. A command is transmitted to the storage device to perform a scan on data stored at the block comprising the portion of data to acquire failure information associated with a plurality of subsets of the data stored at the block. The failure information associated with the plurality of subsets of the data stored at the block is received from the storage device.,"['G06F11/0793', 'G06F11/076', 'G06F11/108', 'G06F11/1092', 'G06F12/0246', 'G06F12/0253', 'G06F3/0619', 'G06F3/064', 'G06F3/0683', 'G06F2212/1044', 'G06F2212/7201', 'G06F2212/7205']"
CN109272992B,Spoken language evaluation method and device for generating spoken language evaluation model,"The application provides a spoken language evaluation method, a device and a device for generating a spoken language evaluation model, wherein the spoken language evaluation method is applied to a data processing end of a spoken language evaluation system and comprises the following steps: acquiring comment voice data to be detected; extracting the spoken language attribute feature information of the comment voice data to be detected; and obtaining a scoring result according to the spoken language attribute characteristic information of the speech data to be evaluated based on the pre-generated spoken language evaluation model.","['G10L15/063', 'G10L25/51', 'G10L2015/0631']"
CN113271400B,Imaging device and electronic equipment,"The present invention relates to an imaging apparatus and an electronic device. Wherein the imaging device may include: an imaging unit in which a plurality of pixels are two-dimensionally arranged, and which captures an image; a signal processing unit that performs at least a part of signal processing for data based on a subject image output from the imaging unit; an output I/F that outputs a signal processing result of the signal processing or intermediate data, and the subject image to the outside; and an output control unit that outputs at least one of the signal processing result of the signal processing unit and the subject image from the output I/F to the outside.","['H04N23/84', 'G01C3/06', 'G01S17/89', 'G01S17/93', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'H04N23/00', 'H04N23/54', 'H04N23/61', 'H04N23/617', 'H04N23/62', 'H04N23/70', 'H04N23/81', 'H04N25/443', 'H04N25/75', 'H04N25/76', 'H04N25/79', 'H10F39/12']"
KR20220050758A,Multi-directional scene text recognition method and system based on multidimensional attention mechanism,"Provided are a multi-directional scene text recognizing method based on a multi-dimensional attention mechanism and a system thereof. The multi-directional scene text recognizing method of the present invention comprises the steps of: normalizing a text row/column image I output from an external text detection module by a feature extractor, extracting a feature from a normalized image using a deep convolutional neural network, obtaining an initial feature map F_0, and superimposing a two-dimensional directional location code P on the initial feature map F_0 to output a multi-channel feature map F; converting, by an encoder, the multi-channel feature map F output from the feature extractor into an implicit expression H; and converting, by a decoder, the implicit expression H output from the encoder into a recognized text, and using the same as an output result. The multi-directional scene text recognizing method and the system thereof are applied to various directions such as the width and the height of a scene image and a curved text row, and have high applicability. Therefore, the better recognition capability for a scene text is provided.","['G06V20/62', 'G06V20/63', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/08', 'G06V10/40', 'G06V10/95', 'G06V30/166', 'G06V30/18057', 'G06V30/10']"
CN111325851B,"Image processing method and device, electronic equipment and computer readable storage medium","The embodiment of the disclosure provides an image processing method and device, electronic equipment and a computer readable storage medium. The method comprises the following steps: acquiring an image to be processed, wherein the image to be processed comprises an object to be processed; extracting features of the image to be processed to obtain the target key point position of the object to be processed; acquiring a training set, wherein the training set comprises a training sample with a target design style type, and the training sample comprises known key point positions and set slide bar parameters of a rendering engine corresponding to the target design style type; obtaining a weight coefficient of a training sample according to the target key point position of the object to be processed and the known key point position of the training sample; and obtaining target slide bar parameters of the object to be processed according to the weight coefficient of the training sample and the corresponding set slide bar parameters, and generating the virtual image of the object to be processed based on the target slide bar parameters. The scheme provided by the embodiment of the disclosure can adaptively migrate the design style of the training sample to the avatar of the image to be processed.","['G06T19/006', 'G06F18/214', 'G06F18/22', 'G06T19/20', 'G06T3/02', 'G06T7/10', 'G06V40/162', 'G06V40/171', 'G06T2207/30201', 'G06T2219/2024']"
US12094022B2,Systems and methods for disaster control,The present disclosure is related to systems and methods for disaster control. The method includes obtaining an alert message including information associated with a disaster in a target area. The method includes sending a first shooting instruction to at least one camera device to capture first image data associated with the target area. The method includes obtaining a plan for controlling the disaster from at least one processor. The first image data may be transmitted to the at least one processor through a communication network. The plan may be determined based on the information associated with the disaster and the first image data.,"['G06Q50/265', 'H04N7/181', 'B64C39/024', 'B64D47/08', 'G06V20/17', 'G06V20/52', 'G08B21/10', 'H04N23/698', 'H04N7/18', 'H04W4/40', 'H04W4/90', 'B64U10/13', 'B64U2101/30', 'B64U2201/10', 'B64U2201/20']"
US20200064444A1,"Method, apparatus, and system for human identification based on human radio biometric information","Methods, apparatus and systems for monitoring an object expression are described. In one example, a described apparatus in a venue comprises a receiver and a processor. The receiver is configured for: receiving a wireless signal from a transmitter through a wireless multipath channel that is impacted by an expression of an object in the venue, wherein the object has at least one movable part and is expressed in the expression with respect to a setup in the venue; and obtaining a time series of channel information (TSCI) of the wireless multipath channel based on the wireless signal received by the receiver. The processor is configured for computing information associated with the object based at least partially on the TSCI obtained when the object is expressed in the expression, and performing, based on the information associated with the object, a task associated with at least one of the object and the venue.","['G01S13/003', 'G01S13/931', 'G01S7/006', 'G01S7/412', 'G01S7/415', 'G01S7/417', 'G06N3/04', 'G06F2218/00']"
US11819369B2,Augmented reality device for providing feedback to an acute care provider,"A spatially sensitive augmented reality system for providing resuscitative feedback in a mixed reality environment to an acute care provider during occurrence of a cardiac event in a patient includes a wearable augmented reality device having at least one three-dimensional sensor, a visual display for viewing by the acute care provider, and at least one processor. The at least one processor is configured to receive and process three-dimensional information of a scene of the cardiac event; produce a three-dimensional representation of a field of view of the acute care provider based on the processed three-dimensional information; identify one or more physical objects associated with the cardiac event in the three-dimensional representation; generate at least one virtual three-dimensional object within the three-dimensional representation; and generate an image of the virtual three-dimensional object within the three-dimensional representation on the visual display.","['A61B90/36', 'A61B1/05', 'A61B1/267', 'A61B34/25', 'A61H31/005', 'A61M16/0084', 'A61M16/04', 'A61M16/0488', 'A61N1/39044', 'A61N1/3993', 'G09B23/288', 'G09B5/02', 'A61B2017/00207', 'A61B2017/00216', 'A61B2034/2048', 'A61B2034/254', 'A61B2034/256', 'A61B2034/258', 'A61B2090/3614', 'A61B2090/365', 'A61B2090/371', 'A61B2090/372', 'A61B2090/373', 'A61B2090/502', 'A61B90/96', 'A61H2201/10', 'A61H2201/5007', 'A61H2201/501', 'A61H2201/5012', 'A61H2201/5043', 'A61M2205/507', 'A61M2205/6009', 'A61M2205/6018', 'A61M2205/6072']"
US20200020165A1,Smart device,"An Internet of Thing (IoT) device includes a body with a processor, a camera and a wireless transceiver coupled to the processor.","['G06F3/017', 'G06T19/006', 'G06F3/011', 'G06K9/00342', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/045', 'G06N3/088', 'G06N7/005', 'G06N7/01', 'G06N99/005', 'G06T19/003', 'G06V40/23', 'G06N5/025', 'G06N5/046']"
US10433075B2,Low latency audio enhancement,A hearing aid system and method is disclosed. Disclosed embodiments provide for low latency enhanced audio using a hearing aid earpiece and an auxiliary processing unit wirelessly connected to the earpiece. These and other embodiments are disclosed herein.,"['H04R25/505', 'G10L25/78', 'H04R25/50', 'H04R25/554', 'H04R2225/39', 'H04R2225/41', 'H04R2225/51', 'H04R2225/55']"
CN113205568B,"Image processing method, device, electronic equipment and storage medium","The disclosure relates to an image processing method, an image processing device, electronic equipment and a storage medium, and belongs to the technical field of computers. The method comprises the following steps: smoothing the skin area of the target object to obtain a first image for an original image containing the target object; determining skin texture material corresponding to the face area based on the face area of the target object; rendering the skin texture material to obtain a face texture image corresponding to the target object, wherein the face key point information and the face posture information of the face texture image are matched with the target object; and fusing the face texture image and the first image to obtain a second image. The method and the device can restore the face texture details after the original image is ground, and weaken the false face feeling of the grinding belt on the basis of not introducing image noise, so that the image processing effect is improved.","['G06T5/50', 'G06T5/70', 'G06T11/001', 'G06T11/00', 'G06T15/04', 'G06T5/20', 'G06T5/77', 'G06T7/73', 'G06T2200/04', 'G06T2207/10004', 'G06T2207/20221', 'G06T2207/30201']"
CN117436004B,Motor performance real-time monitoring system and method,"The invention relates to the technical field of motor testing, in particular to a motor performance real-time monitoring system and a motor performance real-time monitoring method. According to the invention, data cleaning and normalization are carried out through Apache Spark distributed computation, the efficiency and reliability of data processing are improved, the application of K-means cluster analysis and association rule mining enables motor state monitoring to be finer, a fine operation mode is identified, a visual analysis module is introduced, a convolutional neural network and an isolated forest algorithm are combined, a complex abnormal image mode is identified by the system, comprehensive motor state analysis is provided, the abnormal mode identification module enhances the prediction capability of abnormal conditions, the network analysis module provides deep inter-component correlation analysis, and the adoption of the mode prediction module enables the system to conduct effective future trend prediction, and further enhances the capability of preventive maintenance.","['G06F18/24323', 'G01D21/02', 'G01R31/343', 'G06F18/10', 'G06F18/23213', 'G06N20/20', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/088', 'G06N3/098', 'G06Q50/06']"
US11670070B2,Cloud-edge-end cooperative control method of 5G networked unmanned aerial vehicle for security rescue,"The present invention discloses a cloud-edge-end cooperative control method of a 5G networked UAV for security rescue, including: an image acquisition step: performing, by a single-chip microcomputer, attitude resolution on data acquired by a detection sensor, to obtain image data; a sparse landmark map building step: performing, by a control platform, front-end feature point matching, local map building and optimization, loopback detection, and frame resolution on the image data, to generate a sparse landmark map; a three-dimensional dense map building step: generating, by an edge cloud, a three-dimensional dense map based on a key frame pose and key frame observation data of the sparse landmark map; a high-precision semantic map building step: obtaining a high-precision semantic map; and a UAV movement step: adjusting, by the driving mechanism, a pose of the UAV according to the three-dimensional dense map or the high-precision semantic map.","['G06V20/17', 'G06V10/443', 'G06T15/005', 'G06F16/29', 'G06T17/05', 'G06T7/33', 'G06V10/25', 'G06V10/255', 'G06V10/267', 'G06V10/757', 'G06V10/766', 'G06V10/82', 'G06V10/88', 'G08C17/02', 'H04L67/10', 'H04N21/2187', 'G06V20/56', 'Y02D10/00']"
US11620505B2,Neuromorphic package devices and neuromorphic computing systems,"A neuromorphic package device includes a systolic array package and a controller. The systolic array package includes neuromorphic chips arranged in a systolic array along a first direction and a second direction. The controller communicates with a host controls the neuromorphic chips. Each of the neuromorphic chips sequentially transfers weights of a plurality layers of a neural network system in the first direction to store the weights. A first neuromorphic chip performs a calculation based on stored weights therein and an input data received in the second direction, and provides a result of the calculation to at least one of a second neuromorphic chip and a third neuromorphic chip which are adjacent to the first neuromorphic chip. The at least one of the second and third neuromorphic chips performs a calculation based on a provided result of the calculation and stored weights therein.","['G06N3/065', 'G06N3/0635', 'G06N20/00', 'G06N3/04', 'G06N3/045', 'G06N3/049', 'G06N3/063', 'G06N3/08', 'G11C11/54', 'G11C13/0007', 'G11C13/003', 'G11C2213/15', 'G11C2213/79']"
US10046229B2,Smart device,"An Internet of Thing (IoT) device includes a body with a processor, a camera and a wireless transceiver coupled to the processor.","['A63B69/36', 'A42B3/0433', 'A61B5/11', 'A61B5/1116', 'A61B5/1118', 'A61B5/1128', 'A61B5/6804', 'A61B5/681', 'A63B43/004', 'A63B60/46', 'A63B69/38', 'A63B71/06', 'A63B71/145', 'B33Y10/00', 'G01L5/0052', 'G01L5/10', 'G01L5/226', 'G06F1/163', 'G06F3/00', 'G06F3/017', 'G06K9/00342', 'G06V10/143', 'G06V10/44', 'G06V10/462', 'G06V10/48', 'G06V10/753', 'G06V20/58', 'G06V30/142', 'G06V40/113', 'G06V40/23', 'G06V40/28', 'G09B19/0038', 'G16H20/30', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'H04L67/131', 'H04N23/57', 'H04N5/2257', 'H04W4/027', 'H04W4/38', 'H04W84/18', 'A42B3/046', 'A61B5/163', 'A61B5/165', 'A61B5/18', 'A61B5/6826', 'A61B5/6893', 'A63B2071/1233', 'A63B2071/125', 'A63B2071/1283', 'A63B21/072', 'A63B21/0724', 'A63B21/0726', 'A63B2207/02', 'A63B2220/12', 'A63B2220/13', 'A63B2220/16', 'A63B2220/20', 'A63B2220/24', 'A63B2220/30', 'A63B2220/40', 'A63B2220/51', 'A63B2220/53', 'A63B2220/56', 'A63B2220/72', 'A63B2220/74', 'A63B2220/75', 'A63B2220/76', 'A63B2220/803', 'A63B2220/806', 'A63B2220/807', 'A63B2220/833', 'A63B2220/836', 'A63B2225/30', 'A63B2225/50', 'A63B2225/54', 'A63B2225/74', 'A63B2230/06', 'A63B2230/60', 'A63B2230/70', 'A63B2243/0025', 'A63B2243/0037', 'A63B2243/0054', 'A63B2243/0066', 'A63B2243/007', 'A63B2243/0095', 'A63B2244/102', 'A63B2244/18', 'A63B2244/19', 'A63B2244/20', 'A63B2244/203', 'A63B69/0002', 'A63B69/0026', 'A63B69/0028', 'A63B69/0048', 'A63B69/0071', 'A63B69/02', 'A63B69/06', 'A63B69/16', 'A63B69/3632', 'A63B71/085', 'A63B71/10', 'A63B71/1216', 'A63B71/1291', 'A63B71/141', 'G01N2291/02483', 'G01N29/14', 'H04B1/04', 'H04L67/10', 'H04N7/18', 'H04W4/80', 'H04W88/02']"
US12001944B2,Tool for facilitating efficiency in machine learning,"A mechanism is described for facilitating smart distribution of resources for deep learning autonomous machines. A method of embodiments, as described herein, includes detecting one or more sets of data from one or more sources over one or more networks, and introducing a library to a neural network application to determine an optimal point at which to apply frequency scaling without degrading performance of the neural network application at a computing device.","['G06N3/063', 'G06F9/46', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N5/01', 'G06F9/505']"
US11674883B2,Image-based assay performance improvement,"The present invention is related to correct the errors in instruments, operation, and others using intelligent monitoring structures and machine learning, and others.","['G01N15/1484', 'G01N1/2813', 'G01N15/1468', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T1/0014', 'G01N2001/282']"
EP3972262A1,"Screencasting display method, and electronic apparatus","Embodiments of this application provide a projection display method and an electronic device, and relate to the field of terminal technologies, to dynamically adjust, based on a quantity of source devices, a parameter of display data projected onto a destination device, so as to improve display smoothness and use experience of a user during projection. The method includes: A source device sends a projection instruction to a destination device, where the projection instruction is used to instruct to project a display interface of the source device onto the destination device for display. The source device receives a first broadcast sent by the destination device, where the first broadcast includes a quantity N of source devices that need to perform projection onto the destination device for display. The source device negotiates a first projection parameter with the destination device based on the quantity N of the source devices, where the first projection parameter includes one or more of a projection resolution, a transmission bit rate, or an encoding compression rate. The source device sends first display data to the destination device based on the first projection parameter.","['H04N9/3188', 'G06F3/14', 'G09G3/001', 'G09G5/14', 'H04N21/2662', 'H04N21/4122', 'H04N21/4126', 'H04N21/41407', 'H04N21/4312', 'H04N21/436', 'H04N21/43632', 'H04N21/43637', 'H04N21/440263', 'H04N21/440281', 'H04N21/4408', 'G09G2370/04', 'G09G2370/20']"
US20250111534A9,Systems and Methods for Image-Based Location Determination,Embodiments relate to systems and methods of location determination based on images. Embodiments perform comparison of an input image to images in a library of reference background images using a background matching module to identify a matching image. Embodiments determine location associated with the input image based on the metadata associated with the matching background image.,"['B01J20/28026', 'B01J20/28033', 'B01J20/2808', 'C08G18/4072', 'C08G18/485', 'C08G18/632', 'C08G18/7621', 'C08J5/18', 'C08J9/0066', 'C08K3/36', 'G01S19/13', 'G06N3/0464', 'G06N3/08', 'G06Q50/10', 'G06T7/248', 'G06T7/74', 'G06V10/46', 'G06V10/70', 'G06V10/751', 'G06V10/82', 'G06V20/39', 'G06V20/52', 'G06V20/56', 'G06V20/582', 'G06V20/586', 'G08G1/0175', 'G08G1/04', 'H04N7/181', 'C08G2110/0008', 'C08G2110/005', 'C08G2110/0083', 'C08J2205/06', 'C08J2323/06', 'C08J2375/08', 'C08K2201/005', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30232', 'G06T2207/30248', 'G06V20/625', 'G06V2201/10']"
US12354438B2,Management system of substitute currency for gaming,"A detection system including a control device detecting fraud performed in a game table by using a result of an image analysis performed by an image analyzing device is included. A substitute currency for gaming used for this detection system has a multi-layer structure in which a plurality of plastic layers having different colors are stacked, a coloring layer is included at least in the middle, and white layers or thin-color layers (may be layers having a color thinner than that of the coloring layer; not illustrated in the drawing) are stacked on both sides of the coloring layer disposed in the middle.","['G07F17/3241', 'G06K19/07749', 'G07F17/3209', 'G07F17/322', 'G07F17/3248', 'G06K19/047']"
US7769513B2,Image processing for vehicular applications applying edge detection technique,Arrangement and method for obtaining information about objects in an environment in or around a vehicle includes one or more optical imagers for obtaining images of the environment and a processor coupled to the imager(s) for obtaining information about an object in one or more images obtained by the imager(s). The processor is arranged to process the obtained images to determine edges of objects in the images and input data about the edges into a trained pattern recognition algorithm which has been trained to provide information about the object as output. The pattern recognition algorithm may include a neural network or variation thereof. The information about the object may be used to control a vehicular component such as an airbag or light filter.,"['B60N2/028', 'G06V10/143', 'G06V20/593']"
US7676062B2,Image processing for vehicular applications applying image comparisons,"Vehicle including a compartment receivable of an object and a system for tracking the object includes at least one imaging device each arranged to receive an image of a portion of the compartment containing the object and a control unit coupled to each imaging device and which controls the imaging device to obtain a first set of images without the object and at least one second image including the object. The control unit analyzes the second image(s) in consideration of the first set of images to derive information about the object. This information may be the type, size and/or position of the object or a part thereof. The information may be used to control vehicular components which have a variable use based on the type, size or position of the object or part thereof.","['B60R21/01552', 'B60R21/0152', 'G06V10/143', 'G06V20/593', 'B60R21/0153']"
US12347270B2,Inspection system and management system,"When an unfair gaming currency is delivered to a dealer from a player, the currency is detected as unfair. The inspection system for inspecting the gaming currency, in which an RF tag is built, comprises: a gaming currency tray for housing the gaming currencies of the dealer in a casino game; an RF reader for reading the RF tags of the plural gaming currencies housed in the gaming currency tray; plural photosensors for detecting at least the number of the plural gaming currencies housed in the gaming currency tray at a constant time interval or always in a method other than RFID; and an inspection/alarm part for generating alarms when the number of the gaming currencies whose RF tags are read by the RF reader is not equal to the number of the gaming currencies detected by the plural photosensors.","['G07F17/3241', 'A44C21/00', 'A63F1/06', 'A63F1/067', 'A63F1/18', 'A63F3/00', 'A63F3/00157', 'A63F9/24', 'B32B27/08', 'B32B37/182', 'G01G19/52', 'G01G19/62', 'G06F1/187', 'G06K19/047', 'G06K19/0723', 'G06K19/077', 'G06K7/10237', 'G06K7/10366', 'G06K7/10415', 'G06Q20/00', 'G06Q20/208', 'G06Q50/10', 'G06Q50/34', 'G07D11/22', 'G07D11/50', 'G07D5/00', 'G07D5/04', 'G07D5/08', 'G07F17/32', 'G07F17/3206', 'G07F17/3209', 'G07F17/322', 'G07F17/3223', 'G07F17/3232', 'G07F17/3234', 'G07F17/3237', 'G07F17/3248', 'G07F17/3251', 'G07G1/00', 'G07G1/0072', 'H05K7/1401', 'H05K7/1489', 'A63F2009/2435', 'A63F2009/2489', 'A63F2250/58', 'G06T2207/20084', 'G07F17/3293']"
CN114863236B,Image object detection method based on dual attention mechanism,"The invention discloses an image target detection method based on a dual-attention mechanism, which comprises the following steps: cutMix, performing operations on the plurality of training pictures to obtain preprocessing data; based on a convolutional neural network, extracting image features in the preprocessed data to form a pyramid structure from bottom to top, and obtaining a multi-scale feature map; based on a dual-attention mechanism, embedding the multi-scale feature map into a detection module network of a target detection model to obtain a dual-attention information feature map; candidate regions of the input samples are generated from the dual attention information profile. According to the image target detection method based on the dual-attention mechanism, the multi-directional fusion characteristics containing rich context information are sent into a detection network through the multi-directional characteristic fusion mechanism; the attention mechanism is deployed on the channel and the space dimension, so that different branches screen effective information from the master-slave characteristic diagram according to training targets, the capability of the network for focusing on the effective information is improved, and the generalization capability and the detection performance are improved.","['G06V10/806', 'G06F18/2415', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06V10/40', 'G06V10/764', 'G06V10/766', 'G06V10/82', 'G06V2201/07']"
US11969596B2,"Implantable closed-loop neuromodulation device, systems, and methods of use","Described herein are implantable closed-loop neuromodulation devices, systems that includes such devices and an interrogator configured to emit ultrasonic waves that power the device, methods of using such devices and systems, and methods of modulating neural activity. The implantable device can include one or more curved members extending from a body. The curved members are configured to at least partially circumscribe a nerve, and include one or more electrode pads. The body includes an ultrasonic transducer configured to receive ultrasonic waves and convert energy from the ultrasonic waves into an electrical energy; and a computational circuit configured to receive a detection signal based on a detected electrophysiological signal, generate a stimulation signal based on the detection signal, and operate the electrode pads of to emit an electrical pulse to the nerve based on the stimulation signal.","['A61N1/36135', 'A61N1/36132', 'A61N1/0556', 'A61N1/36125', 'A61N1/36139', 'A61N1/3787']"
US10885559B1,"Generation, curation, and presentation of media collections with automated advertising","Systems, devices, media, instructions, and methods for computer based automated content generation, curation, and presentation are described. In one embodiment a content collection is generated with a first continuous presentation group by associating a first content element from a first content message of the plurality of content messages and a second content element from a second content message of the plurality of content messages to associate the first content element and the second content element as the first continuous presentation group. Advertising element placement within the presentation order for the first media collection is determined, and adjusted to avoid interrupting the continuous presentation group. In other embodiments, various advertising patterns are used and adjusted based on curated presentation groups within content collections.","['G06Q30/0276', 'G06F3/04817', 'G06F3/04847', 'G06F40/166', 'G11B27/031', 'G11B27/28', 'H04N21/23424', 'H04N21/2668', 'H04N21/812']"
CN109918184B,"Picture processing system, method and related device and equipment","The embodiment of the application discloses a picture processing system, a picture processing method, a related device and equipment, wherein the picture processing system stores large-scale picture data by using a distributed storage system, the stored large-scale picture data is preprocessed by using a distributed computing system to generate training data for training a neural network model, and then the generated training data is stored by using the distributed storage system, so that the storage requirement and the processing requirement of the large-scale picture data are met; in addition, in order to ensure that the generated training data set meets the training requirement of the deep neural network model, a client in the system can break up the picture set, and in the process of preprocessing the picture data by using the distributed computing system and storing the picture data by using the distributed storage system, a specific processing mode is adopted to ensure that the picture data in the obtained training data set for training the neural network model is randomly broken up.",[]
US11057631B2,Point cloud coding standard conformance definition in computing environments,"A mechanism is described for facilitating defining of interoperability signaling and conformance points for the PCC standard in computing environments. A computing device of embodiments, as described herein, includes a decoder to decode a compressed bitstream of video data representing a point cloud, point cloud reconstructor circuitry to reconstruct a point cloud from the decoded patch video data, a syntax element parser to receive at least one syntax element representing interoperability signaling in the compressed bitstream to indicate the number of points in one or more pictures of the video data, and processing hardware to determine if the number of points in the one or more pictures of the compressed bitstream is within the conformance limits of the point cloud reconstructor circuitry.","['H04N19/196', 'H04N19/136', 'H04N19/42', 'H04N19/463', 'H04N19/597', 'H04N19/70']"
CN109069100B,Ultrasound imaging system and method thereof,"A computing system, comprising: a memory for storing instructions and a processor for executing instructions. The processor executes the instructions to perform the steps of: receiving data relating to an image or a user; determining a characteristic in the data; determining a user preference from a user profile; obtaining a model; segmenting the image based on the features, the user preferences, and the model. The model is generated by: determining historical characteristics from the historical data as an input; determining a desired output; obtaining an initial model based on said inputs and said desired outputs; determining an actual output of one of said initial models; determining an error between an actual output of the initial model and the desired output; generating the model by updating the initial model according to the error.","['G01S7/003', 'A61B8/5215', 'A61B8/5269', 'A61B8/5292', 'A61B8/565', 'G01S7/52084', 'G01S7/52098', 'G06F18/23', 'G06F18/24', 'G06T5/60', 'G06T7/10', 'G06T7/11', 'G06V10/20', 'G06V10/44', 'G06V10/762', 'G06V10/764', 'G06V10/82', 'G16H30/40', 'G16H50/20', 'G06T2207/10132', 'G06T2207/20008', 'G06T2207/20081', 'G06V2201/03']"
US20230267375A1,"Distributed Machine Learning Systems, Apparatus, And Methods","A distributed, online machine learning system is presented. Contemplated systems include many private data servers, each having local private data. Researchers can request that relevant private data servers train implementations of machine learning algorithms on their local private data without requiring de-identification of the private data or without exposing the private data to unauthorized computing systems. The private data servers also generate synthetic or proxy data according to the data distributions of the actual data. The servers then use the proxy data to train proxy models. When the proxy models are sufficiently similar to the trained actual models, the proxy data, proxy model parameters, or other learned knowledge can be transmitted to one or more non-private computing devices. The learned knowledge from many private data servers can then be aggregated into one or more trained global models without exposing private data.","['G06N20/00', 'G06F21/6254', 'G06N20/10', 'G16H10/60', 'G16H40/20', 'G16H50/20', 'G16H50/50', 'G06F21/6245']"
CN111814719B,Skeleton behavior recognition method based on 3D space-time diagram convolution,"The invention provides a skeleton behavior recognition method based on 3D space-time diagram convolution, which not only can realize the simultaneous spatial modeling and time modeling of skeleton information, but also can represent the connectivity between space-time information; meanwhile, the method can obtain excellent recognition accuracy on a large skeleton data set, and has good generalization performance. According to the technical scheme, a 3D space-time diagram convolutional neural network model is constructed by combining a Laplacian of a 2D diagram convolution and a time Laplacian of a plurality of frames, and updating of a current node in the 3D space-time diagram convolutional neural network model depends on the state of a joint node connected with the current node in the current 2D diagram, and is related to the node state of a corresponding node in the adjacent 2D diagram; and the convolution of the 3D graph is constructed by combining the related state information in the current 2D graph and the state information of the same node in the adjacent 2D graphs which are adjacent front and back, so that the communication of the space information and the time information is realized.","['G06V40/20', 'G06F18/214', 'G06N3/045', 'G06V20/40']"
CN115326783B,"Raman spectrum preprocessing model generation method, system, terminal and storage medium","The invention relates to a method, a system, a terminal and a storage medium for generating a Raman spectrum preprocessing model, which are characterized in that noise, a baseline background signal and a Raman peak in a real Raman spectrum library are extracted and built, raman characteristic peaks in the Raman peak library are freely combined to generate an ideal spectrum library without noise and the baseline background signal, the extracted noise and the baseline background signal are superposed on the ideal spectrum library to generate a reference spectrum library, the ideal spectrum library and a random Gaussian noise input generator generate a simulation spectrum library, a discriminator and the generator form countertraining, and a high-simulation Raman spectrum library conforming to the real Raman spectrum characteristic is generated after the training is finished; training a spectrum preprocessing model based on an automatic supervision algorithm by using the library so as to complete automatic parameter setting; the ideal spectrum library is used as a label for model training, the model can be directly used for processing the actually acquired spectrum after the training is finished, the use is simple and quick, the effect of denoising and baseline background removing is good, and the spectrum is high in fidelity.","['G01N21/65', 'G01N21/658', 'G06F30/27']"
US11487939B2,Systems and methods for unsupervised autoregressive text compression,"Embodiments described herein provide a provide a fully unsupervised model for text compression. Specifically, the unsupervised model is configured to identify an optimal deletion path for each input sequence of texts (e.g., a sentence) and words from the input sequence are gradually deleted along the deletion path. To identify the optimal deletion path, the unsupervised model may adopt a pretrained bidirectional language model (BERT) to score each candidate deletion based on the average perplexity of the resulting sentence and performs a simple greedy look-ahead tree search to select the best deletion for each step.","['G06F40/284', 'G06F40/40', 'G06N3/088', 'H03M7/3084', 'H03M7/42', 'H03M7/3059']"
US20250090990A1,Systems for oxygen production,"An oxygen production system (100) may include a main control module (120) and a molecular sieve module (140). The molecular sieve module (140) may include a molecular sieve configured to separate oxygen from air and a molecular sieve information unit. The molecular sieve information unit may be configured to store information of the molecular sieve. The main control module (120) may be configured to read, write and/or update the information of the molecular sieve stored in the molecular sieve information unit. The oxygen production system (100) may occupy small space, have good performance and a high oxygen production efficiency, and enable a user to obtain a more user-friendly experience.","['B01D53/04', 'G16H20/40', 'A61M16/0003', 'A61M16/0051', 'A61M16/022', 'A61M16/024', 'A61M16/10', 'A61M16/101', 'A61M16/201', 'A61M16/202', 'B01D53/047', 'B01D53/053', 'C01B13/0259', 'C01B13/027', 'G05D11/13', 'G06N3/08', 'G16H10/00', 'G16H40/60', 'A61M16/0063', 'A61M16/0677', 'A61M16/204', 'A61M16/208', 'A61M2016/0015', 'A61M2016/0021', 'A61M2016/0027', 'A61M2016/0033', 'A61M2016/1025', 'A61M2202/0208', 'A61M2205/276', 'A61M2205/332', 'A61M2205/3365', 'A61M2205/3368', 'A61M2205/3553', 'A61M2205/3592', 'A61M2205/3606', 'A61M2205/362', 'A61M2205/502', 'A61M2205/52', 'A61M2205/581', 'A61M2205/582', 'A61M2205/6009', 'A61M2205/6072', 'A61M2205/609', 'A61M2205/7545', 'A61M2205/8206', 'A61M2205/8237', 'A61M2230/06', 'A61M2230/205', 'A61M2230/30', 'A61M2230/40', 'A61M2230/63', 'B01D2253/108', 'B01D2256/12', 'B01D2259/40007', 'B01D2259/40009', 'B01D2259/4533']"
US20230012186A1,System and method for vibroacoustic diagnostic and condition monitoring a system using neural networks,"A method for diagnostic and condition monitoring of a system includes receiving data from one or more sensors, the data associated with the system; generating an audio feature based on the data; inputting the audio feature into a neural network model; and receiving one or more attribute predictions and a state prediction from the neural network model. In some embodiments, the monitored system is a vehicle and the one or more sensors are vibroacoustic sensors.","['G07C5/0833', 'G07C5/0808', 'G07C5/008']"
US10068557B1,Generating music with deep neural networks,"The present disclosure provides systems and methods that include or otherwise leverage a machine-learned neural synthesizer model. Unlike a traditional synthesizer which generates audio from hand-designed components like oscillators and wavetables, the neural synthesizer model can use deep neural networks to generate sounds at the level of individual samples. Learning directly from data, the neural synthesizer model can provide intuitive control over timbre and dynamics and enable exploration of new sounds that would be difficult or impossible to produce with a hand-tuned synthesizer. As one example, the neural synthesizer model can be a neural synthesis autoencoder that includes an encoder model that learns embeddings descriptive of musical characteristics and an autoregressive decoder model that is conditioned on the embedding to autoregressively generate musical waveforms that have the musical characteristics one audio sample at a time.","['G10H1/0041', 'G06N3/04', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10H1/0025', 'G10H7/10', 'G10H7/12', 'G10H2210/111', 'G10H2220/116', 'G10H2250/311', 'G10H2250/605', 'G10H2250/615', 'G10H2250/621']"
US12046026B2,Systems and methods for keypoint detection with convolutional neural networks,"A keypoint detection system includes: a camera system including at least one camera; and a processor and memory, the processor and memory being configured to: receive an image captured by the camera system; compute a plurality of keypoints in the image using a convolutional neural network including: a first layer implementing a first convolutional kernel; a second layer implementing a second convolutional kernel; an output layer; and a plurality of connections between the first layer and the second layer and between the second layer and the output layer, each of the connections having a corresponding weight stored in the memory; and output the plurality of keypoints of the image computed by the convolutional neural network.","['G06V10/82', 'G06F18/214', 'G06F18/2414', 'G06N3/045', 'G06N3/084', 'G06T7/001', 'G06T7/246', 'G06V10/44', 'G06V10/454', 'G06V10/462', 'G06V10/757', 'G06V10/764', 'G06N3/063', 'G06T2207/10016', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/10048', 'G06T2207/20081', 'G06T2207/20084', 'H04N23/20', 'H04N5/33']"
US11133204B2,Chamber matching with neural networks in semiconductor equipment tools,"A server trains a neural network by feeding a first set of input time-series data of one or more sensors of a first processing chamber that is within specification to the neural network to produce a corresponding first set of output time-series data. The server calculates a first error. The server feeds a second set of input time-series data from corresponding one or more sensors associated with a second processing chamber under test to the trained neural network to produce a corresponding second set of output time-series data. The server calculates a second error. Responsive to the difference between a second error between the second set of input time-series data and the corresponding second set of output time-series data and a first error between the first set of input time-series data and the corresponding first set of output time-series data being equal to or exceeding a threshold amount, the server declares that the second processing chamber under test mismatches the first processing chamber that is within specifications.","['H01L21/67253', 'H01J37/32935', 'G06N3/08', 'G05B19/41875', 'G06N3/049', 'H01J37/32889', 'H01L21/67184', 'H01L21/67242', 'G05B2219/45031', 'Y02P90/02']"
US11657830B2,Data driven radio enhancement,"Systems and methods are disclosed for data driven radio enhancement. For example, methods may include demodulating a radio signal to obtain a demodulated audio signal; determining a window of audio samples based on the demodulated audio signal; applying an audio enhancement network to the window of audio samples to obtain an enhanced audio segment, in which the audio enhancement network includes a machine learning network that has been trained using demodulated audio signals derived from radio signals; and storing, playing, or transmitting an enhanced audio signal based on the enhanced audio segment.","['G10L21/0364', 'G10L21/0208', 'G06N3/006', 'G06N3/04', 'G06N3/045', 'G06N3/084', 'G06N3/086', 'G10L21/04', 'G10L25/30', 'H04L1/0045', 'H04L1/08', 'G06N3/048', 'G10L25/81', 'G10L25/84']"
US10670416B2,Traffic sign feature creation for high definition maps used for navigating autonomous vehicles,"An HD map system represents landmarks on a high definition map for autonomous vehicle navigation, including describing spatial location of lanes of a road and semantic information about each lane, and along with traffic signs and landmarks. The system generates lane lines designating lanes of roads based on, for example, mapping of camera image pixels with high probability of being on lane lines into a three-dimensional space, and locating/connecting center lines of the lane lines. The system builds a large connected network of lane elements and their connections as a lane element graph. The system also represents traffic signs based on camera images and detection and ranging sensor depth maps. These landmarks are used in building a high definition map that allows autonomous vehicles to safely navigate through their environments.","['G01C21/3638', 'B60W40/04', 'G01C21/32', 'G01C21/3635', 'G01C21/3811', 'G01C21/3867', 'G05D1/0088', 'G06K9/00798', 'G06K9/00818', 'G06K9/44', 'G06K9/4638', 'G06T17/00', 'G06T17/05', 'G06V10/34', 'G06V10/457', 'G06V20/582', 'G06V20/588', 'B60W2420/403', 'B60W2420/408', 'B60W2420/42', 'B60W2420/52']"
US10685284B2,Systems and methods for malicious code detection,"There is provided a neural network system for detection of malicious code, the neural network system comprising: an input receiver configured for receiving input text from one or more code input sources; a convolutional neural network unit including one or more convolutional layers, the convolutional unit configured for receiving the input text and processing the input text through the one or more convolutional layers; a recurrent neural network unit including one or more long short term memory layers, the recurrent neural network unit configured to process the output from the convolutional neural network unit to perform pattern recognition; and a classification unit including one or more classification layers, the classification unit configured to receive output data from the recurrent neural network unit to perform a determination of whether the input text or portions of the input text are malicious code or benign code.","['G06N3/084', 'G06F17/16', 'G06F21/563', 'G06N3/04', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/048', 'G06N3/0481', 'G06N3/082', 'H04L63/1416', 'H04L63/145', 'G06F2221/033']"
US11748106B2,Data operations and finite state machine for machine learning via bypass of computational tasks based on frequently-used data values,"A mechanism is described for facilitating fast data operations and for facilitating a finite state machine for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting input data to be used in computational tasks by a computation component of a processor including a graphics processor. The method may further include determining one or more frequently-used data values (FDVs) from the data, and pushing the one or more frequent data values to bypass the computational tasks.","['G06F9/4498', 'G06F9/4881', 'G06F9/3832', 'G06F9/5027', 'G06F9/544', 'G06T1/20', 'G06F2209/5018']"
CN111898172B,Experience learning in virtual worlds,"More particularly, the present invention relates to a computer-implemented machine learning method. The method includes providing a test dataset of a scene. The test dataset belongs to a test domain. The method includes providing a domain adaptive neural network. The domain adaptive neural network is a machine learning neural network that learns data obtained from training domains. The domain adaptive neural network is configured to infer spatially reconfigurable objects in a scene of the test domain. The method also includes determining an intermediate domain. The intermediate domain is closer to the training domain than the test domain in terms of data distribution. The method further includes inferring, by applying the domain adaptive neural network, objects that are spatially reconfigurable from the context of the test domain shifted over the intermediate domain. Such a method constitutes an improved machine learning method with a dataset comprising a scene of spatially reconfigurable objects.","['G06N3/08', 'G06N3/045', 'G06F30/12', 'G06F18/25', 'G06F30/20', 'G06N3/04', 'G06N3/0464', 'G06N3/0475', 'G06N3/09', 'G06N3/094', 'G06N3/096', 'G06F2111/00', 'G06N3/008']"
AU2023214234B2,Vibration while drilling data processing methods,"A method for determining properties of rock formations being drilled using drill string vibration measurements, comprising: entering, into at least one processor, signals corresponding to vibrations detected along a rotating part of a drill string while drilling a borehole; in the processor, transforming the detected vibration signals into transformed signals representing an elastic response of the drill string combined with rock properties at an interface between rock formations being drilled and a drill bit of the drill string; and in the processor, calculating properties of the rock formations being drilled using the transformed signals.","['G01V1/50', 'E21B49/003', 'G01V1/42', 'G01V1/46', 'G01V20/00', 'G01V11/00', 'G01V2200/16', 'G01V2210/1216', 'G01V2210/48', 'G01V2210/6163', 'G01V2210/6167', 'G01V2210/6169', 'G01V2210/6222', 'G01V2210/6224', 'G01V2210/6242']"
CN111897964B,"Text classification model training method, device, equipment and storage medium","The application discloses a text classification model training method, device, equipment and storage medium, and belongs to the field of artificial intelligence. According to the embodiment of the application, on one hand, the countermeasure sample is introduced, and the text classification model is trained by using the text sample and the countermeasure sample, so that the text classification model learns a classification method for the disturbed text, the robustness of the text classification model is improved, and the accuracy of text classification is improved. On the other hand, the text classification model can reconstruct the text characteristics of the countermeasure sample extracted during classification, restore the text characteristics into text contents, and improve the interpretability of the countermeasure training method. Model parameters are trained by combining errors between the reconstructed text content and the text content of the text sample, so that the text classification model can extract more accurate text features, namely more accurate feature expression of the text content is obtained, and the robustness and accuracy of feature extraction of the text classification model are improved.","['G06F16/35', 'G06F18/214', 'G06F18/22', 'G06F40/30', 'G06N3/045', 'G06N3/047', 'G06N3/08']"
CN112801146B,A target detection method and system,"The invention discloses a target detection method and a target detection system, aiming at the characteristic that a target detection task needs to pay attention to the region where a specific category target corresponds to an original image, an attention mechanism is applied to target detection, a designed network structure is different from a general meta-learning network framework, category probability supervision obtained by a category branch layer is adopted to supervise a category attention layer connected with a feature extraction layer, so that a regression branch layer is guided to calculate the target position, a self-supervision attention mechanism based on category distinction is realized, and the detection precision of a target detection model is improved. Furthermore, the small sample target detection task is combined, the characteristics that the small sample characteristics are difficult to learn by a network due to the small sample number are combined, the large sample image and the small sample image are spliced, and the large sample image and the small sample image are used as sample images to train the target detection model, so that the network can learn the large sample image and the small sample image at the same time, and the detection capability of the target detection model on the small sample is improved.","['G06F18/214', 'G06F18/25', 'G06N3/045', 'G06T3/4038', 'G06V2201/07']"
US11386128B2,Automatic feature learning from a relational database for predictive modelling,Embodiments for automatic feature learning for predictive modeling in a computing environment by a processor. A first table and a second table are joined based on an edge between the first table and the second table defined by an entity graph thereby creating a resulting joined table that is connected by a column of data. The resulting joined table is used as an input into one or more neural network operations that transform the resulting joined table to one or more features to predict a target variable.,"['G06N3/08', 'G06F16/288', 'G06F16/2456', 'G06N3/042', 'G06N3/0427', 'G06N3/044', 'G06N3/0445', 'G06N3/045', 'G06N3/0454', 'G06N3/082', 'G06N5/022', 'G06N20/00', 'G06N3/049', 'G06N5/003', 'G06N5/01', 'G06N7/005', 'G06N7/01']"
TWI704903B,"Magnetic resonance imaging systems, methods, devices, and computer-readable storage media for detecting change in a brain of a patient","Some aspects include a method of detecting change in degree of midline shift in a brain of a patient. The method comprises, while the patient remains positioned within the low-field magnetic resonance imaging device, acquiring first magnetic resonance (MR) image data and second MR image data of the patient’s brain; providing the first and second MR data as input to a trained statistical classifier to obtain corresponding first and second output, identifying, from the first output, at least one initial location of at least one landmark associated with at least one midline structure of the patient’s brain; identifying, from the second output, at least one updated location of the at least one landmark; and determining a degree of change in the midline shift using the at least one initial location of the at least one landmark and the at least one updated location of the at least one landmark. Some aspects include a method of determining change in size of an abnormality in a brain of a patient positioned within a low-field magnetic resonance imaging (MRI) device. The method comprises, while the patient remains positioned within the low-field MRI device, acquiring first and second magnetic resonance (MR) image data of the patient’s brain; providing the first and second MR image data as input to a trained statistical classifier to obtain corresponding first and second output; identifying, using the first output, at least one initial value of at least one feature indicative of a size of the abnormality; identifying, using the second output, at least one updated value of the at least one feature; determining the change in the size of the abnormality using the at least one initial value of the at least one feature and the at least one updated value of the at least one feature. Some aspects include a method of detecting change in biological subject matter of a patient positioned within a low-field magnetic resonance imaging device, the method comprising: while the patient remains positioned within the low-field magnetic resonance device: acquiring first magnetic resonance image data of a portion of the patient; acquiring second magnetic resonance image data of the portion of the patient subsequent to acquiring the first magnetic resonance image data; aligning the first magnetic resonance image data and the second magnetic resonance image data; and comparing the aligned first magnetic resonance image data and second magnetic resonance image data to detect at least one change in the biological subject matter of the portion of the patient.","['A61B5/0055', 'G01R33/5608', 'A61B5/0042', 'A61B5/055', 'A61B5/4064', 'A61B5/7267', 'G01R33/3806', 'G01R33/445', 'G01R33/4806', 'G01R33/483', 'G06F18/2411', 'G06F18/24143', 'G06T7/0012', 'G06T7/0016', 'G06V10/764', 'G06V10/82', 'A61B2576/026', 'G01R33/383', 'G06N3/044', 'G06N3/045', 'G06T2207/10088', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20092', 'G06T2207/20212', 'G06T2207/30016', 'G06T2207/30101', 'G06T2207/30172', 'G06V2201/031', 'G16H30/40', 'G16H50/70']"
US11076088B2,Artificial intelligence (AI)-based control of imaging parameters of image-capture apparatus,"An image-capture apparatus and method for an artificial intelligence (AI) based control of imaging parameters of the image-capture apparatus is provided. The image-capture apparatus controls the imaging sensor based on a set of imaging parameters associated with the imaging sensor, to acquire imaging information. The acquired imaging information includes a first object of a plurality of objects. The image-capture apparatus generates by, a neural network model, a first classification result based on the acquired imaging information and modifies one or more first imaging parameters of the set of imaging parameters based on the generated first classification result for the first object. The image-capture apparatus further controls the imaging sensor based on the modified set of imaging parameters, to reacquire the imaging information to maximize a confidence of the neural network model for the detection of the first object in the reacquired imaging information.","['G06N3/08', 'H04N5/23218', 'G06F18/214', 'G06F18/217', 'G06F18/2415', 'G06F18/41', 'G06K9/6254', 'G06K9/6256', 'G06K9/6262', 'G06K9/6277', 'G06N3/04', 'G06V10/764', 'G06V10/774', 'G06V10/7788', 'G06V10/82', 'G06V20/52', 'H04N23/61', 'H04N23/64']"
US11270455B2,Method and apparatus for pose processing,"Provided is a method for pose estimation in a device, the method comprising capturing an image; estimating poses of an object included in the captured image; obtaining skeleton information of the object based on the estimating of the poses of the object; and processing the skeleton information of the object for at least one of detecting blocking of the object, detecting the poses of the object and adjusting content based on detected virtual object distinct from human body poses.","['G06T7/75', 'G06K9/00342', 'G06K9/00369', 'G06K9/4604', 'G06N3/045', 'G06N3/08', 'G06N3/082', 'G06T7/73', 'G06V10/34', 'G06V10/764', 'G06V10/82', 'G06V40/103', 'G06V40/23', 'G06T2207/20084', 'G06T2207/30196']"
US11048986B2,"Method, apparatus and computer program stored in computer readable medium for state decision of image data",Disclosed is a method for state decision of image data. The method for state decision of image data may include: acquiring first output data by the network function based on the image data; acquiring second output data by an algorithm having a different effect from the network function based on the image data; and deciding state information of the image data based on the first output data and the second output data.,"['G06K9/66', 'G06F18/22', 'G06V10/82', 'G06F18/24', 'G06K9/6267', 'G06N3/08', 'G06N3/088', 'G06V30/19173', 'H04L45/08']"
US12272129B2,System and method for automated transform by manifold approximation,"A system may transform sensor data from a sensor domain to an image domain using data-driven manifold learning techniques which may, for example, be implemented using neural networks. The sensor data may be generated by an image sensor, which may be part of an imaging system. Fully connected layers of a neural network in the system may be applied to the sensor data to apply an activation function to the sensor data. The activation function may be a hyperbolic tangent activation function. Convolutional layers may then be applied that convolve the output of the fully connected layers for high level feature extraction. An output layer may be applied to the output of the convolutional layers to deconvolve the output and produce image data in the image domain.","['G06V10/82', 'A61B5/0035', 'A61B5/0059', 'A61B5/055', 'A61B5/7267', 'A61B5/7425', 'A61B6/032', 'A61B6/037', 'A61B6/463', 'A61B6/5247', 'A61B8/463', 'A61B8/5261', 'G01R33/12', 'G01R33/4818', 'G01R33/5608', 'G06F18/2113', 'G06F18/24143', 'G06N3/045', 'G06N3/08', 'G06T11/006', 'G06V10/764', 'G16H30/40', 'G01R33/4824', 'G06T2207/20024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2210/41', 'G06V2201/03']"
US20200162789A1,Method And Apparatus Of Collaborative Video Processing Through Learned Resolution Scaling,"In a collaborative video processing method and system, a high resolution video input is optionally downscaled to a low resolution video using a down-sampling filter, followed by an end-to-end video coding system to encode the low resolution video for streaming over the Internet. The original high resolution is obtained at the client end by upscaling the low resolution video using a deep learning based high resolution scaling model, which can be trained in a pre-defined progressive order with low resolution videos having different compression parameters and downscaling factors.","['H04N21/440263', 'G06T3/4046', 'H04N21/234363', 'H04N21/437', 'H04N21/6547']"
US11017288B2,Spike timing dependent plasticity in neuromorphic hardware,"System and techniques for spike timing dependent plasticity (STDP) in neuromorphic hardware are described herein. A first spike may be received, at a first neuron at a first time, from a second neuron. The first neuron may produce a second spike at a second time after the first time. At a third time after the second time, the first neuron may receive a third spike from the second neuron. Here, the third spike is a replay of the first spike with a defined time offset. The first neuron may then perform long term potentiation (LTP) for the first spike using the third spike.","['G06N3/04', 'G06N3/049', 'G06N3/063', 'G06N3/088']"
WO2022220642A1,Method and apparatus for support of machine learning or artificial intelligence techniques for csi feedback in fdd mimo systems,"The present disclosure relates to a 5G communication system or a 6G communication system for supporting higher data rates beyond a 4G communication system such as long term evolution (LTE). Machine learning (ML) assisted channel state information (CSI) reporting or ML assisted CSI prediction includes receiving CSI reporting configurations that include indications that enable or disable at least one of: ML-assisted CSI prediction and artificial intelligence channel feature information (AI-CFI) reporting. ML model training is performed or trained ML model parameters are received, and CSI reference signals corresponding to at least one of the CSI reporting configurations are received. If ML-assisted CSI prediction is enabled, the CSI reporting configurations further include: a timing offset for future CSI prediction, and ML configurations including indication of an ML model used for the ML-assisted CSI prediction. If AI-CFI reporting is enabled, the CSI reporting configurations further include: a configuration for a report of the AI-CFI, and ML configurations including indication of an ML model used for the ML assisted-CSI feedback determination.","['H04B7/0626', 'H04W72/51', 'G06N20/00', 'H04B17/24', 'H04B17/373', 'H04B17/3913', 'H04B7/0413', 'H04B7/065', 'H04B7/0658', 'H04L1/0026', 'H04W72/0446', 'H04W72/21', 'H04W72/232', 'H04W72/542', 'H04W8/24', 'H04W80/02']"
CN110853618B,"Language identification method, model training method, device and equipment","The application discloses a language identification method, which comprises the following steps: acquiring audio data to be identified; extracting audio frequency domain features from the audio data to be identified; based on the audio frequency domain characteristics, carrying out sound accompanying data separation on the audio data to be recognized to obtain voice data to be recognized, wherein the sound accompanying data is separated into voice data and accompaniment data which are separated from the audio data; and performing language identification on the voice data to be identified to obtain a language identification result of the audio data to be identified. The application also discloses a method, a device and equipment for training the model. According to the method and the device, only the voice data to be recognized is input in the language recognition model, and the part of the accompanying music is removed, so that the interference of the accompanying music to the language recognition is reduced, and the accuracy of the song language recognition is improved.","['G10L15/005', 'G10L15/02', 'G10L15/063', 'G10L15/16', 'G10L21/0272', 'G10L21/0308', 'G10L25/18', 'G10L25/30']"
US20220358644A1,Three-dimensional medical image analysis method and system for identification of vertebral fractures,"A machine-based learning method estimates a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures. A three-dimensional medical image analysis system for predicting a presence of a vertebral fracture in a subject includes a 3D image processor for receiving and processing 3D image data of a 3D image of the subject, producing two or more sets of 3D voxels. Each of the sets of 3D voxels corresponds to an entirety of the 3D image and each of the sets of 3D voxels consists of equal 3D voxels of different dimensions. The system also includes a voxel classifier for assigning the 3D voxels one or more class probabilities each of the 3D voxels contains a fracture using a computational model, and a fracture probability estimator for estimating a probability of the presence of a vertebral fracture in the subject.","['A61B6/5217', 'A61B6/032', 'A61B6/035', 'A61B6/505', 'G06F18/2415', 'G06K9/6277', 'G06T15/08', 'G06T7/0012', 'G06T7/11', 'G16H30/40', 'G16H50/00', 'G16H50/20', 'G16H50/30', 'G16H50/50', 'G16H50/70', 'A61B2576/00', 'G06T2207/10081', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30012']"
US10430552B2,Distributed telemedicine system and method,"A vital-signs enhanced telemedicine system and method allowing a plurality of medical teams assisting a plurality of patients to interact with and get assistance from a plurality of remote physicians via a plurality of audio, video, and vital signs transmissions and interactive remoting sessions including alarms, analysis, recording, and live playback capabilities.","['G06F19/3418', 'A61B5/0022', 'G16H40/67', 'G16H80/00', 'A61B5/002']"
US11257266B2,Intelligent augmented reality (IAR) platform-based communication system via servers,"Systems, remote servers, devices, and methods for an intelligent augmented reality (IAR) platform-based communications are disclosed. During a communication, real-time audio, video and/or sensor data are captured in real-time; and scene analysis and data analytics are also performed in real-time to extract information from raw data. The extracted information can be further analyzed to provide knowledge. Real-time AR data can be generated by integrating the raw data, AR input data, information input, and knowledge input, based on one or more criteria comprising a user preference, a system setting, an integration parameter, a characteristic of an object or a scene of the raw data, an interactive user control, or a combination thereof. In some embodiments, information and knowledge can be obtained by incorporating Big Data in the analysis.","['G06T11/60', 'G06F16/9535', 'G06F21/6209', 'G06N5/02', 'G06T19/006', 'H04N7/147', 'H04N7/157', 'H04L63/0428']"
US9936208B1,Adaptive power and quality control for video encoders on mobile devices,"Devices, systems and methods are disclosed for improving encoding techniques for mobile devices by adaptively controlling a resolution or frame rate of content to reduce power consumption while maintaining image quality. For example, a local device may determine when the content may be downscaled without degrading a final image quality and may downscale the content prior to encoding and transmitting the encoded content to a remote device. The remote device may decode and upscale the content to the original resolution prior to displaying the content on a display. As downscaling the content is not power intensive, the local device may reduce a power consumption associated with encoding and transmitting the content to the remote device while maintaining the final image quality of the content.","['H04N19/42', 'H04N19/132', 'H04N19/14', 'H04N19/167', 'H04N19/174', 'H04N19/29', 'H04N19/59']"
CN110163236B,"Model training method and device, storage medium and electronic device","The invention discloses a training method and device of a model, a storage medium and an electronic device. Wherein the method comprises the following steps: acquiring a training request, wherein the training request is used for requesting training of a first neural network model to obtain a second neural network model, and the second neural network model is used for identifying pictures with picture types of a first type; determining a training set through a third neural network model, wherein the third neural network model is used for identifying pictures with picture types being target types, the target types comprise first types, the training set comprises pictures which are identified from a first set and are associated with the first types, and the pictures in the first set are not marked with first identifications; and training the first neural network model through the training set to obtain a second neural network model, wherein the number of layers of the neural network in the second neural network model is different from that of the neural network in the second neural network model. The invention solves the technical problem of high time cost for training the neural network model.","['G06F18/2155', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
US9912349B1,"Method and apparatus for processing floating point number matrix, an apparatus and computer-readable storage medium","The present disclosure provides a method and apparatus for processing a floating point number matrix, an apparatus and a computer readable storage medium. In embodiments of the present disclosure, the minimum value of the floating point number model matrix and the maximum value of the floating point number model matrix are obtained according to a floating point number model matrix to be compressed, and then, compression processing is performed for the floating point number model matrix to obtain the fixed point number model matrix according to the bit width, the minimum value of the floating point number model matrix and the maximum value of the floating point number model matrix. The compression processing is performed for the floating point number model matrix of the deep learning model by a fixed point method, to obtain the fixed point number model matrix and reduce the storage space and amount of operation of the deep learning model. Meanwhile, the present disclosure proposes a framework for implementing the apparatus in the deep learning network to maximize the deep learning network precision, that is, a multiplication portion of the matrix uses the apparatus, and operations of other portions such as activation function retain the floating point operation.","['H03M7/30', 'G06F17/16', 'G06N3/02', 'H03M7/24', 'G06F9/30018', 'G06F9/30145', 'G06F9/30149', 'G06F9/30174', 'G06F9/3851', 'G06N3/044', 'G06N3/063', 'G06T15/005']"
US20210150263A1,Machine learning systems and methods for translating captured input images into an interactive demonstration presentation for an envisioned software product,Machine learning systems and associated methods are provided. A processor comprising at least one neural network can process a captured input image to translate the captured input image into an interactive demonstration presentation for an envisioned software product. The processing can include: automatically recognizing features within the captured input image; extracting the recognized features from the captured input image at the machine learning processor; processing each of the extracted features to determine a corresponding element in a library trained via a machine learning algorithm; and automatically replacing the extracted features from the captured input image with the one or more corresponding files or components to transform the captured input image into the interactive demonstration presentation.,"['G06K9/6256', 'G06F8/20', 'G06F16/116', 'G06F16/148', 'G06F16/16', 'G06F18/214', 'G06F18/40', 'G06F3/0481', 'G06F3/0484', 'G06F40/14', 'G06F40/143', 'G06F40/166', 'G06F40/186', 'G06F8/24', 'G06F8/38', 'G06F9/451', 'G06K9/40', 'G06K9/6253', 'G06N3/0454', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N5/01', 'G06N7/01']"
CN111914812B,"Image processing model training method, device, equipment and storage medium","The application discloses an image processing model training method, device, equipment and storage medium, and belongs to the technical field of artificial intelligence. In the embodiment of the application, on one hand, a shielding mode is introduced, the shielding mode of the sample face image is determined and compared with a target shielding mode marked by the sample face image, an image processing model is trained to determine more accurate shielding indication information, the accuracy of face recognition is improved, and the robustness of the image processing model is improved. On the other hand, the image processing model can process the image end to end without independently performing a prediction process of the shielding region and a dictionary query process of the corresponding characteristics of the shielding region by means of an external network, so that the calculated amount is remarkably reduced, the running speed of equipment is increased, the size of the image processing model is also reduced, the influence of external network factors is avoided, and the accuracy is remarkably improved.","['G06V10/273', 'G06V40/161', 'G06V40/171', 'G06F18/214', 'G06V10/82', 'G06V40/162', 'G06V40/168', 'G06V40/172']"
CN116152226B,Commutator inner side image defect detection method based on fusible feature pyramid,"The invention relates to a method for detecting defects of an image on the inner side of a commutator based on a fusible feature pyramid, which comprises the following steps: step S1, a feature extraction network inputs the extracted multi-level features into a feature splicing module of a multi-scale feature pyramid network; step S2, the characteristic splicing module splices the input multi-level characteristics and inputs the spliced multi-level characteristics into a coding and decoding module in a multi-scale characteristic pyramid network; step S3, the encoding and decoding module generates features with multiple scales according to the features input by the feature splicing module; step S4, the characteristic aggregation module of the multi-scale characteristic pyramid network aggregates the multi-level characteristics in the step S1 and the multi-scale characteristics in the step S3 into a fusible characteristic pyramid, and the detection network acquires a convolutional neural network by adding a plurality of convolutional layers after the fusible characteristic pyramid; and S5, training the convolutional neural network to obtain a detection result.","['G06T7/0004', 'G06N3/08', 'G06V10/40', 'G06V10/806', 'G06V10/82', 'G06T2207/20016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30108', 'G06V2201/07', 'Y02P90/30']"
TWI750047B,Semiconductor device and system using the same,"To provide a semiconductor device which can execute the product-sum operation. The semiconductor device includes a first memory cell, a second memory cell, and an offset circuit. First analog data is stored in the first memory cell, and reference analog data is stored in the second memory cell. The first memory cell and the second memory cell supply a first current and a second current, respectively, when a reference potential is applied as a selection signal. The offset circuit has a function of supplying a third current corresponding to a differential current between the first current and the second current. In the semiconductor device, the first memory and the second memory supply a fourth current and a fifth current, respectively, when a potential corresponding to second analog data is applied as a selection signal. By subtracting the third current from a differential current between the fourth current and the fifth current, a current that depends on the sum of products of the first analog data and the second analog data is obtained.","['G06N3/063', 'G06N3/065', 'G06N3/08', 'G11C11/403', 'G11C5/063', 'G11C5/147', 'G11C7/1006', 'G11C7/16', 'H10D30/6755', 'H10D86/423', 'H10D86/481', 'H10D86/60', 'G06N3/045', 'G11C2207/104']"
US11335079B2,Method and system of reflection suppression for image processing,"A system, article, and method of reflection suppression for image processing by detecting undesired reflected objects in an image.","['G06V10/30', 'G06T5/70', 'G06T5/00', 'G06T5/003', 'G06T5/73', 'G06T7/10', 'G06T7/73', 'G06V10/255', 'G06V10/273', 'G06V20/00', 'G06V40/162', 'H04N23/611', 'H04N23/68', 'H04N23/80', 'H04N5/23219', 'H04N5/23229', 'H04N5/23248', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/20012']"
CN114117840B,A hybrid-driven structural performance prediction method based on simulation and experimental data,"The invention discloses a structural performance prediction method based on simulation and test data hybrid drive, in a static test, limited measurement data and simulation data are combined to establish a fusion model, the precision of a proxy model constructed by the hybrid data is improved by utilizing a large amount of simulation data and a small amount of test data, a variable fidelity model construction method is developed to realize structural state field reconstruction, and the health prediction on the spatial dimension is realized by utilizing a multi-precision deep neural network model and learning the linear and nonlinear relations between the test data and the simulation data in a self-adaptive manner. In the health monitoring test, the fusion model is corrected by using an optimization algorithm, the constructed fusion model fuses health monitoring data, the real physical state of the structure can be reflected, and the health prediction on the time dimension is realized. The invention fully considers the static and dynamic characteristics of the aircraft and the damage evolution process and parameter change rule of the composite material, and researches the integrated multi-physical quantity and multi-parameter high-fidelity simulation process reflecting the real-time damage state and the load process of the structure. The parameters of the finite element model are continuously corrected through test data, so that the established digital principle prototype can carry out high-precision mapping on the mechanical response and damage expansion process in the multi-physical-field environment of the structure.","['G06F30/23', 'G06F30/27', 'G06N3/04', 'G06N3/08', 'G06F2119/04', 'G06F2119/14', 'Y02T90/00']"
US10956783B2,Image processing method and apparatus,"An image processing method and apparatus, and a computer readable medium are provided. The method includes obtaining an image. The image is processed using a preset training model that is a function relationship model of a feature sample image and an activation function of the feature sample image. The feature sample image includes an image satisfying an image feature value extraction condition. A target image is obtained that corresponds to the image according to a processing result of the preset training model.","['G06K9/6256', 'G06T3/04', 'G06V10/82', 'G06F18/214', 'G06K9/00228', 'G06K9/3233', 'G06K9/46', 'G06K9/4628', 'G06K9/4647', 'G06K9/6202', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/082', 'G06N3/088', 'G06T11/00', 'G06T11/001', 'G06T11/60', 'G06T3/4046', 'G06V10/25', 'G06V10/454', 'G06V40/161']"
US10635950B2,Surveillance system for recognition in unlabeled videos with domain adversarial learning and knowledge distillation,"A surveillance system is provided that includes a device configured to capture a video sequence, formed from a set of unlabeled testing video frames, of a target area. The surveillance system further includes a processor configured to pre-train a recognition engine formed from a reference set of CNNs on a still image domain that includes labeled training still image frames. The processor adapts the recognition engine to a video domain to form an adapted recognition engine, by applying a non-reference set of CNNs to domains including the still image and video domains and a degraded image domain. The degraded image domain includes labeled synthetically degraded versions of the frames included in the still image domain. The video domain includes random unlabeled training video frames. The processor recognizes, using the adapted engine, at least one object in the target area. A display device displays the recognized objects.","['G06K9/66', 'G06F18/21', 'G06F18/217', 'G06F18/22', 'G06F18/24143', 'G06K9/00268', 'G06K9/00288', 'G06K9/00718', 'G06K9/00744', 'G06K9/00771', 'G06K9/4628', 'G06K9/6201', 'G06K9/6217', 'G06K9/6262', 'G06K9/6274', 'G06N20/00', 'G06N3/02', 'G06N3/045', 'G06N3/0454', 'G06N3/08', 'G06N3/088', 'G06T7/70', 'G06T9/002', 'G06V10/454', 'G06V10/82', 'G06V20/41', 'G06V20/46', 'G06V20/52', 'G06V30/19173', 'G06V40/168', 'G06V40/172', 'G08B13/19613', 'G06K2009/00738', 'G06T2207/20081', 'G06V20/44', 'G08B13/196']"
CN108920993B,Pedestrian attitude identification method and system based on radar and multi-network fusion,"The invention relates to a pedestrian posture identification method and a system based on radar and multi-network fusion, wherein the method comprises the steps of preprocessing an echo signal of a radar signal to obtain an output signal; carrying out suppression processing on a static target in the output signal; searching a distance unit where the pedestrian is located in the output signal after the suppression processing; performing time-frequency analysis on echo signals corresponding to the distance units where the pedestrians are located to obtain echo signal time-frequency graphs; respectively identifying the echo signal time-frequency graphs by utilizing a plurality of convolutional neural networks to obtain an identification result of each convolutional neural network; and fusing the recognition results of each convolutional neural network to obtain a fused posture recognition result. According to the pedestrian posture identification method, the pedestrian posture identification result is given in real time through analysis of radar echoes, and through fusion of a plurality of neural networks, the higher posture identification accuracy can be ensured, the pedestrian posture identification method is not interfered by factors such as illumination conditions, weather and smoke, and can work all day long and all weather.","['G06F2218/12', 'G06F18/253', 'G06N3/045', 'G06V40/103']"
CN112035747B,Information recommendation method and device,"The application provides an information recommendation method, an information recommendation device, electronic equipment and a computer readable storage medium; the method comprises the following steps: acquiring a historical information sequence and a recommendation information set of a user; determining a correlation factor of the historical information sequence corresponding to each piece of recommended information in the recommended information set; determining behavior characteristics of the user corresponding to each piece of recommended information according to the correlation factor of the historical information sequence corresponding to each piece of recommended information in the recommended information set; performing repeated iterative feature extraction processing on the behavior features of each piece of recommended information, and determining the click rate of each piece of recommended information based on the feature extraction result of each piece of recommended information; and executing the recommendation operation based on the click rate of each piece of recommendation information. According to the application, the recommendation accuracy can be improved.","['G06F16/9535', 'G06N3/045', 'Y02D10/00']"
CN110096968B,An ultra-high-speed static gesture recognition method based on deep model optimization,"The invention relates to the technical field of computer vision, and particularly discloses an ultra-high-speed static gesture recognition method based on depth model optimization, which comprises the following steps: designing and training a static gesture recognition neural network model; fusion optimization of a neural network model structure; quantizing the neural network model; and inputting a static gesture graph to be recognized, and outputting a recognition result through a SimNet neural network model. Compared with the prior art, the method can adapt to static gesture images under different backgrounds, recognize different gesture states aiming at different gestures, and realize high accuracy and high recognition rate.","['G06F18/24', 'G06N3/045', 'G06N3/08', 'G06V40/113']"
US11113840B2,Systems and methods for detecting objects in images,"A method configured to implemented on at least one image processing device for detecting objects in images includes obtaining an image including an object. The method also includes generating one or more feature vectors related to the image based on a first convolutional neural network, wherein the one or more feature vectors includes a plurality of parameters. The method further includes determining the position of the object based on at least one of the plurality of parameters. The method still further includes determining a category associated with the object based on at least one the plurality of parameters.","['G06N3/08', 'G06F18/214', 'G06F18/2163', 'G06F18/2415', 'G06F18/2431', 'G06K9/00832', 'G06K9/42', 'G06K9/6256', 'G06K9/6261', 'G06K9/6277', 'G06N3/045', 'G06T7/73', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06V20/59', 'G06T2207/20081', 'G06T2207/20084']"
CN110473141B,"Image processing method, device, storage medium and electronic equipment","The embodiment of the application discloses an image processing method, an image processing device, a storage medium and electronic equipment, wherein the embodiment of the application acquires an image to be processed, and extracts first content characteristics of the image to be processed according to a coding network of a preset convolutional neural network model, wherein the convolutional neural network model comprises a coding network, a characteristic fusion layer and a decoding network, and structures of the coding network and the decoding network are mirror images; acquiring a first style characteristic; at the feature fusion layer, carrying out fusion processing on the first content features and the first style features to obtain first fusion features; and decoding the first fusion characteristic according to the decoding network to generate a first style migration image, so that the efficiency of image style migration is improved.","['G06N3/045', 'G06N3/08', 'G06T3/04', 'G06F18/241']"
US10681388B2,Compression of occupancy or indicator grids,"Encoding and decoding occupancy information is disclosed. A method includes determining row sums for the region, determining column sums for the region, encoding, in a compressed bitstream, at least one of the row sums and the column sums, and encoding, in the compressed bitstream and based on a coding order, at least one of the rows and the columns of the region. The coding order is based on the encoded at least one of the row sums and the column sums. The row sums include, for each row of the region, a respective count of a number of locations in the row having a specified value. The column sums include, for each column of the region, a respective count of a number of locations in the column having the specified value. A location having the specified value is indicative of the occupancy information at the location.","['H04N19/91', 'H04N19/13', 'H04N19/14', 'H04N19/176', 'H04N19/44', 'H04N19/463']"
US10643120B2,Joint learning of local and global features for entity linking via neural networks,"A system, method and computer program product for disambiguating one or more entity mentions in one or more documents. The method facilitates the simultaneous linking entity mentions in a document based on convolution neural networks and recurrent neural networks that model both the local and global features for entity linking. The framework uses the capacity of convolution neural networks to induce the underlying representations for local contexts and the advantage of recurrent neural networks to adaptively compress variable length sequences of predictions for global constraints. The RNN functions to accumulate information about the previous entity mentions and/or target entities, and provide them as the global constraints for the linking process of a current entity mention.","['G06N3/044', 'G06N3/0454', 'G06N3/0445', 'G06N3/045', 'G06N3/084']"
US12330058B2,Extraction and classification of audio events in gaming systems,"A system that incorporates the subject disclosure may include, for example, receiving an input audio stream from a gaming system, the input audio stream including gaming audio of a video game played by a game player, the input audio stream including a plurality of classes of sounds, providing the input audio stream to a neural network, extracting, by the neural network, sounds of a selected class of sounds of the plurality of classes of sounds, and providing a plurality of output audio streams including providing a first audio stream including the sounds of the selected class of sounds of the input audio stream and a second audio stream including remaining sounds of the input audio stream. Additional embodiments are disclosed.","['A63F13/213', 'A63F13/215', 'A63F13/424', 'A63F13/54', 'A63F13/67', 'A63F13/79', 'A63F13/86', 'G06F3/167', 'A63F13/533', 'A63F13/537', 'A63F13/87', 'A63F2300/308', 'A63F2300/5546', 'A63F2300/572', 'A63F2300/6072', 'A63F2300/6081', 'G06N3/02', 'G06N3/08', 'G06N3/09', 'G10L15/16', 'G10L15/26', 'G10L25/51', 'H04R1/1083', 'H04R3/12', 'H04R5/033', 'H04R5/04', 'H04S2400/01', 'H04S2420/01', 'H04S7/302', 'H04S7/308']"
US12026382B2,Storage path routing in a container system,"In some embodiments, storage path routing in a container system includes: determining, within the container system, a storage operation directed to a storage resource; determining one or more conditions associated with a plurality of network paths to the storage resource, where the plurality of network paths includes a first network path through a storage area network and a second network path through a container system communication network; and routing, based on the one or more conditions, the storage operation to the storage resource using the first network path.","['G06F3/061', 'G06F3/0614', 'G06F3/0635', 'G06F3/0653', 'G06F3/0659', 'G06F3/067', 'G06N20/00', 'G06N3/063']"
US11550514B2,Efficient transfers between tiers of a virtual storage system,"Efficiently transferring data between tiers in a virtual storage system, including: receiving, by the virtual storage system, a request to write data to the virtual storage system; transforming, within storage provided by a first tier of storage of the virtual storage system, the data to generate transformed data; and migrating, from the first tier of storage to a second tier of storage that is more durable than the first tier of storage of the virtual storage system, at least a portion of the transformed data.","['G06F3/0664', 'G06F9/45558', 'G06F3/0604', 'G06F3/0608', 'G06F3/0614', 'G06F3/0631', 'G06F3/0641', 'G06F3/0647', 'G06F3/0653', 'G06F3/0659', 'G06F3/0667', 'G06F3/067', 'G06F3/0673', 'G06F3/0685', 'G06F2009/45579', 'G06F9/45541']"
US12026381B2,Preserving identities and policies across replication,"Preserving identities and policies across replication, including: receiving, at a first storage array, a first data frame comprising data associated a dataset stored at the first storage array and an identifier of a quality of service level associated with the first data frame; generating, at the first storage array, a second data frame comprising a portion of the dataset and the identifier of the quality of service level associated with the first data frame; and transmitting the second data frame to a second storage array.","['G06F3/0632', 'G06F3/0613', 'G06F3/065', 'G06F3/0653', 'G06F3/067']"
US11651216B2,Automatic XAI (autoXAI) with evolutionary NAS techniques and model discovery and refinement,"An exemplary model search may provide optimal explainable models based on a dataset. An exemplary embodiment may identify features from a training dataset, and may map feature costs to the identified features. The search space may be sampled to generate initial or seed candidates, which may be chosen based on one or more objectives and/or constraints. The candidates may be iteratively optimized until an exit condition is met. The optimization may be performed by an external optimizer. The external optimizer may iteratively apply constraints to the candidates to quantify a fitness level of each of the seed candidates. The fitness level may be based on the constraints and objectives. The candidates may be a set of data, or may be trained to form explainable models. The external optimizer may optimize the explainable models until the exit conditions are met.","['G06N3/08', 'G06N3/126', 'G06F18/2163', 'G06F18/217', 'G06F18/22', 'G06K9/6201', 'G06K9/6261', 'G06K9/6262', 'G06N5/025', 'G06N3/006', 'G06N3/045', 'G06N3/048', 'G06N3/0481', 'G06N3/049', 'G06N3/084', 'G06N5/045', 'G06N7/01']"
US12407984B2,Fully customizable ear worn devices and associated development platform,"Disclosed herein is an audio system that can be customized by the user (including the developer) and that may allow the user to control more than just the sound levels and may allow the user to select more than one of a few pre-determined settings. Disclosed herein is a development platform that allows manufacturers (including the developers) to test various different parameters, settings, algorithms, functions, processes, accessories, and the like. The development platform allows the manufacturer to simulate the performances from possible options for the audio system, and then load the selected option from the development platform to the audio system. Additionally, the development platform that enables the end user to have the same level of control and ability to access, upload, and control plugins on the end user's device(s).","['G06F3/162', 'G06F3/165', 'G06F3/167', 'H04R25/552', 'H04R3/005', 'H04R3/14', 'H04R5/04', 'H04S3/008', 'H04S7/304', 'H04R2430/01', 'H04R5/033', 'H04S2400/01', 'H04S2400/11', 'H04S2400/13']"
TW202227999A,Lid controller hub,"A lid controller hub (LCH) comprising processing components located in the lid of a mobile computing device, such as a laptop, processes sensor data generated by input sensors (microphones, cameras, touchscreen) and provides for improved and enhanced experiences over existing devices. For example, the LCH provides hardened privacy and the synchronization of touch display activities with the display refresh rate, the latter providing for a smoother and more responsive touch experience over existing designs. The LCH comprises neural network accelerators and digital signal processors that enable waking a device upon detection of an authenticated user's voice or face. The LCH also allows for video- and audio-based contextual awareness and adaptive cooling. By enabling a reduced hinge wire count and a typical day's usage with a single battery charge, an LCH can also provide for an improved industrial design to a simpler hinge and smaller battery.","['G06F15/7807', 'G06F1/1605', 'G06F1/1615', 'G06F1/1616', 'G06F1/1643', 'G06F1/1686', 'G06F1/1688', 'G06F1/169', 'G06F1/3231', 'G06F21/32', 'G06F21/606', 'G06F21/6245', 'G06F21/83', 'G06F3/012', 'G06F3/013', 'G06F3/017', 'G06F3/0304', 'G06F2221/2111', 'Y02D10/00']"
US12248319B2,Regression-based line detection for autonomous driving machines,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment—e.g., for updating a world model—in a variety of autonomous machine applications.","['G05D1/0077', 'G05D1/0088', 'G05D1/0246', 'G05D1/228', 'G06F18/2155', 'G06F18/23', 'G06F18/2411', 'G06N3/0418', 'G06N3/045', 'G06N3/08', 'G06V10/457', 'G06V10/48', 'G06V10/751', 'G06V10/764', 'G06V10/766', 'G06V10/776', 'G06V10/82', 'G06V10/955', 'G06V20/588']"
US12086650B2,Workload placement based on carbon emissions,"Workload placement based on carbon emissions, including: calculating, for each execution environment of a plurality of execution environments, a carbon emission cost associated with a workload; selecting, based on each carbon emission cost for the plurality of execution environments, a target execution environment; and executing the workload on the target execution environment.","['G06F9/5027', 'G06F9/5088', 'G06F3/0604', 'G06F3/0631', 'G06F3/0688', 'G06F9/4881', 'G06F2209/501']"
US10445429B2,Natural language understanding using vocabularies with compressed serialized tries,"Systems and processes for natural language processing using vocabularies with compressed serialized tries are described in the present disclosure. In one example process, natural language input is received. The natural language input is parsed, using a vocabulary, to determine a corresponding user intent. The parsing includes using a data structure of the vocabulary to map a first word of the natural language input to first semantic information and a second word of the natural language input to second semantic information. The data structure includes pointers that map to a same semantic data object of the vocabulary. The first semantic information and the second semantic information are determined using the same semantic data object. The user intent is determined based on the first semantic information and the second semantic information. Performance of a task corresponding to the determined user intent is initiated.","['G06F17/2785', 'G06F40/30', 'G06F17/27', 'G06F17/2705', 'G06F40/205', 'G06F40/237', 'G10L15/1815', 'G10L15/22', 'G10L15/26']"
US20230231912A1,Mesh-aware storage systems,"A storage system proxy associated with a storage system may receive a service mesh policy used by a service mesh. The storage system may include a storage system proxy. The service mesh may include a control plane and a data plane. The data plane may include proxies associated with respective services. The control plane may configure the proxies according to the service mesh policy. The data plane may include the proxies communicating with each other, as configured by the control plane, to relay exchanges between the services. The storage system proxy may communicate with the storage system to configure a volume based on the service mesh policy received from the service mesh. The volume may be exposed to the data plane.","['H04L67/1097', 'H04L67/16', 'H04L67/2804', 'H04L67/288', 'H04L67/306', 'H04L67/51', 'H04L67/56', 'H04L67/561']"
US12079494B2,Optimizing storage system upgrades to preserve resources,"A storage system has a first storage and a second storage. The first storage has a first plurality of blades with first computing resources, first RAM resources and first solid-state storage resources. The second storage has second plurality of blades with second computing resources, second RAM resources and second solid-state storage resources. The first computing resources and the second computing resources cooperate to determine on which blades of the first and second pluralities of blades, and in which storage of the first and second storage, to perform compute processes and memory controller processes, using which of the first and second computing resources. The first computing resources and the second computing resources cooperate to determine on which blades of the first and second pluralities of blades and in which storage of the first and second storage to use which of the first and second RAM resources and to use which of the first and second solid-state storage resources, in service of performing the compute processes and the memory controller processes for data and metadata accesses.","['G06F3/0626', 'G06F3/0631', 'G06F3/0604', 'G06F3/0607', 'G06F3/0617', 'G06F3/065', 'G06F3/0659', 'G06F3/067', 'G06F3/0688']"
US20220019367A1,Migrating Data In And Out Of Cloud Environments,"In an embodiment, a migration of a dataset from a source storage system to a target storage system is initiated, wherein at least one of the source storage system and the target storage system is a cloud-based storage system. The target storage system provides read/write access to the dataset before completing migration of the dataset from the source storage system to the target storage system.","['G06F3/0608', 'G06F21/602', 'G06F21/6218', 'G06F3/0604', 'G06F3/0623', 'G06F3/0631', 'G06F3/0647', 'G06F3/0659', 'G06F3/067', 'H04L63/0435', 'H04L63/10', 'H04L9/0894', 'H04L9/3239', 'H04L9/3297', 'H04L9/50', 'H04L2463/062']"
US11941279B2,Data path virtualization,"In a particular embodiment, a virtual namespace identifier is mapped to one or more volumes stored among a pool of storage resources, wherein at least a first storage system and a second storage system are utilized to provide the storage resources. The virtual namespace identifier is migrated among the pool of storage resources to virtualize a data path for the one or more volumes.","['G06F3/0605', 'G06F3/065', 'G06F16/275', 'G06F3/0617', 'G06F3/0665', 'G06F3/067']"
US12166820B2,Replicating multiple storage systems utilizing coordinated snapshots,"Replicating multiple storage systems utilizing coordinated snapshots, including identifying a replica dataset stored across two or more target storage systems, wherein the replica dataset is a replication target for a source dataset stored across two or more source storage systems; identifying two or more local replicated checkpoints that are replicated from the two or more source storage systems to the two or more target storage systems, wherein two or more local source checkpoints for the two or more local replicated checkpoints are associated with a coordinated source checkpoint for the source dataset; and determining, based on the two or more local replicated checkpoints, a coordinated target checkpoint for the replica dataset.","['G06F11/1471', 'G06F11/1448', 'G06F11/2071', 'G06F16/2379', 'G06F16/273', 'H04L67/1095', 'H04L67/1097', 'G06F11/1469', 'G06F11/2074', 'G06F11/2076', 'G06F2201/84', 'G06F2201/855']"
US12045252B2,Providing quality of service (QoS) for replicating datasets,"Providing Quality of Service (QoS) for replicating datasets including: receiving, by a target data repository from a source data repository, a checkpoint describing one or more updates to one or more datasets stored in the source data repository and the target data repository; adding, by the target data repository, the checkpoint to a first queue for checkpoints directed to one or more volumes in the target data repository, wherein the first queue is included in a plurality of queues for the target data repository; selecting, by the target data repository, one or more queues from the plurality of queues; and servicing an operation from each of the selected one or more queues.","['G06F11/1471', 'G06F16/27', 'G06F11/2071', 'G06F11/2094', 'G06F11/2097', 'G06F11/3034', 'G06F16/275', 'G06F11/2074', 'G06F11/2076', 'G06F2201/84', 'G06F2201/855', 'G06F2201/88']"
US11868622B2,Application recovery across storage systems,"A system and methods for application recovery across storage systems is provided. In some examples, the method includes replicating, from a source storage system to a target storage system, a volume including an application configuration for an application utilizing the volume, wherein the application is executing within a source application host. The method also includes detecting that the application executed in the source application host is unavailable. The method also includes retrieving, from the volume on the target storage system, the application configuration for the application. The method also includes instantiating the application on a target application host using the application configuration retrieved from the volume on the target storage system, wherein the application on the target application host is configured to direct data requests to the volume on the target storage system.","['G06F3/0604', 'G06F3/0619', 'G06F3/0632', 'G06F3/0635', 'G06F3/0659', 'G06F3/067', 'H04L41/0663', 'H04L41/084', 'H04L69/40']"
US12235743B2,Efficient partitioning for storage system resiliency groups,"A storage system with storage drives and a processing device establishes resiliency groups of storage system resources. The storage system determines an explicit trade-off between data survivability over resource failures and data capacity efficiency, for the resiliency groups. Responsive to adding at least one storage drive, the storage system establishes re-formed resiliency groups according to the explicit trade-off, without decreasing data survivability. The storage system may bias to have more and narrower resiliency groups to increase mean time to data loss.","['G06F11/2094', 'G06F11/07', 'G06F11/108', 'G06F11/20', 'G06F11/201', 'G06F11/2015', 'G06F11/202', 'G06F11/2089', 'G06F2201/805']"
US20220019366A1,Providing Data Services During Migration,"In an embodiment, a migration of a dataset from a source storage system to a target storage system is initiated. The target storage system provides data services for the dataset before completing migration of the dataset from the source storage system to the target storage system. The data services can include snapshotting, cloning, data reduction, virtual copy, and replication. In some cases, the data services are provided before any portion of the dataset is copied.","['G06F3/0647', 'G06F21/602', 'G06F21/6218', 'G06F3/0604', 'G06F3/0623', 'G06F3/067', 'H04L63/0435', 'H04L63/10', 'H04L9/0894', 'H04L9/3239', 'H04L9/3297', 'H04L9/50', 'H04L2463/062']"
US11846968B2,Relocation of data for heterogeneous storage systems,A command to relocate data is transmitted by a storage controller. The command includes first address information associated with a first set of blocks storing the data at one or more storage devices using a first programming mode and second address information associated with a second set of blocks at the one or more storage devices to store the relocated data using a second programming mode. The command causes the relocation of the data from the first set of blocks to the second set of blocks while bypassing sending the data to the storage controller. An acknowledgement is received that the relocated data has been stored at the second number of blocks.,"['G06F3/0647', 'G06F11/108', 'G06F12/0246', 'G06F12/06', 'G06F3/0604', 'G06F3/0608', 'G06F3/0634', 'G06F3/064', 'G06F3/0673', 'G06F3/0688', 'G06F2212/1032', 'G06F2212/1044', 'G06F2212/7204', 'G06F2212/7206', 'G06F2212/7208']"
US11922046B2,Erasure coded data within zoned drives,A non-volatile solid-state storage is provided. The non-volatile solid state storage includes a non-volatile random access memory (NVRAM) addressable by a processor external to the non-volatile solid state storage. The NVRAM is configured to store user data and metadata relating to the user data. The non-volatile solid state storage includes a flash memory addressable by the processor. The flash memory is configured to store the user data responsive to the processor directing transfer of the user data from the NVRAM to the flash memory.,"['G06F3/065', 'G06F11/1004', 'G06F11/108', 'G06F13/28', 'G06F3/0619', 'G06F3/067', 'G06F3/0688']"
CN106023302B,"Mobile communication terminal, server and method for realizing three-dimensional reconstruction","The invention is applicable to the field of image processing, and provides a mobile communication terminal, a method for realizing three-dimensional reconstruction thereof and a server. The method comprises the following steps: the mobile communication terminal shoots at least one picture of an object or a scene through a camera; the mobile communication terminal sends the photo to the server through the network, the server synthesizes a three-dimensional model by taking the photo as the input of three-dimensional reconstruction, three-dimensional model data are generated, and the server sends the generated three-dimensional model data to the mobile communication terminal through the network; the mobile communication terminal receives the three-dimensional model data; and the mobile communication terminal performs three-dimensional visual rendering according to the three-dimensional model data. The invention realizes the full-automatic service flow of shooting objects or scenes at any angle and any position, uploading photos, synthesizing and downloading and rendering a three-dimensional model on the mobile communication terminal.","['G06T17/00', 'G06T15/00', 'H04L65/60']"
CN110020651B,License plate detection and positioning method based on deep learning network,"The invention relates to a license plate detection and positioning method based on a deep learning network. The license plate detection positioning method based on the deep learning network is provided for solving the problems that the traditional license plate detection method is poor in expandability, low in complex scene detection rate, poor in generalization capability, poor in license plate detection effect, and the like, and the license plate recognition rate is reduced. In order to obtain accurate license plate positioning in a complex image, firstly, collecting and marking a marked vehicle sample data set and a license plate sample data set; secondly, two convolutional neural networks are respectively constructed, wherein the first convolutional neural network is used for training a license plate detection coarse positioning model, and the second convolutional neural network is used for training a license plate detection angular point regression model; thirdly, the picture to be detected is subjected to license plate detection coarse positioning model to obtain candidate license plate pictures; and finally, detecting the candidate pictures through a license plate detection angular point regression model, acquiring the pictures with the license plates accurately and marking angular point information of the license plates. The method is simple and flexible, and has strong practical applicability.","['G06N3/045', 'G06T7/0002', 'G06T7/70', 'G06V20/62', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20104', 'G06T2207/20164', 'G06V20/625', 'Y02T10/40']"
US12056383B2,Edge management service,"In a particular embodiment, a storage service agent on an edge device is configured to access a particular set of storage system application programming interfaces (APIs) of at least one enterprise storage system, where the storage service agent communicatively coupled to a cloud-based storage service. The storage service agent invokes one or more storage system APIs of the particular set of storage system APIs in response to a control message from the cloud-based storage service.","['G06F3/0605', 'G06F16/275', 'G06F3/0617', 'G06F3/0665', 'G06F3/067', 'G06F3/065']"
US11823699B2,Single-channel and multi-channel source separation enhanced by lip motion,"Methods and systems are provided for implementing source separation techniques, and more specifically performing source separation on mixed source single-channel and multi-channel audio signals enhanced by inputting lip motion information from captured image data, including selecting a target speaker facial image from a plurality of facial images captured over a period of interest; computing a motion vector based on facial features of the target speaker facial image; and separating, based on at least the motion vector, audio corresponding to a constituent source from a mixed source audio signal captured over the period of interest. The mixed source audio signal may be captured from single-channel or multi-channel audio capture devices. Separating audio from the audio signal may be performed by a fusion learning model comprising a plurality of learning sub-models. Separating the audio from the audio signal may be performed by a blind source separation (“BSS”) learning model.","['G10L21/028', 'G10L21/0272', 'G06F18/2413', 'G06F18/251', 'G06F18/253', 'G06N20/10', 'G06N20/20', 'G06N3/044', 'G06N3/045', 'G06T7/20', 'G06V10/764', 'G06V10/806', 'G06V10/82', 'G06V20/46', 'G06V40/171', 'G10L15/25', 'G10L25/30', 'G10L25/87', 'G06N3/08', 'G06T2207/30201']"
US7570785B2,Face monitoring system and method for vehicular occupants,"Imaging system and method for a vehicle includes an infrared source generating an infrared beam along a particular field-of-view in the vehicle, an infrared detector responsive to infrared radiation reflected from objects in the field-of-view of the infrared beam and which generates image signals from the reflected infrared radiation, and a processor responsive to the image signals from the detector. The processor includes face recognition software that images and identifies facial features of a person to detect a person's face and compares the detected image of the person's face with stored images, and causes a vehicle operation, e.g., ignition of the vehicle, to be performed if a particular person's face is identified. The processor may perform a frame subtracting process where the images when the infrared source is on are subtracted from the images when the infrared source is off so as to eliminate background.","['B60K28/066', 'G06V20/59', 'G06V40/161', 'G06V40/18', 'G06V40/28']"
US8152198B2,Vehicular occupant sensing techniques,"Vehicular apparatus and method for determining a characteristic of an object that may be located on a seat of the vehicle includes emitters, each emitting a beam along a path on which the object may be located, each path being in a different direction, receivers, each receiving beams emitted from the array of emitters that are reflected from the object when present in the seat, and a processor coupled to the emitters and the receivers for determining time-of-flight of each reflected and received beam between emission of the beam from the emitters and reception of the beam at the receivers. The processor determines one or more characteristics of the object based on the determined time-of-flight of each reflected and received beam, taken either individually or in combination.","['B60R21/01516', 'B60R21/0152', 'G08B21/22', 'G08B21/24', 'B60R21/0153']"
US7738678B2,Light modulation techniques for imaging objects in or around a vehicle,"Method and system for obtaining information about an object in a compartment in a vehicle includes directing illumination into the compartment, spatial or temporally modulating the illumination, receiving light reflected from an object in the compartment, and analyzing the reflected light to obtain information about the object. The compartment may be a passenger compartment of an automobile, the trunk of an automobile or the interior of a trailer of a truck. The illumination may be directed from a light source and the reflected light received at a receiver spaced apart from the light source. Analysis of the reflected light may therefore entail applying a triangulation calculation to enable a determination of a distance between the light source and illuminated point on the object. The same method and system can be adapted for monitoring the environment around the vehicle.","['G06V20/59', 'B60J10/00', 'B60N2/0022', 'B60N2/0025', 'B60N2/0028', 'B60N2/0029', 'B60N2/0035', 'B60N2/0268', 'B60N2/0272', 'B60Q1/143', 'B60R16/037', 'B60R21/013', 'B60R21/01516', 'B60R21/0152', 'B60R21/0153', 'B60R21/01534', 'B60R21/01536', 'B60R21/01538', 'B60R21/01542', 'B60R21/01552', 'B60R21/01554', 'B60R25/25', 'B60R25/252', 'B60R25/255', 'B60R25/257', 'E05F15/43', 'E05F15/431', 'G01S15/87', 'G01S15/88', 'G01S17/48', 'G01S17/88', 'G01S7/417', 'G01S7/4802', 'G01S7/4814', 'G01S7/539', 'G06V40/10', 'B60N2/267', 'B60N2210/12', 'B60N2210/16', 'B60N2210/20', 'B60N2210/24', 'B60N2210/26', 'B60N2210/42', 'B60N2220/30', 'B60N2230/30', 'B60Q2300/41', 'B60Q2300/42', 'B60R2001/1223', 'B60R2001/1253', 'B60R2021/0027', 'B60R2021/01315', 'B60R21/0134', 'B60R21/0136', 'B60R21/01544', 'B60R21/01548', 'E05F2015/433', 'E05Y2900/516', 'E05Y2900/55', 'G01S13/04', 'G01S15/04', 'G01S15/06', 'G01S17/89', 'G01S7/4817', 'G10K2210/1282', 'G10K2210/3219']"
US11663663B2,Image analysis and identification using machine learning with output estimation,"The present disclosure relates to systems and methods for generating real-time quotes using machine learning algorithms. The system may include a processor in communication with a client device, and a storage medium storing instructions that, when executed, cause the processor to perform operations including: receiving an image of a vehicle from the client device, extracting one or more features from the image, based on the extracted features and using a machine learning algorithm, identifying one or more attributes of the vehicle, based on the identified attributes of the vehicle, determining a make and a model of the vehicle, obtaining comparison information based at least in part on the determined make and model, estimating a quote for the vehicle based on the comparison information; and transmitting the estimated quote for display on the client device.","['G06N3/084', 'G06Q40/03', 'G06N20/00', 'G06N3/045']"
US20210278825A1,Real-Time Production Scheduling with Deep Reinforcement Learning and Monte Carlo Tree Research,Systems and methods provide real-time production scheduling by integrating deep reinforcement learning and Monte Carlo tree search. A manufacturing process simulator is used to train a deep reinforcement learning agent to identify the sub-optimal policies for a production schedule. A Monte Carlo tree search agent is implemented to speed up the search for near-optimal policies of higher quality from the sub-optimal policies.,"['G05B19/41865', 'G06N3/006', 'G05B19/41885', 'G06N3/044', 'G06N3/045', 'G06N3/084', 'G06N5/01', 'G06N7/005', 'G06N7/01']"
CN110278249B,Distributed group intelligent system,"A distributed group intelligence system, comprising: a bottom layer protocol layer for applying a network protocol; the core software platform layer is used for calling the computing resources of the external system platform and supporting a distributed system, a consistency algorithm and a computing model; and an open software layer for providing an open source system framework; the distributed architecture at least comprises: one or more of an HLA system, a DDS system and a Multi-Agent system. The invention solves the problems of large-scale calculation, splitting of a calculation model, cooperation of multiple intelligent expert systems, group intelligent decision and flexible decision organization of an intelligent system and the like.","['G06F9/5083', 'H04L67/10', 'H04L67/1059', 'H04L67/1095', 'H04L67/56', 'H04L69/162']"
US11797634B2,System and method for providing a content item based on computer vision processing of images,"In certain embodiments, one or more images of an object may be received from a device associated with a first account on a communications network. Features of the object may be extracted based on the one or more images, and one or more content items related to the object may be determined based on the features. A hashtag associated with at least one of the features may be determined. A second account connected to the first account may be selected where the second account previously performed a search for the hashtag on the communications network, and at least one of the one or more content items may be provided to the second account.","['G06F16/955', 'G06F16/954', 'G06F16/9566', 'G06T11/00', 'G06V10/44', 'G06V20/20', 'G06V20/40', 'H04L51/10', 'H04L51/52']"
WO2019109771A1,Power artificial-intelligence visual-analysis system on basis of multi-core heterogeneous parallel computing,"Disclosed in the present application is a power artificial-intelligence visual-analysis system on the basis of multi-core heterogeneous parallel computing. The system comprises a multi-core heterogeneous parallel computing module and a service application module. Data is transmitted between the service application module and the multi-core heterogeneous parallel computing module through a web service interface. The multi-core heterogeneous parallel computing module comprises a graphic processing unit (GPU) computing node, a central processing unit (CPU) storage management node, and a CPU computing node, and the nodes are connected by means of a switch. The service application module comprises an image management module, an image labeling module, a model training module, and an algorithm application module.","['G06V10/955', 'G06N3/045', 'G06V10/94']"
US12160369B2,Processor related communications,"A compute device can access local or remote accelerator devices for use in processing a received packet. The received packet can be processed by any combination of local accelerator devices and remote accelerator devices. In some cases, the received packet can be encapsulated in an encapsulating packet and sent to a remote accelerator device for processing. The encapsulating packet can indicate a priority level for processing the received packet and its associated processing task. The priority level can override a priority level that would otherwise be assigned to the received packet and its associated processing task. The remote accelerator device can specify a fullness of an input queue to the compute device. Other information can be conveyed by packets transmitted between and among compute devices and remote accelerator devices to assist in determining an accelerator to use or other uses.","['G06F9/4881', 'H04L41/042', 'H04L45/38', 'H04L47/2433', 'H04L47/2483', 'H04L47/6215', 'H04L47/83', 'H04L2212/00', 'H04L47/805']"
US11030780B2,Ultrasound speckle reduction and image reconstruction using deep learning techniques,"Ultrasound B-mode images are reconstructed directly from transducer channel signals using a convolutional neural network (CNN). The CNN is trained with a dataset including, as inputs, simulated transducer array channel signals containing simulated speckle and, as outputs, corresponding simulated speckle-free B-mode ground truth images. After training, measured real-time RF signals taken directly from an ultrasound transducer array elements prior to summation are input to the CNN and processed by the CNN to generate as output an estimated real-time B-mode image with reduced speckle.","['G06T11/008', 'A61B8/14', 'A61B8/5215', 'G06N20/00', 'G06N3/045', 'G06N3/08', 'G06T11/006', 'A61B8/5207', 'A61B8/5269', 'G06T2211/428', 'G06T2211/441']"
CN113112088B,An edge-cloud collaborative digital twin intelligent production scheduling application running location adaptation method,"The invention provides a method for adapting the running position of an intelligent production scheduling application with edge cloud cooperation and digital twinning. Arranging a generated digital twin system on the edge layer and the cloud layer; and an adaptive strategy controller is arranged on the cloud layer. The adaptive strategy controller dynamically senses edges, cloud resource states, application attributes and the like in the production process, aims at minimizing delay of a digital twin intelligent scheduling decision period, and performs real-time adaptive switching on the running position of the digital twin intelligent scheduling application under two conditions of a determined environment and a non-determined environment; and adopting a digital twin intelligent scheduling application running position based on prediction to adapt and switch in real time in a non-determined environment. The method for determining the running position of the digital twin intelligent scheduling application reduces performance loss caused by data interaction and command issuing delay of a digital twin system, and improves the guarantee of scheduling precision based on the digital twin.","['G06Q10/04', 'G06F30/23', 'G06F30/27', 'G06N3/08', 'G06Q10/06315', 'G06Q10/06393', 'G06Q50/04', 'Y02P90/30']"
EP4154511A1,Maintaining fixed sizes for target objects in frames,"Techniques are provided for processing one or more frames. For example, a region of interest can be determined in a first frame of a sequence of frames. The region of interest in the first frame includes an object having a size in the first frame. A portion of a second frame of the sequence of frames (occurring after the first frame in the sequence of frames) can be cropped and scaled to cause the object in the second frame to have a same size (and in some cases a same location) as the object in the first frame.","['G06N3/084', 'G06F18/2413', 'G06F3/0481', 'G06F3/0484', 'G06N3/045', 'G06N3/0464', 'G06N3/098', 'G06T3/00', 'G06T3/40', 'G06T7/246', 'G06T7/254', 'G06V10/235', 'G06V10/25', 'G06V10/32', 'G06V10/62', 'G06V10/764', 'G06V10/82', 'G06V20/40', 'G06V20/46', 'H04N23/45', 'H04N23/61', 'H04N23/617', 'H04N23/62', 'H04N23/631', 'H04N23/632', 'H04N23/6811', 'H04N23/683', 'H04N23/69', 'H04N23/80', 'H04N23/90', 'H04N5/2628', 'G06N3/047', 'G06N3/048', 'G06T2207/10016', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/20132', 'G06T2207/30201', 'G06T2210/12']"
CN106000904B,A kind of house refuse Automated Sorting System,"A kind of house refuse Automated Sorting System, including rubbish object-recognition unit, garbage sorting control unit, manipulator and transmission house refuse conveyer belt on fixed position installation sampling camera；The house refuse on camera captured in real-time conveyer belt is sampled, by obtained optical image transmission to rubbish object-recognition unit；The above-mentioned optical imagery of rubbish object-recognition unit real-time reception is simultaneously shown, according to the characteristics of the target rubbish of pre-sorting, optical imagery is handled, the object in image is identified, and obtains object pose information frame, and input to garbage sorting control unit；Garbage sorting control unit is according to the object pose information frame of input, according to the relative position of manipulator and conveyer belt, judge whether object carries out the operation interval of idle manipulator, the posture information for the object for entering robot work section is transformed under robot coordinate system, and send to corresponding manipulator, object corresponding to manipulator crawl corresponding to control.","['B07C5/34', 'B07C5/361']"
US9729312B2,System and method for high-assurance data storage and processing based on homomorphic encryption,"A key value storage (KVS) system comprising: a client-side agent configured to encrypt data; three nodes hosted respectively in three cloud service providers, wherein each node comprises: a management node configured to receive encrypted data from the client-side agent, a homomorphic encryption (HE) key manager configured to fetch a public key of a given object in the KVS system, a homomorphic encryption and processing engine configured to execute commands over the encrypted data without decrypting it, a homomorphic memory store, a hypervisor configured to monitor performance of the management node in order to assess the quality of service of the management node; and wherein each node serves on a rotating basis in a master node role, a secondary node role, or a back-up node role, wherein the nodes rotate their roles when the master node's hypervisor detects a reduced quality of service of the master node's management node.","['H04L9/008', 'G06F9/45558', 'H04L63/00', 'H04L63/0428', 'H04L63/06', 'G06F2009/45587']"
US20210258265A1,Resource management for components of a virtualized execution environment,"Examples described herein relate to at least one processor that is to perform a command to build a container using multiple routines and allocate resources to at least one routine based on specification of a service level agreement (SLA) associated with each of the at least one routine. In some examples, the container is compatible with one or more of: Docker containers, Rkt containers, LXD containers, OpenVZ containers, Linux-VServer, Windows Containers, Hyper-V Containers, unikernels, or Java containers. In some examples, a service level is to specify one or more of: time to completion of a routine or resource allocation to the routine. In some examples, the resources include one or more of: cache allocation, memory allocation, memory bandwidth, network interface bandwidth, or accelerator allocation.","['G06F11/3428', 'H04L47/762', 'G06F11/3006', 'G06F11/301', 'G06F11/3058', 'G06F9/45558', 'H04L47/781', 'H04L47/805', 'H04L47/826', 'H04L47/83', 'G06F2009/45562', 'G06F2009/45575', 'G06F2009/45579', 'G06F2009/45583', 'G06F2009/45595']"
US7832762B2,Vehicular bus including crash sensor or occupant protection system control module,"Vehicle including a crash sensor system arranged to determine a crash condition involving the vehicle which might cause injury to a vehicular occupant, at least one module each including an occupant protection device actuatable upon determination of a crash condition in order to protect the occupant from injury during the crash, and a vehicle bus to which the crash sensor system and module(s) are connected. The crash sensor system generates a signal upon a determination of a crash condition and directs the signal over the bus. Each module is arranged to actuate its occupant protection device in consideration of the signal. The signal might be directly sent to the module from the crash sensor system or sent to a control module which processes it and in turn generates a signal to be directed via the bus to the module(s).","['B60R21/013', 'B60R21/0132', 'B60R21/0136', 'B60R2021/01068', 'B60R21/0134']"
US11599998B2,"Machine learning systems and methods for assessment, healing prediction, and treatment of wounds","Machine learning systems and methods are disclosed for prediction of wound healing, such as for diabetic foot ulcers or other wounds, and for assessment implementations such as segmentation of images into wound regions and non-wound regions. Systems for assessing or predicting wound healing can include a light detection element configured to collect light of at least a first wavelength reflected from a tissue region including a wound, and one or more processors configured to generate an image based on a signal from the light detection element having pixels depicting the tissue region, determine reflectance intensity values for at least a subset of the pixels, determine one or more quantitative features of the subset of the plurality of pixels based on the reflectance intensity values, and generate a predicted or assessed healing parameter associated with the wound over a predetermined time interval.","['A61B5/445', 'G06T7/0012', 'A61B5/7275', 'G06T7/11', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'H04N25/135', 'A61B5/0077', 'G06T2207/10024', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30088', 'G06T2207/30096']"
CN113377850B,Big data technology platform of cognitive Internet of things,"The invention discloses a cognitive Internet of things big data technology platform which comprises a core module, a core extension module, a text processing module, a signal/data processing module, a customization technology module and an interface function module.","['G06F16/25', 'G06F16/951', 'G06N3/02', 'G06N3/084', 'G06Q10/103']"
US20230181042A1,"Machine learning systems and methods for assessment, healing prediction, and treatment of wounds","Machine learning systems and methods are disclosed for prediction of wound healing, such as for diabetic foot ulcers or other wounds, and for assessment implementations such as segmentation of images into wound regions and non-wound regions. Systems for assessing or predicting wound healing can include a light detection element configured to collect light of at least a first wavelength reflected from a tissue region including a wound or portion thereof, and one or more processors configured to generate an image based on a signal from the light detection element having pixels depicting the tissue region, automatically segment the pixels into wound pixels and non-wound pixels, determine one or more optically determined tissue features of the wound or portion thereof, and generate a predicted or assessed healing parameter associated with the wound or portion thereof over a predetermined time interval.","['A61B5/0059', 'G06T7/0012', 'A61B5/0075', 'A61B5/0077', 'A61B5/445', 'A61B5/4842', 'A61B5/7267', 'A61P17/02', 'A61B2562/046', 'A61B2576/02', 'G06T2207/10048', 'G06T2207/30088', 'G06T2207/30096', 'G16H30/40']"
US11484710B2,Device and system for real-time gait modulation and methods of operation thereof,"Apparatus, systems, and methods for real-time gait modulation are disclosed. In one embodiment, a functional electrical stimulation (FES) device is disclosed comprising one or more elastic wearable articles, a control unit comprising a wireless communication module, one or more processors, one or more memory units, a portable power supply, an electrical muscle stimulation (EMS) generator, and an inertial measurement unit (IMU) comprising at least a gyroscope and an accelerometer. The FES device can also comprise one or more electrode arrays configured to be in physical contact with the limb of the user. The processors can be programmed to execute instructions to retrieve readings from the IMU, calculate a gait cycle percentage by inputting at least the IMU readings into a machine learning algorithm, and instruct the EMS generator to provide electrical stimulation via the one or more electrode arrays based in part on the gait cycle percentage calculated.","['A61B5/0022', 'A61B5/112', 'A61B5/6828', 'A61N1/0452', 'A61N1/0456', 'A61N1/0476', 'A61N1/36003', 'A61N1/3603', 'G06F3/011', 'G06F3/017', 'G06N20/00', 'G06N3/08', 'A61B2562/0219', 'G06N20/10', 'G06N20/20', 'G06N5/01', 'G06N7/01']"
CN113159073B,"Knowledge distillation method and device, storage medium and terminal","A knowledge distillation method and device, a storage medium and a terminal, wherein the method comprises the following steps: the method comprises the steps of obtaining a sample image, and inputting the sample image into a teacher network and a student network respectively, wherein the teacher network comprises a first feature extraction module, the first feature extraction module comprises one or more cascaded first feature units, the student network comprises a second feature extraction module, the second feature extraction module comprises one or more cascaded second feature units, and the sample image is provided with a label; aggregating the feature vector calculated by each second feature unit to the feature vector calculated by the first feature unit corresponding to the second feature unit; calculating a first prediction result according to the feature vector output by the first feature extraction module, and calculating a second prediction result according to the feature vector output by the second feature extraction module; calculating distillation loss according to the first prediction result, the second prediction result and the label; and updating the student network according to the distillation loss.","['G06V10/44', 'G06F18/241', 'G06N3/045', 'G06N3/08']"
CN111985370B,Crop pest and disease identification method based on mixed attention module,"The invention discloses a crop pest fine-grained identification method based on an improved mixed attention moduleC(F) And MS(F) (ii) a Finally obtaining a characteristic diagram F2The final prediction probability is generated using the softmax function. In order to improve the accuracy of the pest and disease identification model and detect pests in time, the mixed attention CBAM is improved, the problem of interference generated by serial connection channel attention and space attention is solved through a parallel connection structure of the channel attention and the space attention, the accuracy of the pest and disease fine-grained identification model added with attention is improved more stably, and the direct generalization of I _ CBAM in different models is also ensured.","['G06V20/13', 'G06F18/214', 'G06F18/2415', 'G06N3/0409', 'G06N3/045', 'G06N3/08']"
US7734061B2,Optical occupant sensing techniques,"Vehicular system for determining the presence of an object in a passenger compartment of the vehicle includes a first image receiver arranged at a first location for obtaining a first two-dimensional view of a portion of the compartment, and a second image receiver arranged at a second location for obtaining a second two-dimensional view of the same portion of the compartment, the second image receiver being arranged relative to the first image receiver such that three dimensions of the portion of the compartment are encompassed by the first and second views. A processor receives images from the first and second image receivers and determines whether an object is present in the compartment based on the images. A reactive system, such as an airbag assembly, may be coupled to the processor and controlled thereby based on the determination of whether an object is present in the imaged portion of the compartment.","['B60J10/00', 'B60N2/0022', 'B60N2/0025', 'B60N2/0028', 'B60N2/0029', 'B60N2/0035', 'B60N2/0268', 'B60N2/0272', 'B60N2/267', 'B60Q1/143', 'B60R16/037', 'B60R21/01516', 'B60R21/0152', 'B60R21/01534', 'B60R21/01536', 'B60R21/01538', 'B60R21/0154', 'B60R21/01542', 'B60R21/01552', 'B60R21/01554', 'B60R25/25', 'B60R25/252', 'B60R25/255', 'B60R25/257', 'E05F15/43', 'E05F15/431', 'G01S15/87', 'G01S15/88', 'G01S17/04', 'G01S17/88', 'G01S7/4802', 'G01S7/539', 'G06V20/59', 'G06V40/10', 'B60N2210/12', 'B60N2210/16', 'B60N2210/24', 'B60N2210/26', 'B60N2210/30', 'B60N2210/42', 'B60N2220/20', 'B60N2220/30', 'B60N2230/30', 'B60Q2300/3321', 'B60Q2300/41', 'B60Q2300/42', 'B60R2001/1223', 'B60R2001/1253', 'B60R2021/0027', 'B60R2021/01315', 'B60R21/0134', 'B60R21/0153', 'B60R21/01544', 'B60R21/01548', 'E05F2015/433', 'E05Y2900/55', 'G01S13/04', 'G01S15/04', 'G01S15/06', 'G01S17/89', 'G10K2210/1282', 'G10K2210/3219']"
US11354702B2,Generating interactive advertising with content collections,"Systems, devices, media, instructions, and methods are provided for presentation of media collections with automated interactive advertising. In one embodiment, a server system merges advertising data with interaction elements to create an advertising element, and communicates the advertising element to a client device with other pieces of content. In another embodiment, advertising data is received at a client device and merged at the client device with interaction elements to generate an advertising element. The advertising element is then displayed between content elements that are part of one or more content collections. In various embodiments, interaction data recorded at the device is used to manage the presentation of future advertising elements.","['G06Q30/0244', 'G06Q30/0242', 'G06F16/951', 'G06F16/9535', 'G06F3/017', 'G06F3/0488', 'G06Q30/0241', 'G06Q30/0251', 'G06Q30/0258', 'G06Q30/0267', 'G06Q30/0276', 'G06Q30/0277']"
US9030321B2,Cargo theft prevention using text messaging,"Method for monitoring a cargo container in which a transmitter is arranged on the container and periodically transmits messages to a remote site or location according to a schedule of messages. When a message is not received according to the schedule, which may be the result of tampering with the transmitter or another nefarious action involving the container, it may be considered that the container has been stolen. A rate of transmission of the messages may be modified based on a condition of the vehicle, such as the presence of a driver inside the vehicle, a distance between a driver inside the vehicle and the vehicle, the vehicle being at rest after motion of the vehicle stops, a location of the vehicle, biometric identification of a driver of the vehicle and deviation of the vehicle from an expected route, and/or based on current time and weather around the vehicle.","['B60T1/005', 'B60T1/067', 'B60T7/16', 'G01S13/04', 'G08B13/00', 'G08B13/1427', 'G08B13/2417', 'H04K3/222', 'H04K3/88', 'G08B13/1436', 'G08B13/19647', 'H04K2203/16', 'H04K2203/22', 'H04K3/226', 'Y10T70/65']"
US10646156B1,Adaptive image processing in assisted reproductive imaging modalities,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['A61B5/4325', 'A61B8/5223', 'G06K9/00671', 'G06N20/10', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G06N3/088', 'G06T7/0012', 'G06T7/0016', 'G06V10/764', 'G06V10/82', 'G06V20/20', 'G16H10/60', 'G16H30/40', 'G16H50/20', 'G16H50/70', 'G06N3/044', 'G06N3/047', 'G06N3/048', 'G06T2200/28', 'G06T2207/10024', 'G06T2207/10132', 'G06T2207/10136', 'G06T2207/20036', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/03', 'Y02A90/10']"
US11783369B2,Interactive advertising with media collections,"Systems, devices, media, instructions, and methods are provided for presentation of media collections with automated interactive advertising. In one embodiment, a client device receives content elements for display as part of a content collection. Advertising data is also received for display between selected content elements. Interaction elements are merged with the create an advertising element. During display of the advertising data, the interaction elements are presented on the client device output, and are controllable via user inputs. In various embodiments, interaction data recorded at the device is used to manage the presentation of future advertising data.",['G06Q30/0244']
US9015092B2,Dynamically reconfigurable stochastic learning apparatus and methods,"Generalized learning rules may be implemented. A framework may be used to enable adaptive signal processing system to flexibly combine different learning rules (supervised, unsupervised, reinforcement learning) with different methods (online or batch learning). The generalized learning framework may employ average performance function as the learning measure thereby enabling modular architecture where learning tasks are separated from control tasks, so that changes in one of the modules do not necessitate changes within the other. Separation of learning tasks from the control tasks implementations may allow dynamic reconfiguration of the learning block in response to a task change or learning method change in real time. The generalized learning apparatus may be capable of implementing several learning rules concurrently based on the desired control application and without requiring users to explicitly identify the required learning rule composition for that application.","['G06N3/08', 'G06N20/00', 'G06N99/005']"
CN110738605B,"Image denoising method, system, equipment and medium based on transfer learning","The invention discloses an image denoising method, system, equipment and medium based on transfer learning, which acquire an image to be denoised; inputting an image to be denoised into a pre-trained denoising neural network based on transfer learning for processing, wherein the denoising neural network based on transfer learning comprises: a main noise reduction network and a noise distribution information extraction network; the noise distribution information extraction network is used for extracting random noise distribution characteristics; after preprocessing the random noise distribution characteristics, the random noise distribution characteristics are used as dynamic normalization parameters of each residual error module of the main noise reduction network, and are migrated into the data characteristics of the main noise reduction network, so that the convergence speed of the main network is accelerated; carrying out normalization processing on the image features extracted by each residual error module of the main noise reduction network by utilizing dynamic normalization parameters, and outputting a pure noise image by the main noise reduction network; and carrying out difference processing on the pure noise image and the image to be denoised to obtain a denoised image.","['G06T5/70', 'G06T2207/20081', 'G06T2207/20084']"
US7349555B2,Documents and apparatus to encode documents,"The present invention relates generally to documents, e.g., such as legal tender, currency and identification documents, and apparatus for encoding documents. One claim recites: a physical document including a machine-detectable hidden signal. Presence of the hidden signal is determined by collecting visible light image data associated with the document and transforming the image data to a complementary domain to generate transform data. Presence of a telltale pattern in the transform data indicates a presence of the hidden signal. The hidden signal is associated with a type or status of the physical document. One type is legal tender. Another type is an identification document. An example of status is “do not copy”. Of course, other combinations are claimed as well.","['B42D25/23', 'B42D25/00', 'G06F16/955', 'G06K19/06037', 'G06K19/06046', 'G06K19/14', 'G06K19/18', 'G06K7/14', 'G06K7/1417', 'G06K7/1447', 'G06Q20/341', 'G06Q20/40145', 'G06T1/0021', 'G06T1/005', 'G06V20/80', 'G07C9/22', 'G07C9/253', 'G07D7/0032', 'G07D7/0034', 'G07D7/004', 'G07D7/0047', 'G07D7/005', 'G07D7/2016', 'G07D7/2033', 'G07F17/16', 'G07F7/08', 'G07F7/086', 'G07F7/1008', 'G07F7/1016', 'G07F7/12', 'G07F7/122', 'G10L19/018', 'G11B20/00086', 'G11B20/00094', 'G11B20/00115', 'G11B20/00166', 'G11B20/00181', 'G11B20/0021', 'G11B20/00884', 'G11B20/00891', 'H04B1/665', 'H04N1/00005', 'H04N1/00037', 'H04N1/00079', 'H04N1/32144', 'H04N1/3216', 'H04N1/32203', 'H04N1/32208', 'H04N1/32251', 'H04N1/32288', 'H04N1/32352', 'H04N19/00', 'H04N19/467', 'H04N21/23892', 'H04N21/8358', 'H04N5/913', 'B42D25/309', 'G06K2019/06253', 'G06T2201/0052', 'G06T2201/0064', 'G06T2201/0065', 'G07C2209/41', 'H04N2005/91321', 'H04N2005/91335', 'H04N2201/3205', 'H04N2201/3207', 'H04N2201/3226', 'H04N2201/3233', 'H04N2201/327', 'H04N2201/3271', 'H04N2201/3274', 'H04N2201/328']"
CN113808244B,Support for motion blur and ray tracing hardware acceleration for moving/deformed geometry,"Ray tracing hardware acceleration to support motion blur and motion/deformation geometry is disclosed. For example, dynamic objects in the acceleration data structure are encoded with temporal and spatial information. The hardware includes circuitry to test ray intersection for motion/deformation geometry by applying such temporal and spatial information. Such a circuit accelerates visibility sampling of moving geometries (including rigid body motion and object deformation) and their associated moving bounding volumes to achieve visibility sampling performance similar to static geometries.","['G06T15/06', 'G06F9/5027', 'G06T1/20', 'G06T1/60', 'G06T15/005', 'G06T15/08', 'G06T17/10', 'G06T3/4007', 'G06T9/00', 'G06T2200/28']"
US12037972B2,Inertial pneumatic wave energy device,"A buoyant wave energy device is disclosed that incorporates an open-bottomed tube of substantial length in which is partially enclosed a first body of water that oscillates in response to wave action. The device incorporates a buoy to which an upper end of the tube is connected and inside of which is trapped a second body of water of substantial mass. A differential phase in the oscillations of the water trapped in the tube, and the oscillations of the buoy of augmented mass, result in the periodic compression of a pocket of air trapped at the top of the tube, and in the subsequent expulsion of pressurized air through a turbine, thereby generating electrical power.","['F03B13/142', 'F03B13/24', 'H02K7/1823', 'F05B2220/706', 'F05B2240/133', 'F05B2240/93', 'F05B2240/95', 'Y02E10/30']"
US20230071099A1,Methods and systems for presentation of media collections with automated advertising,"Systems, devices, media, instructions, and methods are provided for presentation of media collections with automated advertising. In one embodiment, display time data associated for a first plurality of content elements and a first advertising element as displayed on a first device are used in adjusting a presentation order for a second content collection comprising a second plurality of content elements and at least a second advertising element, where a placement of the second advertising element within the presentation order is based on the display time data. In some embodiments, a ratio of advertising to content elements is targeted over time for a user based on user interactions with various content and advertising elements.","['G06Q30/0264', 'G06F3/04842', 'G06F3/04845', 'G06F3/04883', 'G06Q30/0241', 'H04N21/4312', 'H04N21/812']"
US20220383604A1,Methods and systems for three-dimensional model sharing,"Examples of the disclosure describe systems and methods for decomposing and sharing 3D models. In an example method, a first version of a virtual three-dimensional model is displayed via a display of a wearable head device. A request is made to a host device for data associated with a second version of the virtual three-dimensional model, wherein the second version of the virtual three-dimensional model comprises a constituent part. It is determined whether the first version of the virtual three-dimensional model comprises the constituent part. In accordance with a determination that the first version of the virtual three-dimensional model does not comprise the constituent part, a request is made to the host device for data associated with the constituent part. The second version of the virtual three-dimensional model is displayed, via the display of the wearable head device. In accordance with a determination that the first version of the virtual three-dimensional model comprises the constituent part, a request is not made to the host device for data associated with the constituent part.","['G06T17/20', 'A63F13/213', 'A63F13/26', 'A63F13/355', 'G02B27/0172', 'G06F3/011', 'G06F3/017', 'G06T19/20', 'G02B2027/0134', 'G02B2027/014', 'G02B2027/0178', 'G06T2200/16', 'G06T2210/08', 'G06T2219/024', 'G06T2219/2008']"
US11082731B1,Privacy-preserving video analytics,"Generally discussed herein are devices, systems, and methods for privacy-preserving video. A method can include identifying which classes of objects are present in video data, for each class of the classes identified in the video data, generating respective video streams that include objects of the class and exclude objects not of the class, and providing each of the respective video streams to a content distribution network.","['H04N21/23476', 'G06F18/2431', 'G06F21/6245', 'G06K9/00771', 'G06K9/628', 'G06V10/25', 'G06V10/764', 'G06V10/82', 'G06V20/52', 'G08B13/19667', 'G08B13/19686', 'H04N21/23418', 'H04N21/234318', 'H04N21/2353', 'H04N21/23895', 'H04N21/2393', 'H04N21/4318', 'H04N21/44008', 'H04N21/4408', 'H04N21/45455', 'H04N21/4627', 'H04N21/4728', 'H04N21/84', 'H04N23/61', 'H04N23/661', 'G06K2209/27', 'G06N3/044', 'G06N3/045', 'G06V2201/10']"
US11922532B2,System for mitigating the problem of deepfake media content using watermarking,"Watermarking media content, in combination with blockchain and distributed storage networks, prevents the proliferation of Deepfake content. Digital watermarks are embedded in the audio and video tracks of video clips of trusted content producers at the time the videos are captured or before they are distributed. The watermarks are detected at the social media network's portals, nodes, and back ends. The embedded watermark imparts a unique identifier to the video, that links it to a blockchain. The watermarks also allow video source tracking, integrity verification, and alteration localization. The watermark detectors can be standalone software applications, or they can be integrated with other applications. They are used to perform three main tasks: (1) they alert the Internet user when he watches an inauthentic news video, so that he may discard it, (2) they prevent a Deepfake content from propagating through the network (3) they perform forensic analysis to help track and remove Deepfake content postings.","['G06T1/0028', 'G06F18/22', 'G06F21/1063', 'G06F21/16', 'G06F21/645', 'G06T1/005', 'G06T1/0092', 'G06V20/46', 'G06V40/16', 'G06V40/171', 'G10L19/018', 'G06T2201/0051', 'G06T2201/0052', 'G06T2201/0061', 'G06T2201/0601']"
CN112577747B,Rolling bearing fault diagnosis method based on space pooling network,"The invention provides a rolling bearing fault diagnosis method based on a space pooling network, which is characterized by collecting vibration signals of a rolling bearing in a fault state and a normal state, cutting the collected vibration signals of the bearing to form samples, and dividing the samples into a training set, a verification set and a test set; then inputting the samples in the training set and the verification set into a convolutional neural network for training and adjusting the structure of the convolutional neural network; after the last 'convolution+pooling' unit of the convolution neural network of the structure is determined, adding a spatial pooling attention to weight the characteristics, and adding two spatial pooling layers and a softmax classifier to complete the construction of a spatial pooling model; and inputting samples of the training set and the verification set into a space pooling network for parameter updating, inputting samples of the test set into the trained space pooling network to obtain a bearing state type, comparing the bearing state type with a label, and calculating to obtain diagnosis precision.","['G01M13/045', 'G06F18/2414', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06F2218/08', 'G06F2218/12', 'Y02T90/00']"
US11889381B2,"Generation, curation, and presentation of media collections",Systems and methods are provided for receiving input increasing a default predetermined window of time that the new media collection is accessible and activating the new media collection for the increased predetermined window of time and a geographic boundary size for where media content originates. The systems and methods further cause a plurality of content messages comprising media content originating in the geographical boundary size to be included in the new media collection and displayed in response to a request from a computing device to view the new media collection based on determining the request occurs within the increased predetermined window of time that the new media collection is accessible.,"['H04W4/021', 'H04L12/1859', 'H04L51/52', 'H04L67/52']"
US12374040B2,Environment reconstruction and path planning for autonomous systems and applications,"Approaches for environment reconstruction and path planning for autonomous machine systems and applications are described. An iterative volumetric mapping function for an ego-machine may compute a distance field, and from the distance field derive a cost map representing a volumetric reconstruction of the physical environment around the ego-machine. The cost map may be used for collision avoidance and path planning. The iterative volumetric mapping function may also optionally compute a color integration map and visualization mesh from the distance field that can be used for visualization of the physical environment around the ego-machine. The cost map may be computed as a Euclidean Signed Distance Field (ESDF) and the distance field from which the cost map is computed may include a Truncated Signed Distance Field (TSDF). The distance field, cost map, color integration map and visualization mesh may each be stored in memory as maps of a plurality of map layers.","['G06T17/05', 'B60W30/09', 'B60W60/001', 'B60W60/0015', 'G05D1/242', 'G05D1/2464', 'G05D1/2465', 'G05D1/622', 'G06F16/2272', 'G06T1/20', 'G06T17/20', 'G06T7/50', 'G06V10/82', 'G06V20/56', 'G06V20/58', 'B60W2420/403', 'B60W2420/408', 'B60W2552/05', 'B60W2554/20', 'B60W2556/40', 'G05D1/0214', 'G05D1/0231', 'G05D1/101', 'G05D2111/17', 'G06T2200/04', 'G06T2200/08', 'G06T2207/10024', 'G06T2207/10028', 'G06T2207/30244', 'G06T2207/30261', 'G06T2215/12']"
CN109447048B,Artificial intelligence early warning system,"The invention relates to an artificial intelligence early warning system which comprises an intelligent internet of things and risk factor data acquisition system (100), a risk factor management system (200), cloud computing (300), cloud storage (400), a cloud database (500), an artificial intelligence early warning operating system (600), an artificial intelligence early warning server (700), an internet + distributed early warning kiosk (800), a five-level artificial intelligence early warning system (900), a four-level artificial intelligence early warning system (1000), a three-level artificial intelligence early warning system (1100), a two-level artificial intelligence early warning system (1200) and a one-level artificial intelligence early warning system (1300). According to the invention, an artificial intelligent early warning system is used for collecting, contrastively analyzing, reasoning, evaluating, cloud computing, cloud storage, grading alarm and coping prevention and control on risk factors; the all-weather 24-hour monitoring on the peripheral control points of the police kiosk is realized, the information sharing can be realized for users, the utilization rate of information resources is improved, and the safety guarantee is increased for maintaining the frontier stability.","['G06V40/70', 'G06F18/22', 'G06F40/253', 'G06F40/289', 'G06F40/30', 'G06V10/95']"
US8977576B2,Methods for solving computational problems using a quantum processor,"Methods for solving a computational problem including minimizing an objective including a set of weights and a dictionary by casting the weights as Boolean variables and alternately using a quantum processor and a non-quantum processor to successively optimize the weights and the dictionary, respectively. A first set of values for the dictionary is guessed and the objective is mapped to a QUBO. A quantum processor is used to optimize the objective for the Boolean weights based on the first set of values for the dictionary by minimizing the resulting QUBO. A non-quantum processor is used to optimize the objective for the dictionary based on the Boolean weights by updating at least some of the columns of the dictionary. These processes are successively repeated until a solution criterion is met. Minimization of the objective may be used to generate features in a learning problem and/or in data compression.","['G06N99/002', 'G06N10/60', 'B82Y10/00', 'G06N5/01']"
US20200395117A1,Adaptive image processing method and system in assisted reproductive technologies,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['G16H30/20', 'G06N20/00', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G16H10/60', 'G16H20/10', 'G16H30/40', 'G16H50/20', 'G16H50/30', 'A61B10/0012', 'A61B8/5223', 'G06N3/082', 'Y02A90/10']"
US20220337747A1,Apparatus and method for operating multiple cameras for digital photography,"A method for operating an electronic device includes capturing, by an image sensor module, a stream from a pixel array. The method also includes processing, by the image sensor module, the stream to generate a preview stream and a full frame stream. The method further includes compressing, by the image sensor module, the preview stream using a first compression and the full frame stream using a second compression. In addition, the method includes outputting, by the image sensor module, the compressed preview stream and the compressed full frame stream.","['H04N5/2621', 'H04N5/23238', 'H04N23/698', 'H04N23/45', 'H04N23/58', 'H04N23/65', 'H04N23/667', 'H04N23/695', 'H04N23/951', 'H04N25/41', 'H04N5/2258', 'H04N5/23245', 'H04N5/23299', 'H04N23/741', 'H04N5/2226']"
US10258248B2,Vector-based shock indication,"A system for managing care of a person receiving emergency cardiac assistance includes one or more capacitors arranged to deliver a defibrillating shock to a person; one or more electronic ports for receiving a plurality of signals from sensors for obtaining indications of an electrocardiogram (ECG) for the person; and a patient treatment module executable on one or more computer processors using code stored in non-transitory media and to provide a determination of a likelihood of success from delivering a future defibrillating shock to the person with the one or more capacitors, using a mathematical computation applied to a vector value defined by signals from at least two of the plurality of signals.","['A61B5/04011', 'A61B5/341', 'A61B5/04012', 'A61B5/0531', 'A61B5/347', 'A61B5/4836', 'A61B5/4848', 'A61B5/7257', 'A61B5/7264', 'A61B5/7275', 'A61N1/3925', 'A61N1/3987', 'A61N1/3993', 'G06F19/00', 'G16H50/30', 'A61B5/7221']"
US11189358B2,Method of controlling operation of nonvolatile memory device using machine learning and storage system,"According to a method of controlling an operation of a nonvolatile memory device using machine learning, operating conditions of the nonvolatile memory device are determined by performing an inferring operation using a machine learning model. Training data that are generated based on feature information and error information are collected, where the error information indicate results of error correction code (ECC) decoding of the nonvolatile memory device. The machine learning model is updated by performing a learning operation based on the training data. Optimized operating conditions for individual user environments are provided by collecting training data in the storage system and performing the learning operation and the inferring operation based on the training data.","['G06F11/1044', 'G11C29/52', 'G11C16/26', 'G06F11/1048', 'G06F11/1068', 'G06F18/214', 'G06F18/2148', 'G06K9/6257', 'G06N20/00', 'G06N20/20', 'G06N3/045', 'G06N3/08', 'G06N5/04', 'G11C16/3404', 'G11C29/021', 'G11C29/028', 'G11C29/42', 'G11C29/44', 'G11C29/4401', 'G11C29/50004', 'G11C2029/0409', 'G11C2029/0411', 'G11C2029/4402', 'G11C29/40']"
CN110610707B,"Voice keyword recognition method and device, electronic equipment and storage medium","The embodiment of the invention provides a method and a device for recognizing a voice keyword, electronic equipment and a storage medium, wherein the method comprises the following steps: extracting an acoustic state posterior probability distribution vector of each frame in the voice data corresponding to the word to be recognized; the acoustic state posterior probability distribution vector for any frame includes posterior probabilities of the any frame with respect to a plurality of acoustic states; inputting the acoustic state posterior probability distribution vector of each frame in the voice data into a keyword recognition model to obtain a keyword recognition result corresponding to the word to be recognized and output by the keyword recognition model; the keyword recognition model is obtained by training based on the posterior probability distribution vector of the acoustic state of the sample of each sample frame in the sample word and the keyword identification of the sample word. The method, the device, the electronic equipment and the storage medium provided by the embodiment of the invention can improve the identification precision, avoid the misjudgment problem of similar words, improve the response accuracy and optimize the user experience.","['G06N3/045', 'G06N3/084', 'G10L15/02', 'G10L15/26', 'G10L25/30']"
CN114299559B,Finger vein recognition method based on lightweight fusion of global and local feature network,"A finger vein recognition method based on lightweight fusion global and local feature networks is disclosed. 1. Constructing a data set, dividing a training set and a test set, 2, designing a lightweight fusion global and local feature network FGL-MobileNet based on a lightweight residual error unit, 3, designing a FGL-Net based on fusion global and local features, including a main network based on an improved residual error network and a global feature and local feature extraction module, 4, designing a network loss function, 5, training a whole FGL-MobileNet network model until the whole training set is iteratively trained for a plurality of times, and 6, inputting a test set image into the trained FGL-MobileNet network model to extract finger vein features and perform identification comparison. According to the invention, FGL-MobileNet is built by stacking the units, so that the receptive field of the finger vein features can be rapidly and effectively enlarged by the network, thus the more abundant finger vein detail features are obtained, the extracted finger vein features are more discriminative, and the number of network parameters is greatly reduced.",['Y02T10/40']
US20250190482A1,Content summarization leveraging systems and processes for key moment identification and extraction,"A system or process may generate a summarization of multimedia content by determining one or more salient moments therefrom. Multimedia content may be received and a plurality of frames and audio, visual, and metadata elements associated therewith are extracted from the multimedia content. A plurality of importance sub-scores may be generated for each frame of the multimedia content, each of the plurality of sub-scores being associated with a particular analytical modality. For each frame, the plurality of importance sub-scores associated therewith may be aggregated into an importance score. The frames may be ranked by importance and a plurality of top-ranked frames are identified and determined to satisfy an importance threshold. The plurality of top-ranked frames are sequentially arranged and merged into a plurality of moment candidates that are ranked for importance. A subset of top-ranked moment candidates are merged into a final summarization of the multimedia content.","['G06F16/739', 'G06F16/45', 'G06F16/483', 'G06N20/00', 'G06V20/41', 'G06V20/47', 'G06N3/045', 'G06N3/088']"
CN111712161B,Bed with sensor features for determining snoring and breathing parameters of two sleepers,The mattress supports a left user and a right user. The at least one acoustic sensor is configured to sense acoustic energy in the environment of the left user and the right user. The at least one pressure sensor is configured to sense pressure applied to the left portion by the left user and pressure applied to the right portion by the right user. The controller is configured to receive at least one acoustic stream from the at least one acoustic sensor and at least one pressure stream from the at least one pressure sensor. A left snoring/breathing parameter and a right snoring/breathing parameter are generated. The controller is further configured to send an instruction to drive the controllable device to the controllable device in response to determining that the home automation rule includes a condition comprising at least one of a left snore/breath parameter and a right snore/breath parameter.,"['A47C27/083', 'A47C21/003', 'A47C27/082', 'A47C27/10', 'A61B5/0022', 'A61B5/024', 'A61B5/0816', 'A61B5/11', 'A61B5/4809', 'A61B5/4812', 'A61B5/4818', 'A61B5/6892', 'A61B5/7264', 'A61B5/7267', 'A61B7/003', 'G16H40/67', 'A61B5/021', 'A61B7/00', 'A61F5/56', 'G16H50/70']"
US7511833B2,System for obtaining information about vehicular components,"System and method for obtaining information about components in a vehicle in which reflective devices are arranged in association with each component, a detector detects waves reflected by the reflective device(s), and a processor obtains information about the components from the detected waves. Reflection of waves from each reflective device is transformed into information about the reflective device, such as deriving the distance between the reflective device and the detector from the reflected waves and transforming this distance determination into a determination of the position of the component. In addition to or instead of the position of the component, the orientation of the component can be determined, or the presence of the component. Information derived from the reflective device(s) can be used to control any number and variety of vehicular systems, such as an occupant protection system.","['G01S13/04', 'B60J10/00', 'B60N2/0022', 'B60N2/0023', 'B60N2/0025', 'B60N2/0026', 'B60N2/0028', 'B60N2/003', 'B60N2/0035', 'B60N2/0268', 'B60N2/0272', 'B60R1/088', 'B60R11/0241', 'B60R16/037', 'B60R21/01516', 'B60R21/0152', 'B60R21/0153', 'B60R21/01534', 'B60R21/01536', 'B60R21/01538', 'B60R21/01542', 'B60R21/01552', 'B60R21/01554', 'B60R25/25', 'B60R25/252', 'B60R25/255', 'B60R25/257', 'E05F15/43', 'E05F15/431', 'E05F15/70', 'G01F23/20', 'G01F23/2962', 'G01F23/804', 'G01S7/417', 'G06V20/59', 'G06V40/10', 'B60N2210/12', 'B60N2210/18', 'B60N2210/20', 'B60N2210/24', 'B60N2210/26', 'B60N2210/42', 'B60N2230/30', 'B60R2001/1223', 'B60R2001/1253', 'B60R2021/0027', 'B60R2021/01315', 'B60R21/0132', 'B60R21/0134', 'B60R21/01544', 'B60R21/01548', 'E05Y2900/538', 'E05Y2900/55', 'G01S13/74', 'G10K2210/1282', 'G10K2210/3219']"
US7477758B2,System and method for detecting objects in vehicular compartments,System and method for detecting the presence of contents of a vehicular compartment in which a detector system generates an output signal indicative of the absence of an object in the compartment when an object is not situated in the compartment and a different output signal indicative of a particular object in the compartment when such an object is situated in the compartment. Different output signals are thus generated for different objects. A processor is coupled to the detector system for processing the output signal to create a signal characteristic of the object which is indicative of whether the object is animate or inanimate. This system is coupled to a reactive system for affecting one or more vehicular components when the created signal is indicative of an animate object. The reactive system may be a release device for opening an access door or panel to the compartment.,"['G01S15/523', 'B60J10/00', 'B60N2/0024', 'B60N2/0027', 'B60N2/0268', 'B60N2/0272', 'B60N2/268', 'B60R1/088', 'B60R11/0241', 'B60R16/037', 'B60R21/01512', 'B60R21/01516', 'B60R21/0152', 'B60R21/01534', 'B60R21/01536', 'B60R21/01538', 'B60R21/0154', 'B60R21/01542', 'B60R21/01552', 'B60R21/01554', 'B60R22/20', 'B60R25/25', 'B60R25/252', 'B60R25/255', 'B60R25/257', 'E05F15/43', 'E05F15/431', 'G01G23/3728', 'G01S15/87', 'G01S15/88', 'G01S17/88', 'G01S7/417', 'G01S7/4802', 'G01S7/539', 'G06V20/59', 'G06V40/10', 'B60N2210/18', 'B60N2210/26', 'B60N2210/42', 'B60N2230/30', 'B60R2001/1223', 'B60R2001/1253', 'B60R2021/0027', 'B60R2021/01315', 'B60R2021/23153', 'B60R2021/26094', 'B60R2021/2765', 'B60R2022/208', 'B60R2022/4825', 'B60R21/0134', 'B60R21/01544', 'B60R21/01548', 'B60R21/21656', 'B60R21/276', 'E05F2015/433', 'E05Y2900/55', 'G01S13/04', 'G01S15/04', 'G01S15/06', 'G01S17/89', 'G10K2210/1282', 'G10K2210/3219']"
US10853937B2,Unsupervised image-based anomaly detection using multi-scale context-dependent deep autoencoding gaussian mixture model,"A false alarm reduction system is provided that includes a processor cropping each input image at randomly chosen positions to form cropped images of a same size at different scales in different contexts. The system further includes a CONDA-GMM, having a first and a second conditional deep autoencoder for respectively (i) taking each cropped image without a respective center block as input for measuring a discrepancy between a reconstructed and a target center block, and (ii) taking an entirety of cropped images with the target center block. The CONDA-GMM constructs density estimates based on reconstruction error features and low-dimensional embedding representations derived from image encodings. The processor determines an anomaly existence based on a prediction of a likelihood of the anomaly existing in a framework of a CGMM, given the context being a representation of the cropped image with the center block removed and having a discrepancy above a threshold.","['G06T7/0004', 'G06F18/214', 'G06F18/2414', 'G06F18/2433', 'G06K9/4604', 'G06K9/4628', 'G06K9/4671', 'G06K9/6256', 'G06K9/6273', 'G06K9/6284', 'G06T3/403', 'G06T7/001', 'G06V10/454', 'G06V10/462', 'G06V10/764', 'G06V10/82', 'G06K2209/19', 'G06T2207/20081', 'G06T2207/20084', 'G06V2201/06', 'G08B29/186']"
CN111614599B,Webshell detection method and device based on artificial intelligence,"The application discloses a webshell detection method and device based on artificial intelligence. The method comprises the following steps: step A, sample data of a webshell backdoor file is obtained; b, extracting features of the webshell backdoor file sample to generate a feature vector for supervised learning, wherein the feature vector for supervised learning comprises at least one of text features, byte code features and abnormal behavior features; step C, respectively establishing a learning model of each characteristic vector according to the characteristic vector of supervised learning; and D, detecting the network flow by using the learning model.","['H04L63/1408', 'G06F18/24', 'G06N3/045', 'G06N3/08']"
US10897633B2,System and method for real-time processing of compressed videos,"A real-time system and method for displaying video on a display are disclosed. Received compressed video data is decoded to produce an uncompressed first video frame, a first frame syntax element, an uncompressed second video frame, and a second frame syntax element. A computationally intensive process is applied to the uncompressed first video frame to produce an enhanced first video frame. A block having a portion of the enhanced first video frame from the enhanced first video frame is adaptively transferred to the uncompressed second video frame to produce an enhanced second video frame without applying the computationally intensive process to the uncompressed second video frame. The transferring is guided by the first frame syntax element and the second frame syntax element. The enhanced first video frame and the enhanced second video frame are displayed.","['H04N19/70', 'G06T3/4053', 'H04N19/105', 'H04N19/117', 'H04N19/124', 'H04N19/15', 'H04N19/159', 'H04N19/46', 'H04N19/513', 'H04N19/61', 'H04N19/86', 'H04N19/172', 'H04N19/176', 'H04N19/182', 'H04N19/184']"
CN111771141B,LIDAR localization in autonomous vehicles using 3D CNN networks for solution inference,A method of solution inference using neural networks in LIDAR positioning includes constructing a cost amount for a predicted pose of an autonomous vehicle (ADV) in solution space. The cost amount includes a plurality of sub-amounts. Each sub-quantity represents a matching cost between a keypoint from the online point cloud and a corresponding keypoint on the pre-built point cloud map (1001). The method further includes regularizing the cost amount to match a cost refinement matching cost (1003) using a Conventional Neural Network (CNN); and infer an optimal offset of the predicted pose from the regularized cost amount. The optimal offset may be used to determine the location of the ADV (1005).,"['G01S7/4913', 'G01S7/4808', 'G01S17/08', 'G01S17/89', 'G01S17/931', 'G01S7/40', 'G05D1/024', 'G06F18/254', 'G06N3/02', 'G06N3/044', 'G06N3/0442', 'G06N3/045', 'G06N3/0464', 'G06N3/08', 'G06N3/088', 'G06N3/09', 'G06T7/579', 'G06T7/74', 'G06V10/462', 'G06V10/764', 'G06V10/809', 'G06V10/82', 'G06V20/58', 'G06N3/048', 'G06T2207/10016', 'G06T2207/10028', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30252']"
US10318881B2,Systems and methods for quantum processing of data,"Systems, methods and aspects, and embodiments thereof relate to unsupervised or semi-supervised features learning using a quantum processor. To achieve unsupervised or semi-supervised features learning, the quantum processor is programmed to achieve Hierarchal Deep Learning (referred to as HDL) over one or more data sets. Systems and methods search for, parse, and detect maximally repeating patterns in one or more data sets or across data or data sets. Embodiments and aspects regard using sparse coding to detect maximally repeating patterns in or across data. Examples of sparse coding include L0 and L1 sparse coding. Some implementations may involve appending, incorporating or attaching labels to dictionary elements, or constituent elements of one or more dictionaries. There may be a logical association between label and the element labeled such that the process of unsupervised or semi-supervised feature learning spans both the elements and the incorporated, attached or appended label.","['G06N10/60', 'G06N20/00', 'G06N10/00', 'G06N99/002', 'G06N99/005', 'G06N99/00']"
US7805500B2,Network linking methods and apparatus,"Some portions of the present disclosure relate to processing audio signals for network linking. One claim recites an apparatus including: electronic memory for buffering data representing an audio signal; and an electronic processor. The electronic processor is programmed for: analyzing the data representing an audio signal to extract identifying data therefrom; controlling communication of the identifying data to a remote device over a network, in which the remote device uses the identifying data as an index to identify a pointer from among a plurality of pointers, the plurality of pointers each identifying a remote computer or resource on the network; and controlling use of a pointer identified by the index and received from the remote device over the network. Of course, other claims and combinations are provided too.","['H04L67/02', 'H04L67/563']"
AU2017389535B2,"Image tampering detection method and system, electronic apparatus and storage medium","Disclosed are an image tampering detection method and system, an electronic apparatus and a storage medium. The method comprises: A. performing block segmentation on an image to be detected, dividing the image to be detected into several small image fragments, and extracting initial tampering detection features from the various small image fragments; and B. encoding the extracted initial tampering detection features by using a predetermined encoder so as to generate complex tampering features, and determining, according to the generated complex tampering features, a tampering detection result corresponding to the image to be detected, wherein the tampering detection result comprises being tampered with and being non-tampered with. The present invention achieves the accurate detection of image tampering of different types and formats.","['G06T7/11', 'G06T7/0002', 'G06T1/0028', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/088', 'G06N3/09', 'G06N3/048', 'G06T2201/0201', 'G06T2207/10004', 'G06T2207/10024', 'G06T2207/20021', 'G06T2207/20081', 'G06T2207/20084']"
US20230127651A1,Digital-Twin-Enabled Digital Product Network System,"A digital product network system includes a set of digital products each having a product memory, a product network interface, and a product processor programmed with product instructions. The digital product network system includes a product network control tower having a control tower memory, a control tower network interface, and a control tower processor programmed with control tower instructions. The digital product network system includes a digital twin system defined at least in part by at least one of the product instructions or the control tower instructions to encode a set of digital twins representing the set of digital products","['G06Q10/08', 'G05B13/048', 'B25J9/16', 'G05B23/0283', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/08', 'G06N7/01', 'G06Q10/04', 'G06Q10/067', 'G06Q10/087', 'G06Q30/0201', 'G06Q30/0202', 'H04L9/50']"
CN113705877B,Real-time monthly runoff forecast method based on deep learning model,"The invention provides a real-time moon runoff forecasting method based on a deep learning model, which comprises the following steps: step 1, collecting forecasting factors based on historical information and future meteorological information, and determining the longest time delay of the influence of early stage month runoffs on forecasting months according to autocorrelation analysis of the month runoffs in the historical period of the river basin; step 2, respectively carrying out normalization processing on the forecasting factors in the training period and the month runoff data, and automatically screening the forecasting factors by adopting a LASSO regression method based on an embedded idea; step 3, clustering the training period sample set by adopting a K-means clustering method based on a partition idea, and dividing the samples into K classes which are not overlapped with each other; step 4, calculating the distance between the forecasting factor vector of the verification set and the clustering centers of K training sets, finding the training set closest to the training set, and training a combined deep learning forecasting model combined with a convolutional neural network and a gating circulation unit network by using the data set; and 5, correcting the forecast residual error in real time by adopting an autoregressive moving average model.","['G06Q10/04', 'G06F18/214', 'G06F18/23', 'G06N3/045', 'G06N3/08', 'Y02A10/40', 'Y02A90/10']"
US20190007695A1,Apparatus and methods for distance estimation using stereo imagery,"Frame sequences from multiple image sensors may be combined in order to form, for example, an interleaved frame sequence. Individual frames of the combined sequence may be configured a by combination (e.g., concatenation) of frames from one or more source sequences. The interleaved/concatenated frame sequence may be encoded using a motion estimation encoder. Output of the video encoder may be processed (e.g., parsed) in order to extract motion information present in the encoded video. The motion information may be utilized in order to determine a depth of visual scene, such as by using binocular disparity between two or more images by an adaptive controller in order to detect one or more objects salient to a given task. In one variant, depth information is utilized during control and operation of mobile robotic devices.","['H04N19/51', 'G06K9/00355', 'G06T7/285', 'G06T7/579', 'G06T7/593', 'G06V40/28', 'G06T2207/10021', 'G06T2207/30252']"
US11937147B2,Monitoring system for site safety and tracking,A worksite safety tracking system includes at least one network comprising a plurality of communicatively coupled electronic devices and at least one mobile tracking device communicatively coupled to the network. Alerts are generated by the network based on locations of the tracking device within the worksite.,"['H04W4/029', 'G06Q10/063114', 'G06Q50/08', 'G06Q50/265', 'G08B21/14', 'H04W4/021', 'G01S19/14', 'G01S19/51', 'G08B21/0446', 'G08B29/04']"
CN107288617B,A method and system for improving oil measurement accuracy of pumping unit dynamometer diagram,"The invention relates to the technical field of pumping units, in particular to a method for improving the oil measuring precision of an indicator diagram of a pumping well, which comprises the following steps of S101: preprocessing a ground indicator diagram; step S102: converting a ground indicator diagram; step S103: working condition diagnosis; step S104: primarily calculating the liquid yield; step S105: and finally calculating the liquid production amount. The invention also comprises a system for improving the oil measuring precision of the indicator diagram of the pumping well, which comprises an indicator diagram processing module, a working condition diagnosis and classification module, a liquid production amount metering module and a liquid production amount checking module which are sequentially connected. After the method and the system are adopted, the indicator diagram data of the pumping well collected and transmitted to the real-time database is analyzed, diagnosed and optimized, and the accuracy of the liquid production measurement of the pumping well can be greatly improved, so that the dynamic change of the oil well production can be accurately mastered, and the production management level of the oil well can be effectively improved.",['E21B47/00']
US11023785B2,Sparse MRI data collection and classification using machine learning,"A system, method and program product for implementing a sparse sampling strategy for acquiring MRI data. A method includes: collecting and labeling a training dataset of MRI scans for a predetermined diagnostic; selecting a sampling shape and associated parameter values; sampling each MRI scan in the training data set using the sampling shape and associated parameter values to generate a set of sparse samples; training a neural network using the sparse samples and assigning an accuracy to a resulting trained neural network; and adjusting the associated parameter values, and repeating the sampling and training until optimized parameter values are established.","['G06K9/6268', 'G06N3/08', 'G01R33/4818', 'G06F18/2136', 'G06F18/217', 'G06F18/241', 'G06F18/2433', 'G06K9/6249', 'G06K9/6262', 'G06K9/6284', 'G06N3/042', 'G06N5/02', 'G06T11/003', 'G06V10/7715', 'G06K2209/05', 'G06T2207/10088', 'G06V2201/03']"
CN112418329B,A method and system for cervical OCT image classification based on multi-scale texture feature fusion,"The invention provides a cervical OCT image depth supervision classification method and system based on multi-scale textural feature fusion, which divides an acquired 3D OCT image of cervical tissue into a training set and a test set; the method comprises the steps of constructing an OCT image classification model by using a convolutional neural network as a backbone network, fusing a multi-scale feature coding module and a feature fusion module, and finally classifying and outputting through a full connection layer and a SoftMax layer; adding a branch classifier to each branch in the multi-scale feature coding module by adopting a depth supervision mechanism, setting a corresponding loss function, adjusting the size of a 2D OCT image in a training set, and inputting the 2D OCT image into an OCT image classification model for training to obtain a trained OCT image classification model; and testing the OCT image classification model, and counting the prediction result. The invention introduces a multi-scale feature coding mechanism and a multi-scale feature fusion mechanism to optimize the basic model of the convolutional neural network, can better extract the features of the cervical OCT image and improve the classification effect of the cervical OCT image.","['G06F18/254', 'G06F18/214', 'G06F18/253', 'G06N3/045', 'G06N3/08', 'G06V2201/03']"
US11818806B2,ML model training procedure,"This disclosure provides systems, devices, apparatus, and methods, including computer programs encoded on storage media, for an ML model training procedure. A network entity may receive a trigger to activate an ML model training procedure based on at least one of an indication from an ML model repository or a protocol of the network entity. The network entity may transmit an ML model training request to activate the ML model training at one or more nodes. The one or more nodes may be associated with a RAN that may transmit, based on receiving the ML model training request, ML model training results indicative of a trained ML model. In aspects, an apparatus, such as a UE, may train the ML model based on an ML model training configuration received from the RAN, and transmit an ML model training report indicative of the trained ML model.","['H04L41/16', 'H04W88/08', 'G06F18/214', 'G06N20/00', 'H04L41/0816', 'H04W76/27', 'H04W88/14']"
CN109635820B,Construction method of Parkinson's disease bradykinesia video detection model based on deep neural network,"The invention discloses a construction method of a Parkinson's disease bradykinesia video detection model based on a deep neural network, which combines computer vision and deep learning technologies, evaluates the movement mode of a tested person through short video and judges the possibility of existence of bradykinesia symptoms. The invention simultaneously considers the motion behavior and the motion process, provides a detailed data acquisition method and a motion trail definition method, and designs three novel measurement indexes and a periodic motion network model PMNet to process the judgment problem of bradykinesia symptoms. Different from the traditional method, the method has the characteristics of expandability and portability, the key point extraction method based on the convolutional neural network can be replaced by other more accurate models, and more features can be added to describe the movement behavior. In addition, the invention can be competent for other similar periodic exercise evaluations, such as the finger tap action of item 3.4 of the MDS-UPDRS scale.","['G16H50/20', 'G06F18/21', 'G06N3/08', 'G06V10/462']"
CN114600457B,"Video encoding and decoding method, device and readable medium","The application provides a method, a device and a readable medium for video coding. A method of video encoding, comprising receiving a picture and determining a replacement representation of the picture by performing an optimization procedure for adjusting values of elements of the replacement representation to optimize rate-distortion performance of encoding the replacement representation based on an end-to-end E2E optimization framework. The E2E optimization framework is a pre-trained video coding and decoding framework based on an artificial neural network ANN. The alternate representation is encoded to generate a code stream.","['H04N19/85', 'G06N3/045', 'G06N3/0455', 'G06N3/0499', 'G06N3/08', 'G06N3/084', 'G06N3/09', 'G06N3/0985', 'H04N19/124', 'H04N19/147', 'H04N19/149', 'H04N19/172', 'H04N19/184', 'H04N19/192']"
US11889096B2,Video codec assisted real-time video enhancement using deep learning,"Techniques related to accelerated video enhancement using deep learning selectively applied based on video codec information are discussed. Such techniques include applying a deep learning video enhancement network selectively to decoded non-skip blocks that are in low quantization parameter frames, bypassing the deep learning network for decoded skip blocks in low quantization parameter frames, and applying non-deep learning video enhancement to high quantization parameter frames.","['H04N19/44', 'G06F18/251', 'G06N3/0464', 'G06N3/049', 'G06N3/08', 'G06T3/4007', 'G06T3/4046', 'G06T3/4053', 'G06T9/002', 'G06V10/82', 'H04N19/102', 'H04N19/103', 'H04N19/124', 'H04N19/132', 'H04N19/159', 'H04N19/172', 'H04N19/176', 'H04N19/184', 'H04N19/30', 'H04N19/42', 'H04N19/503', 'H04N19/513', 'H04N19/587', 'H04N19/59', 'H04N19/593', 'H04N19/85', 'G06N3/045', 'G06T2207/20081', 'G06T2207/20084']"
US11340939B1,Application-aware analytics for storage systems,"Providing application-aware analytics for storage systems, including: collecting, by a workload migration module, from a first host, first data describing performance characteristics of the first host and second data describing performance characteristics of one or more clients connected to the first host and associated with a workload supported by the first host; identifying, based on the data, a second host for servicing the workload; and deploying the workload in the second host.","['G06F9/4856', 'G06F9/5088', 'G06F3/0604', 'G06F3/061', 'G06F3/0647', 'G06F3/067', 'G06F9/5016', 'G06F2209/501', 'G06F8/60']"
US12315040B2,Method and device for imaging of lensless hyperspectral image,Disclosed are a hyperspectral imaging method and an apparatus thereof. A method of reconstructing a hyperspectral image includes receiving an image photographed through a diffractive optical element and reconstructing a hyperspectral image of the received image based on the received image and information about a point spread function for each wavelength of the diffractive optical element. The diffractive optical element may generate an anisotropic shape of the point spread function that varies with a spectrum.,"['G06T11/001', 'G02B5/18', 'G01J3/18', 'G01J3/28', 'G01J3/2823', 'G02B27/4205', 'G06N3/045', 'G06N3/08', 'G06T5/50', 'G06T5/60', 'G06T5/73', 'H04N23/55', 'H04N9/01', 'G01J2003/2826', 'G06T2207/10036', 'G06T2207/20081', 'G06T2207/20084', 'G06T2207/30181']"
US9973473B2,"Methods, systems, and computer readable media for rapid filtering of opaque data traffic","Methods, systems, and computer readable media for rapid filtering of opaque data traffic are disclosed. According to one method, the method includes receiving a packet containing a payload. The method also includes analyzing a portion of the payload for determining whether the packet contains compressed or encrypted data. The method further includes performing, if the packet contains compressed or encrypted data, at least one of sending the packet to an opaque traffic analysis engine for analysis, discarding the packet, logging the packet, or marking the packet.","['H04L63/0245', 'H04L63/1416']"
US10408189B2,Efficient systems and methods for construction and operation of mobile wind power platforms,"In embodiments of the present invention improved capabilities are described for a mobile wind power support structure, comprising a superstructure with mobile platform support structures, and a plurality of deployable rotating wind power structures, wherein the plurality of deployable rotating wind power structures are positioned in the superstructure through a wind orientation facility.","['F03D1/04', 'F03D1/025', 'F03D13/20', 'F03D80/70', 'F03D9/11', 'F03D9/25', 'F05B2220/706', 'F05B2240/133', 'F05B2240/30', 'F05B2240/40', 'F05B2240/914', 'F05B2240/98', 'F05B2250/132', 'Y02B10/30', 'Y02B10/70', 'Y02E10/72', 'Y02E10/721', 'Y02E10/725', 'Y02E10/728', 'Y02E70/30']"
US7831358B2,Arrangement and method for obtaining information using phase difference of modulated illumination,"Land-based vehicle including an arrangement for monitoring objects in or about a vehicle includes a source from which modulated illumination is emitted into an area in or about the vehicle, a receiver arranged to receive illumination reflected from an object in the path of the modulated illumination, and circuitry coupled to the receiver and the source and arranged to compare a phase of the modulated illumination with a phase of the reflected radiation at a common frequency to determine whether there is a phase difference between the modulated illumination and the reflected illumination. The phase difference is a measure of a property of the object, such as the distance between the object and the source/receiver, which can be co-located. Otherwise, if the source and receiver and not co-located or substantially co-located, the distance is a measure of the distance of travel of the illumination.","['B60R21/01542', 'B60R21/01516', 'B60R21/0152', 'B60R21/0153', 'E05F15/73', 'E05Y2900/50']"
US7768380B2,Security system control for monitoring vehicular compartments,"Security system and method for monitoring vehicular compartments includes at least one optical image receiving unit arranged to receive optical images of a compartment of the vehicle, e.g., from at least a portion of the face of a person located at a driver's station in a passenger compartment of the vehicle, and produce image signals therefrom and a processor including an electronic facial-recognition system coupled to the optical image receiving unit(s) responsive to the image signals and controllably coupled to the enabling system, and an electronic storage device coupled to the facial-recognition system to store a set of image signals. The facial-recognition system enables ignition of the vehicle system only if signals representative of select characteristics of a scanned face of the person derived from the image signals produced by the optical image receiving unit(s) match a member of a set of signals stored in the electronic storage device. Each member representative of select characteristics of the scanned face of an authorized operator.","['G06V20/59', 'B60N2/0022', 'B60N2/0025', 'B60N2/0026', 'B60N2/0028', 'B60N2/0029', 'B60N2/0031', 'B60N2/0033', 'B60N2/0035', 'G06V40/10', 'B60N2/267', 'B60N2210/12', 'B60N2210/16', 'B60N2210/18', 'B60N2210/20', 'B60N2210/24', 'B60N2210/26', 'B60N2210/42', 'B60N2220/30', 'B60N2230/30']"
US20220245574A1,"Systems, Methods, Kits, and Apparatuses for Digital Product Network Systems and Biology-Based Value Chain Networks","A digital product network system generally includes a set of digital products each having a product memory, a product network interface, and a product processor programmed with product instructions; a product network control tower having a control tower memory, a control tower network interface, and a control tower processor programmed with control tower instructions; and a digital twin system defined at least in part by at least one of the product instructions or the control tower instructions to encode a set of digital twins representing the set of digital products.","['G06Q10/087', 'G06F9/451', 'G05B2219/40113']"
US20240144103A1,"Systems, methods, kits, and apparatuses for ai- driven digital twins for value chain network control towers","A VCN process may receive, by a value chain network digital twin, information associated with a value chain network. A VCN process may provide the information to a set of Artificial Intelligence (AI)-based learning models, wherein at least one member of the set of AI-based learning models is trained to classify at least one of: an operating state, a fault condition, an operating flow, or a behavior of the value chain network and at least one member of the set of AI-based learning models is trained to determine a task to be completed for the value chain network. A VCN process may provide at least one of an instruction for executing the task in the value chain network digital twin and a recommendation for executing the task in the value chain network digital twin.","['G06N20/00', 'G05D1/0297', 'G05B19/4155', 'G05B19/41885', 'G05D1/223', 'G05D1/6987', 'G06N3/08', 'G06Q10/06', 'G06Q10/0635', 'G06Q10/06375', 'G06Q10/06395', 'G06Q10/08', 'G06Q10/0833', 'G06Q10/087', 'G06Q10/0875', 'G06Q30/0201', 'G06Q30/0202', 'G06Q50/04', 'G06Q50/40', 'G05B2219/50391', 'G05D2101/15', 'G05D2107/70', 'G05D2109/10', 'G06N20/10', 'G06N20/20', 'G06N3/006', 'G06N3/044', 'G06N3/0455', 'G06N3/049', 'G06N3/084', 'G06N3/088', 'G06N5/01', 'G06N7/01', 'G06Q2220/00']"
US7655895B2,Vehicle-mounted monitoring arrangement and method using light-regulation,"Land-based vehicle including an arrangement for monitoring objects in or about a vehicle which includes a source from which illumination is emitted into an area in or about the vehicle, a receiver arranged to receive illumination reflected from an object in the path of the illumination, a light-regulating component arranged in front of the receiver to regulate reception of illumination by the receiver, and circuitry coupled to the source, the receiver and the light-regulating component. The light-regulating component is modulated to enable a determination of a distance between an object from which the illumination has been reflected and the receiver. The circuitry obtains information about objects from which the received illumination has been reflected other than distance information and associates with the objects distances between the objects and the receiver. This improves the ability to control vehicular systems based on the presence of objects in or about the vehicle.","['B60R21/01542', 'B60R21/01516', 'B60R21/0152', 'B60R21/0153']"
US11748555B2,Systems and methods for machine content generation,"Computerized systems and methods are disclosed to generate a document by providing a document structure having one or more seed landmark texts therein, each landmark text including a milestone overview text and a plurality of component texts; from the milestone overview text, generating one or more computer-generated text suggestions to supplement the milestone overview text; combining the milestone overview text with each component text and generating one or more computer-generated component text suggestions; and creating the document by combining the milestone overview, the one or more computer-generated text suggestions, and each component text with corresponding one or more computer-generated component text suggestions.","['G06F40/169', 'G06F21/1015', 'G06F21/32', 'G06F40/137', 'G06N20/00', 'G06N3/044', 'G06N3/045', 'G06N3/047', 'G06N3/088', 'G06N5/022', 'G06F21/105', 'G06F40/30']"
US9137417B2,Systems and methods for processing video data,"A method includes storing raw or normalized video data in a computer accessible storage medium; analyzing portions of the video data with a first analytic engine to: determine whether the raw video data is within a first set of parameters; and generate with the first analytic engine a first set of processor settings; processing the raw or normalized video data with the first set of processor settings; and analyzing portions of the processed data with a second analytic engine to determine whether the processed data is within a second set of parameters; generating with the second analytic engine a second set of processor settings to reprocess the raw or normalized video data, sending the second set of processor settings to the first analytic engine; and reprocessing the raw or normalized video data with the first analytic engine using the second set of processor settings.","['H04N1/40', 'G06K9/3208', 'G06T5/00', 'G06V10/242', 'H04N1/40093', 'G06T2207/10008', 'G06T2207/30168', 'H04N2201/0458']"
US11786251B2,Method for adaptive control schemes for surgical network control and interaction,"A method for adaptive control of surgical network control and interaction is disclosed. The surgical network includes a surgical feedback system. The surgical feedback system includes a surgical instrument, a data source, and a surgical hub configured to communicably couple to the data source and the surgical instrument. The surgical hub includes a control circuit. The method includes receiving, by the control circuit, information related to devices communicatively coupled to the surgical network; and adaptively controlling, by the control circuit, the surgical network based on the received information.","['A61B17/1155', 'A61B1/00006', 'A61B1/00009', 'A61B1/000096', 'A61B1/00011', 'A61B1/00045', 'A61B1/051', 'A61B1/0661', 'A61B17/0682', 'A61B17/072', 'A61B17/07207', 'A61B17/1114', 'A61B17/1285', 'A61B17/320092', 'A61B18/1442', 'A61B18/1445', 'A61B34/20', 'A61B34/25', 'A61B34/32', 'A61B34/71', 'A61B5/0066', 'A61B5/0075', 'A61B5/0261', 'A61B6/5247', 'A61B90/35', 'A61B90/361', 'A61M1/73', 'A61M1/79', 'B25J13/006', 'B25J9/1689', 'B25J9/1697', 'G06K19/07749', 'G06K7/10316', 'G16H10/60', 'G16H20/40', 'G16H40/40', 'G16H40/63', 'G16H40/67', 'G16H50/20', 'G16H70/20', 'H01Q1/22', 'H01Q9/0407', 'H04L63/123', 'H04L63/1416', 'H04L67/10', 'H04L67/12', 'H04N5/272', 'H04N7/183', 'H05K1/028', 'H05K1/189', 'A61B1/04', 'A61B1/06', 'A61B17/0469', 'A61B17/07292', 'A61B18/1402', 'A61B2017/00017', 'A61B2017/00022', 'A61B2017/00026', 'A61B2017/0003', 'A61B2017/00039', 'A61B2017/00044', 'A61B2017/00057', 'A61B2017/00061', 'A61B2017/00075', 'A61B2017/00084', 'A61B2017/00097', 'A61B2017/00106', 'A61B2017/0011', 'A61B2017/00115', 'A61B2017/00119', 'A61B2017/00123', 'A61B2017/00128', 'A61B2017/00199', 'A61B2017/00203', 'A61B2017/00221', 'A61B2017/00225', 'A61B2017/00398', 'A61B2017/00402', 'A61B2017/00734', 'A61B2017/00809', 'A61B2017/00818', 'A61B2017/07257', 'A61B2017/07271', 'A61B2017/07278', 'A61B2017/07285', 'A61B2017/1132', 'A61B2017/32007', 'A61B2017/320074', 'A61B2017/320084', 'A61B2017/320095', 'A61B2017/320097', 'A61B2018/00541', 'A61B2018/00589', 'A61B2018/00595', 'A61B2018/00601', 'A61B2018/00607', 'A61B2018/0063', 'A61B2018/00642', 'A61B2018/00684', 'A61B2018/00702', 'A61B2018/00779', 'A61B2018/00791', 'A61B2018/00827', 'A61B2018/00875', 'A61B2018/00892', 'A61B2018/00988', 'A61B2018/00994', 'A61B2018/1253', 'A61B2018/167', 'A61B2034/2055', 'A61B2034/2057', 'A61B2034/2065', 'A61B2034/256', 'A61B2034/258', 'A61B2034/301', 'A61B2034/305', 'A61B2090/064', 'A61B2090/0807', 'A61B2090/0809', 'A61B2090/309', 'A61B2217/005', 'A61B2217/007', 'A61B2218/002', 'A61B2218/007', 'A61B2218/008', 'A61B34/30', 'A61B90/30', 'A61B90/98', 'A61M1/80', 'A61M13/003', 'A61M2205/3306', 'A61M2205/3327', 'A61M2205/3331', 'A61M2205/3365', 'A61M2205/3368', 'G05B2219/40174', 'G05B2219/45119', 'H04W12/63']"
US20220019204A1,"Intelligent data object model for distributed product manufacturing, assembly and facility infrastructure","A computer aided process for creation of a manufacturing facility, for production of a user-selected product, relies on a set of functional modules for specification of the facility's floorspace requirements, manufacturing equipment, and equipment layout to allow optimization of the facility for a production capacity specified by the user.","['G06F30/15', 'G05B19/41805', 'G05B19/41865', 'G05B19/4188', 'G05B19/41885', 'G06F16/906', 'G06F16/907', 'G06F16/951', 'G06F30/20', 'G06F30/27', 'G06N3/042', 'G06N5/022', 'G06Q10/0631', 'G06Q50/04', 'G05B2219/32085', 'G05B2219/32335', 'G05B2219/32345', 'G06F18/214', 'G06K9/6256', 'G06N3/08', 'Y02P90/02', 'Y02P90/30']"
US10697294B2,Vibration while drilling data processing methods,"A method for determining properties of rock formations using drill string vibration measurements includes entering into a processor signals corresponding to vibrations detected along a rotating part of a drill string while drilling a borehole. The vibration signals are transformed into transformed signals representing elastic response of the drill string, the rock formations and borehole fluid to a filtered impulse originating at a known location along the drill string. Properties of the rock formations are calculated using the transformed signals.","['E21B49/005', 'E21B47/122', 'E21B47/13', 'E21B49/003', 'G01V1/282', 'G01V1/306', 'G01V1/50', 'G01V2200/16', 'G01V2210/1216']"
EP4156171A1,Singing voice separation with deep u-net convolutional networks,"A method for estimating a component of a provided audio signal, comprising converting the provided audio signal to an image, applying the image to a U-Net trained to estimate one of vocal content and instrumental content; and converting an output of the U-Net to an output audio signal, the output audio signal representing an estimate of either a vocal component of the provided audio signal or an instrumental component of the provided audio signal, depending on whether the U-Net is trained to estimate the vocal content or the instrumental content, respectively.","['G10L25/81', 'G10L21/0272', 'G06N3/045', 'G06N3/08', 'G06N3/084', 'G10H1/0008', 'G10H1/0033', 'G10H1/365', 'G10L15/16', 'G10L21/06', 'G06N3/082', 'G10H2210/056', 'G10H2250/235', 'G10H2250/311', 'G10H2250/455', 'G10L25/18', 'G10L25/30']"
US12135685B2,Verifying data has been correctly replicated to a replication target,"Verifying that data has been correctly replicated to a replication target, including: replicating a dataset stored at a first computing system to a second computing system; and determining, based at least on a comparison of a first hash and a second hash, validity of the dataset stored at the second computing system, wherein the first hash is generated by applying a hash function to a copy of the dataset that is stored at the first computing system and the second hash is generated by applying the hash function to a copy of the dataset that is stored at the second computing system.","['G06F3/065', 'G06F16/128', 'G06F16/183', 'G06F16/27', 'G06F21/6272', 'G06F21/64', 'G06F21/78', 'G06F3/0607', 'G06F3/0619', 'G06F3/0646', 'G06F3/067', 'G06F3/0688']"
US10663977B2,Method for dynamically querying a remote operator for assistance,"One variation of a method for dynamically querying a remote operator for assistance includes, at an autonomous vehicle: autonomously navigating along a roadway; at locations along the roadway, testing performance of a set of wireless networks; in response to degradation of the set of wireless networks, decreasing a sensitivity threshold for triggering remote operator events at the autonomous vehicle; in response to a condition at the autonomous vehicle exceeding the sensitivity threshold at a particular location along the roadway, triggering a remote operator event; during the remote operator event, transmitting sensor data to a remote computer system via a subset of wireless networks, in the set of wireless networks, based on performance of the set of wireless networks proximal the particular location; and executing a navigational command received from a remote operator via a wireless network in the set of wireless networks.","['G05D1/0285', 'H04W4/024', 'G05D1/0011', 'G05D1/0022', 'G05D1/0027', 'G05D1/0088', 'H04W4/40', 'H04W4/44', 'G05D2201/0213', 'H04W84/042']"
US11373368B2,Reality-based three-dimensional infrastructure reconstruction,"Two-dimensional aerial images and other geo-spatial information are processed to produce land classification data, vector data and attribute data for buildings found within the images. This data is stored upon a server computer within shape files, and also stored are source code scripts describing how to reconstruct a type of building along with compiled versions of the scripts. A software game or simulator executes upon a client computer in which an avatar moves within a landscape. A classifier classifies a type of building in the shape file to execute the appropriate script. Depending upon its location, a scene composer downloads a shape file and a compiled script is executed in order to reconstruct any number of buildings in the vicinity of the avatar. The script produces a three-dimensional textured mesh which is then rendered upon a screen of the client computer to display a two-dimensional representation of the building.","['G06T17/20', 'G06T17/05', 'G06F8/44', 'G06F8/60', 'G06T15/04', 'G06T19/00', 'G06T3/0031', 'G06T3/06', 'H04L67/06', 'H04L67/131', 'H04L67/52', 'G06F9/44521', 'G06T2210/36']"
US11455409B2,Storage layer data obfuscation,"Storage layer data obfuscation, including: determining a subset of a dataset to obfuscate in accordance with a security policy; generating, based at least in part on the security policy, an obfuscated snapshot of the dataset that is representative of the dataset with the subset of the dataset obfuscated; and sending, to a target computer system, the obfuscated snapshot from which a restored version of the dataset includes the subset of the dataset obfuscated.","['G06F16/212', 'G06F16/221', 'G06F21/6218', 'G06F3/0623', 'G06F3/065', 'G06F3/067', 'G06F3/0689']"
US12328167B2,Method and device for transmitting channel state information,"Disclosed are a method and a device for transmitting channel state information. The method comprises: a first device constructs a training set of a channel state information indication model that is used by the first device for transmitting channel state information, and the sample structure of the plurality of samples included in the training set being determined according to an M*N matrix structure, each line amongst the M rows of the matrix structure corresponding to a plurality of sub-carriers on the frequency domain or a preset duration on the time domain, each column amongst the N columns of the matrix structure corresponding to at least one antenna or a preset angle on the spatial domain, and each value in the matrix structure representing the channel quality of the corresponding frequency domain or spatial domain or representing the channel quality of the corresponding time domain or spatial domain.","['H04B7/0632', 'H04B7/0626', 'H04B7/0617', 'H04B7/063', 'H04B7/0634', 'H04B7/086']"
US20210287069A1,Name matching engine boosted by machine learning,"Techniques are described herein for a Name Matching Engine that integrates two Machine Learning (ML) module options. The first ML module is a feature-engineered classifier that boosts text-based name matching techniques with a binary classifier ML model. The feature-engineered classifier comprises a first stage of text-based candidate finding, and a second stage in which a binary classifier model predicts whether each string, of the candidate match list, is a match or not. The binary classifier model is based on features from two or more of: a name feature level, a word feature level, a character feature level, and an initial feature level. The second ML module of the Name Matching Engine comprises an end-to-end Recurrent Neural Network (45RNN) model that directly accepts name strings as a sequence of n-grams and generates learned text embeddings. The text embeddings of matching name strings are close to each other in the feature space.","['G06F16/90344', 'G06N3/0454', 'G06F18/2113', 'G06F18/214', 'G06F18/22', 'G06F18/24133', 'G06F40/295', 'G06F40/30', 'G06K9/6215', 'G06K9/623', 'G06K9/6256', 'G06N3/044', 'G06N3/045', 'G06N3/048', 'G06N3/08', 'G06N3/084', 'G06N5/04', 'G06N20/20', 'G06N5/01']"
CN109992710B,"Click rate estimation method, system, medium and computing device","The embodiment of the invention provides a click rate estimation method, which comprises the following steps: obtaining a training sample set based on first feature information corresponding to a plurality of historical click information of a user, wherein each first feature information is used for representing a feature attribute of the corresponding historical click information; performing logistic regression training based on the training sample set to obtain a logistic regression model; generating a first embedded vector based on the logistic regression model, wherein the first embedded vector is used for representing a weight value corresponding to each piece of first characteristic information; and performing deep neural network training based on the first embedded vector to obtain a click rate prediction model, wherein the click rate prediction model is used for predicting the click rate of the information to be recommended of the user. The invention takes the embedded vector as the link, not only keeps the memory capability of the embedded vector, but also considers the generalization capability of the embedded vector, and greatly improves the accuracy of click rate estimation. The embodiment of the invention also provides a click rate pre-estimation system, a medium and a computing device.","['G06F18/214', 'G06N3/08', 'G06Q10/04']"
CN112101152B,"Electroencephalogram emotion recognition method, electroencephalogram emotion recognition system, computer equipment and wearable equipment","The invention belongs to the technical field of intersection of machine learning and emotion recognition, and discloses an electroencephalogram emotion recognition method, an electroencephalogram emotion recognition system, computer equipment and wearable equipment, wherein the influence of non-emotion signals on emotion recognition is reduced by removing electroencephalogram signals generated during initial video conversion and subtracting the average value of the signals from the rest data; extracting time-frequency domain characteristics of the preprocessed electroencephalogram signals by using short-time Fourier transform; the features are put into a convolutional neural network for training, and high-quality features are extracted; and performing hypergraph learning on the obtained features, constructing a hypergraph classifier model, and completing emotion classification recognition. According to the invention, the time-frequency characteristics of the electroencephalogram signals are optimized by adopting a deep learning method, and then the training and classification are carried out by sampling by using a hypergraph learning method, so that the training time is effectively shortened and the operation space is compressed on the basis of improving the hypergraph learning classification accuracy, and the method has important significance for the design and research and development of portable wearable equipment.","['G06F2218/12', 'G06N3/045', 'G06N3/08', 'G06F2218/02', 'G06F2218/08']"
US20230266308A1,Uses of systems with degrees of freedom poised between fully quantum and fully classical states,"Disclosed herein are systems and uses of systems operating between fully quantum coherent and fully classical states. Such systems operate in what is termed the “Poised realm” and exhibit unique behaviors that can be applied to a number of useful applications. Non-limiting examples include drug discovery, computers, and artificial intelligence","['G01N33/54366', 'B82Y10/00', 'G06N10/00', 'G06N10/20', 'G06N10/70', 'G16B35/00', 'G16C20/50', 'G16C20/60', 'G16C20/64', 'G01N2500/04', 'G01N2500/20']"
CN113343821B,Non-contact heart rate measurement method based on space-time attention network and input optimization,"The invention discloses a non-contact heart rate measuring method based on a space-time attention network and input optimization, which comprises the following steps: 1, acquiring a data set containing a face video, a label physiological signal and a label heart rate, and preprocessing; 2, training a super-resolution model ESRGAN for recovering physiological information in the image; 3, constructing a space-time attention network model M; 4, training a space-time attention network model M by adopting a transfer learning strategy to obtain a preliminarily trained space-time attention network model M'; and 5, performing combined training on the generator S 'in the preliminarily trained ESRGAN and the preliminarily trained space-time attention network model M' to realize non-contact heart rate measurement. The invention can effectively and accurately extract the rPPG signal, greatly improve the quality of the extracted signal, and calculate the heart rate information from the rPPG signal, thereby obviously improving the accuracy of non-contact heart rate measurement.","['G06F18/214', 'G06F18/253']"
US20230252224A1,Systems and methods for machine content generation,"Computerized systems and methods are disclosed to generate a document with a transformer by prompt-engineering the transformer with a title and a summary to generate a description of the document; displaying a set of claims and allowing user editing of the set of claims; receiving one or more figures; receiving a part list with a plurality of element names for each figure; generating an expanded description of each element name through prompt engineering based on prior text in the document; selecting one or more boilerplate texts for major sections of the document; and organizing the document with the title, a background, the summary, a brief description of the drawings, and a detailed description.","['G06F40/151', 'G06F3/0482', 'G06F3/04845', 'G06F40/166', 'G06F40/40', 'G06F40/56', 'G06Q10/10', 'G06Q50/184']"
US10426442B1,Adaptive image processing in assisted reproductive imaging modalities,"Adaptive image processing, image analysis, pattern recognition, and time-to-event prediction in various imaging modalities associated with assisted reproductive technology. The reference image may be processed according to one or more adaptive processing frameworks for de-speckling or noise processing of ultrasound images. The subject image is processed according to various computer vision techniques for object detection, recognition, annotation, segmentation, and classification of reproductive anatomy, such as follicles, ovaries and the uterus. An image processing framework may also analyze secondary data along with subject image data to analyze time-to-event progression of the subject image.","['A61B8/085', 'A61B8/5207', 'A61B8/5223', 'A61D19/02', 'G16H10/60', 'G16H30/20', 'G16H30/40', 'G16H40/20', 'G16H40/63', 'G16H50/20', 'A61B8/0866', 'A61B8/483', 'G06T2207/10136', 'G06T2207/30044', 'Y02A90/10']"
US10721859B2,Monitoring and control implement for crop improvement,"An example machinery includes an automated crop management motorized vehicle having an intelligent, modularized image sensor (e.g. camera or video) system that is portable to other crop management vehicles such as a combine, planter or a tillage machine. The image sensor system includes a framework having a bank of procedures for monitoring and control of navigation, spray application, weeding, seeding, machine configuration, in real time as the machines go through a crop field throughout a crop cycle. One example implementation includes electronic circuits, with more than one set mounted on a platform that facilitates moving the setup to other agricultural machines. The framework captures, preserves and corrects the captured images for real time analysis and response, and for spray management to improve crop yield that is correlated with the machine settings and crop management practices.","['H04N7/188', 'A01C21/007', 'A01C21/005', 'B60R11/04', 'G06T7/0004', 'G06T7/73', 'H04N23/51', 'H04N5/2252', 'H04N7/181', 'A01M7/0089', 'G06T2207/10021', 'G06T2207/10028', 'G06T2207/30188']"
TWI868284B,"Parallel processor, accelerator device, and method of performing parallel processing","Described herein is an accelerator device including a host interface, a fabric interconnect coupled with the host interface, and one or more hardware tiles coupled with the fabric interconnect, the one or more hardware tiles including sparse matrix multiply acceleration hardware including a systolic array with feedback inputs.","['G06F7/5443', 'G06T1/20', 'G06F15/8046', 'G06F17/16', 'G06F7/523', 'G06F9/3001', 'G06F9/30036', 'G06F9/30038', 'G06F9/30145', 'G06N20/00', 'G06N3/063', 'G06T1/60', 'G06N3/045', 'G06N3/08']"
US20230135553A1,AI-Managed Additive Manufacturing for Value Chain Networks,"A distributed manufacturing network information technology system includes a cloud-based additive manufacturing management platform with a user interface, connectivity facilities, data storage facilities, and monitoring facilities. The distributed manufacturing network information technology system includes a set of applications for enabling the additive manufacturing management platform to manage a set of distributed manufacturing network entities. The distributed manufacturing network information technology system includes an artificial intelligence system configured to learn on a training set of outcomes, parameters, and data collected from the distributed manufacturing network entities to optimize manufacturing and value chain workflows.","['G06Q10/06313', 'G05D1/0297', 'G06Q20/14', 'B22F10/85', 'B25J9/161', 'B25J9/163', 'B25J9/1653', 'B25J9/1661', 'B25J9/1671', 'B25J9/1682', 'B25J9/1697', 'B29C64/357', 'B29C64/379', 'B29C64/386', 'B29C64/393', 'B33Y10/00', 'B33Y40/00', 'B33Y50/00', 'B33Y50/02', 'G02B26/00', 'G05B13/0265', 'G05B13/042', 'G05B17/02', 'G05B19/402', 'G05B19/4097', 'G05B19/4099', 'G05B19/41865', 'G05D1/0027', 'G05D1/0221', 'G05D1/221', 'G05D1/6987', 'G06F30/27', 'G06N20/00', 'G06N20/10', 'G06N20/20', 'G06N3/006', 'G06N3/045', 'G06N3/084', 'G06N3/088', 'G06N5/025', 'G06Q10/06311', 'G06Q10/0633', 'G06Q10/0635', 'G06Q10/087', 'G06Q10/10', 'G06Q50/04', 'G06T7/70', 'H04L63/1441', 'H04L9/3239', 'H04L9/50', 'B22F10/70', 'B22F2998/00', 'B29C64/10', 'G02B3/14', 'G05B2219/32015', 'G05B2219/32117', 'G05B2219/32254', 'G05B2219/32291', 'G05B2219/32365', 'G05B2219/33006', 'G05B2219/35134', 'G05B2219/36252', 'G05B2219/39146', 'G05B2219/39167', 'G05B2219/40113', 'G05B2219/49023', 'G06F2113/10', 'G06Q10/06', 'G06Q10/0631', 'G06Q10/063114', 'G06Q10/06316', 'G06Q10/06395', 'G06Q10/0831', 'G06Q10/0833', 'G06Q2220/00', 'G06Q30/0201', 'G06T2207/20081', 'Y02P80/10', 'Y02P80/40', 'Y02P90/02', 'Y02P90/30', 'Y02P90/84']"
